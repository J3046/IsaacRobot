################################################################################
                      [1m Learning iteration 0/1500 [0m                       

                       Computation: 11139 steps/s (collection: 8.548s, learning 0.277s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0018
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 25.5662
                       Mean reward: 0.00
               Mean episode length: 21.93
    Episode_Reward/reaching_object: 0.0005
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0002
          Episode_Reward/joint_vel: -0.0002
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 8.82s
                      Time elapsed: 00:00:08
                               ETA: 03:40:36

################################################################################
                      [1m Learning iteration 1/1500 [0m                       

                       Computation: 15370 steps/s (collection: 6.234s, learning 0.162s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0003
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 25.6756
                       Mean reward: 0.00
               Mean episode length: 45.42
    Episode_Reward/reaching_object: 0.0013
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0005
          Episode_Reward/joint_vel: -0.0006
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 6.40s
                      Time elapsed: 00:00:15
                               ETA: 03:10:07

################################################################################
                      [1m Learning iteration 2/1500 [0m                       

                       Computation: 15426 steps/s (collection: 6.228s, learning 0.145s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 25.6684
                       Mean reward: 0.00
               Mean episode length: 69.07
    Episode_Reward/reaching_object: 0.0022
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0009
          Episode_Reward/joint_vel: -0.0010
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 6.37s
                      Time elapsed: 00:00:21
                               ETA: 02:59:41

################################################################################
                      [1m Learning iteration 3/1500 [0m                       

                       Computation: 14717 steps/s (collection: 6.536s, learning 0.144s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 25.7144
                       Mean reward: 0.00
               Mean episode length: 93.12
    Episode_Reward/reaching_object: 0.0031
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0012
          Episode_Reward/joint_vel: -0.0015
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 6.68s
                      Time elapsed: 00:00:28
                               ETA: 02:56:20

################################################################################
                      [1m Learning iteration 4/1500 [0m                       

                       Computation: 14253 steps/s (collection: 6.762s, learning 0.135s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 25.7353
                       Mean reward: 0.01
               Mean episode length: 117.84
    Episode_Reward/reaching_object: 0.0045
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0016
          Episode_Reward/joint_vel: -0.0019
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 6.90s
                      Time elapsed: 00:00:35
                               ETA: 02:55:22

################################################################################
                      [1m Learning iteration 5/1500 [0m                       

                       Computation: 15171 steps/s (collection: 6.335s, learning 0.144s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 25.7594
                       Mean reward: 0.01
               Mean episode length: 141.19
    Episode_Reward/reaching_object: 0.0056
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0019
          Episode_Reward/joint_vel: -0.0023
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 6.48s
                      Time elapsed: 00:00:41
                               ETA: 02:52:57

################################################################################
                      [1m Learning iteration 6/1500 [0m                       

                       Computation: 14886 steps/s (collection: 6.457s, learning 0.147s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 25.7487
                       Mean reward: 0.01
               Mean episode length: 165.18
    Episode_Reward/reaching_object: 0.0071
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0023
          Episode_Reward/joint_vel: -0.0027
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 6.60s
                      Time elapsed: 00:00:48
                               ETA: 02:51:38

################################################################################
                      [1m Learning iteration 7/1500 [0m                       

                       Computation: 14846 steps/s (collection: 6.496s, learning 0.125s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 25.7234
                       Mean reward: 0.02
               Mean episode length: 189.88
    Episode_Reward/reaching_object: 0.0092
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0026
          Episode_Reward/joint_vel: -0.0031
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 6.62s
                      Time elapsed: 00:00:54
                               ETA: 02:50:40

################################################################################
                      [1m Learning iteration 8/1500 [0m                       

                       Computation: 20187 steps/s (collection: 4.778s, learning 0.092s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 25.7103
                       Mean reward: 0.04
               Mean episode length: 213.51
    Episode_Reward/reaching_object: 0.0118
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0030
          Episode_Reward/joint_vel: -0.0035
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 4.87s
                      Time elapsed: 00:00:59
                               ETA: 02:45:03

################################################################################
                      [1m Learning iteration 9/1500 [0m                       

                       Computation: 64941 steps/s (collection: 1.421s, learning 0.093s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 25.7153
                       Mean reward: 0.05
               Mean episode length: 236.90
    Episode_Reward/reaching_object: 0.0141
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0033
          Episode_Reward/joint_vel: -0.0039
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 1.51s
                      Time elapsed: 00:01:01
                               ETA: 02:32:13

################################################################################
                      [1m Learning iteration 10/1500 [0m                      

                       Computation: 66139 steps/s (collection: 1.387s, learning 0.099s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 25.7271
                       Mean reward: 0.05
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0184
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 1.49s
                      Time elapsed: 00:01:02
                               ETA: 02:21:38

################################################################################
                      [1m Learning iteration 11/1500 [0m                      

                       Computation: 65327 steps/s (collection: 1.409s, learning 0.096s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 25.7494
                       Mean reward: 0.07
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0208
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 1.50s
                      Time elapsed: 00:01:04
                               ETA: 02:12:51

################################################################################
                      [1m Learning iteration 12/1500 [0m                      

                       Computation: 65685 steps/s (collection: 1.403s, learning 0.094s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 25.7667
                       Mean reward: 0.11
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0275
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 1.50s
                      Time elapsed: 00:01:05
                               ETA: 02:05:25

################################################################################
                      [1m Learning iteration 13/1500 [0m                      

                       Computation: 65399 steps/s (collection: 1.412s, learning 0.091s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 25.7440
                       Mean reward: 0.14
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0358
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 1.50s
                      Time elapsed: 00:01:07
                               ETA: 01:59:02

################################################################################
                      [1m Learning iteration 14/1500 [0m                      

                       Computation: 64500 steps/s (collection: 1.435s, learning 0.090s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0004
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 25.7586
                       Mean reward: 0.24
               Mean episode length: 249.66
    Episode_Reward/reaching_object: 0.0466
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 1.52s
                      Time elapsed: 00:01:08
                               ETA: 01:53:32

################################################################################
                      [1m Learning iteration 15/1500 [0m                      

                       Computation: 60690 steps/s (collection: 1.525s, learning 0.095s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0007
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 25.8069
                       Mean reward: 0.36
               Mean episode length: 248.78
    Episode_Reward/reaching_object: 0.0680
    Episode_Reward/rotating_object: 0.0002
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 1.62s
                      Time elapsed: 00:01:10
                               ETA: 01:48:53

################################################################################
                      [1m Learning iteration 16/1500 [0m                      

                       Computation: 58255 steps/s (collection: 1.588s, learning 0.100s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0411
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 25.8548
                       Mean reward: 0.44
               Mean episode length: 247.12
    Episode_Reward/reaching_object: 0.0862
    Episode_Reward/rotating_object: 0.0001
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 1.69s
                      Time elapsed: 00:01:12
                               ETA: 01:44:51

################################################################################
                      [1m Learning iteration 17/1500 [0m                      

                       Computation: 54001 steps/s (collection: 1.701s, learning 0.120s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0296
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 25.8624
                       Mean reward: 0.56
               Mean episode length: 242.68
    Episode_Reward/reaching_object: 0.1140
    Episode_Reward/rotating_object: 0.0005
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 1.82s
                      Time elapsed: 00:01:13
                               ETA: 01:41:28

################################################################################
                      [1m Learning iteration 18/1500 [0m                      

                       Computation: 52673 steps/s (collection: 1.750s, learning 0.116s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0033
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 25.9068
                       Mean reward: 0.67
               Mean episode length: 240.06
    Episode_Reward/reaching_object: 0.1307
    Episode_Reward/rotating_object: 0.0013
        Episode_Reward/action_rate: -0.0035
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 1.87s
                      Time elapsed: 00:01:15
                               ETA: 01:38:29

################################################################################
                      [1m Learning iteration 19/1500 [0m                      

                       Computation: 55450 steps/s (collection: 1.682s, learning 0.091s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0024
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 25.9638
                       Mean reward: 0.71
               Mean episode length: 227.81
    Episode_Reward/reaching_object: 0.1464
    Episode_Reward/rotating_object: 0.0020
        Episode_Reward/action_rate: -0.0034
          Episode_Reward/joint_vel: -0.0040
      Episode_Termination/time_out: 8.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 1.77s
                      Time elapsed: 00:01:17
                               ETA: 01:35:41

################################################################################
                      [1m Learning iteration 20/1500 [0m                      

                       Computation: 54530 steps/s (collection: 1.711s, learning 0.092s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0021
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 26.0073
                       Mean reward: 0.81
               Mean episode length: 225.09
    Episode_Reward/reaching_object: 0.1605
    Episode_Reward/rotating_object: 0.0026
        Episode_Reward/action_rate: -0.0034
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 7.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 1.80s
                      Time elapsed: 00:01:19
                               ETA: 01:33:11

################################################################################
                      [1m Learning iteration 21/1500 [0m                      

                       Computation: 52002 steps/s (collection: 1.804s, learning 0.087s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0022
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 26.0562
                       Mean reward: 0.86
               Mean episode length: 221.34
    Episode_Reward/reaching_object: 0.1698
    Episode_Reward/rotating_object: 0.0034
        Episode_Reward/action_rate: -0.0033
          Episode_Reward/joint_vel: -0.0040
      Episode_Termination/time_out: 5.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 1.89s
                      Time elapsed: 00:01:21
                               ETA: 01:31:00

################################################################################
                      [1m Learning iteration 22/1500 [0m                      

                       Computation: 55433 steps/s (collection: 1.683s, learning 0.090s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0026
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 26.0960
                       Mean reward: 0.98
               Mean episode length: 221.51
    Episode_Reward/reaching_object: 0.1890
    Episode_Reward/rotating_object: 0.0056
        Episode_Reward/action_rate: -0.0033
          Episode_Reward/joint_vel: -0.0040
      Episode_Termination/time_out: 3.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 1.77s
                      Time elapsed: 00:01:23
                               ETA: 01:28:53

################################################################################
                      [1m Learning iteration 23/1500 [0m                      

                       Computation: 49852 steps/s (collection: 1.854s, learning 0.118s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0035
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 26.1402
                       Mean reward: 0.98
               Mean episode length: 216.13
    Episode_Reward/reaching_object: 0.2018
    Episode_Reward/rotating_object: 0.0112
        Episode_Reward/action_rate: -0.0033
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 3.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 1.97s
                      Time elapsed: 00:01:24
                               ETA: 01:27:09

################################################################################
                      [1m Learning iteration 24/1500 [0m                      

                       Computation: 53633 steps/s (collection: 1.710s, learning 0.123s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0034
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 26.1979
                       Mean reward: 1.00
               Mean episode length: 215.63
    Episode_Reward/reaching_object: 0.1953
    Episode_Reward/rotating_object: 0.0141
        Episode_Reward/action_rate: -0.0033
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 4.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 1.83s
                      Time elapsed: 00:01:26
                               ETA: 01:25:25

################################################################################
                      [1m Learning iteration 25/1500 [0m                      

                       Computation: 54209 steps/s (collection: 1.713s, learning 0.101s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0057
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 26.2475
                       Mean reward: 1.21
               Mean episode length: 219.72
    Episode_Reward/reaching_object: 0.2107
    Episode_Reward/rotating_object: 0.0172
        Episode_Reward/action_rate: -0.0033
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 3.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 1.81s
                      Time elapsed: 00:01:28
                               ETA: 01:23:47

################################################################################
                      [1m Learning iteration 26/1500 [0m                      

                       Computation: 54379 steps/s (collection: 1.716s, learning 0.092s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0050
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 26.2742
                       Mean reward: 1.11
               Mean episode length: 221.80
    Episode_Reward/reaching_object: 0.2274
    Episode_Reward/rotating_object: 0.0161
        Episode_Reward/action_rate: -0.0034
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 4.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.7917
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 1.81s
                      Time elapsed: 00:01:30
                               ETA: 01:22:16

################################################################################
                      [1m Learning iteration 27/1500 [0m                      

                       Computation: 55645 steps/s (collection: 1.676s, learning 0.091s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0076
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 26.3041
                       Mean reward: 1.38
               Mean episode length: 227.14
    Episode_Reward/reaching_object: 0.2422
    Episode_Reward/rotating_object: 0.0158
        Episode_Reward/action_rate: -0.0034
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 5.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 1.77s
                      Time elapsed: 00:01:32
                               ETA: 01:20:50

################################################################################
                      [1m Learning iteration 28/1500 [0m                      

                       Computation: 53639 steps/s (collection: 1.740s, learning 0.093s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0099
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 26.3564
                       Mean reward: 1.54
               Mean episode length: 227.22
    Episode_Reward/reaching_object: 0.2684
    Episode_Reward/rotating_object: 0.0392
        Episode_Reward/action_rate: -0.0035
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 6.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.5417
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 1.83s
                      Time elapsed: 00:01:34
                               ETA: 01:19:32

################################################################################
                      [1m Learning iteration 29/1500 [0m                      

                       Computation: 54010 steps/s (collection: 1.728s, learning 0.093s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0124
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 26.3986
                       Mean reward: 1.53
               Mean episode length: 231.92
    Episode_Reward/reaching_object: 0.2895
    Episode_Reward/rotating_object: 0.0396
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 9.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.2500
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 1.82s
                      Time elapsed: 00:01:35
                               ETA: 01:18:19

################################################################################
                      [1m Learning iteration 30/1500 [0m                      

                       Computation: 54532 steps/s (collection: 1.707s, learning 0.096s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0157
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 26.4868
                       Mean reward: 1.66
               Mean episode length: 236.79
    Episode_Reward/reaching_object: 0.2983
    Episode_Reward/rotating_object: 0.0408
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 10.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.4583
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 1.80s
                      Time elapsed: 00:01:37
                               ETA: 01:17:10

################################################################################
                      [1m Learning iteration 31/1500 [0m                      

                       Computation: 54658 steps/s (collection: 1.712s, learning 0.087s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0408
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 26.5302
                       Mean reward: 1.92
               Mean episode length: 239.40
    Episode_Reward/reaching_object: 0.3284
    Episode_Reward/rotating_object: 0.0468
        Episode_Reward/action_rate: -0.0038
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 11.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 1.80s
                      Time elapsed: 00:01:39
                               ETA: 01:16:05

################################################################################
                      [1m Learning iteration 32/1500 [0m                      

                       Computation: 53482 steps/s (collection: 1.726s, learning 0.113s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.0266
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 26.6526
                       Mean reward: 2.23
               Mean episode length: 236.71
    Episode_Reward/reaching_object: 0.3413
    Episode_Reward/rotating_object: 0.0592
        Episode_Reward/action_rate: -0.0038
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 1.84s
                      Time elapsed: 00:01:41
                               ETA: 01:15:05

################################################################################
                      [1m Learning iteration 33/1500 [0m                      

                       Computation: 52820 steps/s (collection: 1.751s, learning 0.110s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.0411
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 26.7537
                       Mean reward: 2.51
               Mean episode length: 239.84
    Episode_Reward/reaching_object: 0.3442
    Episode_Reward/rotating_object: 0.1368
        Episode_Reward/action_rate: -0.0038
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 1.86s
                      Time elapsed: 00:01:43
                               ETA: 01:14:10

################################################################################
                      [1m Learning iteration 34/1500 [0m                      

                       Computation: 52939 steps/s (collection: 1.754s, learning 0.103s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.0411
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 26.8752
                       Mean reward: 2.21
               Mean episode length: 238.62
    Episode_Reward/reaching_object: 0.3400
    Episode_Reward/rotating_object: 0.1029
        Episode_Reward/action_rate: -0.0038
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 11.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 1.86s
                      Time elapsed: 00:01:45
                               ETA: 01:13:18

################################################################################
                      [1m Learning iteration 35/1500 [0m                      

                       Computation: 53610 steps/s (collection: 1.740s, learning 0.094s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.1540
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 26.9624
                       Mean reward: 2.65
               Mean episode length: 232.18
    Episode_Reward/reaching_object: 0.3738
    Episode_Reward/rotating_object: 0.1456
        Episode_Reward/action_rate: -0.0039
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 12.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 1.83s
                      Time elapsed: 00:01:46
                               ETA: 01:12:27

################################################################################
                      [1m Learning iteration 36/1500 [0m                      

                       Computation: 53633 steps/s (collection: 1.745s, learning 0.088s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.0752
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 27.1041
                       Mean reward: 3.03
               Mean episode length: 235.64
    Episode_Reward/reaching_object: 0.3746
    Episode_Reward/rotating_object: 0.2150
        Episode_Reward/action_rate: -0.0039
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 1.83s
                      Time elapsed: 00:01:48
                               ETA: 01:11:39

################################################################################
                      [1m Learning iteration 37/1500 [0m                      

                       Computation: 52702 steps/s (collection: 1.769s, learning 0.096s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.1057
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 27.1605
                       Mean reward: 3.17
               Mean episode length: 240.48
    Episode_Reward/reaching_object: 0.3938
    Episode_Reward/rotating_object: 0.2451
        Episode_Reward/action_rate: -0.0040
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 1.87s
                      Time elapsed: 00:01:50
                               ETA: 01:10:55

################################################################################
                      [1m Learning iteration 38/1500 [0m                      

                       Computation: 52387 steps/s (collection: 1.777s, learning 0.099s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.2102
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 27.3072
                       Mean reward: 2.96
               Mean episode length: 235.47
    Episode_Reward/reaching_object: 0.4032
    Episode_Reward/rotating_object: 0.2204
        Episode_Reward/action_rate: -0.0040
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 1.88s
                      Time elapsed: 00:01:52
                               ETA: 01:10:14

################################################################################
                      [1m Learning iteration 39/1500 [0m                      

                       Computation: 53099 steps/s (collection: 1.758s, learning 0.093s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.4954
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 27.4108
                       Mean reward: 4.65
               Mean episode length: 244.25
    Episode_Reward/reaching_object: 0.4268
    Episode_Reward/rotating_object: 0.3630
        Episode_Reward/action_rate: -0.0040
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 1.85s
                      Time elapsed: 00:01:54
                               ETA: 01:09:33

################################################################################
                      [1m Learning iteration 40/1500 [0m                      

                       Computation: 52704 steps/s (collection: 1.766s, learning 0.099s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.8389
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 27.5093
                       Mean reward: 4.25
               Mean episode length: 241.69
    Episode_Reward/reaching_object: 0.4345
    Episode_Reward/rotating_object: 0.4121
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 1.87s
                      Time elapsed: 00:01:56
                               ETA: 01:08:55

################################################################################
                      [1m Learning iteration 41/1500 [0m                      

                       Computation: 53422 steps/s (collection: 1.745s, learning 0.095s)
             Mean action noise std: 1.12
          Mean value_function loss: 1.1543
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 27.5845
                       Mean reward: 6.04
               Mean episode length: 239.20
    Episode_Reward/reaching_object: 0.4513
    Episode_Reward/rotating_object: 0.7517
        Episode_Reward/action_rate: -0.0042
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 1.84s
                      Time elapsed: 00:01:57
                               ETA: 01:08:18

################################################################################
                      [1m Learning iteration 42/1500 [0m                      

                       Computation: 52909 steps/s (collection: 1.764s, learning 0.094s)
             Mean action noise std: 1.13
          Mean value_function loss: 1.4900
               Mean surrogate loss: 0.0035
                 Mean entropy loss: 27.6419
                       Mean reward: 6.52
               Mean episode length: 237.93
    Episode_Reward/reaching_object: 0.4595
    Episode_Reward/rotating_object: 0.6553
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 1.86s
                      Time elapsed: 00:01:59
                               ETA: 01:07:43

################################################################################
                      [1m Learning iteration 43/1500 [0m                      

                       Computation: 53141 steps/s (collection: 1.762s, learning 0.088s)
             Mean action noise std: 1.13
          Mean value_function loss: 1.2923
               Mean surrogate loss: 0.0040
                 Mean entropy loss: 27.6616
                       Mean reward: 7.67
               Mean episode length: 231.98
    Episode_Reward/reaching_object: 0.4771
    Episode_Reward/rotating_object: 1.1669
        Episode_Reward/action_rate: -0.0042
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 1.85s
                      Time elapsed: 00:02:01
                               ETA: 01:07:09

################################################################################
                      [1m Learning iteration 44/1500 [0m                      

                       Computation: 53632 steps/s (collection: 1.741s, learning 0.092s)
             Mean action noise std: 1.13
          Mean value_function loss: 1.9090
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 27.6746
                       Mean reward: 7.06
               Mean episode length: 237.56
    Episode_Reward/reaching_object: 0.4967
    Episode_Reward/rotating_object: 1.0184
        Episode_Reward/action_rate: -0.0043
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 1.83s
                      Time elapsed: 00:02:03
                               ETA: 01:06:36

################################################################################
                      [1m Learning iteration 45/1500 [0m                      

                       Computation: 50178 steps/s (collection: 1.853s, learning 0.106s)
             Mean action noise std: 1.13
          Mean value_function loss: 1.9383
               Mean surrogate loss: 0.0086
                 Mean entropy loss: 27.7304
                       Mean reward: 7.70
               Mean episode length: 234.74
    Episode_Reward/reaching_object: 0.5083
    Episode_Reward/rotating_object: 1.4053
        Episode_Reward/action_rate: -0.0043
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 1.96s
                      Time elapsed: 00:02:05
                               ETA: 01:06:08

################################################################################
                      [1m Learning iteration 46/1500 [0m                      

                       Computation: 51522 steps/s (collection: 1.817s, learning 0.091s)
             Mean action noise std: 1.13
          Mean value_function loss: 2.2957
               Mean surrogate loss: 0.0014
                 Mean entropy loss: 27.7428
                       Mean reward: 10.36
               Mean episode length: 236.99
    Episode_Reward/reaching_object: 0.5149
    Episode_Reward/rotating_object: 1.2050
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0065
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 1.91s
                      Time elapsed: 00:02:07
                               ETA: 01:05:40

################################################################################
                      [1m Learning iteration 47/1500 [0m                      

                       Computation: 51491 steps/s (collection: 1.803s, learning 0.107s)
             Mean action noise std: 1.13
          Mean value_function loss: 2.9373
               Mean surrogate loss: 0.0044
                 Mean entropy loss: 27.7732
                       Mean reward: 8.67
               Mean episode length: 236.33
    Episode_Reward/reaching_object: 0.5346
    Episode_Reward/rotating_object: 1.6107
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0065
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 1.91s
                      Time elapsed: 00:02:09
                               ETA: 01:05:13

################################################################################
                      [1m Learning iteration 48/1500 [0m                      

                       Computation: 46078 steps/s (collection: 1.987s, learning 0.146s)
             Mean action noise std: 1.13
          Mean value_function loss: 3.0945
               Mean surrogate loss: 0.0012
                 Mean entropy loss: 27.7884
                       Mean reward: 13.40
               Mean episode length: 237.11
    Episode_Reward/reaching_object: 0.5443
    Episode_Reward/rotating_object: 2.0950
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 2.13s
                      Time elapsed: 00:02:11
                               ETA: 01:04:54

################################################################################
                      [1m Learning iteration 49/1500 [0m                      

                       Computation: 49203 steps/s (collection: 1.896s, learning 0.102s)
             Mean action noise std: 1.14
          Mean value_function loss: 3.4948
               Mean surrogate loss: 0.0030
                 Mean entropy loss: 27.8664
                       Mean reward: 13.66
               Mean episode length: 242.18
    Episode_Reward/reaching_object: 0.5442
    Episode_Reward/rotating_object: 2.3385
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 2.00s
                      Time elapsed: 00:02:13
                               ETA: 01:04:31

################################################################################
                      [1m Learning iteration 50/1500 [0m                      

                       Computation: 47890 steps/s (collection: 1.918s, learning 0.135s)
             Mean action noise std: 1.14
          Mean value_function loss: 3.5856
               Mean surrogate loss: 0.0140
                 Mean entropy loss: 27.8999
                       Mean reward: 11.69
               Mean episode length: 237.42
    Episode_Reward/reaching_object: 0.5365
    Episode_Reward/rotating_object: 1.9918
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 2.05s
                      Time elapsed: 00:02:15
                               ETA: 01:04:11

################################################################################
                      [1m Learning iteration 51/1500 [0m                      

                       Computation: 51692 steps/s (collection: 1.790s, learning 0.112s)
             Mean action noise std: 1.14
          Mean value_function loss: 2.6727
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 27.9048
                       Mean reward: 9.53
               Mean episode length: 220.11
    Episode_Reward/reaching_object: 0.5202
    Episode_Reward/rotating_object: 3.1094
        Episode_Reward/action_rate: -0.0043
          Episode_Reward/joint_vel: -0.0066
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 1.90s
                      Time elapsed: 00:02:17
                               ETA: 01:03:47

################################################################################
                      [1m Learning iteration 52/1500 [0m                      

                       Computation: 51441 steps/s (collection: 1.820s, learning 0.091s)
             Mean action noise std: 1.15
          Mean value_function loss: 2.6546
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 27.9646
                       Mean reward: 18.37
               Mean episode length: 230.90
    Episode_Reward/reaching_object: 0.5231
    Episode_Reward/rotating_object: 2.7078
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 1.91s
                      Time elapsed: 00:02:19
                               ETA: 01:03:25

################################################################################
                      [1m Learning iteration 53/1500 [0m                      

                       Computation: 52010 steps/s (collection: 1.795s, learning 0.095s)
             Mean action noise std: 1.15
          Mean value_function loss: 2.7840
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 28.0752
                       Mean reward: 17.29
               Mean episode length: 237.51
    Episode_Reward/reaching_object: 0.5158
    Episode_Reward/rotating_object: 2.3004
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 1.89s
                      Time elapsed: 00:02:21
                               ETA: 01:03:02

################################################################################
                      [1m Learning iteration 54/1500 [0m                      

                       Computation: 52459 steps/s (collection: 1.775s, learning 0.099s)
             Mean action noise std: 1.16
          Mean value_function loss: 2.5791
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 28.1331
                       Mean reward: 18.10
               Mean episode length: 237.42
    Episode_Reward/reaching_object: 0.5301
    Episode_Reward/rotating_object: 2.6825
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 1.87s
                      Time elapsed: 00:02:23
                               ETA: 01:02:40

################################################################################
                      [1m Learning iteration 55/1500 [0m                      

                       Computation: 53142 steps/s (collection: 1.752s, learning 0.098s)
             Mean action noise std: 1.16
          Mean value_function loss: 3.1976
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 28.1838
                       Mean reward: 14.16
               Mean episode length: 230.89
    Episode_Reward/reaching_object: 0.5057
    Episode_Reward/rotating_object: 2.1913
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 1.85s
                      Time elapsed: 00:02:24
                               ETA: 01:02:18

################################################################################
                      [1m Learning iteration 56/1500 [0m                      

                       Computation: 51934 steps/s (collection: 1.800s, learning 0.093s)
             Mean action noise std: 1.16
          Mean value_function loss: 4.0730
               Mean surrogate loss: 0.0026
                 Mean entropy loss: 28.2248
                       Mean reward: 10.18
               Mean episode length: 235.72
    Episode_Reward/reaching_object: 0.5039
    Episode_Reward/rotating_object: 1.7900
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0071
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 1.89s
                      Time elapsed: 00:02:26
                               ETA: 01:01:58

################################################################################
                      [1m Learning iteration 57/1500 [0m                      

                       Computation: 52593 steps/s (collection: 1.779s, learning 0.091s)
             Mean action noise std: 1.16
          Mean value_function loss: 4.7265
               Mean surrogate loss: 0.0042
                 Mean entropy loss: 28.2636
                       Mean reward: 14.35
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 0.5212
    Episode_Reward/rotating_object: 2.3658
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 1.87s
                      Time elapsed: 00:02:28
                               ETA: 01:01:38

################################################################################
                      [1m Learning iteration 58/1500 [0m                      

                       Computation: 53569 steps/s (collection: 1.743s, learning 0.092s)
             Mean action noise std: 1.17
          Mean value_function loss: 5.4645
               Mean surrogate loss: 0.0075
                 Mean entropy loss: 28.2790
                       Mean reward: 18.76
               Mean episode length: 239.88
    Episode_Reward/reaching_object: 0.5313
    Episode_Reward/rotating_object: 3.3832
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 1.84s
                      Time elapsed: 00:02:30
                               ETA: 01:01:18

################################################################################
                      [1m Learning iteration 59/1500 [0m                      

                       Computation: 53248 steps/s (collection: 1.756s, learning 0.090s)
             Mean action noise std: 1.17
          Mean value_function loss: 6.2014
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 28.2869
                       Mean reward: 17.14
               Mean episode length: 241.50
    Episode_Reward/reaching_object: 0.5247
    Episode_Reward/rotating_object: 3.3705
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 1.85s
                      Time elapsed: 00:02:32
                               ETA: 01:00:58

################################################################################
                      [1m Learning iteration 60/1500 [0m                      

                       Computation: 53765 steps/s (collection: 1.728s, learning 0.100s)
             Mean action noise std: 1.17
          Mean value_function loss: 7.4763
               Mean surrogate loss: 0.0026
                 Mean entropy loss: 28.3355
                       Mean reward: 22.38
               Mean episode length: 241.43
    Episode_Reward/reaching_object: 0.5159
    Episode_Reward/rotating_object: 3.9985
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 1.83s
                      Time elapsed: 00:02:34
                               ETA: 01:00:39

################################################################################
                      [1m Learning iteration 61/1500 [0m                      

                       Computation: 52189 steps/s (collection: 1.770s, learning 0.114s)
             Mean action noise std: 1.17
          Mean value_function loss: 8.0836
               Mean surrogate loss: 0.0013
                 Mean entropy loss: 28.3723
                       Mean reward: 12.47
               Mean episode length: 243.79
    Episode_Reward/reaching_object: 0.5072
    Episode_Reward/rotating_object: 3.4989
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 1.88s
                      Time elapsed: 00:02:36
                               ETA: 01:00:21

################################################################################
                      [1m Learning iteration 62/1500 [0m                      

                       Computation: 52754 steps/s (collection: 1.763s, learning 0.101s)
             Mean action noise std: 1.18
          Mean value_function loss: 8.2214
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 28.4401
                       Mean reward: 30.70
               Mean episode length: 242.02
    Episode_Reward/reaching_object: 0.5242
    Episode_Reward/rotating_object: 5.2081
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 1.86s
                      Time elapsed: 00:02:37
                               ETA: 01:00:04

################################################################################
                      [1m Learning iteration 63/1500 [0m                      

                       Computation: 52124 steps/s (collection: 1.788s, learning 0.098s)
             Mean action noise std: 1.18
          Mean value_function loss: 7.2338
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 28.4993
                       Mean reward: 31.87
               Mean episode length: 241.34
    Episode_Reward/reaching_object: 0.5088
    Episode_Reward/rotating_object: 5.3717
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 1.89s
                      Time elapsed: 00:02:39
                               ETA: 00:59:48

################################################################################
                      [1m Learning iteration 64/1500 [0m                      

                       Computation: 52309 steps/s (collection: 1.788s, learning 0.091s)
             Mean action noise std: 1.18
          Mean value_function loss: 8.6154
               Mean surrogate loss: 0.0017
                 Mean entropy loss: 28.5462
                       Mean reward: 24.61
               Mean episode length: 246.07
    Episode_Reward/reaching_object: 0.4942
    Episode_Reward/rotating_object: 4.4002
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 1.88s
                      Time elapsed: 00:02:41
                               ETA: 00:59:31

################################################################################
                      [1m Learning iteration 65/1500 [0m                      

                       Computation: 51403 steps/s (collection: 1.800s, learning 0.112s)
             Mean action noise std: 1.19
          Mean value_function loss: 8.1067
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 28.5978
                       Mean reward: 26.78
               Mean episode length: 238.28
    Episode_Reward/reaching_object: 0.4993
    Episode_Reward/rotating_object: 5.7772
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0073
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 1.91s
                      Time elapsed: 00:02:43
                               ETA: 00:59:16

################################################################################
                      [1m Learning iteration 66/1500 [0m                      

                       Computation: 52626 steps/s (collection: 1.763s, learning 0.105s)
             Mean action noise std: 1.19
          Mean value_function loss: 8.6432
               Mean surrogate loss: 0.0043
                 Mean entropy loss: 28.6402
                       Mean reward: 30.68
               Mean episode length: 226.63
    Episode_Reward/reaching_object: 0.4888
    Episode_Reward/rotating_object: 5.0653
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 1.87s
                      Time elapsed: 00:02:45
                               ETA: 00:59:01

################################################################################
                      [1m Learning iteration 67/1500 [0m                      

                       Computation: 52905 steps/s (collection: 1.752s, learning 0.107s)
             Mean action noise std: 1.19
          Mean value_function loss: 8.5607
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 28.6634
                       Mean reward: 23.42
               Mean episode length: 229.48
    Episode_Reward/reaching_object: 0.4776
    Episode_Reward/rotating_object: 4.5303
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 1.86s
                      Time elapsed: 00:02:47
                               ETA: 00:58:46

################################################################################
                      [1m Learning iteration 68/1500 [0m                      

                       Computation: 53636 steps/s (collection: 1.743s, learning 0.090s)
             Mean action noise std: 1.19
          Mean value_function loss: 9.9103
               Mean surrogate loss: 0.0050
                 Mean entropy loss: 28.6953
                       Mean reward: 43.87
               Mean episode length: 231.35
    Episode_Reward/reaching_object: 0.4972
    Episode_Reward/rotating_object: 6.3856
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 1.83s
                      Time elapsed: 00:02:49
                               ETA: 00:58:30

################################################################################
                      [1m Learning iteration 69/1500 [0m                      

                       Computation: 53634 steps/s (collection: 1.741s, learning 0.092s)
             Mean action noise std: 1.19
          Mean value_function loss: 10.1965
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 28.7058
                       Mean reward: 35.87
               Mean episode length: 233.84
    Episode_Reward/reaching_object: 0.4957
    Episode_Reward/rotating_object: 5.7499
        Episode_Reward/action_rate: -0.0050
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 1.83s
                      Time elapsed: 00:02:50
                               ETA: 00:58:15

################################################################################
                      [1m Learning iteration 70/1500 [0m                      

                       Computation: 53419 steps/s (collection: 1.745s, learning 0.095s)
             Mean action noise std: 1.20
          Mean value_function loss: 10.0571
               Mean surrogate loss: 0.0043
                 Mean entropy loss: 28.7657
                       Mean reward: 31.68
               Mean episode length: 238.01
    Episode_Reward/reaching_object: 0.5138
    Episode_Reward/rotating_object: 5.9624
        Episode_Reward/action_rate: -0.0050
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 1.84s
                      Time elapsed: 00:02:52
                               ETA: 00:58:00

################################################################################
                      [1m Learning iteration 71/1500 [0m                      

                       Computation: 53606 steps/s (collection: 1.728s, learning 0.106s)
             Mean action noise std: 1.20
          Mean value_function loss: 9.5078
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 28.7812
                       Mean reward: 17.81
               Mean episode length: 239.32
    Episode_Reward/reaching_object: 0.4872
    Episode_Reward/rotating_object: 5.0513
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 1.83s
                      Time elapsed: 00:02:54
                               ETA: 00:57:46

################################################################################
                      [1m Learning iteration 72/1500 [0m                      

                       Computation: 52722 steps/s (collection: 1.768s, learning 0.096s)
             Mean action noise std: 1.20
          Mean value_function loss: 10.2783
               Mean surrogate loss: 0.0039
                 Mean entropy loss: 28.8168
                       Mean reward: 38.64
               Mean episode length: 240.06
    Episode_Reward/reaching_object: 0.4977
    Episode_Reward/rotating_object: 5.1212
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 1.86s
                      Time elapsed: 00:02:56
                               ETA: 00:57:33

################################################################################
                      [1m Learning iteration 73/1500 [0m                      

                       Computation: 54291 steps/s (collection: 1.719s, learning 0.092s)
             Mean action noise std: 1.20
          Mean value_function loss: 11.0854
               Mean surrogate loss: 0.0045
                 Mean entropy loss: 28.8361
                       Mean reward: 36.92
               Mean episode length: 243.99
    Episode_Reward/reaching_object: 0.4977
    Episode_Reward/rotating_object: 5.9147
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 1.81s
                      Time elapsed: 00:02:58
                               ETA: 00:57:18

################################################################################
                      [1m Learning iteration 74/1500 [0m                      

                       Computation: 53431 steps/s (collection: 1.741s, learning 0.099s)
             Mean action noise std: 1.20
          Mean value_function loss: 10.6767
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 28.8443
                       Mean reward: 40.05
               Mean episode length: 245.38
    Episode_Reward/reaching_object: 0.5054
    Episode_Reward/rotating_object: 7.4219
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 1.84s
                      Time elapsed: 00:03:00
                               ETA: 00:57:05

################################################################################
                      [1m Learning iteration 75/1500 [0m                      

                       Computation: 52765 steps/s (collection: 1.770s, learning 0.093s)
             Mean action noise std: 1.21
          Mean value_function loss: 10.0506
               Mean surrogate loss: 0.0016
                 Mean entropy loss: 28.8718
                       Mean reward: 36.98
               Mean episode length: 243.26
    Episode_Reward/reaching_object: 0.4909
    Episode_Reward/rotating_object: 6.0010
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 1.86s
                      Time elapsed: 00:03:02
                               ETA: 00:56:53

################################################################################
                      [1m Learning iteration 76/1500 [0m                      

                       Computation: 53468 steps/s (collection: 1.748s, learning 0.091s)
             Mean action noise std: 1.21
          Mean value_function loss: 10.5471
               Mean surrogate loss: 0.0027
                 Mean entropy loss: 28.8940
                       Mean reward: 29.99
               Mean episode length: 241.96
    Episode_Reward/reaching_object: 0.4771
    Episode_Reward/rotating_object: 6.1958
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 1.84s
                      Time elapsed: 00:03:03
                               ETA: 00:56:40

################################################################################
                      [1m Learning iteration 77/1500 [0m                      

                       Computation: 53311 steps/s (collection: 1.749s, learning 0.095s)
             Mean action noise std: 1.21
          Mean value_function loss: 10.0842
               Mean surrogate loss: 0.0020
                 Mean entropy loss: 28.9117
                       Mean reward: 32.40
               Mean episode length: 242.72
    Episode_Reward/reaching_object: 0.4858
    Episode_Reward/rotating_object: 6.8373
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 1.84s
                      Time elapsed: 00:03:05
                               ETA: 00:56:28

################################################################################
                      [1m Learning iteration 78/1500 [0m                      

                       Computation: 53823 steps/s (collection: 1.735s, learning 0.092s)
             Mean action noise std: 1.21
          Mean value_function loss: 10.8962
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 28.9322
                       Mean reward: 34.62
               Mean episode length: 237.58
    Episode_Reward/reaching_object: 0.4757
    Episode_Reward/rotating_object: 6.5429
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 1.83s
                      Time elapsed: 00:03:07
                               ETA: 00:56:15

################################################################################
                      [1m Learning iteration 79/1500 [0m                      

                       Computation: 53054 steps/s (collection: 1.759s, learning 0.094s)
             Mean action noise std: 1.21
          Mean value_function loss: 11.5252
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 28.9845
                       Mean reward: 30.56
               Mean episode length: 243.07
    Episode_Reward/reaching_object: 0.4699
    Episode_Reward/rotating_object: 7.3312
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 1.85s
                      Time elapsed: 00:03:09
                               ETA: 00:56:04

################################################################################
                      [1m Learning iteration 80/1500 [0m                      

                       Computation: 53821 steps/s (collection: 1.729s, learning 0.098s)
             Mean action noise std: 1.22
          Mean value_function loss: 12.3934
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 29.0400
                       Mean reward: 32.56
               Mean episode length: 241.15
    Episode_Reward/reaching_object: 0.4516
    Episode_Reward/rotating_object: 6.4555
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 1.83s
                      Time elapsed: 00:03:11
                               ETA: 00:55:52

################################################################################
                      [1m Learning iteration 81/1500 [0m                      

                       Computation: 53527 steps/s (collection: 1.743s, learning 0.094s)
             Mean action noise std: 1.22
          Mean value_function loss: 9.7523
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 29.0795
                       Mean reward: 52.81
               Mean episode length: 239.26
    Episode_Reward/reaching_object: 0.4715
    Episode_Reward/rotating_object: 7.4140
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 1.84s
                      Time elapsed: 00:03:13
                               ETA: 00:55:40

################################################################################
                      [1m Learning iteration 82/1500 [0m                      

                       Computation: 53638 steps/s (collection: 1.724s, learning 0.109s)
             Mean action noise std: 1.22
          Mean value_function loss: 11.1020
               Mean surrogate loss: 0.0073
                 Mean entropy loss: 29.1247
                       Mean reward: 34.42
               Mean episode length: 247.03
    Episode_Reward/reaching_object: 0.4551
    Episode_Reward/rotating_object: 5.0998
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 1.83s
                      Time elapsed: 00:03:14
                               ETA: 00:55:29

################################################################################
                      [1m Learning iteration 83/1500 [0m                      

                       Computation: 53711 steps/s (collection: 1.737s, learning 0.093s)
             Mean action noise std: 1.22
          Mean value_function loss: 10.1556
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 29.1311
                       Mean reward: 29.27
               Mean episode length: 240.40
    Episode_Reward/reaching_object: 0.4585
    Episode_Reward/rotating_object: 5.7787
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 1.83s
                      Time elapsed: 00:03:16
                               ETA: 00:55:18

################################################################################
                      [1m Learning iteration 84/1500 [0m                      

                       Computation: 53807 steps/s (collection: 1.722s, learning 0.105s)
             Mean action noise std: 1.22
          Mean value_function loss: 9.9505
               Mean surrogate loss: 0.0058
                 Mean entropy loss: 29.1549
                       Mean reward: 32.38
               Mean episode length: 241.60
    Episode_Reward/reaching_object: 0.4618
    Episode_Reward/rotating_object: 7.1484
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 1.83s
                      Time elapsed: 00:03:18
                               ETA: 00:55:07

################################################################################
                      [1m Learning iteration 85/1500 [0m                      

                       Computation: 53175 steps/s (collection: 1.756s, learning 0.093s)
             Mean action noise std: 1.22
          Mean value_function loss: 10.1642
               Mean surrogate loss: 0.0063
                 Mean entropy loss: 29.1627
                       Mean reward: 29.70
               Mean episode length: 246.43
    Episode_Reward/reaching_object: 0.4443
    Episode_Reward/rotating_object: 6.1090
        Episode_Reward/action_rate: -0.0055
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 1.85s
                      Time elapsed: 00:03:20
                               ETA: 00:54:57

################################################################################
                      [1m Learning iteration 86/1500 [0m                      

                       Computation: 52632 steps/s (collection: 1.760s, learning 0.108s)
             Mean action noise std: 1.23
          Mean value_function loss: 11.1437
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 29.1690
                       Mean reward: 41.50
               Mean episode length: 241.59
    Episode_Reward/reaching_object: 0.4470
    Episode_Reward/rotating_object: 6.1309
        Episode_Reward/action_rate: -0.0055
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 1.87s
                      Time elapsed: 00:03:22
                               ETA: 00:54:47

################################################################################
                      [1m Learning iteration 87/1500 [0m                      

                       Computation: 52926 steps/s (collection: 1.746s, learning 0.112s)
             Mean action noise std: 1.23
          Mean value_function loss: 11.3094
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 29.2132
                       Mean reward: 30.71
               Mean episode length: 243.17
    Episode_Reward/reaching_object: 0.4494
    Episode_Reward/rotating_object: 5.6457
        Episode_Reward/action_rate: -0.0055
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 1.86s
                      Time elapsed: 00:03:24
                               ETA: 00:54:37

################################################################################
                      [1m Learning iteration 88/1500 [0m                      

                       Computation: 53055 steps/s (collection: 1.760s, learning 0.093s)
             Mean action noise std: 1.23
          Mean value_function loss: 11.2144
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 29.2638
                       Mean reward: 18.22
               Mean episode length: 240.80
    Episode_Reward/reaching_object: 0.4540
    Episode_Reward/rotating_object: 6.6101
        Episode_Reward/action_rate: -0.0055
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 1.85s
                      Time elapsed: 00:03:25
                               ETA: 00:54:27

################################################################################
                      [1m Learning iteration 89/1500 [0m                      

                       Computation: 51744 steps/s (collection: 1.809s, learning 0.091s)
             Mean action noise std: 1.24
          Mean value_function loss: 12.6723
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 29.3186
                       Mean reward: 42.94
               Mean episode length: 236.62
    Episode_Reward/reaching_object: 0.4624
    Episode_Reward/rotating_object: 6.5616
        Episode_Reward/action_rate: -0.0055
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 1.90s
                      Time elapsed: 00:03:27
                               ETA: 00:54:19

################################################################################
                      [1m Learning iteration 90/1500 [0m                      

                       Computation: 52285 steps/s (collection: 1.784s, learning 0.096s)
             Mean action noise std: 1.24
          Mean value_function loss: 12.1261
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 29.3551
                       Mean reward: 26.50
               Mean episode length: 231.85
    Episode_Reward/reaching_object: 0.4303
    Episode_Reward/rotating_object: 6.0383
        Episode_Reward/action_rate: -0.0055
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 1.88s
                      Time elapsed: 00:03:29
                               ETA: 00:54:10

################################################################################
                      [1m Learning iteration 91/1500 [0m                      

                       Computation: 52439 steps/s (collection: 1.784s, learning 0.091s)
             Mean action noise std: 1.24
          Mean value_function loss: 13.3357
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 29.3875
                       Mean reward: 42.46
               Mean episode length: 238.73
    Episode_Reward/reaching_object: 0.4613
    Episode_Reward/rotating_object: 7.6414
        Episode_Reward/action_rate: -0.0055
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 1.87s
                      Time elapsed: 00:03:31
                               ETA: 00:54:01

################################################################################
                      [1m Learning iteration 92/1500 [0m                      

                       Computation: 52115 steps/s (collection: 1.794s, learning 0.093s)
             Mean action noise std: 1.24
          Mean value_function loss: 13.7884
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 29.4358
                       Mean reward: 35.24
               Mean episode length: 233.33
    Episode_Reward/reaching_object: 0.4412
    Episode_Reward/rotating_object: 7.0098
        Episode_Reward/action_rate: -0.0055
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 1.89s
                      Time elapsed: 00:03:33
                               ETA: 00:53:52

################################################################################
                      [1m Learning iteration 93/1500 [0m                      

                       Computation: 51898 steps/s (collection: 1.802s, learning 0.093s)
             Mean action noise std: 1.25
          Mean value_function loss: 12.9553
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 29.4742
                       Mean reward: 43.68
               Mean episode length: 240.63
    Episode_Reward/reaching_object: 0.4450
    Episode_Reward/rotating_object: 6.3338
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 1.89s
                      Time elapsed: 00:03:35
                               ETA: 00:53:44

################################################################################
                      [1m Learning iteration 94/1500 [0m                      

                       Computation: 53088 steps/s (collection: 1.756s, learning 0.095s)
             Mean action noise std: 1.25
          Mean value_function loss: 13.6405
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 29.5079
                       Mean reward: 29.70
               Mean episode length: 237.98
    Episode_Reward/reaching_object: 0.4409
    Episode_Reward/rotating_object: 6.3179
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 1.85s
                      Time elapsed: 00:03:37
                               ETA: 00:53:35

################################################################################
                      [1m Learning iteration 95/1500 [0m                      

                       Computation: 52374 steps/s (collection: 1.787s, learning 0.090s)
             Mean action noise std: 1.25
          Mean value_function loss: 15.6622
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 29.5565
                       Mean reward: 26.73
               Mean episode length: 236.45
    Episode_Reward/reaching_object: 0.4376
    Episode_Reward/rotating_object: 5.4007
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 1.88s
                      Time elapsed: 00:03:39
                               ETA: 00:53:27

################################################################################
                      [1m Learning iteration 96/1500 [0m                      

                       Computation: 52772 steps/s (collection: 1.772s, learning 0.091s)
             Mean action noise std: 1.26
          Mean value_function loss: 22.2205
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 29.6132
                       Mean reward: 23.41
               Mean episode length: 239.05
    Episode_Reward/reaching_object: 0.4488
    Episode_Reward/rotating_object: 6.1320
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 1.86s
                      Time elapsed: 00:03:41
                               ETA: 00:53:18

################################################################################
                      [1m Learning iteration 97/1500 [0m                      

                       Computation: 51910 steps/s (collection: 1.801s, learning 0.093s)
             Mean action noise std: 1.26
          Mean value_function loss: 17.9311
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 29.6544
                       Mean reward: 25.84
               Mean episode length: 237.72
    Episode_Reward/reaching_object: 0.4360
    Episode_Reward/rotating_object: 6.4230
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 1.89s
                      Time elapsed: 00:03:42
                               ETA: 00:53:11

################################################################################
                      [1m Learning iteration 98/1500 [0m                      

                       Computation: 51807 steps/s (collection: 1.785s, learning 0.112s)
             Mean action noise std: 1.26
          Mean value_function loss: 15.1866
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 29.6979
                       Mean reward: 27.13
               Mean episode length: 239.32
    Episode_Reward/reaching_object: 0.4320
    Episode_Reward/rotating_object: 6.2987
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 1.90s
                      Time elapsed: 00:03:44
                               ETA: 00:53:03

################################################################################
                      [1m Learning iteration 99/1500 [0m                      

                       Computation: 52308 steps/s (collection: 1.767s, learning 0.113s)
             Mean action noise std: 1.27
          Mean value_function loss: 14.5611
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 29.7370
                       Mean reward: 34.09
               Mean episode length: 235.52
    Episode_Reward/reaching_object: 0.4244
    Episode_Reward/rotating_object: 6.5440
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 1.88s
                      Time elapsed: 00:03:46
                               ETA: 00:52:55

################################################################################
                     [1m Learning iteration 100/1500 [0m                      

                       Computation: 51431 steps/s (collection: 1.801s, learning 0.111s)
             Mean action noise std: 1.27
          Mean value_function loss: 14.5875
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 29.7870
                       Mean reward: 40.20
               Mean episode length: 245.05
    Episode_Reward/reaching_object: 0.4256
    Episode_Reward/rotating_object: 6.5957
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 1.91s
                      Time elapsed: 00:03:48
                               ETA: 00:52:48

################################################################################
                     [1m Learning iteration 101/1500 [0m                      

                       Computation: 52557 steps/s (collection: 1.776s, learning 0.095s)
             Mean action noise std: 1.27
          Mean value_function loss: 12.6848
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 29.8374
                       Mean reward: 45.73
               Mean episode length: 240.69
    Episode_Reward/reaching_object: 0.4308
    Episode_Reward/rotating_object: 8.1372
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 1.87s
                      Time elapsed: 00:03:50
                               ETA: 00:52:40

################################################################################
                     [1m Learning iteration 102/1500 [0m                      

                       Computation: 52507 steps/s (collection: 1.779s, learning 0.094s)
             Mean action noise std: 1.28
          Mean value_function loss: 13.3216
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 29.8830
                       Mean reward: 25.91
               Mean episode length: 242.04
    Episode_Reward/reaching_object: 0.4046
    Episode_Reward/rotating_object: 5.4010
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 1.87s
                      Time elapsed: 00:03:52
                               ETA: 00:52:33

################################################################################
                     [1m Learning iteration 103/1500 [0m                      

                       Computation: 52944 steps/s (collection: 1.769s, learning 0.088s)
             Mean action noise std: 1.28
          Mean value_function loss: 14.8461
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 29.9297
                       Mean reward: 37.37
               Mean episode length: 245.30
    Episode_Reward/reaching_object: 0.4295
    Episode_Reward/rotating_object: 7.0658
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 1.86s
                      Time elapsed: 00:03:54
                               ETA: 00:52:25

################################################################################
                     [1m Learning iteration 104/1500 [0m                      

                       Computation: 52299 steps/s (collection: 1.775s, learning 0.105s)
             Mean action noise std: 1.28
          Mean value_function loss: 13.5488
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 29.9656
                       Mean reward: 32.77
               Mean episode length: 238.93
    Episode_Reward/reaching_object: 0.4097
    Episode_Reward/rotating_object: 6.1790
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 1.88s
                      Time elapsed: 00:03:56
                               ETA: 00:52:18

################################################################################
                     [1m Learning iteration 105/1500 [0m                      

                       Computation: 53333 steps/s (collection: 1.753s, learning 0.090s)
             Mean action noise std: 1.29
          Mean value_function loss: 12.1700
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 30.0015
                       Mean reward: 35.85
               Mean episode length: 241.90
    Episode_Reward/reaching_object: 0.4145
    Episode_Reward/rotating_object: 7.9039
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 1.84s
                      Time elapsed: 00:03:57
                               ETA: 00:52:10

################################################################################
                     [1m Learning iteration 106/1500 [0m                      

                       Computation: 52908 steps/s (collection: 1.768s, learning 0.090s)
             Mean action noise std: 1.29
          Mean value_function loss: 16.9464
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 30.0491
                       Mean reward: 36.16
               Mean episode length: 239.69
    Episode_Reward/reaching_object: 0.4207
    Episode_Reward/rotating_object: 6.7645
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 1.86s
                      Time elapsed: 00:03:59
                               ETA: 00:52:03

################################################################################
                     [1m Learning iteration 107/1500 [0m                      

                       Computation: 51969 steps/s (collection: 1.795s, learning 0.097s)
             Mean action noise std: 1.29
          Mean value_function loss: 18.9812
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 30.0757
                       Mean reward: 26.87
               Mean episode length: 248.51
    Episode_Reward/reaching_object: 0.4147
    Episode_Reward/rotating_object: 5.7645
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 1.89s
                      Time elapsed: 00:04:01
                               ETA: 00:51:56

################################################################################
                     [1m Learning iteration 108/1500 [0m                      

                       Computation: 53141 steps/s (collection: 1.755s, learning 0.095s)
             Mean action noise std: 1.29
          Mean value_function loss: 17.6154
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 30.0968
                       Mean reward: 41.70
               Mean episode length: 236.48
    Episode_Reward/reaching_object: 0.4315
    Episode_Reward/rotating_object: 7.7951
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 1.85s
                      Time elapsed: 00:04:03
                               ETA: 00:51:49

################################################################################
                     [1m Learning iteration 109/1500 [0m                      

                       Computation: 51324 steps/s (collection: 1.823s, learning 0.092s)
             Mean action noise std: 1.29
          Mean value_function loss: 17.9850
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 30.1159
                       Mean reward: 34.42
               Mean episode length: 240.12
    Episode_Reward/reaching_object: 0.4298
    Episode_Reward/rotating_object: 6.5590
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 1.92s
                      Time elapsed: 00:04:05
                               ETA: 00:51:43

################################################################################
                     [1m Learning iteration 110/1500 [0m                      

                       Computation: 51997 steps/s (collection: 1.789s, learning 0.102s)
             Mean action noise std: 1.30
          Mean value_function loss: 17.9785
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 30.1544
                       Mean reward: 42.33
               Mean episode length: 240.29
    Episode_Reward/reaching_object: 0.4161
    Episode_Reward/rotating_object: 6.7068
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 1.89s
                      Time elapsed: 00:04:07
                               ETA: 00:51:37

################################################################################
                     [1m Learning iteration 111/1500 [0m                      

                       Computation: 51172 steps/s (collection: 1.829s, learning 0.093s)
             Mean action noise std: 1.30
          Mean value_function loss: 20.2894
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 30.2072
                       Mean reward: 36.87
               Mean episode length: 242.06
    Episode_Reward/reaching_object: 0.4132
    Episode_Reward/rotating_object: 6.5165
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 1.92s
                      Time elapsed: 00:04:09
                               ETA: 00:51:30

################################################################################
                     [1m Learning iteration 112/1500 [0m                      

                       Computation: 52285 steps/s (collection: 1.784s, learning 0.097s)
             Mean action noise std: 1.30
          Mean value_function loss: 18.7664
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 30.2451
                       Mean reward: 41.97
               Mean episode length: 238.16
    Episode_Reward/reaching_object: 0.4168
    Episode_Reward/rotating_object: 6.6501
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 1.88s
                      Time elapsed: 00:04:11
                               ETA: 00:51:24

################################################################################
                     [1m Learning iteration 113/1500 [0m                      

                       Computation: 52415 steps/s (collection: 1.780s, learning 0.096s)
             Mean action noise std: 1.31
          Mean value_function loss: 17.7214
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 30.2908
                       Mean reward: 42.82
               Mean episode length: 242.93
    Episode_Reward/reaching_object: 0.4421
    Episode_Reward/rotating_object: 7.8954
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 1.88s
                      Time elapsed: 00:04:12
                               ETA: 00:51:18

################################################################################
                     [1m Learning iteration 114/1500 [0m                      

                       Computation: 52332 steps/s (collection: 1.776s, learning 0.103s)
             Mean action noise std: 1.31
          Mean value_function loss: 19.3575
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 30.3314
                       Mean reward: 30.77
               Mean episode length: 241.65
    Episode_Reward/reaching_object: 0.4393
    Episode_Reward/rotating_object: 8.1139
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 1.88s
                      Time elapsed: 00:04:14
                               ETA: 00:51:11

################################################################################
                     [1m Learning iteration 115/1500 [0m                      

                       Computation: 51393 steps/s (collection: 1.810s, learning 0.103s)
             Mean action noise std: 1.31
          Mean value_function loss: 22.5479
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 30.3669
                       Mean reward: 42.90
               Mean episode length: 244.86
    Episode_Reward/reaching_object: 0.4421
    Episode_Reward/rotating_object: 7.5831
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 1.91s
                      Time elapsed: 00:04:16
                               ETA: 00:51:05

################################################################################
                     [1m Learning iteration 116/1500 [0m                      

                       Computation: 52251 steps/s (collection: 1.783s, learning 0.098s)
             Mean action noise std: 1.31
          Mean value_function loss: 24.4862
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 30.4038
                       Mean reward: 47.22
               Mean episode length: 238.64
    Episode_Reward/reaching_object: 0.4449
    Episode_Reward/rotating_object: 8.0549
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 1.88s
                      Time elapsed: 00:04:18
                               ETA: 00:50:59

################################################################################
                     [1m Learning iteration 117/1500 [0m                      

                       Computation: 50906 steps/s (collection: 1.826s, learning 0.105s)
             Mean action noise std: 1.31
          Mean value_function loss: 25.0291
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 30.4336
                       Mean reward: 49.03
               Mean episode length: 244.55
    Episode_Reward/reaching_object: 0.4534
    Episode_Reward/rotating_object: 8.2965
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 1.93s
                      Time elapsed: 00:04:20
                               ETA: 00:50:54

################################################################################
                     [1m Learning iteration 118/1500 [0m                      

                       Computation: 52184 steps/s (collection: 1.792s, learning 0.092s)
             Mean action noise std: 1.32
          Mean value_function loss: 23.6541
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 30.4472
                       Mean reward: 54.08
               Mean episode length: 244.20
    Episode_Reward/reaching_object: 0.4685
    Episode_Reward/rotating_object: 9.6404
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 1.88s
                      Time elapsed: 00:04:22
                               ETA: 00:50:48

################################################################################
                     [1m Learning iteration 119/1500 [0m                      

                       Computation: 53061 steps/s (collection: 1.755s, learning 0.098s)
             Mean action noise std: 1.32
          Mean value_function loss: 23.2401
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 30.4795
                       Mean reward: 36.71
               Mean episode length: 243.54
    Episode_Reward/reaching_object: 0.4437
    Episode_Reward/rotating_object: 8.0848
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 1.85s
                      Time elapsed: 00:04:24
                               ETA: 00:50:42

################################################################################
                     [1m Learning iteration 120/1500 [0m                      

                       Computation: 52581 steps/s (collection: 1.769s, learning 0.100s)
             Mean action noise std: 1.32
          Mean value_function loss: 26.5369
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 30.5123
                       Mean reward: 48.00
               Mean episode length: 238.37
    Episode_Reward/reaching_object: 0.4441
    Episode_Reward/rotating_object: 6.8617
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 1.87s
                      Time elapsed: 00:04:26
                               ETA: 00:50:36

################################################################################
                     [1m Learning iteration 121/1500 [0m                      

                       Computation: 52537 steps/s (collection: 1.784s, learning 0.087s)
             Mean action noise std: 1.32
          Mean value_function loss: 27.0863
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 30.5330
                       Mean reward: 32.67
               Mean episode length: 243.89
    Episode_Reward/reaching_object: 0.4533
    Episode_Reward/rotating_object: 8.5014
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 1.87s
                      Time elapsed: 00:04:28
                               ETA: 00:50:30

################################################################################
                     [1m Learning iteration 122/1500 [0m                      

                       Computation: 52267 steps/s (collection: 1.786s, learning 0.095s)
             Mean action noise std: 1.32
          Mean value_function loss: 23.6506
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 30.5547
                       Mean reward: 48.82
               Mean episode length: 244.17
    Episode_Reward/reaching_object: 0.4540
    Episode_Reward/rotating_object: 9.7554
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 1.88s
                      Time elapsed: 00:04:29
                               ETA: 00:50:24

################################################################################
                     [1m Learning iteration 123/1500 [0m                      

                       Computation: 52303 steps/s (collection: 1.789s, learning 0.091s)
             Mean action noise std: 1.33
          Mean value_function loss: 22.9980
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 30.6054
                       Mean reward: 42.50
               Mean episode length: 242.61
    Episode_Reward/reaching_object: 0.4492
    Episode_Reward/rotating_object: 8.6815
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 1.88s
                      Time elapsed: 00:04:31
                               ETA: 00:50:18

################################################################################
                     [1m Learning iteration 124/1500 [0m                      

                       Computation: 51662 steps/s (collection: 1.811s, learning 0.092s)
             Mean action noise std: 1.33
          Mean value_function loss: 23.7356
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 30.6539
                       Mean reward: 47.83
               Mean episode length: 239.90
    Episode_Reward/reaching_object: 0.4458
    Episode_Reward/rotating_object: 8.4557
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 1.90s
                      Time elapsed: 00:04:33
                               ETA: 00:50:13

################################################################################
                     [1m Learning iteration 125/1500 [0m                      

                       Computation: 51876 steps/s (collection: 1.799s, learning 0.096s)
             Mean action noise std: 1.33
          Mean value_function loss: 22.4015
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 30.6965
                       Mean reward: 43.49
               Mean episode length: 238.78
    Episode_Reward/reaching_object: 0.4289
    Episode_Reward/rotating_object: 9.3236
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 1.89s
                      Time elapsed: 00:04:35
                               ETA: 00:50:07

################################################################################
                     [1m Learning iteration 126/1500 [0m                      

                       Computation: 52170 steps/s (collection: 1.790s, learning 0.095s)
             Mean action noise std: 1.34
          Mean value_function loss: 22.9956
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 30.7135
                       Mean reward: 55.69
               Mean episode length: 239.31
    Episode_Reward/reaching_object: 0.4378
    Episode_Reward/rotating_object: 8.8070
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 1.88s
                      Time elapsed: 00:04:37
                               ETA: 00:50:02

################################################################################
                     [1m Learning iteration 127/1500 [0m                      

                       Computation: 52852 steps/s (collection: 1.770s, learning 0.090s)
             Mean action noise std: 1.34
          Mean value_function loss: 23.8484
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 30.7370
                       Mean reward: 37.63
               Mean episode length: 236.99
    Episode_Reward/reaching_object: 0.4235
    Episode_Reward/rotating_object: 7.5226
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 1.86s
                      Time elapsed: 00:04:39
                               ETA: 00:49:56

################################################################################
                     [1m Learning iteration 128/1500 [0m                      

                       Computation: 51886 steps/s (collection: 1.802s, learning 0.092s)
             Mean action noise std: 1.34
          Mean value_function loss: 27.7431
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 30.7639
                       Mean reward: 61.93
               Mean episode length: 235.70
    Episode_Reward/reaching_object: 0.4422
    Episode_Reward/rotating_object: 10.8632
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 1.89s
                      Time elapsed: 00:04:41
                               ETA: 00:49:51

################################################################################
                     [1m Learning iteration 129/1500 [0m                      

                       Computation: 52675 steps/s (collection: 1.763s, learning 0.104s)
             Mean action noise std: 1.34
          Mean value_function loss: 26.4865
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 30.7883
                       Mean reward: 62.81
               Mean episode length: 237.56
    Episode_Reward/reaching_object: 0.4601
    Episode_Reward/rotating_object: 10.6000
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 1.87s
                      Time elapsed: 00:04:43
                               ETA: 00:49:45

################################################################################
                     [1m Learning iteration 130/1500 [0m                      

                       Computation: 52798 steps/s (collection: 1.757s, learning 0.105s)
             Mean action noise std: 1.34
          Mean value_function loss: 25.5065
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 30.8099
                       Mean reward: 56.81
               Mean episode length: 233.25
    Episode_Reward/reaching_object: 0.4371
    Episode_Reward/rotating_object: 9.9983
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 1.86s
                      Time elapsed: 00:04:44
                               ETA: 00:49:40

################################################################################
                     [1m Learning iteration 131/1500 [0m                      

                       Computation: 51965 steps/s (collection: 1.781s, learning 0.111s)
             Mean action noise std: 1.35
          Mean value_function loss: 26.4384
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 30.8333
                       Mean reward: 47.74
               Mean episode length: 234.24
    Episode_Reward/reaching_object: 0.4467
    Episode_Reward/rotating_object: 10.7456
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 1.89s
                      Time elapsed: 00:04:46
                               ETA: 00:49:35

################################################################################
                     [1m Learning iteration 132/1500 [0m                      

                       Computation: 52308 steps/s (collection: 1.771s, learning 0.109s)
             Mean action noise std: 1.35
          Mean value_function loss: 29.5233
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 30.8601
                       Mean reward: 33.31
               Mean episode length: 234.12
    Episode_Reward/reaching_object: 0.4441
    Episode_Reward/rotating_object: 8.7224
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 1.88s
                      Time elapsed: 00:04:48
                               ETA: 00:49:30

################################################################################
                     [1m Learning iteration 133/1500 [0m                      

                       Computation: 51679 steps/s (collection: 1.800s, learning 0.103s)
             Mean action noise std: 1.35
          Mean value_function loss: 23.8886
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 30.8928
                       Mean reward: 52.31
               Mean episode length: 237.46
    Episode_Reward/reaching_object: 0.4418
    Episode_Reward/rotating_object: 10.3078
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 1.90s
                      Time elapsed: 00:04:50
                               ETA: 00:49:25

################################################################################
                     [1m Learning iteration 134/1500 [0m                      

                       Computation: 52657 steps/s (collection: 1.770s, learning 0.097s)
             Mean action noise std: 1.35
          Mean value_function loss: 22.2473
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 30.9335
                       Mean reward: 41.19
               Mean episode length: 233.48
    Episode_Reward/reaching_object: 0.4268
    Episode_Reward/rotating_object: 8.6348
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 1.87s
                      Time elapsed: 00:04:52
                               ETA: 00:49:20

################################################################################
                     [1m Learning iteration 135/1500 [0m                      

                       Computation: 53069 steps/s (collection: 1.761s, learning 0.091s)
             Mean action noise std: 1.36
          Mean value_function loss: 23.7446
               Mean surrogate loss: 0.0013
                 Mean entropy loss: 30.9708
                       Mean reward: 60.62
               Mean episode length: 233.76
    Episode_Reward/reaching_object: 0.4205
    Episode_Reward/rotating_object: 10.2909
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 1.85s
                      Time elapsed: 00:04:54
                               ETA: 00:49:14

################################################################################
                     [1m Learning iteration 136/1500 [0m                      

                       Computation: 52446 steps/s (collection: 1.778s, learning 0.097s)
             Mean action noise std: 1.36
          Mean value_function loss: 21.6025
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 30.9794
                       Mean reward: 43.03
               Mean episode length: 232.04
    Episode_Reward/reaching_object: 0.4211
    Episode_Reward/rotating_object: 9.5937
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 1.87s
                      Time elapsed: 00:04:56
                               ETA: 00:49:09

################################################################################
                     [1m Learning iteration 137/1500 [0m                      

                       Computation: 51417 steps/s (collection: 1.804s, learning 0.108s)
             Mean action noise std: 1.36
          Mean value_function loss: 21.5581
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 31.0050
                       Mean reward: 54.25
               Mean episode length: 239.35
    Episode_Reward/reaching_object: 0.4266
    Episode_Reward/rotating_object: 12.4067
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 1.91s
                      Time elapsed: 00:04:58
                               ETA: 00:49:05

################################################################################
                     [1m Learning iteration 138/1500 [0m                      

                       Computation: 52721 steps/s (collection: 1.771s, learning 0.093s)
             Mean action noise std: 1.36
          Mean value_function loss: 24.2772
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 31.0437
                       Mean reward: 58.75
               Mean episode length: 237.87
    Episode_Reward/reaching_object: 0.4338
    Episode_Reward/rotating_object: 12.0768
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 1.86s
                      Time elapsed: 00:05:00
                               ETA: 00:48:59

################################################################################
                     [1m Learning iteration 139/1500 [0m                      

                       Computation: 52224 steps/s (collection: 1.791s, learning 0.091s)
             Mean action noise std: 1.37
          Mean value_function loss: 21.8373
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 31.0872
                       Mean reward: 70.45
               Mean episode length: 244.07
    Episode_Reward/reaching_object: 0.4266
    Episode_Reward/rotating_object: 10.9565
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 1.88s
                      Time elapsed: 00:05:01
                               ETA: 00:48:55

################################################################################
                     [1m Learning iteration 140/1500 [0m                      

                       Computation: 52736 steps/s (collection: 1.774s, learning 0.090s)
             Mean action noise std: 1.37
          Mean value_function loss: 24.3911
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 31.1130
                       Mean reward: 72.97
               Mean episode length: 229.88
    Episode_Reward/reaching_object: 0.4163
    Episode_Reward/rotating_object: 9.7981
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 1.86s
                      Time elapsed: 00:05:03
                               ETA: 00:48:50

################################################################################
                     [1m Learning iteration 141/1500 [0m                      

                       Computation: 51595 steps/s (collection: 1.796s, learning 0.110s)
             Mean action noise std: 1.37
          Mean value_function loss: 21.5003
               Mean surrogate loss: 0.0028
                 Mean entropy loss: 31.1179
                       Mean reward: 55.53
               Mean episode length: 237.66
    Episode_Reward/reaching_object: 0.4289
    Episode_Reward/rotating_object: 12.0934
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 1.91s
                      Time elapsed: 00:05:05
                               ETA: 00:48:45

################################################################################
                     [1m Learning iteration 142/1500 [0m                      

                       Computation: 53417 steps/s (collection: 1.743s, learning 0.097s)
             Mean action noise std: 1.37
          Mean value_function loss: 18.5870
               Mean surrogate loss: 0.0040
                 Mean entropy loss: 31.1207
                       Mean reward: 46.71
               Mean episode length: 229.12
    Episode_Reward/reaching_object: 0.4331
    Episode_Reward/rotating_object: 10.2484
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 1.84s
                      Time elapsed: 00:05:07
                               ETA: 00:48:40

################################################################################
                     [1m Learning iteration 143/1500 [0m                      

                       Computation: 51922 steps/s (collection: 1.802s, learning 0.091s)
             Mean action noise std: 1.37
          Mean value_function loss: 22.5613
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 31.1235
                       Mean reward: 62.15
               Mean episode length: 236.17
    Episode_Reward/reaching_object: 0.4119
    Episode_Reward/rotating_object: 10.0179
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 1.89s
                      Time elapsed: 00:05:09
                               ETA: 00:48:35

################################################################################
                     [1m Learning iteration 144/1500 [0m                      

                       Computation: 52567 steps/s (collection: 1.779s, learning 0.092s)
             Mean action noise std: 1.37
          Mean value_function loss: 21.6492
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 31.1577
                       Mean reward: 54.77
               Mean episode length: 236.03
    Episode_Reward/reaching_object: 0.4216
    Episode_Reward/rotating_object: 11.2810
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 1.87s
                      Time elapsed: 00:05:11
                               ETA: 00:48:31

################################################################################
                     [1m Learning iteration 145/1500 [0m                      

                       Computation: 52620 steps/s (collection: 1.775s, learning 0.093s)
             Mean action noise std: 1.37
          Mean value_function loss: 23.4313
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 31.2042
                       Mean reward: 64.63
               Mean episode length: 233.28
    Episode_Reward/reaching_object: 0.3956
    Episode_Reward/rotating_object: 11.5659
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 1.87s
                      Time elapsed: 00:05:13
                               ETA: 00:48:26

################################################################################
                     [1m Learning iteration 146/1500 [0m                      

                       Computation: 52823 steps/s (collection: 1.770s, learning 0.091s)
             Mean action noise std: 1.38
          Mean value_function loss: 25.1781
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 31.2350
                       Mean reward: 65.33
               Mean episode length: 237.12
    Episode_Reward/reaching_object: 0.4205
    Episode_Reward/rotating_object: 12.1432
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 1.86s
                      Time elapsed: 00:05:15
                               ETA: 00:48:21

################################################################################
                     [1m Learning iteration 147/1500 [0m                      

                       Computation: 52200 steps/s (collection: 1.772s, learning 0.112s)
             Mean action noise std: 1.38
          Mean value_function loss: 28.6082
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 31.2699
                       Mean reward: 50.91
               Mean episode length: 234.54
    Episode_Reward/reaching_object: 0.4075
    Episode_Reward/rotating_object: 11.1961
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 1.88s
                      Time elapsed: 00:05:16
                               ETA: 00:48:17

################################################################################
                     [1m Learning iteration 148/1500 [0m                      

                       Computation: 51687 steps/s (collection: 1.782s, learning 0.120s)
             Mean action noise std: 1.38
          Mean value_function loss: 31.0462
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 31.3088
                       Mean reward: 72.83
               Mean episode length: 231.72
    Episode_Reward/reaching_object: 0.4193
    Episode_Reward/rotating_object: 13.0398
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 1.90s
                      Time elapsed: 00:05:18
                               ETA: 00:48:12

################################################################################
                     [1m Learning iteration 149/1500 [0m                      

                       Computation: 53230 steps/s (collection: 1.754s, learning 0.093s)
             Mean action noise std: 1.39
          Mean value_function loss: 26.6720
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 31.3441
                       Mean reward: 58.26
               Mean episode length: 238.62
    Episode_Reward/reaching_object: 0.4218
    Episode_Reward/rotating_object: 12.2334
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 1.85s
                      Time elapsed: 00:05:20
                               ETA: 00:48:08

################################################################################
                     [1m Learning iteration 150/1500 [0m                      

                       Computation: 52577 steps/s (collection: 1.772s, learning 0.098s)
             Mean action noise std: 1.39
          Mean value_function loss: 24.9725
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 31.3788
                       Mean reward: 59.70
               Mean episode length: 239.64
    Episode_Reward/reaching_object: 0.4158
    Episode_Reward/rotating_object: 12.0747
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 1.87s
                      Time elapsed: 00:05:22
                               ETA: 00:48:03

################################################################################
                     [1m Learning iteration 151/1500 [0m                      

                       Computation: 52363 steps/s (collection: 1.781s, learning 0.096s)
             Mean action noise std: 1.39
          Mean value_function loss: 28.5153
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 31.4137
                       Mean reward: 69.24
               Mean episode length: 233.17
    Episode_Reward/reaching_object: 0.4318
    Episode_Reward/rotating_object: 12.6864
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 1.88s
                      Time elapsed: 00:05:24
                               ETA: 00:47:59

################################################################################
                     [1m Learning iteration 152/1500 [0m                      

                       Computation: 52085 steps/s (collection: 1.788s, learning 0.100s)
             Mean action noise std: 1.39
          Mean value_function loss: 28.6495
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 31.4450
                       Mean reward: 68.50
               Mean episode length: 230.61
    Episode_Reward/reaching_object: 0.4320
    Episode_Reward/rotating_object: 11.7803
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 1.89s
                      Time elapsed: 00:05:26
                               ETA: 00:47:54

################################################################################
                     [1m Learning iteration 153/1500 [0m                      

                       Computation: 52913 steps/s (collection: 1.753s, learning 0.105s)
             Mean action noise std: 1.39
          Mean value_function loss: 31.1120
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 31.4726
                       Mean reward: 68.66
               Mean episode length: 227.94
    Episode_Reward/reaching_object: 0.4137
    Episode_Reward/rotating_object: 11.3917
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 1.86s
                      Time elapsed: 00:05:28
                               ETA: 00:47:50

################################################################################
                     [1m Learning iteration 154/1500 [0m                      

                       Computation: 52599 steps/s (collection: 1.780s, learning 0.089s)
             Mean action noise std: 1.40
          Mean value_function loss: 28.3391
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 31.4920
                       Mean reward: 79.18
               Mean episode length: 237.89
    Episode_Reward/reaching_object: 0.4470
    Episode_Reward/rotating_object: 13.3868
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 1.87s
                      Time elapsed: 00:05:30
                               ETA: 00:47:45

################################################################################
                     [1m Learning iteration 155/1500 [0m                      

                       Computation: 52286 steps/s (collection: 1.783s, learning 0.097s)
             Mean action noise std: 1.40
          Mean value_function loss: 31.5796
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 31.5221
                       Mean reward: 86.71
               Mean episode length: 237.79
    Episode_Reward/reaching_object: 0.4499
    Episode_Reward/rotating_object: 13.3536
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 1.88s
                      Time elapsed: 00:05:31
                               ETA: 00:47:41

################################################################################
                     [1m Learning iteration 156/1500 [0m                      

                       Computation: 52663 steps/s (collection: 1.774s, learning 0.093s)
             Mean action noise std: 1.40
          Mean value_function loss: 26.9663
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 31.5451
                       Mean reward: 59.45
               Mean episode length: 240.38
    Episode_Reward/reaching_object: 0.4471
    Episode_Reward/rotating_object: 13.0798
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 1.87s
                      Time elapsed: 00:05:33
                               ETA: 00:47:37

################################################################################
                     [1m Learning iteration 157/1500 [0m                      

                       Computation: 52037 steps/s (collection: 1.791s, learning 0.099s)
             Mean action noise std: 1.40
          Mean value_function loss: 27.1768
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 31.5614
                       Mean reward: 70.77
               Mean episode length: 231.16
    Episode_Reward/reaching_object: 0.4419
    Episode_Reward/rotating_object: 12.1349
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 1.89s
                      Time elapsed: 00:05:35
                               ETA: 00:47:33

################################################################################
                     [1m Learning iteration 158/1500 [0m                      

                       Computation: 52138 steps/s (collection: 1.795s, learning 0.091s)
             Mean action noise std: 1.40
          Mean value_function loss: 23.9084
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 31.5811
                       Mean reward: 79.34
               Mean episode length: 234.03
    Episode_Reward/reaching_object: 0.4465
    Episode_Reward/rotating_object: 15.5134
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 1.89s
                      Time elapsed: 00:05:37
                               ETA: 00:47:28

################################################################################
                     [1m Learning iteration 159/1500 [0m                      

                       Computation: 52267 steps/s (collection: 1.793s, learning 0.088s)
             Mean action noise std: 1.41
          Mean value_function loss: 23.9634
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 31.6240
                       Mean reward: 95.10
               Mean episode length: 230.64
    Episode_Reward/reaching_object: 0.4284
    Episode_Reward/rotating_object: 14.6352
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 1.88s
                      Time elapsed: 00:05:39
                               ETA: 00:47:24

################################################################################
                     [1m Learning iteration 160/1500 [0m                      

                       Computation: 51921 steps/s (collection: 1.799s, learning 0.094s)
             Mean action noise std: 1.41
          Mean value_function loss: 26.3357
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 31.6576
                       Mean reward: 65.73
               Mean episode length: 234.27
    Episode_Reward/reaching_object: 0.4328
    Episode_Reward/rotating_object: 13.3247
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 1.89s
                      Time elapsed: 00:05:41
                               ETA: 00:47:20

################################################################################
                     [1m Learning iteration 161/1500 [0m                      

                       Computation: 51679 steps/s (collection: 1.810s, learning 0.092s)
             Mean action noise std: 1.41
          Mean value_function loss: 26.8255
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 31.6944
                       Mean reward: 57.99
               Mean episode length: 230.29
    Episode_Reward/reaching_object: 0.4282
    Episode_Reward/rotating_object: 12.3183
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 1.90s
                      Time elapsed: 00:05:43
                               ETA: 00:47:16

################################################################################
                     [1m Learning iteration 162/1500 [0m                      

                       Computation: 51370 steps/s (collection: 1.807s, learning 0.107s)
             Mean action noise std: 1.42
          Mean value_function loss: 27.8308
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 31.7207
                       Mean reward: 74.96
               Mean episode length: 233.49
    Episode_Reward/reaching_object: 0.4320
    Episode_Reward/rotating_object: 12.9826
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 1.91s
                      Time elapsed: 00:05:45
                               ETA: 00:47:13

################################################################################
                     [1m Learning iteration 163/1500 [0m                      

                       Computation: 52089 steps/s (collection: 1.781s, learning 0.107s)
             Mean action noise std: 1.42
          Mean value_function loss: 27.4937
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 31.7499
                       Mean reward: 67.85
               Mean episode length: 230.94
    Episode_Reward/reaching_object: 0.4465
    Episode_Reward/rotating_object: 13.9112
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 1.89s
                      Time elapsed: 00:05:47
                               ETA: 00:47:09

################################################################################
                     [1m Learning iteration 164/1500 [0m                      

                       Computation: 51828 steps/s (collection: 1.805s, learning 0.092s)
             Mean action noise std: 1.42
          Mean value_function loss: 27.6667
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 31.7732
                       Mean reward: 70.67
               Mean episode length: 232.63
    Episode_Reward/reaching_object: 0.4360
    Episode_Reward/rotating_object: 15.2143
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 1.90s
                      Time elapsed: 00:05:48
                               ETA: 00:47:05

################################################################################
                     [1m Learning iteration 165/1500 [0m                      

                       Computation: 52014 steps/s (collection: 1.796s, learning 0.094s)
             Mean action noise std: 1.42
          Mean value_function loss: 26.2070
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 31.7836
                       Mean reward: 57.91
               Mean episode length: 234.94
    Episode_Reward/reaching_object: 0.4426
    Episode_Reward/rotating_object: 14.8177
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 1.89s
                      Time elapsed: 00:05:50
                               ETA: 00:47:01

################################################################################
                     [1m Learning iteration 166/1500 [0m                      

                       Computation: 52084 steps/s (collection: 1.787s, learning 0.101s)
             Mean action noise std: 1.42
          Mean value_function loss: 27.3538
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 31.8116
                       Mean reward: 70.07
               Mean episode length: 216.04
    Episode_Reward/reaching_object: 0.4306
    Episode_Reward/rotating_object: 14.3636
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 1.89s
                      Time elapsed: 00:05:52
                               ETA: 00:46:57

################################################################################
                     [1m Learning iteration 167/1500 [0m                      

                       Computation: 51931 steps/s (collection: 1.799s, learning 0.094s)
             Mean action noise std: 1.42
          Mean value_function loss: 30.2328
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 31.8438
                       Mean reward: 52.28
               Mean episode length: 222.44
    Episode_Reward/reaching_object: 0.4308
    Episode_Reward/rotating_object: 12.4822
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 1.89s
                      Time elapsed: 00:05:54
                               ETA: 00:46:53

################################################################################
                     [1m Learning iteration 168/1500 [0m                      

                       Computation: 51367 steps/s (collection: 1.822s, learning 0.092s)
             Mean action noise std: 1.43
          Mean value_function loss: 36.6758
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 31.8685
                       Mean reward: 63.43
               Mean episode length: 217.86
    Episode_Reward/reaching_object: 0.4186
    Episode_Reward/rotating_object: 12.2123
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 1.91s
                      Time elapsed: 00:05:56
                               ETA: 00:46:49

################################################################################
                     [1m Learning iteration 169/1500 [0m                      

                       Computation: 52011 steps/s (collection: 1.800s, learning 0.090s)
             Mean action noise std: 1.43
          Mean value_function loss: 38.9332
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 31.8979
                       Mean reward: 63.61
               Mean episode length: 211.95
    Episode_Reward/reaching_object: 0.4305
    Episode_Reward/rotating_object: 12.6016
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 11.6250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 1.89s
                      Time elapsed: 00:05:58
                               ETA: 00:46:45

################################################################################
                     [1m Learning iteration 170/1500 [0m                      

                       Computation: 50845 steps/s (collection: 1.841s, learning 0.092s)
             Mean action noise std: 1.43
          Mean value_function loss: 33.7248
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 31.9252
                       Mean reward: 74.29
               Mean episode length: 228.62
    Episode_Reward/reaching_object: 0.4253
    Episode_Reward/rotating_object: 12.7934
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 1.93s
                      Time elapsed: 00:06:00
                               ETA: 00:46:42

################################################################################
                     [1m Learning iteration 171/1500 [0m                      

                       Computation: 51458 steps/s (collection: 1.819s, learning 0.092s)
             Mean action noise std: 1.43
          Mean value_function loss: 34.9943
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 31.9542
                       Mean reward: 81.18
               Mean episode length: 216.88
    Episode_Reward/reaching_object: 0.4278
    Episode_Reward/rotating_object: 13.3908
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 1.91s
                      Time elapsed: 00:06:02
                               ETA: 00:46:38

################################################################################
                     [1m Learning iteration 172/1500 [0m                      

                       Computation: 51948 steps/s (collection: 1.804s, learning 0.089s)
             Mean action noise std: 1.44
          Mean value_function loss: 33.3456
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 31.9863
                       Mean reward: 68.34
               Mean episode length: 222.31
    Episode_Reward/reaching_object: 0.4362
    Episode_Reward/rotating_object: 14.0827
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 1.89s
                      Time elapsed: 00:06:04
                               ETA: 00:46:35

################################################################################
                     [1m Learning iteration 173/1500 [0m                      

                       Computation: 52428 steps/s (collection: 1.786s, learning 0.089s)
             Mean action noise std: 1.44
          Mean value_function loss: 31.5890
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 32.0139
                       Mean reward: 73.97
               Mean episode length: 218.79
    Episode_Reward/reaching_object: 0.4184
    Episode_Reward/rotating_object: 12.7956
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 1.88s
                      Time elapsed: 00:06:05
                               ETA: 00:46:31

################################################################################
                     [1m Learning iteration 174/1500 [0m                      

                       Computation: 51642 steps/s (collection: 1.813s, learning 0.091s)
             Mean action noise std: 1.44
          Mean value_function loss: 36.5823
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 32.0359
                       Mean reward: 67.43
               Mean episode length: 221.03
    Episode_Reward/reaching_object: 0.4269
    Episode_Reward/rotating_object: 14.4878
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 1.90s
                      Time elapsed: 00:06:07
                               ETA: 00:46:27

################################################################################
                     [1m Learning iteration 175/1500 [0m                      

                       Computation: 51488 steps/s (collection: 1.813s, learning 0.096s)
             Mean action noise std: 1.44
          Mean value_function loss: 38.8497
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 32.0515
                       Mean reward: 53.36
               Mean episode length: 212.45
    Episode_Reward/reaching_object: 0.4264
    Episode_Reward/rotating_object: 14.4726
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 11.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 1.91s
                      Time elapsed: 00:06:09
                               ETA: 00:46:24

################################################################################
                     [1m Learning iteration 176/1500 [0m                      

                       Computation: 51567 steps/s (collection: 1.802s, learning 0.104s)
             Mean action noise std: 1.44
          Mean value_function loss: 44.3248
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 32.0683
                       Mean reward: 67.17
               Mean episode length: 213.14
    Episode_Reward/reaching_object: 0.4245
    Episode_Reward/rotating_object: 14.1990
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 6.2917
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 1.91s
                      Time elapsed: 00:06:11
                               ETA: 00:46:20

################################################################################
                     [1m Learning iteration 177/1500 [0m                      

                       Computation: 52143 steps/s (collection: 1.792s, learning 0.093s)
             Mean action noise std: 1.44
          Mean value_function loss: 37.2135
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 32.0807
                       Mean reward: 66.05
               Mean episode length: 221.57
    Episode_Reward/reaching_object: 0.4385
    Episode_Reward/rotating_object: 14.9813
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 1.89s
                      Time elapsed: 00:06:13
                               ETA: 00:46:16

################################################################################
                     [1m Learning iteration 178/1500 [0m                      

                       Computation: 52048 steps/s (collection: 1.790s, learning 0.099s)
             Mean action noise std: 1.45
          Mean value_function loss: 35.8149
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 32.0964
                       Mean reward: 92.94
               Mean episode length: 224.40
    Episode_Reward/reaching_object: 0.4420
    Episode_Reward/rotating_object: 15.3348
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 11.6250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 1.89s
                      Time elapsed: 00:06:15
                               ETA: 00:46:13

################################################################################
                     [1m Learning iteration 179/1500 [0m                      

                       Computation: 51462 steps/s (collection: 1.791s, learning 0.119s)
             Mean action noise std: 1.45
          Mean value_function loss: 39.7693
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 32.1181
                       Mean reward: 77.68
               Mean episode length: 220.08
    Episode_Reward/reaching_object: 0.4418
    Episode_Reward/rotating_object: 15.0827
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 12.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 1.91s
                      Time elapsed: 00:06:17
                               ETA: 00:46:09

################################################################################
                     [1m Learning iteration 180/1500 [0m                      

                       Computation: 51945 steps/s (collection: 1.789s, learning 0.104s)
             Mean action noise std: 1.45
          Mean value_function loss: 34.2015
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 32.1379
                       Mean reward: 60.54
               Mean episode length: 228.73
    Episode_Reward/reaching_object: 0.4442
    Episode_Reward/rotating_object: 14.3538
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 12.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 1.89s
                      Time elapsed: 00:06:19
                               ETA: 00:46:06

################################################################################
                     [1m Learning iteration 181/1500 [0m                      

                       Computation: 48564 steps/s (collection: 1.844s, learning 0.181s)
             Mean action noise std: 1.45
          Mean value_function loss: 31.6405
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.1586
                       Mean reward: 89.19
               Mean episode length: 225.08
    Episode_Reward/reaching_object: 0.4525
    Episode_Reward/rotating_object: 15.6220
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 2.02s
                      Time elapsed: 00:06:21
                               ETA: 00:46:03

################################################################################
                     [1m Learning iteration 182/1500 [0m                      

                       Computation: 48357 steps/s (collection: 1.913s, learning 0.120s)
             Mean action noise std: 1.45
          Mean value_function loss: 33.7965
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 32.1745
                       Mean reward: 72.79
               Mean episode length: 221.23
    Episode_Reward/reaching_object: 0.4538
    Episode_Reward/rotating_object: 15.7993
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 2.03s
                      Time elapsed: 00:06:23
                               ETA: 00:46:00

################################################################################
                     [1m Learning iteration 183/1500 [0m                      

                       Computation: 49939 steps/s (collection: 1.841s, learning 0.127s)
             Mean action noise std: 1.45
          Mean value_function loss: 32.2558
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 32.2018
                       Mean reward: 79.65
               Mean episode length: 231.84
    Episode_Reward/reaching_object: 0.4353
    Episode_Reward/rotating_object: 15.2429
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 1.97s
                      Time elapsed: 00:06:25
                               ETA: 00:45:57

################################################################################
                     [1m Learning iteration 184/1500 [0m                      

                       Computation: 50650 steps/s (collection: 1.852s, learning 0.089s)
             Mean action noise std: 1.46
          Mean value_function loss: 35.5131
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 32.2424
                       Mean reward: 102.85
               Mean episode length: 221.42
    Episode_Reward/reaching_object: 0.4528
    Episode_Reward/rotating_object: 17.4868
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 1.94s
                      Time elapsed: 00:06:27
                               ETA: 00:45:54

################################################################################
                     [1m Learning iteration 185/1500 [0m                      

                       Computation: 49315 steps/s (collection: 1.883s, learning 0.110s)
             Mean action noise std: 1.46
          Mean value_function loss: 36.1379
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 32.2899
                       Mean reward: 65.86
               Mean episode length: 227.14
    Episode_Reward/reaching_object: 0.4512
    Episode_Reward/rotating_object: 16.5047
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 1.99s
                      Time elapsed: 00:06:29
                               ETA: 00:45:51

################################################################################
                     [1m Learning iteration 186/1500 [0m                      

                       Computation: 50682 steps/s (collection: 1.829s, learning 0.111s)
             Mean action noise std: 1.46
          Mean value_function loss: 40.4446
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 32.3265
                       Mean reward: 84.34
               Mean episode length: 218.35
    Episode_Reward/reaching_object: 0.4534
    Episode_Reward/rotating_object: 15.4970
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 1.94s
                      Time elapsed: 00:06:31
                               ETA: 00:45:48

################################################################################
                     [1m Learning iteration 187/1500 [0m                      

                       Computation: 49892 steps/s (collection: 1.843s, learning 0.127s)
             Mean action noise std: 1.47
          Mean value_function loss: 45.1441
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 32.3432
                       Mean reward: 85.67
               Mean episode length: 215.35
    Episode_Reward/reaching_object: 0.4553
    Episode_Reward/rotating_object: 18.7302
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 1.97s
                      Time elapsed: 00:06:33
                               ETA: 00:45:45

################################################################################
                     [1m Learning iteration 188/1500 [0m                      

                       Computation: 50031 steps/s (collection: 1.845s, learning 0.120s)
             Mean action noise std: 1.47
          Mean value_function loss: 42.3024
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 32.3492
                       Mean reward: 81.59
               Mean episode length: 225.98
    Episode_Reward/reaching_object: 0.4658
    Episode_Reward/rotating_object: 15.4794
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 11.5833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 1.96s
                      Time elapsed: 00:06:35
                               ETA: 00:45:42

################################################################################
                     [1m Learning iteration 189/1500 [0m                      

                       Computation: 51143 steps/s (collection: 1.830s, learning 0.092s)
             Mean action noise std: 1.47
          Mean value_function loss: 41.9254
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 32.3602
                       Mean reward: 89.80
               Mean episode length: 212.69
    Episode_Reward/reaching_object: 0.4432
    Episode_Reward/rotating_object: 16.6844
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 11.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 1.92s
                      Time elapsed: 00:06:37
                               ETA: 00:45:39

################################################################################
                     [1m Learning iteration 190/1500 [0m                      

                       Computation: 50874 steps/s (collection: 1.815s, learning 0.117s)
             Mean action noise std: 1.47
          Mean value_function loss: 42.4854
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 32.3905
                       Mean reward: 87.19
               Mean episode length: 232.94
    Episode_Reward/reaching_object: 0.4424
    Episode_Reward/rotating_object: 15.1884
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 1.93s
                      Time elapsed: 00:06:38
                               ETA: 00:45:36

################################################################################
                     [1m Learning iteration 191/1500 [0m                      

                       Computation: 51075 steps/s (collection: 1.793s, learning 0.132s)
             Mean action noise std: 1.47
          Mean value_function loss: 47.8586
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 32.4288
                       Mean reward: 102.24
               Mean episode length: 222.82
    Episode_Reward/reaching_object: 0.4472
    Episode_Reward/rotating_object: 17.9195
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 1.92s
                      Time elapsed: 00:06:40
                               ETA: 00:45:33

################################################################################
                     [1m Learning iteration 192/1500 [0m                      

                       Computation: 50563 steps/s (collection: 1.840s, learning 0.104s)
             Mean action noise std: 1.48
          Mean value_function loss: 49.1042
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 32.4593
                       Mean reward: 110.37
               Mean episode length: 228.53
    Episode_Reward/reaching_object: 0.4589
    Episode_Reward/rotating_object: 18.6983
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 1.94s
                      Time elapsed: 00:06:42
                               ETA: 00:45:30

################################################################################
                     [1m Learning iteration 193/1500 [0m                      

                       Computation: 51404 steps/s (collection: 1.818s, learning 0.095s)
             Mean action noise std: 1.48
          Mean value_function loss: 65.2338
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 32.4834
                       Mean reward: 76.46
               Mean episode length: 217.63
    Episode_Reward/reaching_object: 0.4462
    Episode_Reward/rotating_object: 17.1733
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 1.91s
                      Time elapsed: 00:06:44
                               ETA: 00:45:26

################################################################################
                     [1m Learning iteration 194/1500 [0m                      

                       Computation: 50631 steps/s (collection: 1.831s, learning 0.111s)
             Mean action noise std: 1.48
          Mean value_function loss: 54.7091
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 32.5004
                       Mean reward: 115.86
               Mean episode length: 220.59
    Episode_Reward/reaching_object: 0.4647
    Episode_Reward/rotating_object: 19.9864
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 1.94s
                      Time elapsed: 00:06:46
                               ETA: 00:45:23

################################################################################
                     [1m Learning iteration 195/1500 [0m                      

                       Computation: 50414 steps/s (collection: 1.860s, learning 0.090s)
             Mean action noise std: 1.48
          Mean value_function loss: 49.7427
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 32.5211
                       Mean reward: 90.32
               Mean episode length: 224.51
    Episode_Reward/reaching_object: 0.4523
    Episode_Reward/rotating_object: 19.2258
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 1.95s
                      Time elapsed: 00:06:48
                               ETA: 00:45:20

################################################################################
                     [1m Learning iteration 196/1500 [0m                      

                       Computation: 51153 steps/s (collection: 1.829s, learning 0.093s)
             Mean action noise std: 1.48
          Mean value_function loss: 44.4902
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 32.5418
                       Mean reward: 82.95
               Mean episode length: 220.16
    Episode_Reward/reaching_object: 0.4595
    Episode_Reward/rotating_object: 15.9791
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 1.92s
                      Time elapsed: 00:06:50
                               ETA: 00:45:17

################################################################################
                     [1m Learning iteration 197/1500 [0m                      

                       Computation: 50277 steps/s (collection: 1.848s, learning 0.108s)
             Mean action noise std: 1.48
          Mean value_function loss: 47.6502
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 32.5627
                       Mean reward: 79.22
               Mean episode length: 220.87
    Episode_Reward/reaching_object: 0.4512
    Episode_Reward/rotating_object: 18.5125
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 1.96s
                      Time elapsed: 00:06:52
                               ETA: 00:45:14

################################################################################
                     [1m Learning iteration 198/1500 [0m                      

                       Computation: 52314 steps/s (collection: 1.785s, learning 0.094s)
             Mean action noise std: 1.49
          Mean value_function loss: 51.8020
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 32.5942
                       Mean reward: 97.87
               Mean episode length: 227.13
    Episode_Reward/reaching_object: 0.4419
    Episode_Reward/rotating_object: 19.0720
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 1.88s
                      Time elapsed: 00:06:54
                               ETA: 00:45:11

################################################################################
                     [1m Learning iteration 199/1500 [0m                      

                       Computation: 50339 steps/s (collection: 1.815s, learning 0.138s)
             Mean action noise std: 1.49
          Mean value_function loss: 50.4891
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 32.6177
                       Mean reward: 101.59
               Mean episode length: 220.79
    Episode_Reward/reaching_object: 0.4528
    Episode_Reward/rotating_object: 19.6036
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 11.9167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 1.95s
                      Time elapsed: 00:06:56
                               ETA: 00:45:08

################################################################################
                     [1m Learning iteration 200/1500 [0m                      

                       Computation: 51197 steps/s (collection: 1.810s, learning 0.110s)
             Mean action noise std: 1.49
          Mean value_function loss: 48.0106
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 32.6415
                       Mean reward: 79.22
               Mean episode length: 215.49
    Episode_Reward/reaching_object: 0.4520
    Episode_Reward/rotating_object: 19.1130
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 1.92s
                      Time elapsed: 00:06:58
                               ETA: 00:45:05

################################################################################
                     [1m Learning iteration 201/1500 [0m                      

                       Computation: 51911 steps/s (collection: 1.794s, learning 0.100s)
             Mean action noise std: 1.49
          Mean value_function loss: 49.2224
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 32.6691
                       Mean reward: 125.11
               Mean episode length: 226.38
    Episode_Reward/reaching_object: 0.4426
    Episode_Reward/rotating_object: 21.1834
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 1.89s
                      Time elapsed: 00:07:00
                               ETA: 00:45:02

################################################################################
                     [1m Learning iteration 202/1500 [0m                      

                       Computation: 49625 steps/s (collection: 1.820s, learning 0.161s)
             Mean action noise std: 1.50
          Mean value_function loss: 46.0039
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 32.6922
                       Mean reward: 101.34
               Mean episode length: 222.51
    Episode_Reward/reaching_object: 0.4524
    Episode_Reward/rotating_object: 19.1965
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 1.98s
                      Time elapsed: 00:07:02
                               ETA: 00:44:59

################################################################################
                     [1m Learning iteration 203/1500 [0m                      

                       Computation: 50183 steps/s (collection: 1.807s, learning 0.152s)
             Mean action noise std: 1.50
          Mean value_function loss: 49.9192
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 32.7193
                       Mean reward: 86.72
               Mean episode length: 228.58
    Episode_Reward/reaching_object: 0.4614
    Episode_Reward/rotating_object: 20.3575
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 1.96s
                      Time elapsed: 00:07:04
                               ETA: 00:44:56

################################################################################
                     [1m Learning iteration 204/1500 [0m                      

                       Computation: 50714 steps/s (collection: 1.848s, learning 0.091s)
             Mean action noise std: 1.50
          Mean value_function loss: 49.6289
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 32.7352
                       Mean reward: 91.01
               Mean episode length: 235.73
    Episode_Reward/reaching_object: 0.4475
    Episode_Reward/rotating_object: 19.8056
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 1.94s
                      Time elapsed: 00:07:06
                               ETA: 00:44:53

################################################################################
                     [1m Learning iteration 205/1500 [0m                      

                       Computation: 49587 steps/s (collection: 1.790s, learning 0.192s)
             Mean action noise std: 1.50
          Mean value_function loss: 45.0688
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 32.7531
                       Mean reward: 122.96
               Mean episode length: 219.77
    Episode_Reward/reaching_object: 0.4596
    Episode_Reward/rotating_object: 20.6851
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 1.98s
                      Time elapsed: 00:07:08
                               ETA: 00:44:50

################################################################################
                     [1m Learning iteration 206/1500 [0m                      

                       Computation: 48966 steps/s (collection: 1.906s, learning 0.102s)
             Mean action noise std: 1.50
          Mean value_function loss: 44.8910
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 32.7845
                       Mean reward: 117.91
               Mean episode length: 225.30
    Episode_Reward/reaching_object: 0.4654
    Episode_Reward/rotating_object: 21.5993
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 2.01s
                      Time elapsed: 00:07:10
                               ETA: 00:44:48

################################################################################
                     [1m Learning iteration 207/1500 [0m                      

                       Computation: 50094 steps/s (collection: 1.814s, learning 0.148s)
             Mean action noise std: 1.51
          Mean value_function loss: 51.5186
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 32.8213
                       Mean reward: 105.20
               Mean episode length: 216.52
    Episode_Reward/reaching_object: 0.4523
    Episode_Reward/rotating_object: 19.0189
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 1.96s
                      Time elapsed: 00:07:12
                               ETA: 00:44:45

################################################################################
                     [1m Learning iteration 208/1500 [0m                      

                       Computation: 49388 steps/s (collection: 1.834s, learning 0.156s)
             Mean action noise std: 1.51
          Mean value_function loss: 50.3079
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 32.8340
                       Mean reward: 119.25
               Mean episode length: 219.68
    Episode_Reward/reaching_object: 0.4610
    Episode_Reward/rotating_object: 21.3035
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 1.99s
                      Time elapsed: 00:07:14
                               ETA: 00:44:42

################################################################################
                     [1m Learning iteration 209/1500 [0m                      

                       Computation: 52369 steps/s (collection: 1.769s, learning 0.108s)
             Mean action noise std: 1.51
          Mean value_function loss: 50.8410
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 32.8585
                       Mean reward: 121.13
               Mean episode length: 223.40
    Episode_Reward/reaching_object: 0.4549
    Episode_Reward/rotating_object: 23.5807
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 1.88s
                      Time elapsed: 00:07:15
                               ETA: 00:44:39

################################################################################
                     [1m Learning iteration 210/1500 [0m                      

                       Computation: 51488 steps/s (collection: 1.820s, learning 0.090s)
             Mean action noise std: 1.51
          Mean value_function loss: 51.5337
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 32.8896
                       Mean reward: 113.58
               Mean episode length: 218.93
    Episode_Reward/reaching_object: 0.4566
    Episode_Reward/rotating_object: 20.3086
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 12.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 1.91s
                      Time elapsed: 00:07:17
                               ETA: 00:44:36

################################################################################
                     [1m Learning iteration 211/1500 [0m                      

                       Computation: 49904 steps/s (collection: 1.858s, learning 0.112s)
             Mean action noise std: 1.51
          Mean value_function loss: 53.0012
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 32.9132
                       Mean reward: 133.15
               Mean episode length: 224.32
    Episode_Reward/reaching_object: 0.4640
    Episode_Reward/rotating_object: 21.0145
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 1.97s
                      Time elapsed: 00:07:19
                               ETA: 00:44:33

################################################################################
                     [1m Learning iteration 212/1500 [0m                      

                       Computation: 51248 steps/s (collection: 1.822s, learning 0.096s)
             Mean action noise std: 1.52
          Mean value_function loss: 61.1812
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 32.9359
                       Mean reward: 85.89
               Mean episode length: 219.91
    Episode_Reward/reaching_object: 0.4649
    Episode_Reward/rotating_object: 20.7496
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 1.92s
                      Time elapsed: 00:07:21
                               ETA: 00:44:30

################################################################################
                     [1m Learning iteration 213/1500 [0m                      

                       Computation: 52368 steps/s (collection: 1.769s, learning 0.108s)
             Mean action noise std: 1.52
          Mean value_function loss: 47.9744
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 32.9639
                       Mean reward: 122.41
               Mean episode length: 216.12
    Episode_Reward/reaching_object: 0.4678
    Episode_Reward/rotating_object: 22.6630
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 1.88s
                      Time elapsed: 00:07:23
                               ETA: 00:44:27

################################################################################
                     [1m Learning iteration 214/1500 [0m                      

                       Computation: 51091 steps/s (collection: 1.808s, learning 0.116s)
             Mean action noise std: 1.52
          Mean value_function loss: 46.7429
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 32.9903
                       Mean reward: 121.04
               Mean episode length: 218.33
    Episode_Reward/reaching_object: 0.4491
    Episode_Reward/rotating_object: 22.9266
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 1.92s
                      Time elapsed: 00:07:25
                               ETA: 00:44:24

################################################################################
                     [1m Learning iteration 215/1500 [0m                      

                       Computation: 49892 steps/s (collection: 1.835s, learning 0.135s)
             Mean action noise std: 1.52
          Mean value_function loss: 44.0543
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 33.0004
                       Mean reward: 126.52
               Mean episode length: 217.02
    Episode_Reward/reaching_object: 0.4691
    Episode_Reward/rotating_object: 23.3647
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 1.97s
                      Time elapsed: 00:07:27
                               ETA: 00:44:21

################################################################################
                     [1m Learning iteration 216/1500 [0m                      

                       Computation: 48904 steps/s (collection: 1.915s, learning 0.095s)
             Mean action noise std: 1.52
          Mean value_function loss: 48.8236
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 33.0170
                       Mean reward: 121.40
               Mean episode length: 218.63
    Episode_Reward/reaching_object: 0.4505
    Episode_Reward/rotating_object: 25.4863
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 2.01s
                      Time elapsed: 00:07:29
                               ETA: 00:44:19

################################################################################
                     [1m Learning iteration 217/1500 [0m                      

                       Computation: 52071 steps/s (collection: 1.799s, learning 0.089s)
             Mean action noise std: 1.53
          Mean value_function loss: 46.9140
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 33.0310
                       Mean reward: 100.51
               Mean episode length: 220.38
    Episode_Reward/reaching_object: 0.4704
    Episode_Reward/rotating_object: 24.9357
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 1.89s
                      Time elapsed: 00:07:31
                               ETA: 00:44:16

################################################################################
                     [1m Learning iteration 218/1500 [0m                      

                       Computation: 53032 steps/s (collection: 1.755s, learning 0.099s)
             Mean action noise std: 1.53
          Mean value_function loss: 52.0084
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 33.0553
                       Mean reward: 103.52
               Mean episode length: 218.25
    Episode_Reward/reaching_object: 0.4428
    Episode_Reward/rotating_object: 23.1556
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 1.85s
                      Time elapsed: 00:07:33
                               ETA: 00:44:12

################################################################################
                     [1m Learning iteration 219/1500 [0m                      

                       Computation: 52819 steps/s (collection: 1.769s, learning 0.092s)
             Mean action noise std: 1.53
          Mean value_function loss: 49.0467
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 33.0755
                       Mean reward: 135.75
               Mean episode length: 219.20
    Episode_Reward/reaching_object: 0.4537
    Episode_Reward/rotating_object: 25.4399
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 1.86s
                      Time elapsed: 00:07:35
                               ETA: 00:44:09

################################################################################
                     [1m Learning iteration 220/1500 [0m                      

                       Computation: 52491 steps/s (collection: 1.778s, learning 0.095s)
             Mean action noise std: 1.53
          Mean value_function loss: 46.9048
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 33.0951
                       Mean reward: 116.18
               Mean episode length: 223.76
    Episode_Reward/reaching_object: 0.4706
    Episode_Reward/rotating_object: 23.5414
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 1.87s
                      Time elapsed: 00:07:36
                               ETA: 00:44:06

################################################################################
                     [1m Learning iteration 221/1500 [0m                      

                       Computation: 52222 steps/s (collection: 1.792s, learning 0.091s)
             Mean action noise std: 1.53
          Mean value_function loss: 48.0253
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 33.1069
                       Mean reward: 115.88
               Mean episode length: 219.93
    Episode_Reward/reaching_object: 0.4612
    Episode_Reward/rotating_object: 24.6932
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 11.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 1.88s
                      Time elapsed: 00:07:38
                               ETA: 00:44:03

################################################################################
                     [1m Learning iteration 222/1500 [0m                      

                       Computation: 53463 steps/s (collection: 1.745s, learning 0.094s)
             Mean action noise std: 1.53
          Mean value_function loss: 57.2092
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 33.1275
                       Mean reward: 136.96
               Mean episode length: 219.05
    Episode_Reward/reaching_object: 0.4649
    Episode_Reward/rotating_object: 25.9712
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 1.84s
                      Time elapsed: 00:07:40
                               ETA: 00:43:59

################################################################################
                     [1m Learning iteration 223/1500 [0m                      

                       Computation: 52189 steps/s (collection: 1.780s, learning 0.104s)
             Mean action noise std: 1.54
          Mean value_function loss: 48.4737
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 33.1545
                       Mean reward: 106.96
               Mean episode length: 207.75
    Episode_Reward/reaching_object: 0.4607
    Episode_Reward/rotating_object: 26.4825
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 1.88s
                      Time elapsed: 00:07:42
                               ETA: 00:43:56

################################################################################
                     [1m Learning iteration 224/1500 [0m                      

                       Computation: 53664 steps/s (collection: 1.733s, learning 0.099s)
             Mean action noise std: 1.54
          Mean value_function loss: 52.1575
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 33.1742
                       Mean reward: 128.10
               Mean episode length: 230.38
    Episode_Reward/reaching_object: 0.4714
    Episode_Reward/rotating_object: 24.9848
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 1.83s
                      Time elapsed: 00:07:44
                               ETA: 00:43:53

################################################################################
                     [1m Learning iteration 225/1500 [0m                      

                       Computation: 52266 steps/s (collection: 1.758s, learning 0.123s)
             Mean action noise std: 1.54
          Mean value_function loss: 44.3686
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 33.1941
                       Mean reward: 130.34
               Mean episode length: 217.90
    Episode_Reward/reaching_object: 0.4590
    Episode_Reward/rotating_object: 24.7766
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 1.88s
                      Time elapsed: 00:07:46
                               ETA: 00:43:50

################################################################################
                     [1m Learning iteration 226/1500 [0m                      

                       Computation: 51981 steps/s (collection: 1.765s, learning 0.126s)
             Mean action noise std: 1.54
          Mean value_function loss: 48.8154
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 33.2097
                       Mean reward: 128.33
               Mean episode length: 225.01
    Episode_Reward/reaching_object: 0.4692
    Episode_Reward/rotating_object: 28.3831
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 1.89s
                      Time elapsed: 00:07:48
                               ETA: 00:43:47

################################################################################
                     [1m Learning iteration 227/1500 [0m                      

                       Computation: 51825 steps/s (collection: 1.802s, learning 0.095s)
             Mean action noise std: 1.54
          Mean value_function loss: 48.2688
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 33.2194
                       Mean reward: 142.33
               Mean episode length: 225.53
    Episode_Reward/reaching_object: 0.4572
    Episode_Reward/rotating_object: 28.0091
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 1.90s
                      Time elapsed: 00:07:50
                               ETA: 00:43:44

################################################################################
                     [1m Learning iteration 228/1500 [0m                      

                       Computation: 51605 steps/s (collection: 1.810s, learning 0.095s)
             Mean action noise std: 1.54
          Mean value_function loss: 56.8407
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 33.2380
                       Mean reward: 124.30
               Mean episode length: 219.37
    Episode_Reward/reaching_object: 0.4578
    Episode_Reward/rotating_object: 26.9901
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 1.90s
                      Time elapsed: 00:07:51
                               ETA: 00:43:41

################################################################################
                     [1m Learning iteration 229/1500 [0m                      

                       Computation: 52375 steps/s (collection: 1.788s, learning 0.089s)
             Mean action noise std: 1.54
          Mean value_function loss: 56.0127
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 33.2516
                       Mean reward: 142.36
               Mean episode length: 230.35
    Episode_Reward/reaching_object: 0.4746
    Episode_Reward/rotating_object: 25.4971
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 1.88s
                      Time elapsed: 00:07:53
                               ETA: 00:43:38

################################################################################
                     [1m Learning iteration 230/1500 [0m                      

                       Computation: 52704 steps/s (collection: 1.769s, learning 0.096s)
             Mean action noise std: 1.55
          Mean value_function loss: 64.1252
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 33.2676
                       Mean reward: 162.74
               Mean episode length: 223.27
    Episode_Reward/reaching_object: 0.4670
    Episode_Reward/rotating_object: 28.6172
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 1.87s
                      Time elapsed: 00:07:55
                               ETA: 00:43:35

################################################################################
                     [1m Learning iteration 231/1500 [0m                      

                       Computation: 51955 steps/s (collection: 1.798s, learning 0.094s)
             Mean action noise std: 1.55
          Mean value_function loss: 68.7589
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 33.2874
                       Mean reward: 152.80
               Mean episode length: 214.93
    Episode_Reward/reaching_object: 0.4882
    Episode_Reward/rotating_object: 28.4803
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 1.89s
                      Time elapsed: 00:07:57
                               ETA: 00:43:32

################################################################################
                     [1m Learning iteration 232/1500 [0m                      

                       Computation: 50394 steps/s (collection: 1.837s, learning 0.114s)
             Mean action noise std: 1.55
          Mean value_function loss: 64.3215
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 33.3096
                       Mean reward: 117.98
               Mean episode length: 218.53
    Episode_Reward/reaching_object: 0.4806
    Episode_Reward/rotating_object: 25.8037
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 1.95s
                      Time elapsed: 00:07:59
                               ETA: 00:43:29

################################################################################
                     [1m Learning iteration 233/1500 [0m                      

                       Computation: 51296 steps/s (collection: 1.802s, learning 0.114s)
             Mean action noise std: 1.55
          Mean value_function loss: 72.4958
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 33.3253
                       Mean reward: 132.21
               Mean episode length: 212.91
    Episode_Reward/reaching_object: 0.4906
    Episode_Reward/rotating_object: 26.5222
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 1.92s
                      Time elapsed: 00:08:01
                               ETA: 00:43:26

################################################################################
                     [1m Learning iteration 234/1500 [0m                      

                       Computation: 50879 steps/s (collection: 1.816s, learning 0.116s)
             Mean action noise std: 1.55
          Mean value_function loss: 72.6200
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 33.3539
                       Mean reward: 164.87
               Mean episode length: 227.15
    Episode_Reward/reaching_object: 0.4872
    Episode_Reward/rotating_object: 26.5269
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 1.93s
                      Time elapsed: 00:08:03
                               ETA: 00:43:24

################################################################################
                     [1m Learning iteration 235/1500 [0m                      

                       Computation: 52150 steps/s (collection: 1.786s, learning 0.099s)
             Mean action noise std: 1.56
          Mean value_function loss: 77.1053
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 33.3719
                       Mean reward: 142.74
               Mean episode length: 217.84
    Episode_Reward/reaching_object: 0.5059
    Episode_Reward/rotating_object: 27.2612
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 1.88s
                      Time elapsed: 00:08:05
                               ETA: 00:43:21

################################################################################
                     [1m Learning iteration 236/1500 [0m                      

                       Computation: 52367 steps/s (collection: 1.787s, learning 0.090s)
             Mean action noise std: 1.56
          Mean value_function loss: 70.6158
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 33.3875
                       Mean reward: 157.77
               Mean episode length: 213.65
    Episode_Reward/reaching_object: 0.4793
    Episode_Reward/rotating_object: 28.9435
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 1.88s
                      Time elapsed: 00:08:07
                               ETA: 00:43:18

################################################################################
                     [1m Learning iteration 237/1500 [0m                      

                       Computation: 52546 steps/s (collection: 1.780s, learning 0.091s)
             Mean action noise std: 1.56
          Mean value_function loss: 77.5277
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 33.4010
                       Mean reward: 154.47
               Mean episode length: 219.30
    Episode_Reward/reaching_object: 0.4899
    Episode_Reward/rotating_object: 28.6661
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 1.87s
                      Time elapsed: 00:08:09
                               ETA: 00:43:15

################################################################################
                     [1m Learning iteration 238/1500 [0m                      

                       Computation: 51855 steps/s (collection: 1.802s, learning 0.094s)
             Mean action noise std: 1.56
          Mean value_function loss: 75.2834
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 33.4156
                       Mean reward: 155.94
               Mean episode length: 220.64
    Episode_Reward/reaching_object: 0.5056
    Episode_Reward/rotating_object: 29.0998
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 1.90s
                      Time elapsed: 00:08:10
                               ETA: 00:43:12

################################################################################
                     [1m Learning iteration 239/1500 [0m                      

                       Computation: 51596 steps/s (collection: 1.792s, learning 0.114s)
             Mean action noise std: 1.56
          Mean value_function loss: 74.6975
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 33.4270
                       Mean reward: 133.75
               Mean episode length: 217.23
    Episode_Reward/reaching_object: 0.4886
    Episode_Reward/rotating_object: 28.3583
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 1.91s
                      Time elapsed: 00:08:12
                               ETA: 00:43:09

################################################################################
                     [1m Learning iteration 240/1500 [0m                      

                       Computation: 51352 steps/s (collection: 1.815s, learning 0.100s)
             Mean action noise std: 1.56
          Mean value_function loss: 74.9330
               Mean surrogate loss: 0.0023
                 Mean entropy loss: 33.4420
                       Mean reward: 159.86
               Mean episode length: 216.32
    Episode_Reward/reaching_object: 0.4942
    Episode_Reward/rotating_object: 29.2991
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 11.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 1.91s
                      Time elapsed: 00:08:14
                               ETA: 00:43:06

################################################################################
                     [1m Learning iteration 241/1500 [0m                      

                       Computation: 50589 steps/s (collection: 1.836s, learning 0.108s)
             Mean action noise std: 1.56
          Mean value_function loss: 57.7554
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 33.4491
                       Mean reward: 174.72
               Mean episode length: 227.76
    Episode_Reward/reaching_object: 0.5066
    Episode_Reward/rotating_object: 32.0867
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 1.94s
                      Time elapsed: 00:08:16
                               ETA: 00:43:03

################################################################################
                     [1m Learning iteration 242/1500 [0m                      

                       Computation: 50035 steps/s (collection: 1.813s, learning 0.152s)
             Mean action noise std: 1.57
          Mean value_function loss: 65.6679
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 33.4760
                       Mean reward: 169.44
               Mean episode length: 217.48
    Episode_Reward/reaching_object: 0.5049
    Episode_Reward/rotating_object: 30.3800
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 1.96s
                      Time elapsed: 00:08:18
                               ETA: 00:43:01

################################################################################
                     [1m Learning iteration 243/1500 [0m                      

                       Computation: 51400 steps/s (collection: 1.813s, learning 0.099s)
             Mean action noise std: 1.57
          Mean value_function loss: 68.4565
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 33.5035
                       Mean reward: 161.37
               Mean episode length: 209.63
    Episode_Reward/reaching_object: 0.4883
    Episode_Reward/rotating_object: 31.4567
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 1.91s
                      Time elapsed: 00:08:20
                               ETA: 00:42:58

################################################################################
                     [1m Learning iteration 244/1500 [0m                      

                       Computation: 50726 steps/s (collection: 1.834s, learning 0.104s)
             Mean action noise std: 1.57
          Mean value_function loss: 72.1509
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 33.5161
                       Mean reward: 175.22
               Mean episode length: 220.93
    Episode_Reward/reaching_object: 0.5099
    Episode_Reward/rotating_object: 34.1050
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 1.94s
                      Time elapsed: 00:08:22
                               ETA: 00:42:55

################################################################################
                     [1m Learning iteration 245/1500 [0m                      

                       Computation: 51895 steps/s (collection: 1.784s, learning 0.111s)
             Mean action noise std: 1.57
          Mean value_function loss: 72.1222
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 33.5322
                       Mean reward: 188.80
               Mean episode length: 223.05
    Episode_Reward/reaching_object: 0.5067
    Episode_Reward/rotating_object: 34.9210
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 1.89s
                      Time elapsed: 00:08:24
                               ETA: 00:42:53

################################################################################
                     [1m Learning iteration 246/1500 [0m                      

                       Computation: 50468 steps/s (collection: 1.846s, learning 0.102s)
             Mean action noise std: 1.57
          Mean value_function loss: 72.8277
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 33.5583
                       Mean reward: 189.82
               Mean episode length: 230.91
    Episode_Reward/reaching_object: 0.5146
    Episode_Reward/rotating_object: 32.8423
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 1.95s
                      Time elapsed: 00:08:26
                               ETA: 00:42:50

################################################################################
                     [1m Learning iteration 247/1500 [0m                      

                       Computation: 51192 steps/s (collection: 1.820s, learning 0.101s)
             Mean action noise std: 1.57
          Mean value_function loss: 77.6515
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 33.5755
                       Mean reward: 163.00
               Mean episode length: 218.29
    Episode_Reward/reaching_object: 0.5122
    Episode_Reward/rotating_object: 33.2082
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 1.92s
                      Time elapsed: 00:08:28
                               ETA: 00:42:47

################################################################################
                     [1m Learning iteration 248/1500 [0m                      

                       Computation: 51166 steps/s (collection: 1.812s, learning 0.110s)
             Mean action noise std: 1.57
          Mean value_function loss: 61.6919
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 33.5895
                       Mean reward: 177.73
               Mean episode length: 225.35
    Episode_Reward/reaching_object: 0.5131
    Episode_Reward/rotating_object: 29.9710
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 1.92s
                      Time elapsed: 00:08:30
                               ETA: 00:42:45

################################################################################
                     [1m Learning iteration 249/1500 [0m                      

                       Computation: 51759 steps/s (collection: 1.805s, learning 0.094s)
             Mean action noise std: 1.58
          Mean value_function loss: 78.3972
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 33.6010
                       Mean reward: 196.08
               Mean episode length: 225.68
    Episode_Reward/reaching_object: 0.4868
    Episode_Reward/rotating_object: 31.0991
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 1.90s
                      Time elapsed: 00:08:32
                               ETA: 00:42:42

################################################################################
                     [1m Learning iteration 250/1500 [0m                      

                       Computation: 51636 steps/s (collection: 1.789s, learning 0.115s)
             Mean action noise std: 1.58
          Mean value_function loss: 70.0426
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 33.6161
                       Mean reward: 154.93
               Mean episode length: 215.25
    Episode_Reward/reaching_object: 0.4960
    Episode_Reward/rotating_object: 36.1591
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 1.90s
                      Time elapsed: 00:08:33
                               ETA: 00:42:39

################################################################################
                     [1m Learning iteration 251/1500 [0m                      

                       Computation: 52683 steps/s (collection: 1.772s, learning 0.094s)
             Mean action noise std: 1.58
          Mean value_function loss: 78.9972
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 33.6385
                       Mean reward: 166.83
               Mean episode length: 213.60
    Episode_Reward/reaching_object: 0.4832
    Episode_Reward/rotating_object: 33.1932
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 1.87s
                      Time elapsed: 00:08:35
                               ETA: 00:42:36

################################################################################
                     [1m Learning iteration 252/1500 [0m                      

                       Computation: 50287 steps/s (collection: 1.816s, learning 0.139s)
             Mean action noise std: 1.58
          Mean value_function loss: 77.9028
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 33.6550
                       Mean reward: 167.22
               Mean episode length: 213.80
    Episode_Reward/reaching_object: 0.4890
    Episode_Reward/rotating_object: 33.6369
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 1.95s
                      Time elapsed: 00:08:37
                               ETA: 00:42:34

################################################################################
                     [1m Learning iteration 253/1500 [0m                      

                       Computation: 51944 steps/s (collection: 1.785s, learning 0.107s)
             Mean action noise std: 1.58
          Mean value_function loss: 82.0582
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 33.6714
                       Mean reward: 168.75
               Mean episode length: 223.61
    Episode_Reward/reaching_object: 0.4934
    Episode_Reward/rotating_object: 32.1059
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 1.89s
                      Time elapsed: 00:08:39
                               ETA: 00:42:31

################################################################################
                     [1m Learning iteration 254/1500 [0m                      

                       Computation: 51426 steps/s (collection: 1.809s, learning 0.102s)
             Mean action noise std: 1.58
          Mean value_function loss: 84.5310
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 33.6813
                       Mean reward: 142.18
               Mean episode length: 215.78
    Episode_Reward/reaching_object: 0.5065
    Episode_Reward/rotating_object: 37.0854
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 1.91s
                      Time elapsed: 00:08:41
                               ETA: 00:42:28

################################################################################
                     [1m Learning iteration 255/1500 [0m                      

                       Computation: 51848 steps/s (collection: 1.778s, learning 0.118s)
             Mean action noise std: 1.58
          Mean value_function loss: 85.7499
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 33.6952
                       Mean reward: 201.60
               Mean episode length: 227.32
    Episode_Reward/reaching_object: 0.4910
    Episode_Reward/rotating_object: 34.1427
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 1.90s
                      Time elapsed: 00:08:43
                               ETA: 00:42:25

################################################################################
                     [1m Learning iteration 256/1500 [0m                      

                       Computation: 53258 steps/s (collection: 1.736s, learning 0.110s)
             Mean action noise std: 1.59
          Mean value_function loss: 84.7690
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 33.7056
                       Mean reward: 164.72
               Mean episode length: 216.05
    Episode_Reward/reaching_object: 0.5018
    Episode_Reward/rotating_object: 37.0472
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 1.85s
                      Time elapsed: 00:08:45
                               ETA: 00:42:22

################################################################################
                     [1m Learning iteration 257/1500 [0m                      

                       Computation: 52803 steps/s (collection: 1.766s, learning 0.096s)
             Mean action noise std: 1.59
          Mean value_function loss: 88.2709
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 33.7130
                       Mean reward: 199.21
               Mean episode length: 226.21
    Episode_Reward/reaching_object: 0.5427
    Episode_Reward/rotating_object: 36.8736
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 1.86s
                      Time elapsed: 00:08:47
                               ETA: 00:42:19

################################################################################
                     [1m Learning iteration 258/1500 [0m                      

                       Computation: 53267 steps/s (collection: 1.751s, learning 0.094s)
             Mean action noise std: 1.59
          Mean value_function loss: 85.0015
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 33.7250
                       Mean reward: 190.27
               Mean episode length: 220.84
    Episode_Reward/reaching_object: 0.5208
    Episode_Reward/rotating_object: 36.6377
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 1.85s
                      Time elapsed: 00:08:49
                               ETA: 00:42:16

################################################################################
                     [1m Learning iteration 259/1500 [0m                      

                       Computation: 53126 steps/s (collection: 1.756s, learning 0.094s)
             Mean action noise std: 1.59
          Mean value_function loss: 84.2998
               Mean surrogate loss: 0.0069
                 Mean entropy loss: 33.7392
                       Mean reward: 185.83
               Mean episode length: 225.33
    Episode_Reward/reaching_object: 0.5306
    Episode_Reward/rotating_object: 37.4537
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 1.85s
                      Time elapsed: 00:08:50
                               ETA: 00:42:13

################################################################################
                     [1m Learning iteration 260/1500 [0m                      

                       Computation: 53325 steps/s (collection: 1.748s, learning 0.095s)
             Mean action noise std: 1.59
          Mean value_function loss: 86.0140
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 33.7415
                       Mean reward: 209.71
               Mean episode length: 215.23
    Episode_Reward/reaching_object: 0.5165
    Episode_Reward/rotating_object: 37.4353
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 1.84s
                      Time elapsed: 00:08:52
                               ETA: 00:42:11

################################################################################
                     [1m Learning iteration 261/1500 [0m                      

                       Computation: 53414 steps/s (collection: 1.748s, learning 0.093s)
             Mean action noise std: 1.59
          Mean value_function loss: 79.4337
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 33.7494
                       Mean reward: 191.93
               Mean episode length: 219.31
    Episode_Reward/reaching_object: 0.5364
    Episode_Reward/rotating_object: 39.9078
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 1.84s
                      Time elapsed: 00:08:54
                               ETA: 00:42:08

################################################################################
                     [1m Learning iteration 262/1500 [0m                      

                       Computation: 53944 steps/s (collection: 1.734s, learning 0.088s)
             Mean action noise std: 1.59
          Mean value_function loss: 82.1592
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 33.7609
                       Mean reward: 197.99
               Mean episode length: 225.10
    Episode_Reward/reaching_object: 0.5459
    Episode_Reward/rotating_object: 41.3984
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 1.82s
                      Time elapsed: 00:08:56
                               ETA: 00:42:04

################################################################################
                     [1m Learning iteration 263/1500 [0m                      

                       Computation: 54004 steps/s (collection: 1.732s, learning 0.088s)
             Mean action noise std: 1.59
          Mean value_function loss: 76.2884
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 33.7670
                       Mean reward: 246.75
               Mean episode length: 229.24
    Episode_Reward/reaching_object: 0.5450
    Episode_Reward/rotating_object: 43.9946
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 1.82s
                      Time elapsed: 00:08:58
                               ETA: 00:42:01

################################################################################
                     [1m Learning iteration 264/1500 [0m                      

                       Computation: 52324 steps/s (collection: 1.775s, learning 0.104s)
             Mean action noise std: 1.59
          Mean value_function loss: 82.7473
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 33.7723
                       Mean reward: 240.43
               Mean episode length: 234.15
    Episode_Reward/reaching_object: 0.5471
    Episode_Reward/rotating_object: 44.7044
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 1.88s
                      Time elapsed: 00:09:00
                               ETA: 00:41:59

################################################################################
                     [1m Learning iteration 265/1500 [0m                      

                       Computation: 53839 steps/s (collection: 1.713s, learning 0.113s)
             Mean action noise std: 1.59
          Mean value_function loss: 82.6823
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 33.7878
                       Mean reward: 179.85
               Mean episode length: 217.07
    Episode_Reward/reaching_object: 0.5190
    Episode_Reward/rotating_object: 41.9975
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 1.83s
                      Time elapsed: 00:09:01
                               ETA: 00:41:56

################################################################################
                     [1m Learning iteration 266/1500 [0m                      

                       Computation: 53031 steps/s (collection: 1.747s, learning 0.107s)
             Mean action noise std: 1.59
          Mean value_function loss: 85.0731
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 33.8024
                       Mean reward: 247.17
               Mean episode length: 233.37
    Episode_Reward/reaching_object: 0.5285
    Episode_Reward/rotating_object: 44.0648
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 1.85s
                      Time elapsed: 00:09:03
                               ETA: 00:41:53

################################################################################
                     [1m Learning iteration 267/1500 [0m                      

                       Computation: 52426 steps/s (collection: 1.759s, learning 0.117s)
             Mean action noise std: 1.60
          Mean value_function loss: 77.3946
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 33.8100
                       Mean reward: 252.63
               Mean episode length: 220.15
    Episode_Reward/reaching_object: 0.5260
    Episode_Reward/rotating_object: 43.4014
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 1.88s
                      Time elapsed: 00:09:05
                               ETA: 00:41:50

################################################################################
                     [1m Learning iteration 268/1500 [0m                      

                       Computation: 53221 steps/s (collection: 1.710s, learning 0.137s)
             Mean action noise std: 1.60
          Mean value_function loss: 88.8049
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 33.8209
                       Mean reward: 223.53
               Mean episode length: 214.85
    Episode_Reward/reaching_object: 0.5310
    Episode_Reward/rotating_object: 45.4920
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 1.85s
                      Time elapsed: 00:09:07
                               ETA: 00:41:47

################################################################################
                     [1m Learning iteration 269/1500 [0m                      

                       Computation: 53084 steps/s (collection: 1.748s, learning 0.104s)
             Mean action noise std: 1.60
          Mean value_function loss: 88.6358
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 33.8245
                       Mean reward: 225.58
               Mean episode length: 221.86
    Episode_Reward/reaching_object: 0.5248
    Episode_Reward/rotating_object: 41.8350
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 1.85s
                      Time elapsed: 00:09:09
                               ETA: 00:41:44

################################################################################
                     [1m Learning iteration 270/1500 [0m                      

                       Computation: 53947 steps/s (collection: 1.734s, learning 0.089s)
             Mean action noise std: 1.60
          Mean value_function loss: 91.8447
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 33.8269
                       Mean reward: 208.68
               Mean episode length: 226.02
    Episode_Reward/reaching_object: 0.5559
    Episode_Reward/rotating_object: 45.1127
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 1.82s
                      Time elapsed: 00:09:11
                               ETA: 00:41:41

################################################################################
                     [1m Learning iteration 271/1500 [0m                      

                       Computation: 52400 steps/s (collection: 1.767s, learning 0.109s)
             Mean action noise std: 1.60
          Mean value_function loss: 89.3754
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 33.8368
                       Mean reward: 235.62
               Mean episode length: 220.32
    Episode_Reward/reaching_object: 0.5420
    Episode_Reward/rotating_object: 48.3176
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 1.88s
                      Time elapsed: 00:09:13
                               ETA: 00:41:38

################################################################################
                     [1m Learning iteration 272/1500 [0m                      

                       Computation: 52737 steps/s (collection: 1.755s, learning 0.109s)
             Mean action noise std: 1.60
          Mean value_function loss: 103.5003
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 33.8553
                       Mean reward: 225.30
               Mean episode length: 223.79
    Episode_Reward/reaching_object: 0.5487
    Episode_Reward/rotating_object: 43.9420
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 1.86s
                      Time elapsed: 00:09:14
                               ETA: 00:41:36

################################################################################
                     [1m Learning iteration 273/1500 [0m                      

                       Computation: 52491 steps/s (collection: 1.776s, learning 0.097s)
             Mean action noise std: 1.60
          Mean value_function loss: 99.3932
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 33.8654
                       Mean reward: 253.36
               Mean episode length: 229.34
    Episode_Reward/reaching_object: 0.5714
    Episode_Reward/rotating_object: 49.2771
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 1.87s
                      Time elapsed: 00:09:16
                               ETA: 00:41:33

################################################################################
                     [1m Learning iteration 274/1500 [0m                      

                       Computation: 50889 steps/s (collection: 1.791s, learning 0.141s)
             Mean action noise std: 1.60
          Mean value_function loss: 90.1819
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 33.8713
                       Mean reward: 281.50
               Mean episode length: 232.24
    Episode_Reward/reaching_object: 0.5737
    Episode_Reward/rotating_object: 51.2447
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 1.93s
                      Time elapsed: 00:09:18
                               ETA: 00:41:30

################################################################################
                     [1m Learning iteration 275/1500 [0m                      

                       Computation: 51842 steps/s (collection: 1.785s, learning 0.112s)
             Mean action noise std: 1.60
          Mean value_function loss: 100.0889
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 33.8811
                       Mean reward: 257.16
               Mean episode length: 226.81
    Episode_Reward/reaching_object: 0.5693
    Episode_Reward/rotating_object: 48.1759
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 1.90s
                      Time elapsed: 00:09:20
                               ETA: 00:41:28

################################################################################
                     [1m Learning iteration 276/1500 [0m                      

                       Computation: 51851 steps/s (collection: 1.764s, learning 0.132s)
             Mean action noise std: 1.60
          Mean value_function loss: 100.1615
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 33.8961
                       Mean reward: 272.05
               Mean episode length: 227.12
    Episode_Reward/reaching_object: 0.5807
    Episode_Reward/rotating_object: 52.5689
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 1.90s
                      Time elapsed: 00:09:22
                               ETA: 00:41:25

################################################################################
                     [1m Learning iteration 277/1500 [0m                      

                       Computation: 51842 steps/s (collection: 1.763s, learning 0.133s)
             Mean action noise std: 1.60
          Mean value_function loss: 94.2178
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 33.9054
                       Mean reward: 247.81
               Mean episode length: 230.69
    Episode_Reward/reaching_object: 0.5821
    Episode_Reward/rotating_object: 47.9630
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 1.90s
                      Time elapsed: 00:09:24
                               ETA: 00:41:22

################################################################################
                     [1m Learning iteration 278/1500 [0m                      

                       Computation: 52258 steps/s (collection: 1.787s, learning 0.094s)
             Mean action noise std: 1.61
          Mean value_function loss: 98.0355
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 33.9141
                       Mean reward: 271.01
               Mean episode length: 228.01
    Episode_Reward/reaching_object: 0.5927
    Episode_Reward/rotating_object: 53.3576
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 1.88s
                      Time elapsed: 00:09:26
                               ETA: 00:41:20

################################################################################
                     [1m Learning iteration 279/1500 [0m                      

                       Computation: 52175 steps/s (collection: 1.791s, learning 0.094s)
             Mean action noise std: 1.61
          Mean value_function loss: 104.8061
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 33.9269
                       Mean reward: 246.11
               Mean episode length: 210.96
    Episode_Reward/reaching_object: 0.6025
    Episode_Reward/rotating_object: 55.6131
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 1.88s
                      Time elapsed: 00:09:28
                               ETA: 00:41:17

################################################################################
                     [1m Learning iteration 280/1500 [0m                      

                       Computation: 52492 steps/s (collection: 1.783s, learning 0.090s)
             Mean action noise std: 1.61
          Mean value_function loss: 148.8392
               Mean surrogate loss: 0.0315
                 Mean entropy loss: 33.9389
                       Mean reward: 276.58
               Mean episode length: 229.29
    Episode_Reward/reaching_object: 0.6021
    Episode_Reward/rotating_object: 55.3160
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 1.87s
                      Time elapsed: 00:09:30
                               ETA: 00:41:14

################################################################################
                     [1m Learning iteration 281/1500 [0m                      

                       Computation: 52534 steps/s (collection: 1.776s, learning 0.096s)
             Mean action noise std: 1.61
          Mean value_function loss: 123.4642
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 33.9398
                       Mean reward: 282.48
               Mean episode length: 230.05
    Episode_Reward/reaching_object: 0.5779
    Episode_Reward/rotating_object: 51.1131
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 1.87s
                      Time elapsed: 00:09:31
                               ETA: 00:41:12

################################################################################
                     [1m Learning iteration 282/1500 [0m                      

                       Computation: 53327 steps/s (collection: 1.748s, learning 0.096s)
             Mean action noise std: 1.61
          Mean value_function loss: 118.4089
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 33.9456
                       Mean reward: 258.94
               Mean episode length: 219.28
    Episode_Reward/reaching_object: 0.5734
    Episode_Reward/rotating_object: 52.5767
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 1.84s
                      Time elapsed: 00:09:33
                               ETA: 00:41:09

################################################################################
                     [1m Learning iteration 283/1500 [0m                      

                       Computation: 52562 steps/s (collection: 1.762s, learning 0.109s)
             Mean action noise std: 1.61
          Mean value_function loss: 112.9466
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 33.9547
                       Mean reward: 272.36
               Mean episode length: 220.96
    Episode_Reward/reaching_object: 0.5956
    Episode_Reward/rotating_object: 53.4065
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 1.87s
                      Time elapsed: 00:09:35
                               ETA: 00:41:06

################################################################################
                     [1m Learning iteration 284/1500 [0m                      

                       Computation: 53292 steps/s (collection: 1.745s, learning 0.100s)
             Mean action noise std: 1.61
          Mean value_function loss: 106.1354
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 33.9608
                       Mean reward: 260.50
               Mean episode length: 215.70
    Episode_Reward/reaching_object: 0.5778
    Episode_Reward/rotating_object: 52.1108
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 1.84s
                      Time elapsed: 00:09:37
                               ETA: 00:41:03

################################################################################
                     [1m Learning iteration 285/1500 [0m                      

                       Computation: 53205 steps/s (collection: 1.758s, learning 0.090s)
             Mean action noise std: 1.61
          Mean value_function loss: 98.3860
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 33.9701
                       Mean reward: 283.84
               Mean episode length: 224.64
    Episode_Reward/reaching_object: 0.5933
    Episode_Reward/rotating_object: 55.5303
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 1.85s
                      Time elapsed: 00:09:39
                               ETA: 00:41:01

################################################################################
                     [1m Learning iteration 286/1500 [0m                      

                       Computation: 53352 steps/s (collection: 1.741s, learning 0.101s)
             Mean action noise std: 1.61
          Mean value_function loss: 109.0374
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 33.9861
                       Mean reward: 272.76
               Mean episode length: 218.51
    Episode_Reward/reaching_object: 0.5812
    Episode_Reward/rotating_object: 55.6328
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 1.84s
                      Time elapsed: 00:09:41
                               ETA: 00:40:58

################################################################################
                     [1m Learning iteration 287/1500 [0m                      

                       Computation: 53314 steps/s (collection: 1.752s, learning 0.092s)
             Mean action noise std: 1.61
          Mean value_function loss: 101.9340
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 33.9994
                       Mean reward: 269.38
               Mean episode length: 228.46
    Episode_Reward/reaching_object: 0.5809
    Episode_Reward/rotating_object: 55.9977
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 1.84s
                      Time elapsed: 00:09:43
                               ETA: 00:40:55

################################################################################
                     [1m Learning iteration 288/1500 [0m                      

                       Computation: 53021 steps/s (collection: 1.757s, learning 0.098s)
             Mean action noise std: 1.61
          Mean value_function loss: 112.7510
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 34.0053
                       Mean reward: 275.22
               Mean episode length: 222.68
    Episode_Reward/reaching_object: 0.5910
    Episode_Reward/rotating_object: 56.0675
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 1.85s
                      Time elapsed: 00:09:44
                               ETA: 00:40:52

################################################################################
                     [1m Learning iteration 289/1500 [0m                      

                       Computation: 52771 steps/s (collection: 1.773s, learning 0.090s)
             Mean action noise std: 1.61
          Mean value_function loss: 126.3564
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 34.0147
                       Mean reward: 266.79
               Mean episode length: 216.33
    Episode_Reward/reaching_object: 0.6034
    Episode_Reward/rotating_object: 59.9671
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 1.86s
                      Time elapsed: 00:09:46
                               ETA: 00:40:50

################################################################################
                     [1m Learning iteration 290/1500 [0m                      

                       Computation: 52328 steps/s (collection: 1.740s, learning 0.139s)
             Mean action noise std: 1.62
          Mean value_function loss: 114.4102
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 34.0301
                       Mean reward: 255.37
               Mean episode length: 220.68
    Episode_Reward/reaching_object: 0.6074
    Episode_Reward/rotating_object: 58.4500
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 1.88s
                      Time elapsed: 00:09:48
                               ETA: 00:40:47

################################################################################
                     [1m Learning iteration 291/1500 [0m                      

                       Computation: 52490 steps/s (collection: 1.762s, learning 0.110s)
             Mean action noise std: 1.62
          Mean value_function loss: 109.8743
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 34.0436
                       Mean reward: 332.11
               Mean episode length: 227.64
    Episode_Reward/reaching_object: 0.6124
    Episode_Reward/rotating_object: 62.2576
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 1.87s
                      Time elapsed: 00:09:50
                               ETA: 00:40:44

################################################################################
                     [1m Learning iteration 292/1500 [0m                      

                       Computation: 51824 steps/s (collection: 1.809s, learning 0.088s)
             Mean action noise std: 1.62
          Mean value_function loss: 118.6185
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 34.0546
                       Mean reward: 271.73
               Mean episode length: 222.56
    Episode_Reward/reaching_object: 0.6011
    Episode_Reward/rotating_object: 55.8514
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 1.90s
                      Time elapsed: 00:09:52
                               ETA: 00:40:42

################################################################################
                     [1m Learning iteration 293/1500 [0m                      

                       Computation: 51821 steps/s (collection: 1.798s, learning 0.099s)
             Mean action noise std: 1.62
          Mean value_function loss: 114.9777
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 34.0693
                       Mean reward: 291.91
               Mean episode length: 228.02
    Episode_Reward/reaching_object: 0.6140
    Episode_Reward/rotating_object: 57.8308
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 1.90s
                      Time elapsed: 00:09:54
                               ETA: 00:40:39

################################################################################
                     [1m Learning iteration 294/1500 [0m                      

                       Computation: 53234 steps/s (collection: 1.753s, learning 0.094s)
             Mean action noise std: 1.62
          Mean value_function loss: 118.7050
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 34.0808
                       Mean reward: 313.68
               Mean episode length: 228.74
    Episode_Reward/reaching_object: 0.6325
    Episode_Reward/rotating_object: 61.1207
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 1.85s
                      Time elapsed: 00:09:56
                               ETA: 00:40:37

################################################################################
                     [1m Learning iteration 295/1500 [0m                      

                       Computation: 52811 steps/s (collection: 1.763s, learning 0.098s)
             Mean action noise std: 1.62
          Mean value_function loss: 123.8342
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 34.0890
                       Mean reward: 292.10
               Mean episode length: 225.32
    Episode_Reward/reaching_object: 0.6217
    Episode_Reward/rotating_object: 63.9152
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 1.86s
                      Time elapsed: 00:09:57
                               ETA: 00:40:34

################################################################################
                     [1m Learning iteration 296/1500 [0m                      

                       Computation: 52883 steps/s (collection: 1.763s, learning 0.096s)
             Mean action noise std: 1.62
          Mean value_function loss: 117.1665
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 34.0961
                       Mean reward: 348.60
               Mean episode length: 233.18
    Episode_Reward/reaching_object: 0.6403
    Episode_Reward/rotating_object: 64.9449
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 1.86s
                      Time elapsed: 00:09:59
                               ETA: 00:40:31

################################################################################
                     [1m Learning iteration 297/1500 [0m                      

                       Computation: 51929 steps/s (collection: 1.752s, learning 0.141s)
             Mean action noise std: 1.62
          Mean value_function loss: 112.0082
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 34.1059
                       Mean reward: 349.55
               Mean episode length: 239.22
    Episode_Reward/reaching_object: 0.6621
    Episode_Reward/rotating_object: 65.0399
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 1.89s
                      Time elapsed: 00:10:01
                               ETA: 00:40:29

################################################################################
                     [1m Learning iteration 298/1500 [0m                      

                       Computation: 52350 steps/s (collection: 1.785s, learning 0.093s)
             Mean action noise std: 1.62
          Mean value_function loss: 116.8753
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 34.1132
                       Mean reward: 306.77
               Mean episode length: 229.27
    Episode_Reward/reaching_object: 0.6496
    Episode_Reward/rotating_object: 65.7964
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 1.88s
                      Time elapsed: 00:10:03
                               ETA: 00:40:26

################################################################################
                     [1m Learning iteration 299/1500 [0m                      

                       Computation: 53336 steps/s (collection: 1.735s, learning 0.108s)
             Mean action noise std: 1.63
          Mean value_function loss: 123.4623
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 34.1244
                       Mean reward: 380.38
               Mean episode length: 242.13
    Episode_Reward/reaching_object: 0.6715
    Episode_Reward/rotating_object: 73.3025
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 1.84s
                      Time elapsed: 00:10:05
                               ETA: 00:40:23

################################################################################
                     [1m Learning iteration 300/1500 [0m                      

                       Computation: 51619 steps/s (collection: 1.801s, learning 0.104s)
             Mean action noise std: 1.63
          Mean value_function loss: 134.0946
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 34.1348
                       Mean reward: 362.22
               Mean episode length: 230.52
    Episode_Reward/reaching_object: 0.6535
    Episode_Reward/rotating_object: 69.4649
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 1.90s
                      Time elapsed: 00:10:07
                               ETA: 00:40:21

################################################################################
                     [1m Learning iteration 301/1500 [0m                      

                       Computation: 53335 steps/s (collection: 1.753s, learning 0.090s)
             Mean action noise std: 1.63
          Mean value_function loss: 128.9422
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 34.1390
                       Mean reward: 334.40
               Mean episode length: 225.61
    Episode_Reward/reaching_object: 0.6622
    Episode_Reward/rotating_object: 71.8409
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 1.84s
                      Time elapsed: 00:10:09
                               ETA: 00:40:18

################################################################################
                     [1m Learning iteration 302/1500 [0m                      

                       Computation: 53174 steps/s (collection: 1.756s, learning 0.093s)
             Mean action noise std: 1.63
          Mean value_function loss: 120.7165
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 34.1473
                       Mean reward: 312.40
               Mean episode length: 227.01
    Episode_Reward/reaching_object: 0.6574
    Episode_Reward/rotating_object: 64.2562
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 1.85s
                      Time elapsed: 00:10:11
                               ETA: 00:40:15

################################################################################
                     [1m Learning iteration 303/1500 [0m                      

                       Computation: 52359 steps/s (collection: 1.788s, learning 0.090s)
             Mean action noise std: 1.63
          Mean value_function loss: 122.7821
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 34.1606
                       Mean reward: 360.91
               Mean episode length: 232.29
    Episode_Reward/reaching_object: 0.6607
    Episode_Reward/rotating_object: 72.0485
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 1.88s
                      Time elapsed: 00:10:12
                               ETA: 00:40:13

################################################################################
                     [1m Learning iteration 304/1500 [0m                      

                       Computation: 52208 steps/s (collection: 1.793s, learning 0.090s)
             Mean action noise std: 1.63
          Mean value_function loss: 116.9424
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 34.1711
                       Mean reward: 394.98
               Mean episode length: 240.95
    Episode_Reward/reaching_object: 0.6617
    Episode_Reward/rotating_object: 71.8699
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 1.88s
                      Time elapsed: 00:10:14
                               ETA: 00:40:10

################################################################################
                     [1m Learning iteration 305/1500 [0m                      

                       Computation: 50239 steps/s (collection: 1.824s, learning 0.133s)
             Mean action noise std: 1.63
          Mean value_function loss: 108.0169
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 34.1808
                       Mean reward: 354.09
               Mean episode length: 237.86
    Episode_Reward/reaching_object: 0.6633
    Episode_Reward/rotating_object: 68.3802
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 1.96s
                      Time elapsed: 00:10:16
                               ETA: 00:40:08

################################################################################
                     [1m Learning iteration 306/1500 [0m                      

                       Computation: 50409 steps/s (collection: 1.835s, learning 0.115s)
             Mean action noise std: 1.63
          Mean value_function loss: 100.8343
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 34.1894
                       Mean reward: 362.06
               Mean episode length: 241.01
    Episode_Reward/reaching_object: 0.6736
    Episode_Reward/rotating_object: 72.7383
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 1.95s
                      Time elapsed: 00:10:18
                               ETA: 00:40:06

################################################################################
                     [1m Learning iteration 307/1500 [0m                      

                       Computation: 51987 steps/s (collection: 1.771s, learning 0.120s)
             Mean action noise std: 1.63
          Mean value_function loss: 106.8110
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 34.2005
                       Mean reward: 385.99
               Mean episode length: 233.05
    Episode_Reward/reaching_object: 0.6490
    Episode_Reward/rotating_object: 72.6295
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 1.89s
                      Time elapsed: 00:10:20
                               ETA: 00:40:03

################################################################################
                     [1m Learning iteration 308/1500 [0m                      

                       Computation: 52458 steps/s (collection: 1.784s, learning 0.090s)
             Mean action noise std: 1.63
          Mean value_function loss: 106.2807
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 34.2082
                       Mean reward: 404.61
               Mean episode length: 235.84
    Episode_Reward/reaching_object: 0.6612
    Episode_Reward/rotating_object: 76.2599
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 1.87s
                      Time elapsed: 00:10:22
                               ETA: 00:40:01

################################################################################
                     [1m Learning iteration 309/1500 [0m                      

                       Computation: 52707 steps/s (collection: 1.775s, learning 0.090s)
             Mean action noise std: 1.63
          Mean value_function loss: 107.6870
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 34.2145
                       Mean reward: 361.80
               Mean episode length: 232.66
    Episode_Reward/reaching_object: 0.6670
    Episode_Reward/rotating_object: 71.3150
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 1.87s
                      Time elapsed: 00:10:24
                               ETA: 00:39:58

################################################################################
                     [1m Learning iteration 310/1500 [0m                      

                       Computation: 50156 steps/s (collection: 1.845s, learning 0.115s)
             Mean action noise std: 1.63
          Mean value_function loss: 102.7394
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 34.2225
                       Mean reward: 334.82
               Mean episode length: 234.33
    Episode_Reward/reaching_object: 0.6636
    Episode_Reward/rotating_object: 73.6028
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 1.96s
                      Time elapsed: 00:10:26
                               ETA: 00:39:56

################################################################################
                     [1m Learning iteration 311/1500 [0m                      

                       Computation: 51675 steps/s (collection: 1.801s, learning 0.101s)
             Mean action noise std: 1.64
          Mean value_function loss: 118.4223
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 34.2293
                       Mean reward: 379.56
               Mean episode length: 238.27
    Episode_Reward/reaching_object: 0.6619
    Episode_Reward/rotating_object: 74.6367
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 1.90s
                      Time elapsed: 00:10:28
                               ETA: 00:39:54

################################################################################
                     [1m Learning iteration 312/1500 [0m                      

                       Computation: 50804 steps/s (collection: 1.809s, learning 0.126s)
             Mean action noise std: 1.64
          Mean value_function loss: 105.0851
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 34.2395
                       Mean reward: 378.97
               Mean episode length: 226.19
    Episode_Reward/reaching_object: 0.6582
    Episode_Reward/rotating_object: 73.7248
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 1.93s
                      Time elapsed: 00:10:30
                               ETA: 00:39:51

################################################################################
                     [1m Learning iteration 313/1500 [0m                      

                       Computation: 51512 steps/s (collection: 1.800s, learning 0.109s)
             Mean action noise std: 1.64
          Mean value_function loss: 118.0213
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 34.2488
                       Mean reward: 347.30
               Mean episode length: 235.34
    Episode_Reward/reaching_object: 0.6699
    Episode_Reward/rotating_object: 73.0372
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 1.91s
                      Time elapsed: 00:10:32
                               ETA: 00:39:49

################################################################################
                     [1m Learning iteration 314/1500 [0m                      

                       Computation: 51758 steps/s (collection: 1.811s, learning 0.088s)
             Mean action noise std: 1.64
          Mean value_function loss: 128.8275
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 34.2549
                       Mean reward: 364.68
               Mean episode length: 230.47
    Episode_Reward/reaching_object: 0.6500
    Episode_Reward/rotating_object: 75.5696
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 1.90s
                      Time elapsed: 00:10:33
                               ETA: 00:39:46

################################################################################
                     [1m Learning iteration 315/1500 [0m                      

                       Computation: 51098 steps/s (collection: 1.791s, learning 0.133s)
             Mean action noise std: 1.64
          Mean value_function loss: 129.1685
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 34.2654
                       Mean reward: 397.80
               Mean episode length: 237.42
    Episode_Reward/reaching_object: 0.6658
    Episode_Reward/rotating_object: 72.2018
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 1.92s
                      Time elapsed: 00:10:35
                               ETA: 00:39:44

################################################################################
                     [1m Learning iteration 316/1500 [0m                      

                       Computation: 49901 steps/s (collection: 1.796s, learning 0.174s)
             Mean action noise std: 1.64
          Mean value_function loss: 140.5413
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 34.2736
                       Mean reward: 393.87
               Mean episode length: 235.27
    Episode_Reward/reaching_object: 0.6861
    Episode_Reward/rotating_object: 75.1676
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 1.97s
                      Time elapsed: 00:10:37
                               ETA: 00:39:42

################################################################################
                     [1m Learning iteration 317/1500 [0m                      

                       Computation: 50325 steps/s (collection: 1.828s, learning 0.125s)
             Mean action noise std: 1.64
          Mean value_function loss: 117.5659
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 34.2799
                       Mean reward: 418.73
               Mean episode length: 235.96
    Episode_Reward/reaching_object: 0.6639
    Episode_Reward/rotating_object: 77.6679
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 1.95s
                      Time elapsed: 00:10:39
                               ETA: 00:39:40

################################################################################
                     [1m Learning iteration 318/1500 [0m                      

                       Computation: 49040 steps/s (collection: 1.837s, learning 0.168s)
             Mean action noise std: 1.64
          Mean value_function loss: 115.7606
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 34.2863
                       Mean reward: 422.36
               Mean episode length: 233.44
    Episode_Reward/reaching_object: 0.6776
    Episode_Reward/rotating_object: 78.7438
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 2.00s
                      Time elapsed: 00:10:41
                               ETA: 00:39:38

################################################################################
                     [1m Learning iteration 319/1500 [0m                      

                       Computation: 52092 steps/s (collection: 1.778s, learning 0.109s)
             Mean action noise std: 1.64
          Mean value_function loss: 118.4513
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 34.2911
                       Mean reward: 390.18
               Mean episode length: 223.86
    Episode_Reward/reaching_object: 0.6589
    Episode_Reward/rotating_object: 75.5129
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 1.89s
                      Time elapsed: 00:10:43
                               ETA: 00:39:35

################################################################################
                     [1m Learning iteration 320/1500 [0m                      

                       Computation: 50527 steps/s (collection: 1.834s, learning 0.111s)
             Mean action noise std: 1.64
          Mean value_function loss: 116.4645
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 34.2973
                       Mean reward: 389.22
               Mean episode length: 234.61
    Episode_Reward/reaching_object: 0.6754
    Episode_Reward/rotating_object: 78.1470
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 1.95s
                      Time elapsed: 00:10:45
                               ETA: 00:39:33

################################################################################
                     [1m Learning iteration 321/1500 [0m                      

                       Computation: 50974 steps/s (collection: 1.810s, learning 0.118s)
             Mean action noise std: 1.64
          Mean value_function loss: 114.2631
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 34.3045
                       Mean reward: 431.98
               Mean episode length: 229.94
    Episode_Reward/reaching_object: 0.6666
    Episode_Reward/rotating_object: 80.9318
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 1.93s
                      Time elapsed: 00:10:47
                               ETA: 00:39:31

################################################################################
                     [1m Learning iteration 322/1500 [0m                      

                       Computation: 50909 steps/s (collection: 1.834s, learning 0.097s)
             Mean action noise std: 1.64
          Mean value_function loss: 113.4875
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 34.3186
                       Mean reward: 426.84
               Mean episode length: 236.51
    Episode_Reward/reaching_object: 0.6707
    Episode_Reward/rotating_object: 79.5459
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 1.93s
                      Time elapsed: 00:10:49
                               ETA: 00:39:28

################################################################################
                     [1m Learning iteration 323/1500 [0m                      

                       Computation: 51482 steps/s (collection: 1.819s, learning 0.091s)
             Mean action noise std: 1.65
          Mean value_function loss: 109.4702
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 34.3298
                       Mean reward: 380.69
               Mean episode length: 231.07
    Episode_Reward/reaching_object: 0.6704
    Episode_Reward/rotating_object: 80.4187
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 1.91s
                      Time elapsed: 00:10:51
                               ETA: 00:39:26

################################################################################
                     [1m Learning iteration 324/1500 [0m                      

                       Computation: 51085 steps/s (collection: 1.809s, learning 0.116s)
             Mean action noise std: 1.65
          Mean value_function loss: 107.9311
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 34.3377
                       Mean reward: 375.37
               Mean episode length: 227.54
    Episode_Reward/reaching_object: 0.6716
    Episode_Reward/rotating_object: 80.6698
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 1.92s
                      Time elapsed: 00:10:53
                               ETA: 00:39:24

################################################################################
                     [1m Learning iteration 325/1500 [0m                      

                       Computation: 50878 steps/s (collection: 1.835s, learning 0.097s)
             Mean action noise std: 1.65
          Mean value_function loss: 127.6745
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 34.3467
                       Mean reward: 396.28
               Mean episode length: 227.97
    Episode_Reward/reaching_object: 0.6672
    Episode_Reward/rotating_object: 81.4516
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 1.93s
                      Time elapsed: 00:10:55
                               ETA: 00:39:21

################################################################################
                     [1m Learning iteration 326/1500 [0m                      

                       Computation: 52112 steps/s (collection: 1.796s, learning 0.090s)
             Mean action noise std: 1.65
          Mean value_function loss: 128.4320
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 34.3597
                       Mean reward: 368.46
               Mean episode length: 217.99
    Episode_Reward/reaching_object: 0.6515
    Episode_Reward/rotating_object: 79.0213
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 1.89s
                      Time elapsed: 00:10:57
                               ETA: 00:39:19

################################################################################
                     [1m Learning iteration 327/1500 [0m                      

                       Computation: 51680 steps/s (collection: 1.813s, learning 0.090s)
             Mean action noise std: 1.65
          Mean value_function loss: 123.2807
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 34.3698
                       Mean reward: 457.18
               Mean episode length: 238.04
    Episode_Reward/reaching_object: 0.6610
    Episode_Reward/rotating_object: 80.0572
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 1.90s
                      Time elapsed: 00:10:59
                               ETA: 00:39:16

################################################################################
                     [1m Learning iteration 328/1500 [0m                      

                       Computation: 51375 steps/s (collection: 1.806s, learning 0.108s)
             Mean action noise std: 1.65
          Mean value_function loss: 109.8275
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 34.3801
                       Mean reward: 390.45
               Mean episode length: 233.33
    Episode_Reward/reaching_object: 0.6550
    Episode_Reward/rotating_object: 80.2386
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 1.91s
                      Time elapsed: 00:11:00
                               ETA: 00:39:14

################################################################################
                     [1m Learning iteration 329/1500 [0m                      

                       Computation: 51124 steps/s (collection: 1.824s, learning 0.099s)
             Mean action noise std: 1.65
          Mean value_function loss: 124.9635
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 34.3842
                       Mean reward: 407.24
               Mean episode length: 230.22
    Episode_Reward/reaching_object: 0.6735
    Episode_Reward/rotating_object: 84.5818
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 1.92s
                      Time elapsed: 00:11:02
                               ETA: 00:39:12

################################################################################
                     [1m Learning iteration 330/1500 [0m                      

                       Computation: 50121 steps/s (collection: 1.833s, learning 0.129s)
             Mean action noise std: 1.65
          Mean value_function loss: 118.4289
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 34.3883
                       Mean reward: 420.35
               Mean episode length: 228.99
    Episode_Reward/reaching_object: 0.6518
    Episode_Reward/rotating_object: 81.6615
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 1.96s
                      Time elapsed: 00:11:04
                               ETA: 00:39:10

################################################################################
                     [1m Learning iteration 331/1500 [0m                      

                       Computation: 48603 steps/s (collection: 1.864s, learning 0.158s)
             Mean action noise std: 1.65
          Mean value_function loss: 135.2746
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 34.3934
                       Mean reward: 424.20
               Mean episode length: 234.01
    Episode_Reward/reaching_object: 0.6687
    Episode_Reward/rotating_object: 84.6782
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 2.02s
                      Time elapsed: 00:11:06
                               ETA: 00:39:08

################################################################################
                     [1m Learning iteration 332/1500 [0m                      

                       Computation: 49326 steps/s (collection: 1.828s, learning 0.165s)
             Mean action noise std: 1.65
          Mean value_function loss: 130.4971
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 34.3998
                       Mean reward: 394.31
               Mean episode length: 223.48
    Episode_Reward/reaching_object: 0.6704
    Episode_Reward/rotating_object: 86.6091
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 1.99s
                      Time elapsed: 00:11:08
                               ETA: 00:39:06

################################################################################
                     [1m Learning iteration 333/1500 [0m                      

                       Computation: 19485 steps/s (collection: 4.925s, learning 0.120s)
             Mean action noise std: 1.65
          Mean value_function loss: 125.3227
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 34.4079
                       Mean reward: 462.76
               Mean episode length: 238.18
    Episode_Reward/reaching_object: 0.6829
    Episode_Reward/rotating_object: 87.4156
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 5.04s
                      Time elapsed: 00:11:13
                               ETA: 00:39:14

################################################################################
                     [1m Learning iteration 334/1500 [0m                      

                       Computation: 14813 steps/s (collection: 6.517s, learning 0.120s)
             Mean action noise std: 1.65
          Mean value_function loss: 119.1962
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 34.4164
                       Mean reward: 394.72
               Mean episode length: 224.07
    Episode_Reward/reaching_object: 0.6511
    Episode_Reward/rotating_object: 81.2870
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 6.64s
                      Time elapsed: 00:11:20
                               ETA: 00:39:28

################################################################################
                     [1m Learning iteration 335/1500 [0m                      

                       Computation: 14762 steps/s (collection: 6.541s, learning 0.118s)
             Mean action noise std: 1.65
          Mean value_function loss: 113.5510
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 34.4230
                       Mean reward: 365.70
               Mean episode length: 216.40
    Episode_Reward/reaching_object: 0.6562
    Episode_Reward/rotating_object: 79.5745
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 6.66s
                      Time elapsed: 00:11:27
                               ETA: 00:39:42

################################################################################
                     [1m Learning iteration 336/1500 [0m                      

                       Computation: 14201 steps/s (collection: 6.798s, learning 0.125s)
             Mean action noise std: 1.66
          Mean value_function loss: 102.4920
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 34.4305
                       Mean reward: 439.67
               Mean episode length: 233.09
    Episode_Reward/reaching_object: 0.6669
    Episode_Reward/rotating_object: 86.3346
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 6.92s
                      Time elapsed: 00:11:34
                               ETA: 00:39:57

################################################################################
                     [1m Learning iteration 337/1500 [0m                      

                       Computation: 14587 steps/s (collection: 6.614s, learning 0.124s)
             Mean action noise std: 1.66
          Mean value_function loss: 112.8590
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 34.4402
                       Mean reward: 481.52
               Mean episode length: 243.41
    Episode_Reward/reaching_object: 0.6790
    Episode_Reward/rotating_object: 90.1967
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 6.74s
                      Time elapsed: 00:11:40
                               ETA: 00:40:11

################################################################################
                     [1m Learning iteration 338/1500 [0m                      

                       Computation: 15100 steps/s (collection: 6.393s, learning 0.118s)
             Mean action noise std: 1.66
          Mean value_function loss: 110.2493
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 34.4452
                       Mean reward: 454.15
               Mean episode length: 241.99
    Episode_Reward/reaching_object: 0.6784
    Episode_Reward/rotating_object: 87.4582
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 6.51s
                      Time elapsed: 00:11:47
                               ETA: 00:40:24

################################################################################
                     [1m Learning iteration 339/1500 [0m                      

                       Computation: 14318 steps/s (collection: 6.700s, learning 0.166s)
             Mean action noise std: 1.66
          Mean value_function loss: 107.2522
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 34.4507
                       Mean reward: 448.51
               Mean episode length: 237.74
    Episode_Reward/reaching_object: 0.6942
    Episode_Reward/rotating_object: 90.4758
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 6.87s
                      Time elapsed: 00:11:54
                               ETA: 00:40:38

################################################################################
                     [1m Learning iteration 340/1500 [0m                      

                       Computation: 14615 steps/s (collection: 6.608s, learning 0.119s)
             Mean action noise std: 1.66
          Mean value_function loss: 115.3303
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 34.4549
                       Mean reward: 462.48
               Mean episode length: 242.68
    Episode_Reward/reaching_object: 0.6862
    Episode_Reward/rotating_object: 90.0338
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 6.73s
                      Time elapsed: 00:12:00
                               ETA: 00:40:52

################################################################################
                     [1m Learning iteration 341/1500 [0m                      

                       Computation: 12939 steps/s (collection: 7.448s, learning 0.149s)
             Mean action noise std: 1.66
          Mean value_function loss: 119.6052
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 34.4613
                       Mean reward: 430.32
               Mean episode length: 230.58
    Episode_Reward/reaching_object: 0.6782
    Episode_Reward/rotating_object: 87.7230
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 7.60s
                      Time elapsed: 00:12:08
                               ETA: 00:41:09

################################################################################
                     [1m Learning iteration 342/1500 [0m                      

                       Computation: 42671 steps/s (collection: 2.178s, learning 0.126s)
             Mean action noise std: 1.66
          Mean value_function loss: 118.5891
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 34.4733
                       Mean reward: 480.45
               Mean episode length: 238.99
    Episode_Reward/reaching_object: 0.6841
    Episode_Reward/rotating_object: 90.5325
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 2.30s
                      Time elapsed: 00:12:10
                               ETA: 00:41:07

################################################################################
                     [1m Learning iteration 343/1500 [0m                      

                       Computation: 52436 steps/s (collection: 1.783s, learning 0.092s)
             Mean action noise std: 1.66
          Mean value_function loss: 114.6576
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 34.4806
                       Mean reward: 469.69
               Mean episode length: 238.85
    Episode_Reward/reaching_object: 0.6836
    Episode_Reward/rotating_object: 92.0163
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 1.87s
                      Time elapsed: 00:12:12
                               ETA: 00:41:04

################################################################################
                     [1m Learning iteration 344/1500 [0m                      

                       Computation: 52408 steps/s (collection: 1.783s, learning 0.093s)
             Mean action noise std: 1.66
          Mean value_function loss: 127.5352
               Mean surrogate loss: 0.0016
                 Mean entropy loss: 34.4833
                       Mean reward: 469.66
               Mean episode length: 227.30
    Episode_Reward/reaching_object: 0.6660
    Episode_Reward/rotating_object: 92.5507
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 1.88s
                      Time elapsed: 00:12:14
                               ETA: 00:41:01

################################################################################
                     [1m Learning iteration 345/1500 [0m                      

                       Computation: 53381 steps/s (collection: 1.744s, learning 0.097s)
             Mean action noise std: 1.66
          Mean value_function loss: 99.0556
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 34.4867
                       Mean reward: 491.17
               Mean episode length: 234.57
    Episode_Reward/reaching_object: 0.6818
    Episode_Reward/rotating_object: 92.8681
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 1.84s
                      Time elapsed: 00:12:16
                               ETA: 00:40:58

################################################################################
                     [1m Learning iteration 346/1500 [0m                      

                       Computation: 50934 steps/s (collection: 1.830s, learning 0.100s)
             Mean action noise std: 1.66
          Mean value_function loss: 91.1377
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 34.4939
                       Mean reward: 459.47
               Mean episode length: 238.64
    Episode_Reward/reaching_object: 0.6879
    Episode_Reward/rotating_object: 94.8863
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 1.93s
                      Time elapsed: 00:12:18
                               ETA: 00:40:55

################################################################################
                     [1m Learning iteration 347/1500 [0m                      

                       Computation: 52401 steps/s (collection: 1.775s, learning 0.101s)
             Mean action noise std: 1.66
          Mean value_function loss: 94.5682
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 34.4996
                       Mean reward: 505.33
               Mean episode length: 237.01
    Episode_Reward/reaching_object: 0.6738
    Episode_Reward/rotating_object: 97.1943
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 1.88s
                      Time elapsed: 00:12:20
                               ETA: 00:40:52

################################################################################
                     [1m Learning iteration 348/1500 [0m                      

                       Computation: 51707 steps/s (collection: 1.780s, learning 0.121s)
             Mean action noise std: 1.66
          Mean value_function loss: 104.8384
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 34.5028
                       Mean reward: 478.95
               Mean episode length: 241.81
    Episode_Reward/reaching_object: 0.6817
    Episode_Reward/rotating_object: 99.7266
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 1.90s
                      Time elapsed: 00:12:22
                               ETA: 00:40:49

################################################################################
                     [1m Learning iteration 349/1500 [0m                      

                       Computation: 53006 steps/s (collection: 1.760s, learning 0.095s)
             Mean action noise std: 1.66
          Mean value_function loss: 108.5353
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 34.5100
                       Mean reward: 463.47
               Mean episode length: 232.53
    Episode_Reward/reaching_object: 0.6722
    Episode_Reward/rotating_object: 96.0669
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 1.85s
                      Time elapsed: 00:12:24
                               ETA: 00:40:46

################################################################################
                     [1m Learning iteration 350/1500 [0m                      

                       Computation: 53163 steps/s (collection: 1.749s, learning 0.101s)
             Mean action noise std: 1.66
          Mean value_function loss: 97.7761
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 34.5228
                       Mean reward: 511.87
               Mean episode length: 241.82
    Episode_Reward/reaching_object: 0.6770
    Episode_Reward/rotating_object: 99.2208
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 1.85s
                      Time elapsed: 00:12:25
                               ETA: 00:40:43

################################################################################
                     [1m Learning iteration 351/1500 [0m                      

                       Computation: 53911 steps/s (collection: 1.728s, learning 0.095s)
             Mean action noise std: 1.67
          Mean value_function loss: 92.8758
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 34.5288
                       Mean reward: 501.63
               Mean episode length: 245.32
    Episode_Reward/reaching_object: 0.6901
    Episode_Reward/rotating_object: 100.1058
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 1.82s
                      Time elapsed: 00:12:27
                               ETA: 00:40:40

################################################################################
                     [1m Learning iteration 352/1500 [0m                      

                       Computation: 52355 steps/s (collection: 1.775s, learning 0.103s)
             Mean action noise std: 1.67
          Mean value_function loss: 98.6175
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 34.5371
                       Mean reward: 501.89
               Mean episode length: 241.47
    Episode_Reward/reaching_object: 0.6773
    Episode_Reward/rotating_object: 99.4603
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 1.88s
                      Time elapsed: 00:12:29
                               ETA: 00:40:37

################################################################################
                     [1m Learning iteration 353/1500 [0m                      

                       Computation: 49238 steps/s (collection: 1.875s, learning 0.122s)
             Mean action noise std: 1.67
          Mean value_function loss: 104.1878
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 34.5462
                       Mean reward: 493.93
               Mean episode length: 241.78
    Episode_Reward/reaching_object: 0.6756
    Episode_Reward/rotating_object: 94.5776
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 2.00s
                      Time elapsed: 00:12:31
                               ETA: 00:40:35

################################################################################
                     [1m Learning iteration 354/1500 [0m                      

                       Computation: 50185 steps/s (collection: 1.835s, learning 0.123s)
             Mean action noise std: 1.67
          Mean value_function loss: 103.0368
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 34.5575
                       Mean reward: 482.98
               Mean episode length: 240.72
    Episode_Reward/reaching_object: 0.6634
    Episode_Reward/rotating_object: 97.2507
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 1.96s
                      Time elapsed: 00:12:33
                               ETA: 00:40:32

################################################################################
                     [1m Learning iteration 355/1500 [0m                      

                       Computation: 51326 steps/s (collection: 1.747s, learning 0.169s)
             Mean action noise std: 1.67
          Mean value_function loss: 101.3170
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 34.5674
                       Mean reward: 474.62
               Mean episode length: 234.76
    Episode_Reward/reaching_object: 0.6665
    Episode_Reward/rotating_object: 93.2544
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 1.92s
                      Time elapsed: 00:12:35
                               ETA: 00:40:29

################################################################################
                     [1m Learning iteration 356/1500 [0m                      

                       Computation: 53224 steps/s (collection: 1.722s, learning 0.125s)
             Mean action noise std: 1.67
          Mean value_function loss: 101.6146
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 34.5758
                       Mean reward: 506.47
               Mean episode length: 234.77
    Episode_Reward/reaching_object: 0.6705
    Episode_Reward/rotating_object: 96.8889
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 1.85s
                      Time elapsed: 00:12:37
                               ETA: 00:40:26

################################################################################
                     [1m Learning iteration 357/1500 [0m                      

                       Computation: 51946 steps/s (collection: 1.775s, learning 0.117s)
             Mean action noise std: 1.67
          Mean value_function loss: 108.2011
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 34.5819
                       Mean reward: 470.06
               Mean episode length: 233.95
    Episode_Reward/reaching_object: 0.6690
    Episode_Reward/rotating_object: 95.2243
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 1.89s
                      Time elapsed: 00:12:39
                               ETA: 00:40:23

################################################################################
                     [1m Learning iteration 358/1500 [0m                      

                       Computation: 52373 steps/s (collection: 1.778s, learning 0.099s)
             Mean action noise std: 1.67
          Mean value_function loss: 101.0011
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 34.5905
                       Mean reward: 523.55
               Mean episode length: 238.64
    Episode_Reward/reaching_object: 0.6638
    Episode_Reward/rotating_object: 97.2114
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 1.88s
                      Time elapsed: 00:12:41
                               ETA: 00:40:20

################################################################################
                     [1m Learning iteration 359/1500 [0m                      

                       Computation: 53017 steps/s (collection: 1.760s, learning 0.095s)
             Mean action noise std: 1.67
          Mean value_function loss: 105.5983
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 34.5992
                       Mean reward: 499.97
               Mean episode length: 237.46
    Episode_Reward/reaching_object: 0.6726
    Episode_Reward/rotating_object: 99.4372
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 1.85s
                      Time elapsed: 00:12:42
                               ETA: 00:40:17

################################################################################
                     [1m Learning iteration 360/1500 [0m                      

                       Computation: 52778 steps/s (collection: 1.769s, learning 0.094s)
             Mean action noise std: 1.67
          Mean value_function loss: 98.1840
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 34.6038
                       Mean reward: 479.70
               Mean episode length: 241.95
    Episode_Reward/reaching_object: 0.6790
    Episode_Reward/rotating_object: 97.3596
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 1.86s
                      Time elapsed: 00:12:44
                               ETA: 00:40:15

################################################################################
                     [1m Learning iteration 361/1500 [0m                      

                       Computation: 52266 steps/s (collection: 1.789s, learning 0.092s)
             Mean action noise std: 1.67
          Mean value_function loss: 98.9730
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 34.6074
                       Mean reward: 449.84
               Mean episode length: 236.46
    Episode_Reward/reaching_object: 0.6783
    Episode_Reward/rotating_object: 98.0149
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 1.88s
                      Time elapsed: 00:12:46
                               ETA: 00:40:12

################################################################################
                     [1m Learning iteration 362/1500 [0m                      

                       Computation: 52184 steps/s (collection: 1.777s, learning 0.106s)
             Mean action noise std: 1.67
          Mean value_function loss: 108.1009
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 34.6131
                       Mean reward: 527.50
               Mean episode length: 241.87
    Episode_Reward/reaching_object: 0.6702
    Episode_Reward/rotating_object: 100.9447
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 1.88s
                      Time elapsed: 00:12:48
                               ETA: 00:40:09

################################################################################
                     [1m Learning iteration 363/1500 [0m                      

                       Computation: 53804 steps/s (collection: 1.732s, learning 0.095s)
             Mean action noise std: 1.67
          Mean value_function loss: 112.9945
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 34.6188
                       Mean reward: 524.08
               Mean episode length: 237.44
    Episode_Reward/reaching_object: 0.6750
    Episode_Reward/rotating_object: 102.3043
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 1.83s
                      Time elapsed: 00:12:50
                               ETA: 00:40:06

################################################################################
                     [1m Learning iteration 364/1500 [0m                      

                       Computation: 53485 steps/s (collection: 1.734s, learning 0.104s)
             Mean action noise std: 1.68
          Mean value_function loss: 110.8924
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 34.6245
                       Mean reward: 522.83
               Mean episode length: 236.06
    Episode_Reward/reaching_object: 0.6577
    Episode_Reward/rotating_object: 100.0905
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 1.84s
                      Time elapsed: 00:12:52
                               ETA: 00:40:03

################################################################################
                     [1m Learning iteration 365/1500 [0m                      

                       Computation: 52358 steps/s (collection: 1.777s, learning 0.101s)
             Mean action noise std: 1.68
          Mean value_function loss: 103.5089
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 34.6340
                       Mean reward: 507.38
               Mean episode length: 237.00
    Episode_Reward/reaching_object: 0.6657
    Episode_Reward/rotating_object: 103.1211
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 1.88s
                      Time elapsed: 00:12:54
                               ETA: 00:40:00

################################################################################
                     [1m Learning iteration 366/1500 [0m                      

                       Computation: 53477 steps/s (collection: 1.748s, learning 0.090s)
             Mean action noise std: 1.68
          Mean value_function loss: 113.3503
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 34.6433
                       Mean reward: 493.54
               Mean episode length: 237.12
    Episode_Reward/reaching_object: 0.6666
    Episode_Reward/rotating_object: 99.3335
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 1.84s
                      Time elapsed: 00:12:55
                               ETA: 00:39:57

################################################################################
                     [1m Learning iteration 367/1500 [0m                      

                       Computation: 53200 steps/s (collection: 1.751s, learning 0.097s)
             Mean action noise std: 1.68
          Mean value_function loss: 100.1078
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 34.6489
                       Mean reward: 558.78
               Mean episode length: 243.42
    Episode_Reward/reaching_object: 0.6752
    Episode_Reward/rotating_object: 101.2812
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 1.85s
                      Time elapsed: 00:12:57
                               ETA: 00:39:54

################################################################################
                     [1m Learning iteration 368/1500 [0m                      

                       Computation: 53190 steps/s (collection: 1.759s, learning 0.090s)
             Mean action noise std: 1.68
          Mean value_function loss: 103.8237
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 34.6555
                       Mean reward: 480.42
               Mean episode length: 232.24
    Episode_Reward/reaching_object: 0.6731
    Episode_Reward/rotating_object: 103.8014
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 1.85s
                      Time elapsed: 00:12:59
                               ETA: 00:39:51

################################################################################
                     [1m Learning iteration 369/1500 [0m                      

                       Computation: 50706 steps/s (collection: 1.842s, learning 0.097s)
             Mean action noise std: 1.68
          Mean value_function loss: 96.4886
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 34.6618
                       Mean reward: 528.30
               Mean episode length: 238.62
    Episode_Reward/reaching_object: 0.6606
    Episode_Reward/rotating_object: 100.0855
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 1.94s
                      Time elapsed: 00:13:01
                               ETA: 00:39:49

################################################################################
                     [1m Learning iteration 370/1500 [0m                      

                       Computation: 52361 steps/s (collection: 1.751s, learning 0.127s)
             Mean action noise std: 1.68
          Mean value_function loss: 106.2845
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 34.6660
                       Mean reward: 515.88
               Mean episode length: 240.01
    Episode_Reward/reaching_object: 0.6714
    Episode_Reward/rotating_object: 101.7591
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 1.88s
                      Time elapsed: 00:13:03
                               ETA: 00:39:46

################################################################################
                     [1m Learning iteration 371/1500 [0m                      

                       Computation: 51385 steps/s (collection: 1.787s, learning 0.126s)
             Mean action noise std: 1.68
          Mean value_function loss: 99.6394
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 34.6734
                       Mean reward: 498.51
               Mean episode length: 235.38
    Episode_Reward/reaching_object: 0.6600
    Episode_Reward/rotating_object: 100.0685
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 1.91s
                      Time elapsed: 00:13:05
                               ETA: 00:39:43

################################################################################
                     [1m Learning iteration 372/1500 [0m                      

                       Computation: 48409 steps/s (collection: 1.874s, learning 0.157s)
             Mean action noise std: 1.68
          Mean value_function loss: 106.8819
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 34.6794
                       Mean reward: 558.98
               Mean episode length: 244.61
    Episode_Reward/reaching_object: 0.6648
    Episode_Reward/rotating_object: 105.8609
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 2.03s
                      Time elapsed: 00:13:07
                               ETA: 00:39:41

################################################################################
                     [1m Learning iteration 373/1500 [0m                      

                       Computation: 48242 steps/s (collection: 1.913s, learning 0.125s)
             Mean action noise std: 1.68
          Mean value_function loss: 104.8436
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 34.6888
                       Mean reward: 544.19
               Mean episode length: 241.44
    Episode_Reward/reaching_object: 0.6657
    Episode_Reward/rotating_object: 105.7941
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 2.04s
                      Time elapsed: 00:13:09
                               ETA: 00:39:38

################################################################################
                     [1m Learning iteration 374/1500 [0m                      

                       Computation: 50606 steps/s (collection: 1.796s, learning 0.146s)
             Mean action noise std: 1.68
          Mean value_function loss: 109.7100
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 34.6980
                       Mean reward: 487.32
               Mean episode length: 227.08
    Episode_Reward/reaching_object: 0.6599
    Episode_Reward/rotating_object: 101.8421
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 1.94s
                      Time elapsed: 00:13:11
                               ETA: 00:39:36

################################################################################
                     [1m Learning iteration 375/1500 [0m                      

                       Computation: 51853 steps/s (collection: 1.777s, learning 0.119s)
             Mean action noise std: 1.68
          Mean value_function loss: 114.5783
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 34.7018
                       Mean reward: 529.12
               Mean episode length: 239.31
    Episode_Reward/reaching_object: 0.6538
    Episode_Reward/rotating_object: 103.4542
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 1.90s
                      Time elapsed: 00:13:13
                               ETA: 00:39:33

################################################################################
                     [1m Learning iteration 376/1500 [0m                      

                       Computation: 51673 steps/s (collection: 1.809s, learning 0.093s)
             Mean action noise std: 1.68
          Mean value_function loss: 118.4580
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 34.7056
                       Mean reward: 493.06
               Mean episode length: 232.64
    Episode_Reward/reaching_object: 0.6495
    Episode_Reward/rotating_object: 104.4284
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 1.90s
                      Time elapsed: 00:13:15
                               ETA: 00:39:30

################################################################################
                     [1m Learning iteration 377/1500 [0m                      

                       Computation: 52340 steps/s (collection: 1.769s, learning 0.110s)
             Mean action noise std: 1.68
          Mean value_function loss: 109.9304
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 34.7125
                       Mean reward: 513.92
               Mean episode length: 229.54
    Episode_Reward/reaching_object: 0.6565
    Episode_Reward/rotating_object: 105.6465
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 1.88s
                      Time elapsed: 00:13:17
                               ETA: 00:39:27

################################################################################
                     [1m Learning iteration 378/1500 [0m                      

                       Computation: 48890 steps/s (collection: 1.897s, learning 0.114s)
             Mean action noise std: 1.69
          Mean value_function loss: 109.6086
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 34.7172
                       Mean reward: 526.09
               Mean episode length: 231.63
    Episode_Reward/reaching_object: 0.6472
    Episode_Reward/rotating_object: 104.3778
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 2.01s
                      Time elapsed: 00:13:19
                               ETA: 00:39:25

################################################################################
                     [1m Learning iteration 379/1500 [0m                      

                       Computation: 51739 steps/s (collection: 1.785s, learning 0.115s)
             Mean action noise std: 1.69
          Mean value_function loss: 113.7967
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 34.7274
                       Mean reward: 544.46
               Mean episode length: 242.71
    Episode_Reward/reaching_object: 0.6571
    Episode_Reward/rotating_object: 104.0475
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 1.90s
                      Time elapsed: 00:13:20
                               ETA: 00:39:22

################################################################################
                     [1m Learning iteration 380/1500 [0m                      

                       Computation: 51079 steps/s (collection: 1.810s, learning 0.114s)
             Mean action noise std: 1.69
          Mean value_function loss: 114.2893
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 34.7384
                       Mean reward: 548.40
               Mean episode length: 237.82
    Episode_Reward/reaching_object: 0.6442
    Episode_Reward/rotating_object: 105.9699
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 1.92s
                      Time elapsed: 00:13:22
                               ETA: 00:39:20

################################################################################
                     [1m Learning iteration 381/1500 [0m                      

                       Computation: 52290 steps/s (collection: 1.781s, learning 0.099s)
             Mean action noise std: 1.69
          Mean value_function loss: 95.1947
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 34.7476
                       Mean reward: 519.94
               Mean episode length: 230.65
    Episode_Reward/reaching_object: 0.6451
    Episode_Reward/rotating_object: 109.8135
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 1.88s
                      Time elapsed: 00:13:24
                               ETA: 00:39:17

################################################################################
                     [1m Learning iteration 382/1500 [0m                      

                       Computation: 52893 steps/s (collection: 1.746s, learning 0.112s)
             Mean action noise std: 1.69
          Mean value_function loss: 102.0027
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 34.7526
                       Mean reward: 541.66
               Mean episode length: 240.73
    Episode_Reward/reaching_object: 0.6591
    Episode_Reward/rotating_object: 109.8797
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 1.86s
                      Time elapsed: 00:13:26
                               ETA: 00:39:14

################################################################################
                     [1m Learning iteration 383/1500 [0m                      

                       Computation: 51852 steps/s (collection: 1.749s, learning 0.147s)
             Mean action noise std: 1.69
          Mean value_function loss: 94.9433
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 34.7552
                       Mean reward: 563.23
               Mean episode length: 242.41
    Episode_Reward/reaching_object: 0.6555
    Episode_Reward/rotating_object: 106.8428
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 1.90s
                      Time elapsed: 00:13:28
                               ETA: 00:39:11

################################################################################
                     [1m Learning iteration 384/1500 [0m                      

                       Computation: 52713 steps/s (collection: 1.746s, learning 0.119s)
             Mean action noise std: 1.69
          Mean value_function loss: 92.3246
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 34.7580
                       Mean reward: 538.49
               Mean episode length: 237.12
    Episode_Reward/reaching_object: 0.6542
    Episode_Reward/rotating_object: 106.1814
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 1.86s
                      Time elapsed: 00:13:30
                               ETA: 00:39:09

################################################################################
                     [1m Learning iteration 385/1500 [0m                      

                       Computation: 48858 steps/s (collection: 1.872s, learning 0.140s)
             Mean action noise std: 1.69
          Mean value_function loss: 86.9968
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 34.7622
                       Mean reward: 501.27
               Mean episode length: 240.94
    Episode_Reward/reaching_object: 0.6524
    Episode_Reward/rotating_object: 105.0993
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 2.01s
                      Time elapsed: 00:13:32
                               ETA: 00:39:06

################################################################################
                     [1m Learning iteration 386/1500 [0m                      

                       Computation: 48763 steps/s (collection: 1.870s, learning 0.146s)
             Mean action noise std: 1.69
          Mean value_function loss: 98.0632
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 34.7715
                       Mean reward: 536.51
               Mean episode length: 235.39
    Episode_Reward/reaching_object: 0.6490
    Episode_Reward/rotating_object: 108.2306
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 2.02s
                      Time elapsed: 00:13:34
                               ETA: 00:39:04

################################################################################
                     [1m Learning iteration 387/1500 [0m                      

                       Computation: 53842 steps/s (collection: 1.735s, learning 0.091s)
             Mean action noise std: 1.69
          Mean value_function loss: 89.9646
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 34.7816
                       Mean reward: 555.32
               Mean episode length: 243.58
    Episode_Reward/reaching_object: 0.6417
    Episode_Reward/rotating_object: 107.7553
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 1.83s
                      Time elapsed: 00:13:36
                               ETA: 00:39:01

################################################################################
                     [1m Learning iteration 388/1500 [0m                      

                       Computation: 52355 steps/s (collection: 1.783s, learning 0.095s)
             Mean action noise std: 1.69
          Mean value_function loss: 91.9627
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 34.7867
                       Mean reward: 548.67
               Mean episode length: 244.19
    Episode_Reward/reaching_object: 0.6476
    Episode_Reward/rotating_object: 107.5524
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 1.88s
                      Time elapsed: 00:13:38
                               ETA: 00:38:58

################################################################################
                     [1m Learning iteration 389/1500 [0m                      

                       Computation: 54050 steps/s (collection: 1.724s, learning 0.095s)
             Mean action noise std: 1.69
          Mean value_function loss: 93.2314
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 34.7923
                       Mean reward: 567.21
               Mean episode length: 244.42
    Episode_Reward/reaching_object: 0.6564
    Episode_Reward/rotating_object: 111.4492
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 1.82s
                      Time elapsed: 00:13:39
                               ETA: 00:38:55

################################################################################
                     [1m Learning iteration 390/1500 [0m                      

                       Computation: 52478 steps/s (collection: 1.764s, learning 0.109s)
             Mean action noise std: 1.69
          Mean value_function loss: 87.3692
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 34.7964
                       Mean reward: 561.87
               Mean episode length: 245.01
    Episode_Reward/reaching_object: 0.6534
    Episode_Reward/rotating_object: 111.0254
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 1.87s
                      Time elapsed: 00:13:41
                               ETA: 00:38:52

################################################################################
                     [1m Learning iteration 391/1500 [0m                      

                       Computation: 52317 steps/s (collection: 1.787s, learning 0.092s)
             Mean action noise std: 1.70
          Mean value_function loss: 93.2880
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 34.7992
                       Mean reward: 582.10
               Mean episode length: 242.69
    Episode_Reward/reaching_object: 0.6524
    Episode_Reward/rotating_object: 112.4610
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 1.88s
                      Time elapsed: 00:13:43
                               ETA: 00:38:50

################################################################################
                     [1m Learning iteration 392/1500 [0m                      

                       Computation: 51796 steps/s (collection: 1.789s, learning 0.109s)
             Mean action noise std: 1.70
          Mean value_function loss: 91.3371
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 34.8015
                       Mean reward: 565.20
               Mean episode length: 244.38
    Episode_Reward/reaching_object: 0.6596
    Episode_Reward/rotating_object: 112.5196
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 1.90s
                      Time elapsed: 00:13:45
                               ETA: 00:38:47

################################################################################
                     [1m Learning iteration 393/1500 [0m                      

                       Computation: 50474 steps/s (collection: 1.789s, learning 0.158s)
             Mean action noise std: 1.70
          Mean value_function loss: 102.4752
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 34.7995
                       Mean reward: 540.26
               Mean episode length: 241.56
    Episode_Reward/reaching_object: 0.6501
    Episode_Reward/rotating_object: 111.5177
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 1.95s
                      Time elapsed: 00:13:47
                               ETA: 00:38:45

################################################################################
                     [1m Learning iteration 394/1500 [0m                      

                       Computation: 51677 steps/s (collection: 1.756s, learning 0.146s)
             Mean action noise std: 1.70
          Mean value_function loss: 91.9097
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 34.8017
                       Mean reward: 601.55
               Mean episode length: 245.20
    Episode_Reward/reaching_object: 0.6628
    Episode_Reward/rotating_object: 112.7626
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 1.90s
                      Time elapsed: 00:13:49
                               ETA: 00:38:42

################################################################################
                     [1m Learning iteration 395/1500 [0m                      

                       Computation: 52914 steps/s (collection: 1.771s, learning 0.087s)
             Mean action noise std: 1.70
          Mean value_function loss: 86.8022
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 34.8097
                       Mean reward: 540.90
               Mean episode length: 244.56
    Episode_Reward/reaching_object: 0.6751
    Episode_Reward/rotating_object: 108.7220
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 1.86s
                      Time elapsed: 00:13:51
                               ETA: 00:38:39

################################################################################
                     [1m Learning iteration 396/1500 [0m                      

                       Computation: 52350 steps/s (collection: 1.781s, learning 0.096s)
             Mean action noise std: 1.70
          Mean value_function loss: 99.9289
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 34.8187
                       Mean reward: 555.58
               Mean episode length: 238.04
    Episode_Reward/reaching_object: 0.6534
    Episode_Reward/rotating_object: 106.6531
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 1.88s
                      Time elapsed: 00:13:53
                               ETA: 00:38:36

################################################################################
                     [1m Learning iteration 397/1500 [0m                      

                       Computation: 52394 steps/s (collection: 1.785s, learning 0.091s)
             Mean action noise std: 1.70
          Mean value_function loss: 90.6972
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 34.8294
                       Mean reward: 571.34
               Mean episode length: 239.20
    Episode_Reward/reaching_object: 0.6638
    Episode_Reward/rotating_object: 115.7134
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 1.88s
                      Time elapsed: 00:13:55
                               ETA: 00:38:34

################################################################################
                     [1m Learning iteration 398/1500 [0m                      

                       Computation: 52133 steps/s (collection: 1.777s, learning 0.109s)
             Mean action noise std: 1.70
          Mean value_function loss: 93.1212
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 34.8339
                       Mean reward: 566.37
               Mean episode length: 243.58
    Episode_Reward/reaching_object: 0.6691
    Episode_Reward/rotating_object: 112.0764
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 1.89s
                      Time elapsed: 00:13:56
                               ETA: 00:38:31

################################################################################
                     [1m Learning iteration 399/1500 [0m                      

                       Computation: 52215 steps/s (collection: 1.782s, learning 0.101s)
             Mean action noise std: 1.70
          Mean value_function loss: 99.0356
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 34.8358
                       Mean reward: 568.07
               Mean episode length: 232.57
    Episode_Reward/reaching_object: 0.6637
    Episode_Reward/rotating_object: 114.1115
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 1.88s
                      Time elapsed: 00:13:58
                               ETA: 00:38:28

################################################################################
                     [1m Learning iteration 400/1500 [0m                      

                       Computation: 51286 steps/s (collection: 1.813s, learning 0.104s)
             Mean action noise std: 1.70
          Mean value_function loss: 100.9584
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 34.8394
                       Mean reward: 559.53
               Mean episode length: 237.93
    Episode_Reward/reaching_object: 0.6763
    Episode_Reward/rotating_object: 115.1893
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 1.92s
                      Time elapsed: 00:14:00
                               ETA: 00:38:26

################################################################################
                     [1m Learning iteration 401/1500 [0m                      

                       Computation: 53136 steps/s (collection: 1.750s, learning 0.100s)
             Mean action noise std: 1.70
          Mean value_function loss: 90.4772
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 34.8431
                       Mean reward: 592.89
               Mean episode length: 243.05
    Episode_Reward/reaching_object: 0.6753
    Episode_Reward/rotating_object: 116.2458
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 1.85s
                      Time elapsed: 00:14:02
                               ETA: 00:38:23

################################################################################
                     [1m Learning iteration 402/1500 [0m                      

                       Computation: 52834 steps/s (collection: 1.746s, learning 0.115s)
             Mean action noise std: 1.70
          Mean value_function loss: 97.0821
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 34.8499
                       Mean reward: 599.22
               Mean episode length: 245.86
    Episode_Reward/reaching_object: 0.6731
    Episode_Reward/rotating_object: 114.3396
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 1.86s
                      Time elapsed: 00:14:04
                               ETA: 00:38:20

################################################################################
                     [1m Learning iteration 403/1500 [0m                      

                       Computation: 53061 steps/s (collection: 1.763s, learning 0.090s)
             Mean action noise std: 1.70
          Mean value_function loss: 92.1700
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 34.8565
                       Mean reward: 574.52
               Mean episode length: 236.18
    Episode_Reward/reaching_object: 0.6797
    Episode_Reward/rotating_object: 115.5966
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 1.85s
                      Time elapsed: 00:14:06
                               ETA: 00:38:17

################################################################################
                     [1m Learning iteration 404/1500 [0m                      

                       Computation: 52380 steps/s (collection: 1.785s, learning 0.092s)
             Mean action noise std: 1.70
          Mean value_function loss: 82.7505
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 34.8653
                       Mean reward: 568.43
               Mean episode length: 240.54
    Episode_Reward/reaching_object: 0.6710
    Episode_Reward/rotating_object: 114.2596
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 1.88s
                      Time elapsed: 00:14:08
                               ETA: 00:38:15

################################################################################
                     [1m Learning iteration 405/1500 [0m                      

                       Computation: 51966 steps/s (collection: 1.795s, learning 0.097s)
             Mean action noise std: 1.70
          Mean value_function loss: 91.2010
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 34.8705
                       Mean reward: 568.60
               Mean episode length: 240.19
    Episode_Reward/reaching_object: 0.6781
    Episode_Reward/rotating_object: 113.6523
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 1.89s
                      Time elapsed: 00:14:10
                               ETA: 00:38:12

################################################################################
                     [1m Learning iteration 406/1500 [0m                      

                       Computation: 52190 steps/s (collection: 1.787s, learning 0.097s)
             Mean action noise std: 1.70
          Mean value_function loss: 98.4750
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 34.8743
                       Mean reward: 586.89
               Mean episode length: 235.58
    Episode_Reward/reaching_object: 0.6592
    Episode_Reward/rotating_object: 118.0599
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 1.88s
                      Time elapsed: 00:14:11
                               ETA: 00:38:09

################################################################################
                     [1m Learning iteration 407/1500 [0m                      

                       Computation: 51603 steps/s (collection: 1.816s, learning 0.089s)
             Mean action noise std: 1.70
          Mean value_function loss: 88.9254
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 34.8828
                       Mean reward: 566.32
               Mean episode length: 239.30
    Episode_Reward/reaching_object: 0.6570
    Episode_Reward/rotating_object: 114.3554
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 1.90s
                      Time elapsed: 00:14:13
                               ETA: 00:38:07

################################################################################
                     [1m Learning iteration 408/1500 [0m                      

                       Computation: 51846 steps/s (collection: 1.806s, learning 0.090s)
             Mean action noise std: 1.71
          Mean value_function loss: 86.5970
               Mean surrogate loss: 0.0013
                 Mean entropy loss: 34.8943
                       Mean reward: 586.29
               Mean episode length: 239.76
    Episode_Reward/reaching_object: 0.6698
    Episode_Reward/rotating_object: 117.4836
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 1.90s
                      Time elapsed: 00:14:15
                               ETA: 00:38:04

################################################################################
                     [1m Learning iteration 409/1500 [0m                      

                       Computation: 50147 steps/s (collection: 1.809s, learning 0.152s)
             Mean action noise std: 1.71
          Mean value_function loss: 87.9362
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 34.8990
                       Mean reward: 554.36
               Mean episode length: 232.71
    Episode_Reward/reaching_object: 0.6691
    Episode_Reward/rotating_object: 115.9891
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 1.96s
                      Time elapsed: 00:14:17
                               ETA: 00:38:02

################################################################################
                     [1m Learning iteration 410/1500 [0m                      

                       Computation: 49545 steps/s (collection: 1.826s, learning 0.158s)
             Mean action noise std: 1.71
          Mean value_function loss: 82.7279
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 34.9005
                       Mean reward: 567.91
               Mean episode length: 239.26
    Episode_Reward/reaching_object: 0.6606
    Episode_Reward/rotating_object: 118.1101
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 1.98s
                      Time elapsed: 00:14:19
                               ETA: 00:37:59

################################################################################
                     [1m Learning iteration 411/1500 [0m                      

                       Computation: 51798 steps/s (collection: 1.781s, learning 0.117s)
             Mean action noise std: 1.71
          Mean value_function loss: 87.7557
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 34.9032
                       Mean reward: 586.56
               Mean episode length: 242.23
    Episode_Reward/reaching_object: 0.6577
    Episode_Reward/rotating_object: 114.5727
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 1.90s
                      Time elapsed: 00:14:21
                               ETA: 00:37:57

################################################################################
                     [1m Learning iteration 412/1500 [0m                      

                       Computation: 51991 steps/s (collection: 1.798s, learning 0.093s)
             Mean action noise std: 1.71
          Mean value_function loss: 84.0272
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 34.9077
                       Mean reward: 607.73
               Mean episode length: 240.61
    Episode_Reward/reaching_object: 0.6536
    Episode_Reward/rotating_object: 117.4309
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 1.89s
                      Time elapsed: 00:14:23
                               ETA: 00:37:54

################################################################################
                     [1m Learning iteration 413/1500 [0m                      

                       Computation: 51830 steps/s (collection: 1.801s, learning 0.096s)
             Mean action noise std: 1.71
          Mean value_function loss: 81.2757
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 34.9161
                       Mean reward: 590.28
               Mean episode length: 240.02
    Episode_Reward/reaching_object: 0.6580
    Episode_Reward/rotating_object: 119.8214
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 1.90s
                      Time elapsed: 00:14:25
                               ETA: 00:37:52

################################################################################
                     [1m Learning iteration 414/1500 [0m                      

                       Computation: 52579 steps/s (collection: 1.773s, learning 0.097s)
             Mean action noise std: 1.71
          Mean value_function loss: 76.4636
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 34.9240
                       Mean reward: 607.82
               Mean episode length: 245.09
    Episode_Reward/reaching_object: 0.6658
    Episode_Reward/rotating_object: 116.0355
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 1.87s
                      Time elapsed: 00:14:27
                               ETA: 00:37:49

################################################################################
                     [1m Learning iteration 415/1500 [0m                      

                       Computation: 51609 steps/s (collection: 1.792s, learning 0.113s)
             Mean action noise std: 1.71
          Mean value_function loss: 79.5775
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 34.9324
                       Mean reward: 615.61
               Mean episode length: 246.40
    Episode_Reward/reaching_object: 0.6594
    Episode_Reward/rotating_object: 118.6713
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 1.90s
                      Time elapsed: 00:14:29
                               ETA: 00:37:46

################################################################################
                     [1m Learning iteration 416/1500 [0m                      

                       Computation: 52805 steps/s (collection: 1.767s, learning 0.095s)
             Mean action noise std: 1.71
          Mean value_function loss: 81.2892
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 34.9380
                       Mean reward: 610.41
               Mean episode length: 243.93
    Episode_Reward/reaching_object: 0.6533
    Episode_Reward/rotating_object: 117.1677
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 1.86s
                      Time elapsed: 00:14:30
                               ETA: 00:37:44

################################################################################
                     [1m Learning iteration 417/1500 [0m                      

                       Computation: 51998 steps/s (collection: 1.794s, learning 0.097s)
             Mean action noise std: 1.71
          Mean value_function loss: 80.8017
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 34.9434
                       Mean reward: 614.81
               Mean episode length: 244.11
    Episode_Reward/reaching_object: 0.6607
    Episode_Reward/rotating_object: 117.8484
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 1.89s
                      Time elapsed: 00:14:32
                               ETA: 00:37:41

################################################################################
                     [1m Learning iteration 418/1500 [0m                      

                       Computation: 50909 steps/s (collection: 1.805s, learning 0.126s)
             Mean action noise std: 1.71
          Mean value_function loss: 79.8171
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 34.9463
                       Mean reward: 619.34
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.6591
    Episode_Reward/rotating_object: 121.6372
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 1.93s
                      Time elapsed: 00:14:34
                               ETA: 00:37:39

################################################################################
                     [1m Learning iteration 419/1500 [0m                      

                       Computation: 51150 steps/s (collection: 1.777s, learning 0.145s)
             Mean action noise std: 1.71
          Mean value_function loss: 88.5099
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 34.9471
                       Mean reward: 602.90
               Mean episode length: 235.08
    Episode_Reward/reaching_object: 0.6495
    Episode_Reward/rotating_object: 117.1347
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 1.92s
                      Time elapsed: 00:14:36
                               ETA: 00:37:36

################################################################################
                     [1m Learning iteration 420/1500 [0m                      

                       Computation: 50839 steps/s (collection: 1.838s, learning 0.095s)
             Mean action noise std: 1.71
          Mean value_function loss: 89.2522
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 34.9507
                       Mean reward: 602.03
               Mean episode length: 239.02
    Episode_Reward/reaching_object: 0.6525
    Episode_Reward/rotating_object: 123.2752
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 1.93s
                      Time elapsed: 00:14:38
                               ETA: 00:37:34

################################################################################
                     [1m Learning iteration 421/1500 [0m                      

                       Computation: 53302 steps/s (collection: 1.741s, learning 0.103s)
             Mean action noise std: 1.71
          Mean value_function loss: 84.6152
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 34.9562
                       Mean reward: 615.67
               Mean episode length: 242.10
    Episode_Reward/reaching_object: 0.6615
    Episode_Reward/rotating_object: 118.6884
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 1.84s
                      Time elapsed: 00:14:40
                               ETA: 00:37:31

################################################################################
                     [1m Learning iteration 422/1500 [0m                      

                       Computation: 51526 steps/s (collection: 1.807s, learning 0.101s)
             Mean action noise std: 1.71
          Mean value_function loss: 92.2333
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 34.9597
                       Mean reward: 595.81
               Mean episode length: 240.47
    Episode_Reward/reaching_object: 0.6588
    Episode_Reward/rotating_object: 115.3156
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 1.91s
                      Time elapsed: 00:14:42
                               ETA: 00:37:28

################################################################################
                     [1m Learning iteration 423/1500 [0m                      

                       Computation: 52629 steps/s (collection: 1.759s, learning 0.109s)
             Mean action noise std: 1.71
          Mean value_function loss: 81.5662
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 34.9635
                       Mean reward: 578.59
               Mean episode length: 236.03
    Episode_Reward/reaching_object: 0.6587
    Episode_Reward/rotating_object: 114.7730
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 1.87s
                      Time elapsed: 00:14:44
                               ETA: 00:37:26

################################################################################
                     [1m Learning iteration 424/1500 [0m                      

                       Computation: 51606 steps/s (collection: 1.788s, learning 0.117s)
             Mean action noise std: 1.72
          Mean value_function loss: 82.4621
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 34.9701
                       Mean reward: 612.12
               Mean episode length: 242.00
    Episode_Reward/reaching_object: 0.6618
    Episode_Reward/rotating_object: 119.5224
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 1.90s
                      Time elapsed: 00:14:46
                               ETA: 00:37:23

################################################################################
                     [1m Learning iteration 425/1500 [0m                      

                       Computation: 52598 steps/s (collection: 1.781s, learning 0.088s)
             Mean action noise std: 1.72
          Mean value_function loss: 76.9093
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 34.9788
                       Mean reward: 630.11
               Mean episode length: 241.92
    Episode_Reward/reaching_object: 0.6656
    Episode_Reward/rotating_object: 121.6173
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 1.87s
                      Time elapsed: 00:14:48
                               ETA: 00:37:21

################################################################################
                     [1m Learning iteration 426/1500 [0m                      

                       Computation: 52069 steps/s (collection: 1.788s, learning 0.100s)
             Mean action noise std: 1.72
          Mean value_function loss: 77.1692
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 34.9905
                       Mean reward: 581.71
               Mean episode length: 235.16
    Episode_Reward/reaching_object: 0.6629
    Episode_Reward/rotating_object: 117.7541
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 1.89s
                      Time elapsed: 00:14:49
                               ETA: 00:37:18

################################################################################
                     [1m Learning iteration 427/1500 [0m                      

                       Computation: 53956 steps/s (collection: 1.732s, learning 0.090s)
             Mean action noise std: 1.72
          Mean value_function loss: 80.3319
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 35.0004
                       Mean reward: 621.35
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 0.6746
    Episode_Reward/rotating_object: 120.6039
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 1.82s
                      Time elapsed: 00:14:51
                               ETA: 00:37:15

################################################################################
                     [1m Learning iteration 428/1500 [0m                      

                       Computation: 48041 steps/s (collection: 1.915s, learning 0.131s)
             Mean action noise std: 1.72
          Mean value_function loss: 78.8811
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 35.0063
                       Mean reward: 635.25
               Mean episode length: 245.36
    Episode_Reward/reaching_object: 0.6768
    Episode_Reward/rotating_object: 123.6441
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 2.05s
                      Time elapsed: 00:14:53
                               ETA: 00:37:13

################################################################################
                     [1m Learning iteration 429/1500 [0m                      

                       Computation: 52411 steps/s (collection: 1.761s, learning 0.114s)
             Mean action noise std: 1.72
          Mean value_function loss: 75.1183
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 35.0078
                       Mean reward: 628.78
               Mean episode length: 242.50
    Episode_Reward/reaching_object: 0.6663
    Episode_Reward/rotating_object: 124.7617
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 1.88s
                      Time elapsed: 00:14:55
                               ETA: 00:37:10

################################################################################
                     [1m Learning iteration 430/1500 [0m                      

                       Computation: 52203 steps/s (collection: 1.794s, learning 0.089s)
             Mean action noise std: 1.72
          Mean value_function loss: 79.6790
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 35.0115
                       Mean reward: 622.10
               Mean episode length: 242.77
    Episode_Reward/reaching_object: 0.6617
    Episode_Reward/rotating_object: 122.9395
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 1.88s
                      Time elapsed: 00:14:57
                               ETA: 00:37:08

################################################################################
                     [1m Learning iteration 431/1500 [0m                      

                       Computation: 53063 steps/s (collection: 1.753s, learning 0.100s)
             Mean action noise std: 1.72
          Mean value_function loss: 84.4550
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 35.0154
                       Mean reward: 648.82
               Mean episode length: 242.55
    Episode_Reward/reaching_object: 0.6591
    Episode_Reward/rotating_object: 123.2878
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 1.85s
                      Time elapsed: 00:14:59
                               ETA: 00:37:05

################################################################################
                     [1m Learning iteration 432/1500 [0m                      

                       Computation: 51638 steps/s (collection: 1.803s, learning 0.101s)
             Mean action noise std: 1.72
          Mean value_function loss: 76.9346
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 35.0229
                       Mean reward: 632.36
               Mean episode length: 244.72
    Episode_Reward/reaching_object: 0.6684
    Episode_Reward/rotating_object: 123.5653
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 1.90s
                      Time elapsed: 00:15:01
                               ETA: 00:37:03

################################################################################
                     [1m Learning iteration 433/1500 [0m                      

                       Computation: 53370 steps/s (collection: 1.740s, learning 0.102s)
             Mean action noise std: 1.72
          Mean value_function loss: 78.2371
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 35.0284
                       Mean reward: 610.12
               Mean episode length: 239.75
    Episode_Reward/reaching_object: 0.6584
    Episode_Reward/rotating_object: 122.3940
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 1.84s
                      Time elapsed: 00:15:03
                               ETA: 00:37:00

################################################################################
                     [1m Learning iteration 434/1500 [0m                      

                       Computation: 53195 steps/s (collection: 1.756s, learning 0.092s)
             Mean action noise std: 1.72
          Mean value_function loss: 72.8492
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 35.0341
                       Mean reward: 627.98
               Mean episode length: 246.96
    Episode_Reward/reaching_object: 0.6679
    Episode_Reward/rotating_object: 123.6392
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 1.85s
                      Time elapsed: 00:15:05
                               ETA: 00:36:57

################################################################################
                     [1m Learning iteration 435/1500 [0m                      

                       Computation: 52499 steps/s (collection: 1.782s, learning 0.090s)
             Mean action noise std: 1.72
          Mean value_function loss: 72.6500
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 35.0429
                       Mean reward: 607.77
               Mean episode length: 242.44
    Episode_Reward/reaching_object: 0.6684
    Episode_Reward/rotating_object: 124.7366
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 1.87s
                      Time elapsed: 00:15:06
                               ETA: 00:36:55

################################################################################
                     [1m Learning iteration 436/1500 [0m                      

                       Computation: 51493 steps/s (collection: 1.761s, learning 0.148s)
             Mean action noise std: 1.72
          Mean value_function loss: 78.7029
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 35.0478
                       Mean reward: 619.68
               Mean episode length: 245.76
    Episode_Reward/reaching_object: 0.6728
    Episode_Reward/rotating_object: 122.0950
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 1.91s
                      Time elapsed: 00:15:08
                               ETA: 00:36:52

################################################################################
                     [1m Learning iteration 437/1500 [0m                      

                       Computation: 51883 steps/s (collection: 1.758s, learning 0.137s)
             Mean action noise std: 1.73
          Mean value_function loss: 77.1107
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 35.0524
                       Mean reward: 630.68
               Mean episode length: 244.56
    Episode_Reward/reaching_object: 0.6771
    Episode_Reward/rotating_object: 128.6053
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 1.89s
                      Time elapsed: 00:15:10
                               ETA: 00:36:50

################################################################################
                     [1m Learning iteration 438/1500 [0m                      

                       Computation: 52773 steps/s (collection: 1.774s, learning 0.089s)
             Mean action noise std: 1.73
          Mean value_function loss: 76.5212
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 35.0604
                       Mean reward: 642.96
               Mean episode length: 244.72
    Episode_Reward/reaching_object: 0.6742
    Episode_Reward/rotating_object: 127.7572
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 1.86s
                      Time elapsed: 00:15:12
                               ETA: 00:36:47

################################################################################
                     [1m Learning iteration 439/1500 [0m                      

                       Computation: 52803 steps/s (collection: 1.759s, learning 0.102s)
             Mean action noise std: 1.73
          Mean value_function loss: 73.6711
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 35.0639
                       Mean reward: 627.03
               Mean episode length: 245.75
    Episode_Reward/reaching_object: 0.6768
    Episode_Reward/rotating_object: 125.6986
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 1.86s
                      Time elapsed: 00:15:14
                               ETA: 00:36:45

################################################################################
                     [1m Learning iteration 440/1500 [0m                      

                       Computation: 52984 steps/s (collection: 1.767s, learning 0.089s)
             Mean action noise std: 1.73
          Mean value_function loss: 70.8234
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 35.0691
                       Mean reward: 642.05
               Mean episode length: 247.69
    Episode_Reward/reaching_object: 0.6836
    Episode_Reward/rotating_object: 126.2958
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 1.86s
                      Time elapsed: 00:15:16
                               ETA: 00:36:42

################################################################################
                     [1m Learning iteration 441/1500 [0m                      

                       Computation: 51552 steps/s (collection: 1.812s, learning 0.095s)
             Mean action noise std: 1.73
          Mean value_function loss: 75.9408
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 35.0773
                       Mean reward: 662.10
               Mean episode length: 244.20
    Episode_Reward/reaching_object: 0.6661
    Episode_Reward/rotating_object: 127.2233
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 1.91s
                      Time elapsed: 00:15:18
                               ETA: 00:36:39

################################################################################
                     [1m Learning iteration 442/1500 [0m                      

                       Computation: 53247 steps/s (collection: 1.756s, learning 0.091s)
             Mean action noise std: 1.73
          Mean value_function loss: 69.1494
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 35.0837
                       Mean reward: 646.31
               Mean episode length: 247.11
    Episode_Reward/reaching_object: 0.6708
    Episode_Reward/rotating_object: 126.7229
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 1.85s
                      Time elapsed: 00:15:20
                               ETA: 00:36:37

################################################################################
                     [1m Learning iteration 443/1500 [0m                      

                       Computation: 52643 steps/s (collection: 1.777s, learning 0.090s)
             Mean action noise std: 1.73
          Mean value_function loss: 78.0624
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 35.0922
                       Mean reward: 617.00
               Mean episode length: 240.73
    Episode_Reward/reaching_object: 0.6656
    Episode_Reward/rotating_object: 126.0179
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 1.87s
                      Time elapsed: 00:15:21
                               ETA: 00:36:34

################################################################################
                     [1m Learning iteration 444/1500 [0m                      

                       Computation: 52142 steps/s (collection: 1.741s, learning 0.144s)
             Mean action noise std: 1.73
          Mean value_function loss: 72.9971
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 35.1048
                       Mean reward: 645.64
               Mean episode length: 244.21
    Episode_Reward/reaching_object: 0.6730
    Episode_Reward/rotating_object: 129.2760
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 1.89s
                      Time elapsed: 00:15:23
                               ETA: 00:36:32

################################################################################
                     [1m Learning iteration 445/1500 [0m                      

                       Computation: 52574 steps/s (collection: 1.758s, learning 0.111s)
             Mean action noise std: 1.73
          Mean value_function loss: 69.9229
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 35.1100
                       Mean reward: 657.09
               Mean episode length: 240.29
    Episode_Reward/reaching_object: 0.6639
    Episode_Reward/rotating_object: 126.5995
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 1.87s
                      Time elapsed: 00:15:25
                               ETA: 00:36:29

################################################################################
                     [1m Learning iteration 446/1500 [0m                      

                       Computation: 52817 steps/s (collection: 1.772s, learning 0.090s)
             Mean action noise std: 1.73
          Mean value_function loss: 72.1050
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 35.1143
                       Mean reward: 640.18
               Mean episode length: 244.29
    Episode_Reward/reaching_object: 0.6698
    Episode_Reward/rotating_object: 127.9457
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 1.86s
                      Time elapsed: 00:15:27
                               ETA: 00:36:27

################################################################################
                     [1m Learning iteration 447/1500 [0m                      

                       Computation: 53474 steps/s (collection: 1.734s, learning 0.105s)
             Mean action noise std: 1.73
          Mean value_function loss: 72.6785
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 35.1173
                       Mean reward: 686.72
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 0.6524
    Episode_Reward/rotating_object: 129.9241
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 1.84s
                      Time elapsed: 00:15:29
                               ETA: 00:36:24

################################################################################
                     [1m Learning iteration 448/1500 [0m                      

                       Computation: 53170 steps/s (collection: 1.752s, learning 0.097s)
             Mean action noise std: 1.73
          Mean value_function loss: 82.0683
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 35.1164
                       Mean reward: 649.10
               Mean episode length: 248.06
    Episode_Reward/reaching_object: 0.6520
    Episode_Reward/rotating_object: 128.3887
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 1.85s
                      Time elapsed: 00:15:31
                               ETA: 00:36:21

################################################################################
                     [1m Learning iteration 449/1500 [0m                      

                       Computation: 53243 steps/s (collection: 1.757s, learning 0.090s)
             Mean action noise std: 1.73
          Mean value_function loss: 75.0183
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 35.1193
                       Mean reward: 628.39
               Mean episode length: 240.74
    Episode_Reward/reaching_object: 0.6461
    Episode_Reward/rotating_object: 126.6562
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 1.85s
                      Time elapsed: 00:15:33
                               ETA: 00:36:19

################################################################################
                     [1m Learning iteration 450/1500 [0m                      

                       Computation: 52971 steps/s (collection: 1.746s, learning 0.110s)
             Mean action noise std: 1.74
          Mean value_function loss: 72.5070
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 35.1328
                       Mean reward: 633.40
               Mean episode length: 236.78
    Episode_Reward/reaching_object: 0.6461
    Episode_Reward/rotating_object: 126.1091
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 1.86s
                      Time elapsed: 00:15:34
                               ETA: 00:36:16

################################################################################
                     [1m Learning iteration 451/1500 [0m                      

                       Computation: 53413 steps/s (collection: 1.731s, learning 0.109s)
             Mean action noise std: 1.74
          Mean value_function loss: 76.1490
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 35.1482
                       Mean reward: 640.23
               Mean episode length: 244.65
    Episode_Reward/reaching_object: 0.6486
    Episode_Reward/rotating_object: 128.1919
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 1.84s
                      Time elapsed: 00:15:36
                               ETA: 00:36:13

################################################################################
                     [1m Learning iteration 452/1500 [0m                      

                       Computation: 51663 steps/s (collection: 1.801s, learning 0.102s)
             Mean action noise std: 1.74
          Mean value_function loss: 69.6499
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 35.1636
                       Mean reward: 660.79
               Mean episode length: 244.54
    Episode_Reward/reaching_object: 0.6402
    Episode_Reward/rotating_object: 128.7179
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 1.90s
                      Time elapsed: 00:15:38
                               ETA: 00:36:11

################################################################################
                     [1m Learning iteration 453/1500 [0m                      

                       Computation: 53232 steps/s (collection: 1.743s, learning 0.103s)
             Mean action noise std: 1.74
          Mean value_function loss: 70.2846
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 35.1739
                       Mean reward: 620.65
               Mean episode length: 236.24
    Episode_Reward/reaching_object: 0.6345
    Episode_Reward/rotating_object: 127.7684
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 1.85s
                      Time elapsed: 00:15:40
                               ETA: 00:36:08

################################################################################
                     [1m Learning iteration 454/1500 [0m                      

                       Computation: 52643 steps/s (collection: 1.760s, learning 0.108s)
             Mean action noise std: 1.74
          Mean value_function loss: 72.3914
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 35.1768
                       Mean reward: 655.63
               Mean episode length: 244.57
    Episode_Reward/reaching_object: 0.6537
    Episode_Reward/rotating_object: 130.4707
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 1.87s
                      Time elapsed: 00:15:42
                               ETA: 00:36:06

################################################################################
                     [1m Learning iteration 455/1500 [0m                      

                       Computation: 52312 steps/s (collection: 1.767s, learning 0.112s)
             Mean action noise std: 1.74
          Mean value_function loss: 69.4213
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 35.1812
                       Mean reward: 655.90
               Mean episode length: 245.91
    Episode_Reward/reaching_object: 0.6610
    Episode_Reward/rotating_object: 129.4898
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 1.88s
                      Time elapsed: 00:15:44
                               ETA: 00:36:03

################################################################################
                     [1m Learning iteration 456/1500 [0m                      

                       Computation: 52611 steps/s (collection: 1.771s, learning 0.098s)
             Mean action noise std: 1.74
          Mean value_function loss: 78.0825
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 35.1950
                       Mean reward: 679.65
               Mean episode length: 244.86
    Episode_Reward/reaching_object: 0.6539
    Episode_Reward/rotating_object: 129.3019
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 1.87s
                      Time elapsed: 00:15:46
                               ETA: 00:36:01

################################################################################
                     [1m Learning iteration 457/1500 [0m                      

                       Computation: 50294 steps/s (collection: 1.810s, learning 0.144s)
             Mean action noise std: 1.74
          Mean value_function loss: 68.5619
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 35.2059
                       Mean reward: 645.27
               Mean episode length: 244.02
    Episode_Reward/reaching_object: 0.6566
    Episode_Reward/rotating_object: 127.2983
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 1.95s
                      Time elapsed: 00:15:48
                               ETA: 00:35:59

################################################################################
                     [1m Learning iteration 458/1500 [0m                      

                       Computation: 50491 steps/s (collection: 1.791s, learning 0.156s)
             Mean action noise std: 1.74
          Mean value_function loss: 76.9745
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 35.2140
                       Mean reward: 657.54
               Mean episode length: 243.33
    Episode_Reward/reaching_object: 0.6641
    Episode_Reward/rotating_object: 131.0179
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 1.95s
                      Time elapsed: 00:15:50
                               ETA: 00:35:56

################################################################################
                     [1m Learning iteration 459/1500 [0m                      

                       Computation: 52242 steps/s (collection: 1.765s, learning 0.117s)
             Mean action noise std: 1.75
          Mean value_function loss: 72.8146
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 35.2227
                       Mean reward: 647.77
               Mean episode length: 242.97
    Episode_Reward/reaching_object: 0.6687
    Episode_Reward/rotating_object: 131.6253
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 1.88s
                      Time elapsed: 00:15:51
                               ETA: 00:35:54

################################################################################
                     [1m Learning iteration 460/1500 [0m                      

                       Computation: 53309 steps/s (collection: 1.749s, learning 0.095s)
             Mean action noise std: 1.75
          Mean value_function loss: 82.8782
               Mean surrogate loss: 0.0032
                 Mean entropy loss: 35.2303
                       Mean reward: 670.62
               Mean episode length: 245.37
    Episode_Reward/reaching_object: 0.6662
    Episode_Reward/rotating_object: 130.9005
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 1.84s
                      Time elapsed: 00:15:53
                               ETA: 00:35:51

################################################################################
                     [1m Learning iteration 461/1500 [0m                      

                       Computation: 52539 steps/s (collection: 1.777s, learning 0.094s)
             Mean action noise std: 1.75
          Mean value_function loss: 63.0287
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 35.2318
                       Mean reward: 653.89
               Mean episode length: 245.75
    Episode_Reward/reaching_object: 0.6756
    Episode_Reward/rotating_object: 132.7585
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 1.87s
                      Time elapsed: 00:15:55
                               ETA: 00:35:49

################################################################################
                     [1m Learning iteration 462/1500 [0m                      

                       Computation: 51217 steps/s (collection: 1.809s, learning 0.111s)
             Mean action noise std: 1.75
          Mean value_function loss: 68.5418
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 35.2379
                       Mean reward: 672.62
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 0.6661
    Episode_Reward/rotating_object: 133.0808
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 1.92s
                      Time elapsed: 00:15:57
                               ETA: 00:35:46

################################################################################
                     [1m Learning iteration 463/1500 [0m                      

                       Computation: 49774 steps/s (collection: 1.857s, learning 0.118s)
             Mean action noise std: 1.75
          Mean value_function loss: 65.9284
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 35.2477
                       Mean reward: 639.81
               Mean episode length: 242.37
    Episode_Reward/reaching_object: 0.6644
    Episode_Reward/rotating_object: 133.7834
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 1.97s
                      Time elapsed: 00:15:59
                               ETA: 00:35:44

################################################################################
                     [1m Learning iteration 464/1500 [0m                      

                       Computation: 52399 steps/s (collection: 1.782s, learning 0.094s)
             Mean action noise std: 1.75
          Mean value_function loss: 78.2538
               Mean surrogate loss: 0.0012
                 Mean entropy loss: 35.2525
                       Mean reward: 659.94
               Mean episode length: 242.47
    Episode_Reward/reaching_object: 0.6524
    Episode_Reward/rotating_object: 127.2535
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 1.88s
                      Time elapsed: 00:16:01
                               ETA: 00:35:41

################################################################################
                     [1m Learning iteration 465/1500 [0m                      

                       Computation: 53021 steps/s (collection: 1.754s, learning 0.100s)
             Mean action noise std: 1.75
          Mean value_function loss: 66.2338
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 35.2533
                       Mean reward: 656.04
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.6567
    Episode_Reward/rotating_object: 131.7782
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 1.85s
                      Time elapsed: 00:16:03
                               ETA: 00:35:39

################################################################################
                     [1m Learning iteration 466/1500 [0m                      

                       Computation: 51627 steps/s (collection: 1.737s, learning 0.167s)
             Mean action noise std: 1.75
          Mean value_function loss: 64.5035
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 35.2558
                       Mean reward: 662.71
               Mean episode length: 246.09
    Episode_Reward/reaching_object: 0.6576
    Episode_Reward/rotating_object: 132.2538
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 1.90s
                      Time elapsed: 00:16:05
                               ETA: 00:35:36

################################################################################
                     [1m Learning iteration 467/1500 [0m                      

                       Computation: 52999 steps/s (collection: 1.739s, learning 0.116s)
             Mean action noise std: 1.75
          Mean value_function loss: 71.8039
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 35.2587
                       Mean reward: 681.84
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 0.6584
    Episode_Reward/rotating_object: 133.8903
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 1.85s
                      Time elapsed: 00:16:06
                               ETA: 00:35:34

################################################################################
                     [1m Learning iteration 468/1500 [0m                      

                       Computation: 51995 steps/s (collection: 1.751s, learning 0.140s)
             Mean action noise std: 1.75
          Mean value_function loss: 70.5920
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 35.2664
                       Mean reward: 662.33
               Mean episode length: 243.99
    Episode_Reward/reaching_object: 0.6583
    Episode_Reward/rotating_object: 133.3843
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 1.89s
                      Time elapsed: 00:16:08
                               ETA: 00:35:31

################################################################################
                     [1m Learning iteration 469/1500 [0m                      

                       Computation: 52169 steps/s (collection: 1.782s, learning 0.102s)
             Mean action noise std: 1.75
          Mean value_function loss: 61.8045
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 35.2735
                       Mean reward: 669.38
               Mean episode length: 244.49
    Episode_Reward/reaching_object: 0.6535
    Episode_Reward/rotating_object: 133.8871
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 1.88s
                      Time elapsed: 00:16:10
                               ETA: 00:35:29

################################################################################
                     [1m Learning iteration 470/1500 [0m                      

                       Computation: 51276 steps/s (collection: 1.811s, learning 0.107s)
             Mean action noise std: 1.75
          Mean value_function loss: 60.2104
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 35.2818
                       Mean reward: 676.58
               Mean episode length: 242.50
    Episode_Reward/reaching_object: 0.6530
    Episode_Reward/rotating_object: 134.1323
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 1.92s
                      Time elapsed: 00:16:12
                               ETA: 00:35:27

################################################################################
                     [1m Learning iteration 471/1500 [0m                      

                       Computation: 51414 steps/s (collection: 1.807s, learning 0.105s)
             Mean action noise std: 1.76
          Mean value_function loss: 67.4323
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 35.2929
                       Mean reward: 687.37
               Mean episode length: 243.34
    Episode_Reward/reaching_object: 0.6444
    Episode_Reward/rotating_object: 134.9769
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 1.91s
                      Time elapsed: 00:16:14
                               ETA: 00:35:24

################################################################################
                     [1m Learning iteration 472/1500 [0m                      

                       Computation: 50685 steps/s (collection: 1.803s, learning 0.136s)
             Mean action noise std: 1.76
          Mean value_function loss: 62.6248
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 35.3049
                       Mean reward: 666.24
               Mean episode length: 247.54
    Episode_Reward/reaching_object: 0.6599
    Episode_Reward/rotating_object: 131.6978
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 1.94s
                      Time elapsed: 00:16:16
                               ETA: 00:35:22

################################################################################
                     [1m Learning iteration 473/1500 [0m                      

                       Computation: 51272 steps/s (collection: 1.822s, learning 0.095s)
             Mean action noise std: 1.76
          Mean value_function loss: 64.0284
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 35.3110
                       Mean reward: 673.18
               Mean episode length: 245.54
    Episode_Reward/reaching_object: 0.6493
    Episode_Reward/rotating_object: 135.3586
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 1.92s
                      Time elapsed: 00:16:18
                               ETA: 00:35:19

################################################################################
                     [1m Learning iteration 474/1500 [0m                      

                       Computation: 49076 steps/s (collection: 1.876s, learning 0.127s)
             Mean action noise std: 1.76
          Mean value_function loss: 59.6048
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 35.3180
                       Mean reward: 686.48
               Mean episode length: 246.44
    Episode_Reward/reaching_object: 0.6490
    Episode_Reward/rotating_object: 132.8507
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 2.00s
                      Time elapsed: 00:16:20
                               ETA: 00:35:17

################################################################################
                     [1m Learning iteration 475/1500 [0m                      

                       Computation: 50999 steps/s (collection: 1.811s, learning 0.116s)
             Mean action noise std: 1.76
          Mean value_function loss: 61.8638
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 35.3228
                       Mean reward: 677.77
               Mean episode length: 248.09
    Episode_Reward/reaching_object: 0.6603
    Episode_Reward/rotating_object: 132.1196
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 1.93s
                      Time elapsed: 00:16:22
                               ETA: 00:35:15

################################################################################
                     [1m Learning iteration 476/1500 [0m                      

                       Computation: 52038 steps/s (collection: 1.770s, learning 0.119s)
             Mean action noise std: 1.76
          Mean value_function loss: 65.6618
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 35.3279
                       Mean reward: 667.23
               Mean episode length: 245.54
    Episode_Reward/reaching_object: 0.6533
    Episode_Reward/rotating_object: 130.3311
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 1.89s
                      Time elapsed: 00:16:24
                               ETA: 00:35:12

################################################################################
                     [1m Learning iteration 477/1500 [0m                      

                       Computation: 50678 steps/s (collection: 1.825s, learning 0.115s)
             Mean action noise std: 1.76
          Mean value_function loss: 65.1028
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 35.3315
                       Mean reward: 678.37
               Mean episode length: 245.70
    Episode_Reward/reaching_object: 0.6531
    Episode_Reward/rotating_object: 132.3107
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 1.94s
                      Time elapsed: 00:16:26
                               ETA: 00:35:10

################################################################################
                     [1m Learning iteration 478/1500 [0m                      

                       Computation: 51312 steps/s (collection: 1.799s, learning 0.116s)
             Mean action noise std: 1.76
          Mean value_function loss: 64.5299
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 35.3322
                       Mean reward: 684.74
               Mean episode length: 245.25
    Episode_Reward/reaching_object: 0.6595
    Episode_Reward/rotating_object: 135.1687
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 1.92s
                      Time elapsed: 00:16:28
                               ETA: 00:35:08

################################################################################
                     [1m Learning iteration 479/1500 [0m                      

                       Computation: 51310 steps/s (collection: 1.809s, learning 0.107s)
             Mean action noise std: 1.76
          Mean value_function loss: 58.8751
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 35.3411
                       Mean reward: 694.31
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.6619
    Episode_Reward/rotating_object: 136.3282
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 1.92s
                      Time elapsed: 00:16:30
                               ETA: 00:35:05

################################################################################
                     [1m Learning iteration 480/1500 [0m                      

                       Computation: 52117 steps/s (collection: 1.790s, learning 0.096s)
             Mean action noise std: 1.76
          Mean value_function loss: 62.5304
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 35.3555
                       Mean reward: 667.25
               Mean episode length: 246.32
    Episode_Reward/reaching_object: 0.6551
    Episode_Reward/rotating_object: 135.9162
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 1.89s
                      Time elapsed: 00:16:31
                               ETA: 00:35:03

################################################################################
                     [1m Learning iteration 481/1500 [0m                      

                       Computation: 51499 steps/s (collection: 1.811s, learning 0.098s)
             Mean action noise std: 1.76
          Mean value_function loss: 60.7419
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 35.3744
                       Mean reward: 669.35
               Mean episode length: 247.26
    Episode_Reward/reaching_object: 0.6635
    Episode_Reward/rotating_object: 136.3216
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 1.91s
                      Time elapsed: 00:16:33
                               ETA: 00:35:01

################################################################################
                     [1m Learning iteration 482/1500 [0m                      

                       Computation: 50080 steps/s (collection: 1.846s, learning 0.117s)
             Mean action noise std: 1.77
          Mean value_function loss: 57.9986
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 35.3857
                       Mean reward: 682.77
               Mean episode length: 245.01
    Episode_Reward/reaching_object: 0.6643
    Episode_Reward/rotating_object: 136.8338
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 1.96s
                      Time elapsed: 00:16:35
                               ETA: 00:34:58

################################################################################
                     [1m Learning iteration 483/1500 [0m                      

                       Computation: 51224 steps/s (collection: 1.811s, learning 0.109s)
             Mean action noise std: 1.77
          Mean value_function loss: 60.2563
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 35.3929
                       Mean reward: 683.94
               Mean episode length: 248.36
    Episode_Reward/reaching_object: 0.6638
    Episode_Reward/rotating_object: 135.0885
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 1.92s
                      Time elapsed: 00:16:37
                               ETA: 00:34:56

################################################################################
                     [1m Learning iteration 484/1500 [0m                      

                       Computation: 50920 steps/s (collection: 1.810s, learning 0.120s)
             Mean action noise std: 1.77
          Mean value_function loss: 62.2230
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 35.3993
                       Mean reward: 615.68
               Mean episode length: 237.23
    Episode_Reward/reaching_object: 0.6594
    Episode_Reward/rotating_object: 133.5131
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 1.93s
                      Time elapsed: 00:16:39
                               ETA: 00:34:54

################################################################################
                     [1m Learning iteration 485/1500 [0m                      

                       Computation: 51582 steps/s (collection: 1.784s, learning 0.122s)
             Mean action noise std: 1.77
          Mean value_function loss: 62.8370
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 35.4022
                       Mean reward: 673.13
               Mean episode length: 245.14
    Episode_Reward/reaching_object: 0.6629
    Episode_Reward/rotating_object: 133.7054
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 1.91s
                      Time elapsed: 00:16:41
                               ETA: 00:34:51

################################################################################
                     [1m Learning iteration 486/1500 [0m                      

                       Computation: 51625 steps/s (collection: 1.803s, learning 0.102s)
             Mean action noise std: 1.77
          Mean value_function loss: 61.3289
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 35.4068
                       Mean reward: 668.66
               Mean episode length: 242.96
    Episode_Reward/reaching_object: 0.6602
    Episode_Reward/rotating_object: 132.4302
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 1.90s
                      Time elapsed: 00:16:43
                               ETA: 00:34:49

################################################################################
                     [1m Learning iteration 487/1500 [0m                      

                       Computation: 51454 steps/s (collection: 1.777s, learning 0.133s)
             Mean action noise std: 1.77
          Mean value_function loss: 58.3652
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 35.4242
                       Mean reward: 678.87
               Mean episode length: 246.21
    Episode_Reward/reaching_object: 0.6545
    Episode_Reward/rotating_object: 136.4516
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 1.91s
                      Time elapsed: 00:16:45
                               ETA: 00:34:46

################################################################################
                     [1m Learning iteration 488/1500 [0m                      

                       Computation: 50865 steps/s (collection: 1.825s, learning 0.108s)
             Mean action noise std: 1.77
          Mean value_function loss: 60.5797
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 35.4382
                       Mean reward: 696.41
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6548
    Episode_Reward/rotating_object: 137.7612
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 1.93s
                      Time elapsed: 00:16:47
                               ETA: 00:34:44

################################################################################
                     [1m Learning iteration 489/1500 [0m                      

                       Computation: 48419 steps/s (collection: 1.870s, learning 0.161s)
             Mean action noise std: 1.77
          Mean value_function loss: 62.7337
               Mean surrogate loss: 0.0025
                 Mean entropy loss: 35.4521
                       Mean reward: 693.12
               Mean episode length: 247.37
    Episode_Reward/reaching_object: 0.6466
    Episode_Reward/rotating_object: 134.7949
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 2.03s
                      Time elapsed: 00:16:49
                               ETA: 00:34:42

################################################################################
                     [1m Learning iteration 490/1500 [0m                      

                       Computation: 51154 steps/s (collection: 1.804s, learning 0.118s)
             Mean action noise std: 1.77
          Mean value_function loss: 61.9449
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 35.4544
                       Mean reward: 652.29
               Mean episode length: 239.65
    Episode_Reward/reaching_object: 0.6355
    Episode_Reward/rotating_object: 136.2808
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 1.92s
                      Time elapsed: 00:16:51
                               ETA: 00:34:40

################################################################################
                     [1m Learning iteration 491/1500 [0m                      

                       Computation: 50774 steps/s (collection: 1.778s, learning 0.158s)
             Mean action noise std: 1.78
          Mean value_function loss: 57.5582
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 35.4606
                       Mean reward: 705.11
               Mean episode length: 248.78
    Episode_Reward/reaching_object: 0.6525
    Episode_Reward/rotating_object: 136.9363
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 1.94s
                      Time elapsed: 00:16:53
                               ETA: 00:34:37

################################################################################
                     [1m Learning iteration 492/1500 [0m                      

                       Computation: 52113 steps/s (collection: 1.790s, learning 0.096s)
             Mean action noise std: 1.78
          Mean value_function loss: 58.9353
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 35.4723
                       Mean reward: 694.67
               Mean episode length: 244.53
    Episode_Reward/reaching_object: 0.6503
    Episode_Reward/rotating_object: 139.2661
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 1.89s
                      Time elapsed: 00:16:55
                               ETA: 00:34:35

################################################################################
                     [1m Learning iteration 493/1500 [0m                      

                       Computation: 50857 steps/s (collection: 1.820s, learning 0.113s)
             Mean action noise std: 1.78
          Mean value_function loss: 61.1686
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 35.4826
                       Mean reward: 671.78
               Mean episode length: 239.11
    Episode_Reward/reaching_object: 0.6429
    Episode_Reward/rotating_object: 132.3817
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 1.93s
                      Time elapsed: 00:16:57
                               ETA: 00:34:33

################################################################################
                     [1m Learning iteration 494/1500 [0m                      

                       Computation: 51631 steps/s (collection: 1.806s, learning 0.098s)
             Mean action noise std: 1.78
          Mean value_function loss: 56.8077
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 35.4949
                       Mean reward: 682.15
               Mean episode length: 244.79
    Episode_Reward/reaching_object: 0.6425
    Episode_Reward/rotating_object: 135.4296
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 1.90s
                      Time elapsed: 00:16:58
                               ETA: 00:34:30

################################################################################
                     [1m Learning iteration 495/1500 [0m                      

                       Computation: 51180 steps/s (collection: 1.815s, learning 0.106s)
             Mean action noise std: 1.78
          Mean value_function loss: 60.4466
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 35.5007
                       Mean reward: 693.55
               Mean episode length: 246.02
    Episode_Reward/reaching_object: 0.6501
    Episode_Reward/rotating_object: 137.7409
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 1.92s
                      Time elapsed: 00:17:00
                               ETA: 00:34:28

################################################################################
                     [1m Learning iteration 496/1500 [0m                      

                       Computation: 52191 steps/s (collection: 1.788s, learning 0.095s)
             Mean action noise std: 1.78
          Mean value_function loss: 57.0703
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 35.5110
                       Mean reward: 674.33
               Mean episode length: 241.87
    Episode_Reward/reaching_object: 0.6451
    Episode_Reward/rotating_object: 135.4554
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 1.88s
                      Time elapsed: 00:17:02
                               ETA: 00:34:26

################################################################################
                     [1m Learning iteration 497/1500 [0m                      

                       Computation: 51286 steps/s (collection: 1.816s, learning 0.101s)
             Mean action noise std: 1.78
          Mean value_function loss: 62.5049
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 35.5281
                       Mean reward: 686.67
               Mean episode length: 246.09
    Episode_Reward/reaching_object: 0.6526
    Episode_Reward/rotating_object: 138.4819
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 1.92s
                      Time elapsed: 00:17:04
                               ETA: 00:34:23

################################################################################
                     [1m Learning iteration 498/1500 [0m                      

                       Computation: 51639 steps/s (collection: 1.800s, learning 0.104s)
             Mean action noise std: 1.79
          Mean value_function loss: 54.7860
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 35.5430
                       Mean reward: 706.56
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 0.6498
    Episode_Reward/rotating_object: 138.6393
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 1.90s
                      Time elapsed: 00:17:06
                               ETA: 00:34:21

################################################################################
                     [1m Learning iteration 499/1500 [0m                      

                       Computation: 50278 steps/s (collection: 1.861s, learning 0.095s)
             Mean action noise std: 1.79
          Mean value_function loss: 55.3461
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 35.5501
                       Mean reward: 706.69
               Mean episode length: 245.23
    Episode_Reward/reaching_object: 0.6478
    Episode_Reward/rotating_object: 135.7537
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 1.96s
                      Time elapsed: 00:17:08
                               ETA: 00:34:19

################################################################################
                     [1m Learning iteration 500/1500 [0m                      

                       Computation: 50549 steps/s (collection: 1.788s, learning 0.157s)
             Mean action noise std: 1.79
          Mean value_function loss: 51.5511
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 35.5569
                       Mean reward: 678.27
               Mean episode length: 244.47
    Episode_Reward/reaching_object: 0.6495
    Episode_Reward/rotating_object: 137.9392
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 1.94s
                      Time elapsed: 00:17:10
                               ETA: 00:34:16

################################################################################
                     [1m Learning iteration 501/1500 [0m                      

                       Computation: 49976 steps/s (collection: 1.779s, learning 0.188s)
             Mean action noise std: 1.79
          Mean value_function loss: 58.2638
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 35.5603
                       Mean reward: 720.30
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 0.6534
    Episode_Reward/rotating_object: 139.6056
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 1.97s
                      Time elapsed: 00:17:12
                               ETA: 00:34:14

################################################################################
                     [1m Learning iteration 502/1500 [0m                      

                       Computation: 51832 steps/s (collection: 1.769s, learning 0.128s)
             Mean action noise std: 1.79
          Mean value_function loss: 51.6854
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 35.5698
                       Mean reward: 703.14
               Mean episode length: 243.92
    Episode_Reward/reaching_object: 0.6503
    Episode_Reward/rotating_object: 140.6772
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 1.90s
                      Time elapsed: 00:17:14
                               ETA: 00:34:12

################################################################################
                     [1m Learning iteration 503/1500 [0m                      

                       Computation: 50982 steps/s (collection: 1.807s, learning 0.121s)
             Mean action noise std: 1.79
          Mean value_function loss: 59.2879
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 35.5870
                       Mean reward: 674.87
               Mean episode length: 239.62
    Episode_Reward/reaching_object: 0.6501
    Episode_Reward/rotating_object: 137.3307
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 1.93s
                      Time elapsed: 00:17:16
                               ETA: 00:34:09

################################################################################
                     [1m Learning iteration 504/1500 [0m                      

                       Computation: 50699 steps/s (collection: 1.832s, learning 0.107s)
             Mean action noise std: 1.79
          Mean value_function loss: 50.9766
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 35.6005
                       Mean reward: 725.73
               Mean episode length: 246.97
    Episode_Reward/reaching_object: 0.6538
    Episode_Reward/rotating_object: 141.0298
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 1.94s
                      Time elapsed: 00:17:18
                               ETA: 00:34:07

################################################################################
                     [1m Learning iteration 505/1500 [0m                      

                       Computation: 49067 steps/s (collection: 1.860s, learning 0.144s)
             Mean action noise std: 1.80
          Mean value_function loss: 50.6647
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 35.6113
                       Mean reward: 725.42
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 0.6611
    Episode_Reward/rotating_object: 141.6264
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 2.00s
                      Time elapsed: 00:17:20
                               ETA: 00:34:05

################################################################################
                     [1m Learning iteration 506/1500 [0m                      

                       Computation: 49151 steps/s (collection: 1.903s, learning 0.097s)
             Mean action noise std: 1.80
          Mean value_function loss: 44.9409
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 35.6117
                       Mean reward: 693.58
               Mean episode length: 242.32
    Episode_Reward/reaching_object: 0.6602
    Episode_Reward/rotating_object: 142.2394
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 2.00s
                      Time elapsed: 00:17:22
                               ETA: 00:34:03

################################################################################
                     [1m Learning iteration 507/1500 [0m                      

                       Computation: 50612 steps/s (collection: 1.827s, learning 0.115s)
             Mean action noise std: 1.80
          Mean value_function loss: 51.3611
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 35.6131
                       Mean reward: 728.74
               Mean episode length: 246.74
    Episode_Reward/reaching_object: 0.6657
    Episode_Reward/rotating_object: 142.1476
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 1.94s
                      Time elapsed: 00:17:24
                               ETA: 00:34:00

################################################################################
                     [1m Learning iteration 508/1500 [0m                      

                       Computation: 51113 steps/s (collection: 1.805s, learning 0.119s)
             Mean action noise std: 1.80
          Mean value_function loss: 53.6637
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 35.6209
                       Mean reward: 684.49
               Mean episode length: 239.64
    Episode_Reward/reaching_object: 0.6602
    Episode_Reward/rotating_object: 140.4533
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 1.92s
                      Time elapsed: 00:17:26
                               ETA: 00:33:58

################################################################################
                     [1m Learning iteration 509/1500 [0m                      

                       Computation: 50799 steps/s (collection: 1.836s, learning 0.099s)
             Mean action noise std: 1.80
          Mean value_function loss: 53.5304
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 35.6259
                       Mean reward: 713.23
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 0.6569
    Episode_Reward/rotating_object: 140.8461
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 1.94s
                      Time elapsed: 00:17:27
                               ETA: 00:33:56

################################################################################
                     [1m Learning iteration 510/1500 [0m                      

                       Computation: 51241 steps/s (collection: 1.798s, learning 0.121s)
             Mean action noise std: 1.80
          Mean value_function loss: 56.1546
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 35.6310
                       Mean reward: 691.85
               Mean episode length: 243.01
    Episode_Reward/reaching_object: 0.6703
    Episode_Reward/rotating_object: 142.8898
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 1.92s
                      Time elapsed: 00:17:29
                               ETA: 00:33:54

################################################################################
                     [1m Learning iteration 511/1500 [0m                      

                       Computation: 51115 steps/s (collection: 1.822s, learning 0.102s)
             Mean action noise std: 1.80
          Mean value_function loss: 53.8789
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 35.6451
                       Mean reward: 719.30
               Mean episode length: 244.83
    Episode_Reward/reaching_object: 0.6658
    Episode_Reward/rotating_object: 141.3930
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 1.92s
                      Time elapsed: 00:17:31
                               ETA: 00:33:51

################################################################################
                     [1m Learning iteration 512/1500 [0m                      

                       Computation: 51957 steps/s (collection: 1.775s, learning 0.117s)
             Mean action noise std: 1.80
          Mean value_function loss: 53.2372
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 35.6560
                       Mean reward: 730.51
               Mean episode length: 249.23
    Episode_Reward/reaching_object: 0.6671
    Episode_Reward/rotating_object: 143.0678
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 1.89s
                      Time elapsed: 00:17:33
                               ETA: 00:33:49

################################################################################
                     [1m Learning iteration 513/1500 [0m                      

                       Computation: 50008 steps/s (collection: 1.854s, learning 0.112s)
             Mean action noise std: 1.80
          Mean value_function loss: 50.4609
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 35.6680
                       Mean reward: 709.01
               Mean episode length: 241.49
    Episode_Reward/reaching_object: 0.6561
    Episode_Reward/rotating_object: 143.1612
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 1.97s
                      Time elapsed: 00:17:35
                               ETA: 00:33:47

################################################################################
                     [1m Learning iteration 514/1500 [0m                      

                       Computation: 53150 steps/s (collection: 1.752s, learning 0.097s)
             Mean action noise std: 1.80
          Mean value_function loss: 52.2754
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 35.6737
                       Mean reward: 708.22
               Mean episode length: 243.39
    Episode_Reward/reaching_object: 0.6472
    Episode_Reward/rotating_object: 142.3316
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 1.85s
                      Time elapsed: 00:17:37
                               ETA: 00:33:44

################################################################################
                     [1m Learning iteration 515/1500 [0m                      

                       Computation: 51622 steps/s (collection: 1.794s, learning 0.110s)
             Mean action noise std: 1.81
          Mean value_function loss: 45.3123
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 35.6777
                       Mean reward: 700.13
               Mean episode length: 244.45
    Episode_Reward/reaching_object: 0.6617
    Episode_Reward/rotating_object: 141.7574
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 1.90s
                      Time elapsed: 00:17:39
                               ETA: 00:33:42

################################################################################
                     [1m Learning iteration 516/1500 [0m                      

                       Computation: 51157 steps/s (collection: 1.804s, learning 0.117s)
             Mean action noise std: 1.81
          Mean value_function loss: 47.5497
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 35.6814
                       Mean reward: 695.67
               Mean episode length: 242.93
    Episode_Reward/reaching_object: 0.6606
    Episode_Reward/rotating_object: 143.9786
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 1.92s
                      Time elapsed: 00:17:41
                               ETA: 00:33:40

################################################################################
                     [1m Learning iteration 517/1500 [0m                      

                       Computation: 52289 steps/s (collection: 1.776s, learning 0.104s)
             Mean action noise std: 1.81
          Mean value_function loss: 49.9207
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 35.6827
                       Mean reward: 724.58
               Mean episode length: 248.42
    Episode_Reward/reaching_object: 0.6570
    Episode_Reward/rotating_object: 143.4943
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 1.88s
                      Time elapsed: 00:17:43
                               ETA: 00:33:37

################################################################################
                     [1m Learning iteration 518/1500 [0m                      

                       Computation: 51613 steps/s (collection: 1.807s, learning 0.098s)
             Mean action noise std: 1.81
          Mean value_function loss: 47.4358
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 35.6858
                       Mean reward: 703.72
               Mean episode length: 246.32
    Episode_Reward/reaching_object: 0.6537
    Episode_Reward/rotating_object: 139.8731
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 1.90s
                      Time elapsed: 00:17:45
                               ETA: 00:33:35

################################################################################
                     [1m Learning iteration 519/1500 [0m                      

                       Computation: 51184 steps/s (collection: 1.816s, learning 0.105s)
             Mean action noise std: 1.81
          Mean value_function loss: 45.8830
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 35.6975
                       Mean reward: 701.80
               Mean episode length: 245.37
    Episode_Reward/reaching_object: 0.6571
    Episode_Reward/rotating_object: 143.1504
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 1.92s
                      Time elapsed: 00:17:47
                               ETA: 00:33:33

################################################################################
                     [1m Learning iteration 520/1500 [0m                      

                       Computation: 50569 steps/s (collection: 1.839s, learning 0.105s)
             Mean action noise std: 1.81
          Mean value_function loss: 48.3782
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 35.7096
                       Mean reward: 706.09
               Mean episode length: 243.45
    Episode_Reward/reaching_object: 0.6570
    Episode_Reward/rotating_object: 143.0855
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 1.94s
                      Time elapsed: 00:17:48
                               ETA: 00:33:30

################################################################################
                     [1m Learning iteration 521/1500 [0m                      

                       Computation: 51430 steps/s (collection: 1.814s, learning 0.098s)
             Mean action noise std: 1.81
          Mean value_function loss: 49.1556
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 35.7159
                       Mean reward: 729.73
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6607
    Episode_Reward/rotating_object: 144.2842
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 1.91s
                      Time elapsed: 00:17:50
                               ETA: 00:33:28

################################################################################
                     [1m Learning iteration 522/1500 [0m                      

                       Computation: 52083 steps/s (collection: 1.792s, learning 0.095s)
             Mean action noise std: 1.81
          Mean value_function loss: 45.9914
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 35.7260
                       Mean reward: 724.97
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.6580
    Episode_Reward/rotating_object: 144.5889
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 1.89s
                      Time elapsed: 00:17:52
                               ETA: 00:33:26

################################################################################
                     [1m Learning iteration 523/1500 [0m                      

                       Computation: 51568 steps/s (collection: 1.806s, learning 0.101s)
             Mean action noise std: 1.81
          Mean value_function loss: 46.6403
               Mean surrogate loss: 0.0022
                 Mean entropy loss: 35.7294
                       Mean reward: 699.53
               Mean episode length: 242.70
    Episode_Reward/reaching_object: 0.6500
    Episode_Reward/rotating_object: 142.1147
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 1.91s
                      Time elapsed: 00:17:54
                               ETA: 00:33:23

################################################################################
                     [1m Learning iteration 524/1500 [0m                      

                       Computation: 49364 steps/s (collection: 1.854s, learning 0.138s)
             Mean action noise std: 1.81
          Mean value_function loss: 37.6947
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 35.7295
                       Mean reward: 745.70
               Mean episode length: 245.87
    Episode_Reward/reaching_object: 0.6563
    Episode_Reward/rotating_object: 145.1473
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 1.99s
                      Time elapsed: 00:17:56
                               ETA: 00:33:21

################################################################################
                     [1m Learning iteration 525/1500 [0m                      

                       Computation: 48624 steps/s (collection: 1.881s, learning 0.141s)
             Mean action noise std: 1.81
          Mean value_function loss: 44.2976
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 35.7311
                       Mean reward: 735.85
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 0.6538
    Episode_Reward/rotating_object: 144.4609
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 2.02s
                      Time elapsed: 00:17:58
                               ETA: 00:33:19

################################################################################
                     [1m Learning iteration 526/1500 [0m                      

                       Computation: 49879 steps/s (collection: 1.852s, learning 0.119s)
             Mean action noise std: 1.81
          Mean value_function loss: 43.2134
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 35.7349
                       Mean reward: 734.47
               Mean episode length: 245.75
    Episode_Reward/reaching_object: 0.6572
    Episode_Reward/rotating_object: 145.6913
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 1.97s
                      Time elapsed: 00:18:00
                               ETA: 00:33:17

################################################################################
                     [1m Learning iteration 527/1500 [0m                      

                       Computation: 46893 steps/s (collection: 1.967s, learning 0.129s)
             Mean action noise std: 1.82
          Mean value_function loss: 38.4631
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 35.7442
                       Mean reward: 726.24
               Mean episode length: 246.13
    Episode_Reward/reaching_object: 0.6562
    Episode_Reward/rotating_object: 148.0740
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 2.10s
                      Time elapsed: 00:18:02
                               ETA: 00:33:15

################################################################################
                     [1m Learning iteration 528/1500 [0m                      

                       Computation: 50771 steps/s (collection: 1.841s, learning 0.095s)
             Mean action noise std: 1.82
          Mean value_function loss: 44.4612
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 35.7482
                       Mean reward: 725.52
               Mean episode length: 244.36
    Episode_Reward/reaching_object: 0.6537
    Episode_Reward/rotating_object: 145.6457
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 1.94s
                      Time elapsed: 00:18:04
                               ETA: 00:33:13

################################################################################
                     [1m Learning iteration 529/1500 [0m                      

                       Computation: 52262 steps/s (collection: 1.786s, learning 0.095s)
             Mean action noise std: 1.82
          Mean value_function loss: 46.2166
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 35.7492
                       Mean reward: 730.49
               Mean episode length: 244.79
    Episode_Reward/reaching_object: 0.6550
    Episode_Reward/rotating_object: 146.6475
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 1.88s
                      Time elapsed: 00:18:06
                               ETA: 00:33:10

################################################################################
                     [1m Learning iteration 530/1500 [0m                      

                       Computation: 51738 steps/s (collection: 1.785s, learning 0.115s)
             Mean action noise std: 1.82
          Mean value_function loss: 45.8340
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 35.7558
                       Mean reward: 742.72
               Mean episode length: 245.76
    Episode_Reward/reaching_object: 0.6555
    Episode_Reward/rotating_object: 147.2579
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 1.90s
                      Time elapsed: 00:18:08
                               ETA: 00:33:08

################################################################################
                     [1m Learning iteration 531/1500 [0m                      

                       Computation: 48950 steps/s (collection: 1.813s, learning 0.196s)
             Mean action noise std: 1.82
          Mean value_function loss: 46.1375
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 35.7726
                       Mean reward: 747.29
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.6596
    Episode_Reward/rotating_object: 148.2467
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 2.01s
                      Time elapsed: 00:18:10
                               ETA: 00:33:06

################################################################################
                     [1m Learning iteration 532/1500 [0m                      

                       Computation: 51447 steps/s (collection: 1.789s, learning 0.122s)
             Mean action noise std: 1.82
          Mean value_function loss: 50.9127
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 35.7864
                       Mean reward: 726.54
               Mean episode length: 243.90
    Episode_Reward/reaching_object: 0.6538
    Episode_Reward/rotating_object: 145.3841
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 1.91s
                      Time elapsed: 00:18:12
                               ETA: 00:33:03

################################################################################
                     [1m Learning iteration 533/1500 [0m                      

                       Computation: 52237 steps/s (collection: 1.776s, learning 0.105s)
             Mean action noise std: 1.82
          Mean value_function loss: 47.1402
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 35.7892
                       Mean reward: 729.24
               Mean episode length: 246.23
    Episode_Reward/reaching_object: 0.6445
    Episode_Reward/rotating_object: 145.8127
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 1.88s
                      Time elapsed: 00:18:14
                               ETA: 00:33:01

################################################################################
                     [1m Learning iteration 534/1500 [0m                      

                       Computation: 51303 steps/s (collection: 1.811s, learning 0.106s)
             Mean action noise std: 1.82
          Mean value_function loss: 40.8228
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 35.8016
                       Mean reward: 717.19
               Mean episode length: 245.10
    Episode_Reward/reaching_object: 0.6380
    Episode_Reward/rotating_object: 144.4494
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 1.92s
                      Time elapsed: 00:18:16
                               ETA: 00:32:59

################################################################################
                     [1m Learning iteration 535/1500 [0m                      

                       Computation: 50937 steps/s (collection: 1.802s, learning 0.128s)
             Mean action noise std: 1.83
          Mean value_function loss: 35.0641
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 35.8086
                       Mean reward: 741.89
               Mean episode length: 245.45
    Episode_Reward/reaching_object: 0.6435
    Episode_Reward/rotating_object: 147.9200
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 1.93s
                      Time elapsed: 00:18:18
                               ETA: 00:32:57

################################################################################
                     [1m Learning iteration 536/1500 [0m                      

                       Computation: 47633 steps/s (collection: 1.941s, learning 0.123s)
             Mean action noise std: 1.83
          Mean value_function loss: 43.3471
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 35.8127
                       Mean reward: 743.49
               Mean episode length: 242.02
    Episode_Reward/reaching_object: 0.6348
    Episode_Reward/rotating_object: 144.8929
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 2.06s
                      Time elapsed: 00:18:20
                               ETA: 00:32:55

################################################################################
                     [1m Learning iteration 537/1500 [0m                      

                       Computation: 50901 steps/s (collection: 1.826s, learning 0.105s)
             Mean action noise std: 1.83
          Mean value_function loss: 38.5476
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 35.8164
                       Mean reward: 706.32
               Mean episode length: 243.87
    Episode_Reward/reaching_object: 0.6403
    Episode_Reward/rotating_object: 145.5077
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 1.93s
                      Time elapsed: 00:18:22
                               ETA: 00:32:52

################################################################################
                     [1m Learning iteration 538/1500 [0m                      

                       Computation: 52533 steps/s (collection: 1.772s, learning 0.099s)
             Mean action noise std: 1.83
          Mean value_function loss: 36.9708
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 35.8310
                       Mean reward: 748.71
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6478
    Episode_Reward/rotating_object: 148.3380
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 1.87s
                      Time elapsed: 00:18:24
                               ETA: 00:32:50

################################################################################
                     [1m Learning iteration 539/1500 [0m                      

                       Computation: 51366 steps/s (collection: 1.807s, learning 0.107s)
             Mean action noise std: 1.83
          Mean value_function loss: 40.3834
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 35.8444
                       Mean reward: 727.51
               Mean episode length: 242.25
    Episode_Reward/reaching_object: 0.6367
    Episode_Reward/rotating_object: 147.7697
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 1.91s
                      Time elapsed: 00:18:25
                               ETA: 00:32:48

################################################################################
                     [1m Learning iteration 540/1500 [0m                      

                       Computation: 51109 steps/s (collection: 1.814s, learning 0.110s)
             Mean action noise std: 1.83
          Mean value_function loss: 33.7300
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 35.8551
                       Mean reward: 744.83
               Mean episode length: 244.06
    Episode_Reward/reaching_object: 0.6485
    Episode_Reward/rotating_object: 146.6062
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 1.92s
                      Time elapsed: 00:18:27
                               ETA: 00:32:45

################################################################################
                     [1m Learning iteration 541/1500 [0m                      

                       Computation: 51588 steps/s (collection: 1.787s, learning 0.118s)
             Mean action noise std: 1.83
          Mean value_function loss: 37.7188
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 35.8649
                       Mean reward: 741.08
               Mean episode length: 244.14
    Episode_Reward/reaching_object: 0.6463
    Episode_Reward/rotating_object: 147.4211
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 1.91s
                      Time elapsed: 00:18:29
                               ETA: 00:32:43

################################################################################
                     [1m Learning iteration 542/1500 [0m                      

                       Computation: 52061 steps/s (collection: 1.758s, learning 0.131s)
             Mean action noise std: 1.84
          Mean value_function loss: 32.3817
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 35.8778
                       Mean reward: 763.39
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6495
    Episode_Reward/rotating_object: 149.1082
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 1.89s
                      Time elapsed: 00:18:31
                               ETA: 00:32:41

################################################################################
                     [1m Learning iteration 543/1500 [0m                      

                       Computation: 48443 steps/s (collection: 1.781s, learning 0.248s)
             Mean action noise std: 1.84
          Mean value_function loss: 35.6213
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 35.8876
                       Mean reward: 759.46
               Mean episode length: 248.39
    Episode_Reward/reaching_object: 0.6533
    Episode_Reward/rotating_object: 149.7063
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 2.03s
                      Time elapsed: 00:18:33
                               ETA: 00:32:39

################################################################################
                     [1m Learning iteration 544/1500 [0m                      

                       Computation: 49958 steps/s (collection: 1.833s, learning 0.135s)
             Mean action noise std: 1.84
          Mean value_function loss: 36.0845
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 35.8980
                       Mean reward: 754.48
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6532
    Episode_Reward/rotating_object: 148.8820
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 1.97s
                      Time elapsed: 00:18:35
                               ETA: 00:32:36

################################################################################
                     [1m Learning iteration 545/1500 [0m                      

                       Computation: 47374 steps/s (collection: 1.913s, learning 0.162s)
             Mean action noise std: 1.84
          Mean value_function loss: 34.4169
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 35.9017
                       Mean reward: 760.79
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6512
    Episode_Reward/rotating_object: 149.7706
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 2.08s
                      Time elapsed: 00:18:37
                               ETA: 00:32:34

################################################################################
                     [1m Learning iteration 546/1500 [0m                      

                       Computation: 48968 steps/s (collection: 1.855s, learning 0.153s)
             Mean action noise std: 1.84
          Mean value_function loss: 34.2047
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 35.9118
                       Mean reward: 765.32
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6528
    Episode_Reward/rotating_object: 148.0300
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 2.01s
                      Time elapsed: 00:18:39
                               ETA: 00:32:32

################################################################################
                     [1m Learning iteration 547/1500 [0m                      

                       Computation: 51564 steps/s (collection: 1.812s, learning 0.094s)
             Mean action noise std: 1.85
          Mean value_function loss: 34.8309
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 35.9309
                       Mean reward: 734.81
               Mean episode length: 244.40
    Episode_Reward/reaching_object: 0.6566
    Episode_Reward/rotating_object: 149.4950
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 1.91s
                      Time elapsed: 00:18:41
                               ETA: 00:32:30

################################################################################
                     [1m Learning iteration 548/1500 [0m                      

                       Computation: 52269 steps/s (collection: 1.774s, learning 0.107s)
             Mean action noise std: 1.85
          Mean value_function loss: 34.6941
               Mean surrogate loss: 0.0016
                 Mean entropy loss: 35.9416
                       Mean reward: 773.90
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6552
    Episode_Reward/rotating_object: 150.5923
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 1.88s
                      Time elapsed: 00:18:43
                               ETA: 00:32:28

################################################################################
                     [1m Learning iteration 549/1500 [0m                      

                       Computation: 50779 steps/s (collection: 1.837s, learning 0.098s)
             Mean action noise std: 1.85
          Mean value_function loss: 37.7929
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 35.9409
                       Mean reward: 759.57
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.6555
    Episode_Reward/rotating_object: 148.5582
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 1.94s
                      Time elapsed: 00:18:45
                               ETA: 00:32:26

################################################################################
                     [1m Learning iteration 550/1500 [0m                      

                       Computation: 50681 steps/s (collection: 1.829s, learning 0.111s)
             Mean action noise std: 1.85
          Mean value_function loss: 47.6527
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 35.9407
                       Mean reward: 755.55
               Mean episode length: 245.70
    Episode_Reward/reaching_object: 0.6554
    Episode_Reward/rotating_object: 149.4332
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 1.94s
                      Time elapsed: 00:18:47
                               ETA: 00:32:23

################################################################################
                     [1m Learning iteration 551/1500 [0m                      

                       Computation: 51970 steps/s (collection: 1.794s, learning 0.097s)
             Mean action noise std: 1.85
          Mean value_function loss: 38.9071
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 35.9443
                       Mean reward: 751.09
               Mean episode length: 244.07
    Episode_Reward/reaching_object: 0.6505
    Episode_Reward/rotating_object: 149.1340
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 1.89s
                      Time elapsed: 00:18:49
                               ETA: 00:32:21

################################################################################
                     [1m Learning iteration 552/1500 [0m                      

                       Computation: 51317 steps/s (collection: 1.822s, learning 0.094s)
             Mean action noise std: 1.85
          Mean value_function loss: 33.4743
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 35.9517
                       Mean reward: 766.65
               Mean episode length: 248.81
    Episode_Reward/reaching_object: 0.6579
    Episode_Reward/rotating_object: 151.7169
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 1.92s
                      Time elapsed: 00:18:51
                               ETA: 00:32:19

################################################################################
                     [1m Learning iteration 553/1500 [0m                      

                       Computation: 50289 steps/s (collection: 1.831s, learning 0.124s)
             Mean action noise std: 1.85
          Mean value_function loss: 39.0889
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 35.9560
                       Mean reward: 754.01
               Mean episode length: 246.59
    Episode_Reward/reaching_object: 0.6505
    Episode_Reward/rotating_object: 148.5241
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 1.95s
                      Time elapsed: 00:18:53
                               ETA: 00:32:16

################################################################################
                     [1m Learning iteration 554/1500 [0m                      

                       Computation: 52140 steps/s (collection: 1.757s, learning 0.128s)
             Mean action noise std: 1.85
          Mean value_function loss: 33.4171
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 35.9640
                       Mean reward: 760.35
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.6490
    Episode_Reward/rotating_object: 149.9086
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 1.89s
                      Time elapsed: 00:18:55
                               ETA: 00:32:14

################################################################################
                     [1m Learning iteration 555/1500 [0m                      

                       Computation: 49144 steps/s (collection: 1.781s, learning 0.219s)
             Mean action noise std: 1.85
          Mean value_function loss: 32.3895
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 35.9708
                       Mean reward: 754.37
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 0.6554
    Episode_Reward/rotating_object: 150.5780
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 2.00s
                      Time elapsed: 00:18:57
                               ETA: 00:32:12

################################################################################
                     [1m Learning iteration 556/1500 [0m                      

                       Computation: 50277 steps/s (collection: 1.805s, learning 0.150s)
             Mean action noise std: 1.85
          Mean value_function loss: 33.2257
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 35.9818
                       Mean reward: 762.92
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6489
    Episode_Reward/rotating_object: 150.0120
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 1.96s
                      Time elapsed: 00:18:58
                               ETA: 00:32:10

################################################################################
                     [1m Learning iteration 557/1500 [0m                      

                       Computation: 48670 steps/s (collection: 1.850s, learning 0.170s)
             Mean action noise std: 1.85
          Mean value_function loss: 31.2305
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 35.9889
                       Mean reward: 753.54
               Mean episode length: 246.01
    Episode_Reward/reaching_object: 0.6464
    Episode_Reward/rotating_object: 150.4633
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 2.02s
                      Time elapsed: 00:19:01
                               ETA: 00:32:08

################################################################################
                     [1m Learning iteration 558/1500 [0m                      

                       Computation: 51126 steps/s (collection: 1.796s, learning 0.127s)
             Mean action noise std: 1.85
          Mean value_function loss: 33.6213
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 35.9854
                       Mean reward: 772.90
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6437
    Episode_Reward/rotating_object: 150.5302
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 1.92s
                      Time elapsed: 00:19:02
                               ETA: 00:32:06

################################################################################
                     [1m Learning iteration 559/1500 [0m                      

                       Computation: 51029 steps/s (collection: 1.783s, learning 0.144s)
             Mean action noise std: 1.86
          Mean value_function loss: 38.3567
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 35.9813
                       Mean reward: 737.67
               Mean episode length: 241.45
    Episode_Reward/reaching_object: 0.6464
    Episode_Reward/rotating_object: 150.6541
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 1.93s
                      Time elapsed: 00:19:04
                               ETA: 00:32:03

################################################################################
                     [1m Learning iteration 560/1500 [0m                      

                       Computation: 51173 steps/s (collection: 1.809s, learning 0.112s)
             Mean action noise std: 1.86
          Mean value_function loss: 34.7776
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 35.9892
                       Mean reward: 748.72
               Mean episode length: 244.28
    Episode_Reward/reaching_object: 0.6470
    Episode_Reward/rotating_object: 150.2831
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 1.92s
                      Time elapsed: 00:19:06
                               ETA: 00:32:01

################################################################################
                     [1m Learning iteration 561/1500 [0m                      

                       Computation: 48369 steps/s (collection: 1.854s, learning 0.179s)
             Mean action noise std: 1.86
          Mean value_function loss: 31.9887
               Mean surrogate loss: 0.0144
                 Mean entropy loss: 35.9963
                       Mean reward: 776.10
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6512
    Episode_Reward/rotating_object: 152.5749
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 2.03s
                      Time elapsed: 00:19:08
                               ETA: 00:31:59

################################################################################
                     [1m Learning iteration 562/1500 [0m                      

                       Computation: 52011 steps/s (collection: 1.794s, learning 0.096s)
             Mean action noise std: 1.86
          Mean value_function loss: 30.1866
               Mean surrogate loss: 0.0130
                 Mean entropy loss: 35.9969
                       Mean reward: 756.17
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 0.6489
    Episode_Reward/rotating_object: 151.1776
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 1.89s
                      Time elapsed: 00:19:10
                               ETA: 00:31:57

################################################################################
                     [1m Learning iteration 563/1500 [0m                      

                       Computation: 51646 steps/s (collection: 1.807s, learning 0.096s)
             Mean action noise std: 1.86
          Mean value_function loss: 28.0367
               Mean surrogate loss: 0.0034
                 Mean entropy loss: 35.9995
                       Mean reward: 763.47
               Mean episode length: 245.95
    Episode_Reward/reaching_object: 0.6471
    Episode_Reward/rotating_object: 152.6078
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 1.90s
                      Time elapsed: 00:19:12
                               ETA: 00:31:54

################################################################################
                     [1m Learning iteration 564/1500 [0m                      

                       Computation: 52683 steps/s (collection: 1.772s, learning 0.094s)
             Mean action noise std: 1.86
          Mean value_function loss: 30.7835
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 36.0107
                       Mean reward: 751.39
               Mean episode length: 246.09
    Episode_Reward/reaching_object: 0.6491
    Episode_Reward/rotating_object: 152.5206
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 1.87s
                      Time elapsed: 00:19:14
                               ETA: 00:31:52

################################################################################
                     [1m Learning iteration 565/1500 [0m                      

                       Computation: 51687 steps/s (collection: 1.802s, learning 0.100s)
             Mean action noise std: 1.86
          Mean value_function loss: 30.9339
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 36.0239
                       Mean reward: 741.41
               Mean episode length: 243.61
    Episode_Reward/reaching_object: 0.6467
    Episode_Reward/rotating_object: 151.2438
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 1.90s
                      Time elapsed: 00:19:16
                               ETA: 00:31:50

################################################################################
                     [1m Learning iteration 566/1500 [0m                      

                       Computation: 52111 steps/s (collection: 1.783s, learning 0.104s)
             Mean action noise std: 1.87
          Mean value_function loss: 25.2530
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 36.0440
                       Mean reward: 766.46
               Mean episode length: 248.12
    Episode_Reward/reaching_object: 0.6523
    Episode_Reward/rotating_object: 151.5278
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 1.89s
                      Time elapsed: 00:19:18
                               ETA: 00:31:47

################################################################################
                     [1m Learning iteration 567/1500 [0m                      

                       Computation: 52307 steps/s (collection: 1.766s, learning 0.114s)
             Mean action noise std: 1.87
          Mean value_function loss: 31.7647
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 36.0647
                       Mean reward: 766.62
               Mean episode length: 245.55
    Episode_Reward/reaching_object: 0.6536
    Episode_Reward/rotating_object: 152.9574
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 1.88s
                      Time elapsed: 00:19:20
                               ETA: 00:31:45

################################################################################
                     [1m Learning iteration 568/1500 [0m                      

                       Computation: 50742 steps/s (collection: 1.767s, learning 0.171s)
             Mean action noise std: 1.87
          Mean value_function loss: 26.1952
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 36.0859
                       Mean reward: 746.00
               Mean episode length: 244.62
    Episode_Reward/reaching_object: 0.6437
    Episode_Reward/rotating_object: 152.0409
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 1.94s
                      Time elapsed: 00:19:22
                               ETA: 00:31:43

################################################################################
                     [1m Learning iteration 569/1500 [0m                      

                       Computation: 52275 steps/s (collection: 1.736s, learning 0.145s)
             Mean action noise std: 1.87
          Mean value_function loss: 23.7596
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 36.0940
                       Mean reward: 770.94
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.6524
    Episode_Reward/rotating_object: 153.9307
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 1.88s
                      Time elapsed: 00:19:23
                               ETA: 00:31:41

################################################################################
                     [1m Learning iteration 570/1500 [0m                      

                       Computation: 50371 steps/s (collection: 1.794s, learning 0.157s)
             Mean action noise std: 1.87
          Mean value_function loss: 26.8110
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 36.1042
                       Mean reward: 774.69
               Mean episode length: 248.02
    Episode_Reward/reaching_object: 0.6504
    Episode_Reward/rotating_object: 153.8259
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 1.95s
                      Time elapsed: 00:19:25
                               ETA: 00:31:38

################################################################################
                     [1m Learning iteration 571/1500 [0m                      

                       Computation: 51051 steps/s (collection: 1.795s, learning 0.131s)
             Mean action noise std: 1.88
          Mean value_function loss: 30.0960
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 36.1168
                       Mean reward: 774.05
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 0.6508
    Episode_Reward/rotating_object: 153.7771
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 1.93s
                      Time elapsed: 00:19:27
                               ETA: 00:31:36

################################################################################
                     [1m Learning iteration 572/1500 [0m                      

                       Computation: 51714 steps/s (collection: 1.774s, learning 0.127s)
             Mean action noise std: 1.88
          Mean value_function loss: 27.4950
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 36.1280
                       Mean reward: 761.70
               Mean episode length: 243.86
    Episode_Reward/reaching_object: 0.6482
    Episode_Reward/rotating_object: 153.3372
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 1.90s
                      Time elapsed: 00:19:29
                               ETA: 00:31:34

################################################################################
                     [1m Learning iteration 573/1500 [0m                      

                       Computation: 51751 steps/s (collection: 1.796s, learning 0.104s)
             Mean action noise std: 1.88
          Mean value_function loss: 29.6170
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 36.1440
                       Mean reward: 769.90
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6575
    Episode_Reward/rotating_object: 152.9446
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 1.90s
                      Time elapsed: 00:19:31
                               ETA: 00:31:32

################################################################################
                     [1m Learning iteration 574/1500 [0m                      

                       Computation: 47821 steps/s (collection: 1.883s, learning 0.173s)
             Mean action noise std: 1.88
          Mean value_function loss: 24.5729
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 36.1583
                       Mean reward: 764.95
               Mean episode length: 248.98
    Episode_Reward/reaching_object: 0.6561
    Episode_Reward/rotating_object: 153.3187
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 2.06s
                      Time elapsed: 00:19:33
                               ETA: 00:31:30

################################################################################
                     [1m Learning iteration 575/1500 [0m                      

                       Computation: 50424 steps/s (collection: 1.847s, learning 0.103s)
             Mean action noise std: 1.88
          Mean value_function loss: 21.3780
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 36.1734
                       Mean reward: 754.50
               Mean episode length: 246.95
    Episode_Reward/reaching_object: 0.6602
    Episode_Reward/rotating_object: 151.7844
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 1.95s
                      Time elapsed: 00:19:35
                               ETA: 00:31:27

################################################################################
                     [1m Learning iteration 576/1500 [0m                      

                       Computation: 51423 steps/s (collection: 1.800s, learning 0.112s)
             Mean action noise std: 1.88
          Mean value_function loss: 29.8576
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 36.1819
                       Mean reward: 766.76
               Mean episode length: 245.82
    Episode_Reward/reaching_object: 0.6598
    Episode_Reward/rotating_object: 153.2848
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 1.91s
                      Time elapsed: 00:19:37
                               ETA: 00:31:25

################################################################################
                     [1m Learning iteration 577/1500 [0m                      

                       Computation: 51854 steps/s (collection: 1.789s, learning 0.107s)
             Mean action noise std: 1.89
          Mean value_function loss: 23.8102
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 36.1953
                       Mean reward: 761.90
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.6635
    Episode_Reward/rotating_object: 153.6720
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 1.90s
                      Time elapsed: 00:19:39
                               ETA: 00:31:23

################################################################################
                     [1m Learning iteration 578/1500 [0m                      

                       Computation: 52336 steps/s (collection: 1.776s, learning 0.102s)
             Mean action noise std: 1.89
          Mean value_function loss: 30.3424
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 36.2117
                       Mean reward: 771.05
               Mean episode length: 245.77
    Episode_Reward/reaching_object: 0.6650
    Episode_Reward/rotating_object: 152.3396
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 1.88s
                      Time elapsed: 00:19:41
                               ETA: 00:31:21

################################################################################
                     [1m Learning iteration 579/1500 [0m                      

                       Computation: 52759 steps/s (collection: 1.756s, learning 0.107s)
             Mean action noise std: 1.89
          Mean value_function loss: 22.3112
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 36.2279
                       Mean reward: 770.52
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6667
    Episode_Reward/rotating_object: 154.7829
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 1.86s
                      Time elapsed: 00:19:43
                               ETA: 00:31:18

################################################################################
                     [1m Learning iteration 580/1500 [0m                      

                       Computation: 52765 steps/s (collection: 1.750s, learning 0.113s)
             Mean action noise std: 1.89
          Mean value_function loss: 22.4590
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 36.2369
                       Mean reward: 784.02
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6685
    Episode_Reward/rotating_object: 155.0818
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 1.86s
                      Time elapsed: 00:19:45
                               ETA: 00:31:16

################################################################################
                     [1m Learning iteration 581/1500 [0m                      

                       Computation: 51135 steps/s (collection: 1.772s, learning 0.151s)
             Mean action noise std: 1.89
          Mean value_function loss: 23.1062
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 36.2394
                       Mean reward: 778.41
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6699
    Episode_Reward/rotating_object: 154.5209
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 1.92s
                      Time elapsed: 00:19:46
                               ETA: 00:31:14

################################################################################
                     [1m Learning iteration 582/1500 [0m                      

                       Computation: 50576 steps/s (collection: 1.797s, learning 0.147s)
             Mean action noise std: 1.89
          Mean value_function loss: 22.1493
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 36.2448
                       Mean reward: 789.55
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6631
    Episode_Reward/rotating_object: 156.9711
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 1.94s
                      Time elapsed: 00:19:48
                               ETA: 00:31:12

################################################################################
                     [1m Learning iteration 583/1500 [0m                      

                       Computation: 53409 steps/s (collection: 1.743s, learning 0.097s)
             Mean action noise std: 1.89
          Mean value_function loss: 25.3511
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 36.2512
                       Mean reward: 774.78
               Mean episode length: 243.51
    Episode_Reward/reaching_object: 0.6568
    Episode_Reward/rotating_object: 156.1308
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 1.84s
                      Time elapsed: 00:19:50
                               ETA: 00:31:09

################################################################################
                     [1m Learning iteration 584/1500 [0m                      

                       Computation: 51962 steps/s (collection: 1.782s, learning 0.109s)
             Mean action noise std: 1.90
          Mean value_function loss: 27.5233
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 36.2515
                       Mean reward: 767.64
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 0.6516
    Episode_Reward/rotating_object: 153.7450
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 1.89s
                      Time elapsed: 00:19:52
                               ETA: 00:31:07

################################################################################
                     [1m Learning iteration 585/1500 [0m                      

                       Computation: 51541 steps/s (collection: 1.813s, learning 0.094s)
             Mean action noise std: 1.90
          Mean value_function loss: 29.8382
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 36.2613
                       Mean reward: 764.36
               Mean episode length: 244.55
    Episode_Reward/reaching_object: 0.6413
    Episode_Reward/rotating_object: 153.7429
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 1.91s
                      Time elapsed: 00:19:54
                               ETA: 00:31:05

################################################################################
                     [1m Learning iteration 586/1500 [0m                      

                       Computation: 53062 steps/s (collection: 1.758s, learning 0.095s)
             Mean action noise std: 1.90
          Mean value_function loss: 28.8523
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 36.2828
                       Mean reward: 765.07
               Mean episode length: 246.42
    Episode_Reward/reaching_object: 0.6522
    Episode_Reward/rotating_object: 153.7601
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 1.85s
                      Time elapsed: 00:19:56
                               ETA: 00:31:02

################################################################################
                     [1m Learning iteration 587/1500 [0m                      

                       Computation: 52324 steps/s (collection: 1.778s, learning 0.101s)
             Mean action noise std: 1.91
          Mean value_function loss: 26.7576
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 36.3158
                       Mean reward: 782.96
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 0.6461
    Episode_Reward/rotating_object: 153.8964
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 1.88s
                      Time elapsed: 00:19:58
                               ETA: 00:31:00

################################################################################
                     [1m Learning iteration 588/1500 [0m                      

                       Computation: 52312 steps/s (collection: 1.778s, learning 0.101s)
             Mean action noise std: 1.91
          Mean value_function loss: 25.9025
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 36.3412
                       Mean reward: 765.74
               Mean episode length: 243.63
    Episode_Reward/reaching_object: 0.6482
    Episode_Reward/rotating_object: 154.8623
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 1.88s
                      Time elapsed: 00:20:00
                               ETA: 00:30:58

################################################################################
                     [1m Learning iteration 589/1500 [0m                      

                       Computation: 52745 steps/s (collection: 1.759s, learning 0.105s)
             Mean action noise std: 1.91
          Mean value_function loss: 24.6746
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 36.3592
                       Mean reward: 774.19
               Mean episode length: 248.05
    Episode_Reward/reaching_object: 0.6482
    Episode_Reward/rotating_object: 153.4137
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 1.86s
                      Time elapsed: 00:20:02
                               ETA: 00:30:56

################################################################################
                     [1m Learning iteration 590/1500 [0m                      

                       Computation: 53702 steps/s (collection: 1.733s, learning 0.098s)
             Mean action noise std: 1.91
          Mean value_function loss: 26.8545
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 36.3842
                       Mean reward: 788.53
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.6482
    Episode_Reward/rotating_object: 155.6189
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 1.83s
                      Time elapsed: 00:20:03
                               ETA: 00:30:53

################################################################################
                     [1m Learning iteration 591/1500 [0m                      

                       Computation: 52949 steps/s (collection: 1.757s, learning 0.100s)
             Mean action noise std: 1.92
          Mean value_function loss: 30.7515
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 36.4088
                       Mean reward: 790.70
               Mean episode length: 246.00
    Episode_Reward/reaching_object: 0.6438
    Episode_Reward/rotating_object: 152.7190
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 1.86s
                      Time elapsed: 00:20:05
                               ETA: 00:30:51

################################################################################
                     [1m Learning iteration 592/1500 [0m                      

                       Computation: 53373 steps/s (collection: 1.748s, learning 0.094s)
             Mean action noise std: 1.92
          Mean value_function loss: 20.8671
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 36.4311
                       Mean reward: 787.40
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.6534
    Episode_Reward/rotating_object: 155.1729
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 1.84s
                      Time elapsed: 00:20:07
                               ETA: 00:30:49

################################################################################
                     [1m Learning iteration 593/1500 [0m                      

                       Computation: 52581 steps/s (collection: 1.752s, learning 0.117s)
             Mean action noise std: 1.92
          Mean value_function loss: 28.6906
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 36.4446
                       Mean reward: 776.34
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 0.6520
    Episode_Reward/rotating_object: 153.6471
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 1.87s
                      Time elapsed: 00:20:09
                               ETA: 00:30:46

################################################################################
                     [1m Learning iteration 594/1500 [0m                      

                       Computation: 52310 steps/s (collection: 1.772s, learning 0.108s)
             Mean action noise std: 1.92
          Mean value_function loss: 22.3459
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 36.4593
                       Mean reward: 793.55
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.6573
    Episode_Reward/rotating_object: 156.2713
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 1.88s
                      Time elapsed: 00:20:11
                               ETA: 00:30:44

################################################################################
                     [1m Learning iteration 595/1500 [0m                      

                       Computation: 52499 steps/s (collection: 1.769s, learning 0.104s)
             Mean action noise std: 1.93
          Mean value_function loss: 21.5723
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 36.4768
                       Mean reward: 784.99
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6628
    Episode_Reward/rotating_object: 155.7768
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 1.87s
                      Time elapsed: 00:20:13
                               ETA: 00:30:42

################################################################################
                     [1m Learning iteration 596/1500 [0m                      

                       Computation: 50887 steps/s (collection: 1.794s, learning 0.138s)
             Mean action noise std: 1.93
          Mean value_function loss: 24.1097
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 36.4781
                       Mean reward: 779.51
               Mean episode length: 246.16
    Episode_Reward/reaching_object: 0.6675
    Episode_Reward/rotating_object: 156.2019
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 1.93s
                      Time elapsed: 00:20:15
                               ETA: 00:30:39

################################################################################
                     [1m Learning iteration 597/1500 [0m                      

                       Computation: 49237 steps/s (collection: 1.880s, learning 0.116s)
             Mean action noise std: 1.93
          Mean value_function loss: 23.2556
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 36.4931
                       Mean reward: 751.73
               Mean episode length: 240.84
    Episode_Reward/reaching_object: 0.6703
    Episode_Reward/rotating_object: 155.7765
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 2.00s
                      Time elapsed: 00:20:17
                               ETA: 00:30:37

################################################################################
                     [1m Learning iteration 598/1500 [0m                      

                       Computation: 50760 steps/s (collection: 1.773s, learning 0.164s)
             Mean action noise std: 1.93
          Mean value_function loss: 21.5596
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 36.5079
                       Mean reward: 791.89
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6735
    Episode_Reward/rotating_object: 155.1219
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 1.94s
                      Time elapsed: 00:20:19
                               ETA: 00:30:35

################################################################################
                     [1m Learning iteration 599/1500 [0m                      

                       Computation: 52907 steps/s (collection: 1.760s, learning 0.098s)
             Mean action noise std: 1.93
          Mean value_function loss: 23.2196
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 36.5132
                       Mean reward: 791.52
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6686
    Episode_Reward/rotating_object: 155.5582
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 1.86s
                      Time elapsed: 00:20:20
                               ETA: 00:30:33

################################################################################
                     [1m Learning iteration 600/1500 [0m                      

                       Computation: 51061 steps/s (collection: 1.823s, learning 0.102s)
             Mean action noise std: 1.93
          Mean value_function loss: 23.6238
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 36.5168
                       Mean reward: 764.73
               Mean episode length: 239.34
    Episode_Reward/reaching_object: 0.6660
    Episode_Reward/rotating_object: 156.3893
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 1.93s
                      Time elapsed: 00:20:22
                               ETA: 00:30:31

################################################################################
                     [1m Learning iteration 601/1500 [0m                      

                       Computation: 51939 steps/s (collection: 1.776s, learning 0.116s)
             Mean action noise std: 1.93
          Mean value_function loss: 25.4835
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 36.5189
                       Mean reward: 775.37
               Mean episode length: 243.92
    Episode_Reward/reaching_object: 0.6663
    Episode_Reward/rotating_object: 157.4492
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 1.89s
                      Time elapsed: 00:20:24
                               ETA: 00:30:28

################################################################################
                     [1m Learning iteration 602/1500 [0m                      

                       Computation: 51652 steps/s (collection: 1.793s, learning 0.110s)
             Mean action noise std: 1.93
          Mean value_function loss: 22.4085
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 36.5141
                       Mean reward: 791.64
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 0.6622
    Episode_Reward/rotating_object: 157.4506
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 1.90s
                      Time elapsed: 00:20:26
                               ETA: 00:30:26

################################################################################
                     [1m Learning iteration 603/1500 [0m                      

                       Computation: 52808 steps/s (collection: 1.753s, learning 0.109s)
             Mean action noise std: 1.94
          Mean value_function loss: 17.7070
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 36.5288
                       Mean reward: 781.66
               Mean episode length: 246.48
    Episode_Reward/reaching_object: 0.6628
    Episode_Reward/rotating_object: 158.2944
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 1.86s
                      Time elapsed: 00:20:28
                               ETA: 00:30:24

################################################################################
                     [1m Learning iteration 604/1500 [0m                      

                       Computation: 50960 steps/s (collection: 1.804s, learning 0.125s)
             Mean action noise std: 1.94
          Mean value_function loss: 20.0367
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 36.5344
                       Mean reward: 792.78
               Mean episode length: 248.00
    Episode_Reward/reaching_object: 0.6581
    Episode_Reward/rotating_object: 159.0487
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 1.93s
                      Time elapsed: 00:20:30
                               ETA: 00:30:22

################################################################################
                     [1m Learning iteration 605/1500 [0m                      

                       Computation: 52322 steps/s (collection: 1.735s, learning 0.144s)
             Mean action noise std: 1.94
          Mean value_function loss: 21.4068
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 36.5372
                       Mean reward: 795.37
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6629
    Episode_Reward/rotating_object: 157.6956
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 1.88s
                      Time elapsed: 00:20:32
                               ETA: 00:30:19

################################################################################
                     [1m Learning iteration 606/1500 [0m                      

                       Computation: 51244 steps/s (collection: 1.734s, learning 0.185s)
             Mean action noise std: 1.94
          Mean value_function loss: 18.8050
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 36.5517
                       Mean reward: 805.62
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6480
    Episode_Reward/rotating_object: 156.6077
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 1.92s
                      Time elapsed: 00:20:34
                               ETA: 00:30:17

################################################################################
                     [1m Learning iteration 607/1500 [0m                      

                       Computation: 54240 steps/s (collection: 1.718s, learning 0.094s)
             Mean action noise std: 1.94
          Mean value_function loss: 21.3014
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 36.5625
                       Mean reward: 803.87
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6553
    Episode_Reward/rotating_object: 157.6867
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 1.81s
                      Time elapsed: 00:20:36
                               ETA: 00:30:15

################################################################################
                     [1m Learning iteration 608/1500 [0m                      

                       Computation: 52445 steps/s (collection: 1.760s, learning 0.115s)
             Mean action noise std: 1.94
          Mean value_function loss: 26.2918
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 36.5678
                       Mean reward: 804.64
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6493
    Episode_Reward/rotating_object: 157.4063
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 1.87s
                      Time elapsed: 00:20:37
                               ETA: 00:30:13

################################################################################
                     [1m Learning iteration 609/1500 [0m                      

                       Computation: 53800 steps/s (collection: 1.724s, learning 0.104s)
             Mean action noise std: 1.95
          Mean value_function loss: 25.2805
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 36.5753
                       Mean reward: 776.64
               Mean episode length: 244.84
    Episode_Reward/reaching_object: 0.6461
    Episode_Reward/rotating_object: 156.6611
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 1.83s
                      Time elapsed: 00:20:39
                               ETA: 00:30:10

################################################################################
                     [1m Learning iteration 610/1500 [0m                      

                       Computation: 53282 steps/s (collection: 1.740s, learning 0.105s)
             Mean action noise std: 1.95
          Mean value_function loss: 18.8821
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 36.5939
                       Mean reward: 789.28
               Mean episode length: 246.73
    Episode_Reward/reaching_object: 0.6406
    Episode_Reward/rotating_object: 156.8682
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 1.84s
                      Time elapsed: 00:20:41
                               ETA: 00:30:08

################################################################################
                     [1m Learning iteration 611/1500 [0m                      

                       Computation: 52572 steps/s (collection: 1.769s, learning 0.101s)
             Mean action noise std: 1.95
          Mean value_function loss: 22.6814
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 36.6121
                       Mean reward: 786.56
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 0.6366
    Episode_Reward/rotating_object: 158.4538
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 1.87s
                      Time elapsed: 00:20:43
                               ETA: 00:30:06

################################################################################
                     [1m Learning iteration 612/1500 [0m                      

                       Computation: 51640 steps/s (collection: 1.751s, learning 0.153s)
             Mean action noise std: 1.95
          Mean value_function loss: 20.5401
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 36.6237
                       Mean reward: 782.15
               Mean episode length: 246.07
    Episode_Reward/reaching_object: 0.6393
    Episode_Reward/rotating_object: 156.0355
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 1.90s
                      Time elapsed: 00:20:45
                               ETA: 00:30:04

################################################################################
                     [1m Learning iteration 613/1500 [0m                      

                       Computation: 52880 steps/s (collection: 1.713s, learning 0.146s)
             Mean action noise std: 1.95
          Mean value_function loss: 14.9069
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 36.6265
                       Mean reward: 802.50
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6479
    Episode_Reward/rotating_object: 159.7277
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 1.86s
                      Time elapsed: 00:20:47
                               ETA: 00:30:01

################################################################################
                     [1m Learning iteration 614/1500 [0m                      

                       Computation: 54721 steps/s (collection: 1.703s, learning 0.093s)
             Mean action noise std: 1.96
          Mean value_function loss: 18.0515
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 36.6325
                       Mean reward: 798.21
               Mean episode length: 249.76
    Episode_Reward/reaching_object: 0.6387
    Episode_Reward/rotating_object: 156.1497
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 1.80s
                      Time elapsed: 00:20:49
                               ETA: 00:29:59

################################################################################
                     [1m Learning iteration 615/1500 [0m                      

                       Computation: 52811 steps/s (collection: 1.755s, learning 0.107s)
             Mean action noise std: 1.96
          Mean value_function loss: 17.8560
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 36.6474
                       Mean reward: 794.31
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.6433
    Episode_Reward/rotating_object: 157.8415
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 1.86s
                      Time elapsed: 00:20:50
                               ETA: 00:29:57

################################################################################
                     [1m Learning iteration 616/1500 [0m                      

                       Computation: 52361 steps/s (collection: 1.777s, learning 0.101s)
             Mean action noise std: 1.96
          Mean value_function loss: 18.1159
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 36.6546
                       Mean reward: 803.28
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6431
    Episode_Reward/rotating_object: 158.8303
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 1.88s
                      Time elapsed: 00:20:52
                               ETA: 00:29:54

################################################################################
                     [1m Learning iteration 617/1500 [0m                      

                       Computation: 52051 steps/s (collection: 1.775s, learning 0.114s)
             Mean action noise std: 1.96
          Mean value_function loss: 21.7038
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 36.6587
                       Mean reward: 785.38
               Mean episode length: 245.75
    Episode_Reward/reaching_object: 0.6409
    Episode_Reward/rotating_object: 157.3401
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 1.89s
                      Time elapsed: 00:20:54
                               ETA: 00:29:52

################################################################################
                     [1m Learning iteration 618/1500 [0m                      

                       Computation: 53319 steps/s (collection: 1.736s, learning 0.108s)
             Mean action noise std: 1.96
          Mean value_function loss: 18.5449
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 36.6697
                       Mean reward: 799.21
               Mean episode length: 248.04
    Episode_Reward/reaching_object: 0.6416
    Episode_Reward/rotating_object: 158.8812
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 1.84s
                      Time elapsed: 00:20:56
                               ETA: 00:29:50

################################################################################
                     [1m Learning iteration 619/1500 [0m                      

                       Computation: 52778 steps/s (collection: 1.728s, learning 0.135s)
             Mean action noise std: 1.97
          Mean value_function loss: 21.8328
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 36.6831
                       Mean reward: 789.39
               Mean episode length: 245.92
    Episode_Reward/reaching_object: 0.6452
    Episode_Reward/rotating_object: 157.5760
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 1.86s
                      Time elapsed: 00:20:58
                               ETA: 00:29:48

################################################################################
                     [1m Learning iteration 620/1500 [0m                      

                       Computation: 50922 steps/s (collection: 1.730s, learning 0.201s)
             Mean action noise std: 1.97
          Mean value_function loss: 20.2453
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 36.6958
                       Mean reward: 783.99
               Mean episode length: 243.98
    Episode_Reward/reaching_object: 0.6504
    Episode_Reward/rotating_object: 159.5801
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 1.93s
                      Time elapsed: 00:21:00
                               ETA: 00:29:45

################################################################################
                     [1m Learning iteration 621/1500 [0m                      

                       Computation: 53512 steps/s (collection: 1.718s, learning 0.119s)
             Mean action noise std: 1.97
          Mean value_function loss: 20.4919
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 36.7053
                       Mean reward: 792.24
               Mean episode length: 245.78
    Episode_Reward/reaching_object: 0.6503
    Episode_Reward/rotating_object: 160.3538
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 1.84s
                      Time elapsed: 00:21:02
                               ETA: 00:29:43

################################################################################
                     [1m Learning iteration 622/1500 [0m                      

                       Computation: 52830 steps/s (collection: 1.752s, learning 0.109s)
             Mean action noise std: 1.97
          Mean value_function loss: 21.7571
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 36.7321
                       Mean reward: 794.59
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 0.6429
    Episode_Reward/rotating_object: 158.4465
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 1.86s
                      Time elapsed: 00:21:03
                               ETA: 00:29:41

################################################################################
                     [1m Learning iteration 623/1500 [0m                      

                       Computation: 53091 steps/s (collection: 1.749s, learning 0.103s)
             Mean action noise std: 1.98
          Mean value_function loss: 17.2947
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 36.7466
                       Mean reward: 785.98
               Mean episode length: 245.84
    Episode_Reward/reaching_object: 0.6559
    Episode_Reward/rotating_object: 158.4622
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 1.85s
                      Time elapsed: 00:21:05
                               ETA: 00:29:39

################################################################################
                     [1m Learning iteration 624/1500 [0m                      

                       Computation: 53569 steps/s (collection: 1.739s, learning 0.096s)
             Mean action noise std: 1.98
          Mean value_function loss: 13.9877
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 36.7547
                       Mean reward: 804.16
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6573
    Episode_Reward/rotating_object: 160.0743
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 1.84s
                      Time elapsed: 00:21:07
                               ETA: 00:29:36

################################################################################
                     [1m Learning iteration 625/1500 [0m                      

                       Computation: 50682 steps/s (collection: 1.806s, learning 0.134s)
             Mean action noise std: 1.98
          Mean value_function loss: 18.8744
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 36.7695
                       Mean reward: 797.09
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 0.6571
    Episode_Reward/rotating_object: 160.3179
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 1.94s
                      Time elapsed: 00:21:09
                               ETA: 00:29:34

################################################################################
                     [1m Learning iteration 626/1500 [0m                      

                       Computation: 50690 steps/s (collection: 1.808s, learning 0.131s)
             Mean action noise std: 1.98
          Mean value_function loss: 15.3012
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 36.7966
                       Mean reward: 805.48
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.6543
    Episode_Reward/rotating_object: 160.4957
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 1.94s
                      Time elapsed: 00:21:11
                               ETA: 00:29:32

################################################################################
                     [1m Learning iteration 627/1500 [0m                      

                       Computation: 52042 steps/s (collection: 1.707s, learning 0.182s)
             Mean action noise std: 1.99
          Mean value_function loss: 16.7923
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 36.8198
                       Mean reward: 810.66
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6580
    Episode_Reward/rotating_object: 161.1794
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 1.89s
                      Time elapsed: 00:21:13
                               ETA: 00:29:30

################################################################################
                     [1m Learning iteration 628/1500 [0m                      

                       Computation: 52847 steps/s (collection: 1.731s, learning 0.129s)
             Mean action noise std: 1.99
          Mean value_function loss: 19.1786
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 36.8480
                       Mean reward: 796.14
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.6511
    Episode_Reward/rotating_object: 158.7512
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 1.86s
                      Time elapsed: 00:21:15
                               ETA: 00:29:27

################################################################################
                     [1m Learning iteration 629/1500 [0m                      

                       Computation: 53460 steps/s (collection: 1.746s, learning 0.093s)
             Mean action noise std: 1.99
          Mean value_function loss: 19.7125
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 36.8694
                       Mean reward: 801.10
               Mean episode length: 248.00
    Episode_Reward/reaching_object: 0.6500
    Episode_Reward/rotating_object: 158.5849
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 1.84s
                      Time elapsed: 00:21:17
                               ETA: 00:29:25

################################################################################
                     [1m Learning iteration 630/1500 [0m                      

                       Computation: 53037 steps/s (collection: 1.754s, learning 0.100s)
             Mean action noise std: 1.99
          Mean value_function loss: 17.6777
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 36.8785
                       Mean reward: 791.76
               Mean episode length: 248.18
    Episode_Reward/reaching_object: 0.6510
    Episode_Reward/rotating_object: 160.1421
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 1.85s
                      Time elapsed: 00:21:18
                               ETA: 00:29:23

################################################################################
                     [1m Learning iteration 631/1500 [0m                      

                       Computation: 53587 steps/s (collection: 1.737s, learning 0.098s)
             Mean action noise std: 2.00
          Mean value_function loss: 20.6582
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 36.8948
                       Mean reward: 806.07
               Mean episode length: 248.00
    Episode_Reward/reaching_object: 0.6464
    Episode_Reward/rotating_object: 160.2243
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 1.83s
                      Time elapsed: 00:21:20
                               ETA: 00:29:21

################################################################################
                     [1m Learning iteration 632/1500 [0m                      

                       Computation: 53713 steps/s (collection: 1.717s, learning 0.114s)
             Mean action noise std: 2.00
          Mean value_function loss: 18.4957
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 36.9320
                       Mean reward: 795.82
               Mean episode length: 245.80
    Episode_Reward/reaching_object: 0.6436
    Episode_Reward/rotating_object: 159.2581
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 1.83s
                      Time elapsed: 00:21:22
                               ETA: 00:29:18

################################################################################
                     [1m Learning iteration 633/1500 [0m                      

                       Computation: 53381 steps/s (collection: 1.701s, learning 0.141s)
             Mean action noise std: 2.01
          Mean value_function loss: 21.7451
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 36.9661
                       Mean reward: 789.99
               Mean episode length: 245.02
    Episode_Reward/reaching_object: 0.6411
    Episode_Reward/rotating_object: 157.5976
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 1.84s
                      Time elapsed: 00:21:24
                               ETA: 00:29:16

################################################################################
                     [1m Learning iteration 634/1500 [0m                      

                       Computation: 52173 steps/s (collection: 1.701s, learning 0.183s)
             Mean action noise std: 2.01
          Mean value_function loss: 20.8186
               Mean surrogate loss: 0.0032
                 Mean entropy loss: 37.0006
                       Mean reward: 795.31
               Mean episode length: 245.47
    Episode_Reward/reaching_object: 0.6429
    Episode_Reward/rotating_object: 158.3988
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 1.88s
                      Time elapsed: 00:21:26
                               ETA: 00:29:14

################################################################################
                     [1m Learning iteration 635/1500 [0m                      

                       Computation: 51029 steps/s (collection: 1.761s, learning 0.166s)
             Mean action noise std: 2.01
          Mean value_function loss: 18.3973
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 37.0094
                       Mean reward: 808.71
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.6428
    Episode_Reward/rotating_object: 160.5234
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 1.93s
                      Time elapsed: 00:21:28
                               ETA: 00:29:12

################################################################################
                     [1m Learning iteration 636/1500 [0m                      

                       Computation: 53550 steps/s (collection: 1.735s, learning 0.101s)
             Mean action noise std: 2.01
          Mean value_function loss: 18.2430
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 37.0148
                       Mean reward: 800.18
               Mean episode length: 245.85
    Episode_Reward/reaching_object: 0.6397
    Episode_Reward/rotating_object: 160.7113
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 1.84s
                      Time elapsed: 00:21:30
                               ETA: 00:29:09

################################################################################
                     [1m Learning iteration 637/1500 [0m                      

                       Computation: 54981 steps/s (collection: 1.694s, learning 0.094s)
             Mean action noise std: 2.01
          Mean value_function loss: 21.9388
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 37.0219
                       Mean reward: 798.43
               Mean episode length: 246.40
    Episode_Reward/reaching_object: 0.6457
    Episode_Reward/rotating_object: 160.5438
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 1.79s
                      Time elapsed: 00:21:31
                               ETA: 00:29:07

################################################################################
                     [1m Learning iteration 638/1500 [0m                      

                       Computation: 54816 steps/s (collection: 1.704s, learning 0.089s)
             Mean action noise std: 2.02
          Mean value_function loss: 27.1493
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 37.0486
                       Mean reward: 788.78
               Mean episode length: 241.38
    Episode_Reward/reaching_object: 0.6329
    Episode_Reward/rotating_object: 158.1555
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 1.79s
                      Time elapsed: 00:21:33
                               ETA: 00:29:05

################################################################################
                     [1m Learning iteration 639/1500 [0m                      

                       Computation: 53613 steps/s (collection: 1.721s, learning 0.113s)
             Mean action noise std: 2.02
          Mean value_function loss: 20.6997
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 37.0842
                       Mean reward: 816.99
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6409
    Episode_Reward/rotating_object: 159.3372
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 1.83s
                      Time elapsed: 00:21:35
                               ETA: 00:29:02

################################################################################
                     [1m Learning iteration 640/1500 [0m                      

                       Computation: 53569 steps/s (collection: 1.678s, learning 0.157s)
             Mean action noise std: 2.03
          Mean value_function loss: 26.8439
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 37.1217
                       Mean reward: 800.65
               Mean episode length: 245.52
    Episode_Reward/reaching_object: 0.6229
    Episode_Reward/rotating_object: 158.8846
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 1.84s
                      Time elapsed: 00:21:37
                               ETA: 00:29:00

################################################################################
                     [1m Learning iteration 641/1500 [0m                      

                       Computation: 53994 steps/s (collection: 1.720s, learning 0.100s)
             Mean action noise std: 2.03
          Mean value_function loss: 21.5081
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 37.1438
                       Mean reward: 818.73
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6365
    Episode_Reward/rotating_object: 159.4433
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 1.82s
                      Time elapsed: 00:21:39
                               ETA: 00:28:58

################################################################################
                     [1m Learning iteration 642/1500 [0m                      

                       Computation: 53867 steps/s (collection: 1.718s, learning 0.106s)
             Mean action noise std: 2.03
          Mean value_function loss: 16.3285
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 37.1560
                       Mean reward: 798.96
               Mean episode length: 245.67
    Episode_Reward/reaching_object: 0.6371
    Episode_Reward/rotating_object: 160.1527
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 1.82s
                      Time elapsed: 00:21:41
                               ETA: 00:28:56

################################################################################
                     [1m Learning iteration 643/1500 [0m                      

                       Computation: 52982 steps/s (collection: 1.750s, learning 0.105s)
             Mean action noise std: 2.03
          Mean value_function loss: 12.6132
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 37.1572
                       Mean reward: 802.51
               Mean episode length: 248.42
    Episode_Reward/reaching_object: 0.6440
    Episode_Reward/rotating_object: 161.3792
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 1.86s
                      Time elapsed: 00:21:42
                               ETA: 00:28:53

################################################################################
                     [1m Learning iteration 644/1500 [0m                      

                       Computation: 54871 steps/s (collection: 1.689s, learning 0.102s)
             Mean action noise std: 2.03
          Mean value_function loss: 20.1264
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 37.1564
                       Mean reward: 783.67
               Mean episode length: 243.88
    Episode_Reward/reaching_object: 0.6334
    Episode_Reward/rotating_object: 159.5129
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 1.79s
                      Time elapsed: 00:21:44
                               ETA: 00:28:51

################################################################################
                     [1m Learning iteration 645/1500 [0m                      

                       Computation: 50525 steps/s (collection: 1.806s, learning 0.140s)
             Mean action noise std: 2.03
          Mean value_function loss: 14.9859
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 37.1668
                       Mean reward: 813.83
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6428
    Episode_Reward/rotating_object: 160.1659
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 1.95s
                      Time elapsed: 00:21:46
                               ETA: 00:28:49

################################################################################
                     [1m Learning iteration 646/1500 [0m                      

                       Computation: 53014 steps/s (collection: 1.672s, learning 0.182s)
             Mean action noise std: 2.04
          Mean value_function loss: 15.3265
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 37.1758
                       Mean reward: 815.79
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6429
    Episode_Reward/rotating_object: 161.1475
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 1.85s
                      Time elapsed: 00:21:48
                               ETA: 00:28:47

################################################################################
                     [1m Learning iteration 647/1500 [0m                      

                       Computation: 56806 steps/s (collection: 1.631s, learning 0.099s)
             Mean action noise std: 2.04
          Mean value_function loss: 14.2476
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 37.1913
                       Mean reward: 823.30
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6450
    Episode_Reward/rotating_object: 162.5717
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 1.73s
                      Time elapsed: 00:21:50
                               ETA: 00:28:44

################################################################################
                     [1m Learning iteration 648/1500 [0m                      

                       Computation: 53973 steps/s (collection: 1.722s, learning 0.099s)
             Mean action noise std: 2.04
          Mean value_function loss: 13.2792
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 37.1985
                       Mean reward: 809.04
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6439
    Episode_Reward/rotating_object: 160.3352
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 1.82s
                      Time elapsed: 00:21:52
                               ETA: 00:28:42

################################################################################
                     [1m Learning iteration 649/1500 [0m                      

                       Computation: 56393 steps/s (collection: 1.655s, learning 0.089s)
             Mean action noise std: 2.04
          Mean value_function loss: 21.2175
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 37.2038
                       Mean reward: 809.14
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.6410
    Episode_Reward/rotating_object: 160.0211
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 1.74s
                      Time elapsed: 00:21:53
                               ETA: 00:28:40

################################################################################
                     [1m Learning iteration 650/1500 [0m                      

                       Computation: 56517 steps/s (collection: 1.647s, learning 0.093s)
             Mean action noise std: 2.04
          Mean value_function loss: 12.1722
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 37.2076
                       Mean reward: 812.50
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6459
    Episode_Reward/rotating_object: 161.2185
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 1.74s
                      Time elapsed: 00:21:55
                               ETA: 00:28:37

################################################################################
                     [1m Learning iteration 651/1500 [0m                      

                       Computation: 55260 steps/s (collection: 1.656s, learning 0.123s)
             Mean action noise std: 2.04
          Mean value_function loss: 13.7077
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 37.2088
                       Mean reward: 809.18
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6449
    Episode_Reward/rotating_object: 160.7794
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 1.78s
                      Time elapsed: 00:21:57
                               ETA: 00:28:35

################################################################################
                     [1m Learning iteration 652/1500 [0m                      

                       Computation: 56536 steps/s (collection: 1.650s, learning 0.089s)
             Mean action noise std: 2.04
          Mean value_function loss: 19.8415
               Mean surrogate loss: 0.0014
                 Mean entropy loss: 37.2116
                       Mean reward: 794.62
               Mean episode length: 243.61
    Episode_Reward/reaching_object: 0.6445
    Episode_Reward/rotating_object: 160.3347
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 1.74s
                      Time elapsed: 00:21:59
                               ETA: 00:28:32

################################################################################
                     [1m Learning iteration 653/1500 [0m                      

                       Computation: 55326 steps/s (collection: 1.687s, learning 0.090s)
             Mean action noise std: 2.04
          Mean value_function loss: 15.3173
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 37.2120
                       Mean reward: 813.82
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6485
    Episode_Reward/rotating_object: 162.2130
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 1.78s
                      Time elapsed: 00:22:00
                               ETA: 00:28:30

################################################################################
                     [1m Learning iteration 654/1500 [0m                      

                       Computation: 55120 steps/s (collection: 1.694s, learning 0.089s)
             Mean action noise std: 2.04
          Mean value_function loss: 13.6749
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 37.2128
                       Mean reward: 817.27
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6484
    Episode_Reward/rotating_object: 162.5096
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 1.78s
                      Time elapsed: 00:22:02
                               ETA: 00:28:28

################################################################################
                     [1m Learning iteration 655/1500 [0m                      

                       Computation: 55841 steps/s (collection: 1.664s, learning 0.096s)
             Mean action noise std: 2.04
          Mean value_function loss: 14.4364
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 37.2137
                       Mean reward: 814.41
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6500
    Episode_Reward/rotating_object: 162.0840
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 1.76s
                      Time elapsed: 00:22:04
                               ETA: 00:28:25

################################################################################
                     [1m Learning iteration 656/1500 [0m                      

                       Computation: 56378 steps/s (collection: 1.652s, learning 0.091s)
             Mean action noise std: 2.04
          Mean value_function loss: 17.6926
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 37.2149
                       Mean reward: 797.09
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 0.6474
    Episode_Reward/rotating_object: 161.0197
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 1.74s
                      Time elapsed: 00:22:06
                               ETA: 00:28:23

################################################################################
                     [1m Learning iteration 657/1500 [0m                      

                       Computation: 54316 steps/s (collection: 1.712s, learning 0.098s)
             Mean action noise std: 2.04
          Mean value_function loss: 16.3159
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 37.2173
                       Mean reward: 810.36
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 0.6517
    Episode_Reward/rotating_object: 161.0289
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 1.81s
                      Time elapsed: 00:22:07
                               ETA: 00:28:21

################################################################################
                     [1m Learning iteration 658/1500 [0m                      

                       Computation: 55230 steps/s (collection: 1.679s, learning 0.101s)
             Mean action noise std: 2.04
          Mean value_function loss: 15.6879
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 37.2225
                       Mean reward: 821.51
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6541
    Episode_Reward/rotating_object: 161.3117
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 1.78s
                      Time elapsed: 00:22:09
                               ETA: 00:28:18

################################################################################
                     [1m Learning iteration 659/1500 [0m                      

                       Computation: 55641 steps/s (collection: 1.672s, learning 0.095s)
             Mean action noise std: 2.05
          Mean value_function loss: 13.1444
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 37.2300
                       Mean reward: 807.36
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 0.6570
    Episode_Reward/rotating_object: 161.5170
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 1.77s
                      Time elapsed: 00:22:11
                               ETA: 00:28:16

################################################################################
                     [1m Learning iteration 660/1500 [0m                      

                       Computation: 56650 steps/s (collection: 1.646s, learning 0.089s)
             Mean action noise std: 2.05
          Mean value_function loss: 14.2516
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 37.2366
                       Mean reward: 818.23
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6611
    Episode_Reward/rotating_object: 162.2506
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 1.74s
                      Time elapsed: 00:22:13
                               ETA: 00:28:14

################################################################################
                     [1m Learning iteration 661/1500 [0m                      

                       Computation: 55475 steps/s (collection: 1.673s, learning 0.100s)
             Mean action noise std: 2.05
          Mean value_function loss: 14.8962
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 37.2532
                       Mean reward: 797.24
               Mean episode length: 244.37
    Episode_Reward/reaching_object: 0.6569
    Episode_Reward/rotating_object: 160.6922
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 1.77s
                      Time elapsed: 00:22:14
                               ETA: 00:28:11

################################################################################
                     [1m Learning iteration 662/1500 [0m                      

                       Computation: 54833 steps/s (collection: 1.681s, learning 0.112s)
             Mean action noise std: 2.05
          Mean value_function loss: 17.8653
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 37.2703
                       Mean reward: 812.99
               Mean episode length: 247.96
    Episode_Reward/reaching_object: 0.6653
    Episode_Reward/rotating_object: 162.9996
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 1.79s
                      Time elapsed: 00:22:16
                               ETA: 00:28:09

################################################################################
                     [1m Learning iteration 663/1500 [0m                      

                       Computation: 55736 steps/s (collection: 1.652s, learning 0.111s)
             Mean action noise std: 2.05
          Mean value_function loss: 16.4454
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 37.2861
                       Mean reward: 816.76
               Mean episode length: 248.57
    Episode_Reward/reaching_object: 0.6625
    Episode_Reward/rotating_object: 161.6669
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 1.76s
                      Time elapsed: 00:22:18
                               ETA: 00:28:07

################################################################################
                     [1m Learning iteration 664/1500 [0m                      

                       Computation: 54899 steps/s (collection: 1.681s, learning 0.110s)
             Mean action noise std: 2.06
          Mean value_function loss: 13.6151
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 37.2955
                       Mean reward: 822.35
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6605
    Episode_Reward/rotating_object: 162.8987
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 1.79s
                      Time elapsed: 00:22:20
                               ETA: 00:28:04

################################################################################
                     [1m Learning iteration 665/1500 [0m                      

                       Computation: 55853 steps/s (collection: 1.671s, learning 0.089s)
             Mean action noise std: 2.06
          Mean value_function loss: 16.2064
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 37.3057
                       Mean reward: 806.14
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 0.6621
    Episode_Reward/rotating_object: 160.9919
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 1.76s
                      Time elapsed: 00:22:22
                               ETA: 00:28:02

################################################################################
                     [1m Learning iteration 666/1500 [0m                      

                       Computation: 31065 steps/s (collection: 3.056s, learning 0.108s)
             Mean action noise std: 2.06
          Mean value_function loss: 12.8820
               Mean surrogate loss: 0.0028
                 Mean entropy loss: 37.3215
                       Mean reward: 826.03
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6591
    Episode_Reward/rotating_object: 162.9692
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 3.16s
                      Time elapsed: 00:22:25
                               ETA: 00:28:02

################################################################################
                     [1m Learning iteration 667/1500 [0m                      

                       Computation: 15400 steps/s (collection: 6.241s, learning 0.142s)
             Mean action noise std: 2.06
          Mean value_function loss: 14.8579
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 37.3309
                       Mean reward: 822.63
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6642
    Episode_Reward/rotating_object: 162.4047
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 6.38s
                      Time elapsed: 00:22:31
                               ETA: 00:28:05

################################################################################
                     [1m Learning iteration 668/1500 [0m                      

                       Computation: 15151 steps/s (collection: 6.351s, learning 0.138s)
             Mean action noise std: 2.07
          Mean value_function loss: 16.9601
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 37.3526
                       Mean reward: 806.06
               Mean episode length: 243.66
    Episode_Reward/reaching_object: 0.6532
    Episode_Reward/rotating_object: 161.7904
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 6.49s
                      Time elapsed: 00:22:38
                               ETA: 00:28:08

################################################################################
                     [1m Learning iteration 669/1500 [0m                      

                       Computation: 15184 steps/s (collection: 6.354s, learning 0.119s)
             Mean action noise std: 2.07
          Mean value_function loss: 12.9577
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 37.3691
                       Mean reward: 822.10
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6560
    Episode_Reward/rotating_object: 162.0997
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 6.47s
                      Time elapsed: 00:22:44
                               ETA: 00:28:12

################################################################################
                     [1m Learning iteration 670/1500 [0m                      

                       Computation: 15335 steps/s (collection: 6.288s, learning 0.123s)
             Mean action noise std: 2.07
          Mean value_function loss: 15.0138
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 37.3859
                       Mean reward: 823.60
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6535
    Episode_Reward/rotating_object: 162.0608
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 6.41s
                      Time elapsed: 00:22:50
                               ETA: 00:28:15

################################################################################
                     [1m Learning iteration 671/1500 [0m                      

                       Computation: 15359 steps/s (collection: 6.261s, learning 0.140s)
             Mean action noise std: 2.07
          Mean value_function loss: 11.6290
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 37.4135
                       Mean reward: 822.24
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6634
    Episode_Reward/rotating_object: 163.3486
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 6.40s
                      Time elapsed: 00:22:57
                               ETA: 00:28:19

################################################################################
                     [1m Learning iteration 672/1500 [0m                      

                       Computation: 15218 steps/s (collection: 6.314s, learning 0.145s)
             Mean action noise std: 2.07
          Mean value_function loss: 16.1395
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 37.4263
                       Mean reward: 813.31
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 0.6531
    Episode_Reward/rotating_object: 161.5099
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 6.46s
                      Time elapsed: 00:23:03
                               ETA: 00:28:22

################################################################################
                     [1m Learning iteration 673/1500 [0m                      

                       Computation: 15457 steps/s (collection: 6.217s, learning 0.143s)
             Mean action noise std: 2.08
          Mean value_function loss: 21.0208
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 37.4358
                       Mean reward: 813.95
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.6527
    Episode_Reward/rotating_object: 161.1245
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 6.36s
                      Time elapsed: 00:23:10
                               ETA: 00:28:25

################################################################################
                     [1m Learning iteration 674/1500 [0m                      

                       Computation: 15315 steps/s (collection: 6.295s, learning 0.123s)
             Mean action noise std: 2.08
          Mean value_function loss: 13.0118
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 37.4407
                       Mean reward: 818.71
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6577
    Episode_Reward/rotating_object: 162.2090
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 6.42s
                      Time elapsed: 00:23:16
                               ETA: 00:28:29

################################################################################
                     [1m Learning iteration 675/1500 [0m                      

                       Computation: 24886 steps/s (collection: 3.846s, learning 0.105s)
             Mean action noise std: 2.08
          Mean value_function loss: 20.2801
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 37.4454
                       Mean reward: 792.11
               Mean episode length: 244.19
    Episode_Reward/reaching_object: 0.6509
    Episode_Reward/rotating_object: 161.8076
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 3.95s
                      Time elapsed: 00:23:20
                               ETA: 00:28:29

################################################################################
                     [1m Learning iteration 676/1500 [0m                      

                       Computation: 49335 steps/s (collection: 1.886s, learning 0.107s)
             Mean action noise std: 2.08
          Mean value_function loss: 14.3506
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 37.4551
                       Mean reward: 815.15
               Mean episode length: 248.09
    Episode_Reward/reaching_object: 0.6586
    Episode_Reward/rotating_object: 161.5685
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 1.99s
                      Time elapsed: 00:23:22
                               ETA: 00:28:27

################################################################################
                     [1m Learning iteration 677/1500 [0m                      

                       Computation: 52463 steps/s (collection: 1.780s, learning 0.094s)
             Mean action noise std: 2.08
          Mean value_function loss: 11.1134
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 37.4720
                       Mean reward: 809.56
               Mean episode length: 246.05
    Episode_Reward/reaching_object: 0.6584
    Episode_Reward/rotating_object: 162.2351
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 1.87s
                      Time elapsed: 00:23:24
                               ETA: 00:28:24

################################################################################
                     [1m Learning iteration 678/1500 [0m                      

                       Computation: 54850 steps/s (collection: 1.662s, learning 0.130s)
             Mean action noise std: 2.09
          Mean value_function loss: 16.4385
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 37.4895
                       Mean reward: 816.69
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.6552
    Episode_Reward/rotating_object: 162.3710
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 1.79s
                      Time elapsed: 00:23:26
                               ETA: 00:28:22

################################################################################
                     [1m Learning iteration 679/1500 [0m                      

                       Computation: 54773 steps/s (collection: 1.686s, learning 0.109s)
             Mean action noise std: 2.09
          Mean value_function loss: 11.4912
               Mean surrogate loss: 0.0026
                 Mean entropy loss: 37.5047
                       Mean reward: 818.90
               Mean episode length: 248.00
    Episode_Reward/reaching_object: 0.6572
    Episode_Reward/rotating_object: 163.7713
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 1.79s
                      Time elapsed: 00:23:28
                               ETA: 00:28:19

################################################################################
                     [1m Learning iteration 680/1500 [0m                      

                       Computation: 55484 steps/s (collection: 1.663s, learning 0.109s)
             Mean action noise std: 2.09
          Mean value_function loss: 12.7694
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 37.5100
                       Mean reward: 816.27
               Mean episode length: 248.05
    Episode_Reward/reaching_object: 0.6572
    Episode_Reward/rotating_object: 162.1925
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 1.77s
                      Time elapsed: 00:23:29
                               ETA: 00:28:17

################################################################################
                     [1m Learning iteration 681/1500 [0m                      

                       Computation: 56669 steps/s (collection: 1.629s, learning 0.106s)
             Mean action noise std: 2.09
          Mean value_function loss: 11.5928
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 37.5192
                       Mean reward: 814.66
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 0.6583
    Episode_Reward/rotating_object: 163.7988
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 1.73s
                      Time elapsed: 00:23:31
                               ETA: 00:28:15

################################################################################
                     [1m Learning iteration 682/1500 [0m                      

                       Computation: 56717 steps/s (collection: 1.641s, learning 0.092s)
             Mean action noise std: 2.09
          Mean value_function loss: 12.3241
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 37.5280
                       Mean reward: 819.61
               Mean episode length: 247.98
    Episode_Reward/reaching_object: 0.6573
    Episode_Reward/rotating_object: 163.3116
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 1.73s
                      Time elapsed: 00:23:33
                               ETA: 00:28:12

################################################################################
                     [1m Learning iteration 683/1500 [0m                      

                       Computation: 54408 steps/s (collection: 1.695s, learning 0.112s)
             Mean action noise std: 2.09
          Mean value_function loss: 11.6265
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 37.5346
                       Mean reward: 813.62
               Mean episode length: 247.69
    Episode_Reward/reaching_object: 0.6612
    Episode_Reward/rotating_object: 162.4002
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 1.81s
                      Time elapsed: 00:23:35
                               ETA: 00:28:10

################################################################################
                     [1m Learning iteration 684/1500 [0m                      

                       Computation: 55760 steps/s (collection: 1.674s, learning 0.089s)
             Mean action noise std: 2.10
          Mean value_function loss: 12.1736
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 37.5389
                       Mean reward: 819.08
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.6624
    Episode_Reward/rotating_object: 163.0307
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 1.76s
                      Time elapsed: 00:23:36
                               ETA: 00:28:07

################################################################################
                     [1m Learning iteration 685/1500 [0m                      

                       Computation: 55567 steps/s (collection: 1.679s, learning 0.090s)
             Mean action noise std: 2.10
          Mean value_function loss: 9.6760
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 37.5498
                       Mean reward: 826.43
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6577
    Episode_Reward/rotating_object: 163.2036
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 1.77s
                      Time elapsed: 00:23:38
                               ETA: 00:28:05

################################################################################
                     [1m Learning iteration 686/1500 [0m                      

                       Computation: 52609 steps/s (collection: 1.773s, learning 0.096s)
             Mean action noise std: 2.10
          Mean value_function loss: 14.6004
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 37.5537
                       Mean reward: 810.99
               Mean episode length: 245.85
    Episode_Reward/reaching_object: 0.6572
    Episode_Reward/rotating_object: 163.5645
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 1.87s
                      Time elapsed: 00:23:40
                               ETA: 00:28:03

################################################################################
                     [1m Learning iteration 687/1500 [0m                      

                       Computation: 56574 steps/s (collection: 1.626s, learning 0.112s)
             Mean action noise std: 2.10
          Mean value_function loss: 14.2118
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 37.5846
                       Mean reward: 817.75
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 0.6551
    Episode_Reward/rotating_object: 163.0285
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 1.74s
                      Time elapsed: 00:23:42
                               ETA: 00:28:00

################################################################################
                     [1m Learning iteration 688/1500 [0m                      

                       Computation: 55227 steps/s (collection: 1.672s, learning 0.108s)
             Mean action noise std: 2.11
          Mean value_function loss: 15.1247
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 37.6082
                       Mean reward: 810.84
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.6509
    Episode_Reward/rotating_object: 161.1949
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 1.78s
                      Time elapsed: 00:23:43
                               ETA: 00:27:58

################################################################################
                     [1m Learning iteration 689/1500 [0m                      

                       Computation: 55178 steps/s (collection: 1.669s, learning 0.112s)
             Mean action noise std: 2.11
          Mean value_function loss: 14.0160
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 37.6315
                       Mean reward: 810.14
               Mean episode length: 245.82
    Episode_Reward/reaching_object: 0.6507
    Episode_Reward/rotating_object: 162.0504
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 1.78s
                      Time elapsed: 00:23:45
                               ETA: 00:27:55

################################################################################
                     [1m Learning iteration 690/1500 [0m                      

                       Computation: 54958 steps/s (collection: 1.680s, learning 0.109s)
             Mean action noise std: 2.11
          Mean value_function loss: 9.5746
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 37.6508
                       Mean reward: 826.28
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6625
    Episode_Reward/rotating_object: 163.9559
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 1.79s
                      Time elapsed: 00:23:47
                               ETA: 00:27:53

################################################################################
                     [1m Learning iteration 691/1500 [0m                      

                       Computation: 54244 steps/s (collection: 1.714s, learning 0.098s)
             Mean action noise std: 2.11
          Mean value_function loss: 12.8649
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 37.6574
                       Mean reward: 823.78
               Mean episode length: 247.69
    Episode_Reward/reaching_object: 0.6563
    Episode_Reward/rotating_object: 164.4299
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 1.81s
                      Time elapsed: 00:23:49
                               ETA: 00:27:51

################################################################################
                     [1m Learning iteration 692/1500 [0m                      

                       Computation: 55488 steps/s (collection: 1.680s, learning 0.092s)
             Mean action noise std: 2.12
          Mean value_function loss: 14.6734
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 37.6722
                       Mean reward: 810.31
               Mean episode length: 245.84
    Episode_Reward/reaching_object: 0.6577
    Episode_Reward/rotating_object: 162.3389
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 1.77s
                      Time elapsed: 00:23:51
                               ETA: 00:27:48

################################################################################
                     [1m Learning iteration 693/1500 [0m                      

                       Computation: 54911 steps/s (collection: 1.685s, learning 0.106s)
             Mean action noise std: 2.12
          Mean value_function loss: 15.2068
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 37.6897
                       Mean reward: 819.82
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.6570
    Episode_Reward/rotating_object: 163.1912
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 1.79s
                      Time elapsed: 00:23:52
                               ETA: 00:27:46

################################################################################
                     [1m Learning iteration 694/1500 [0m                      

                       Computation: 54148 steps/s (collection: 1.720s, learning 0.096s)
             Mean action noise std: 2.12
          Mean value_function loss: 12.2542
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 37.7149
                       Mean reward: 818.25
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 0.6629
    Episode_Reward/rotating_object: 164.4948
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 1.82s
                      Time elapsed: 00:23:54
                               ETA: 00:27:43

################################################################################
                     [1m Learning iteration 695/1500 [0m                      

                       Computation: 54383 steps/s (collection: 1.714s, learning 0.094s)
             Mean action noise std: 2.12
          Mean value_function loss: 12.3794
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 37.7303
                       Mean reward: 807.26
               Mean episode length: 245.70
    Episode_Reward/reaching_object: 0.6605
    Episode_Reward/rotating_object: 162.6860
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 1.81s
                      Time elapsed: 00:23:56
                               ETA: 00:27:41

################################################################################
                     [1m Learning iteration 696/1500 [0m                      

                       Computation: 55571 steps/s (collection: 1.662s, learning 0.107s)
             Mean action noise std: 2.13
          Mean value_function loss: 15.4297
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 37.7383
                       Mean reward: 813.59
               Mean episode length: 245.51
    Episode_Reward/reaching_object: 0.6615
    Episode_Reward/rotating_object: 163.1692
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 1.77s
                      Time elapsed: 00:23:58
                               ETA: 00:27:39

################################################################################
                     [1m Learning iteration 697/1500 [0m                      

                       Computation: 56411 steps/s (collection: 1.636s, learning 0.106s)
             Mean action noise std: 2.13
          Mean value_function loss: 14.0548
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 37.7628
                       Mean reward: 816.55
               Mean episode length: 247.69
    Episode_Reward/reaching_object: 0.6717
    Episode_Reward/rotating_object: 164.9545
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 1.74s
                      Time elapsed: 00:24:00
                               ETA: 00:27:36

################################################################################
                     [1m Learning iteration 698/1500 [0m                      

                       Computation: 54068 steps/s (collection: 1.715s, learning 0.103s)
             Mean action noise std: 2.13
          Mean value_function loss: 14.8285
               Mean surrogate loss: 0.0110
                 Mean entropy loss: 37.7849
                       Mean reward: 821.77
               Mean episode length: 248.07
    Episode_Reward/reaching_object: 0.6694
    Episode_Reward/rotating_object: 164.6999
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 1.82s
                      Time elapsed: 00:24:01
                               ETA: 00:27:34

################################################################################
                     [1m Learning iteration 699/1500 [0m                      

                       Computation: 54138 steps/s (collection: 1.704s, learning 0.112s)
             Mean action noise std: 2.13
          Mean value_function loss: 18.6671
               Mean surrogate loss: 0.0025
                 Mean entropy loss: 37.7874
                       Mean reward: 815.72
               Mean episode length: 245.60
    Episode_Reward/reaching_object: 0.6729
    Episode_Reward/rotating_object: 164.3282
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 1.82s
                      Time elapsed: 00:24:03
                               ETA: 00:27:31

################################################################################
                     [1m Learning iteration 700/1500 [0m                      

                       Computation: 54460 steps/s (collection: 1.698s, learning 0.107s)
             Mean action noise std: 2.13
          Mean value_function loss: 14.4704
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 37.7892
                       Mean reward: 813.51
               Mean episode length: 246.95
    Episode_Reward/reaching_object: 0.6711
    Episode_Reward/rotating_object: 163.4865
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 1.81s
                      Time elapsed: 00:24:05
                               ETA: 00:27:29

################################################################################
                     [1m Learning iteration 701/1500 [0m                      

                       Computation: 55352 steps/s (collection: 1.681s, learning 0.095s)
             Mean action noise std: 2.13
          Mean value_function loss: 11.0225
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 37.7954
                       Mean reward: 829.25
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6771
    Episode_Reward/rotating_object: 164.0216
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 1.78s
                      Time elapsed: 00:24:07
                               ETA: 00:27:27

################################################################################
                     [1m Learning iteration 702/1500 [0m                      

                       Computation: 55181 steps/s (collection: 1.676s, learning 0.106s)
             Mean action noise std: 2.13
          Mean value_function loss: 15.3477
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 37.8048
                       Mean reward: 824.25
               Mean episode length: 248.15
    Episode_Reward/reaching_object: 0.6757
    Episode_Reward/rotating_object: 163.8430
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 1.78s
                      Time elapsed: 00:24:09
                               ETA: 00:27:24

################################################################################
                     [1m Learning iteration 703/1500 [0m                      

                       Computation: 53582 steps/s (collection: 1.735s, learning 0.100s)
             Mean action noise std: 2.14
          Mean value_function loss: 15.8849
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 37.8172
                       Mean reward: 831.05
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6786
    Episode_Reward/rotating_object: 164.6888
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 1.83s
                      Time elapsed: 00:24:10
                               ETA: 00:27:22

################################################################################
                     [1m Learning iteration 704/1500 [0m                      

                       Computation: 54614 steps/s (collection: 1.702s, learning 0.098s)
             Mean action noise std: 2.14
          Mean value_function loss: 11.6278
               Mean surrogate loss: 0.0015
                 Mean entropy loss: 37.8285
                       Mean reward: 835.14
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6823
    Episode_Reward/rotating_object: 165.5712
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 1.80s
                      Time elapsed: 00:24:12
                               ETA: 00:27:20

################################################################################
                     [1m Learning iteration 705/1500 [0m                      

                       Computation: 53917 steps/s (collection: 1.728s, learning 0.095s)
             Mean action noise std: 2.14
          Mean value_function loss: 13.0854
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 37.8389
                       Mean reward: 835.99
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6766
    Episode_Reward/rotating_object: 164.1861
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 1.82s
                      Time elapsed: 00:24:14
                               ETA: 00:27:17

################################################################################
                     [1m Learning iteration 706/1500 [0m                      

                       Computation: 55674 steps/s (collection: 1.667s, learning 0.099s)
             Mean action noise std: 2.14
          Mean value_function loss: 15.9690
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 37.8503
                       Mean reward: 820.75
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.6756
    Episode_Reward/rotating_object: 163.5960
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 1.77s
                      Time elapsed: 00:24:16
                               ETA: 00:27:15

################################################################################
                     [1m Learning iteration 707/1500 [0m                      

                       Computation: 56599 steps/s (collection: 1.641s, learning 0.096s)
             Mean action noise std: 2.14
          Mean value_function loss: 17.2887
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 37.8611
                       Mean reward: 819.58
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.6728
    Episode_Reward/rotating_object: 163.9916
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 1.74s
                      Time elapsed: 00:24:18
                               ETA: 00:27:13

################################################################################
                     [1m Learning iteration 708/1500 [0m                      

                       Computation: 56511 steps/s (collection: 1.647s, learning 0.092s)
             Mean action noise std: 2.15
          Mean value_function loss: 13.4155
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 37.8752
                       Mean reward: 827.17
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6823
    Episode_Reward/rotating_object: 165.4404
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 1.74s
                      Time elapsed: 00:24:19
                               ETA: 00:27:10

################################################################################
                     [1m Learning iteration 709/1500 [0m                      

                       Computation: 56357 steps/s (collection: 1.650s, learning 0.095s)
             Mean action noise std: 2.15
          Mean value_function loss: 15.5372
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 37.8870
                       Mean reward: 805.76
               Mean episode length: 246.14
    Episode_Reward/reaching_object: 0.6667
    Episode_Reward/rotating_object: 162.6405
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 1.74s
                      Time elapsed: 00:24:21
                               ETA: 00:27:08

################################################################################
                     [1m Learning iteration 710/1500 [0m                      

                       Computation: 57478 steps/s (collection: 1.613s, learning 0.097s)
             Mean action noise std: 2.15
          Mean value_function loss: 17.1925
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 37.9019
                       Mean reward: 811.40
               Mean episode length: 244.77
    Episode_Reward/reaching_object: 0.6691
    Episode_Reward/rotating_object: 162.6438
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 1.71s
                      Time elapsed: 00:24:23
                               ETA: 00:27:05

################################################################################
                     [1m Learning iteration 711/1500 [0m                      

                       Computation: 56810 steps/s (collection: 1.632s, learning 0.099s)
             Mean action noise std: 2.15
          Mean value_function loss: 12.9719
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 37.9267
                       Mean reward: 833.53
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6704
    Episode_Reward/rotating_object: 164.0920
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 1.73s
                      Time elapsed: 00:24:24
                               ETA: 00:27:03

################################################################################
                     [1m Learning iteration 712/1500 [0m                      

                       Computation: 57828 steps/s (collection: 1.612s, learning 0.088s)
             Mean action noise std: 2.16
          Mean value_function loss: 10.8946
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 37.9477
                       Mean reward: 832.66
               Mean episode length: 248.42
    Episode_Reward/reaching_object: 0.6748
    Episode_Reward/rotating_object: 164.0861
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 1.70s
                      Time elapsed: 00:24:26
                               ETA: 00:27:00

################################################################################
                     [1m Learning iteration 713/1500 [0m                      

                       Computation: 56028 steps/s (collection: 1.661s, learning 0.094s)
             Mean action noise std: 2.16
          Mean value_function loss: 18.3418
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 37.9613
                       Mean reward: 839.35
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6723
    Episode_Reward/rotating_object: 163.8260
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 1.75s
                      Time elapsed: 00:24:28
                               ETA: 00:26:58

################################################################################
                     [1m Learning iteration 714/1500 [0m                      

                       Computation: 57376 steps/s (collection: 1.621s, learning 0.092s)
             Mean action noise std: 2.16
          Mean value_function loss: 13.1070
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 37.9744
                       Mean reward: 818.31
               Mean episode length: 246.01
    Episode_Reward/reaching_object: 0.6788
    Episode_Reward/rotating_object: 163.6320
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 1.71s
                      Time elapsed: 00:24:30
                               ETA: 00:26:56

################################################################################
                     [1m Learning iteration 715/1500 [0m                      

                       Computation: 53092 steps/s (collection: 1.733s, learning 0.119s)
             Mean action noise std: 2.16
          Mean value_function loss: 14.3464
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 37.9883
                       Mean reward: 830.88
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6769
    Episode_Reward/rotating_object: 163.9497
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 1.85s
                      Time elapsed: 00:24:31
                               ETA: 00:26:53

################################################################################
                     [1m Learning iteration 716/1500 [0m                      

                       Computation: 56077 steps/s (collection: 1.659s, learning 0.094s)
             Mean action noise std: 2.16
          Mean value_function loss: 18.0058
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 38.0009
                       Mean reward: 832.65
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6762
    Episode_Reward/rotating_object: 162.9701
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 1.75s
                      Time elapsed: 00:24:33
                               ETA: 00:26:51

################################################################################
                     [1m Learning iteration 717/1500 [0m                      

                       Computation: 56021 steps/s (collection: 1.642s, learning 0.113s)
             Mean action noise std: 2.17
          Mean value_function loss: 13.3875
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 38.0211
                       Mean reward: 820.34
               Mean episode length: 245.82
    Episode_Reward/reaching_object: 0.6802
    Episode_Reward/rotating_object: 163.7263
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 1.75s
                      Time elapsed: 00:24:35
                               ETA: 00:26:49

################################################################################
                     [1m Learning iteration 718/1500 [0m                      

                       Computation: 56570 steps/s (collection: 1.629s, learning 0.109s)
             Mean action noise std: 2.17
          Mean value_function loss: 11.9756
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 38.0402
                       Mean reward: 828.78
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6884
    Episode_Reward/rotating_object: 164.7409
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 1.74s
                      Time elapsed: 00:24:37
                               ETA: 00:26:46

################################################################################
                     [1m Learning iteration 719/1500 [0m                      

                       Computation: 54981 steps/s (collection: 1.692s, learning 0.096s)
             Mean action noise std: 2.17
          Mean value_function loss: 16.2256
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 38.0545
                       Mean reward: 834.46
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6905
    Episode_Reward/rotating_object: 164.6817
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 1.79s
                      Time elapsed: 00:24:38
                               ETA: 00:26:44

################################################################################
                     [1m Learning iteration 720/1500 [0m                      

                       Computation: 54765 steps/s (collection: 1.694s, learning 0.101s)
             Mean action noise std: 2.18
          Mean value_function loss: 13.5285
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 38.0768
                       Mean reward: 835.24
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6866
    Episode_Reward/rotating_object: 163.9547
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 1.79s
                      Time elapsed: 00:24:40
                               ETA: 00:26:41

################################################################################
                     [1m Learning iteration 721/1500 [0m                      

                       Computation: 54912 steps/s (collection: 1.702s, learning 0.089s)
             Mean action noise std: 2.18
          Mean value_function loss: 13.4776
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 38.0981
                       Mean reward: 834.16
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6910
    Episode_Reward/rotating_object: 164.1938
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 1.79s
                      Time elapsed: 00:24:42
                               ETA: 00:26:39

################################################################################
                     [1m Learning iteration 722/1500 [0m                      

                       Computation: 56301 steps/s (collection: 1.647s, learning 0.099s)
             Mean action noise std: 2.18
          Mean value_function loss: 11.6790
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 38.1103
                       Mean reward: 811.36
               Mean episode length: 244.82
    Episode_Reward/reaching_object: 0.6933
    Episode_Reward/rotating_object: 164.8788
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 1.75s
                      Time elapsed: 00:24:44
                               ETA: 00:26:37

################################################################################
                     [1m Learning iteration 723/1500 [0m                      

                       Computation: 52379 steps/s (collection: 1.762s, learning 0.115s)
             Mean action noise std: 2.18
          Mean value_function loss: 10.0393
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 38.1162
                       Mean reward: 832.10
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6982
    Episode_Reward/rotating_object: 165.6133
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 1.88s
                      Time elapsed: 00:24:46
                               ETA: 00:26:34

################################################################################
                     [1m Learning iteration 724/1500 [0m                      

                       Computation: 54657 steps/s (collection: 1.692s, learning 0.106s)
             Mean action noise std: 2.18
          Mean value_function loss: 12.5117
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 38.1222
                       Mean reward: 822.35
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.6949
    Episode_Reward/rotating_object: 165.3470
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 1.80s
                      Time elapsed: 00:24:47
                               ETA: 00:26:32

################################################################################
                     [1m Learning iteration 725/1500 [0m                      

                       Computation: 56456 steps/s (collection: 1.644s, learning 0.098s)
             Mean action noise std: 2.18
          Mean value_function loss: 10.6268
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 38.1403
                       Mean reward: 837.46
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6876
    Episode_Reward/rotating_object: 164.4737
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 1.74s
                      Time elapsed: 00:24:49
                               ETA: 00:26:30

################################################################################
                     [1m Learning iteration 726/1500 [0m                      

                       Computation: 53012 steps/s (collection: 1.757s, learning 0.097s)
             Mean action noise std: 2.19
          Mean value_function loss: 17.6017
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 38.1550
                       Mean reward: 792.79
               Mean episode length: 241.75
    Episode_Reward/reaching_object: 0.6884
    Episode_Reward/rotating_object: 164.5688
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 1.85s
                      Time elapsed: 00:24:51
                               ETA: 00:26:28

################################################################################
                     [1m Learning iteration 727/1500 [0m                      

                       Computation: 55969 steps/s (collection: 1.665s, learning 0.091s)
             Mean action noise std: 2.19
          Mean value_function loss: 18.3892
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 38.1721
                       Mean reward: 817.90
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 0.6868
    Episode_Reward/rotating_object: 164.0748
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 1.76s
                      Time elapsed: 00:24:53
                               ETA: 00:26:25

################################################################################
                     [1m Learning iteration 728/1500 [0m                      

                       Computation: 55689 steps/s (collection: 1.658s, learning 0.108s)
             Mean action noise std: 2.19
          Mean value_function loss: 16.5568
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 38.1977
                       Mean reward: 813.15
               Mean episode length: 246.49
    Episode_Reward/reaching_object: 0.6793
    Episode_Reward/rotating_object: 163.9339
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 1.77s
                      Time elapsed: 00:24:55
                               ETA: 00:26:23

################################################################################
                     [1m Learning iteration 729/1500 [0m                      

                       Computation: 53750 steps/s (collection: 1.728s, learning 0.101s)
             Mean action noise std: 2.20
          Mean value_function loss: 13.6982
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 38.2174
                       Mean reward: 831.25
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.6807
    Episode_Reward/rotating_object: 164.1498
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 1.83s
                      Time elapsed: 00:24:56
                               ETA: 00:26:21

################################################################################
                     [1m Learning iteration 730/1500 [0m                      

                       Computation: 54996 steps/s (collection: 1.693s, learning 0.095s)
             Mean action noise std: 2.20
          Mean value_function loss: 16.4206
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 38.2346
                       Mean reward: 831.24
               Mean episode length: 247.68
    Episode_Reward/reaching_object: 0.6779
    Episode_Reward/rotating_object: 164.6096
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 1.79s
                      Time elapsed: 00:24:58
                               ETA: 00:26:18

################################################################################
                     [1m Learning iteration 731/1500 [0m                      

                       Computation: 55419 steps/s (collection: 1.682s, learning 0.092s)
             Mean action noise std: 2.20
          Mean value_function loss: 15.4799
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 38.2504
                       Mean reward: 836.63
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6885
    Episode_Reward/rotating_object: 166.1196
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 1.77s
                      Time elapsed: 00:25:00
                               ETA: 00:26:16

################################################################################
                     [1m Learning iteration 732/1500 [0m                      

                       Computation: 54823 steps/s (collection: 1.686s, learning 0.107s)
             Mean action noise std: 2.20
          Mean value_function loss: 10.4418
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 38.2595
                       Mean reward: 827.07
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6879
    Episode_Reward/rotating_object: 163.6008
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 1.79s
                      Time elapsed: 00:25:02
                               ETA: 00:26:14

################################################################################
                     [1m Learning iteration 733/1500 [0m                      

                       Computation: 56824 steps/s (collection: 1.627s, learning 0.103s)
             Mean action noise std: 2.20
          Mean value_function loss: 15.1761
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 38.2660
                       Mean reward: 824.72
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 0.6910
    Episode_Reward/rotating_object: 164.3257
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 1.73s
                      Time elapsed: 00:25:04
                               ETA: 00:26:11

################################################################################
                     [1m Learning iteration 734/1500 [0m                      

                       Computation: 54299 steps/s (collection: 1.701s, learning 0.109s)
             Mean action noise std: 2.20
          Mean value_function loss: 15.4733
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 38.2721
                       Mean reward: 830.96
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 0.6886
    Episode_Reward/rotating_object: 165.6398
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 1.81s
                      Time elapsed: 00:25:05
                               ETA: 00:26:09

################################################################################
                     [1m Learning iteration 735/1500 [0m                      

                       Computation: 54257 steps/s (collection: 1.711s, learning 0.101s)
             Mean action noise std: 2.21
          Mean value_function loss: 16.0996
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 38.2844
                       Mean reward: 820.41
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 0.6884
    Episode_Reward/rotating_object: 164.2103
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 1.81s
                      Time elapsed: 00:25:07
                               ETA: 00:26:07

################################################################################
                     [1m Learning iteration 736/1500 [0m                      

                       Computation: 54336 steps/s (collection: 1.711s, learning 0.099s)
             Mean action noise std: 2.21
          Mean value_function loss: 15.2788
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 38.2903
                       Mean reward: 831.19
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.6907
    Episode_Reward/rotating_object: 165.6154
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 1.81s
                      Time elapsed: 00:25:09
                               ETA: 00:26:04

################################################################################
                     [1m Learning iteration 737/1500 [0m                      

                       Computation: 56212 steps/s (collection: 1.661s, learning 0.088s)
             Mean action noise std: 2.21
          Mean value_function loss: 15.0153
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 38.3052
                       Mean reward: 821.98
               Mean episode length: 245.75
    Episode_Reward/reaching_object: 0.6919
    Episode_Reward/rotating_object: 164.5255
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 1.75s
                      Time elapsed: 00:25:11
                               ETA: 00:26:02

################################################################################
                     [1m Learning iteration 738/1500 [0m                      

                       Computation: 56685 steps/s (collection: 1.645s, learning 0.090s)
             Mean action noise std: 2.21
          Mean value_function loss: 12.5008
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 38.3326
                       Mean reward: 836.84
               Mean episode length: 248.13
    Episode_Reward/reaching_object: 0.6912
    Episode_Reward/rotating_object: 164.5703
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 1.73s
                      Time elapsed: 00:25:12
                               ETA: 00:26:00

################################################################################
                     [1m Learning iteration 739/1500 [0m                      

                       Computation: 55377 steps/s (collection: 1.657s, learning 0.118s)
             Mean action noise std: 2.22
          Mean value_function loss: 16.1900
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 38.3483
                       Mean reward: 826.72
               Mean episode length: 245.90
    Episode_Reward/reaching_object: 0.6875
    Episode_Reward/rotating_object: 164.3899
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 1.78s
                      Time elapsed: 00:25:14
                               ETA: 00:25:57

################################################################################
                     [1m Learning iteration 740/1500 [0m                      

                       Computation: 56631 steps/s (collection: 1.634s, learning 0.102s)
             Mean action noise std: 2.22
          Mean value_function loss: 15.0507
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 38.3625
                       Mean reward: 831.94
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.6929
    Episode_Reward/rotating_object: 166.7930
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 1.74s
                      Time elapsed: 00:25:16
                               ETA: 00:25:55

################################################################################
                     [1m Learning iteration 741/1500 [0m                      

                       Computation: 56636 steps/s (collection: 1.641s, learning 0.095s)
             Mean action noise std: 2.22
          Mean value_function loss: 15.6432
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 38.3809
                       Mean reward: 833.98
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 0.6899
    Episode_Reward/rotating_object: 165.0424
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 1.74s
                      Time elapsed: 00:25:18
                               ETA: 00:25:52

################################################################################
                     [1m Learning iteration 742/1500 [0m                      

                       Computation: 56656 steps/s (collection: 1.643s, learning 0.092s)
             Mean action noise std: 2.22
          Mean value_function loss: 16.4509
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 38.4011
                       Mean reward: 821.33
               Mean episode length: 248.85
    Episode_Reward/reaching_object: 0.6876
    Episode_Reward/rotating_object: 164.3320
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 1.74s
                      Time elapsed: 00:25:19
                               ETA: 00:25:50

################################################################################
                     [1m Learning iteration 743/1500 [0m                      

                       Computation: 56228 steps/s (collection: 1.652s, learning 0.097s)
             Mean action noise std: 2.23
          Mean value_function loss: 21.4822
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 38.4275
                       Mean reward: 820.42
               Mean episode length: 245.89
    Episode_Reward/reaching_object: 0.6897
    Episode_Reward/rotating_object: 163.2618
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 1.75s
                      Time elapsed: 00:25:21
                               ETA: 00:25:48

################################################################################
                     [1m Learning iteration 744/1500 [0m                      

                       Computation: 56211 steps/s (collection: 1.646s, learning 0.103s)
             Mean action noise std: 2.23
          Mean value_function loss: 21.1761
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 38.4422
                       Mean reward: 828.44
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.6809
    Episode_Reward/rotating_object: 162.3429
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 1.75s
                      Time elapsed: 00:25:23
                               ETA: 00:25:45

################################################################################
                     [1m Learning iteration 745/1500 [0m                      

                       Computation: 57124 steps/s (collection: 1.629s, learning 0.092s)
             Mean action noise std: 2.23
          Mean value_function loss: 13.7861
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 38.4528
                       Mean reward: 831.78
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 0.6877
    Episode_Reward/rotating_object: 164.9134
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 1.72s
                      Time elapsed: 00:25:25
                               ETA: 00:25:43

################################################################################
                     [1m Learning iteration 746/1500 [0m                      

                       Computation: 56603 steps/s (collection: 1.640s, learning 0.097s)
             Mean action noise std: 2.23
          Mean value_function loss: 12.5106
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 38.4633
                       Mean reward: 839.67
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6902
    Episode_Reward/rotating_object: 165.5362
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 1.74s
                      Time elapsed: 00:25:26
                               ETA: 00:25:41

################################################################################
                     [1m Learning iteration 747/1500 [0m                      

                       Computation: 57311 steps/s (collection: 1.626s, learning 0.089s)
             Mean action noise std: 2.23
          Mean value_function loss: 12.9079
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 38.4665
                       Mean reward: 813.85
               Mean episode length: 245.16
    Episode_Reward/reaching_object: 0.6834
    Episode_Reward/rotating_object: 163.8829
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 1.72s
                      Time elapsed: 00:25:28
                               ETA: 00:25:38

################################################################################
                     [1m Learning iteration 748/1500 [0m                      

                       Computation: 57343 steps/s (collection: 1.625s, learning 0.090s)
             Mean action noise std: 2.24
          Mean value_function loss: 17.8284
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 38.4727
                       Mean reward: 816.67
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 0.6901
    Episode_Reward/rotating_object: 164.7741
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 1.71s
                      Time elapsed: 00:25:30
                               ETA: 00:25:36

################################################################################
                     [1m Learning iteration 749/1500 [0m                      

                       Computation: 56770 steps/s (collection: 1.629s, learning 0.103s)
             Mean action noise std: 2.24
          Mean value_function loss: 19.6561
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 38.4859
                       Mean reward: 813.58
               Mean episode length: 243.83
    Episode_Reward/reaching_object: 0.6800
    Episode_Reward/rotating_object: 162.3941
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 1.73s
                      Time elapsed: 00:25:32
                               ETA: 00:25:34

################################################################################
                     [1m Learning iteration 750/1500 [0m                      

                       Computation: 56264 steps/s (collection: 1.634s, learning 0.113s)
             Mean action noise std: 2.24
          Mean value_function loss: 12.4807
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 38.5148
                       Mean reward: 834.33
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 0.6877
    Episode_Reward/rotating_object: 164.1542
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 1.75s
                      Time elapsed: 00:25:33
                               ETA: 00:25:31

################################################################################
                     [1m Learning iteration 751/1500 [0m                      

                       Computation: 55895 steps/s (collection: 1.651s, learning 0.108s)
             Mean action noise std: 2.24
          Mean value_function loss: 20.5469
               Mean surrogate loss: 0.0031
                 Mean entropy loss: 38.5403
                       Mean reward: 807.18
               Mean episode length: 243.55
    Episode_Reward/reaching_object: 0.6812
    Episode_Reward/rotating_object: 163.8582
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 1.76s
                      Time elapsed: 00:25:35
                               ETA: 00:25:29

################################################################################
                     [1m Learning iteration 752/1500 [0m                      

                       Computation: 56981 steps/s (collection: 1.639s, learning 0.087s)
             Mean action noise std: 2.24
          Mean value_function loss: 16.1291
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 38.5449
                       Mean reward: 833.41
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 0.6829
    Episode_Reward/rotating_object: 165.1937
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 1.73s
                      Time elapsed: 00:25:37
                               ETA: 00:25:27

################################################################################
                     [1m Learning iteration 753/1500 [0m                      

                       Computation: 56679 steps/s (collection: 1.642s, learning 0.093s)
             Mean action noise std: 2.25
          Mean value_function loss: 13.0137
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 38.5492
                       Mean reward: 823.73
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 0.6842
    Episode_Reward/rotating_object: 165.4933
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 1.73s
                      Time elapsed: 00:25:39
                               ETA: 00:25:24

################################################################################
                     [1m Learning iteration 754/1500 [0m                      

                       Computation: 56130 steps/s (collection: 1.656s, learning 0.095s)
             Mean action noise std: 2.25
          Mean value_function loss: 16.6987
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 38.5515
                       Mean reward: 820.26
               Mean episode length: 247.40
    Episode_Reward/reaching_object: 0.6851
    Episode_Reward/rotating_object: 164.5371
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 1.75s
                      Time elapsed: 00:25:40
                               ETA: 00:25:22

################################################################################
                     [1m Learning iteration 755/1500 [0m                      

                       Computation: 55864 steps/s (collection: 1.658s, learning 0.102s)
             Mean action noise std: 2.25
          Mean value_function loss: 13.3850
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 38.5586
                       Mean reward: 831.44
               Mean episode length: 248.90
    Episode_Reward/reaching_object: 0.6911
    Episode_Reward/rotating_object: 166.1166
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 1.76s
                      Time elapsed: 00:25:42
                               ETA: 00:25:20

################################################################################
                     [1m Learning iteration 756/1500 [0m                      

                       Computation: 56737 steps/s (collection: 1.623s, learning 0.109s)
             Mean action noise std: 2.25
          Mean value_function loss: 16.9769
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 38.5708
                       Mean reward: 823.06
               Mean episode length: 247.97
    Episode_Reward/reaching_object: 0.6873
    Episode_Reward/rotating_object: 164.7204
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 1.73s
                      Time elapsed: 00:25:44
                               ETA: 00:25:17

################################################################################
                     [1m Learning iteration 757/1500 [0m                      

                       Computation: 56548 steps/s (collection: 1.645s, learning 0.093s)
             Mean action noise std: 2.25
          Mean value_function loss: 15.3050
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 38.5832
                       Mean reward: 823.91
               Mean episode length: 249.64
    Episode_Reward/reaching_object: 0.6892
    Episode_Reward/rotating_object: 165.5595
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 1.74s
                      Time elapsed: 00:25:45
                               ETA: 00:25:15

################################################################################
                     [1m Learning iteration 758/1500 [0m                      

                       Computation: 56573 steps/s (collection: 1.644s, learning 0.094s)
             Mean action noise std: 2.26
          Mean value_function loss: 14.9393
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 38.6024
                       Mean reward: 842.41
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6815
    Episode_Reward/rotating_object: 164.3798
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 1.74s
                      Time elapsed: 00:25:47
                               ETA: 00:25:13

################################################################################
                     [1m Learning iteration 759/1500 [0m                      

                       Computation: 56415 steps/s (collection: 1.646s, learning 0.097s)
             Mean action noise std: 2.26
          Mean value_function loss: 14.7077
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 38.6236
                       Mean reward: 816.03
               Mean episode length: 246.05
    Episode_Reward/reaching_object: 0.6860
    Episode_Reward/rotating_object: 164.9733
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 1.74s
                      Time elapsed: 00:25:49
                               ETA: 00:25:10

################################################################################
                     [1m Learning iteration 760/1500 [0m                      

                       Computation: 57202 steps/s (collection: 1.627s, learning 0.092s)
             Mean action noise std: 2.26
          Mean value_function loss: 16.4713
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 38.6493
                       Mean reward: 810.85
               Mean episode length: 243.84
    Episode_Reward/reaching_object: 0.6880
    Episode_Reward/rotating_object: 166.1027
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 1.72s
                      Time elapsed: 00:25:51
                               ETA: 00:25:08

################################################################################
                     [1m Learning iteration 761/1500 [0m                      

                       Computation: 56113 steps/s (collection: 1.651s, learning 0.101s)
             Mean action noise std: 2.26
          Mean value_function loss: 12.4993
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 38.6690
                       Mean reward: 835.25
               Mean episode length: 248.18
    Episode_Reward/reaching_object: 0.6852
    Episode_Reward/rotating_object: 165.5121
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 1.75s
                      Time elapsed: 00:25:52
                               ETA: 00:25:06

################################################################################
                     [1m Learning iteration 762/1500 [0m                      

                       Computation: 56495 steps/s (collection: 1.648s, learning 0.092s)
             Mean action noise std: 2.27
          Mean value_function loss: 13.0829
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 38.6784
                       Mean reward: 816.52
               Mean episode length: 245.77
    Episode_Reward/reaching_object: 0.6835
    Episode_Reward/rotating_object: 163.1153
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 1.74s
                      Time elapsed: 00:25:54
                               ETA: 00:25:03

################################################################################
                     [1m Learning iteration 763/1500 [0m                      

                       Computation: 56386 steps/s (collection: 1.651s, learning 0.093s)
             Mean action noise std: 2.27
          Mean value_function loss: 11.1707
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 38.6891
                       Mean reward: 818.58
               Mean episode length: 245.58
    Episode_Reward/reaching_object: 0.6918
    Episode_Reward/rotating_object: 165.9951
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 1.74s
                      Time elapsed: 00:25:56
                               ETA: 00:25:01

################################################################################
                     [1m Learning iteration 764/1500 [0m                      

                       Computation: 57326 steps/s (collection: 1.626s, learning 0.089s)
             Mean action noise std: 2.27
          Mean value_function loss: 10.0784
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 38.6946
                       Mean reward: 828.33
               Mean episode length: 248.07
    Episode_Reward/reaching_object: 0.6943
    Episode_Reward/rotating_object: 165.9361
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 1.71s
                      Time elapsed: 00:25:58
                               ETA: 00:24:59

################################################################################
                     [1m Learning iteration 765/1500 [0m                      

                       Computation: 57115 steps/s (collection: 1.631s, learning 0.090s)
             Mean action noise std: 2.27
          Mean value_function loss: 18.9563
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 38.7081
                       Mean reward: 818.72
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 0.6875
    Episode_Reward/rotating_object: 164.7789
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 1.72s
                      Time elapsed: 00:25:59
                               ETA: 00:24:56

################################################################################
                     [1m Learning iteration 766/1500 [0m                      

                       Computation: 56471 steps/s (collection: 1.630s, learning 0.110s)
             Mean action noise std: 2.27
          Mean value_function loss: 14.3573
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 38.7300
                       Mean reward: 834.82
               Mean episode length: 248.00
    Episode_Reward/reaching_object: 0.6976
    Episode_Reward/rotating_object: 164.3261
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 1.74s
                      Time elapsed: 00:26:01
                               ETA: 00:24:54

################################################################################
                     [1m Learning iteration 767/1500 [0m                      

                       Computation: 56604 steps/s (collection: 1.633s, learning 0.104s)
             Mean action noise std: 2.28
          Mean value_function loss: 13.8828
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 38.7396
                       Mean reward: 840.21
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6981
    Episode_Reward/rotating_object: 165.6987
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 1.74s
                      Time elapsed: 00:26:03
                               ETA: 00:24:52

################################################################################
                     [1m Learning iteration 768/1500 [0m                      

                       Computation: 56008 steps/s (collection: 1.656s, learning 0.100s)
             Mean action noise std: 2.28
          Mean value_function loss: 14.6606
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 38.7494
                       Mean reward: 820.85
               Mean episode length: 245.49
    Episode_Reward/reaching_object: 0.6993
    Episode_Reward/rotating_object: 165.1315
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 1.76s
                      Time elapsed: 00:26:05
                               ETA: 00:24:49

################################################################################
                     [1m Learning iteration 769/1500 [0m                      

                       Computation: 56319 steps/s (collection: 1.646s, learning 0.099s)
             Mean action noise std: 2.28
          Mean value_function loss: 11.5172
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 38.7626
                       Mean reward: 837.09
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7049
    Episode_Reward/rotating_object: 165.9366
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 1.75s
                      Time elapsed: 00:26:06
                               ETA: 00:24:47

################################################################################
                     [1m Learning iteration 770/1500 [0m                      

                       Computation: 55405 steps/s (collection: 1.683s, learning 0.092s)
             Mean action noise std: 2.28
          Mean value_function loss: 17.5302
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 38.7740
                       Mean reward: 840.16
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.6933
    Episode_Reward/rotating_object: 164.7240
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 1.77s
                      Time elapsed: 00:26:08
                               ETA: 00:24:45

################################################################################
                     [1m Learning iteration 771/1500 [0m                      

                       Computation: 53718 steps/s (collection: 1.731s, learning 0.099s)
             Mean action noise std: 2.28
          Mean value_function loss: 13.8979
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 38.7895
                       Mean reward: 828.50
               Mean episode length: 248.17
    Episode_Reward/reaching_object: 0.7038
    Episode_Reward/rotating_object: 164.6446
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 1.83s
                      Time elapsed: 00:26:10
                               ETA: 00:24:42

################################################################################
                     [1m Learning iteration 772/1500 [0m                      

                       Computation: 55173 steps/s (collection: 1.684s, learning 0.098s)
             Mean action noise std: 2.29
          Mean value_function loss: 12.2657
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 38.8018
                       Mean reward: 841.56
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7010
    Episode_Reward/rotating_object: 166.2727
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 1.78s
                      Time elapsed: 00:26:12
                               ETA: 00:24:40

################################################################################
                     [1m Learning iteration 773/1500 [0m                      

                       Computation: 54578 steps/s (collection: 1.688s, learning 0.113s)
             Mean action noise std: 2.29
          Mean value_function loss: 10.5726
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 38.8165
                       Mean reward: 824.64
               Mean episode length: 245.78
    Episode_Reward/reaching_object: 0.6972
    Episode_Reward/rotating_object: 164.9635
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 1.80s
                      Time elapsed: 00:26:14
                               ETA: 00:24:38

################################################################################
                     [1m Learning iteration 774/1500 [0m                      

                       Computation: 56141 steps/s (collection: 1.637s, learning 0.114s)
             Mean action noise std: 2.29
          Mean value_function loss: 12.9740
               Mean surrogate loss: 0.0021
                 Mean entropy loss: 38.8279
                       Mean reward: 830.21
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7060
    Episode_Reward/rotating_object: 166.6744
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 1.75s
                      Time elapsed: 00:26:15
                               ETA: 00:24:36

################################################################################
                     [1m Learning iteration 775/1500 [0m                      

                       Computation: 56334 steps/s (collection: 1.635s, learning 0.110s)
             Mean action noise std: 2.29
          Mean value_function loss: 13.9176
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 38.8353
                       Mean reward: 830.47
               Mean episode length: 245.39
    Episode_Reward/reaching_object: 0.6981
    Episode_Reward/rotating_object: 166.5178
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 1.74s
                      Time elapsed: 00:26:17
                               ETA: 00:24:33

################################################################################
                     [1m Learning iteration 776/1500 [0m                      

                       Computation: 56356 steps/s (collection: 1.651s, learning 0.093s)
             Mean action noise std: 2.29
          Mean value_function loss: 13.7809
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 38.8466
                       Mean reward: 825.00
               Mean episode length: 248.21
    Episode_Reward/reaching_object: 0.7015
    Episode_Reward/rotating_object: 165.5604
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 1.74s
                      Time elapsed: 00:26:19
                               ETA: 00:24:31

################################################################################
                     [1m Learning iteration 777/1500 [0m                      

                       Computation: 56139 steps/s (collection: 1.642s, learning 0.110s)
             Mean action noise std: 2.29
          Mean value_function loss: 11.8032
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 38.8563
                       Mean reward: 846.54
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7000
    Episode_Reward/rotating_object: 166.6969
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 1.75s
                      Time elapsed: 00:26:21
                               ETA: 00:24:29

################################################################################
                     [1m Learning iteration 778/1500 [0m                      

                       Computation: 55514 steps/s (collection: 1.680s, learning 0.091s)
             Mean action noise std: 2.30
          Mean value_function loss: 13.5711
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 38.8687
                       Mean reward: 846.98
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7002
    Episode_Reward/rotating_object: 165.8437
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 1.77s
                      Time elapsed: 00:26:22
                               ETA: 00:24:26

################################################################################
                     [1m Learning iteration 779/1500 [0m                      

                       Computation: 56677 steps/s (collection: 1.639s, learning 0.095s)
             Mean action noise std: 2.30
          Mean value_function loss: 11.6269
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 38.8848
                       Mean reward: 837.63
               Mean episode length: 248.04
    Episode_Reward/reaching_object: 0.7063
    Episode_Reward/rotating_object: 167.4598
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 1.73s
                      Time elapsed: 00:26:24
                               ETA: 00:24:24

################################################################################
                     [1m Learning iteration 780/1500 [0m                      

                       Computation: 55876 steps/s (collection: 1.664s, learning 0.095s)
             Mean action noise std: 2.30
          Mean value_function loss: 15.8020
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 38.8899
                       Mean reward: 823.43
               Mean episode length: 246.70
    Episode_Reward/reaching_object: 0.6984
    Episode_Reward/rotating_object: 164.7194
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 1.76s
                      Time elapsed: 00:26:26
                               ETA: 00:24:22

################################################################################
                     [1m Learning iteration 781/1500 [0m                      

                       Computation: 56311 steps/s (collection: 1.652s, learning 0.094s)
             Mean action noise std: 2.30
          Mean value_function loss: 16.7512
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 38.9026
                       Mean reward: 819.99
               Mean episode length: 245.36
    Episode_Reward/reaching_object: 0.6966
    Episode_Reward/rotating_object: 165.6300
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 1.75s
                      Time elapsed: 00:26:28
                               ETA: 00:24:20

################################################################################
                     [1m Learning iteration 782/1500 [0m                      

                       Computation: 56250 steps/s (collection: 1.657s, learning 0.091s)
             Mean action noise std: 2.31
          Mean value_function loss: 12.9879
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 38.9228
                       Mean reward: 839.45
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.6960
    Episode_Reward/rotating_object: 165.1690
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 1.75s
                      Time elapsed: 00:26:29
                               ETA: 00:24:17

################################################################################
                     [1m Learning iteration 783/1500 [0m                      

                       Computation: 55527 steps/s (collection: 1.672s, learning 0.098s)
             Mean action noise std: 2.31
          Mean value_function loss: 13.5893
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 38.9349
                       Mean reward: 832.46
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7020
    Episode_Reward/rotating_object: 165.5284
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 1.77s
                      Time elapsed: 00:26:31
                               ETA: 00:24:15

################################################################################
                     [1m Learning iteration 784/1500 [0m                      

                       Computation: 56255 steps/s (collection: 1.658s, learning 0.090s)
             Mean action noise std: 2.31
          Mean value_function loss: 18.5673
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 38.9484
                       Mean reward: 832.87
               Mean episode length: 245.62
    Episode_Reward/reaching_object: 0.6991
    Episode_Reward/rotating_object: 164.6797
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 1.75s
                      Time elapsed: 00:26:33
                               ETA: 00:24:13

################################################################################
                     [1m Learning iteration 785/1500 [0m                      

                       Computation: 55067 steps/s (collection: 1.693s, learning 0.092s)
             Mean action noise std: 2.31
          Mean value_function loss: 16.4509
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 38.9651
                       Mean reward: 834.76
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 0.7015
    Episode_Reward/rotating_object: 165.6212
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 1.79s
                      Time elapsed: 00:26:35
                               ETA: 00:24:10

################################################################################
                     [1m Learning iteration 786/1500 [0m                      

                       Computation: 54553 steps/s (collection: 1.676s, learning 0.126s)
             Mean action noise std: 2.32
          Mean value_function loss: 8.7663
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 38.9812
                       Mean reward: 842.18
               Mean episode length: 248.71
    Episode_Reward/reaching_object: 0.7104
    Episode_Reward/rotating_object: 168.4924
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 1.80s
                      Time elapsed: 00:26:36
                               ETA: 00:24:08

################################################################################
                     [1m Learning iteration 787/1500 [0m                      

                       Computation: 57023 steps/s (collection: 1.616s, learning 0.108s)
             Mean action noise std: 2.32
          Mean value_function loss: 15.0067
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 38.9955
                       Mean reward: 848.52
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7000
    Episode_Reward/rotating_object: 165.0385
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 1.72s
                      Time elapsed: 00:26:38
                               ETA: 00:24:06

################################################################################
                     [1m Learning iteration 788/1500 [0m                      

                       Computation: 57315 steps/s (collection: 1.625s, learning 0.091s)
             Mean action noise std: 2.32
          Mean value_function loss: 11.3526
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 39.0042
                       Mean reward: 840.90
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7102
    Episode_Reward/rotating_object: 166.5474
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 1.72s
                      Time elapsed: 00:26:40
                               ETA: 00:24:04

################################################################################
                     [1m Learning iteration 789/1500 [0m                      

                       Computation: 56597 steps/s (collection: 1.648s, learning 0.089s)
             Mean action noise std: 2.32
          Mean value_function loss: 9.5719
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 39.0162
                       Mean reward: 843.60
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7137
    Episode_Reward/rotating_object: 167.3828
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 1.74s
                      Time elapsed: 00:26:42
                               ETA: 00:24:01

################################################################################
                     [1m Learning iteration 790/1500 [0m                      

                       Computation: 56895 steps/s (collection: 1.638s, learning 0.090s)
             Mean action noise std: 2.32
          Mean value_function loss: 10.9310
               Mean surrogate loss: 0.0015
                 Mean entropy loss: 39.0222
                       Mean reward: 831.90
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7112
    Episode_Reward/rotating_object: 166.0628
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 1.73s
                      Time elapsed: 00:26:43
                               ETA: 00:23:59

################################################################################
                     [1m Learning iteration 791/1500 [0m                      

                       Computation: 56685 steps/s (collection: 1.642s, learning 0.092s)
             Mean action noise std: 2.32
          Mean value_function loss: 11.5540
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 39.0244
                       Mean reward: 841.81
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 0.7066
    Episode_Reward/rotating_object: 164.9507
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 1.73s
                      Time elapsed: 00:26:45
                               ETA: 00:23:57

################################################################################
                     [1m Learning iteration 792/1500 [0m                      

                       Computation: 55996 steps/s (collection: 1.666s, learning 0.089s)
             Mean action noise std: 2.33
          Mean value_function loss: 10.0446
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 39.0405
                       Mean reward: 848.85
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7175
    Episode_Reward/rotating_object: 168.3517
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 1.76s
                      Time elapsed: 00:26:47
                               ETA: 00:23:54

################################################################################
                     [1m Learning iteration 793/1500 [0m                      

                       Computation: 55602 steps/s (collection: 1.657s, learning 0.111s)
             Mean action noise std: 2.33
          Mean value_function loss: 10.4402
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 39.0586
                       Mean reward: 837.28
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7171
    Episode_Reward/rotating_object: 167.2481
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 1.77s
                      Time elapsed: 00:26:49
                               ETA: 00:23:52

################################################################################
                     [1m Learning iteration 794/1500 [0m                      

                       Computation: 56466 steps/s (collection: 1.650s, learning 0.091s)
             Mean action noise std: 2.33
          Mean value_function loss: 8.6533
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 39.0629
                       Mean reward: 827.44
               Mean episode length: 246.75
    Episode_Reward/reaching_object: 0.7163
    Episode_Reward/rotating_object: 165.8608
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 1.74s
                      Time elapsed: 00:26:50
                               ETA: 00:23:50

################################################################################
                     [1m Learning iteration 795/1500 [0m                      

                       Computation: 56239 steps/s (collection: 1.658s, learning 0.090s)
             Mean action noise std: 2.33
          Mean value_function loss: 13.8271
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 39.0714
                       Mean reward: 850.10
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7249
    Episode_Reward/rotating_object: 168.2777
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 1.75s
                      Time elapsed: 00:26:52
                               ETA: 00:23:48

################################################################################
                     [1m Learning iteration 796/1500 [0m                      

                       Computation: 56643 steps/s (collection: 1.648s, learning 0.088s)
             Mean action noise std: 2.33
          Mean value_function loss: 12.8256
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 39.0798
                       Mean reward: 846.60
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7209
    Episode_Reward/rotating_object: 167.0749
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 1.74s
                      Time elapsed: 00:26:54
                               ETA: 00:23:45

################################################################################
                     [1m Learning iteration 797/1500 [0m                      

                       Computation: 56199 steps/s (collection: 1.653s, learning 0.096s)
             Mean action noise std: 2.34
          Mean value_function loss: 10.8093
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 39.0829
                       Mean reward: 837.87
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7163
    Episode_Reward/rotating_object: 167.1885
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 1.75s
                      Time elapsed: 00:26:56
                               ETA: 00:23:43

################################################################################
                     [1m Learning iteration 798/1500 [0m                      

                       Computation: 56352 steps/s (collection: 1.648s, learning 0.096s)
             Mean action noise std: 2.34
          Mean value_function loss: 12.2408
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 39.0837
                       Mean reward: 850.22
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7155
    Episode_Reward/rotating_object: 167.1465
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 1.74s
                      Time elapsed: 00:26:57
                               ETA: 00:23:41

################################################################################
                     [1m Learning iteration 799/1500 [0m                      

                       Computation: 56439 steps/s (collection: 1.650s, learning 0.092s)
             Mean action noise std: 2.34
          Mean value_function loss: 15.1818
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 39.0927
                       Mean reward: 826.73
               Mean episode length: 245.65
    Episode_Reward/reaching_object: 0.7083
    Episode_Reward/rotating_object: 167.0581
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 1.74s
                      Time elapsed: 00:26:59
                               ETA: 00:23:39

################################################################################
                     [1m Learning iteration 800/1500 [0m                      

                       Computation: 56486 steps/s (collection: 1.645s, learning 0.096s)
             Mean action noise std: 2.34
          Mean value_function loss: 15.9585
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 39.1138
                       Mean reward: 810.23
               Mean episode length: 240.68
    Episode_Reward/reaching_object: 0.7070
    Episode_Reward/rotating_object: 166.7624
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 1.74s
                      Time elapsed: 00:27:01
                               ETA: 00:23:36

################################################################################
                     [1m Learning iteration 801/1500 [0m                      

                       Computation: 55901 steps/s (collection: 1.647s, learning 0.112s)
             Mean action noise std: 2.34
          Mean value_function loss: 9.7092
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 39.1279
                       Mean reward: 853.12
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6983
    Episode_Reward/rotating_object: 167.1157
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 1.76s
                      Time elapsed: 00:27:02
                               ETA: 00:23:34

################################################################################
                     [1m Learning iteration 802/1500 [0m                      

                       Computation: 56500 steps/s (collection: 1.637s, learning 0.103s)
             Mean action noise std: 2.35
          Mean value_function loss: 9.0311
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 39.1452
                       Mean reward: 853.37
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7014
    Episode_Reward/rotating_object: 169.3805
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 1.74s
                      Time elapsed: 00:27:04
                               ETA: 00:23:32

################################################################################
                     [1m Learning iteration 803/1500 [0m                      

                       Computation: 56047 steps/s (collection: 1.660s, learning 0.094s)
             Mean action noise std: 2.35
          Mean value_function loss: 11.0173
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 39.1566
                       Mean reward: 836.54
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 0.6878
    Episode_Reward/rotating_object: 168.1850
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 1.75s
                      Time elapsed: 00:27:06
                               ETA: 00:23:30

################################################################################
                     [1m Learning iteration 804/1500 [0m                      

                       Computation: 55557 steps/s (collection: 1.648s, learning 0.121s)
             Mean action noise std: 2.35
          Mean value_function loss: 21.8381
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 39.1624
                       Mean reward: 831.91
               Mean episode length: 246.23
    Episode_Reward/reaching_object: 0.6813
    Episode_Reward/rotating_object: 164.8298
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 1.77s
                      Time elapsed: 00:27:08
                               ETA: 00:23:27

################################################################################
                     [1m Learning iteration 805/1500 [0m                      

                       Computation: 55802 steps/s (collection: 1.672s, learning 0.090s)
             Mean action noise std: 2.35
          Mean value_function loss: 9.5541
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 39.1843
                       Mean reward: 842.43
               Mean episode length: 248.01
    Episode_Reward/reaching_object: 0.6856
    Episode_Reward/rotating_object: 167.3352
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 1.76s
                      Time elapsed: 00:27:10
                               ETA: 00:23:25

################################################################################
                     [1m Learning iteration 806/1500 [0m                      

                       Computation: 56664 steps/s (collection: 1.641s, learning 0.094s)
             Mean action noise std: 2.36
          Mean value_function loss: 11.4125
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 39.2069
                       Mean reward: 848.10
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6857
    Episode_Reward/rotating_object: 167.4816
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 1.73s
                      Time elapsed: 00:27:11
                               ETA: 00:23:23

################################################################################
                     [1m Learning iteration 807/1500 [0m                      

                       Computation: 56645 steps/s (collection: 1.645s, learning 0.090s)
             Mean action noise std: 2.36
          Mean value_function loss: 21.4479
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 39.2262
                       Mean reward: 831.77
               Mean episode length: 245.70
    Episode_Reward/reaching_object: 0.6799
    Episode_Reward/rotating_object: 166.4128
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 1.74s
                      Time elapsed: 00:27:13
                               ETA: 00:23:21

################################################################################
                     [1m Learning iteration 808/1500 [0m                      

                       Computation: 56460 steps/s (collection: 1.653s, learning 0.088s)
             Mean action noise std: 2.36
          Mean value_function loss: 10.0338
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 39.2483
                       Mean reward: 847.31
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6805
    Episode_Reward/rotating_object: 167.3687
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 1.74s
                      Time elapsed: 00:27:15
                               ETA: 00:23:18

################################################################################
                     [1m Learning iteration 809/1500 [0m                      

                       Computation: 56510 steps/s (collection: 1.648s, learning 0.092s)
             Mean action noise std: 2.36
          Mean value_function loss: 11.0525
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 39.2633
                       Mean reward: 839.13
               Mean episode length: 248.19
    Episode_Reward/reaching_object: 0.6806
    Episode_Reward/rotating_object: 167.4216
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 1.74s
                      Time elapsed: 00:27:16
                               ETA: 00:23:16

################################################################################
                     [1m Learning iteration 810/1500 [0m                      

                       Computation: 57098 steps/s (collection: 1.631s, learning 0.091s)
             Mean action noise std: 2.37
          Mean value_function loss: 14.9099
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 39.2715
                       Mean reward: 823.82
               Mean episode length: 244.52
    Episode_Reward/reaching_object: 0.6724
    Episode_Reward/rotating_object: 166.6546
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 1.72s
                      Time elapsed: 00:27:18
                               ETA: 00:23:14

################################################################################
                     [1m Learning iteration 811/1500 [0m                      

                       Computation: 56758 steps/s (collection: 1.630s, learning 0.102s)
             Mean action noise std: 2.37
          Mean value_function loss: 10.5995
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 39.2796
                       Mean reward: 844.53
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.6816
    Episode_Reward/rotating_object: 169.1156
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 1.73s
                      Time elapsed: 00:27:20
                               ETA: 00:23:11

################################################################################
                     [1m Learning iteration 812/1500 [0m                      

                       Computation: 56316 steps/s (collection: 1.655s, learning 0.090s)
             Mean action noise std: 2.37
          Mean value_function loss: 12.9133
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 39.2871
                       Mean reward: 850.52
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6771
    Episode_Reward/rotating_object: 168.4759
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 1.75s
                      Time elapsed: 00:27:22
                               ETA: 00:23:09

################################################################################
                     [1m Learning iteration 813/1500 [0m                      

                       Computation: 56431 steps/s (collection: 1.643s, learning 0.099s)
             Mean action noise std: 2.37
          Mean value_function loss: 12.2790
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 39.3013
                       Mean reward: 840.76
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.6691
    Episode_Reward/rotating_object: 163.3124
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 1.74s
                      Time elapsed: 00:27:23
                               ETA: 00:23:07

################################################################################
                     [1m Learning iteration 814/1500 [0m                      

                       Computation: 56182 steps/s (collection: 1.649s, learning 0.101s)
             Mean action noise std: 2.37
          Mean value_function loss: 7.4068
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 39.3233
                       Mean reward: 841.93
               Mean episode length: 248.15
    Episode_Reward/reaching_object: 0.6775
    Episode_Reward/rotating_object: 168.6033
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 1.75s
                      Time elapsed: 00:27:25
                               ETA: 00:23:05

################################################################################
                     [1m Learning iteration 815/1500 [0m                      

                       Computation: 56760 steps/s (collection: 1.644s, learning 0.088s)
             Mean action noise std: 2.38
          Mean value_function loss: 16.0620
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 39.3364
                       Mean reward: 832.54
               Mean episode length: 246.33
    Episode_Reward/reaching_object: 0.6778
    Episode_Reward/rotating_object: 166.8488
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 1.73s
                      Time elapsed: 00:27:27
                               ETA: 00:23:02

################################################################################
                     [1m Learning iteration 816/1500 [0m                      

                       Computation: 56059 steps/s (collection: 1.663s, learning 0.091s)
             Mean action noise std: 2.38
          Mean value_function loss: 16.8179
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 39.3458
                       Mean reward: 847.21
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6797
    Episode_Reward/rotating_object: 168.2122
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 1.75s
                      Time elapsed: 00:27:29
                               ETA: 00:23:00

################################################################################
                     [1m Learning iteration 817/1500 [0m                      

                       Computation: 57056 steps/s (collection: 1.621s, learning 0.102s)
             Mean action noise std: 2.38
          Mean value_function loss: 15.8630
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 39.3602
                       Mean reward: 826.76
               Mean episode length: 243.76
    Episode_Reward/reaching_object: 0.6678
    Episode_Reward/rotating_object: 163.7297
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 1.72s
                      Time elapsed: 00:27:30
                               ETA: 00:22:58

################################################################################
                     [1m Learning iteration 818/1500 [0m                      

                       Computation: 55794 steps/s (collection: 1.663s, learning 0.099s)
             Mean action noise std: 2.38
          Mean value_function loss: 17.9234
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 39.3676
                       Mean reward: 845.76
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.6709
    Episode_Reward/rotating_object: 167.3526
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 1.76s
                      Time elapsed: 00:27:32
                               ETA: 00:22:56

################################################################################
                     [1m Learning iteration 819/1500 [0m                      

                       Computation: 55252 steps/s (collection: 1.672s, learning 0.108s)
             Mean action noise std: 2.38
          Mean value_function loss: 20.0769
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 39.3776
                       Mean reward: 813.74
               Mean episode length: 239.39
    Episode_Reward/reaching_object: 0.6707
    Episode_Reward/rotating_object: 166.0817
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 1.78s
                      Time elapsed: 00:27:34
                               ETA: 00:22:53

################################################################################
                     [1m Learning iteration 820/1500 [0m                      

                       Computation: 56333 steps/s (collection: 1.648s, learning 0.098s)
             Mean action noise std: 2.39
          Mean value_function loss: 17.8221
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 39.4001
                       Mean reward: 852.93
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6698
    Episode_Reward/rotating_object: 167.0538
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 1.75s
                      Time elapsed: 00:27:36
                               ETA: 00:22:51

################################################################################
                     [1m Learning iteration 821/1500 [0m                      

                       Computation: 55103 steps/s (collection: 1.674s, learning 0.109s)
             Mean action noise std: 2.39
          Mean value_function loss: 9.5528
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 39.4131
                       Mean reward: 836.86
               Mean episode length: 246.65
    Episode_Reward/reaching_object: 0.6736
    Episode_Reward/rotating_object: 167.9581
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 1.78s
                      Time elapsed: 00:27:37
                               ETA: 00:22:49

################################################################################
                     [1m Learning iteration 822/1500 [0m                      

                       Computation: 54962 steps/s (collection: 1.693s, learning 0.096s)
             Mean action noise std: 2.39
          Mean value_function loss: 16.6485
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 39.4192
                       Mean reward: 844.51
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6677
    Episode_Reward/rotating_object: 166.3904
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 1.79s
                      Time elapsed: 00:27:39
                               ETA: 00:22:47

################################################################################
                     [1m Learning iteration 823/1500 [0m                      

                       Computation: 56593 steps/s (collection: 1.646s, learning 0.091s)
             Mean action noise std: 2.39
          Mean value_function loss: 11.3948
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 39.4287
                       Mean reward: 850.27
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6694
    Episode_Reward/rotating_object: 168.5520
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 1.74s
                      Time elapsed: 00:27:41
                               ETA: 00:22:45

################################################################################
                     [1m Learning iteration 824/1500 [0m                      

                       Computation: 55879 steps/s (collection: 1.670s, learning 0.089s)
             Mean action noise std: 2.39
          Mean value_function loss: 18.1935
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 39.4344
                       Mean reward: 824.38
               Mean episode length: 244.65
    Episode_Reward/reaching_object: 0.6627
    Episode_Reward/rotating_object: 165.9290
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 1.76s
                      Time elapsed: 00:27:43
                               ETA: 00:22:42

################################################################################
                     [1m Learning iteration 825/1500 [0m                      

                       Computation: 56486 steps/s (collection: 1.642s, learning 0.099s)
             Mean action noise std: 2.39
          Mean value_function loss: 9.9386
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 39.4409
                       Mean reward: 841.59
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6675
    Episode_Reward/rotating_object: 168.5659
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 1.74s
                      Time elapsed: 00:27:44
                               ETA: 00:22:40

################################################################################
                     [1m Learning iteration 826/1500 [0m                      

                       Computation: 55771 steps/s (collection: 1.668s, learning 0.095s)
             Mean action noise std: 2.40
          Mean value_function loss: 14.2032
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 39.4496
                       Mean reward: 819.09
               Mean episode length: 243.29
    Episode_Reward/reaching_object: 0.6516
    Episode_Reward/rotating_object: 165.7766
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 1.76s
                      Time elapsed: 00:27:46
                               ETA: 00:22:38

################################################################################
                     [1m Learning iteration 827/1500 [0m                      

                       Computation: 55987 steps/s (collection: 1.663s, learning 0.092s)
             Mean action noise std: 2.40
          Mean value_function loss: 11.0720
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.4651
                       Mean reward: 847.60
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6683
    Episode_Reward/rotating_object: 167.9672
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 1.76s
                      Time elapsed: 00:27:48
                               ETA: 00:22:36

################################################################################
                     [1m Learning iteration 828/1500 [0m                      

                       Computation: 55570 steps/s (collection: 1.664s, learning 0.105s)
             Mean action noise std: 2.40
          Mean value_function loss: 14.9028
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 39.4780
                       Mean reward: 850.55
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6606
    Episode_Reward/rotating_object: 167.0761
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 1.77s
                      Time elapsed: 00:27:50
                               ETA: 00:22:33

################################################################################
                     [1m Learning iteration 829/1500 [0m                      

                       Computation: 57205 steps/s (collection: 1.628s, learning 0.090s)
             Mean action noise std: 2.40
          Mean value_function loss: 15.4278
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 39.4898
                       Mean reward: 834.76
               Mean episode length: 248.00
    Episode_Reward/reaching_object: 0.6688
    Episode_Reward/rotating_object: 166.6716
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 1.72s
                      Time elapsed: 00:27:51
                               ETA: 00:22:31

################################################################################
                     [1m Learning iteration 830/1500 [0m                      

                       Computation: 56616 steps/s (collection: 1.646s, learning 0.091s)
             Mean action noise std: 2.40
          Mean value_function loss: 10.5688
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.5055
                       Mean reward: 832.92
               Mean episode length: 246.41
    Episode_Reward/reaching_object: 0.6729
    Episode_Reward/rotating_object: 168.3340
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 1.74s
                      Time elapsed: 00:27:53
                               ETA: 00:22:29

################################################################################
                     [1m Learning iteration 831/1500 [0m                      

                       Computation: 56638 steps/s (collection: 1.638s, learning 0.098s)
             Mean action noise std: 2.41
          Mean value_function loss: 15.1127
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 39.5162
                       Mean reward: 833.77
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 0.6636
    Episode_Reward/rotating_object: 166.3092
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 1.74s
                      Time elapsed: 00:27:55
                               ETA: 00:22:27

################################################################################
                     [1m Learning iteration 832/1500 [0m                      

                       Computation: 57212 steps/s (collection: 1.623s, learning 0.095s)
             Mean action noise std: 2.41
          Mean value_function loss: 13.5196
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 39.5400
                       Mean reward: 847.08
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6718
    Episode_Reward/rotating_object: 166.8718
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 1.72s
                      Time elapsed: 00:27:57
                               ETA: 00:22:24

################################################################################
                     [1m Learning iteration 833/1500 [0m                      

                       Computation: 56798 steps/s (collection: 1.640s, learning 0.091s)
             Mean action noise std: 2.41
          Mean value_function loss: 17.5707
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 39.5565
                       Mean reward: 835.34
               Mean episode length: 245.57
    Episode_Reward/reaching_object: 0.6628
    Episode_Reward/rotating_object: 167.2471
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 1.73s
                      Time elapsed: 00:27:58
                               ETA: 00:22:22

################################################################################
                     [1m Learning iteration 834/1500 [0m                      

                       Computation: 55966 steps/s (collection: 1.667s, learning 0.089s)
             Mean action noise std: 2.41
          Mean value_function loss: 18.8680
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 39.5631
                       Mean reward: 836.90
               Mean episode length: 245.88
    Episode_Reward/reaching_object: 0.6568
    Episode_Reward/rotating_object: 164.5693
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 1.76s
                      Time elapsed: 00:28:00
                               ETA: 00:22:20

################################################################################
                     [1m Learning iteration 835/1500 [0m                      

                       Computation: 56524 steps/s (collection: 1.652s, learning 0.088s)
             Mean action noise std: 2.42
          Mean value_function loss: 10.7507
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 39.5794
                       Mean reward: 850.81
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6722
    Episode_Reward/rotating_object: 167.2947
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 1.74s
                      Time elapsed: 00:28:02
                               ETA: 00:22:18

################################################################################
                     [1m Learning iteration 836/1500 [0m                      

                       Computation: 55732 steps/s (collection: 1.651s, learning 0.113s)
             Mean action noise std: 2.42
          Mean value_function loss: 17.3021
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 39.5925
                       Mean reward: 824.96
               Mean episode length: 245.78
    Episode_Reward/reaching_object: 0.6722
    Episode_Reward/rotating_object: 166.3208
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 1.76s
                      Time elapsed: 00:28:04
                               ETA: 00:22:16

################################################################################
                     [1m Learning iteration 837/1500 [0m                      

                       Computation: 55976 steps/s (collection: 1.664s, learning 0.092s)
             Mean action noise std: 2.42
          Mean value_function loss: 26.1231
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.6088
                       Mean reward: 803.07
               Mean episode length: 236.91
    Episode_Reward/reaching_object: 0.6676
    Episode_Reward/rotating_object: 164.5793
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 1.76s
                      Time elapsed: 00:28:05
                               ETA: 00:22:13

################################################################################
                     [1m Learning iteration 838/1500 [0m                      

                       Computation: 55626 steps/s (collection: 1.663s, learning 0.105s)
             Mean action noise std: 2.42
          Mean value_function loss: 12.3434
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 39.6246
                       Mean reward: 850.76
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6805
    Episode_Reward/rotating_object: 168.5477
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 1.77s
                      Time elapsed: 00:28:07
                               ETA: 00:22:11

################################################################################
                     [1m Learning iteration 839/1500 [0m                      

                       Computation: 55090 steps/s (collection: 1.684s, learning 0.101s)
             Mean action noise std: 2.43
          Mean value_function loss: 17.8720
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.6399
                       Mean reward: 825.57
               Mean episode length: 244.57
    Episode_Reward/reaching_object: 0.6740
    Episode_Reward/rotating_object: 166.1934
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 1.78s
                      Time elapsed: 00:28:09
                               ETA: 00:22:09

################################################################################
                     [1m Learning iteration 840/1500 [0m                      

                       Computation: 54677 steps/s (collection: 1.695s, learning 0.103s)
             Mean action noise std: 2.43
          Mean value_function loss: 14.6873
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 39.6544
                       Mean reward: 843.86
               Mean episode length: 247.69
    Episode_Reward/reaching_object: 0.6838
    Episode_Reward/rotating_object: 167.3618
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 1.80s
                      Time elapsed: 00:28:11
                               ETA: 00:22:07

################################################################################
                     [1m Learning iteration 841/1500 [0m                      

                       Computation: 56705 steps/s (collection: 1.634s, learning 0.100s)
             Mean action noise std: 2.43
          Mean value_function loss: 16.1646
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 39.6713
                       Mean reward: 821.46
               Mean episode length: 242.85
    Episode_Reward/reaching_object: 0.6780
    Episode_Reward/rotating_object: 166.7560
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 1.73s
                      Time elapsed: 00:28:12
                               ETA: 00:22:05

################################################################################
                     [1m Learning iteration 842/1500 [0m                      

                       Computation: 55665 steps/s (collection: 1.672s, learning 0.094s)
             Mean action noise std: 2.43
          Mean value_function loss: 15.4820
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 39.6827
                       Mean reward: 836.91
               Mean episode length: 247.11
    Episode_Reward/reaching_object: 0.6859
    Episode_Reward/rotating_object: 168.4929
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 1.77s
                      Time elapsed: 00:28:14
                               ETA: 00:22:02

################################################################################
                     [1m Learning iteration 843/1500 [0m                      

                       Computation: 54712 steps/s (collection: 1.703s, learning 0.094s)
             Mean action noise std: 2.44
          Mean value_function loss: 18.0375
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.7013
                       Mean reward: 824.28
               Mean episode length: 243.37
    Episode_Reward/reaching_object: 0.6920
    Episode_Reward/rotating_object: 166.8809
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 1.80s
                      Time elapsed: 00:28:16
                               ETA: 00:22:00

################################################################################
                     [1m Learning iteration 844/1500 [0m                      

                       Computation: 56799 steps/s (collection: 1.639s, learning 0.092s)
             Mean action noise std: 2.44
          Mean value_function loss: 12.0675
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 39.7210
                       Mean reward: 827.83
               Mean episode length: 246.26
    Episode_Reward/reaching_object: 0.6888
    Episode_Reward/rotating_object: 167.6207
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 1.73s
                      Time elapsed: 00:28:18
                               ETA: 00:21:58

################################################################################
                     [1m Learning iteration 845/1500 [0m                      

                       Computation: 55644 steps/s (collection: 1.666s, learning 0.101s)
             Mean action noise std: 2.44
          Mean value_function loss: 11.1318
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 39.7316
                       Mean reward: 835.80
               Mean episode length: 248.17
    Episode_Reward/reaching_object: 0.6900
    Episode_Reward/rotating_object: 166.4233
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 1.77s
                      Time elapsed: 00:28:20
                               ETA: 00:21:56

################################################################################
                     [1m Learning iteration 846/1500 [0m                      

                       Computation: 56831 steps/s (collection: 1.638s, learning 0.092s)
             Mean action noise std: 2.44
          Mean value_function loss: 11.7552
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 39.7404
                       Mean reward: 846.02
               Mean episode length: 248.41
    Episode_Reward/reaching_object: 0.6930
    Episode_Reward/rotating_object: 168.1559
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 1.73s
                      Time elapsed: 00:28:21
                               ETA: 00:21:54

################################################################################
                     [1m Learning iteration 847/1500 [0m                      

                       Computation: 55345 steps/s (collection: 1.687s, learning 0.090s)
             Mean action noise std: 2.45
          Mean value_function loss: 14.9536
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 39.7542
                       Mean reward: 843.71
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 0.6959
    Episode_Reward/rotating_object: 168.3641
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 1.78s
                      Time elapsed: 00:28:23
                               ETA: 00:21:51

################################################################################
                     [1m Learning iteration 848/1500 [0m                      

                       Computation: 56031 steps/s (collection: 1.643s, learning 0.111s)
             Mean action noise std: 2.45
          Mean value_function loss: 11.5689
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 39.7644
                       Mean reward: 825.15
               Mean episode length: 246.25
    Episode_Reward/reaching_object: 0.6867
    Episode_Reward/rotating_object: 166.8284
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 1.75s
                      Time elapsed: 00:28:25
                               ETA: 00:21:49

################################################################################
                     [1m Learning iteration 849/1500 [0m                      

                       Computation: 56937 steps/s (collection: 1.636s, learning 0.091s)
             Mean action noise std: 2.45
          Mean value_function loss: 14.7168
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 39.7749
                       Mean reward: 849.37
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6916
    Episode_Reward/rotating_object: 167.9164
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 1.73s
                      Time elapsed: 00:28:27
                               ETA: 00:21:47

################################################################################
                     [1m Learning iteration 850/1500 [0m                      

                       Computation: 56258 steps/s (collection: 1.657s, learning 0.090s)
             Mean action noise std: 2.46
          Mean value_function loss: 15.5079
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 39.7957
                       Mean reward: 843.08
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 0.6828
    Episode_Reward/rotating_object: 167.9650
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 1.75s
                      Time elapsed: 00:28:28
                               ETA: 00:21:45

################################################################################
                     [1m Learning iteration 851/1500 [0m                      

                       Computation: 55953 steps/s (collection: 1.663s, learning 0.093s)
             Mean action noise std: 2.46
          Mean value_function loss: 12.0014
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 39.8312
                       Mean reward: 837.37
               Mean episode length: 245.83
    Episode_Reward/reaching_object: 0.6777
    Episode_Reward/rotating_object: 166.9139
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 1.76s
                      Time elapsed: 00:28:30
                               ETA: 00:21:42

################################################################################
                     [1m Learning iteration 852/1500 [0m                      

                       Computation: 56476 steps/s (collection: 1.650s, learning 0.091s)
             Mean action noise std: 2.46
          Mean value_function loss: 15.7355
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 39.8460
                       Mean reward: 842.59
               Mean episode length: 247.67
    Episode_Reward/reaching_object: 0.6827
    Episode_Reward/rotating_object: 166.2915
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 1.74s
                      Time elapsed: 00:28:32
                               ETA: 00:21:40

################################################################################
                     [1m Learning iteration 853/1500 [0m                      

                       Computation: 55379 steps/s (collection: 1.668s, learning 0.107s)
             Mean action noise std: 2.46
          Mean value_function loss: 9.3263
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 39.8581
                       Mean reward: 851.16
               Mean episode length: 248.83
    Episode_Reward/reaching_object: 0.6781
    Episode_Reward/rotating_object: 167.8868
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 1.78s
                      Time elapsed: 00:28:34
                               ETA: 00:21:38

################################################################################
                     [1m Learning iteration 854/1500 [0m                      

                       Computation: 55671 steps/s (collection: 1.659s, learning 0.107s)
             Mean action noise std: 2.47
          Mean value_function loss: 10.0643
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 39.8719
                       Mean reward: 842.62
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 0.6867
    Episode_Reward/rotating_object: 168.3647
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 1.77s
                      Time elapsed: 00:28:35
                               ETA: 00:21:36

################################################################################
                     [1m Learning iteration 855/1500 [0m                      

                       Computation: 54362 steps/s (collection: 1.693s, learning 0.116s)
             Mean action noise std: 2.47
          Mean value_function loss: 10.7632
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 39.8834
                       Mean reward: 838.03
               Mean episode length: 245.75
    Episode_Reward/reaching_object: 0.6795
    Episode_Reward/rotating_object: 166.5044
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 1.81s
                      Time elapsed: 00:28:37
                               ETA: 00:21:34

################################################################################
                     [1m Learning iteration 856/1500 [0m                      

                       Computation: 56073 steps/s (collection: 1.662s, learning 0.091s)
             Mean action noise std: 2.47
          Mean value_function loss: 12.1911
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 39.8981
                       Mean reward: 842.59
               Mean episode length: 247.43
    Episode_Reward/reaching_object: 0.6836
    Episode_Reward/rotating_object: 168.5210
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 1.75s
                      Time elapsed: 00:28:39
                               ETA: 00:21:32

################################################################################
                     [1m Learning iteration 857/1500 [0m                      

                       Computation: 56643 steps/s (collection: 1.634s, learning 0.102s)
             Mean action noise std: 2.47
          Mean value_function loss: 10.6997
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 39.9180
                       Mean reward: 842.43
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 0.6819
    Episode_Reward/rotating_object: 167.5043
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 1.74s
                      Time elapsed: 00:28:41
                               ETA: 00:21:29

################################################################################
                     [1m Learning iteration 858/1500 [0m                      

                       Computation: 56600 steps/s (collection: 1.640s, learning 0.097s)
             Mean action noise std: 2.47
          Mean value_function loss: 18.6745
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 39.9329
                       Mean reward: 846.01
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6798
    Episode_Reward/rotating_object: 166.8578
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 1.74s
                      Time elapsed: 00:28:42
                               ETA: 00:21:27

################################################################################
                     [1m Learning iteration 859/1500 [0m                      

                       Computation: 55784 steps/s (collection: 1.673s, learning 0.089s)
             Mean action noise std: 2.47
          Mean value_function loss: 13.2749
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 39.9430
                       Mean reward: 849.95
               Mean episode length: 248.11
    Episode_Reward/reaching_object: 0.6788
    Episode_Reward/rotating_object: 167.6215
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 1.76s
                      Time elapsed: 00:28:44
                               ETA: 00:21:25

################################################################################
                     [1m Learning iteration 860/1500 [0m                      

                       Computation: 55151 steps/s (collection: 1.689s, learning 0.094s)
             Mean action noise std: 2.48
          Mean value_function loss: 20.8238
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 39.9561
                       Mean reward: 831.34
               Mean episode length: 244.10
    Episode_Reward/reaching_object: 0.6815
    Episode_Reward/rotating_object: 166.7333
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 1.78s
                      Time elapsed: 00:28:46
                               ETA: 00:21:23

################################################################################
                     [1m Learning iteration 861/1500 [0m                      

                       Computation: 56396 steps/s (collection: 1.644s, learning 0.099s)
             Mean action noise std: 2.48
          Mean value_function loss: 15.7701
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 39.9858
                       Mean reward: 828.89
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 0.6811
    Episode_Reward/rotating_object: 166.6236
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 1.74s
                      Time elapsed: 00:28:48
                               ETA: 00:21:21

################################################################################
                     [1m Learning iteration 862/1500 [0m                      

                       Computation: 55142 steps/s (collection: 1.674s, learning 0.109s)
             Mean action noise std: 2.48
          Mean value_function loss: 10.7857
               Mean surrogate loss: 0.0025
                 Mean entropy loss: 40.0126
                       Mean reward: 844.21
               Mean episode length: 248.07
    Episode_Reward/reaching_object: 0.6902
    Episode_Reward/rotating_object: 167.5926
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 1.78s
                      Time elapsed: 00:28:49
                               ETA: 00:21:18

################################################################################
                     [1m Learning iteration 863/1500 [0m                      

                       Computation: 56323 steps/s (collection: 1.657s, learning 0.089s)
             Mean action noise std: 2.48
          Mean value_function loss: 20.9105
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 40.0175
                       Mean reward: 827.21
               Mean episode length: 244.04
    Episode_Reward/reaching_object: 0.6945
    Episode_Reward/rotating_object: 166.8107
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 1.75s
                      Time elapsed: 00:28:51
                               ETA: 00:21:16

################################################################################
                     [1m Learning iteration 864/1500 [0m                      

                       Computation: 56420 steps/s (collection: 1.649s, learning 0.093s)
             Mean action noise std: 2.49
          Mean value_function loss: 14.1091
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 40.0381
                       Mean reward: 846.61
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.6956
    Episode_Reward/rotating_object: 167.3271
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 1.74s
                      Time elapsed: 00:28:53
                               ETA: 00:21:14

################################################################################
                     [1m Learning iteration 865/1500 [0m                      

                       Computation: 55502 steps/s (collection: 1.682s, learning 0.090s)
             Mean action noise std: 2.49
          Mean value_function loss: 12.6270
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 40.0504
                       Mean reward: 818.50
               Mean episode length: 243.25
    Episode_Reward/reaching_object: 0.6943
    Episode_Reward/rotating_object: 166.9677
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 1.77s
                      Time elapsed: 00:28:55
                               ETA: 00:21:12

################################################################################
                     [1m Learning iteration 866/1500 [0m                      

                       Computation: 56459 steps/s (collection: 1.640s, learning 0.101s)
             Mean action noise std: 2.49
          Mean value_function loss: 11.5846
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 40.0606
                       Mean reward: 854.81
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7042
    Episode_Reward/rotating_object: 169.9272
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 1.74s
                      Time elapsed: 00:28:56
                               ETA: 00:21:10

################################################################################
                     [1m Learning iteration 867/1500 [0m                      

                       Computation: 56322 steps/s (collection: 1.654s, learning 0.092s)
             Mean action noise std: 2.49
          Mean value_function loss: 11.9960
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 40.0801
                       Mean reward: 840.96
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 0.7005
    Episode_Reward/rotating_object: 167.5566
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 1.75s
                      Time elapsed: 00:28:58
                               ETA: 00:21:07

################################################################################
                     [1m Learning iteration 868/1500 [0m                      

                       Computation: 56352 steps/s (collection: 1.648s, learning 0.097s)
             Mean action noise std: 2.50
          Mean value_function loss: 15.0914
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 40.0978
                       Mean reward: 835.49
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 0.7116
    Episode_Reward/rotating_object: 168.1993
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 1.74s
                      Time elapsed: 00:29:00
                               ETA: 00:21:05

################################################################################
                     [1m Learning iteration 869/1500 [0m                      

                       Computation: 55836 steps/s (collection: 1.666s, learning 0.095s)
             Mean action noise std: 2.50
          Mean value_function loss: 11.1323
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 40.1105
                       Mean reward: 843.73
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7113
    Episode_Reward/rotating_object: 168.6553
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 1.76s
                      Time elapsed: 00:29:02
                               ETA: 00:21:03

################################################################################
                     [1m Learning iteration 870/1500 [0m                      

                       Computation: 55567 steps/s (collection: 1.663s, learning 0.106s)
             Mean action noise std: 2.50
          Mean value_function loss: 11.5467
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.1236
                       Mean reward: 831.72
               Mean episode length: 245.76
    Episode_Reward/reaching_object: 0.7080
    Episode_Reward/rotating_object: 167.6873
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 1.77s
                      Time elapsed: 00:29:03
                               ETA: 00:21:01

################################################################################
                     [1m Learning iteration 871/1500 [0m                      

                       Computation: 56134 steps/s (collection: 1.643s, learning 0.108s)
             Mean action noise std: 2.50
          Mean value_function loss: 8.2171
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 40.1366
                       Mean reward: 860.20
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7171
    Episode_Reward/rotating_object: 170.0566
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 1.75s
                      Time elapsed: 00:29:05
                               ETA: 00:20:59

################################################################################
                     [1m Learning iteration 872/1500 [0m                      

                       Computation: 56851 steps/s (collection: 1.624s, learning 0.105s)
             Mean action noise std: 2.50
          Mean value_function loss: 12.3446
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 40.1419
                       Mean reward: 836.26
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 0.7135
    Episode_Reward/rotating_object: 168.3766
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 1.73s
                      Time elapsed: 00:29:07
                               ETA: 00:20:57

################################################################################
                     [1m Learning iteration 873/1500 [0m                      

                       Computation: 55301 steps/s (collection: 1.644s, learning 0.133s)
             Mean action noise std: 2.51
          Mean value_function loss: 14.1919
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 40.1507
                       Mean reward: 844.15
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7142
    Episode_Reward/rotating_object: 168.0802
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 1.78s
                      Time elapsed: 00:29:09
                               ETA: 00:20:54

################################################################################
                     [1m Learning iteration 874/1500 [0m                      

                       Computation: 50832 steps/s (collection: 1.821s, learning 0.113s)
             Mean action noise std: 2.51
          Mean value_function loss: 14.2473
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 40.1575
                       Mean reward: 845.87
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7123
    Episode_Reward/rotating_object: 167.2876
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 1.93s
                      Time elapsed: 00:29:11
                               ETA: 00:20:52

################################################################################
                     [1m Learning iteration 875/1500 [0m                      

                       Computation: 50436 steps/s (collection: 1.791s, learning 0.158s)
             Mean action noise std: 2.51
          Mean value_function loss: 18.6406
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.1689
                       Mean reward: 839.24
               Mean episode length: 247.97
    Episode_Reward/reaching_object: 0.7049
    Episode_Reward/rotating_object: 165.4184
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 1.95s
                      Time elapsed: 00:29:13
                               ETA: 00:20:50

################################################################################
                     [1m Learning iteration 876/1500 [0m                      

                       Computation: 52501 steps/s (collection: 1.759s, learning 0.113s)
             Mean action noise std: 2.51
          Mean value_function loss: 15.2719
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 40.1860
                       Mean reward: 830.09
               Mean episode length: 243.52
    Episode_Reward/reaching_object: 0.7106
    Episode_Reward/rotating_object: 166.0782
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 1.87s
                      Time elapsed: 00:29:14
                               ETA: 00:20:48

################################################################################
                     [1m Learning iteration 877/1500 [0m                      

                       Computation: 53852 steps/s (collection: 1.732s, learning 0.093s)
             Mean action noise std: 2.52
          Mean value_function loss: 11.4335
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 40.2056
                       Mean reward: 847.19
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7195
    Episode_Reward/rotating_object: 168.5177
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 1.83s
                      Time elapsed: 00:29:16
                               ETA: 00:20:46

################################################################################
                     [1m Learning iteration 878/1500 [0m                      

                       Computation: 54063 steps/s (collection: 1.689s, learning 0.130s)
             Mean action noise std: 2.52
          Mean value_function loss: 10.1697
               Mean surrogate loss: 0.0030
                 Mean entropy loss: 40.2251
                       Mean reward: 849.82
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7140
    Episode_Reward/rotating_object: 169.0144
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 1.82s
                      Time elapsed: 00:29:18
                               ETA: 00:20:44

################################################################################
                     [1m Learning iteration 879/1500 [0m                      

                       Computation: 53425 steps/s (collection: 1.688s, learning 0.152s)
             Mean action noise std: 2.52
          Mean value_function loss: 11.1664
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.2340
                       Mean reward: 848.70
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.7215
    Episode_Reward/rotating_object: 169.2337
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 18.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 1.84s
                      Time elapsed: 00:29:20
                               ETA: 00:20:42

################################################################################
                     [1m Learning iteration 880/1500 [0m                      

                       Computation: 53903 steps/s (collection: 1.719s, learning 0.105s)
             Mean action noise std: 2.52
          Mean value_function loss: 15.7771
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 40.2490
                       Mean reward: 849.85
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 0.7133
    Episode_Reward/rotating_object: 167.8030
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 1.82s
                      Time elapsed: 00:29:22
                               ETA: 00:20:40

################################################################################
                     [1m Learning iteration 881/1500 [0m                      

                       Computation: 54633 steps/s (collection: 1.703s, learning 0.096s)
             Mean action noise std: 2.52
          Mean value_function loss: 12.8192
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 40.2618
                       Mean reward: 836.19
               Mean episode length: 245.44
    Episode_Reward/reaching_object: 0.7153
    Episode_Reward/rotating_object: 167.4918
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 1.80s
                      Time elapsed: 00:29:24
                               ETA: 00:20:38

################################################################################
                     [1m Learning iteration 882/1500 [0m                      

                       Computation: 53511 steps/s (collection: 1.735s, learning 0.102s)
             Mean action noise std: 2.53
          Mean value_function loss: 18.6436
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 40.2746
                       Mean reward: 846.94
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.7251
    Episode_Reward/rotating_object: 169.5265
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 1.84s
                      Time elapsed: 00:29:25
                               ETA: 00:20:35

################################################################################
                     [1m Learning iteration 883/1500 [0m                      

                       Computation: 54578 steps/s (collection: 1.680s, learning 0.122s)
             Mean action noise std: 2.53
          Mean value_function loss: 16.3909
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 40.2936
                       Mean reward: 849.44
               Mean episode length: 248.13
    Episode_Reward/reaching_object: 0.7144
    Episode_Reward/rotating_object: 168.5034
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 1.80s
                      Time elapsed: 00:29:27
                               ETA: 00:20:33

################################################################################
                     [1m Learning iteration 884/1500 [0m                      

                       Computation: 54607 steps/s (collection: 1.697s, learning 0.104s)
             Mean action noise std: 2.53
          Mean value_function loss: 20.3216
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 40.3106
                       Mean reward: 843.54
               Mean episode length: 245.49
    Episode_Reward/reaching_object: 0.7164
    Episode_Reward/rotating_object: 167.1184
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 1.80s
                      Time elapsed: 00:29:29
                               ETA: 00:20:31

################################################################################
                     [1m Learning iteration 885/1500 [0m                      

                       Computation: 54797 steps/s (collection: 1.661s, learning 0.132s)
             Mean action noise std: 2.53
          Mean value_function loss: 17.0863
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 40.3249
                       Mean reward: 840.85
               Mean episode length: 246.16
    Episode_Reward/reaching_object: 0.7117
    Episode_Reward/rotating_object: 166.0041
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 1.79s
                      Time elapsed: 00:29:31
                               ETA: 00:20:29

################################################################################
                     [1m Learning iteration 886/1500 [0m                      

                       Computation: 53926 steps/s (collection: 1.718s, learning 0.105s)
             Mean action noise std: 2.54
          Mean value_function loss: 16.7564
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 40.3386
                       Mean reward: 831.95
               Mean episode length: 244.53
    Episode_Reward/reaching_object: 0.7185
    Episode_Reward/rotating_object: 166.7168
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 1.82s
                      Time elapsed: 00:29:33
                               ETA: 00:20:27

################################################################################
                     [1m Learning iteration 887/1500 [0m                      

                       Computation: 54815 steps/s (collection: 1.679s, learning 0.114s)
             Mean action noise std: 2.54
          Mean value_function loss: 14.2845
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 40.3531
                       Mean reward: 841.28
               Mean episode length: 245.95
    Episode_Reward/reaching_object: 0.7204
    Episode_Reward/rotating_object: 169.0680
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 1.79s
                      Time elapsed: 00:29:34
                               ETA: 00:20:25

################################################################################
                     [1m Learning iteration 888/1500 [0m                      

                       Computation: 54236 steps/s (collection: 1.707s, learning 0.106s)
             Mean action noise std: 2.54
          Mean value_function loss: 16.7863
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 40.3633
                       Mean reward: 858.21
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7146
    Episode_Reward/rotating_object: 166.6521
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 1.81s
                      Time elapsed: 00:29:36
                               ETA: 00:20:23

################################################################################
                     [1m Learning iteration 889/1500 [0m                      

                       Computation: 54989 steps/s (collection: 1.684s, learning 0.104s)
             Mean action noise std: 2.54
          Mean value_function loss: 18.4553
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 40.3817
                       Mean reward: 848.58
               Mean episode length: 248.74
    Episode_Reward/reaching_object: 0.7258
    Episode_Reward/rotating_object: 168.4011
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 1.79s
                      Time elapsed: 00:29:38
                               ETA: 00:20:20

################################################################################
                     [1m Learning iteration 890/1500 [0m                      

                       Computation: 50979 steps/s (collection: 1.771s, learning 0.158s)
             Mean action noise std: 2.55
          Mean value_function loss: 15.1560
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 40.3964
                       Mean reward: 842.23
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 0.7214
    Episode_Reward/rotating_object: 167.5658
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 1.93s
                      Time elapsed: 00:29:40
                               ETA: 00:20:18

################################################################################
                     [1m Learning iteration 891/1500 [0m                      

                       Computation: 53933 steps/s (collection: 1.678s, learning 0.145s)
             Mean action noise std: 2.55
          Mean value_function loss: 19.6303
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 40.4159
                       Mean reward: 847.47
               Mean episode length: 247.68
    Episode_Reward/reaching_object: 0.7261
    Episode_Reward/rotating_object: 168.0914
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 1.82s
                      Time elapsed: 00:29:42
                               ETA: 00:20:16

################################################################################
                     [1m Learning iteration 892/1500 [0m                      

                       Computation: 54611 steps/s (collection: 1.683s, learning 0.117s)
             Mean action noise std: 2.55
          Mean value_function loss: 17.3457
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 40.4368
                       Mean reward: 847.28
               Mean episode length: 247.98
    Episode_Reward/reaching_object: 0.7258
    Episode_Reward/rotating_object: 165.9810
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 1.80s
                      Time elapsed: 00:29:44
                               ETA: 00:20:14

################################################################################
                     [1m Learning iteration 893/1500 [0m                      

                       Computation: 55416 steps/s (collection: 1.683s, learning 0.091s)
             Mean action noise std: 2.55
          Mean value_function loss: 13.6968
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.4556
                       Mean reward: 838.95
               Mean episode length: 248.26
    Episode_Reward/reaching_object: 0.7357
    Episode_Reward/rotating_object: 169.3410
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 1.77s
                      Time elapsed: 00:29:45
                               ETA: 00:20:12

################################################################################
                     [1m Learning iteration 894/1500 [0m                      

                       Computation: 54138 steps/s (collection: 1.717s, learning 0.099s)
             Mean action noise std: 2.55
          Mean value_function loss: 14.5575
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 40.4678
                       Mean reward: 838.87
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 0.7289
    Episode_Reward/rotating_object: 167.1991
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 1.82s
                      Time elapsed: 00:29:47
                               ETA: 00:20:10

################################################################################
                     [1m Learning iteration 895/1500 [0m                      

                       Computation: 52932 steps/s (collection: 1.715s, learning 0.142s)
             Mean action noise std: 2.55
          Mean value_function loss: 14.0233
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 40.4688
                       Mean reward: 850.87
               Mean episode length: 249.79
    Episode_Reward/reaching_object: 0.7240
    Episode_Reward/rotating_object: 166.8515
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 1.86s
                      Time elapsed: 00:29:49
                               ETA: 00:20:08

################################################################################
                     [1m Learning iteration 896/1500 [0m                      

                       Computation: 53752 steps/s (collection: 1.699s, learning 0.130s)
             Mean action noise std: 2.56
          Mean value_function loss: 11.3892
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 40.4708
                       Mean reward: 848.80
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7265
    Episode_Reward/rotating_object: 168.2589
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 1.83s
                      Time elapsed: 00:29:51
                               ETA: 00:20:06

################################################################################
                     [1m Learning iteration 897/1500 [0m                      

                       Computation: 55922 steps/s (collection: 1.655s, learning 0.103s)
             Mean action noise std: 2.56
          Mean value_function loss: 9.8375
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 40.4744
                       Mean reward: 837.54
               Mean episode length: 247.23
    Episode_Reward/reaching_object: 0.7275
    Episode_Reward/rotating_object: 169.4062
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 1.76s
                      Time elapsed: 00:29:53
                               ETA: 00:20:04

################################################################################
                     [1m Learning iteration 898/1500 [0m                      

                       Computation: 54710 steps/s (collection: 1.705s, learning 0.092s)
             Mean action noise std: 2.56
          Mean value_function loss: 16.7262
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 40.4770
                       Mean reward: 855.82
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7269
    Episode_Reward/rotating_object: 168.4088
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 1.80s
                      Time elapsed: 00:29:54
                               ETA: 00:20:01

################################################################################
                     [1m Learning iteration 899/1500 [0m                      

                       Computation: 55123 steps/s (collection: 1.695s, learning 0.088s)
             Mean action noise std: 2.56
          Mean value_function loss: 16.1906
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 40.4884
                       Mean reward: 839.40
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7239
    Episode_Reward/rotating_object: 166.6794
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 1.78s
                      Time elapsed: 00:29:56
                               ETA: 00:19:59

################################################################################
                     [1m Learning iteration 900/1500 [0m                      

                       Computation: 53034 steps/s (collection: 1.717s, learning 0.136s)
             Mean action noise std: 2.56
          Mean value_function loss: 17.4070
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.5111
                       Mean reward: 829.71
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7263
    Episode_Reward/rotating_object: 167.3880
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 18.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 1.85s
                      Time elapsed: 00:29:58
                               ETA: 00:19:57

################################################################################
                     [1m Learning iteration 901/1500 [0m                      

                       Computation: 53052 steps/s (collection: 1.668s, learning 0.185s)
             Mean action noise std: 2.57
          Mean value_function loss: 21.4525
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 40.5307
                       Mean reward: 849.74
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7204
    Episode_Reward/rotating_object: 167.4078
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 1.85s
                      Time elapsed: 00:30:00
                               ETA: 00:19:55

################################################################################
                     [1m Learning iteration 902/1500 [0m                      

                       Computation: 54667 steps/s (collection: 1.678s, learning 0.121s)
             Mean action noise std: 2.57
          Mean value_function loss: 14.9334
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 40.5515
                       Mean reward: 835.08
               Mean episode length: 244.07
    Episode_Reward/reaching_object: 0.7200
    Episode_Reward/rotating_object: 167.7844
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 1.80s
                      Time elapsed: 00:30:02
                               ETA: 00:19:53

################################################################################
                     [1m Learning iteration 903/1500 [0m                      

                       Computation: 54455 steps/s (collection: 1.696s, learning 0.110s)
             Mean action noise std: 2.57
          Mean value_function loss: 11.2446
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 40.5677
                       Mean reward: 851.63
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.7174
    Episode_Reward/rotating_object: 168.7160
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 1.81s
                      Time elapsed: 00:30:03
                               ETA: 00:19:51

################################################################################
                     [1m Learning iteration 904/1500 [0m                      

                       Computation: 54275 steps/s (collection: 1.716s, learning 0.095s)
             Mean action noise std: 2.57
          Mean value_function loss: 13.6775
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 40.5814
                       Mean reward: 848.77
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.7249
    Episode_Reward/rotating_object: 168.5865
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 1.81s
                      Time elapsed: 00:30:05
                               ETA: 00:19:49

################################################################################
                     [1m Learning iteration 905/1500 [0m                      

                       Computation: 54281 steps/s (collection: 1.716s, learning 0.095s)
             Mean action noise std: 2.58
          Mean value_function loss: 12.9520
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 40.5965
                       Mean reward: 851.45
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7284
    Episode_Reward/rotating_object: 170.3987
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 1.81s
                      Time elapsed: 00:30:07
                               ETA: 00:19:47

################################################################################
                     [1m Learning iteration 906/1500 [0m                      

                       Computation: 53867 steps/s (collection: 1.695s, learning 0.130s)
             Mean action noise std: 2.58
          Mean value_function loss: 14.1163
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 40.6129
                       Mean reward: 848.89
               Mean episode length: 249.16
    Episode_Reward/reaching_object: 0.7249
    Episode_Reward/rotating_object: 168.7306
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 1.82s
                      Time elapsed: 00:30:09
                               ETA: 00:19:45

################################################################################
                     [1m Learning iteration 907/1500 [0m                      

                       Computation: 53581 steps/s (collection: 1.687s, learning 0.148s)
             Mean action noise std: 2.58
          Mean value_function loss: 22.9008
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 40.6344
                       Mean reward: 834.22
               Mean episode length: 245.01
    Episode_Reward/reaching_object: 0.7205
    Episode_Reward/rotating_object: 168.2419
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 1.83s
                      Time elapsed: 00:30:11
                               ETA: 00:19:42

################################################################################
                     [1m Learning iteration 908/1500 [0m                      

                       Computation: 52711 steps/s (collection: 1.735s, learning 0.129s)
             Mean action noise std: 2.59
          Mean value_function loss: 12.4284
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 40.6613
                       Mean reward: 861.32
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7110
    Episode_Reward/rotating_object: 166.6838
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 1.86s
                      Time elapsed: 00:30:13
                               ETA: 00:19:40

################################################################################
                     [1m Learning iteration 909/1500 [0m                      

                       Computation: 53705 steps/s (collection: 1.737s, learning 0.094s)
             Mean action noise std: 2.59
          Mean value_function loss: 14.2116
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 40.6878
                       Mean reward: 846.43
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7189
    Episode_Reward/rotating_object: 167.6643
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 1.83s
                      Time elapsed: 00:30:14
                               ETA: 00:19:38

################################################################################
                     [1m Learning iteration 910/1500 [0m                      

                       Computation: 53959 steps/s (collection: 1.714s, learning 0.108s)
             Mean action noise std: 2.59
          Mean value_function loss: 15.2970
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 40.7119
                       Mean reward: 844.85
               Mean episode length: 248.40
    Episode_Reward/reaching_object: 0.7231
    Episode_Reward/rotating_object: 169.4248
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 1.82s
                      Time elapsed: 00:30:16
                               ETA: 00:19:36

################################################################################
                     [1m Learning iteration 911/1500 [0m                      

                       Computation: 53777 steps/s (collection: 1.709s, learning 0.119s)
             Mean action noise std: 2.59
          Mean value_function loss: 15.5865
               Mean surrogate loss: 0.0043
                 Mean entropy loss: 40.7289
                       Mean reward: 849.03
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7224
    Episode_Reward/rotating_object: 167.8716
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 1.83s
                      Time elapsed: 00:30:18
                               ETA: 00:19:34

################################################################################
                     [1m Learning iteration 912/1500 [0m                      

                       Computation: 54276 steps/s (collection: 1.693s, learning 0.118s)
             Mean action noise std: 2.59
          Mean value_function loss: 17.9391
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.7310
                       Mean reward: 845.00
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 0.7253
    Episode_Reward/rotating_object: 168.3448
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 1.81s
                      Time elapsed: 00:30:20
                               ETA: 00:19:32

################################################################################
                     [1m Learning iteration 913/1500 [0m                      

                       Computation: 55385 steps/s (collection: 1.681s, learning 0.094s)
             Mean action noise std: 2.60
          Mean value_function loss: 16.6245
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 40.7377
                       Mean reward: 860.36
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7198
    Episode_Reward/rotating_object: 168.6631
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 1.77s
                      Time elapsed: 00:30:22
                               ETA: 00:19:30

################################################################################
                     [1m Learning iteration 914/1500 [0m                      

                       Computation: 55089 steps/s (collection: 1.679s, learning 0.106s)
             Mean action noise std: 2.60
          Mean value_function loss: 13.1805
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 40.7523
                       Mean reward: 855.92
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7265
    Episode_Reward/rotating_object: 169.0843
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 1.78s
                      Time elapsed: 00:30:23
                               ETA: 00:19:28

################################################################################
                     [1m Learning iteration 915/1500 [0m                      

                       Computation: 54246 steps/s (collection: 1.709s, learning 0.104s)
             Mean action noise std: 2.60
          Mean value_function loss: 11.4908
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.7673
                       Mean reward: 862.90
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7225
    Episode_Reward/rotating_object: 168.8996
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 1.81s
                      Time elapsed: 00:30:25
                               ETA: 00:19:26

################################################################################
                     [1m Learning iteration 916/1500 [0m                      

                       Computation: 52360 steps/s (collection: 1.727s, learning 0.151s)
             Mean action noise std: 2.60
          Mean value_function loss: 15.8851
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 40.7895
                       Mean reward: 838.55
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.7321
    Episode_Reward/rotating_object: 168.2370
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 1.88s
                      Time elapsed: 00:30:27
                               ETA: 00:19:23

################################################################################
                     [1m Learning iteration 917/1500 [0m                      

                       Computation: 53992 steps/s (collection: 1.726s, learning 0.095s)
             Mean action noise std: 2.61
          Mean value_function loss: 13.6057
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 40.8056
                       Mean reward: 852.36
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7358
    Episode_Reward/rotating_object: 169.7925
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 1.82s
                      Time elapsed: 00:30:29
                               ETA: 00:19:21

################################################################################
                     [1m Learning iteration 918/1500 [0m                      

                       Computation: 54066 steps/s (collection: 1.708s, learning 0.111s)
             Mean action noise std: 2.61
          Mean value_function loss: 17.9360
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 40.8161
                       Mean reward: 837.66
               Mean episode length: 245.59
    Episode_Reward/reaching_object: 0.7332
    Episode_Reward/rotating_object: 167.6787
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 1.82s
                      Time elapsed: 00:30:31
                               ETA: 00:19:19

################################################################################
                     [1m Learning iteration 919/1500 [0m                      

                       Computation: 53630 steps/s (collection: 1.716s, learning 0.117s)
             Mean action noise std: 2.61
          Mean value_function loss: 17.4314
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 40.8293
                       Mean reward: 824.96
               Mean episode length: 243.54
    Episode_Reward/reaching_object: 0.7321
    Episode_Reward/rotating_object: 166.7800
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 1.83s
                      Time elapsed: 00:30:33
                               ETA: 00:19:17

################################################################################
                     [1m Learning iteration 920/1500 [0m                      

                       Computation: 55411 steps/s (collection: 1.680s, learning 0.094s)
             Mean action noise std: 2.61
          Mean value_function loss: 16.1254
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.8345
                       Mean reward: 832.28
               Mean episode length: 244.34
    Episode_Reward/reaching_object: 0.7347
    Episode_Reward/rotating_object: 167.5093
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 1.77s
                      Time elapsed: 00:30:34
                               ETA: 00:19:15

################################################################################
                     [1m Learning iteration 921/1500 [0m                      

                       Computation: 52472 steps/s (collection: 1.780s, learning 0.093s)
             Mean action noise std: 2.61
          Mean value_function loss: 15.2454
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 40.8523
                       Mean reward: 838.87
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 0.7289
    Episode_Reward/rotating_object: 168.0154
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 1.87s
                      Time elapsed: 00:30:36
                               ETA: 00:19:13

################################################################################
                     [1m Learning iteration 922/1500 [0m                      

                       Computation: 53172 steps/s (collection: 1.757s, learning 0.092s)
             Mean action noise std: 2.62
          Mean value_function loss: 13.1596
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.8702
                       Mean reward: 854.52
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7382
    Episode_Reward/rotating_object: 168.6495
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 1.85s
                      Time elapsed: 00:30:38
                               ETA: 00:19:11

################################################################################
                     [1m Learning iteration 923/1500 [0m                      

                       Computation: 52092 steps/s (collection: 1.768s, learning 0.120s)
             Mean action noise std: 2.62
          Mean value_function loss: 16.0552
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 40.8868
                       Mean reward: 857.16
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7387
    Episode_Reward/rotating_object: 169.7471
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 1.89s
                      Time elapsed: 00:30:40
                               ETA: 00:19:09

################################################################################
                     [1m Learning iteration 924/1500 [0m                      

                       Computation: 52972 steps/s (collection: 1.739s, learning 0.117s)
             Mean action noise std: 2.62
          Mean value_function loss: 20.8096
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 40.8963
                       Mean reward: 839.76
               Mean episode length: 245.70
    Episode_Reward/reaching_object: 0.7228
    Episode_Reward/rotating_object: 165.6388
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 1.86s
                      Time elapsed: 00:30:42
                               ETA: 00:19:07

################################################################################
                     [1m Learning iteration 925/1500 [0m                      

                       Computation: 53774 steps/s (collection: 1.723s, learning 0.106s)
             Mean action noise std: 2.63
          Mean value_function loss: 19.8681
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.9154
                       Mean reward: 857.91
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7268
    Episode_Reward/rotating_object: 167.5769
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 1.83s
                      Time elapsed: 00:30:44
                               ETA: 00:19:05

################################################################################
                     [1m Learning iteration 926/1500 [0m                      

                       Computation: 53302 steps/s (collection: 1.746s, learning 0.098s)
             Mean action noise std: 2.63
          Mean value_function loss: 22.9112
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.9317
                       Mean reward: 833.27
               Mean episode length: 244.41
    Episode_Reward/reaching_object: 0.7190
    Episode_Reward/rotating_object: 166.9140
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 1.84s
                      Time elapsed: 00:30:46
                               ETA: 00:19:03

################################################################################
                     [1m Learning iteration 927/1500 [0m                      

                       Computation: 53017 steps/s (collection: 1.740s, learning 0.115s)
             Mean action noise std: 2.63
          Mean value_function loss: 17.8431
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 40.9507
                       Mean reward: 847.06
               Mean episode length: 248.28
    Episode_Reward/reaching_object: 0.7154
    Episode_Reward/rotating_object: 166.6660
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 1.85s
                      Time elapsed: 00:30:47
                               ETA: 00:19:01

################################################################################
                     [1m Learning iteration 928/1500 [0m                      

                       Computation: 52890 steps/s (collection: 1.756s, learning 0.103s)
             Mean action noise std: 2.63
          Mean value_function loss: 16.3160
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 40.9703
                       Mean reward: 831.05
               Mean episode length: 246.84
    Episode_Reward/reaching_object: 0.7194
    Episode_Reward/rotating_object: 165.7947
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 1.86s
                      Time elapsed: 00:30:49
                               ETA: 00:18:58

################################################################################
                     [1m Learning iteration 929/1500 [0m                      

                       Computation: 53210 steps/s (collection: 1.749s, learning 0.099s)
             Mean action noise std: 2.63
          Mean value_function loss: 16.6341
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 40.9888
                       Mean reward: 818.72
               Mean episode length: 240.94
    Episode_Reward/reaching_object: 0.7229
    Episode_Reward/rotating_object: 166.6530
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 1.85s
                      Time elapsed: 00:30:51
                               ETA: 00:18:56

################################################################################
                     [1m Learning iteration 930/1500 [0m                      

                       Computation: 51894 steps/s (collection: 1.730s, learning 0.164s)
             Mean action noise std: 2.64
          Mean value_function loss: 18.1578
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 41.0073
                       Mean reward: 829.55
               Mean episode length: 246.02
    Episode_Reward/reaching_object: 0.7279
    Episode_Reward/rotating_object: 167.5841
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 1.89s
                      Time elapsed: 00:30:53
                               ETA: 00:18:54

################################################################################
                     [1m Learning iteration 931/1500 [0m                      

                       Computation: 54481 steps/s (collection: 1.703s, learning 0.101s)
             Mean action noise std: 2.64
          Mean value_function loss: 20.2940
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.0165
                       Mean reward: 856.34
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7356
    Episode_Reward/rotating_object: 168.4621
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 18.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 1.80s
                      Time elapsed: 00:30:55
                               ETA: 00:18:52

################################################################################
                     [1m Learning iteration 932/1500 [0m                      

                       Computation: 54354 steps/s (collection: 1.711s, learning 0.098s)
             Mean action noise std: 2.64
          Mean value_function loss: 20.2087
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 41.0319
                       Mean reward: 830.65
               Mean episode length: 244.05
    Episode_Reward/reaching_object: 0.7281
    Episode_Reward/rotating_object: 166.6082
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 1.81s
                      Time elapsed: 00:30:57
                               ETA: 00:18:50

################################################################################
                     [1m Learning iteration 933/1500 [0m                      

                       Computation: 54447 steps/s (collection: 1.705s, learning 0.100s)
             Mean action noise std: 2.64
          Mean value_function loss: 16.5196
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 41.0482
                       Mean reward: 825.56
               Mean episode length: 242.47
    Episode_Reward/reaching_object: 0.7276
    Episode_Reward/rotating_object: 167.6386
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 1.81s
                      Time elapsed: 00:30:58
                               ETA: 00:18:48

################################################################################
                     [1m Learning iteration 934/1500 [0m                      

                       Computation: 53329 steps/s (collection: 1.740s, learning 0.103s)
             Mean action noise std: 2.64
          Mean value_function loss: 15.3570
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 41.0667
                       Mean reward: 829.19
               Mean episode length: 244.24
    Episode_Reward/reaching_object: 0.7242
    Episode_Reward/rotating_object: 166.1703
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 1.84s
                      Time elapsed: 00:31:00
                               ETA: 00:18:46

################################################################################
                     [1m Learning iteration 935/1500 [0m                      

                       Computation: 52068 steps/s (collection: 1.736s, learning 0.152s)
             Mean action noise std: 2.65
          Mean value_function loss: 22.0015
               Mean surrogate loss: 0.0097
                 Mean entropy loss: 41.0793
                       Mean reward: 848.61
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7296
    Episode_Reward/rotating_object: 168.1476
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 1.89s
                      Time elapsed: 00:31:02
                               ETA: 00:18:44

################################################################################
                     [1m Learning iteration 936/1500 [0m                      

                       Computation: 50661 steps/s (collection: 1.764s, learning 0.177s)
             Mean action noise std: 2.65
          Mean value_function loss: 19.9506
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 41.0819
                       Mean reward: 839.90
               Mean episode length: 248.00
    Episode_Reward/reaching_object: 0.7273
    Episode_Reward/rotating_object: 167.6505
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 1.94s
                      Time elapsed: 00:31:04
                               ETA: 00:18:42

################################################################################
                     [1m Learning iteration 937/1500 [0m                      

                       Computation: 53863 steps/s (collection: 1.693s, learning 0.132s)
             Mean action noise std: 2.65
          Mean value_function loss: 34.4673
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 41.0904
                       Mean reward: 835.91
               Mean episode length: 243.49
    Episode_Reward/reaching_object: 0.7166
    Episode_Reward/rotating_object: 165.5707
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 1.83s
                      Time elapsed: 00:31:06
                               ETA: 00:18:40

################################################################################
                     [1m Learning iteration 938/1500 [0m                      

                       Computation: 54444 steps/s (collection: 1.710s, learning 0.096s)
             Mean action noise std: 2.65
          Mean value_function loss: 20.8134
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 41.1099
                       Mean reward: 823.48
               Mean episode length: 241.29
    Episode_Reward/reaching_object: 0.7200
    Episode_Reward/rotating_object: 163.9651
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 1.81s
                      Time elapsed: 00:31:08
                               ETA: 00:18:38

################################################################################
                     [1m Learning iteration 939/1500 [0m                      

                       Computation: 54172 steps/s (collection: 1.721s, learning 0.094s)
             Mean action noise std: 2.65
          Mean value_function loss: 24.3208
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 41.1385
                       Mean reward: 835.39
               Mean episode length: 245.46
    Episode_Reward/reaching_object: 0.7350
    Episode_Reward/rotating_object: 167.5704
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 1.81s
                      Time elapsed: 00:31:10
                               ETA: 00:18:36

################################################################################
                     [1m Learning iteration 940/1500 [0m                      

                       Computation: 53649 steps/s (collection: 1.722s, learning 0.110s)
             Mean action noise std: 2.66
          Mean value_function loss: 19.5075
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.1549
                       Mean reward: 857.81
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7473
    Episode_Reward/rotating_object: 168.1842
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 1.83s
                      Time elapsed: 00:31:11
                               ETA: 00:18:33

################################################################################
                     [1m Learning iteration 941/1500 [0m                      

                       Computation: 52271 steps/s (collection: 1.757s, learning 0.124s)
             Mean action noise std: 2.66
          Mean value_function loss: 27.5892
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 41.1716
                       Mean reward: 812.97
               Mean episode length: 241.57
    Episode_Reward/reaching_object: 0.7334
    Episode_Reward/rotating_object: 164.3604
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 1.88s
                      Time elapsed: 00:31:13
                               ETA: 00:18:31

################################################################################
                     [1m Learning iteration 942/1500 [0m                      

                       Computation: 52486 steps/s (collection: 1.754s, learning 0.119s)
             Mean action noise std: 2.66
          Mean value_function loss: 19.0611
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 41.1909
                       Mean reward: 826.90
               Mean episode length: 243.87
    Episode_Reward/reaching_object: 0.7328
    Episode_Reward/rotating_object: 164.4571
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 1.87s
                      Time elapsed: 00:31:15
                               ETA: 00:18:29

################################################################################
                     [1m Learning iteration 943/1500 [0m                      

                       Computation: 53227 steps/s (collection: 1.725s, learning 0.122s)
             Mean action noise std: 2.66
          Mean value_function loss: 17.8918
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 41.2028
                       Mean reward: 855.98
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7459
    Episode_Reward/rotating_object: 169.1500
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 1.85s
                      Time elapsed: 00:31:17
                               ETA: 00:18:27

################################################################################
                     [1m Learning iteration 944/1500 [0m                      

                       Computation: 53670 steps/s (collection: 1.718s, learning 0.114s)
             Mean action noise std: 2.67
          Mean value_function loss: 18.0105
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 41.2098
                       Mean reward: 829.04
               Mean episode length: 244.83
    Episode_Reward/reaching_object: 0.7364
    Episode_Reward/rotating_object: 167.0536
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 1.83s
                      Time elapsed: 00:31:19
                               ETA: 00:18:25

################################################################################
                     [1m Learning iteration 945/1500 [0m                      

                       Computation: 53940 steps/s (collection: 1.720s, learning 0.103s)
             Mean action noise std: 2.67
          Mean value_function loss: 20.2140
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.2191
                       Mean reward: 831.68
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 0.7353
    Episode_Reward/rotating_object: 165.0093
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 1.82s
                      Time elapsed: 00:31:21
                               ETA: 00:18:23

################################################################################
                     [1m Learning iteration 946/1500 [0m                      

                       Computation: 53242 steps/s (collection: 1.728s, learning 0.118s)
             Mean action noise std: 2.67
          Mean value_function loss: 21.9707
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 41.2292
                       Mean reward: 815.39
               Mean episode length: 242.09
    Episode_Reward/reaching_object: 0.7289
    Episode_Reward/rotating_object: 165.3322
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 1.85s
                      Time elapsed: 00:31:22
                               ETA: 00:18:21

################################################################################
                     [1m Learning iteration 947/1500 [0m                      

                       Computation: 53951 steps/s (collection: 1.720s, learning 0.102s)
             Mean action noise std: 2.67
          Mean value_function loss: 19.3997
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 41.2451
                       Mean reward: 837.89
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 0.7393
    Episode_Reward/rotating_object: 167.1055
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 1.82s
                      Time elapsed: 00:31:24
                               ETA: 00:18:19

################################################################################
                     [1m Learning iteration 948/1500 [0m                      

                       Computation: 52967 steps/s (collection: 1.752s, learning 0.104s)
             Mean action noise std: 2.67
          Mean value_function loss: 19.2154
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 41.2626
                       Mean reward: 839.83
               Mean episode length: 246.18
    Episode_Reward/reaching_object: 0.7314
    Episode_Reward/rotating_object: 165.4977
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 1.86s
                      Time elapsed: 00:31:26
                               ETA: 00:18:17

################################################################################
                     [1m Learning iteration 949/1500 [0m                      

                       Computation: 52170 steps/s (collection: 1.721s, learning 0.163s)
             Mean action noise std: 2.68
          Mean value_function loss: 13.6149
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.2740
                       Mean reward: 836.76
               Mean episode length: 245.52
    Episode_Reward/reaching_object: 0.7427
    Episode_Reward/rotating_object: 168.0083
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 1.88s
                      Time elapsed: 00:31:28
                               ETA: 00:18:15

################################################################################
                     [1m Learning iteration 950/1500 [0m                      

                       Computation: 53200 steps/s (collection: 1.719s, learning 0.129s)
             Mean action noise std: 2.68
          Mean value_function loss: 18.7652
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.2853
                       Mean reward: 852.97
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7412
    Episode_Reward/rotating_object: 166.4349
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 1.85s
                      Time elapsed: 00:31:30
                               ETA: 00:18:13

################################################################################
                     [1m Learning iteration 951/1500 [0m                      

                       Computation: 52660 steps/s (collection: 1.770s, learning 0.097s)
             Mean action noise std: 2.68
          Mean value_function loss: 23.8569
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 41.2981
                       Mean reward: 846.94
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7339
    Episode_Reward/rotating_object: 163.3806
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 1.87s
                      Time elapsed: 00:31:32
                               ETA: 00:18:11

################################################################################
                     [1m Learning iteration 952/1500 [0m                      

                       Computation: 54718 steps/s (collection: 1.702s, learning 0.095s)
             Mean action noise std: 2.68
          Mean value_function loss: 18.7286
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 41.3149
                       Mean reward: 816.74
               Mean episode length: 243.18
    Episode_Reward/reaching_object: 0.7399
    Episode_Reward/rotating_object: 166.6754
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 18.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 1.80s
                      Time elapsed: 00:31:34
                               ETA: 00:18:09

################################################################################
                     [1m Learning iteration 953/1500 [0m                      

                       Computation: 53739 steps/s (collection: 1.735s, learning 0.094s)
             Mean action noise std: 2.69
          Mean value_function loss: 16.8151
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 41.3340
                       Mean reward: 840.50
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7499
    Episode_Reward/rotating_object: 168.8576
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 1.83s
                      Time elapsed: 00:31:35
                               ETA: 00:18:07

################################################################################
                     [1m Learning iteration 954/1500 [0m                      

                       Computation: 52497 steps/s (collection: 1.755s, learning 0.118s)
             Mean action noise std: 2.69
          Mean value_function loss: 23.4870
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.3482
                       Mean reward: 842.83
               Mean episode length: 246.85
    Episode_Reward/reaching_object: 0.7387
    Episode_Reward/rotating_object: 166.5784
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 1.87s
                      Time elapsed: 00:31:37
                               ETA: 00:18:05

################################################################################
                     [1m Learning iteration 955/1500 [0m                      

                       Computation: 51357 steps/s (collection: 1.790s, learning 0.124s)
             Mean action noise std: 2.69
          Mean value_function loss: 22.3101
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 41.3709
                       Mean reward: 861.00
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7404
    Episode_Reward/rotating_object: 167.3096
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 1.91s
                      Time elapsed: 00:31:39
                               ETA: 00:18:02

################################################################################
                     [1m Learning iteration 956/1500 [0m                      

                       Computation: 52502 steps/s (collection: 1.738s, learning 0.134s)
             Mean action noise std: 2.69
          Mean value_function loss: 16.9371
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.3818
                       Mean reward: 832.39
               Mean episode length: 244.02
    Episode_Reward/reaching_object: 0.7421
    Episode_Reward/rotating_object: 168.1061
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 1.87s
                      Time elapsed: 00:31:41
                               ETA: 00:18:00

################################################################################
                     [1m Learning iteration 957/1500 [0m                      

                       Computation: 53663 steps/s (collection: 1.727s, learning 0.105s)
             Mean action noise std: 2.70
          Mean value_function loss: 15.4417
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 41.3960
                       Mean reward: 852.32
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7403
    Episode_Reward/rotating_object: 167.0639
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 1.83s
                      Time elapsed: 00:31:43
                               ETA: 00:17:58

################################################################################
                     [1m Learning iteration 958/1500 [0m                      

                       Computation: 53375 steps/s (collection: 1.729s, learning 0.113s)
             Mean action noise std: 2.70
          Mean value_function loss: 17.4080
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.4147
                       Mean reward: 830.64
               Mean episode length: 244.52
    Episode_Reward/reaching_object: 0.7369
    Episode_Reward/rotating_object: 167.1688
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 1.84s
                      Time elapsed: 00:31:45
                               ETA: 00:17:56

################################################################################
                     [1m Learning iteration 959/1500 [0m                      

                       Computation: 53972 steps/s (collection: 1.720s, learning 0.101s)
             Mean action noise std: 2.70
          Mean value_function loss: 15.0838
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 41.4276
                       Mean reward: 848.32
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7394
    Episode_Reward/rotating_object: 168.8912
        Episode_Reward/action_rate: -0.0355
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 1.82s
                      Time elapsed: 00:31:47
                               ETA: 00:17:54

################################################################################
                     [1m Learning iteration 960/1500 [0m                      

                       Computation: 52992 steps/s (collection: 1.742s, learning 0.113s)
             Mean action noise std: 2.70
          Mean value_function loss: 11.6418
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 41.4378
                       Mean reward: 828.68
               Mean episode length: 248.28
    Episode_Reward/reaching_object: 0.7462
    Episode_Reward/rotating_object: 168.5976
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 1.86s
                      Time elapsed: 00:31:48
                               ETA: 00:17:52

################################################################################
                     [1m Learning iteration 961/1500 [0m                      

                       Computation: 53031 steps/s (collection: 1.752s, learning 0.102s)
             Mean action noise std: 2.70
          Mean value_function loss: 16.5763
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.4432
                       Mean reward: 849.44
               Mean episode length: 247.97
    Episode_Reward/reaching_object: 0.7392
    Episode_Reward/rotating_object: 169.0475
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 1.85s
                      Time elapsed: 00:31:50
                               ETA: 00:17:50

################################################################################
                     [1m Learning iteration 962/1500 [0m                      

                       Computation: 54195 steps/s (collection: 1.721s, learning 0.093s)
             Mean action noise std: 2.71
          Mean value_function loss: 15.6374
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.4588
                       Mean reward: 847.22
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.7360
    Episode_Reward/rotating_object: 168.3275
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 1.81s
                      Time elapsed: 00:31:52
                               ETA: 00:17:48

################################################################################
                     [1m Learning iteration 963/1500 [0m                      

                       Computation: 53693 steps/s (collection: 1.728s, learning 0.103s)
             Mean action noise std: 2.71
          Mean value_function loss: 16.8904
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 41.4713
                       Mean reward: 844.84
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 0.7285
    Episode_Reward/rotating_object: 167.1701
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 1.83s
                      Time elapsed: 00:31:54
                               ETA: 00:17:46

################################################################################
                     [1m Learning iteration 964/1500 [0m                      

                       Computation: 53733 steps/s (collection: 1.724s, learning 0.105s)
             Mean action noise std: 2.71
          Mean value_function loss: 20.1059
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.4826
                       Mean reward: 840.09
               Mean episode length: 247.52
    Episode_Reward/reaching_object: 0.7291
    Episode_Reward/rotating_object: 168.3214
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 1.83s
                      Time elapsed: 00:31:56
                               ETA: 00:17:44

################################################################################
                     [1m Learning iteration 965/1500 [0m                      

                       Computation: 53951 steps/s (collection: 1.717s, learning 0.105s)
             Mean action noise std: 2.71
          Mean value_function loss: 11.2225
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.4923
                       Mean reward: 823.67
               Mean episode length: 245.73
    Episode_Reward/reaching_object: 0.7209
    Episode_Reward/rotating_object: 166.6153
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 1.82s
                      Time elapsed: 00:31:58
                               ETA: 00:17:42

################################################################################
                     [1m Learning iteration 966/1500 [0m                      

                       Computation: 53593 steps/s (collection: 1.708s, learning 0.126s)
             Mean action noise std: 2.71
          Mean value_function loss: 12.2832
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 41.5005
                       Mean reward: 857.31
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7256
    Episode_Reward/rotating_object: 167.9861
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 1.83s
                      Time elapsed: 00:31:59
                               ETA: 00:17:40

################################################################################
                     [1m Learning iteration 967/1500 [0m                      

                       Computation: 53535 steps/s (collection: 1.706s, learning 0.131s)
             Mean action noise std: 2.72
          Mean value_function loss: 16.0652
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 41.5095
                       Mean reward: 848.78
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 0.7164
    Episode_Reward/rotating_object: 167.4343
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 1.84s
                      Time elapsed: 00:32:01
                               ETA: 00:17:38

################################################################################
                     [1m Learning iteration 968/1500 [0m                      

                       Computation: 54652 steps/s (collection: 1.699s, learning 0.100s)
             Mean action noise std: 2.72
          Mean value_function loss: 9.7307
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 41.5236
                       Mean reward: 859.52
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7135
    Episode_Reward/rotating_object: 167.6987
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 1.80s
                      Time elapsed: 00:32:03
                               ETA: 00:17:36

################################################################################
                     [1m Learning iteration 969/1500 [0m                      

                       Computation: 52912 steps/s (collection: 1.747s, learning 0.110s)
             Mean action noise std: 2.72
          Mean value_function loss: 13.6803
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 41.5292
                       Mean reward: 839.76
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7100
    Episode_Reward/rotating_object: 168.1263
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 1.86s
                      Time elapsed: 00:32:05
                               ETA: 00:17:33

################################################################################
                     [1m Learning iteration 970/1500 [0m                      

                       Computation: 52587 steps/s (collection: 1.777s, learning 0.093s)
             Mean action noise std: 2.72
          Mean value_function loss: 12.5324
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 41.5338
                       Mean reward: 858.69
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7098
    Episode_Reward/rotating_object: 169.1431
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 1.87s
                      Time elapsed: 00:32:07
                               ETA: 00:17:31

################################################################################
                     [1m Learning iteration 971/1500 [0m                      

                       Computation: 52574 steps/s (collection: 1.772s, learning 0.098s)
             Mean action noise std: 2.72
          Mean value_function loss: 12.2176
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 41.5435
                       Mean reward: 852.42
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 0.7059
    Episode_Reward/rotating_object: 170.2902
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 1.87s
                      Time elapsed: 00:32:09
                               ETA: 00:17:29

################################################################################
                     [1m Learning iteration 972/1500 [0m                      

                       Computation: 52586 steps/s (collection: 1.761s, learning 0.109s)
             Mean action noise std: 2.72
          Mean value_function loss: 20.1644
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 41.5543
                       Mean reward: 857.69
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7008
    Episode_Reward/rotating_object: 169.0684
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 1.87s
                      Time elapsed: 00:32:10
                               ETA: 00:17:27

################################################################################
                     [1m Learning iteration 973/1500 [0m                      

                       Computation: 49956 steps/s (collection: 1.842s, learning 0.125s)
             Mean action noise std: 2.73
          Mean value_function loss: 19.3256
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.5653
                       Mean reward: 841.82
               Mean episode length: 246.76
    Episode_Reward/reaching_object: 0.6888
    Episode_Reward/rotating_object: 167.8168
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 1.97s
                      Time elapsed: 00:32:12
                               ETA: 00:17:25

################################################################################
                     [1m Learning iteration 974/1500 [0m                      

                       Computation: 48919 steps/s (collection: 1.857s, learning 0.153s)
             Mean action noise std: 2.73
          Mean value_function loss: 14.8542
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 41.5802
                       Mean reward: 840.52
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 0.6886
    Episode_Reward/rotating_object: 166.6183
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 2.01s
                      Time elapsed: 00:32:14
                               ETA: 00:17:23

################################################################################
                     [1m Learning iteration 975/1500 [0m                      

                       Computation: 51509 steps/s (collection: 1.777s, learning 0.131s)
             Mean action noise std: 2.73
          Mean value_function loss: 10.8381
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.5827
                       Mean reward: 845.81
               Mean episode length: 246.72
    Episode_Reward/reaching_object: 0.6955
    Episode_Reward/rotating_object: 169.8660
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 1.91s
                      Time elapsed: 00:32:16
                               ETA: 00:17:21

################################################################################
                     [1m Learning iteration 976/1500 [0m                      

                       Computation: 51500 steps/s (collection: 1.804s, learning 0.105s)
             Mean action noise std: 2.73
          Mean value_function loss: 16.8494
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 41.5840
                       Mean reward: 835.01
               Mean episode length: 245.85
    Episode_Reward/reaching_object: 0.6806
    Episode_Reward/rotating_object: 167.6624
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 1.91s
                      Time elapsed: 00:32:18
                               ETA: 00:17:19

################################################################################
                     [1m Learning iteration 977/1500 [0m                      

                       Computation: 51571 steps/s (collection: 1.770s, learning 0.136s)
             Mean action noise std: 2.73
          Mean value_function loss: 11.1728
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 41.5922
                       Mean reward: 853.68
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6918
    Episode_Reward/rotating_object: 169.5941
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 1.91s
                      Time elapsed: 00:32:20
                               ETA: 00:17:17

################################################################################
                     [1m Learning iteration 978/1500 [0m                      

                       Computation: 53147 steps/s (collection: 1.748s, learning 0.102s)
             Mean action noise std: 2.73
          Mean value_function loss: 19.3676
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 41.6073
                       Mean reward: 837.79
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.6870
    Episode_Reward/rotating_object: 167.8478
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 1.85s
                      Time elapsed: 00:32:22
                               ETA: 00:17:15

################################################################################
                     [1m Learning iteration 979/1500 [0m                      

                       Computation: 53051 steps/s (collection: 1.754s, learning 0.099s)
             Mean action noise std: 2.74
          Mean value_function loss: 18.5148
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 41.6267
                       Mean reward: 832.17
               Mean episode length: 245.80
    Episode_Reward/reaching_object: 0.6815
    Episode_Reward/rotating_object: 165.8641
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 1.85s
                      Time elapsed: 00:32:24
                               ETA: 00:17:13

################################################################################
                     [1m Learning iteration 980/1500 [0m                      

                       Computation: 52873 steps/s (collection: 1.759s, learning 0.101s)
             Mean action noise std: 2.74
          Mean value_function loss: 12.7874
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 41.6441
                       Mean reward: 841.34
               Mean episode length: 246.82
    Episode_Reward/reaching_object: 0.6872
    Episode_Reward/rotating_object: 167.6006
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 1.86s
                      Time elapsed: 00:32:26
                               ETA: 00:17:11

################################################################################
                     [1m Learning iteration 981/1500 [0m                      

                       Computation: 53859 steps/s (collection: 1.732s, learning 0.094s)
             Mean action noise std: 2.74
          Mean value_function loss: 11.2937
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 41.6522
                       Mean reward: 858.18
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6927
    Episode_Reward/rotating_object: 169.6191
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 1.83s
                      Time elapsed: 00:32:28
                               ETA: 00:17:09

################################################################################
                     [1m Learning iteration 982/1500 [0m                      

                       Computation: 51963 steps/s (collection: 1.764s, learning 0.128s)
             Mean action noise std: 2.74
          Mean value_function loss: 7.1215
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 41.6618
                       Mean reward: 863.71
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6935
    Episode_Reward/rotating_object: 168.9343
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 1.89s
                      Time elapsed: 00:32:29
                               ETA: 00:17:07

################################################################################
                     [1m Learning iteration 983/1500 [0m                      

                       Computation: 51851 steps/s (collection: 1.776s, learning 0.120s)
             Mean action noise std: 2.74
          Mean value_function loss: 11.7861
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 41.6680
                       Mean reward: 845.82
               Mean episode length: 246.15
    Episode_Reward/reaching_object: 0.6941
    Episode_Reward/rotating_object: 169.3579
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 18.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 1.90s
                      Time elapsed: 00:32:31
                               ETA: 00:17:05

################################################################################
                     [1m Learning iteration 984/1500 [0m                      

                       Computation: 50873 steps/s (collection: 1.807s, learning 0.126s)
             Mean action noise std: 2.74
          Mean value_function loss: 13.6342
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 41.6715
                       Mean reward: 837.91
               Mean episode length: 244.56
    Episode_Reward/reaching_object: 0.6922
    Episode_Reward/rotating_object: 168.5017
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 1.93s
                      Time elapsed: 00:32:33
                               ETA: 00:17:03

################################################################################
                     [1m Learning iteration 985/1500 [0m                      

                       Computation: 53640 steps/s (collection: 1.737s, learning 0.096s)
             Mean action noise std: 2.75
          Mean value_function loss: 13.9192
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.6777
                       Mean reward: 852.37
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6983
    Episode_Reward/rotating_object: 169.7302
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 1.83s
                      Time elapsed: 00:32:35
                               ETA: 00:17:01

################################################################################
                     [1m Learning iteration 986/1500 [0m                      

                       Computation: 52592 steps/s (collection: 1.771s, learning 0.099s)
             Mean action noise std: 2.75
          Mean value_function loss: 13.7238
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 41.6962
                       Mean reward: 862.84
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7022
    Episode_Reward/rotating_object: 169.6820
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 1.87s
                      Time elapsed: 00:32:37
                               ETA: 00:16:59

################################################################################
                     [1m Learning iteration 987/1500 [0m                      

                       Computation: 53129 steps/s (collection: 1.749s, learning 0.102s)
             Mean action noise std: 2.75
          Mean value_function loss: 25.5041
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.7150
                       Mean reward: 834.82
               Mean episode length: 243.52
    Episode_Reward/reaching_object: 0.6957
    Episode_Reward/rotating_object: 167.3866
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 1.85s
                      Time elapsed: 00:32:39
                               ETA: 00:16:57

################################################################################
                     [1m Learning iteration 988/1500 [0m                      

                       Computation: 52479 steps/s (collection: 1.763s, learning 0.111s)
             Mean action noise std: 2.76
          Mean value_function loss: 13.7954
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 41.7351
                       Mean reward: 849.57
               Mean episode length: 248.02
    Episode_Reward/reaching_object: 0.6977
    Episode_Reward/rotating_object: 166.7137
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 1.87s
                      Time elapsed: 00:32:41
                               ETA: 00:16:55

################################################################################
                     [1m Learning iteration 989/1500 [0m                      

                       Computation: 52099 steps/s (collection: 1.788s, learning 0.099s)
             Mean action noise std: 2.76
          Mean value_function loss: 14.9572
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 41.7455
                       Mean reward: 837.51
               Mean episode length: 243.98
    Episode_Reward/reaching_object: 0.7104
    Episode_Reward/rotating_object: 169.2064
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 1.89s
                      Time elapsed: 00:32:43
                               ETA: 00:16:53

################################################################################
                     [1m Learning iteration 990/1500 [0m                      

                       Computation: 51671 steps/s (collection: 1.758s, learning 0.145s)
             Mean action noise std: 2.76
          Mean value_function loss: 17.1062
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 41.7536
                       Mean reward: 840.40
               Mean episode length: 246.08
    Episode_Reward/reaching_object: 0.7073
    Episode_Reward/rotating_object: 168.7530
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 1.90s
                      Time elapsed: 00:32:45
                               ETA: 00:16:51

################################################################################
                     [1m Learning iteration 991/1500 [0m                      

                       Computation: 52232 steps/s (collection: 1.737s, learning 0.145s)
             Mean action noise std: 2.76
          Mean value_function loss: 13.6213
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.7660
                       Mean reward: 832.64
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 0.7055
    Episode_Reward/rotating_object: 166.3859
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 1.88s
                      Time elapsed: 00:32:46
                               ETA: 00:16:49

################################################################################
                     [1m Learning iteration 992/1500 [0m                      

                       Computation: 53186 steps/s (collection: 1.712s, learning 0.136s)
             Mean action noise std: 2.76
          Mean value_function loss: 13.5638
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 41.7824
                       Mean reward: 860.86
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7228
    Episode_Reward/rotating_object: 170.3112
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 1.85s
                      Time elapsed: 00:32:48
                               ETA: 00:16:47

################################################################################
                     [1m Learning iteration 993/1500 [0m                      

                       Computation: 53765 steps/s (collection: 1.733s, learning 0.096s)
             Mean action noise std: 2.77
          Mean value_function loss: 9.1011
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.7921
                       Mean reward: 857.67
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7194
    Episode_Reward/rotating_object: 169.6086
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 1.83s
                      Time elapsed: 00:32:50
                               ETA: 00:16:45

################################################################################
                     [1m Learning iteration 994/1500 [0m                      

                       Computation: 52977 steps/s (collection: 1.734s, learning 0.121s)
             Mean action noise std: 2.77
          Mean value_function loss: 13.0365
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 41.7944
                       Mean reward: 850.86
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7249
    Episode_Reward/rotating_object: 169.0079
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 18.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 1.86s
                      Time elapsed: 00:32:52
                               ETA: 00:16:43

################################################################################
                     [1m Learning iteration 995/1500 [0m                      

                       Computation: 51294 steps/s (collection: 1.810s, learning 0.106s)
             Mean action noise std: 2.77
          Mean value_function loss: 18.2176
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 41.8046
                       Mean reward: 842.85
               Mean episode length: 245.55
    Episode_Reward/reaching_object: 0.7190
    Episode_Reward/rotating_object: 169.3664
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 1.92s
                      Time elapsed: 00:32:54
                               ETA: 00:16:41

################################################################################
                     [1m Learning iteration 996/1500 [0m                      

                       Computation: 51650 steps/s (collection: 1.800s, learning 0.103s)
             Mean action noise std: 2.77
          Mean value_function loss: 14.5931
               Mean surrogate loss: 0.0068
                 Mean entropy loss: 41.8138
                       Mean reward: 843.20
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 0.7207
    Episode_Reward/rotating_object: 168.9298
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 1.90s
                      Time elapsed: 00:32:56
                               ETA: 00:16:39

################################################################################
                     [1m Learning iteration 997/1500 [0m                      

                       Computation: 50481 steps/s (collection: 1.816s, learning 0.132s)
             Mean action noise std: 2.77
          Mean value_function loss: 13.5756
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 41.8154
                       Mean reward: 860.39
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7276
    Episode_Reward/rotating_object: 167.8339
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 1.95s
                      Time elapsed: 00:32:58
                               ETA: 00:16:37

################################################################################
                     [1m Learning iteration 998/1500 [0m                      

                       Computation: 54632 steps/s (collection: 1.699s, learning 0.100s)
             Mean action noise std: 2.77
          Mean value_function loss: 14.8088
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.8281
                       Mean reward: 842.71
               Mean episode length: 246.06
    Episode_Reward/reaching_object: 0.7162
    Episode_Reward/rotating_object: 168.1831
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 1.80s
                      Time elapsed: 00:32:59
                               ETA: 00:16:34

################################################################################
                     [1m Learning iteration 999/1500 [0m                      

                       Computation: 52873 steps/s (collection: 1.720s, learning 0.140s)
             Mean action noise std: 2.78
          Mean value_function loss: 10.5474
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.8501
                       Mean reward: 863.02
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7140
    Episode_Reward/rotating_object: 168.8403
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 1.86s
                      Time elapsed: 00:33:01
                               ETA: 00:16:32

################################################################################
                     [1m Learning iteration 1000/1500 [0m                     

                       Computation: 14998 steps/s (collection: 6.410s, learning 0.144s)
             Mean action noise std: 2.78
          Mean value_function loss: 16.9084
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 41.8629
                       Mean reward: 850.21
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7136
    Episode_Reward/rotating_object: 168.3480
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 6.55s
                      Time elapsed: 00:33:08
                               ETA: 00:16:33

################################################################################
                     [1m Learning iteration 1001/1500 [0m                     

                       Computation: 14542 steps/s (collection: 6.591s, learning 0.169s)
             Mean action noise std: 2.78
          Mean value_function loss: 17.3140
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 41.8739
                       Mean reward: 834.11
               Mean episode length: 243.47
    Episode_Reward/reaching_object: 0.7151
    Episode_Reward/rotating_object: 168.3983
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 6.76s
                      Time elapsed: 00:33:15
                               ETA: 00:16:33

################################################################################
                     [1m Learning iteration 1002/1500 [0m                     

                       Computation: 14678 steps/s (collection: 6.564s, learning 0.133s)
             Mean action noise std: 2.78
          Mean value_function loss: 10.3258
               Mean surrogate loss: 0.0043
                 Mean entropy loss: 41.8852
                       Mean reward: 842.30
               Mean episode length: 246.06
    Episode_Reward/reaching_object: 0.7184
    Episode_Reward/rotating_object: 168.5861
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 6.70s
                      Time elapsed: 00:33:21
                               ETA: 00:16:33

################################################################################
                     [1m Learning iteration 1003/1500 [0m                     

                       Computation: 14659 steps/s (collection: 6.584s, learning 0.122s)
             Mean action noise std: 2.78
          Mean value_function loss: 13.6658
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 41.8874
                       Mean reward: 847.63
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7203
    Episode_Reward/rotating_object: 168.1481
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 6.71s
                      Time elapsed: 00:33:28
                               ETA: 00:16:34

################################################################################
                     [1m Learning iteration 1004/1500 [0m                     

                       Computation: 14550 steps/s (collection: 6.580s, learning 0.176s)
             Mean action noise std: 2.79
          Mean value_function loss: 18.7725
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 41.8989
                       Mean reward: 842.34
               Mean episode length: 245.62
    Episode_Reward/reaching_object: 0.7249
    Episode_Reward/rotating_object: 168.3238
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 18.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 6.76s
                      Time elapsed: 00:33:35
                               ETA: 00:16:34

################################################################################
                     [1m Learning iteration 1005/1500 [0m                     

                       Computation: 14396 steps/s (collection: 6.629s, learning 0.199s)
             Mean action noise std: 2.79
          Mean value_function loss: 15.8281
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.9186
                       Mean reward: 838.65
               Mean episode length: 246.56
    Episode_Reward/reaching_object: 0.7298
    Episode_Reward/rotating_object: 168.4798
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 6.83s
                      Time elapsed: 00:33:42
                               ETA: 00:16:34

################################################################################
                     [1m Learning iteration 1006/1500 [0m                     

                       Computation: 14194 steps/s (collection: 6.780s, learning 0.145s)
             Mean action noise std: 2.79
          Mean value_function loss: 13.5785
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 41.9409
                       Mean reward: 850.89
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 0.7331
    Episode_Reward/rotating_object: 167.9167
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 6.93s
                      Time elapsed: 00:33:49
                               ETA: 00:16:35

################################################################################
                     [1m Learning iteration 1007/1500 [0m                     

                       Computation: 14549 steps/s (collection: 6.631s, learning 0.125s)
             Mean action noise std: 2.79
          Mean value_function loss: 10.8931
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 41.9486
                       Mean reward: 849.12
               Mean episode length: 248.07
    Episode_Reward/reaching_object: 0.7472
    Episode_Reward/rotating_object: 169.1061
        Episode_Reward/action_rate: -0.0384
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 6.76s
                      Time elapsed: 00:33:55
                               ETA: 00:16:35

################################################################################
                     [1m Learning iteration 1008/1500 [0m                     

                       Computation: 17560 steps/s (collection: 5.448s, learning 0.150s)
             Mean action noise std: 2.80
          Mean value_function loss: 11.2083
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.9588
                       Mean reward: 850.77
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7464
    Episode_Reward/rotating_object: 169.7552
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 5.60s
                      Time elapsed: 00:34:01
                               ETA: 00:16:35

################################################################################
                     [1m Learning iteration 1009/1500 [0m                     

                       Computation: 50694 steps/s (collection: 1.800s, learning 0.140s)
             Mean action noise std: 2.80
          Mean value_function loss: 12.3192
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 41.9700
                       Mean reward: 850.41
               Mean episode length: 247.94
    Episode_Reward/reaching_object: 0.7431
    Episode_Reward/rotating_object: 168.0552
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 1.94s
                      Time elapsed: 00:34:03
                               ETA: 00:16:33

################################################################################
                     [1m Learning iteration 1010/1500 [0m                     

                       Computation: 58333 steps/s (collection: 1.595s, learning 0.090s)
             Mean action noise std: 2.80
          Mean value_function loss: 14.3314
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.9837
                       Mean reward: 852.89
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 0.7561
    Episode_Reward/rotating_object: 170.4503
        Episode_Reward/action_rate: -0.0384
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 1.69s
                      Time elapsed: 00:34:05
                               ETA: 00:16:31

################################################################################
                     [1m Learning iteration 1011/1500 [0m                     

                       Computation: 57114 steps/s (collection: 1.627s, learning 0.094s)
             Mean action noise std: 2.80
          Mean value_function loss: 15.3893
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 42.0033
                       Mean reward: 853.81
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 0.7454
    Episode_Reward/rotating_object: 167.4946
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 1.72s
                      Time elapsed: 00:34:06
                               ETA: 00:16:29

################################################################################
                     [1m Learning iteration 1012/1500 [0m                     

                       Computation: 56280 steps/s (collection: 1.649s, learning 0.098s)
             Mean action noise std: 2.80
          Mean value_function loss: 9.5329
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.0116
                       Mean reward: 862.10
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7685
    Episode_Reward/rotating_object: 171.3769
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 1.75s
                      Time elapsed: 00:34:08
                               ETA: 00:16:26

################################################################################
                     [1m Learning iteration 1013/1500 [0m                     

                       Computation: 57524 steps/s (collection: 1.613s, learning 0.096s)
             Mean action noise std: 2.81
          Mean value_function loss: 8.8845
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 42.0156
                       Mean reward: 852.51
               Mean episode length: 247.97
    Episode_Reward/reaching_object: 0.7699
    Episode_Reward/rotating_object: 170.6280
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 1.71s
                      Time elapsed: 00:34:10
                               ETA: 00:16:24

################################################################################
                     [1m Learning iteration 1014/1500 [0m                     

                       Computation: 57361 steps/s (collection: 1.619s, learning 0.094s)
             Mean action noise std: 2.81
          Mean value_function loss: 9.6200
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.0162
                       Mean reward: 860.55
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7730
    Episode_Reward/rotating_object: 170.6206
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 1.71s
                      Time elapsed: 00:34:11
                               ETA: 00:16:22

################################################################################
                     [1m Learning iteration 1015/1500 [0m                     

                       Computation: 55980 steps/s (collection: 1.660s, learning 0.096s)
             Mean action noise std: 2.81
          Mean value_function loss: 14.5633
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.0145
                       Mean reward: 861.61
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7689
    Episode_Reward/rotating_object: 170.2098
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 1.76s
                      Time elapsed: 00:34:13
                               ETA: 00:16:20

################################################################################
                     [1m Learning iteration 1016/1500 [0m                     

                       Computation: 56068 steps/s (collection: 1.647s, learning 0.107s)
             Mean action noise std: 2.81
          Mean value_function loss: 11.9603
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.0158
                       Mean reward: 859.79
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7699
    Episode_Reward/rotating_object: 168.9886
        Episode_Reward/action_rate: -0.0384
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 1.75s
                      Time elapsed: 00:34:15
                               ETA: 00:16:18

################################################################################
                     [1m Learning iteration 1017/1500 [0m                     

                       Computation: 53889 steps/s (collection: 1.649s, learning 0.176s)
             Mean action noise std: 2.81
          Mean value_function loss: 15.8059
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 42.0179
                       Mean reward: 858.97
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7734
    Episode_Reward/rotating_object: 169.1581
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 1.82s
                      Time elapsed: 00:34:17
                               ETA: 00:16:16

################################################################################
                     [1m Learning iteration 1018/1500 [0m                     

                       Computation: 52718 steps/s (collection: 1.769s, learning 0.096s)
             Mean action noise std: 2.81
          Mean value_function loss: 16.9903
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 42.0292
                       Mean reward: 836.86
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 0.7683
    Episode_Reward/rotating_object: 168.3925
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 1.86s
                      Time elapsed: 00:34:19
                               ETA: 00:16:14

################################################################################
                     [1m Learning iteration 1019/1500 [0m                     

                       Computation: 54963 steps/s (collection: 1.699s, learning 0.090s)
             Mean action noise std: 2.81
          Mean value_function loss: 15.8884
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.0364
                       Mean reward: 844.42
               Mean episode length: 246.37
    Episode_Reward/reaching_object: 0.7646
    Episode_Reward/rotating_object: 167.6566
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 1.79s
                      Time elapsed: 00:34:20
                               ETA: 00:16:11

################################################################################
                     [1m Learning iteration 1020/1500 [0m                     

                       Computation: 52419 steps/s (collection: 1.771s, learning 0.104s)
             Mean action noise std: 2.82
          Mean value_function loss: 12.8212
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 42.0487
                       Mean reward: 854.05
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 0.7659
    Episode_Reward/rotating_object: 168.1302
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 1.88s
                      Time elapsed: 00:34:22
                               ETA: 00:16:09

################################################################################
                     [1m Learning iteration 1021/1500 [0m                     

                       Computation: 56915 steps/s (collection: 1.609s, learning 0.118s)
             Mean action noise std: 2.82
          Mean value_function loss: 18.4919
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 42.0576
                       Mean reward: 857.40
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7710
    Episode_Reward/rotating_object: 168.0763
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 1.73s
                      Time elapsed: 00:34:24
                               ETA: 00:16:07

################################################################################
                     [1m Learning iteration 1022/1500 [0m                     

                       Computation: 55318 steps/s (collection: 1.640s, learning 0.137s)
             Mean action noise std: 2.82
          Mean value_function loss: 17.6248
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.0728
                       Mean reward: 850.83
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 0.7790
    Episode_Reward/rotating_object: 168.9433
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 1.78s
                      Time elapsed: 00:34:26
                               ETA: 00:16:05

################################################################################
                     [1m Learning iteration 1023/1500 [0m                     

                       Computation: 55154 steps/s (collection: 1.630s, learning 0.152s)
             Mean action noise std: 2.82
          Mean value_function loss: 17.9795
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 42.0882
                       Mean reward: 834.31
               Mean episode length: 243.89
    Episode_Reward/reaching_object: 0.7729
    Episode_Reward/rotating_object: 169.0768
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 1.78s
                      Time elapsed: 00:34:28
                               ETA: 00:16:03

################################################################################
                     [1m Learning iteration 1024/1500 [0m                     

                       Computation: 56057 steps/s (collection: 1.640s, learning 0.114s)
             Mean action noise std: 2.83
          Mean value_function loss: 9.7190
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 42.1053
                       Mean reward: 839.45
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7751
    Episode_Reward/rotating_object: 169.0687
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 1.75s
                      Time elapsed: 00:34:29
                               ETA: 00:16:01

################################################################################
                     [1m Learning iteration 1025/1500 [0m                     

                       Computation: 56384 steps/s (collection: 1.632s, learning 0.112s)
             Mean action noise std: 2.83
          Mean value_function loss: 10.0479
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.1157
                       Mean reward: 851.42
               Mean episode length: 248.20
    Episode_Reward/reaching_object: 0.7813
    Episode_Reward/rotating_object: 169.6570
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 1.74s
                      Time elapsed: 00:34:31
                               ETA: 00:15:59

################################################################################
                     [1m Learning iteration 1026/1500 [0m                     

                       Computation: 52341 steps/s (collection: 1.758s, learning 0.120s)
             Mean action noise std: 2.83
          Mean value_function loss: 13.0976
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 42.1225
                       Mean reward: 853.64
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7763
    Episode_Reward/rotating_object: 168.9518
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 1.88s
                      Time elapsed: 00:34:33
                               ETA: 00:15:56

################################################################################
                     [1m Learning iteration 1027/1500 [0m                     

                       Computation: 56008 steps/s (collection: 1.651s, learning 0.105s)
             Mean action noise std: 2.83
          Mean value_function loss: 13.0327
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.1306
                       Mean reward: 845.24
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 0.7743
    Episode_Reward/rotating_object: 168.1219
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 1.76s
                      Time elapsed: 00:34:35
                               ETA: 00:15:54

################################################################################
                     [1m Learning iteration 1028/1500 [0m                     

                       Computation: 54765 steps/s (collection: 1.654s, learning 0.141s)
             Mean action noise std: 2.83
          Mean value_function loss: 14.8743
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 42.1391
                       Mean reward: 837.04
               Mean episode length: 247.62
    Episode_Reward/reaching_object: 0.7776
    Episode_Reward/rotating_object: 169.7634
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 1.80s
                      Time elapsed: 00:34:37
                               ETA: 00:15:52

################################################################################
                     [1m Learning iteration 1029/1500 [0m                     

                       Computation: 52865 steps/s (collection: 1.718s, learning 0.141s)
             Mean action noise std: 2.83
          Mean value_function loss: 17.5457
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.1487
                       Mean reward: 838.74
               Mean episode length: 243.95
    Episode_Reward/reaching_object: 0.7660
    Episode_Reward/rotating_object: 166.3707
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 1.86s
                      Time elapsed: 00:34:38
                               ETA: 00:15:50

################################################################################
                     [1m Learning iteration 1030/1500 [0m                     

                       Computation: 54023 steps/s (collection: 1.711s, learning 0.109s)
             Mean action noise std: 2.84
          Mean value_function loss: 18.7875
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 42.1581
                       Mean reward: 839.54
               Mean episode length: 245.77
    Episode_Reward/reaching_object: 0.7764
    Episode_Reward/rotating_object: 169.3170
        Episode_Reward/action_rate: -0.0393
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 1.82s
                      Time elapsed: 00:34:40
                               ETA: 00:15:48

################################################################################
                     [1m Learning iteration 1031/1500 [0m                     

                       Computation: 55361 steps/s (collection: 1.671s, learning 0.105s)
             Mean action noise std: 2.84
          Mean value_function loss: 16.6195
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 42.1694
                       Mean reward: 852.31
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 0.7680
    Episode_Reward/rotating_object: 166.8872
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 1.78s
                      Time elapsed: 00:34:42
                               ETA: 00:15:46

################################################################################
                     [1m Learning iteration 1032/1500 [0m                     

                       Computation: 55868 steps/s (collection: 1.649s, learning 0.111s)
             Mean action noise std: 2.84
          Mean value_function loss: 21.3413
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.1804
                       Mean reward: 839.87
               Mean episode length: 245.47
    Episode_Reward/reaching_object: 0.7616
    Episode_Reward/rotating_object: 166.1375
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 1.76s
                      Time elapsed: 00:34:44
                               ETA: 00:15:44

################################################################################
                     [1m Learning iteration 1033/1500 [0m                     

                       Computation: 55589 steps/s (collection: 1.655s, learning 0.113s)
             Mean action noise std: 2.84
          Mean value_function loss: 20.7073
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 42.2019
                       Mean reward: 860.98
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7791
    Episode_Reward/rotating_object: 170.3131
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 1.77s
                      Time elapsed: 00:34:45
                               ETA: 00:15:42

################################################################################
                     [1m Learning iteration 1034/1500 [0m                     

                       Computation: 56102 steps/s (collection: 1.648s, learning 0.104s)
             Mean action noise std: 2.84
          Mean value_function loss: 16.6465
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 42.2087
                       Mean reward: 830.69
               Mean episode length: 244.18
    Episode_Reward/reaching_object: 0.7731
    Episode_Reward/rotating_object: 166.9953
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 1.75s
                      Time elapsed: 00:34:47
                               ETA: 00:15:39

################################################################################
                     [1m Learning iteration 1035/1500 [0m                     

                       Computation: 54375 steps/s (collection: 1.694s, learning 0.114s)
             Mean action noise std: 2.85
          Mean value_function loss: 20.9102
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 42.2160
                       Mean reward: 842.61
               Mean episode length: 245.44
    Episode_Reward/reaching_object: 0.7712
    Episode_Reward/rotating_object: 167.4943
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 1.81s
                      Time elapsed: 00:34:49
                               ETA: 00:15:37

################################################################################
                     [1m Learning iteration 1036/1500 [0m                     

                       Computation: 55168 steps/s (collection: 1.644s, learning 0.138s)
             Mean action noise std: 2.85
          Mean value_function loss: 11.9529
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.2277
                       Mean reward: 864.58
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7839
    Episode_Reward/rotating_object: 170.5561
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 1.78s
                      Time elapsed: 00:34:51
                               ETA: 00:15:35

################################################################################
                     [1m Learning iteration 1037/1500 [0m                     

                       Computation: 56556 steps/s (collection: 1.626s, learning 0.113s)
             Mean action noise std: 2.85
          Mean value_function loss: 16.7057
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 42.2366
                       Mean reward: 834.79
               Mean episode length: 244.28
    Episode_Reward/reaching_object: 0.7773
    Episode_Reward/rotating_object: 168.4085
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 1.74s
                      Time elapsed: 00:34:53
                               ETA: 00:15:33

################################################################################
                     [1m Learning iteration 1038/1500 [0m                     

                       Computation: 57069 steps/s (collection: 1.636s, learning 0.087s)
             Mean action noise std: 2.85
          Mean value_function loss: 16.0333
               Mean surrogate loss: 0.0031
                 Mean entropy loss: 42.2449
                       Mean reward: 840.89
               Mean episode length: 246.59
    Episode_Reward/reaching_object: 0.7814
    Episode_Reward/rotating_object: 167.8757
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 1.72s
                      Time elapsed: 00:34:54
                               ETA: 00:15:31

################################################################################
                     [1m Learning iteration 1039/1500 [0m                     

                       Computation: 55331 steps/s (collection: 1.661s, learning 0.116s)
             Mean action noise std: 2.85
          Mean value_function loss: 20.1865
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.2464
                       Mean reward: 837.79
               Mean episode length: 243.80
    Episode_Reward/reaching_object: 0.7723
    Episode_Reward/rotating_object: 167.6555
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 1.78s
                      Time elapsed: 00:34:56
                               ETA: 00:15:29

################################################################################
                     [1m Learning iteration 1040/1500 [0m                     

                       Computation: 54211 steps/s (collection: 1.672s, learning 0.142s)
             Mean action noise std: 2.85
          Mean value_function loss: 19.0271
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.2513
                       Mean reward: 832.09
               Mean episode length: 241.19
    Episode_Reward/reaching_object: 0.7709
    Episode_Reward/rotating_object: 166.7215
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 1.81s
                      Time elapsed: 00:34:58
                               ETA: 00:15:27

################################################################################
                     [1m Learning iteration 1041/1500 [0m                     

                       Computation: 56831 steps/s (collection: 1.642s, learning 0.088s)
             Mean action noise std: 2.86
          Mean value_function loss: 15.1352
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.2703
                       Mean reward: 853.98
               Mean episode length: 248.02
    Episode_Reward/reaching_object: 0.7815
    Episode_Reward/rotating_object: 167.3067
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 1.73s
                      Time elapsed: 00:35:00
                               ETA: 00:15:25

################################################################################
                     [1m Learning iteration 1042/1500 [0m                     

                       Computation: 55353 steps/s (collection: 1.669s, learning 0.107s)
             Mean action noise std: 2.86
          Mean value_function loss: 18.9869
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.2841
                       Mean reward: 845.35
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7843
    Episode_Reward/rotating_object: 169.1958
        Episode_Reward/action_rate: -0.0401
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 1.78s
                      Time elapsed: 00:35:01
                               ETA: 00:15:22

################################################################################
                     [1m Learning iteration 1043/1500 [0m                     

                       Computation: 55448 steps/s (collection: 1.642s, learning 0.131s)
             Mean action noise std: 2.86
          Mean value_function loss: 8.7109
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.2948
                       Mean reward: 857.93
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7935
    Episode_Reward/rotating_object: 170.4005
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 1.77s
                      Time elapsed: 00:35:03
                               ETA: 00:15:20

################################################################################
                     [1m Learning iteration 1044/1500 [0m                     

                       Computation: 56490 steps/s (collection: 1.616s, learning 0.124s)
             Mean action noise std: 2.86
          Mean value_function loss: 10.3219
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 42.3033
                       Mean reward: 847.09
               Mean episode length: 245.59
    Episode_Reward/reaching_object: 0.7837
    Episode_Reward/rotating_object: 168.9930
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 1.74s
                      Time elapsed: 00:35:05
                               ETA: 00:15:18

################################################################################
                     [1m Learning iteration 1045/1500 [0m                     

                       Computation: 56821 steps/s (collection: 1.617s, learning 0.114s)
             Mean action noise std: 2.86
          Mean value_function loss: 9.6201
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 42.3055
                       Mean reward: 854.67
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7884
    Episode_Reward/rotating_object: 169.8906
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 1.73s
                      Time elapsed: 00:35:07
                               ETA: 00:15:16

################################################################################
                     [1m Learning iteration 1046/1500 [0m                     

                       Computation: 55354 steps/s (collection: 1.670s, learning 0.105s)
             Mean action noise std: 2.86
          Mean value_function loss: 13.7850
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.3034
                       Mean reward: 850.92
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7872
    Episode_Reward/rotating_object: 169.0316
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 18.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 1.78s
                      Time elapsed: 00:35:08
                               ETA: 00:15:14

################################################################################
                     [1m Learning iteration 1047/1500 [0m                     

                       Computation: 55251 steps/s (collection: 1.682s, learning 0.098s)
             Mean action noise std: 2.86
          Mean value_function loss: 10.2202
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 42.3126
                       Mean reward: 859.00
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7844
    Episode_Reward/rotating_object: 170.3909
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 1.78s
                      Time elapsed: 00:35:10
                               ETA: 00:15:12

################################################################################
                     [1m Learning iteration 1048/1500 [0m                     

                       Computation: 50800 steps/s (collection: 1.790s, learning 0.146s)
             Mean action noise std: 2.87
          Mean value_function loss: 9.8513
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 42.3231
                       Mean reward: 850.56
               Mean episode length: 248.21
    Episode_Reward/reaching_object: 0.7859
    Episode_Reward/rotating_object: 169.8036
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 1.94s
                      Time elapsed: 00:35:12
                               ETA: 00:15:10

################################################################################
                     [1m Learning iteration 1049/1500 [0m                     

                       Computation: 53332 steps/s (collection: 1.635s, learning 0.208s)
             Mean action noise std: 2.87
          Mean value_function loss: 11.9268
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.3366
                       Mean reward: 842.53
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7837
    Episode_Reward/rotating_object: 169.9070
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 1.84s
                      Time elapsed: 00:35:14
                               ETA: 00:15:08

################################################################################
                     [1m Learning iteration 1050/1500 [0m                     

                       Computation: 54867 steps/s (collection: 1.700s, learning 0.092s)
             Mean action noise std: 2.87
          Mean value_function loss: 10.1739
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.3498
                       Mean reward: 851.90
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7849
    Episode_Reward/rotating_object: 169.6308
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 1.79s
                      Time elapsed: 00:35:16
                               ETA: 00:15:06

################################################################################
                     [1m Learning iteration 1051/1500 [0m                     

                       Computation: 49864 steps/s (collection: 1.816s, learning 0.156s)
             Mean action noise std: 2.87
          Mean value_function loss: 12.3612
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 42.3579
                       Mean reward: 853.23
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7850
    Episode_Reward/rotating_object: 170.2576
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 1.97s
                      Time elapsed: 00:35:18
                               ETA: 00:15:04

################################################################################
                     [1m Learning iteration 1052/1500 [0m                     

                       Computation: 52424 steps/s (collection: 1.751s, learning 0.125s)
             Mean action noise std: 2.87
          Mean value_function loss: 16.0989
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.3629
                       Mean reward: 865.03
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7751
    Episode_Reward/rotating_object: 168.1367
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 1.88s
                      Time elapsed: 00:35:20
                               ETA: 00:15:02

################################################################################
                     [1m Learning iteration 1053/1500 [0m                     

                       Computation: 53060 steps/s (collection: 1.748s, learning 0.105s)
             Mean action noise std: 2.88
          Mean value_function loss: 12.3765
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.3744
                       Mean reward: 854.62
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7780
    Episode_Reward/rotating_object: 169.2495
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 1.85s
                      Time elapsed: 00:35:21
                               ETA: 00:14:59

################################################################################
                     [1m Learning iteration 1054/1500 [0m                     

                       Computation: 53382 steps/s (collection: 1.723s, learning 0.118s)
             Mean action noise std: 2.88
          Mean value_function loss: 13.7797
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.3930
                       Mean reward: 846.42
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.7761
    Episode_Reward/rotating_object: 169.3413
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 1.84s
                      Time elapsed: 00:35:23
                               ETA: 00:14:57

################################################################################
                     [1m Learning iteration 1055/1500 [0m                     

                       Computation: 55468 steps/s (collection: 1.651s, learning 0.122s)
             Mean action noise std: 2.88
          Mean value_function loss: 11.6643
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 42.4061
                       Mean reward: 849.50
               Mean episode length: 245.85
    Episode_Reward/reaching_object: 0.7758
    Episode_Reward/rotating_object: 170.8828
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 1.77s
                      Time elapsed: 00:35:25
                               ETA: 00:14:55

################################################################################
                     [1m Learning iteration 1056/1500 [0m                     

                       Computation: 55539 steps/s (collection: 1.663s, learning 0.107s)
             Mean action noise std: 2.88
          Mean value_function loss: 13.9104
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.4173
                       Mean reward: 859.50
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7702
    Episode_Reward/rotating_object: 168.5522
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 18.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 1.77s
                      Time elapsed: 00:35:27
                               ETA: 00:14:53

################################################################################
                     [1m Learning iteration 1057/1500 [0m                     

                       Computation: 57020 steps/s (collection: 1.633s, learning 0.091s)
             Mean action noise std: 2.89
          Mean value_function loss: 19.1258
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.4259
                       Mean reward: 822.78
               Mean episode length: 243.55
    Episode_Reward/reaching_object: 0.7691
    Episode_Reward/rotating_object: 167.9377
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 1.72s
                      Time elapsed: 00:35:29
                               ETA: 00:14:51

################################################################################
                     [1m Learning iteration 1058/1500 [0m                     

                       Computation: 56240 steps/s (collection: 1.653s, learning 0.095s)
             Mean action noise std: 2.89
          Mean value_function loss: 14.1566
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 42.4418
                       Mean reward: 859.11
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7729
    Episode_Reward/rotating_object: 168.4147
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 1.75s
                      Time elapsed: 00:35:30
                               ETA: 00:14:49

################################################################################
                     [1m Learning iteration 1059/1500 [0m                     

                       Computation: 55191 steps/s (collection: 1.672s, learning 0.110s)
             Mean action noise std: 2.89
          Mean value_function loss: 12.9678
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 42.4464
                       Mean reward: 830.73
               Mean episode length: 245.41
    Episode_Reward/reaching_object: 0.7720
    Episode_Reward/rotating_object: 170.2187
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 1.78s
                      Time elapsed: 00:35:32
                               ETA: 00:14:47

################################################################################
                     [1m Learning iteration 1060/1500 [0m                     

                       Computation: 55495 steps/s (collection: 1.665s, learning 0.106s)
             Mean action noise std: 2.89
          Mean value_function loss: 8.8264
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.4546
                       Mean reward: 861.17
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7785
    Episode_Reward/rotating_object: 171.1306
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 1.77s
                      Time elapsed: 00:35:34
                               ETA: 00:14:45

################################################################################
                     [1m Learning iteration 1061/1500 [0m                     

                       Computation: 52977 steps/s (collection: 1.762s, learning 0.094s)
             Mean action noise std: 2.89
          Mean value_function loss: 9.0745
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 42.4581
                       Mean reward: 863.34
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7760
    Episode_Reward/rotating_object: 170.9104
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 1.86s
                      Time elapsed: 00:35:36
                               ETA: 00:14:43

################################################################################
                     [1m Learning iteration 1062/1500 [0m                     

                       Computation: 53571 steps/s (collection: 1.682s, learning 0.153s)
             Mean action noise std: 2.89
          Mean value_function loss: 13.1667
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.4664
                       Mean reward: 855.93
               Mean episode length: 248.91
    Episode_Reward/reaching_object: 0.7711
    Episode_Reward/rotating_object: 169.5319
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 1.83s
                      Time elapsed: 00:35:38
                               ETA: 00:14:40

################################################################################
                     [1m Learning iteration 1063/1500 [0m                     

                       Computation: 56824 steps/s (collection: 1.639s, learning 0.091s)
             Mean action noise std: 2.89
          Mean value_function loss: 11.5943
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.4833
                       Mean reward: 864.77
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7691
    Episode_Reward/rotating_object: 170.3406
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 1.73s
                      Time elapsed: 00:35:39
                               ETA: 00:14:38

################################################################################
                     [1m Learning iteration 1064/1500 [0m                     

                       Computation: 56052 steps/s (collection: 1.631s, learning 0.123s)
             Mean action noise std: 2.90
          Mean value_function loss: 14.8549
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.4921
                       Mean reward: 836.61
               Mean episode length: 243.56
    Episode_Reward/reaching_object: 0.7649
    Episode_Reward/rotating_object: 167.5655
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 1.75s
                      Time elapsed: 00:35:41
                               ETA: 00:14:36

################################################################################
                     [1m Learning iteration 1065/1500 [0m                     

                       Computation: 56342 steps/s (collection: 1.625s, learning 0.120s)
             Mean action noise std: 2.90
          Mean value_function loss: 11.0813
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 42.5020
                       Mean reward: 854.39
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 0.7714
    Episode_Reward/rotating_object: 170.0964
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 1.74s
                      Time elapsed: 00:35:43
                               ETA: 00:14:34

################################################################################
                     [1m Learning iteration 1066/1500 [0m                     

                       Computation: 56778 steps/s (collection: 1.634s, learning 0.097s)
             Mean action noise std: 2.90
          Mean value_function loss: 10.5697
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 42.5060
                       Mean reward: 862.48
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7719
    Episode_Reward/rotating_object: 169.7497
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 1.73s
                      Time elapsed: 00:35:45
                               ETA: 00:14:32

################################################################################
                     [1m Learning iteration 1067/1500 [0m                     

                       Computation: 55830 steps/s (collection: 1.629s, learning 0.132s)
             Mean action noise std: 2.90
          Mean value_function loss: 10.0504
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.5115
                       Mean reward: 850.92
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7783
    Episode_Reward/rotating_object: 171.0384
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 1.76s
                      Time elapsed: 00:35:46
                               ETA: 00:14:30

################################################################################
                     [1m Learning iteration 1068/1500 [0m                     

                       Computation: 55664 steps/s (collection: 1.666s, learning 0.100s)
             Mean action noise std: 2.90
          Mean value_function loss: 13.6809
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 42.5189
                       Mean reward: 849.08
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7697
    Episode_Reward/rotating_object: 168.5380
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 1.77s
                      Time elapsed: 00:35:48
                               ETA: 00:14:28

################################################################################
                     [1m Learning iteration 1069/1500 [0m                     

                       Computation: 56176 steps/s (collection: 1.646s, learning 0.104s)
             Mean action noise std: 2.90
          Mean value_function loss: 12.9102
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.5239
                       Mean reward: 855.03
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7785
    Episode_Reward/rotating_object: 170.3462
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 1.75s
                      Time elapsed: 00:35:50
                               ETA: 00:14:26

################################################################################
                     [1m Learning iteration 1070/1500 [0m                     

                       Computation: 52719 steps/s (collection: 1.742s, learning 0.123s)
             Mean action noise std: 2.90
          Mean value_function loss: 9.0708
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 42.5325
                       Mean reward: 846.80
               Mean episode length: 245.84
    Episode_Reward/reaching_object: 0.7708
    Episode_Reward/rotating_object: 169.6406
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 1.86s
                      Time elapsed: 00:35:52
                               ETA: 00:14:24

################################################################################
                     [1m Learning iteration 1071/1500 [0m                     

                       Computation: 55977 steps/s (collection: 1.669s, learning 0.088s)
             Mean action noise std: 2.91
          Mean value_function loss: 10.5935
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.5424
                       Mean reward: 834.30
               Mean episode length: 245.60
    Episode_Reward/reaching_object: 0.7724
    Episode_Reward/rotating_object: 168.5672
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 1.76s
                      Time elapsed: 00:35:53
                               ETA: 00:14:21

################################################################################
                     [1m Learning iteration 1072/1500 [0m                     

                       Computation: 52348 steps/s (collection: 1.700s, learning 0.178s)
             Mean action noise std: 2.91
          Mean value_function loss: 12.8601
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 42.5542
                       Mean reward: 837.70
               Mean episode length: 246.08
    Episode_Reward/reaching_object: 0.7785
    Episode_Reward/rotating_object: 169.4843
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 1.88s
                      Time elapsed: 00:35:55
                               ETA: 00:14:19

################################################################################
                     [1m Learning iteration 1073/1500 [0m                     

                       Computation: 55062 steps/s (collection: 1.653s, learning 0.132s)
             Mean action noise std: 2.91
          Mean value_function loss: 13.5137
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.5636
                       Mean reward: 853.57
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 0.7801
    Episode_Reward/rotating_object: 170.3343
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 1.79s
                      Time elapsed: 00:35:57
                               ETA: 00:14:17

################################################################################
                     [1m Learning iteration 1074/1500 [0m                     

                       Computation: 56972 steps/s (collection: 1.629s, learning 0.096s)
             Mean action noise std: 2.91
          Mean value_function loss: 10.5068
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 42.5738
                       Mean reward: 858.78
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7830
    Episode_Reward/rotating_object: 169.1731
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 1.73s
                      Time elapsed: 00:35:59
                               ETA: 00:14:15

################################################################################
                     [1m Learning iteration 1075/1500 [0m                     

                       Computation: 56718 steps/s (collection: 1.638s, learning 0.096s)
             Mean action noise std: 2.91
          Mean value_function loss: 13.2161
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 42.5809
                       Mean reward: 854.13
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7810
    Episode_Reward/rotating_object: 170.9405
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 1.73s
                      Time elapsed: 00:36:01
                               ETA: 00:14:13

################################################################################
                     [1m Learning iteration 1076/1500 [0m                     

                       Computation: 55867 steps/s (collection: 1.623s, learning 0.137s)
             Mean action noise std: 2.92
          Mean value_function loss: 20.8960
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.5913
                       Mean reward: 838.54
               Mean episode length: 244.76
    Episode_Reward/reaching_object: 0.7668
    Episode_Reward/rotating_object: 166.3316
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 1.76s
                      Time elapsed: 00:36:02
                               ETA: 00:14:11

################################################################################
                     [1m Learning iteration 1077/1500 [0m                     

                       Computation: 55248 steps/s (collection: 1.635s, learning 0.144s)
             Mean action noise std: 2.92
          Mean value_function loss: 12.6791
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 42.6039
                       Mean reward: 865.01
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7815
    Episode_Reward/rotating_object: 170.8303
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 18.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 1.78s
                      Time elapsed: 00:36:04
                               ETA: 00:14:09

################################################################################
                     [1m Learning iteration 1078/1500 [0m                     

                       Computation: 56907 steps/s (collection: 1.632s, learning 0.096s)
             Mean action noise std: 2.92
          Mean value_function loss: 13.3776
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 42.6097
                       Mean reward: 863.27
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7798
    Episode_Reward/rotating_object: 170.7013
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 1.73s
                      Time elapsed: 00:36:06
                               ETA: 00:14:07

################################################################################
                     [1m Learning iteration 1079/1500 [0m                     

                       Computation: 56975 steps/s (collection: 1.633s, learning 0.092s)
             Mean action noise std: 2.92
          Mean value_function loss: 16.9425
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.6189
                       Mean reward: 856.06
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7777
    Episode_Reward/rotating_object: 169.6297
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 1.73s
                      Time elapsed: 00:36:08
                               ETA: 00:14:05

################################################################################
                     [1m Learning iteration 1080/1500 [0m                     

                       Computation: 55106 steps/s (collection: 1.665s, learning 0.119s)
             Mean action noise std: 2.92
          Mean value_function loss: 15.2999
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.6350
                       Mean reward: 864.70
               Mean episode length: 249.43
    Episode_Reward/reaching_object: 0.7768
    Episode_Reward/rotating_object: 169.3603
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 1.78s
                      Time elapsed: 00:36:09
                               ETA: 00:14:03

################################################################################
                     [1m Learning iteration 1081/1500 [0m                     

                       Computation: 54604 steps/s (collection: 1.672s, learning 0.128s)
             Mean action noise std: 2.93
          Mean value_function loss: 20.6146
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 42.6478
                       Mean reward: 830.72
               Mean episode length: 241.84
    Episode_Reward/reaching_object: 0.7656
    Episode_Reward/rotating_object: 166.9931
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 1.80s
                      Time elapsed: 00:36:11
                               ETA: 00:14:00

################################################################################
                     [1m Learning iteration 1082/1500 [0m                     

                       Computation: 56185 steps/s (collection: 1.643s, learning 0.107s)
             Mean action noise std: 2.93
          Mean value_function loss: 12.9565
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.6590
                       Mean reward: 846.01
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7744
    Episode_Reward/rotating_object: 169.6361
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 1.75s
                      Time elapsed: 00:36:13
                               ETA: 00:13:58

################################################################################
                     [1m Learning iteration 1083/1500 [0m                     

                       Computation: 56263 steps/s (collection: 1.655s, learning 0.092s)
             Mean action noise std: 2.93
          Mean value_function loss: 8.3108
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 42.6735
                       Mean reward: 852.07
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7806
    Episode_Reward/rotating_object: 169.6389
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 1.75s
                      Time elapsed: 00:36:15
                               ETA: 00:13:56

################################################################################
                     [1m Learning iteration 1084/1500 [0m                     

                       Computation: 55886 steps/s (collection: 1.629s, learning 0.130s)
             Mean action noise std: 2.93
          Mean value_function loss: 15.0426
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.6850
                       Mean reward: 848.57
               Mean episode length: 248.17
    Episode_Reward/reaching_object: 0.7743
    Episode_Reward/rotating_object: 169.6822
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 1.76s
                      Time elapsed: 00:36:16
                               ETA: 00:13:54

################################################################################
                     [1m Learning iteration 1085/1500 [0m                     

                       Computation: 55001 steps/s (collection: 1.647s, learning 0.140s)
             Mean action noise std: 2.93
          Mean value_function loss: 8.9239
               Mean surrogate loss: 0.0185
                 Mean entropy loss: 42.6974
                       Mean reward: 861.16
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7738
    Episode_Reward/rotating_object: 168.9387
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 1.79s
                      Time elapsed: 00:36:18
                               ETA: 00:13:52

################################################################################
                     [1m Learning iteration 1086/1500 [0m                     

                       Computation: 56131 steps/s (collection: 1.650s, learning 0.101s)
             Mean action noise std: 2.94
          Mean value_function loss: 13.2545
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.7013
                       Mean reward: 849.89
               Mean episode length: 245.42
    Episode_Reward/reaching_object: 0.7700
    Episode_Reward/rotating_object: 169.0643
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 1.75s
                      Time elapsed: 00:36:20
                               ETA: 00:13:50

################################################################################
                     [1m Learning iteration 1087/1500 [0m                     

                       Computation: 55793 steps/s (collection: 1.666s, learning 0.096s)
             Mean action noise std: 2.94
          Mean value_function loss: 13.6510
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.7054
                       Mean reward: 852.32
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.7799
    Episode_Reward/rotating_object: 169.6705
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 1.76s
                      Time elapsed: 00:36:22
                               ETA: 00:13:48

################################################################################
                     [1m Learning iteration 1088/1500 [0m                     

                       Computation: 56699 steps/s (collection: 1.643s, learning 0.091s)
             Mean action noise std: 2.94
          Mean value_function loss: 22.9721
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.7132
                       Mean reward: 844.85
               Mean episode length: 245.42
    Episode_Reward/reaching_object: 0.7696
    Episode_Reward/rotating_object: 167.5766
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 1.73s
                      Time elapsed: 00:36:23
                               ETA: 00:13:46

################################################################################
                     [1m Learning iteration 1089/1500 [0m                     

                       Computation: 55643 steps/s (collection: 1.671s, learning 0.096s)
             Mean action noise std: 2.94
          Mean value_function loss: 12.6477
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 42.7209
                       Mean reward: 860.17
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7777
    Episode_Reward/rotating_object: 170.4013
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 1.77s
                      Time elapsed: 00:36:25
                               ETA: 00:13:44

################################################################################
                     [1m Learning iteration 1090/1500 [0m                     

                       Computation: 54958 steps/s (collection: 1.689s, learning 0.100s)
             Mean action noise std: 2.94
          Mean value_function loss: 14.2715
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.7274
                       Mean reward: 853.08
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7797
    Episode_Reward/rotating_object: 168.9789
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 1.79s
                      Time elapsed: 00:36:27
                               ETA: 00:13:42

################################################################################
                     [1m Learning iteration 1091/1500 [0m                     

                       Computation: 56219 steps/s (collection: 1.647s, learning 0.101s)
             Mean action noise std: 2.94
          Mean value_function loss: 18.2762
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 42.7356
                       Mean reward: 837.99
               Mean episode length: 243.47
    Episode_Reward/reaching_object: 0.7736
    Episode_Reward/rotating_object: 169.2618
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 1.75s
                      Time elapsed: 00:36:29
                               ETA: 00:13:39

################################################################################
                     [1m Learning iteration 1092/1500 [0m                     

                       Computation: 55810 steps/s (collection: 1.646s, learning 0.116s)
             Mean action noise std: 2.95
          Mean value_function loss: 12.8717
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.7504
                       Mean reward: 841.24
               Mean episode length: 243.69
    Episode_Reward/reaching_object: 0.7790
    Episode_Reward/rotating_object: 170.0308
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 1.76s
                      Time elapsed: 00:36:30
                               ETA: 00:13:37

################################################################################
                     [1m Learning iteration 1093/1500 [0m                     

                       Computation: 54990 steps/s (collection: 1.661s, learning 0.127s)
             Mean action noise std: 2.95
          Mean value_function loss: 13.1919
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.7638
                       Mean reward: 844.68
               Mean episode length: 247.30
    Episode_Reward/reaching_object: 0.7820
    Episode_Reward/rotating_object: 169.8646
        Episode_Reward/action_rate: -0.0425
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 1.79s
                      Time elapsed: 00:36:32
                               ETA: 00:13:35

################################################################################
                     [1m Learning iteration 1094/1500 [0m                     

                       Computation: 56867 steps/s (collection: 1.619s, learning 0.110s)
             Mean action noise std: 2.95
          Mean value_function loss: 11.7460
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.7742
                       Mean reward: 854.27
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.7820
    Episode_Reward/rotating_object: 169.5309
        Episode_Reward/action_rate: -0.0425
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 1.73s
                      Time elapsed: 00:36:34
                               ETA: 00:13:33

################################################################################
                     [1m Learning iteration 1095/1500 [0m                     

                       Computation: 56161 steps/s (collection: 1.655s, learning 0.095s)
             Mean action noise std: 2.95
          Mean value_function loss: 15.0348
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 42.7892
                       Mean reward: 828.23
               Mean episode length: 243.45
    Episode_Reward/reaching_object: 0.7832
    Episode_Reward/rotating_object: 168.8460
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 1.75s
                      Time elapsed: 00:36:36
                               ETA: 00:13:31

################################################################################
                     [1m Learning iteration 1096/1500 [0m                     

                       Computation: 55612 steps/s (collection: 1.643s, learning 0.125s)
             Mean action noise std: 2.96
          Mean value_function loss: 15.6022
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.8019
                       Mean reward: 854.42
               Mean episode length: 248.50
    Episode_Reward/reaching_object: 0.7859
    Episode_Reward/rotating_object: 169.2212
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 1.77s
                      Time elapsed: 00:36:38
                               ETA: 00:13:29

################################################################################
                     [1m Learning iteration 1097/1500 [0m                     

                       Computation: 54084 steps/s (collection: 1.658s, learning 0.160s)
             Mean action noise std: 2.96
          Mean value_function loss: 24.2774
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 42.8133
                       Mean reward: 832.32
               Mean episode length: 243.48
    Episode_Reward/reaching_object: 0.7749
    Episode_Reward/rotating_object: 166.9384
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 1.82s
                      Time elapsed: 00:36:39
                               ETA: 00:13:27

################################################################################
                     [1m Learning iteration 1098/1500 [0m                     

                       Computation: 52262 steps/s (collection: 1.681s, learning 0.200s)
             Mean action noise std: 2.96
          Mean value_function loss: 15.7023
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.8288
                       Mean reward: 829.24
               Mean episode length: 241.76
    Episode_Reward/reaching_object: 0.7750
    Episode_Reward/rotating_object: 165.1798
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 1.88s
                      Time elapsed: 00:36:41
                               ETA: 00:13:25

################################################################################
                     [1m Learning iteration 1099/1500 [0m                     

                       Computation: 57868 steps/s (collection: 1.598s, learning 0.101s)
             Mean action noise std: 2.96
          Mean value_function loss: 12.4936
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 42.8515
                       Mean reward: 845.56
               Mean episode length: 248.08
    Episode_Reward/reaching_object: 0.7848
    Episode_Reward/rotating_object: 169.3151
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 1.70s
                      Time elapsed: 00:36:43
                               ETA: 00:13:23

################################################################################
                     [1m Learning iteration 1100/1500 [0m                     

                       Computation: 54392 steps/s (collection: 1.680s, learning 0.128s)
             Mean action noise std: 2.96
          Mean value_function loss: 15.5827
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 42.8657
                       Mean reward: 853.18
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.7798
    Episode_Reward/rotating_object: 169.2286
        Episode_Reward/action_rate: -0.0425
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 1.81s
                      Time elapsed: 00:36:45
                               ETA: 00:13:21

################################################################################
                     [1m Learning iteration 1101/1500 [0m                     

                       Computation: 56239 steps/s (collection: 1.652s, learning 0.096s)
             Mean action noise std: 2.97
          Mean value_function loss: 14.2650
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 42.8776
                       Mean reward: 856.19
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.7769
    Episode_Reward/rotating_object: 169.5267
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 1.75s
                      Time elapsed: 00:36:46
                               ETA: 00:13:19

################################################################################
                     [1m Learning iteration 1102/1500 [0m                     

                       Computation: 54938 steps/s (collection: 1.630s, learning 0.159s)
             Mean action noise std: 2.97
          Mean value_function loss: 12.4319
               Mean surrogate loss: 0.0141
                 Mean entropy loss: 42.8877
                       Mean reward: 855.09
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 0.7824
    Episode_Reward/rotating_object: 170.7701
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 1.79s
                      Time elapsed: 00:36:48
                               ETA: 00:13:16

################################################################################
                     [1m Learning iteration 1103/1500 [0m                     

                       Computation: 57391 steps/s (collection: 1.620s, learning 0.093s)
             Mean action noise std: 2.97
          Mean value_function loss: 9.2059
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 42.8887
                       Mean reward: 865.19
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7827
    Episode_Reward/rotating_object: 170.3748
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 1.71s
                      Time elapsed: 00:36:50
                               ETA: 00:13:14

################################################################################
                     [1m Learning iteration 1104/1500 [0m                     

                       Computation: 56228 steps/s (collection: 1.655s, learning 0.093s)
             Mean action noise std: 2.97
          Mean value_function loss: 11.7829
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.8923
                       Mean reward: 848.40
               Mean episode length: 245.98
    Episode_Reward/reaching_object: 0.7783
    Episode_Reward/rotating_object: 169.6889
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 1.75s
                      Time elapsed: 00:36:52
                               ETA: 00:13:12

################################################################################
                     [1m Learning iteration 1105/1500 [0m                     

                       Computation: 57413 steps/s (collection: 1.626s, learning 0.087s)
             Mean action noise std: 2.97
          Mean value_function loss: 13.5259
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.9022
                       Mean reward: 845.90
               Mean episode length: 245.52
    Episode_Reward/reaching_object: 0.7760
    Episode_Reward/rotating_object: 169.1222
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 1.71s
                      Time elapsed: 00:36:53
                               ETA: 00:13:10

################################################################################
                     [1m Learning iteration 1106/1500 [0m                     

                       Computation: 56860 steps/s (collection: 1.629s, learning 0.100s)
             Mean action noise std: 2.97
          Mean value_function loss: 13.3912
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.9097
                       Mean reward: 853.06
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7800
    Episode_Reward/rotating_object: 169.9635
        Episode_Reward/action_rate: -0.0437
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 1.73s
                      Time elapsed: 00:36:55
                               ETA: 00:13:08

################################################################################
                     [1m Learning iteration 1107/1500 [0m                     

                       Computation: 54234 steps/s (collection: 1.701s, learning 0.112s)
             Mean action noise std: 2.98
          Mean value_function loss: 7.3614
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 42.9184
                       Mean reward: 839.77
               Mean episode length: 245.87
    Episode_Reward/reaching_object: 0.7672
    Episode_Reward/rotating_object: 168.3481
        Episode_Reward/action_rate: -0.0434
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 1.81s
                      Time elapsed: 00:36:57
                               ETA: 00:13:06

################################################################################
                     [1m Learning iteration 1108/1500 [0m                     

                       Computation: 55936 steps/s (collection: 1.657s, learning 0.101s)
             Mean action noise std: 2.98
          Mean value_function loss: 10.2405
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.9261
                       Mean reward: 864.04
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7759
    Episode_Reward/rotating_object: 170.4684
        Episode_Reward/action_rate: -0.0437
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 1.76s
                      Time elapsed: 00:36:59
                               ETA: 00:13:04

################################################################################
                     [1m Learning iteration 1109/1500 [0m                     

                       Computation: 55637 steps/s (collection: 1.660s, learning 0.107s)
             Mean action noise std: 2.98
          Mean value_function loss: 15.2035
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 42.9366
                       Mean reward: 854.31
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 0.7635
    Episode_Reward/rotating_object: 169.3477
        Episode_Reward/action_rate: -0.0434
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 18.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 1.77s
                      Time elapsed: 00:37:00
                               ETA: 00:13:02

################################################################################
                     [1m Learning iteration 1110/1500 [0m                     

                       Computation: 55380 steps/s (collection: 1.655s, learning 0.120s)
             Mean action noise std: 2.98
          Mean value_function loss: 15.4319
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.9487
                       Mean reward: 853.58
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 0.7665
    Episode_Reward/rotating_object: 169.9809
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 1.78s
                      Time elapsed: 00:37:02
                               ETA: 00:13:00

################################################################################
                     [1m Learning iteration 1111/1500 [0m                     

                       Computation: 54999 steps/s (collection: 1.674s, learning 0.114s)
             Mean action noise std: 2.98
          Mean value_function loss: 22.9111
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 42.9603
                       Mean reward: 847.28
               Mean episode length: 246.01
    Episode_Reward/reaching_object: 0.7542
    Episode_Reward/rotating_object: 168.1871
        Episode_Reward/action_rate: -0.0433
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 1.79s
                      Time elapsed: 00:37:04
                               ETA: 00:12:58

################################################################################
                     [1m Learning iteration 1112/1500 [0m                     

                       Computation: 53192 steps/s (collection: 1.695s, learning 0.153s)
             Mean action noise std: 2.99
          Mean value_function loss: 15.0881
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.9690
                       Mean reward: 855.19
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7518
    Episode_Reward/rotating_object: 168.4756
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 1.85s
                      Time elapsed: 00:37:06
                               ETA: 00:12:56

################################################################################
                     [1m Learning iteration 1113/1500 [0m                     

                       Computation: 52784 steps/s (collection: 1.773s, learning 0.089s)
             Mean action noise std: 2.99
          Mean value_function loss: 14.9927
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.9841
                       Mean reward: 855.76
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.7516
    Episode_Reward/rotating_object: 168.5673
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 1.86s
                      Time elapsed: 00:37:08
                               ETA: 00:12:54

################################################################################
                     [1m Learning iteration 1114/1500 [0m                     

                       Computation: 56259 steps/s (collection: 1.615s, learning 0.132s)
             Mean action noise std: 2.99
          Mean value_function loss: 16.1782
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.0041
                       Mean reward: 852.23
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7525
    Episode_Reward/rotating_object: 168.7781
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 1.75s
                      Time elapsed: 00:37:10
                               ETA: 00:12:52

################################################################################
                     [1m Learning iteration 1115/1500 [0m                     

                       Computation: 52378 steps/s (collection: 1.777s, learning 0.100s)
             Mean action noise std: 2.99
          Mean value_function loss: 15.2056
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.0164
                       Mean reward: 857.09
               Mean episode length: 248.62
    Episode_Reward/reaching_object: 0.7537
    Episode_Reward/rotating_object: 168.9940
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 1.88s
                      Time elapsed: 00:37:11
                               ETA: 00:12:49

################################################################################
                     [1m Learning iteration 1116/1500 [0m                     

                       Computation: 54030 steps/s (collection: 1.698s, learning 0.122s)
             Mean action noise std: 3.00
          Mean value_function loss: 14.3737
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 43.0262
                       Mean reward: 835.56
               Mean episode length: 245.56
    Episode_Reward/reaching_object: 0.7469
    Episode_Reward/rotating_object: 168.6057
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 1.82s
                      Time elapsed: 00:37:13
                               ETA: 00:12:47

################################################################################
                     [1m Learning iteration 1117/1500 [0m                     

                       Computation: 53792 steps/s (collection: 1.705s, learning 0.123s)
             Mean action noise std: 3.00
          Mean value_function loss: 14.8698
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 43.0421
                       Mean reward: 844.40
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7470
    Episode_Reward/rotating_object: 168.8390
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 1.83s
                      Time elapsed: 00:37:15
                               ETA: 00:12:45

################################################################################
                     [1m Learning iteration 1118/1500 [0m                     

                       Computation: 54163 steps/s (collection: 1.697s, learning 0.118s)
             Mean action noise std: 3.00
          Mean value_function loss: 14.1737
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.0531
                       Mean reward: 855.66
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.7430
    Episode_Reward/rotating_object: 166.7047
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 1.81s
                      Time elapsed: 00:37:17
                               ETA: 00:12:43

################################################################################
                     [1m Learning iteration 1119/1500 [0m                     

                       Computation: 56160 steps/s (collection: 1.654s, learning 0.096s)
             Mean action noise std: 3.00
          Mean value_function loss: 9.7248
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 43.0634
                       Mean reward: 854.89
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.7531
    Episode_Reward/rotating_object: 169.9471
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 1.75s
                      Time elapsed: 00:37:19
                               ETA: 00:12:41

################################################################################
                     [1m Learning iteration 1120/1500 [0m                     

                       Computation: 54645 steps/s (collection: 1.673s, learning 0.126s)
             Mean action noise std: 3.00
          Mean value_function loss: 13.1532
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 43.0705
                       Mean reward: 861.79
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7571
    Episode_Reward/rotating_object: 170.8563
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 1.80s
                      Time elapsed: 00:37:20
                               ETA: 00:12:39

################################################################################
                     [1m Learning iteration 1121/1500 [0m                     

                       Computation: 51006 steps/s (collection: 1.805s, learning 0.122s)
             Mean action noise std: 3.00
          Mean value_function loss: 13.1241
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 43.0799
                       Mean reward: 854.71
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7555
    Episode_Reward/rotating_object: 169.8028
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 1.93s
                      Time elapsed: 00:37:22
                               ETA: 00:12:37

################################################################################
                     [1m Learning iteration 1122/1500 [0m                     

                       Computation: 52207 steps/s (collection: 1.765s, learning 0.118s)
             Mean action noise std: 3.01
          Mean value_function loss: 10.1420
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 43.0914
                       Mean reward: 844.17
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 0.7475
    Episode_Reward/rotating_object: 168.6521
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 1.88s
                      Time elapsed: 00:37:24
                               ETA: 00:12:35

################################################################################
                     [1m Learning iteration 1123/1500 [0m                     

                       Computation: 56191 steps/s (collection: 1.652s, learning 0.097s)
             Mean action noise std: 3.01
          Mean value_function loss: 14.8266
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 43.0991
                       Mean reward: 846.08
               Mean episode length: 245.73
    Episode_Reward/reaching_object: 0.7534
    Episode_Reward/rotating_object: 169.4882
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 1.75s
                      Time elapsed: 00:37:26
                               ETA: 00:12:33

################################################################################
                     [1m Learning iteration 1124/1500 [0m                     

                       Computation: 57062 steps/s (collection: 1.631s, learning 0.092s)
             Mean action noise std: 3.01
          Mean value_function loss: 15.1797
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.1022
                       Mean reward: 861.29
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7471
    Episode_Reward/rotating_object: 167.6778
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 1.72s
                      Time elapsed: 00:37:28
                               ETA: 00:12:31

################################################################################
                     [1m Learning iteration 1125/1500 [0m                     

                       Computation: 55608 steps/s (collection: 1.626s, learning 0.142s)
             Mean action noise std: 3.01
          Mean value_function loss: 12.3923
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.1107
                       Mean reward: 854.95
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7540
    Episode_Reward/rotating_object: 169.9144
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 1.77s
                      Time elapsed: 00:37:29
                               ETA: 00:12:29

################################################################################
                     [1m Learning iteration 1126/1500 [0m                     

                       Computation: 57366 steps/s (collection: 1.606s, learning 0.108s)
             Mean action noise std: 3.01
          Mean value_function loss: 12.1276
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 43.1233
                       Mean reward: 847.91
               Mean episode length: 245.55
    Episode_Reward/reaching_object: 0.7458
    Episode_Reward/rotating_object: 167.9131
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 1.71s
                      Time elapsed: 00:37:31
                               ETA: 00:12:27

################################################################################
                     [1m Learning iteration 1127/1500 [0m                     

                       Computation: 57319 steps/s (collection: 1.619s, learning 0.096s)
             Mean action noise std: 3.01
          Mean value_function loss: 12.8687
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 43.1346
                       Mean reward: 851.44
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7493
    Episode_Reward/rotating_object: 170.1316
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 1.72s
                      Time elapsed: 00:37:33
                               ETA: 00:12:25

################################################################################
                     [1m Learning iteration 1128/1500 [0m                     

                       Computation: 55867 steps/s (collection: 1.657s, learning 0.103s)
             Mean action noise std: 3.02
          Mean value_function loss: 15.2874
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.1496
                       Mean reward: 841.78
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7546
    Episode_Reward/rotating_object: 169.4485
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 1.76s
                      Time elapsed: 00:37:35
                               ETA: 00:12:23

################################################################################
                     [1m Learning iteration 1129/1500 [0m                     

                       Computation: 57046 steps/s (collection: 1.619s, learning 0.104s)
             Mean action noise std: 3.02
          Mean value_function loss: 11.8902
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.1611
                       Mean reward: 860.85
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7431
    Episode_Reward/rotating_object: 169.3243
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 18.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 1.72s
                      Time elapsed: 00:37:36
                               ETA: 00:12:20

################################################################################
                     [1m Learning iteration 1130/1500 [0m                     

                       Computation: 57219 steps/s (collection: 1.623s, learning 0.095s)
             Mean action noise std: 3.02
          Mean value_function loss: 12.5622
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 43.1758
                       Mean reward: 846.39
               Mean episode length: 245.56
    Episode_Reward/reaching_object: 0.7407
    Episode_Reward/rotating_object: 168.3930
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 1.72s
                      Time elapsed: 00:37:38
                               ETA: 00:12:18

################################################################################
                     [1m Learning iteration 1131/1500 [0m                     

                       Computation: 56350 steps/s (collection: 1.652s, learning 0.093s)
             Mean action noise std: 3.02
          Mean value_function loss: 9.4964
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.1857
                       Mean reward: 857.23
               Mean episode length: 248.43
    Episode_Reward/reaching_object: 0.7371
    Episode_Reward/rotating_object: 170.6019
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 1.74s
                      Time elapsed: 00:37:40
                               ETA: 00:12:16

################################################################################
                     [1m Learning iteration 1132/1500 [0m                     

                       Computation: 55694 steps/s (collection: 1.658s, learning 0.107s)
             Mean action noise std: 3.03
          Mean value_function loss: 14.9409
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.1935
                       Mean reward: 852.87
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 0.7320
    Episode_Reward/rotating_object: 168.7559
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 1.77s
                      Time elapsed: 00:37:42
                               ETA: 00:12:14

################################################################################
                     [1m Learning iteration 1133/1500 [0m                     

                       Computation: 55057 steps/s (collection: 1.624s, learning 0.162s)
             Mean action noise std: 3.03
          Mean value_function loss: 9.5616
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 43.2033
                       Mean reward: 856.91
               Mean episode length: 248.33
    Episode_Reward/reaching_object: 0.7304
    Episode_Reward/rotating_object: 169.6295
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 1.79s
                      Time elapsed: 00:37:43
                               ETA: 00:12:12

################################################################################
                     [1m Learning iteration 1134/1500 [0m                     

                       Computation: 56804 steps/s (collection: 1.631s, learning 0.100s)
             Mean action noise std: 3.03
          Mean value_function loss: 7.4461
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.2068
                       Mean reward: 855.31
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 0.7284
    Episode_Reward/rotating_object: 170.3984
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 1.73s
                      Time elapsed: 00:37:45
                               ETA: 00:12:10

################################################################################
                     [1m Learning iteration 1135/1500 [0m                     

                       Computation: 57719 steps/s (collection: 1.611s, learning 0.092s)
             Mean action noise std: 3.03
          Mean value_function loss: 10.6931
               Mean surrogate loss: 0.0028
                 Mean entropy loss: 43.2111
                       Mean reward: 859.35
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7290
    Episode_Reward/rotating_object: 170.6320
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 1.70s
                      Time elapsed: 00:37:47
                               ETA: 00:12:08

################################################################################
                     [1m Learning iteration 1136/1500 [0m                     

                       Computation: 57201 steps/s (collection: 1.624s, learning 0.095s)
             Mean action noise std: 3.03
          Mean value_function loss: 18.0714
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.2156
                       Mean reward: 838.62
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 0.7182
    Episode_Reward/rotating_object: 168.5774
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 1.72s
                      Time elapsed: 00:37:49
                               ETA: 00:12:06

################################################################################
                     [1m Learning iteration 1137/1500 [0m                     

                       Computation: 56640 steps/s (collection: 1.633s, learning 0.103s)
             Mean action noise std: 3.03
          Mean value_function loss: 12.4806
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 43.2306
                       Mean reward: 862.75
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7118
    Episode_Reward/rotating_object: 168.2139
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 1.74s
                      Time elapsed: 00:37:50
                               ETA: 00:12:04

################################################################################
                     [1m Learning iteration 1138/1500 [0m                     

                       Computation: 53795 steps/s (collection: 1.687s, learning 0.140s)
             Mean action noise std: 3.03
          Mean value_function loss: 9.4543
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 43.2461
                       Mean reward: 865.74
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7235
    Episode_Reward/rotating_object: 171.3470
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 1.83s
                      Time elapsed: 00:37:52
                               ETA: 00:12:02

################################################################################
                     [1m Learning iteration 1139/1500 [0m                     

                       Computation: 56454 steps/s (collection: 1.651s, learning 0.091s)
             Mean action noise std: 3.04
          Mean value_function loss: 11.4302
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 43.2523
                       Mean reward: 837.27
               Mean episode length: 244.26
    Episode_Reward/reaching_object: 0.7103
    Episode_Reward/rotating_object: 169.6093
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 1.74s
                      Time elapsed: 00:37:54
                               ETA: 00:12:00

################################################################################
                     [1m Learning iteration 1140/1500 [0m                     

                       Computation: 55405 steps/s (collection: 1.619s, learning 0.155s)
             Mean action noise std: 3.04
          Mean value_function loss: 9.0436
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.2558
                       Mean reward: 859.70
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7149
    Episode_Reward/rotating_object: 171.2420
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 18.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 1.77s
                      Time elapsed: 00:37:56
                               ETA: 00:11:58

################################################################################
                     [1m Learning iteration 1141/1500 [0m                     

                       Computation: 51334 steps/s (collection: 1.688s, learning 0.227s)
             Mean action noise std: 3.04
          Mean value_function loss: 13.4928
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 43.2597
                       Mean reward: 861.45
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7218
    Episode_Reward/rotating_object: 172.0892
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 1.91s
                      Time elapsed: 00:37:58
                               ETA: 00:11:56

################################################################################
                     [1m Learning iteration 1142/1500 [0m                     

                       Computation: 54392 steps/s (collection: 1.686s, learning 0.122s)
             Mean action noise std: 3.04
          Mean value_function loss: 13.9264
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 43.2632
                       Mean reward: 851.18
               Mean episode length: 245.96
    Episode_Reward/reaching_object: 0.7160
    Episode_Reward/rotating_object: 169.2007
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 1.81s
                      Time elapsed: 00:37:59
                               ETA: 00:11:54

################################################################################
                     [1m Learning iteration 1143/1500 [0m                     

                       Computation: 55180 steps/s (collection: 1.665s, learning 0.117s)
             Mean action noise std: 3.04
          Mean value_function loss: 15.5317
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 43.2691
                       Mean reward: 862.91
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7185
    Episode_Reward/rotating_object: 170.2366
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 1.78s
                      Time elapsed: 00:38:01
                               ETA: 00:11:52

################################################################################
                     [1m Learning iteration 1144/1500 [0m                     

                       Computation: 54256 steps/s (collection: 1.717s, learning 0.095s)
             Mean action noise std: 3.04
          Mean value_function loss: 18.9970
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.2745
                       Mean reward: 846.11
               Mean episode length: 245.65
    Episode_Reward/reaching_object: 0.7105
    Episode_Reward/rotating_object: 168.6529
        Episode_Reward/action_rate: -0.0461
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 1.81s
                      Time elapsed: 00:38:03
                               ETA: 00:11:49

################################################################################
                     [1m Learning iteration 1145/1500 [0m                     

                       Computation: 54852 steps/s (collection: 1.689s, learning 0.104s)
             Mean action noise std: 3.04
          Mean value_function loss: 10.1345
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 43.2822
                       Mean reward: 842.26
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7242
    Episode_Reward/rotating_object: 170.0248
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 1.79s
                      Time elapsed: 00:38:05
                               ETA: 00:11:47

################################################################################
                     [1m Learning iteration 1146/1500 [0m                     

                       Computation: 53630 steps/s (collection: 1.682s, learning 0.151s)
             Mean action noise std: 3.04
          Mean value_function loss: 14.0982
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.2866
                       Mean reward: 851.84
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7264
    Episode_Reward/rotating_object: 171.3170
        Episode_Reward/action_rate: -0.0468
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 1.83s
                      Time elapsed: 00:38:07
                               ETA: 00:11:45

################################################################################
                     [1m Learning iteration 1147/1500 [0m                     

                       Computation: 56187 steps/s (collection: 1.632s, learning 0.117s)
             Mean action noise std: 3.04
          Mean value_function loss: 8.1357
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 43.2898
                       Mean reward: 864.52
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7277
    Episode_Reward/rotating_object: 170.8616
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 1.75s
                      Time elapsed: 00:38:08
                               ETA: 00:11:43

################################################################################
                     [1m Learning iteration 1148/1500 [0m                     

                       Computation: 54329 steps/s (collection: 1.690s, learning 0.119s)
             Mean action noise std: 3.05
          Mean value_function loss: 12.5792
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.2934
                       Mean reward: 863.37
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7268
    Episode_Reward/rotating_object: 170.6649
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 1.81s
                      Time elapsed: 00:38:10
                               ETA: 00:11:41

################################################################################
                     [1m Learning iteration 1149/1500 [0m                     

                       Computation: 54159 steps/s (collection: 1.723s, learning 0.092s)
             Mean action noise std: 3.05
          Mean value_function loss: 11.0709
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.2964
                       Mean reward: 863.01
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7254
    Episode_Reward/rotating_object: 170.3680
        Episode_Reward/action_rate: -0.0468
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 1.82s
                      Time elapsed: 00:38:12
                               ETA: 00:11:39

################################################################################
                     [1m Learning iteration 1150/1500 [0m                     

                       Computation: 55411 steps/s (collection: 1.661s, learning 0.113s)
             Mean action noise std: 3.05
          Mean value_function loss: 15.2178
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.3030
                       Mean reward: 838.68
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 0.7256
    Episode_Reward/rotating_object: 169.3552
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 1.77s
                      Time elapsed: 00:38:14
                               ETA: 00:11:37

################################################################################
                     [1m Learning iteration 1151/1500 [0m                     

                       Computation: 52587 steps/s (collection: 1.699s, learning 0.170s)
             Mean action noise std: 3.05
          Mean value_function loss: 12.5351
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 43.3152
                       Mean reward: 848.26
               Mean episode length: 248.21
    Episode_Reward/reaching_object: 0.7242
    Episode_Reward/rotating_object: 170.3220
        Episode_Reward/action_rate: -0.0470
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 1.87s
                      Time elapsed: 00:38:16
                               ETA: 00:11:35

################################################################################
                     [1m Learning iteration 1152/1500 [0m                     

                       Computation: 55332 steps/s (collection: 1.674s, learning 0.102s)
             Mean action noise std: 3.05
          Mean value_function loss: 14.8538
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.3234
                       Mean reward: 867.27
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7180
    Episode_Reward/rotating_object: 169.7902
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 1.78s
                      Time elapsed: 00:38:17
                               ETA: 00:11:33

################################################################################
                     [1m Learning iteration 1153/1500 [0m                     

                       Computation: 55276 steps/s (collection: 1.677s, learning 0.102s)
             Mean action noise std: 3.05
          Mean value_function loss: 13.2427
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 43.3345
                       Mean reward: 846.54
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 0.7173
    Episode_Reward/rotating_object: 168.0953
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 1.78s
                      Time elapsed: 00:38:19
                               ETA: 00:11:31

################################################################################
                     [1m Learning iteration 1154/1500 [0m                     

                       Computation: 56013 steps/s (collection: 1.666s, learning 0.089s)
             Mean action noise std: 3.06
          Mean value_function loss: 15.1308
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 43.3505
                       Mean reward: 821.65
               Mean episode length: 239.41
    Episode_Reward/reaching_object: 0.7136
    Episode_Reward/rotating_object: 168.8231
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 1.75s
                      Time elapsed: 00:38:21
                               ETA: 00:11:29

################################################################################
                     [1m Learning iteration 1155/1500 [0m                     

                       Computation: 53906 steps/s (collection: 1.733s, learning 0.091s)
             Mean action noise std: 3.06
          Mean value_function loss: 10.1714
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 43.3590
                       Mean reward: 857.81
               Mean episode length: 248.12
    Episode_Reward/reaching_object: 0.7232
    Episode_Reward/rotating_object: 170.2232
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 1.82s
                      Time elapsed: 00:38:23
                               ETA: 00:11:27

################################################################################
                     [1m Learning iteration 1156/1500 [0m                     

                       Computation: 54629 steps/s (collection: 1.656s, learning 0.144s)
             Mean action noise std: 3.06
          Mean value_function loss: 16.6541
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.3641
                       Mean reward: 844.23
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 0.7260
    Episode_Reward/rotating_object: 170.3269
        Episode_Reward/action_rate: -0.0471
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 1.80s
                      Time elapsed: 00:38:24
                               ETA: 00:11:25

################################################################################
                     [1m Learning iteration 1157/1500 [0m                     

                       Computation: 56514 steps/s (collection: 1.637s, learning 0.102s)
             Mean action noise std: 3.06
          Mean value_function loss: 7.7175
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 43.3752
                       Mean reward: 864.21
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7328
    Episode_Reward/rotating_object: 171.0755
        Episode_Reward/action_rate: -0.0475
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 1.74s
                      Time elapsed: 00:38:26
                               ETA: 00:11:23

################################################################################
                     [1m Learning iteration 1158/1500 [0m                     

                       Computation: 50467 steps/s (collection: 1.796s, learning 0.152s)
             Mean action noise std: 3.06
          Mean value_function loss: 8.1352
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 43.3812
                       Mean reward: 841.37
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.7365
    Episode_Reward/rotating_object: 170.4144
        Episode_Reward/action_rate: -0.0475
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 1.95s
                      Time elapsed: 00:38:28
                               ETA: 00:11:21

################################################################################
                     [1m Learning iteration 1159/1500 [0m                     

                       Computation: 56449 steps/s (collection: 1.655s, learning 0.086s)
             Mean action noise std: 3.06
          Mean value_function loss: 11.6495
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 43.3837
                       Mean reward: 839.03
               Mean episode length: 245.49
    Episode_Reward/reaching_object: 0.7310
    Episode_Reward/rotating_object: 168.5847
        Episode_Reward/action_rate: -0.0472
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 1.74s
                      Time elapsed: 00:38:30
                               ETA: 00:11:19

################################################################################
                     [1m Learning iteration 1160/1500 [0m                     

                       Computation: 55733 steps/s (collection: 1.648s, learning 0.116s)
             Mean action noise std: 3.07
          Mean value_function loss: 8.8143
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 43.3882
                       Mean reward: 867.15
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7418
    Episode_Reward/rotating_object: 171.2465
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 1.76s
                      Time elapsed: 00:38:32
                               ETA: 00:11:17

################################################################################
                     [1m Learning iteration 1161/1500 [0m                     

                       Computation: 53227 steps/s (collection: 1.696s, learning 0.151s)
             Mean action noise std: 3.07
          Mean value_function loss: 17.4118
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.3934
                       Mean reward: 842.57
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7466
    Episode_Reward/rotating_object: 170.4958
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 1.85s
                      Time elapsed: 00:38:34
                               ETA: 00:11:15

################################################################################
                     [1m Learning iteration 1162/1500 [0m                     

                       Computation: 57378 steps/s (collection: 1.622s, learning 0.092s)
             Mean action noise std: 3.07
          Mean value_function loss: 12.1780
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 43.4075
                       Mean reward: 866.98
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7486
    Episode_Reward/rotating_object: 171.6030
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 1.71s
                      Time elapsed: 00:38:35
                               ETA: 00:11:13

################################################################################
                     [1m Learning iteration 1163/1500 [0m                     

                       Computation: 55578 steps/s (collection: 1.682s, learning 0.087s)
             Mean action noise std: 3.07
          Mean value_function loss: 8.0918
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.4180
                       Mean reward: 856.08
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7482
    Episode_Reward/rotating_object: 170.0323
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 1.77s
                      Time elapsed: 00:38:37
                               ETA: 00:11:10

################################################################################
                     [1m Learning iteration 1164/1500 [0m                     

                       Computation: 56092 steps/s (collection: 1.652s, learning 0.100s)
             Mean action noise std: 3.07
          Mean value_function loss: 15.2420
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 43.4263
                       Mean reward: 837.39
               Mean episode length: 245.43
    Episode_Reward/reaching_object: 0.7419
    Episode_Reward/rotating_object: 168.7717
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 1.75s
                      Time elapsed: 00:38:39
                               ETA: 00:11:08

################################################################################
                     [1m Learning iteration 1165/1500 [0m                     

                       Computation: 56405 steps/s (collection: 1.648s, learning 0.095s)
             Mean action noise std: 3.07
          Mean value_function loss: 12.5520
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.4311
                       Mean reward: 854.30
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 0.7498
    Episode_Reward/rotating_object: 170.2281
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 1.74s
                      Time elapsed: 00:38:41
                               ETA: 00:11:06

################################################################################
                     [1m Learning iteration 1166/1500 [0m                     

                       Computation: 56876 steps/s (collection: 1.636s, learning 0.093s)
             Mean action noise std: 3.08
          Mean value_function loss: 9.9019
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.4416
                       Mean reward: 846.97
               Mean episode length: 246.03
    Episode_Reward/reaching_object: 0.7455
    Episode_Reward/rotating_object: 167.7232
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 1.73s
                      Time elapsed: 00:38:42
                               ETA: 00:11:04

################################################################################
                     [1m Learning iteration 1167/1500 [0m                     

                       Computation: 56867 steps/s (collection: 1.628s, learning 0.101s)
             Mean action noise std: 3.08
          Mean value_function loss: 8.6690
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.4489
                       Mean reward: 858.29
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.7514
    Episode_Reward/rotating_object: 170.8568
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 1.73s
                      Time elapsed: 00:38:44
                               ETA: 00:11:02

################################################################################
                     [1m Learning iteration 1168/1500 [0m                     

                       Computation: 54637 steps/s (collection: 1.686s, learning 0.113s)
             Mean action noise std: 3.08
          Mean value_function loss: 14.6146
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.4497
                       Mean reward: 859.69
               Mean episode length: 247.94
    Episode_Reward/reaching_object: 0.7529
    Episode_Reward/rotating_object: 171.3478
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 1.80s
                      Time elapsed: 00:38:46
                               ETA: 00:11:00

################################################################################
                     [1m Learning iteration 1169/1500 [0m                     

                       Computation: 55029 steps/s (collection: 1.642s, learning 0.145s)
             Mean action noise std: 3.08
          Mean value_function loss: 13.2184
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.4525
                       Mean reward: 824.80
               Mean episode length: 242.02
    Episode_Reward/reaching_object: 0.7492
    Episode_Reward/rotating_object: 168.3167
        Episode_Reward/action_rate: -0.0477
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 1.79s
                      Time elapsed: 00:38:48
                               ETA: 00:10:58

################################################################################
                     [1m Learning iteration 1170/1500 [0m                     

                       Computation: 57125 steps/s (collection: 1.612s, learning 0.109s)
             Mean action noise std: 3.08
          Mean value_function loss: 10.6869
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 43.4676
                       Mean reward: 863.23
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7555
    Episode_Reward/rotating_object: 171.4361
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 1.72s
                      Time elapsed: 00:38:49
                               ETA: 00:10:56

################################################################################
                     [1m Learning iteration 1171/1500 [0m                     

                       Computation: 56628 steps/s (collection: 1.643s, learning 0.093s)
             Mean action noise std: 3.08
          Mean value_function loss: 13.1385
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 43.4801
                       Mean reward: 847.59
               Mean episode length: 246.37
    Episode_Reward/reaching_object: 0.7547
    Episode_Reward/rotating_object: 169.4677
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 1.74s
                      Time elapsed: 00:38:51
                               ETA: 00:10:54

################################################################################
                     [1m Learning iteration 1172/1500 [0m                     

                       Computation: 55268 steps/s (collection: 1.654s, learning 0.125s)
             Mean action noise std: 3.09
          Mean value_function loss: 13.8024
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 43.4938
                       Mean reward: 846.45
               Mean episode length: 246.10
    Episode_Reward/reaching_object: 0.7548
    Episode_Reward/rotating_object: 170.5513
        Episode_Reward/action_rate: -0.0482
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 1.78s
                      Time elapsed: 00:38:53
                               ETA: 00:10:52

################################################################################
                     [1m Learning iteration 1173/1500 [0m                     

                       Computation: 55833 steps/s (collection: 1.619s, learning 0.142s)
             Mean action noise std: 3.09
          Mean value_function loss: 12.3634
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 43.5080
                       Mean reward: 852.63
               Mean episode length: 249.46
    Episode_Reward/reaching_object: 0.7567
    Episode_Reward/rotating_object: 170.5487
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 1.76s
                      Time elapsed: 00:38:55
                               ETA: 00:10:50

################################################################################
                     [1m Learning iteration 1174/1500 [0m                     

                       Computation: 56316 steps/s (collection: 1.658s, learning 0.088s)
             Mean action noise std: 3.09
          Mean value_function loss: 18.6327
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 43.5131
                       Mean reward: 824.02
               Mean episode length: 239.74
    Episode_Reward/reaching_object: 0.7469
    Episode_Reward/rotating_object: 169.6707
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 1.75s
                      Time elapsed: 00:38:56
                               ETA: 00:10:48

################################################################################
                     [1m Learning iteration 1175/1500 [0m                     

                       Computation: 56313 steps/s (collection: 1.653s, learning 0.093s)
             Mean action noise std: 3.09
          Mean value_function loss: 15.9799
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 43.5194
                       Mean reward: 856.60
               Mean episode length: 248.28
    Episode_Reward/reaching_object: 0.7510
    Episode_Reward/rotating_object: 169.6844
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 1.75s
                      Time elapsed: 00:38:58
                               ETA: 00:10:46

################################################################################
                     [1m Learning iteration 1176/1500 [0m                     

                       Computation: 55928 steps/s (collection: 1.648s, learning 0.110s)
             Mean action noise std: 3.09
          Mean value_function loss: 16.7526
               Mean surrogate loss: 0.0038
                 Mean entropy loss: 43.5314
                       Mean reward: 820.68
               Mean episode length: 239.53
    Episode_Reward/reaching_object: 0.7468
    Episode_Reward/rotating_object: 168.0441
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 1.76s
                      Time elapsed: 00:39:00
                               ETA: 00:10:44

################################################################################
                     [1m Learning iteration 1177/1500 [0m                     

                       Computation: 54621 steps/s (collection: 1.659s, learning 0.141s)
             Mean action noise std: 3.09
          Mean value_function loss: 20.3949
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 43.5351
                       Mean reward: 857.68
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7468
    Episode_Reward/rotating_object: 168.8156
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 1.80s
                      Time elapsed: 00:39:02
                               ETA: 00:10:42

################################################################################
                     [1m Learning iteration 1178/1500 [0m                     

                       Computation: 56702 steps/s (collection: 1.645s, learning 0.089s)
             Mean action noise std: 3.10
          Mean value_function loss: 16.2696
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 43.5448
                       Mean reward: 865.01
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7554
    Episode_Reward/rotating_object: 169.6692
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 1.73s
                      Time elapsed: 00:39:03
                               ETA: 00:10:40

################################################################################
                     [1m Learning iteration 1179/1500 [0m                     

                       Computation: 55253 steps/s (collection: 1.687s, learning 0.093s)
             Mean action noise std: 3.10
          Mean value_function loss: 10.5280
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.5501
                       Mean reward: 861.85
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7609
    Episode_Reward/rotating_object: 171.1083
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 1.78s
                      Time elapsed: 00:39:05
                               ETA: 00:10:38

################################################################################
                     [1m Learning iteration 1180/1500 [0m                     

                       Computation: 56864 steps/s (collection: 1.639s, learning 0.090s)
             Mean action noise std: 3.10
          Mean value_function loss: 21.3716
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.5540
                       Mean reward: 848.00
               Mean episode length: 245.79
    Episode_Reward/reaching_object: 0.7535
    Episode_Reward/rotating_object: 168.6606
        Episode_Reward/action_rate: -0.0485
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 1.73s
                      Time elapsed: 00:39:07
                               ETA: 00:10:36

################################################################################
                     [1m Learning iteration 1181/1500 [0m                     

                       Computation: 55937 steps/s (collection: 1.628s, learning 0.130s)
             Mean action noise std: 3.10
          Mean value_function loss: 13.7328
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.5640
                       Mean reward: 855.87
               Mean episode length: 248.45
    Episode_Reward/reaching_object: 0.7592
    Episode_Reward/rotating_object: 169.1573
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 1.76s
                      Time elapsed: 00:39:09
                               ETA: 00:10:33

################################################################################
                     [1m Learning iteration 1182/1500 [0m                     

                       Computation: 54492 steps/s (collection: 1.663s, learning 0.141s)
             Mean action noise std: 3.10
          Mean value_function loss: 12.9738
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.5768
                       Mean reward: 856.58
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 0.7606
    Episode_Reward/rotating_object: 170.3988
        Episode_Reward/action_rate: -0.0490
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 1.80s
                      Time elapsed: 00:39:10
                               ETA: 00:10:31

################################################################################
                     [1m Learning iteration 1183/1500 [0m                     

                       Computation: 55819 steps/s (collection: 1.665s, learning 0.097s)
             Mean action noise std: 3.10
          Mean value_function loss: 17.2414
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.5866
                       Mean reward: 859.35
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.7627
    Episode_Reward/rotating_object: 170.5211
        Episode_Reward/action_rate: -0.0490
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 1.76s
                      Time elapsed: 00:39:12
                               ETA: 00:10:29

################################################################################
                     [1m Learning iteration 1184/1500 [0m                     

                       Computation: 55761 steps/s (collection: 1.657s, learning 0.105s)
             Mean action noise std: 3.11
          Mean value_function loss: 16.8422
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.5983
                       Mean reward: 845.23
               Mean episode length: 245.61
    Episode_Reward/reaching_object: 0.7613
    Episode_Reward/rotating_object: 169.6232
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 1.76s
                      Time elapsed: 00:39:14
                               ETA: 00:10:27

################################################################################
                     [1m Learning iteration 1185/1500 [0m                     

                       Computation: 54091 steps/s (collection: 1.696s, learning 0.121s)
             Mean action noise std: 3.11
          Mean value_function loss: 16.6916
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.6092
                       Mean reward: 854.86
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7593
    Episode_Reward/rotating_object: 168.2922
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 1.82s
                      Time elapsed: 00:39:16
                               ETA: 00:10:25

################################################################################
                     [1m Learning iteration 1186/1500 [0m                     

                       Computation: 55768 steps/s (collection: 1.658s, learning 0.105s)
             Mean action noise std: 3.11
          Mean value_function loss: 21.6790
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 43.6219
                       Mean reward: 835.55
               Mean episode length: 245.68
    Episode_Reward/reaching_object: 0.7566
    Episode_Reward/rotating_object: 169.0414
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 1.76s
                      Time elapsed: 00:39:18
                               ETA: 00:10:23

################################################################################
                     [1m Learning iteration 1187/1500 [0m                     

                       Computation: 51374 steps/s (collection: 1.801s, learning 0.112s)
             Mean action noise std: 3.11
          Mean value_function loss: 14.3871
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 43.6317
                       Mean reward: 864.68
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7623
    Episode_Reward/rotating_object: 168.8032
        Episode_Reward/action_rate: -0.0490
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 1.91s
                      Time elapsed: 00:39:19
                               ETA: 00:10:21

################################################################################
                     [1m Learning iteration 1188/1500 [0m                     

                       Computation: 55438 steps/s (collection: 1.673s, learning 0.101s)
             Mean action noise std: 3.11
          Mean value_function loss: 10.4849
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.6386
                       Mean reward: 866.44
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7613
    Episode_Reward/rotating_object: 169.2944
        Episode_Reward/action_rate: -0.0495
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 1.77s
                      Time elapsed: 00:39:21
                               ETA: 00:10:19

################################################################################
                     [1m Learning iteration 1189/1500 [0m                     

                       Computation: 56086 steps/s (collection: 1.657s, learning 0.096s)
             Mean action noise std: 3.12
          Mean value_function loss: 16.4989
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.6486
                       Mean reward: 840.00
               Mean episode length: 244.07
    Episode_Reward/reaching_object: 0.7568
    Episode_Reward/rotating_object: 169.5481
        Episode_Reward/action_rate: -0.0493
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 1.75s
                      Time elapsed: 00:39:23
                               ETA: 00:10:17

################################################################################
                     [1m Learning iteration 1190/1500 [0m                     

                       Computation: 52975 steps/s (collection: 1.744s, learning 0.111s)
             Mean action noise std: 3.12
          Mean value_function loss: 16.3559
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 43.6622
                       Mean reward: 837.78
               Mean episode length: 244.30
    Episode_Reward/reaching_object: 0.7568
    Episode_Reward/rotating_object: 168.7044
        Episode_Reward/action_rate: -0.0493
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 1.86s
                      Time elapsed: 00:39:25
                               ETA: 00:10:15

################################################################################
                     [1m Learning iteration 1191/1500 [0m                     

                       Computation: 56591 steps/s (collection: 1.633s, learning 0.104s)
             Mean action noise std: 3.12
          Mean value_function loss: 9.1173
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.6816
                       Mean reward: 850.09
               Mean episode length: 248.28
    Episode_Reward/reaching_object: 0.7606
    Episode_Reward/rotating_object: 168.3829
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 1.74s
                      Time elapsed: 00:39:27
                               ETA: 00:10:13

################################################################################
                     [1m Learning iteration 1192/1500 [0m                     

                       Computation: 56044 steps/s (collection: 1.665s, learning 0.089s)
             Mean action noise std: 3.12
          Mean value_function loss: 14.5521
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 43.6917
                       Mean reward: 858.18
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.7563
    Episode_Reward/rotating_object: 169.0598
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 1.75s
                      Time elapsed: 00:39:28
                               ETA: 00:10:11

################################################################################
                     [1m Learning iteration 1193/1500 [0m                     

                       Computation: 54675 steps/s (collection: 1.693s, learning 0.105s)
             Mean action noise std: 3.13
          Mean value_function loss: 13.9739
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 43.7032
                       Mean reward: 845.37
               Mean episode length: 245.84
    Episode_Reward/reaching_object: 0.7519
    Episode_Reward/rotating_object: 168.1006
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 1.80s
                      Time elapsed: 00:39:30
                               ETA: 00:10:09

################################################################################
                     [1m Learning iteration 1194/1500 [0m                     

                       Computation: 54124 steps/s (collection: 1.675s, learning 0.142s)
             Mean action noise std: 3.13
          Mean value_function loss: 14.7465
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 43.7140
                       Mean reward: 851.10
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7531
    Episode_Reward/rotating_object: 168.9065
        Episode_Reward/action_rate: -0.0500
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 1.82s
                      Time elapsed: 00:39:32
                               ETA: 00:10:07

################################################################################
                     [1m Learning iteration 1195/1500 [0m                     

                       Computation: 54936 steps/s (collection: 1.643s, learning 0.147s)
             Mean action noise std: 3.13
          Mean value_function loss: 14.2887
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.7255
                       Mean reward: 832.85
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7442
    Episode_Reward/rotating_object: 168.1414
        Episode_Reward/action_rate: -0.0500
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 1.79s
                      Time elapsed: 00:39:34
                               ETA: 00:10:05

################################################################################
                     [1m Learning iteration 1196/1500 [0m                     

                       Computation: 56244 steps/s (collection: 1.636s, learning 0.112s)
             Mean action noise std: 3.13
          Mean value_function loss: 6.3634
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.7363
                       Mean reward: 861.35
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7480
    Episode_Reward/rotating_object: 170.3944
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 1.75s
                      Time elapsed: 00:39:35
                               ETA: 00:10:03

################################################################################
                     [1m Learning iteration 1197/1500 [0m                     

                       Computation: 54543 steps/s (collection: 1.687s, learning 0.115s)
             Mean action noise std: 3.13
          Mean value_function loss: 11.1934
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 43.7402
                       Mean reward: 842.01
               Mean episode length: 246.32
    Episode_Reward/reaching_object: 0.7353
    Episode_Reward/rotating_object: 169.6916
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 1.80s
                      Time elapsed: 00:39:37
                               ETA: 00:10:01

################################################################################
                     [1m Learning iteration 1198/1500 [0m                     

                       Computation: 55970 steps/s (collection: 1.632s, learning 0.124s)
             Mean action noise std: 3.13
          Mean value_function loss: 16.5607
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.7490
                       Mean reward: 853.57
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.7371
    Episode_Reward/rotating_object: 170.3385
        Episode_Reward/action_rate: -0.0507
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 1.76s
                      Time elapsed: 00:39:39
                               ETA: 00:09:59

################################################################################
                     [1m Learning iteration 1199/1500 [0m                     

                       Computation: 54640 steps/s (collection: 1.629s, learning 0.170s)
             Mean action noise std: 3.14
          Mean value_function loss: 16.1997
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 43.7589
                       Mean reward: 825.26
               Mean episode length: 243.05
    Episode_Reward/reaching_object: 0.7238
    Episode_Reward/rotating_object: 167.7305
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 1.80s
                      Time elapsed: 00:39:41
                               ETA: 00:09:57

################################################################################
                     [1m Learning iteration 1200/1500 [0m                     

                       Computation: 56953 steps/s (collection: 1.622s, learning 0.104s)
             Mean action noise std: 3.14
          Mean value_function loss: 20.2757
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.7723
                       Mean reward: 857.54
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 0.7263
    Episode_Reward/rotating_object: 169.1161
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 1.73s
                      Time elapsed: 00:39:43
                               ETA: 00:09:55

################################################################################
                     [1m Learning iteration 1201/1500 [0m                     

                       Computation: 56517 steps/s (collection: 1.632s, learning 0.107s)
             Mean action noise std: 3.14
          Mean value_function loss: 14.3260
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.7844
                       Mean reward: 853.09
               Mean episode length: 248.31
    Episode_Reward/reaching_object: 0.7217
    Episode_Reward/rotating_object: 167.0629
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 1.74s
                      Time elapsed: 00:39:44
                               ETA: 00:09:53

################################################################################
                     [1m Learning iteration 1202/1500 [0m                     

                       Computation: 56553 steps/s (collection: 1.640s, learning 0.099s)
             Mean action noise std: 3.14
          Mean value_function loss: 15.0276
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 43.7974
                       Mean reward: 863.91
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7230
    Episode_Reward/rotating_object: 169.1779
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 18.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 1.74s
                      Time elapsed: 00:39:46
                               ETA: 00:09:51

################################################################################
                     [1m Learning iteration 1203/1500 [0m                     

                       Computation: 54875 steps/s (collection: 1.636s, learning 0.156s)
             Mean action noise std: 3.14
          Mean value_function loss: 19.1394
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.8063
                       Mean reward: 856.40
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7170
    Episode_Reward/rotating_object: 168.4790
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 1.79s
                      Time elapsed: 00:39:48
                               ETA: 00:09:49

################################################################################
                     [1m Learning iteration 1204/1500 [0m                     

                       Computation: 55695 steps/s (collection: 1.670s, learning 0.095s)
             Mean action noise std: 3.14
          Mean value_function loss: 20.3594
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 43.8179
                       Mean reward: 837.70
               Mean episode length: 244.15
    Episode_Reward/reaching_object: 0.7056
    Episode_Reward/rotating_object: 166.9438
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 1.77s
                      Time elapsed: 00:39:50
                               ETA: 00:09:47

################################################################################
                     [1m Learning iteration 1205/1500 [0m                     

                       Computation: 56228 steps/s (collection: 1.660s, learning 0.089s)
             Mean action noise std: 3.15
          Mean value_function loss: 7.5963
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.8237
                       Mean reward: 860.13
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7171
    Episode_Reward/rotating_object: 171.0389
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 1.75s
                      Time elapsed: 00:39:51
                               ETA: 00:09:45

################################################################################
                     [1m Learning iteration 1206/1500 [0m                     

                       Computation: 56045 steps/s (collection: 1.657s, learning 0.097s)
             Mean action noise std: 3.15
          Mean value_function loss: 9.3589
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 43.8313
                       Mean reward: 851.55
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.7164
    Episode_Reward/rotating_object: 170.2160
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 1.75s
                      Time elapsed: 00:39:53
                               ETA: 00:09:43

################################################################################
                     [1m Learning iteration 1207/1500 [0m                     

                       Computation: 56790 steps/s (collection: 1.635s, learning 0.096s)
             Mean action noise std: 3.15
          Mean value_function loss: 17.0562
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 43.8462
                       Mean reward: 845.71
               Mean episode length: 245.72
    Episode_Reward/reaching_object: 0.7178
    Episode_Reward/rotating_object: 169.7960
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 1.73s
                      Time elapsed: 00:39:55
                               ETA: 00:09:40

################################################################################
                     [1m Learning iteration 1208/1500 [0m                     

                       Computation: 56515 steps/s (collection: 1.650s, learning 0.089s)
             Mean action noise std: 3.15
          Mean value_function loss: 17.8586
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 43.8589
                       Mean reward: 857.82
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.7119
    Episode_Reward/rotating_object: 169.2277
        Episode_Reward/action_rate: -0.0511
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 1.74s
                      Time elapsed: 00:39:57
                               ETA: 00:09:38

################################################################################
                     [1m Learning iteration 1209/1500 [0m                     

                       Computation: 57045 steps/s (collection: 1.627s, learning 0.097s)
             Mean action noise std: 3.16
          Mean value_function loss: 7.7498
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.8665
                       Mean reward: 846.71
               Mean episode length: 248.32
    Episode_Reward/reaching_object: 0.7156
    Episode_Reward/rotating_object: 169.7733
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 1.72s
                      Time elapsed: 00:39:58
                               ETA: 00:09:36

################################################################################
                     [1m Learning iteration 1210/1500 [0m                     

                       Computation: 56094 steps/s (collection: 1.633s, learning 0.119s)
             Mean action noise std: 3.16
          Mean value_function loss: 12.3933
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 43.8715
                       Mean reward: 863.67
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7107
    Episode_Reward/rotating_object: 167.7682
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 1.75s
                      Time elapsed: 00:40:00
                               ETA: 00:09:34

################################################################################
                     [1m Learning iteration 1211/1500 [0m                     

                       Computation: 56039 steps/s (collection: 1.602s, learning 0.152s)
             Mean action noise std: 3.16
          Mean value_function loss: 16.6744
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 43.8804
                       Mean reward: 825.93
               Mean episode length: 241.43
    Episode_Reward/reaching_object: 0.7082
    Episode_Reward/rotating_object: 168.4074
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 1.75s
                      Time elapsed: 00:40:02
                               ETA: 00:09:32

################################################################################
                     [1m Learning iteration 1212/1500 [0m                     

                       Computation: 54009 steps/s (collection: 1.705s, learning 0.116s)
             Mean action noise std: 3.16
          Mean value_function loss: 15.8220
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 43.8917
                       Mean reward: 843.63
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7065
    Episode_Reward/rotating_object: 168.1626
        Episode_Reward/action_rate: -0.0515
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 1.82s
                      Time elapsed: 00:40:04
                               ETA: 00:09:30

################################################################################
                     [1m Learning iteration 1213/1500 [0m                     

                       Computation: 52632 steps/s (collection: 1.765s, learning 0.103s)
             Mean action noise std: 3.16
          Mean value_function loss: 14.6419
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.9014
                       Mean reward: 832.20
               Mean episode length: 243.80
    Episode_Reward/reaching_object: 0.7127
    Episode_Reward/rotating_object: 169.1284
        Episode_Reward/action_rate: -0.0514
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 1.87s
                      Time elapsed: 00:40:05
                               ETA: 00:09:28

################################################################################
                     [1m Learning iteration 1214/1500 [0m                     

                       Computation: 55508 steps/s (collection: 1.664s, learning 0.107s)
             Mean action noise std: 3.16
          Mean value_function loss: 13.6197
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 43.9087
                       Mean reward: 848.33
               Mean episode length: 245.84
    Episode_Reward/reaching_object: 0.7118
    Episode_Reward/rotating_object: 170.6146
        Episode_Reward/action_rate: -0.0517
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 1.77s
                      Time elapsed: 00:40:07
                               ETA: 00:09:26

################################################################################
                     [1m Learning iteration 1215/1500 [0m                     

                       Computation: 55377 steps/s (collection: 1.661s, learning 0.114s)
             Mean action noise std: 3.17
          Mean value_function loss: 9.9393
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 43.9151
                       Mean reward: 860.71
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7157
    Episode_Reward/rotating_object: 170.5660
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 1.78s
                      Time elapsed: 00:40:09
                               ETA: 00:09:24

################################################################################
                     [1m Learning iteration 1216/1500 [0m                     

                       Computation: 54013 steps/s (collection: 1.690s, learning 0.130s)
             Mean action noise std: 3.17
          Mean value_function loss: 11.7159
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 43.9226
                       Mean reward: 856.07
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 0.7092
    Episode_Reward/rotating_object: 169.9593
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 1.82s
                      Time elapsed: 00:40:11
                               ETA: 00:09:22

################################################################################
                     [1m Learning iteration 1217/1500 [0m                     

                       Computation: 57460 steps/s (collection: 1.618s, learning 0.093s)
             Mean action noise std: 3.17
          Mean value_function loss: 8.4614
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 43.9315
                       Mean reward: 837.64
               Mean episode length: 243.70
    Episode_Reward/reaching_object: 0.7117
    Episode_Reward/rotating_object: 169.9529
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 1.71s
                      Time elapsed: 00:40:13
                               ETA: 00:09:20

################################################################################
                     [1m Learning iteration 1218/1500 [0m                     

                       Computation: 55810 steps/s (collection: 1.665s, learning 0.097s)
             Mean action noise std: 3.17
          Mean value_function loss: 5.7002
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.9451
                       Mean reward: 856.20
               Mean episode length: 248.52
    Episode_Reward/reaching_object: 0.7122
    Episode_Reward/rotating_object: 170.4930
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 1.76s
                      Time elapsed: 00:40:14
                               ETA: 00:09:18

################################################################################
                     [1m Learning iteration 1219/1500 [0m                     

                       Computation: 56216 steps/s (collection: 1.618s, learning 0.131s)
             Mean action noise std: 3.17
          Mean value_function loss: 15.6614
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.9496
                       Mean reward: 853.42
               Mean episode length: 246.61
    Episode_Reward/reaching_object: 0.7059
    Episode_Reward/rotating_object: 169.5778
        Episode_Reward/action_rate: -0.0514
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 1.75s
                      Time elapsed: 00:40:16
                               ETA: 00:09:16

################################################################################
                     [1m Learning iteration 1220/1500 [0m                     

                       Computation: 54586 steps/s (collection: 1.688s, learning 0.113s)
             Mean action noise std: 3.17
          Mean value_function loss: 15.1574
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.9533
                       Mean reward: 852.94
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7082
    Episode_Reward/rotating_object: 170.1017
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 1.80s
                      Time elapsed: 00:40:18
                               ETA: 00:09:14

################################################################################
                     [1m Learning iteration 1221/1500 [0m                     

                       Computation: 54383 steps/s (collection: 1.641s, learning 0.167s)
             Mean action noise std: 3.18
          Mean value_function loss: 11.4983
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 43.9601
                       Mean reward: 863.09
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7140
    Episode_Reward/rotating_object: 170.0285
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 1.81s
                      Time elapsed: 00:40:20
                               ETA: 00:09:12

################################################################################
                     [1m Learning iteration 1222/1500 [0m                     

                       Computation: 52984 steps/s (collection: 1.742s, learning 0.113s)
             Mean action noise std: 3.18
          Mean value_function loss: 11.3147
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 43.9724
                       Mean reward: 856.40
               Mean episode length: 248.08
    Episode_Reward/reaching_object: 0.7163
    Episode_Reward/rotating_object: 170.1573
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 1.86s
                      Time elapsed: 00:40:22
                               ETA: 00:09:10

################################################################################
                     [1m Learning iteration 1223/1500 [0m                     

                       Computation: 52204 steps/s (collection: 1.790s, learning 0.093s)
             Mean action noise std: 3.18
          Mean value_function loss: 9.5394
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.9787
                       Mean reward: 853.17
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7170
    Episode_Reward/rotating_object: 169.5450
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 1.88s
                      Time elapsed: 00:40:23
                               ETA: 00:09:08

################################################################################
                     [1m Learning iteration 1224/1500 [0m                     

                       Computation: 56202 steps/s (collection: 1.658s, learning 0.091s)
             Mean action noise std: 3.18
          Mean value_function loss: 8.7545
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.9802
                       Mean reward: 859.46
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7183
    Episode_Reward/rotating_object: 171.0250
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 1.75s
                      Time elapsed: 00:40:25
                               ETA: 00:09:06

################################################################################
                     [1m Learning iteration 1225/1500 [0m                     

                       Computation: 50730 steps/s (collection: 1.679s, learning 0.259s)
             Mean action noise std: 3.18
          Mean value_function loss: 16.9864
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.9873
                       Mean reward: 866.38
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7232
    Episode_Reward/rotating_object: 170.8641
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 1.94s
                      Time elapsed: 00:40:27
                               ETA: 00:09:04

################################################################################
                     [1m Learning iteration 1226/1500 [0m                     

                       Computation: 54754 steps/s (collection: 1.659s, learning 0.137s)
             Mean action noise std: 3.18
          Mean value_function loss: 17.7821
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.9973
                       Mean reward: 847.16
               Mean episode length: 245.75
    Episode_Reward/reaching_object: 0.7113
    Episode_Reward/rotating_object: 168.1855
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 1.80s
                      Time elapsed: 00:40:29
                               ETA: 00:09:02

################################################################################
                     [1m Learning iteration 1227/1500 [0m                     

                       Computation: 56832 steps/s (collection: 1.641s, learning 0.089s)
             Mean action noise std: 3.19
          Mean value_function loss: 12.7269
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 44.0020
                       Mean reward: 864.81
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7165
    Episode_Reward/rotating_object: 171.2778
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 1.73s
                      Time elapsed: 00:40:31
                               ETA: 00:09:00

################################################################################
                     [1m Learning iteration 1228/1500 [0m                     

                       Computation: 53119 steps/s (collection: 1.734s, learning 0.117s)
             Mean action noise std: 3.19
          Mean value_function loss: 19.0839
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.0092
                       Mean reward: 831.11
               Mean episode length: 241.50
    Episode_Reward/reaching_object: 0.7091
    Episode_Reward/rotating_object: 168.9120
        Episode_Reward/action_rate: -0.0514
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 1.85s
                      Time elapsed: 00:40:32
                               ETA: 00:08:58

################################################################################
                     [1m Learning iteration 1229/1500 [0m                     

                       Computation: 54990 steps/s (collection: 1.682s, learning 0.106s)
             Mean action noise std: 3.19
          Mean value_function loss: 16.2098
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 44.0214
                       Mean reward: 812.27
               Mean episode length: 241.32
    Episode_Reward/reaching_object: 0.7147
    Episode_Reward/rotating_object: 168.5276
        Episode_Reward/action_rate: -0.0515
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 1.79s
                      Time elapsed: 00:40:34
                               ETA: 00:08:56

################################################################################
                     [1m Learning iteration 1230/1500 [0m                     

                       Computation: 51512 steps/s (collection: 1.805s, learning 0.103s)
             Mean action noise std: 3.19
          Mean value_function loss: 15.6739
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 44.0305
                       Mean reward: 846.25
               Mean episode length: 246.46
    Episode_Reward/reaching_object: 0.7102
    Episode_Reward/rotating_object: 168.2856
        Episode_Reward/action_rate: -0.0515
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 1.91s
                      Time elapsed: 00:40:36
                               ETA: 00:08:54

################################################################################
                     [1m Learning iteration 1231/1500 [0m                     

                       Computation: 56759 steps/s (collection: 1.625s, learning 0.107s)
             Mean action noise std: 3.19
          Mean value_function loss: 17.4952
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 44.0420
                       Mean reward: 848.06
               Mean episode length: 247.53
    Episode_Reward/reaching_object: 0.7149
    Episode_Reward/rotating_object: 168.5970
        Episode_Reward/action_rate: -0.0515
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 1.73s
                      Time elapsed: 00:40:38
                               ETA: 00:08:52

################################################################################
                     [1m Learning iteration 1232/1500 [0m                     

                       Computation: 56275 steps/s (collection: 1.655s, learning 0.092s)
             Mean action noise std: 3.19
          Mean value_function loss: 16.1316
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 44.0564
                       Mean reward: 828.55
               Mean episode length: 242.77
    Episode_Reward/reaching_object: 0.7088
    Episode_Reward/rotating_object: 167.5761
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 1.75s
                      Time elapsed: 00:40:40
                               ETA: 00:08:50

################################################################################
                     [1m Learning iteration 1233/1500 [0m                     

                       Computation: 55396 steps/s (collection: 1.683s, learning 0.092s)
             Mean action noise std: 3.20
          Mean value_function loss: 16.6119
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 44.0639
                       Mean reward: 845.04
               Mean episode length: 245.47
    Episode_Reward/reaching_object: 0.7202
    Episode_Reward/rotating_object: 169.7282
        Episode_Reward/action_rate: -0.0517
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 1.77s
                      Time elapsed: 00:40:41
                               ETA: 00:08:48

################################################################################
                     [1m Learning iteration 1234/1500 [0m                     

                       Computation: 56093 steps/s (collection: 1.630s, learning 0.122s)
             Mean action noise std: 3.20
          Mean value_function loss: 13.5254
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 44.0705
                       Mean reward: 855.14
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 0.7225
    Episode_Reward/rotating_object: 169.6682
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 1.75s
                      Time elapsed: 00:40:43
                               ETA: 00:08:46

################################################################################
                     [1m Learning iteration 1235/1500 [0m                     

                       Computation: 54082 steps/s (collection: 1.667s, learning 0.151s)
             Mean action noise std: 3.20
          Mean value_function loss: 11.2971
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 44.0751
                       Mean reward: 857.76
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7250
    Episode_Reward/rotating_object: 169.5996
        Episode_Reward/action_rate: -0.0517
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 1.82s
                      Time elapsed: 00:40:45
                               ETA: 00:08:44

################################################################################
                     [1m Learning iteration 1236/1500 [0m                     

                       Computation: 55330 steps/s (collection: 1.671s, learning 0.106s)
             Mean action noise std: 3.20
          Mean value_function loss: 13.6309
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 44.0747
                       Mean reward: 831.04
               Mean episode length: 244.75
    Episode_Reward/reaching_object: 0.7221
    Episode_Reward/rotating_object: 168.7855
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 1.78s
                      Time elapsed: 00:40:47
                               ETA: 00:08:42

################################################################################
                     [1m Learning iteration 1237/1500 [0m                     

                       Computation: 53454 steps/s (collection: 1.739s, learning 0.100s)
             Mean action noise std: 3.20
          Mean value_function loss: 14.0678
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 44.0786
                       Mean reward: 865.22
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7248
    Episode_Reward/rotating_object: 168.9241
        Episode_Reward/action_rate: -0.0515
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 1.84s
                      Time elapsed: 00:40:49
                               ETA: 00:08:40

################################################################################
                     [1m Learning iteration 1238/1500 [0m                     

                       Computation: 56830 steps/s (collection: 1.637s, learning 0.093s)
             Mean action noise std: 3.20
          Mean value_function loss: 13.0916
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 44.0845
                       Mean reward: 865.93
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7317
    Episode_Reward/rotating_object: 171.6559
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 1.73s
                      Time elapsed: 00:40:50
                               ETA: 00:08:38

################################################################################
                     [1m Learning iteration 1239/1500 [0m                     

                       Computation: 55339 steps/s (collection: 1.672s, learning 0.104s)
             Mean action noise std: 3.20
          Mean value_function loss: 11.1529
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 44.0877
                       Mean reward: 866.51
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7285
    Episode_Reward/rotating_object: 170.4745
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 1.78s
                      Time elapsed: 00:40:52
                               ETA: 00:08:36

################################################################################
                     [1m Learning iteration 1240/1500 [0m                     

                       Computation: 50918 steps/s (collection: 1.762s, learning 0.169s)
             Mean action noise std: 3.21
          Mean value_function loss: 13.8782
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 44.0909
                       Mean reward: 847.22
               Mean episode length: 247.96
    Episode_Reward/reaching_object: 0.7333
    Episode_Reward/rotating_object: 169.8423
        Episode_Reward/action_rate: -0.0522
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 1.93s
                      Time elapsed: 00:40:54
                               ETA: 00:08:34

################################################################################
                     [1m Learning iteration 1241/1500 [0m                     

                       Computation: 56794 steps/s (collection: 1.638s, learning 0.093s)
             Mean action noise std: 3.21
          Mean value_function loss: 9.9568
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 44.0931
                       Mean reward: 842.65
               Mean episode length: 243.96
    Episode_Reward/reaching_object: 0.7262
    Episode_Reward/rotating_object: 168.5835
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 1.73s
                      Time elapsed: 00:40:56
                               ETA: 00:08:32

################################################################################
                     [1m Learning iteration 1242/1500 [0m                     

                       Computation: 57904 steps/s (collection: 1.606s, learning 0.092s)
             Mean action noise std: 3.21
          Mean value_function loss: 9.9141
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 44.0939
                       Mean reward: 857.41
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.7352
    Episode_Reward/rotating_object: 171.2957
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 1.70s
                      Time elapsed: 00:40:57
                               ETA: 00:08:30

################################################################################
                     [1m Learning iteration 1243/1500 [0m                     

                       Computation: 55966 steps/s (collection: 1.661s, learning 0.096s)
             Mean action noise std: 3.21
          Mean value_function loss: 13.1470
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 44.0948
                       Mean reward: 857.44
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7232
    Episode_Reward/rotating_object: 168.5251
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 1.76s
                      Time elapsed: 00:40:59
                               ETA: 00:08:28

################################################################################
                     [1m Learning iteration 1244/1500 [0m                     

                       Computation: 56282 steps/s (collection: 1.606s, learning 0.141s)
             Mean action noise std: 3.21
          Mean value_function loss: 12.2033
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 44.0975
                       Mean reward: 867.89
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7217
    Episode_Reward/rotating_object: 170.8555
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 1.75s
                      Time elapsed: 00:41:01
                               ETA: 00:08:26

################################################################################
                     [1m Learning iteration 1245/1500 [0m                     

                       Computation: 52892 steps/s (collection: 1.711s, learning 0.148s)
             Mean action noise std: 3.21
          Mean value_function loss: 12.1483
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 44.1045
                       Mean reward: 862.11
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7218
    Episode_Reward/rotating_object: 171.2340
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 1.86s
                      Time elapsed: 00:41:03
                               ETA: 00:08:24

################################################################################
                     [1m Learning iteration 1246/1500 [0m                     

                       Computation: 53443 steps/s (collection: 1.750s, learning 0.089s)
             Mean action noise std: 3.21
          Mean value_function loss: 7.8148
               Mean surrogate loss: 0.0034
                 Mean entropy loss: 44.1087
                       Mean reward: 856.35
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 0.7192
    Episode_Reward/rotating_object: 171.3799
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 1.84s
                      Time elapsed: 00:41:05
                               ETA: 00:08:22

################################################################################
                     [1m Learning iteration 1247/1500 [0m                     

                       Computation: 54202 steps/s (collection: 1.721s, learning 0.093s)
             Mean action noise std: 3.21
          Mean value_function loss: 9.7153
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 44.1096
                       Mean reward: 846.08
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7130
    Episode_Reward/rotating_object: 170.3817
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 1.81s
                      Time elapsed: 00:41:06
                               ETA: 00:08:20

################################################################################
                     [1m Learning iteration 1248/1500 [0m                     

                       Computation: 56290 steps/s (collection: 1.631s, learning 0.115s)
             Mean action noise std: 3.21
          Mean value_function loss: 9.4975
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 44.1121
                       Mean reward: 865.16
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7118
    Episode_Reward/rotating_object: 171.0760
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 1.75s
                      Time elapsed: 00:41:08
                               ETA: 00:08:18

################################################################################
                     [1m Learning iteration 1249/1500 [0m                     

                       Computation: 54576 steps/s (collection: 1.661s, learning 0.141s)
             Mean action noise std: 3.21
          Mean value_function loss: 7.8326
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 44.1196
                       Mean reward: 866.84
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7093
    Episode_Reward/rotating_object: 171.2906
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 1.80s
                      Time elapsed: 00:41:10
                               ETA: 00:08:16

################################################################################
                     [1m Learning iteration 1250/1500 [0m                     

                       Computation: 56386 steps/s (collection: 1.656s, learning 0.088s)
             Mean action noise std: 3.21
          Mean value_function loss: 8.8121
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 44.1262
                       Mean reward: 861.59
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7066
    Episode_Reward/rotating_object: 170.7508
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 1.74s
                      Time elapsed: 00:41:12
                               ETA: 00:08:14

################################################################################
                     [1m Learning iteration 1251/1500 [0m                     

                       Computation: 53065 steps/s (collection: 1.703s, learning 0.149s)
             Mean action noise std: 3.22
          Mean value_function loss: 7.9216
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 44.1308
                       Mean reward: 852.40
               Mean episode length: 247.99
    Episode_Reward/reaching_object: 0.7077
    Episode_Reward/rotating_object: 170.6955
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 1.85s
                      Time elapsed: 00:41:14
                               ETA: 00:08:12

################################################################################
                     [1m Learning iteration 1252/1500 [0m                     

                       Computation: 55344 steps/s (collection: 1.685s, learning 0.091s)
             Mean action noise std: 3.22
          Mean value_function loss: 18.1455
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 44.1364
                       Mean reward: 842.17
               Mean episode length: 243.56
    Episode_Reward/reaching_object: 0.6968
    Episode_Reward/rotating_object: 168.9969
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 1.78s
                      Time elapsed: 00:41:15
                               ETA: 00:08:10

################################################################################
                     [1m Learning iteration 1253/1500 [0m                     

                       Computation: 57041 steps/s (collection: 1.624s, learning 0.099s)
             Mean action noise std: 3.22
          Mean value_function loss: 14.8249
               Mean surrogate loss: 0.0083
                 Mean entropy loss: 44.1420
                       Mean reward: 847.05
               Mean episode length: 245.79
    Episode_Reward/reaching_object: 0.7060
    Episode_Reward/rotating_object: 170.2653
        Episode_Reward/action_rate: -0.0528
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 1.72s
                      Time elapsed: 00:41:17
                               ETA: 00:08:08

################################################################################
                     [1m Learning iteration 1254/1500 [0m                     

                       Computation: 56949 steps/s (collection: 1.613s, learning 0.113s)
             Mean action noise std: 3.22
          Mean value_function loss: 12.1383
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 44.1430
                       Mean reward: 845.50
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7054
    Episode_Reward/rotating_object: 169.7086
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 18.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 1.73s
                      Time elapsed: 00:41:19
                               ETA: 00:08:05

################################################################################
                     [1m Learning iteration 1255/1500 [0m                     

                       Computation: 56130 steps/s (collection: 1.662s, learning 0.089s)
             Mean action noise std: 3.22
          Mean value_function loss: 15.3756
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 44.1494
                       Mean reward: 831.93
               Mean episode length: 243.46
    Episode_Reward/reaching_object: 0.7057
    Episode_Reward/rotating_object: 168.5732
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 1.75s
                      Time elapsed: 00:41:21
                               ETA: 00:08:03

################################################################################
                     [1m Learning iteration 1256/1500 [0m                     

                       Computation: 55676 steps/s (collection: 1.673s, learning 0.093s)
             Mean action noise std: 3.22
          Mean value_function loss: 10.0276
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 44.1568
                       Mean reward: 863.63
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7205
    Episode_Reward/rotating_object: 170.3268
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 1.77s
                      Time elapsed: 00:41:22
                               ETA: 00:08:01

################################################################################
                     [1m Learning iteration 1257/1500 [0m                     

                       Computation: 50055 steps/s (collection: 1.797s, learning 0.167s)
             Mean action noise std: 3.22
          Mean value_function loss: 13.1199
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 44.1602
                       Mean reward: 840.00
               Mean episode length: 243.31
    Episode_Reward/reaching_object: 0.7178
    Episode_Reward/rotating_object: 170.1188
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 1.96s
                      Time elapsed: 00:41:24
                               ETA: 00:07:59

################################################################################
                     [1m Learning iteration 1258/1500 [0m                     

                       Computation: 53710 steps/s (collection: 1.679s, learning 0.151s)
             Mean action noise std: 3.22
          Mean value_function loss: 13.5091
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 44.1678
                       Mean reward: 847.45
               Mean episode length: 245.57
    Episode_Reward/reaching_object: 0.7190
    Episode_Reward/rotating_object: 170.5506
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 1.83s
                      Time elapsed: 00:41:26
                               ETA: 00:07:57

################################################################################
                     [1m Learning iteration 1259/1500 [0m                     

                       Computation: 53940 steps/s (collection: 1.680s, learning 0.143s)
             Mean action noise std: 3.22
          Mean value_function loss: 16.8002
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 44.1735
                       Mean reward: 863.87
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7154
    Episode_Reward/rotating_object: 169.0767
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 1.82s
                      Time elapsed: 00:41:28
                               ETA: 00:07:55

################################################################################
                     [1m Learning iteration 1260/1500 [0m                     

                       Computation: 54800 steps/s (collection: 1.685s, learning 0.109s)
             Mean action noise std: 3.23
          Mean value_function loss: 11.0139
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 44.1816
                       Mean reward: 868.16
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7207
    Episode_Reward/rotating_object: 170.4511
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 1.79s
                      Time elapsed: 00:41:30
                               ETA: 00:07:53

################################################################################
                     [1m Learning iteration 1261/1500 [0m                     

                       Computation: 55282 steps/s (collection: 1.685s, learning 0.093s)
             Mean action noise std: 3.23
          Mean value_function loss: 16.1973
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 44.1871
                       Mean reward: 840.35
               Mean episode length: 243.62
    Episode_Reward/reaching_object: 0.7247
    Episode_Reward/rotating_object: 171.0322
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 1.78s
                      Time elapsed: 00:41:32
                               ETA: 00:07:51

################################################################################
                     [1m Learning iteration 1262/1500 [0m                     

                       Computation: 53851 steps/s (collection: 1.709s, learning 0.117s)
             Mean action noise std: 3.23
          Mean value_function loss: 17.6779
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 44.1903
                       Mean reward: 853.85
               Mean episode length: 246.84
    Episode_Reward/reaching_object: 0.7132
    Episode_Reward/rotating_object: 167.7536
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 1.83s
                      Time elapsed: 00:41:33
                               ETA: 00:07:49

################################################################################
                     [1m Learning iteration 1263/1500 [0m                     

                       Computation: 52317 steps/s (collection: 1.723s, learning 0.156s)
             Mean action noise std: 3.23
          Mean value_function loss: 20.4357
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 44.1919
                       Mean reward: 837.12
               Mean episode length: 243.20
    Episode_Reward/reaching_object: 0.7083
    Episode_Reward/rotating_object: 166.1986
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 1.88s
                      Time elapsed: 00:41:35
                               ETA: 00:07:47

################################################################################
                     [1m Learning iteration 1264/1500 [0m                     

                       Computation: 56006 steps/s (collection: 1.659s, learning 0.096s)
             Mean action noise std: 3.23
          Mean value_function loss: 16.7109
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 44.1972
                       Mean reward: 865.23
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7195
    Episode_Reward/rotating_object: 170.2248
        Episode_Reward/action_rate: -0.0529
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 1.76s
                      Time elapsed: 00:41:37
                               ETA: 00:07:45

################################################################################
                     [1m Learning iteration 1265/1500 [0m                     

                       Computation: 53157 steps/s (collection: 1.737s, learning 0.112s)
             Mean action noise std: 3.23
          Mean value_function loss: 15.2967
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 44.2065
                       Mean reward: 856.89
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.7182
    Episode_Reward/rotating_object: 170.5308
        Episode_Reward/action_rate: -0.0529
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 1.85s
                      Time elapsed: 00:41:39
                               ETA: 00:07:43

################################################################################
                     [1m Learning iteration 1266/1500 [0m                     

                       Computation: 50875 steps/s (collection: 1.810s, learning 0.122s)
             Mean action noise std: 3.23
          Mean value_function loss: 16.1481
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 44.2164
                       Mean reward: 846.68
               Mean episode length: 245.48
    Episode_Reward/reaching_object: 0.7138
    Episode_Reward/rotating_object: 168.9618
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 1.93s
                      Time elapsed: 00:41:41
                               ETA: 00:07:41

################################################################################
                     [1m Learning iteration 1267/1500 [0m                     

                       Computation: 53013 steps/s (collection: 1.745s, learning 0.110s)
             Mean action noise std: 3.24
          Mean value_function loss: 15.4169
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 44.2274
                       Mean reward: 856.13
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.7142
    Episode_Reward/rotating_object: 170.4736
        Episode_Reward/action_rate: -0.0528
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 1.85s
                      Time elapsed: 00:41:43
                               ETA: 00:07:39

################################################################################
                     [1m Learning iteration 1268/1500 [0m                     

                       Computation: 53886 steps/s (collection: 1.729s, learning 0.095s)
             Mean action noise std: 3.24
          Mean value_function loss: 18.7448
               Mean surrogate loss: 0.2239
                 Mean entropy loss: 44.2396
                       Mean reward: 865.20
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7112
    Episode_Reward/rotating_object: 169.7233
        Episode_Reward/action_rate: -0.0529
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 1.82s
                      Time elapsed: 00:41:44
                               ETA: 00:07:37

################################################################################
                     [1m Learning iteration 1269/1500 [0m                     

                       Computation: 51545 steps/s (collection: 1.812s, learning 0.096s)
             Mean action noise std: 3.24
          Mean value_function loss: 191.3440
               Mean surrogate loss: 0.0068
                 Mean entropy loss: 44.2425
                       Mean reward: 796.26
               Mean episode length: 235.92
    Episode_Reward/reaching_object: 0.7047
    Episode_Reward/rotating_object: 164.7163
        Episode_Reward/action_rate: -0.0522
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 1.91s
                      Time elapsed: 00:41:46
                               ETA: 00:07:35

################################################################################
                     [1m Learning iteration 1270/1500 [0m                     

                       Computation: 50685 steps/s (collection: 1.847s, learning 0.093s)
             Mean action noise std: 3.24
          Mean value_function loss: 145.4205
               Mean surrogate loss: 0.0058
                 Mean entropy loss: 44.2428
                       Mean reward: 801.39
               Mean episode length: 244.02
    Episode_Reward/reaching_object: 0.7268
    Episode_Reward/rotating_object: 160.0033
        Episode_Reward/action_rate: -0.0534
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 1.94s
                      Time elapsed: 00:41:48
                               ETA: 00:07:33

################################################################################
                     [1m Learning iteration 1271/1500 [0m                     

                       Computation: 49988 steps/s (collection: 1.808s, learning 0.159s)
             Mean action noise std: 3.24
          Mean value_function loss: 148.5676
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 44.2430
                       Mean reward: 762.05
               Mean episode length: 240.03
    Episode_Reward/reaching_object: 0.7380
    Episode_Reward/rotating_object: 151.0322
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 1.97s
                      Time elapsed: 00:41:50
                               ETA: 00:07:32

################################################################################
                     [1m Learning iteration 1272/1500 [0m                     

                       Computation: 50949 steps/s (collection: 1.775s, learning 0.155s)
             Mean action noise std: 3.24
          Mean value_function loss: 125.0609
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 44.2434
                       Mean reward: 737.11
               Mean episode length: 241.48
    Episode_Reward/reaching_object: 0.7805
    Episode_Reward/rotating_object: 149.8019
        Episode_Reward/action_rate: -0.0551
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 1.93s
                      Time elapsed: 00:41:52
                               ETA: 00:07:30

################################################################################
                     [1m Learning iteration 1273/1500 [0m                     

                       Computation: 48298 steps/s (collection: 1.882s, learning 0.153s)
             Mean action noise std: 3.24
          Mean value_function loss: 112.4208
               Mean surrogate loss: 0.0122
                 Mean entropy loss: 44.2435
                       Mean reward: 720.46
               Mean episode length: 243.27
    Episode_Reward/reaching_object: 0.7959
    Episode_Reward/rotating_object: 144.1503
        Episode_Reward/action_rate: -0.0556
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 2.04s
                      Time elapsed: 00:41:54
                               ETA: 00:07:28

################################################################################
                     [1m Learning iteration 1274/1500 [0m                     

                       Computation: 49385 steps/s (collection: 1.879s, learning 0.111s)
             Mean action noise std: 3.24
          Mean value_function loss: 111.7756
               Mean surrogate loss: 0.0060
                 Mean entropy loss: 44.2436
                       Mean reward: 712.83
               Mean episode length: 246.68
    Episode_Reward/reaching_object: 0.8289
    Episode_Reward/rotating_object: 140.8763
        Episode_Reward/action_rate: -0.0564
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 1.99s
                      Time elapsed: 00:41:56
                               ETA: 00:07:26

################################################################################
                     [1m Learning iteration 1275/1500 [0m                     

                       Computation: 49571 steps/s (collection: 1.783s, learning 0.200s)
             Mean action noise std: 3.24
          Mean value_function loss: 113.6009
               Mean surrogate loss: 0.0155
                 Mean entropy loss: 44.2436
                       Mean reward: 694.67
               Mean episode length: 245.45
    Episode_Reward/reaching_object: 0.8596
    Episode_Reward/rotating_object: 138.1597
        Episode_Reward/action_rate: -0.0579
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 1.98s
                      Time elapsed: 00:41:58
                               ETA: 00:07:24

################################################################################
                     [1m Learning iteration 1276/1500 [0m                     

                       Computation: 46091 steps/s (collection: 1.991s, learning 0.142s)
             Mean action noise std: 3.24
          Mean value_function loss: 156.3196
               Mean surrogate loss: 0.0066
                 Mean entropy loss: 44.2437
                       Mean reward: 651.75
               Mean episode length: 238.00
    Episode_Reward/reaching_object: 0.8643
    Episode_Reward/rotating_object: 130.3202
        Episode_Reward/action_rate: -0.0572
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 2.13s
                      Time elapsed: 00:42:00
                               ETA: 00:07:22

################################################################################
                     [1m Learning iteration 1277/1500 [0m                     

                       Computation: 50775 steps/s (collection: 1.805s, learning 0.131s)
             Mean action noise std: 3.24
          Mean value_function loss: 171.7773
               Mean surrogate loss: 0.0133
                 Mean entropy loss: 44.2438
                       Mean reward: 616.16
               Mean episode length: 233.76
    Episode_Reward/reaching_object: 0.8801
    Episode_Reward/rotating_object: 126.0882
        Episode_Reward/action_rate: -0.0576
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 1.94s
                      Time elapsed: 00:42:02
                               ETA: 00:07:20

################################################################################
                     [1m Learning iteration 1278/1500 [0m                     

                       Computation: 46061 steps/s (collection: 1.974s, learning 0.161s)
             Mean action noise std: 3.24
          Mean value_function loss: 131.9010
               Mean surrogate loss: 0.0042
                 Mean entropy loss: 44.2440
                       Mean reward: 640.12
               Mean episode length: 244.75
    Episode_Reward/reaching_object: 0.9062
    Episode_Reward/rotating_object: 127.1113
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 2.13s
                      Time elapsed: 00:42:04
                               ETA: 00:07:18

################################################################################
                     [1m Learning iteration 1279/1500 [0m                     

                       Computation: 50220 steps/s (collection: 1.863s, learning 0.094s)
             Mean action noise std: 3.24
          Mean value_function loss: 135.9985
               Mean surrogate loss: 0.0143
                 Mean entropy loss: 44.2442
                       Mean reward: 648.22
               Mean episode length: 245.38
    Episode_Reward/reaching_object: 0.8946
    Episode_Reward/rotating_object: 125.9562
        Episode_Reward/action_rate: -0.0587
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 1.96s
                      Time elapsed: 00:42:06
                               ETA: 00:07:16

################################################################################
                     [1m Learning iteration 1280/1500 [0m                     

                       Computation: 51680 steps/s (collection: 1.800s, learning 0.102s)
             Mean action noise std: 3.24
          Mean value_function loss: 119.2594
               Mean surrogate loss: 0.0072
                 Mean entropy loss: 44.2443
                       Mean reward: 665.26
               Mean episode length: 246.21
    Episode_Reward/reaching_object: 0.9170
    Episode_Reward/rotating_object: 130.0145
        Episode_Reward/action_rate: -0.0596
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 1.90s
                      Time elapsed: 00:42:08
                               ETA: 00:07:14

################################################################################
                     [1m Learning iteration 1281/1500 [0m                     

                       Computation: 45799 steps/s (collection: 1.996s, learning 0.151s)
             Mean action noise std: 3.24
          Mean value_function loss: 105.4600
               Mean surrogate loss: 0.0098
                 Mean entropy loss: 44.2444
                       Mean reward: 655.99
               Mean episode length: 243.76
    Episode_Reward/reaching_object: 0.9096
    Episode_Reward/rotating_object: 129.4445
        Episode_Reward/action_rate: -0.0591
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 2.15s
                      Time elapsed: 00:42:10
                               ETA: 00:07:12

################################################################################
                     [1m Learning iteration 1282/1500 [0m                     

                       Computation: 52642 steps/s (collection: 1.773s, learning 0.095s)
             Mean action noise std: 3.24
          Mean value_function loss: 120.2779
               Mean surrogate loss: 0.0126
                 Mean entropy loss: 44.2445
                       Mean reward: 652.22
               Mean episode length: 242.57
    Episode_Reward/reaching_object: 0.9083
    Episode_Reward/rotating_object: 129.6675
        Episode_Reward/action_rate: -0.0587
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 1.87s
                      Time elapsed: 00:42:12
                               ETA: 00:07:10

################################################################################
                     [1m Learning iteration 1283/1500 [0m                     

                       Computation: 50068 steps/s (collection: 1.800s, learning 0.163s)
             Mean action noise std: 3.24
          Mean value_function loss: 117.2012
               Mean surrogate loss: 0.0036
                 Mean entropy loss: 44.2445
                       Mean reward: 636.58
               Mean episode length: 237.93
    Episode_Reward/reaching_object: 0.9023
    Episode_Reward/rotating_object: 129.3000
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 1.96s
                      Time elapsed: 00:42:14
                               ETA: 00:07:08

################################################################################
                     [1m Learning iteration 1284/1500 [0m                     

                       Computation: 49614 steps/s (collection: 1.838s, learning 0.144s)
             Mean action noise std: 3.24
          Mean value_function loss: 92.4775
               Mean surrogate loss: 0.0122
                 Mean entropy loss: 44.2447
                       Mean reward: 649.35
               Mean episode length: 237.07
    Episode_Reward/reaching_object: 0.9092
    Episode_Reward/rotating_object: 131.6570
        Episode_Reward/action_rate: -0.0580
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 1.98s
                      Time elapsed: 00:42:16
                               ETA: 00:07:06

################################################################################
                     [1m Learning iteration 1285/1500 [0m                     

                       Computation: 51666 steps/s (collection: 1.800s, learning 0.103s)
             Mean action noise std: 3.24
          Mean value_function loss: 78.4007
               Mean surrogate loss: 0.0100
                 Mean entropy loss: 44.2448
                       Mean reward: 677.37
               Mean episode length: 246.35
    Episode_Reward/reaching_object: 0.9147
    Episode_Reward/rotating_object: 133.5062
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 1.90s
                      Time elapsed: 00:42:18
                               ETA: 00:07:04

################################################################################
                     [1m Learning iteration 1286/1500 [0m                     

                       Computation: 52239 steps/s (collection: 1.783s, learning 0.099s)
             Mean action noise std: 3.24
          Mean value_function loss: 49.0842
               Mean surrogate loss: 0.0126
                 Mean entropy loss: 44.2448
                       Mean reward: 700.31
               Mean episode length: 249.45
    Episode_Reward/reaching_object: 0.9257
    Episode_Reward/rotating_object: 136.0440
        Episode_Reward/action_rate: -0.0585
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 1.88s
                      Time elapsed: 00:42:20
                               ETA: 00:07:02

################################################################################
                     [1m Learning iteration 1287/1500 [0m                     

                       Computation: 50889 steps/s (collection: 1.838s, learning 0.093s)
             Mean action noise std: 3.24
          Mean value_function loss: 64.5670
               Mean surrogate loss: 0.0126
                 Mean entropy loss: 44.2448
                       Mean reward: 696.71
               Mean episode length: 246.42
    Episode_Reward/reaching_object: 0.9219
    Episode_Reward/rotating_object: 136.5402
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 1.93s
                      Time elapsed: 00:42:22
                               ETA: 00:07:00

################################################################################
                     [1m Learning iteration 1288/1500 [0m                     

                       Computation: 51129 steps/s (collection: 1.831s, learning 0.092s)
             Mean action noise std: 3.24
          Mean value_function loss: 52.4965
               Mean surrogate loss: 0.0126
                 Mean entropy loss: 44.2447
                       Mean reward: 693.04
               Mean episode length: 244.02
    Episode_Reward/reaching_object: 0.9197
    Episode_Reward/rotating_object: 136.9372
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 1.92s
                      Time elapsed: 00:42:24
                               ETA: 00:06:58

################################################################################
                     [1m Learning iteration 1289/1500 [0m                     

                       Computation: 51257 steps/s (collection: 1.819s, learning 0.099s)
             Mean action noise std: 3.24
          Mean value_function loss: 47.3023
               Mean surrogate loss: 0.0044
                 Mean entropy loss: 44.2447
                       Mean reward: 710.88
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.9207
    Episode_Reward/rotating_object: 137.9604
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 1.92s
                      Time elapsed: 00:42:26
                               ETA: 00:06:56

################################################################################
                     [1m Learning iteration 1290/1500 [0m                     

                       Computation: 51790 steps/s (collection: 1.795s, learning 0.103s)
             Mean action noise std: 3.24
          Mean value_function loss: 34.0228
               Mean surrogate loss: 0.0047
                 Mean entropy loss: 44.2447
                       Mean reward: 721.09
               Mean episode length: 249.81
    Episode_Reward/reaching_object: 0.9270
    Episode_Reward/rotating_object: 140.1804
        Episode_Reward/action_rate: -0.0574
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 1.90s
                      Time elapsed: 00:42:28
                               ETA: 00:06:54

################################################################################
                     [1m Learning iteration 1291/1500 [0m                     

                       Computation: 47232 steps/s (collection: 1.944s, learning 0.138s)
             Mean action noise std: 3.24
          Mean value_function loss: 39.7265
               Mean surrogate loss: 0.0050
                 Mean entropy loss: 44.2444
                       Mean reward: 704.64
               Mean episode length: 242.09
    Episode_Reward/reaching_object: 0.9251
    Episode_Reward/rotating_object: 140.5691
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 2.08s
                      Time elapsed: 00:42:30
                               ETA: 00:06:52

################################################################################
                     [1m Learning iteration 1292/1500 [0m                     

                       Computation: 51110 steps/s (collection: 1.813s, learning 0.110s)
             Mean action noise std: 3.24
          Mean value_function loss: 25.6183
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 44.2437
                       Mean reward: 724.13
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 0.9431
    Episode_Reward/rotating_object: 144.7814
        Episode_Reward/action_rate: -0.0581
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 1.92s
                      Time elapsed: 00:42:32
                               ETA: 00:06:50

################################################################################
                     [1m Learning iteration 1293/1500 [0m                     

                       Computation: 49966 steps/s (collection: 1.850s, learning 0.118s)
             Mean action noise std: 3.24
          Mean value_function loss: 29.7564
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 44.2417
                       Mean reward: 736.69
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.9344
    Episode_Reward/rotating_object: 144.2485
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 1.97s
                      Time elapsed: 00:42:34
                               ETA: 00:06:48

################################################################################
                     [1m Learning iteration 1294/1500 [0m                     

                       Computation: 50164 steps/s (collection: 1.843s, learning 0.117s)
             Mean action noise std: 3.24
          Mean value_function loss: 34.7086
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 44.2377
                       Mean reward: 737.63
               Mean episode length: 247.05
    Episode_Reward/reaching_object: 0.9333
    Episode_Reward/rotating_object: 144.8329
        Episode_Reward/action_rate: -0.0564
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 1.96s
                      Time elapsed: 00:42:36
                               ETA: 00:06:46

################################################################################
                     [1m Learning iteration 1295/1500 [0m                     

                       Computation: 51238 steps/s (collection: 1.795s, learning 0.123s)
             Mean action noise std: 3.24
          Mean value_function loss: 31.0818
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 44.2285
                       Mean reward: 750.66
               Mean episode length: 249.90
    Episode_Reward/reaching_object: 0.9391
    Episode_Reward/rotating_object: 146.4362
        Episode_Reward/action_rate: -0.0565
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 1.92s
                      Time elapsed: 00:42:38
                               ETA: 00:06:44

################################################################################
                     [1m Learning iteration 1296/1500 [0m                     

                       Computation: 50520 steps/s (collection: 1.819s, learning 0.127s)
             Mean action noise std: 3.24
          Mean value_function loss: 22.5525
               Mean surrogate loss: 0.0033
                 Mean entropy loss: 44.2207
                       Mean reward: 731.74
               Mean episode length: 243.45
    Episode_Reward/reaching_object: 0.9403
    Episode_Reward/rotating_object: 147.6919
        Episode_Reward/action_rate: -0.0562
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 1.95s
                      Time elapsed: 00:42:39
                               ETA: 00:06:42

################################################################################
                     [1m Learning iteration 1297/1500 [0m                     

                       Computation: 49729 steps/s (collection: 1.826s, learning 0.151s)
             Mean action noise std: 3.24
          Mean value_function loss: 24.8323
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 44.2167
                       Mean reward: 764.48
               Mean episode length: 249.80
    Episode_Reward/reaching_object: 0.9506
    Episode_Reward/rotating_object: 150.1529
        Episode_Reward/action_rate: -0.0565
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 1.98s
                      Time elapsed: 00:42:41
                               ETA: 00:06:40

################################################################################
                     [1m Learning iteration 1298/1500 [0m                     

                       Computation: 50972 steps/s (collection: 1.822s, learning 0.106s)
             Mean action noise std: 3.24
          Mean value_function loss: 29.8049
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 44.2044
                       Mean reward: 757.85
               Mean episode length: 248.33
    Episode_Reward/reaching_object: 0.9384
    Episode_Reward/rotating_object: 148.6177
        Episode_Reward/action_rate: -0.0556
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 1.93s
                      Time elapsed: 00:42:43
                               ETA: 00:06:38

################################################################################
                     [1m Learning iteration 1299/1500 [0m                     

                       Computation: 49486 steps/s (collection: 1.835s, learning 0.151s)
             Mean action noise std: 3.24
          Mean value_function loss: 20.7929
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 44.1962
                       Mean reward: 771.58
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.9411
    Episode_Reward/rotating_object: 149.8865
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 1.99s
                      Time elapsed: 00:42:45
                               ETA: 00:06:36

################################################################################
                     [1m Learning iteration 1300/1500 [0m                     

                       Computation: 49938 steps/s (collection: 1.809s, learning 0.160s)
             Mean action noise std: 3.23
          Mean value_function loss: 20.6092
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 44.1903
                       Mean reward: 762.45
               Mean episode length: 248.51
    Episode_Reward/reaching_object: 0.9441
    Episode_Reward/rotating_object: 151.1259
        Episode_Reward/action_rate: -0.0550
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 1.97s
                      Time elapsed: 00:42:47
                               ETA: 00:06:34

################################################################################
                     [1m Learning iteration 1301/1500 [0m                     

                       Computation: 50057 steps/s (collection: 1.795s, learning 0.169s)
             Mean action noise std: 3.23
          Mean value_function loss: 14.8646
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 44.1816
                       Mean reward: 765.69
               Mean episode length: 247.98
    Episode_Reward/reaching_object: 0.9542
    Episode_Reward/rotating_object: 153.6480
        Episode_Reward/action_rate: -0.0553
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 1.96s
                      Time elapsed: 00:42:49
                               ETA: 00:06:32

################################################################################
                     [1m Learning iteration 1302/1500 [0m                     

                       Computation: 49687 steps/s (collection: 1.826s, learning 0.153s)
             Mean action noise std: 3.23
          Mean value_function loss: 13.8171
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 44.1666
                       Mean reward: 780.72
               Mean episode length: 248.27
    Episode_Reward/reaching_object: 0.9524
    Episode_Reward/rotating_object: 153.9205
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 1.98s
                      Time elapsed: 00:42:51
                               ETA: 00:06:30

################################################################################
                     [1m Learning iteration 1303/1500 [0m                     

                       Computation: 49627 steps/s (collection: 1.845s, learning 0.136s)
             Mean action noise std: 3.23
          Mean value_function loss: 14.3231
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 44.1609
                       Mean reward: 790.84
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.9534
    Episode_Reward/rotating_object: 154.5291
        Episode_Reward/action_rate: -0.0545
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 1.98s
                      Time elapsed: 00:42:53
                               ETA: 00:06:28

################################################################################
                     [1m Learning iteration 1304/1500 [0m                     

                       Computation: 48400 steps/s (collection: 1.885s, learning 0.146s)
             Mean action noise std: 3.23
          Mean value_function loss: 18.7763
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 44.1535
                       Mean reward: 777.47
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 0.9505
    Episode_Reward/rotating_object: 154.2552
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 2.03s
                      Time elapsed: 00:42:55
                               ETA: 00:06:26

################################################################################
                     [1m Learning iteration 1305/1500 [0m                     

                       Computation: 48304 steps/s (collection: 1.877s, learning 0.158s)
             Mean action noise std: 3.23
          Mean value_function loss: 16.6898
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 44.1431
                       Mean reward: 780.78
               Mean episode length: 246.10
    Episode_Reward/reaching_object: 0.9485
    Episode_Reward/rotating_object: 154.8710
        Episode_Reward/action_rate: -0.0534
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 2.04s
                      Time elapsed: 00:42:57
                               ETA: 00:06:24

################################################################################
                     [1m Learning iteration 1306/1500 [0m                     

                       Computation: 45835 steps/s (collection: 1.935s, learning 0.210s)
             Mean action noise std: 3.23
          Mean value_function loss: 19.6797
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 44.1279
                       Mean reward: 796.24
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.9625
    Episode_Reward/rotating_object: 157.4104
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 2.14s
                      Time elapsed: 00:42:59
                               ETA: 00:06:22

################################################################################
                     [1m Learning iteration 1307/1500 [0m                     

                       Computation: 51343 steps/s (collection: 1.820s, learning 0.095s)
             Mean action noise std: 3.23
          Mean value_function loss: 13.3618
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 44.1104
                       Mean reward: 794.25
               Mean episode length: 248.01
    Episode_Reward/reaching_object: 0.9559
    Episode_Reward/rotating_object: 157.0139
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 1.91s
                      Time elapsed: 00:43:01
                               ETA: 00:06:20

################################################################################
                     [1m Learning iteration 1308/1500 [0m                     

                       Computation: 50491 steps/s (collection: 1.828s, learning 0.119s)
             Mean action noise std: 3.23
          Mean value_function loss: 20.2011
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 44.0928
                       Mean reward: 802.05
               Mean episode length: 249.71
    Episode_Reward/reaching_object: 0.9611
    Episode_Reward/rotating_object: 158.7413
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 1.95s
                      Time elapsed: 00:43:03
                               ETA: 00:06:18

################################################################################
                     [1m Learning iteration 1309/1500 [0m                     

                       Computation: 51284 steps/s (collection: 1.810s, learning 0.107s)
             Mean action noise std: 3.23
          Mean value_function loss: 17.0972
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 44.0856
                       Mean reward: 799.97
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 0.9583
    Episode_Reward/rotating_object: 158.3922
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 1.92s
                      Time elapsed: 00:43:05
                               ETA: 00:06:17

################################################################################
                     [1m Learning iteration 1310/1500 [0m                     

                       Computation: 51765 steps/s (collection: 1.780s, learning 0.119s)
             Mean action noise std: 3.23
          Mean value_function loss: 11.6587
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 44.0730
                       Mean reward: 811.37
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.9600
    Episode_Reward/rotating_object: 158.9884
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 1.90s
                      Time elapsed: 00:43:07
                               ETA: 00:06:15

################################################################################
                     [1m Learning iteration 1311/1500 [0m                     

                       Computation: 49175 steps/s (collection: 1.846s, learning 0.153s)
             Mean action noise std: 3.23
          Mean value_function loss: 15.5123
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 44.0626
                       Mean reward: 811.83
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.9645
    Episode_Reward/rotating_object: 160.0388
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 2.00s
                      Time elapsed: 00:43:09
                               ETA: 00:06:13

################################################################################
                     [1m Learning iteration 1312/1500 [0m                     

                       Computation: 51799 steps/s (collection: 1.795s, learning 0.103s)
             Mean action noise std: 3.23
          Mean value_function loss: 18.2917
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.0531
                       Mean reward: 795.63
               Mean episode length: 246.19
    Episode_Reward/reaching_object: 0.9638
    Episode_Reward/rotating_object: 160.4888
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 1.90s
                      Time elapsed: 00:43:11
                               ETA: 00:06:11

################################################################################
                     [1m Learning iteration 1313/1500 [0m                     

                       Computation: 52769 steps/s (collection: 1.769s, learning 0.094s)
             Mean action noise std: 3.23
          Mean value_function loss: 19.2930
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 44.0428
                       Mean reward: 806.06
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.9597
    Episode_Reward/rotating_object: 159.5405
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 1.86s
                      Time elapsed: 00:43:13
                               ETA: 00:06:09

################################################################################
                     [1m Learning iteration 1314/1500 [0m                     

                       Computation: 51345 steps/s (collection: 1.818s, learning 0.097s)
             Mean action noise std: 3.23
          Mean value_function loss: 13.6401
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.0355
                       Mean reward: 799.50
               Mean episode length: 245.51
    Episode_Reward/reaching_object: 0.9607
    Episode_Reward/rotating_object: 160.6408
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 1.91s
                      Time elapsed: 00:43:15
                               ETA: 00:06:07

################################################################################
                     [1m Learning iteration 1315/1500 [0m                     

                       Computation: 51419 steps/s (collection: 1.817s, learning 0.095s)
             Mean action noise std: 3.23
          Mean value_function loss: 18.5717
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 44.0240
                       Mean reward: 807.25
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.9598
    Episode_Reward/rotating_object: 160.6711
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 1.91s
                      Time elapsed: 00:43:17
                               ETA: 00:06:05

################################################################################
                     [1m Learning iteration 1316/1500 [0m                     

                       Computation: 49675 steps/s (collection: 1.813s, learning 0.166s)
             Mean action noise std: 3.23
          Mean value_function loss: 19.0337
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 44.0172
                       Mean reward: 817.41
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.9556
    Episode_Reward/rotating_object: 160.0895
        Episode_Reward/action_rate: -0.0522
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 1.98s
                      Time elapsed: 00:43:19
                               ETA: 00:06:03

################################################################################
                     [1m Learning iteration 1317/1500 [0m                     

                       Computation: 50209 steps/s (collection: 1.862s, learning 0.096s)
             Mean action noise std: 3.23
          Mean value_function loss: 15.5692
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 44.0069
                       Mean reward: 803.39
               Mean episode length: 246.60
    Episode_Reward/reaching_object: 0.9617
    Episode_Reward/rotating_object: 161.6316
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 1.96s
                      Time elapsed: 00:43:21
                               ETA: 00:06:01

################################################################################
                     [1m Learning iteration 1318/1500 [0m                     

                       Computation: 52046 steps/s (collection: 1.780s, learning 0.109s)
             Mean action noise std: 3.23
          Mean value_function loss: 8.9651
               Mean surrogate loss: 0.0023
                 Mean entropy loss: 44.0037
                       Mean reward: 815.46
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 0.9560
    Episode_Reward/rotating_object: 161.4159
        Episode_Reward/action_rate: -0.0522
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 1.89s
                      Time elapsed: 00:43:23
                               ETA: 00:05:59

################################################################################
                     [1m Learning iteration 1319/1500 [0m                     

                       Computation: 48448 steps/s (collection: 1.868s, learning 0.161s)
             Mean action noise std: 3.23
          Mean value_function loss: 11.7682
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 44.0009
                       Mean reward: 818.81
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.9580
    Episode_Reward/rotating_object: 162.1490
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 2.03s
                      Time elapsed: 00:43:25
                               ETA: 00:05:57

################################################################################
                     [1m Learning iteration 1320/1500 [0m                     

                       Computation: 49031 steps/s (collection: 1.838s, learning 0.167s)
             Mean action noise std: 3.23
          Mean value_function loss: 18.1802
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 43.9972
                       Mean reward: 791.92
               Mean episode length: 241.71
    Episode_Reward/reaching_object: 0.9442
    Episode_Reward/rotating_object: 160.8729
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 2.00s
                      Time elapsed: 00:43:27
                               ETA: 00:05:55

################################################################################
                     [1m Learning iteration 1321/1500 [0m                     

                       Computation: 49992 steps/s (collection: 1.817s, learning 0.150s)
             Mean action noise std: 3.23
          Mean value_function loss: 10.9042
               Mean surrogate loss: 0.0094
                 Mean entropy loss: 43.9954
                       Mean reward: 810.80
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 0.9359
    Episode_Reward/rotating_object: 160.1321
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 1.97s
                      Time elapsed: 00:43:29
                               ETA: 00:05:53

################################################################################
                     [1m Learning iteration 1322/1500 [0m                     

                       Computation: 50377 steps/s (collection: 1.785s, learning 0.166s)
             Mean action noise std: 3.23
          Mean value_function loss: 10.5585
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.9937
                       Mean reward: 816.98
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 0.9368
    Episode_Reward/rotating_object: 162.7364
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 1.95s
                      Time elapsed: 00:43:31
                               ETA: 00:05:51

################################################################################
                     [1m Learning iteration 1323/1500 [0m                     

                       Computation: 48661 steps/s (collection: 1.791s, learning 0.229s)
             Mean action noise std: 3.23
          Mean value_function loss: 7.7275
               Mean surrogate loss: 0.0012
                 Mean entropy loss: 43.9850
                       Mean reward: 830.75
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.9285
    Episode_Reward/rotating_object: 164.1864
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 2.02s
                      Time elapsed: 00:43:33
                               ETA: 00:05:49

################################################################################
                     [1m Learning iteration 1324/1500 [0m                     

                       Computation: 51041 steps/s (collection: 1.773s, learning 0.153s)
             Mean action noise std: 3.23
          Mean value_function loss: 14.3028
               Mean surrogate loss: 0.0273
                 Mean entropy loss: 43.9804
                       Mean reward: 829.29
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.9059
    Episode_Reward/rotating_object: 164.9325
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 1.93s
                      Time elapsed: 00:43:34
                               ETA: 00:05:47

################################################################################
                     [1m Learning iteration 1325/1500 [0m                     

                       Computation: 53123 steps/s (collection: 1.742s, learning 0.109s)
             Mean action noise std: 3.23
          Mean value_function loss: 9.4518
               Mean surrogate loss: 0.0086
                 Mean entropy loss: 43.9803
                       Mean reward: 845.79
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.8870
    Episode_Reward/rotating_object: 165.7660
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 1.85s
                      Time elapsed: 00:43:36
                               ETA: 00:05:45

################################################################################
                     [1m Learning iteration 1326/1500 [0m                     

                       Computation: 53298 steps/s (collection: 1.747s, learning 0.097s)
             Mean action noise std: 3.23
          Mean value_function loss: 13.4118
               Mean surrogate loss: 0.0083
                 Mean entropy loss: 43.9802
                       Mean reward: 835.15
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.8643
    Episode_Reward/rotating_object: 165.4087
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 1.84s
                      Time elapsed: 00:43:38
                               ETA: 00:05:43

################################################################################
                     [1m Learning iteration 1327/1500 [0m                     

                       Computation: 52655 steps/s (collection: 1.771s, learning 0.096s)
             Mean action noise std: 3.23
          Mean value_function loss: 8.0089
               Mean surrogate loss: 0.0058
                 Mean entropy loss: 43.9800
                       Mean reward: 850.78
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.8482
    Episode_Reward/rotating_object: 166.6321
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 1.87s
                      Time elapsed: 00:43:40
                               ETA: 00:05:41

################################################################################
                     [1m Learning iteration 1328/1500 [0m                     

                       Computation: 51511 steps/s (collection: 1.796s, learning 0.112s)
             Mean action noise std: 3.23
          Mean value_function loss: 8.1575
               Mean surrogate loss: 0.0057
                 Mean entropy loss: 43.9798
                       Mean reward: 843.56
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.8421
    Episode_Reward/rotating_object: 168.3019
        Episode_Reward/action_rate: -0.0522
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 1.91s
                      Time elapsed: 00:43:42
                               ETA: 00:05:39

################################################################################
                     [1m Learning iteration 1329/1500 [0m                     

                       Computation: 53442 steps/s (collection: 1.718s, learning 0.121s)
             Mean action noise std: 3.23
          Mean value_function loss: 8.9098
               Mean surrogate loss: 0.0028
                 Mean entropy loss: 43.9789
                       Mean reward: 853.92
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.8233
    Episode_Reward/rotating_object: 169.2951
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 1.84s
                      Time elapsed: 00:43:44
                               ETA: 00:05:37

################################################################################
                     [1m Learning iteration 1330/1500 [0m                     

                       Computation: 54755 steps/s (collection: 1.678s, learning 0.118s)
             Mean action noise std: 3.23
          Mean value_function loss: 6.8391
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 43.9779
                       Mean reward: 856.00
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.8153
    Episode_Reward/rotating_object: 170.0181
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 1.80s
                      Time elapsed: 00:43:46
                               ETA: 00:05:35

################################################################################
                     [1m Learning iteration 1331/1500 [0m                     

                       Computation: 54666 steps/s (collection: 1.705s, learning 0.093s)
             Mean action noise std: 3.23
          Mean value_function loss: 9.2585
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 43.9753
                       Mean reward: 860.11
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7871
    Episode_Reward/rotating_object: 170.3193
        Episode_Reward/action_rate: -0.0522
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 1.80s
                      Time elapsed: 00:43:47
                               ETA: 00:05:33

################################################################################
                     [1m Learning iteration 1332/1500 [0m                     

                       Computation: 55051 steps/s (collection: 1.683s, learning 0.103s)
             Mean action noise std: 3.23
          Mean value_function loss: 9.2008
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 43.9747
                       Mean reward: 860.06
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7727
    Episode_Reward/rotating_object: 170.1966
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 1.79s
                      Time elapsed: 00:43:49
                               ETA: 00:05:31

################################################################################
                     [1m Learning iteration 1333/1500 [0m                     

                       Computation: 20344 steps/s (collection: 4.698s, learning 0.134s)
             Mean action noise std: 3.23
          Mean value_function loss: 7.9532
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 43.9727
                       Mean reward: 844.86
               Mean episode length: 245.89
    Episode_Reward/reaching_object: 0.7544
    Episode_Reward/rotating_object: 169.3906
        Episode_Reward/action_rate: -0.0522
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 4.83s
                      Time elapsed: 00:43:54
                               ETA: 00:05:29

################################################################################
                     [1m Learning iteration 1334/1500 [0m                     

                       Computation: 14757 steps/s (collection: 6.512s, learning 0.150s)
             Mean action noise std: 3.23
          Mean value_function loss: 13.6049
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 43.9697
                       Mean reward: 845.22
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 0.7424
    Episode_Reward/rotating_object: 170.4060
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 6.66s
                      Time elapsed: 00:44:01
                               ETA: 00:05:28

################################################################################
                     [1m Learning iteration 1335/1500 [0m                     

                       Computation: 14689 steps/s (collection: 6.569s, learning 0.123s)
             Mean action noise std: 3.24
          Mean value_function loss: 7.2644
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.9722
                       Mean reward: 860.55
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7269
    Episode_Reward/rotating_object: 170.2419
        Episode_Reward/action_rate: -0.0522
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 6.69s
                      Time elapsed: 00:44:07
                               ETA: 00:05:27

################################################################################
                     [1m Learning iteration 1336/1500 [0m                     

                       Computation: 14964 steps/s (collection: 6.406s, learning 0.163s)
             Mean action noise std: 3.24
          Mean value_function loss: 7.6936
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 43.9750
                       Mean reward: 856.80
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 0.7060
    Episode_Reward/rotating_object: 170.7443
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 6.57s
                      Time elapsed: 00:44:14
                               ETA: 00:05:25

################################################################################
                     [1m Learning iteration 1337/1500 [0m                     

                       Computation: 14508 steps/s (collection: 6.601s, learning 0.175s)
             Mean action noise std: 3.24
          Mean value_function loss: 10.8099
               Mean surrogate loss: 0.0021
                 Mean entropy loss: 43.9764
                       Mean reward: 853.94
               Mean episode length: 248.37
    Episode_Reward/reaching_object: 0.6948
    Episode_Reward/rotating_object: 170.2757
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 6.78s
                      Time elapsed: 00:44:21
                               ETA: 00:05:24

################################################################################
                     [1m Learning iteration 1338/1500 [0m                     

                       Computation: 14584 steps/s (collection: 6.601s, learning 0.139s)
             Mean action noise std: 3.24
          Mean value_function loss: 5.4387
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.9760
                       Mean reward: 861.94
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6892
    Episode_Reward/rotating_object: 172.0157
        Episode_Reward/action_rate: -0.0529
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 6.74s
                      Time elapsed: 00:44:27
                               ETA: 00:05:22

################################################################################
                     [1m Learning iteration 1339/1500 [0m                     

                       Computation: 14750 steps/s (collection: 6.514s, learning 0.150s)
             Mean action noise std: 3.24
          Mean value_function loss: 9.2190
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.9724
                       Mean reward: 857.93
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 0.6791
    Episode_Reward/rotating_object: 171.5364
        Episode_Reward/action_rate: -0.0528
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 6.66s
                      Time elapsed: 00:44:34
                               ETA: 00:05:21

################################################################################
                     [1m Learning iteration 1340/1500 [0m                     

                       Computation: 14722 steps/s (collection: 6.541s, learning 0.137s)
             Mean action noise std: 3.24
          Mean value_function loss: 7.6560
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 43.9813
                       Mean reward: 863.64
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6689
    Episode_Reward/rotating_object: 170.7757
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 6.68s
                      Time elapsed: 00:44:41
                               ETA: 00:05:19

################################################################################
                     [1m Learning iteration 1341/1500 [0m                     

                       Computation: 13147 steps/s (collection: 7.337s, learning 0.140s)
             Mean action noise std: 3.24
          Mean value_function loss: 8.4269
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 43.9938
                       Mean reward: 862.21
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6679
    Episode_Reward/rotating_object: 170.8477
        Episode_Reward/action_rate: -0.0528
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 7.48s
                      Time elapsed: 00:44:48
                               ETA: 00:05:18

################################################################################
                     [1m Learning iteration 1342/1500 [0m                     

                       Computation: 50905 steps/s (collection: 1.778s, learning 0.153s)
             Mean action noise std: 3.24
          Mean value_function loss: 13.9331
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 44.0011
                       Mean reward: 863.45
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6564
    Episode_Reward/rotating_object: 170.5344
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 1.93s
                      Time elapsed: 00:44:50
                               ETA: 00:05:16

################################################################################
                     [1m Learning iteration 1343/1500 [0m                     

                       Computation: 55548 steps/s (collection: 1.649s, learning 0.121s)
             Mean action noise std: 3.25
          Mean value_function loss: 11.6863
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 44.0113
                       Mean reward: 860.37
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6568
    Episode_Reward/rotating_object: 170.0558
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 1.77s
                      Time elapsed: 00:44:52
                               ETA: 00:05:14

################################################################################
                     [1m Learning iteration 1344/1500 [0m                     

                       Computation: 57387 steps/s (collection: 1.624s, learning 0.089s)
             Mean action noise std: 3.25
          Mean value_function loss: 12.8411
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 44.0296
                       Mean reward: 852.95
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 0.6460
    Episode_Reward/rotating_object: 169.0088
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 1.71s
                      Time elapsed: 00:44:54
                               ETA: 00:05:12

################################################################################
                     [1m Learning iteration 1345/1500 [0m                     

                       Computation: 58663 steps/s (collection: 1.582s, learning 0.094s)
             Mean action noise std: 3.25
          Mean value_function loss: 8.9087
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 44.0427
                       Mean reward: 853.49
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 0.6494
    Episode_Reward/rotating_object: 170.2889
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 1.68s
                      Time elapsed: 00:44:55
                               ETA: 00:05:10

################################################################################
                     [1m Learning iteration 1346/1500 [0m                     

                       Computation: 56357 steps/s (collection: 1.597s, learning 0.147s)
             Mean action noise std: 3.25
          Mean value_function loss: 10.8380
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 44.0503
                       Mean reward: 859.57
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6452
    Episode_Reward/rotating_object: 170.6333
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 1.74s
                      Time elapsed: 00:44:57
                               ETA: 00:05:08

################################################################################
                     [1m Learning iteration 1347/1500 [0m                     

                       Computation: 55701 steps/s (collection: 1.646s, learning 0.119s)
             Mean action noise std: 3.25
          Mean value_function loss: 10.5557
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.0532
                       Mean reward: 863.81
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6413
    Episode_Reward/rotating_object: 171.5966
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 1.76s
                      Time elapsed: 00:44:59
                               ETA: 00:05:06

################################################################################
                     [1m Learning iteration 1348/1500 [0m                     

                       Computation: 58786 steps/s (collection: 1.582s, learning 0.090s)
             Mean action noise std: 3.26
          Mean value_function loss: 9.3972
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 44.0625
                       Mean reward: 864.14
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6405
    Episode_Reward/rotating_object: 170.7880
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 1.67s
                      Time elapsed: 00:45:01
                               ETA: 00:05:04

################################################################################
                     [1m Learning iteration 1349/1500 [0m                     

                       Computation: 57632 steps/s (collection: 1.616s, learning 0.090s)
             Mean action noise std: 3.26
          Mean value_function loss: 8.9448
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 44.0739
                       Mean reward: 843.67
               Mean episode length: 248.34
    Episode_Reward/reaching_object: 0.6405
    Episode_Reward/rotating_object: 170.2376
        Episode_Reward/action_rate: -0.0535
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 1.71s
                      Time elapsed: 00:45:02
                               ETA: 00:05:02

################################################################################
                     [1m Learning iteration 1350/1500 [0m                     

                       Computation: 55866 steps/s (collection: 1.549s, learning 0.211s)
             Mean action noise std: 3.26
          Mean value_function loss: 15.4896
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 44.0806
                       Mean reward: 863.24
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6346
    Episode_Reward/rotating_object: 168.6456
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 1.76s
                      Time elapsed: 00:45:04
                               ETA: 00:05:00

################################################################################
                     [1m Learning iteration 1351/1500 [0m                     

                       Computation: 59338 steps/s (collection: 1.567s, learning 0.090s)
             Mean action noise std: 3.26
          Mean value_function loss: 12.2433
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 44.0908
                       Mean reward: 834.01
               Mean episode length: 246.03
    Episode_Reward/reaching_object: 0.6353
    Episode_Reward/rotating_object: 169.4480
        Episode_Reward/action_rate: -0.0535
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 1.66s
                      Time elapsed: 00:45:06
                               ETA: 00:04:58

################################################################################
                     [1m Learning iteration 1352/1500 [0m                     

                       Computation: 57576 steps/s (collection: 1.617s, learning 0.090s)
             Mean action noise std: 3.27
          Mean value_function loss: 9.0908
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 44.0950
                       Mean reward: 851.94
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6401
    Episode_Reward/rotating_object: 168.8340
        Episode_Reward/action_rate: -0.0535
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 1.71s
                      Time elapsed: 00:45:07
                               ETA: 00:04:56

################################################################################
                     [1m Learning iteration 1353/1500 [0m                     

                       Computation: 55743 steps/s (collection: 1.638s, learning 0.125s)
             Mean action noise std: 3.27
          Mean value_function loss: 6.8261
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 44.0993
                       Mean reward: 853.84
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.6373
    Episode_Reward/rotating_object: 170.7030
        Episode_Reward/action_rate: -0.0538
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 1.76s
                      Time elapsed: 00:45:09
                               ETA: 00:04:54

################################################################################
                     [1m Learning iteration 1354/1500 [0m                     

                       Computation: 58052 steps/s (collection: 1.602s, learning 0.091s)
             Mean action noise std: 3.27
          Mean value_function loss: 11.9032
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 44.0988
                       Mean reward: 848.10
               Mean episode length: 246.58
    Episode_Reward/reaching_object: 0.6392
    Episode_Reward/rotating_object: 170.4924
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 1.69s
                      Time elapsed: 00:45:11
                               ETA: 00:04:52

################################################################################
                     [1m Learning iteration 1355/1500 [0m                     

                       Computation: 58152 steps/s (collection: 1.600s, learning 0.090s)
             Mean action noise std: 3.27
          Mean value_function loss: 11.0312
               Mean surrogate loss: 0.0043
                 Mean entropy loss: 44.1068
                       Mean reward: 854.06
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 0.6385
    Episode_Reward/rotating_object: 169.6451
        Episode_Reward/action_rate: -0.0538
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 1.69s
                      Time elapsed: 00:45:12
                               ETA: 00:04:50

################################################################################
                     [1m Learning iteration 1356/1500 [0m                     

                       Computation: 57770 steps/s (collection: 1.583s, learning 0.119s)
             Mean action noise std: 3.27
          Mean value_function loss: 19.8635
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 44.1113
                       Mean reward: 853.59
               Mean episode length: 248.24
    Episode_Reward/reaching_object: 0.6346
    Episode_Reward/rotating_object: 168.3729
        Episode_Reward/action_rate: -0.0536
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 1.70s
                      Time elapsed: 00:45:14
                               ETA: 00:04:48

################################################################################
                     [1m Learning iteration 1357/1500 [0m                     

                       Computation: 58223 steps/s (collection: 1.597s, learning 0.091s)
             Mean action noise std: 3.27
          Mean value_function loss: 14.8785
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 44.1200
                       Mean reward: 855.69
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 0.6347
    Episode_Reward/rotating_object: 169.6211
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 1.69s
                      Time elapsed: 00:45:16
                               ETA: 00:04:46

################################################################################
                     [1m Learning iteration 1358/1500 [0m                     

                       Computation: 56191 steps/s (collection: 1.623s, learning 0.126s)
             Mean action noise std: 3.27
          Mean value_function loss: 10.5413
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 44.1318
                       Mean reward: 853.30
               Mean episode length: 248.27
    Episode_Reward/reaching_object: 0.6314
    Episode_Reward/rotating_object: 168.5502
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 1.75s
                      Time elapsed: 00:45:18
                               ETA: 00:04:44

################################################################################
                     [1m Learning iteration 1359/1500 [0m                     

                       Computation: 55284 steps/s (collection: 1.683s, learning 0.095s)
             Mean action noise std: 3.28
          Mean value_function loss: 12.6692
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 44.1429
                       Mean reward: 853.16
               Mean episode length: 249.02
    Episode_Reward/reaching_object: 0.6420
    Episode_Reward/rotating_object: 169.2896
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 1.78s
                      Time elapsed: 00:45:19
                               ETA: 00:04:41

################################################################################
                     [1m Learning iteration 1360/1500 [0m                     

                       Computation: 57360 steps/s (collection: 1.607s, learning 0.107s)
             Mean action noise std: 3.28
          Mean value_function loss: 8.4073
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 44.1571
                       Mean reward: 856.95
               Mean episode length: 248.01
    Episode_Reward/reaching_object: 0.6383
    Episode_Reward/rotating_object: 169.2710
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 1.71s
                      Time elapsed: 00:45:21
                               ETA: 00:04:39

################################################################################
                     [1m Learning iteration 1361/1500 [0m                     

                       Computation: 56793 steps/s (collection: 1.624s, learning 0.107s)
             Mean action noise std: 3.28
          Mean value_function loss: 9.2324
               Mean surrogate loss: 0.0168
                 Mean entropy loss: 44.1647
                       Mean reward: 861.13
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6357
    Episode_Reward/rotating_object: 168.7844
        Episode_Reward/action_rate: -0.0536
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 1.73s
                      Time elapsed: 00:45:23
                               ETA: 00:04:37

################################################################################
                     [1m Learning iteration 1362/1500 [0m                     

                       Computation: 57898 steps/s (collection: 1.595s, learning 0.103s)
             Mean action noise std: 3.28
          Mean value_function loss: 9.8475
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 44.1664
                       Mean reward: 863.28
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6463
    Episode_Reward/rotating_object: 171.2300
        Episode_Reward/action_rate: -0.0545
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 1.70s
                      Time elapsed: 00:45:25
                               ETA: 00:04:35

################################################################################
                     [1m Learning iteration 1363/1500 [0m                     

                       Computation: 58043 steps/s (collection: 1.601s, learning 0.093s)
             Mean action noise std: 3.28
          Mean value_function loss: 15.4446
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 44.1706
                       Mean reward: 846.79
               Mean episode length: 245.59
    Episode_Reward/reaching_object: 0.6349
    Episode_Reward/rotating_object: 168.9471
        Episode_Reward/action_rate: -0.0536
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 1.69s
                      Time elapsed: 00:45:26
                               ETA: 00:04:33

################################################################################
                     [1m Learning iteration 1364/1500 [0m                     

                       Computation: 58117 steps/s (collection: 1.572s, learning 0.120s)
             Mean action noise std: 3.29
          Mean value_function loss: 14.4952
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 44.1865
                       Mean reward: 846.57
               Mean episode length: 245.92
    Episode_Reward/reaching_object: 0.6410
    Episode_Reward/rotating_object: 170.6976
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 1.69s
                      Time elapsed: 00:45:28
                               ETA: 00:04:31

################################################################################
                     [1m Learning iteration 1365/1500 [0m                     

                       Computation: 55961 steps/s (collection: 1.652s, learning 0.105s)
             Mean action noise std: 3.29
          Mean value_function loss: 15.2007
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.2074
                       Mean reward: 854.83
               Mean episode length: 248.32
    Episode_Reward/reaching_object: 0.6404
    Episode_Reward/rotating_object: 169.9089
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 1.76s
                      Time elapsed: 00:45:30
                               ETA: 00:04:29

################################################################################
                     [1m Learning iteration 1366/1500 [0m                     

                       Computation: 56800 steps/s (collection: 1.619s, learning 0.112s)
             Mean action noise std: 3.29
          Mean value_function loss: 17.4080
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 44.2238
                       Mean reward: 835.32
               Mean episode length: 243.18
    Episode_Reward/reaching_object: 0.6428
    Episode_Reward/rotating_object: 169.2653
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 1.73s
                      Time elapsed: 00:45:31
                               ETA: 00:04:27

################################################################################
                     [1m Learning iteration 1367/1500 [0m                     

                       Computation: 57457 steps/s (collection: 1.618s, learning 0.093s)
             Mean action noise std: 3.29
          Mean value_function loss: 8.6020
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 44.2359
                       Mean reward: 857.32
               Mean episode length: 248.43
    Episode_Reward/reaching_object: 0.6491
    Episode_Reward/rotating_object: 170.7442
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 1.71s
                      Time elapsed: 00:45:33
                               ETA: 00:04:25

################################################################################
                     [1m Learning iteration 1368/1500 [0m                     

                       Computation: 57339 steps/s (collection: 1.598s, learning 0.117s)
             Mean action noise std: 3.29
          Mean value_function loss: 16.0463
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 44.2437
                       Mean reward: 864.49
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6471
    Episode_Reward/rotating_object: 169.6964
        Episode_Reward/action_rate: -0.0542
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 1.71s
                      Time elapsed: 00:45:35
                               ETA: 00:04:23

################################################################################
                     [1m Learning iteration 1369/1500 [0m                     

                       Computation: 57587 steps/s (collection: 1.611s, learning 0.096s)
             Mean action noise std: 3.30
          Mean value_function loss: 15.1182
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 44.2526
                       Mean reward: 852.95
               Mean episode length: 248.01
    Episode_Reward/reaching_object: 0.6447
    Episode_Reward/rotating_object: 169.0436
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 1.71s
                      Time elapsed: 00:45:37
                               ETA: 00:04:21

################################################################################
                     [1m Learning iteration 1370/1500 [0m                     

                       Computation: 57623 steps/s (collection: 1.600s, learning 0.106s)
             Mean action noise std: 3.30
          Mean value_function loss: 11.0371
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 44.2674
                       Mean reward: 862.16
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6526
    Episode_Reward/rotating_object: 170.1413
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 1.71s
                      Time elapsed: 00:45:38
                               ETA: 00:04:19

################################################################################
                     [1m Learning iteration 1371/1500 [0m                     

                       Computation: 57107 steps/s (collection: 1.605s, learning 0.116s)
             Mean action noise std: 3.30
          Mean value_function loss: 9.7539
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 44.2802
                       Mean reward: 850.31
               Mean episode length: 245.89
    Episode_Reward/reaching_object: 0.6485
    Episode_Reward/rotating_object: 170.0289
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 1.72s
                      Time elapsed: 00:45:40
                               ETA: 00:04:17

################################################################################
                     [1m Learning iteration 1372/1500 [0m                     

                       Computation: 57514 steps/s (collection: 1.610s, learning 0.100s)
             Mean action noise std: 3.30
          Mean value_function loss: 10.5111
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.2925
                       Mean reward: 856.58
               Mean episode length: 248.81
    Episode_Reward/reaching_object: 0.6519
    Episode_Reward/rotating_object: 170.0704
        Episode_Reward/action_rate: -0.0545
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 1.71s
                      Time elapsed: 00:45:42
                               ETA: 00:04:15

################################################################################
                     [1m Learning iteration 1373/1500 [0m                     

                       Computation: 53934 steps/s (collection: 1.641s, learning 0.182s)
             Mean action noise std: 3.31
          Mean value_function loss: 14.6261
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 44.3084
                       Mean reward: 830.66
               Mean episode length: 243.41
    Episode_Reward/reaching_object: 0.6532
    Episode_Reward/rotating_object: 169.3676
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 1.82s
                      Time elapsed: 00:45:44
                               ETA: 00:04:13

################################################################################
                     [1m Learning iteration 1374/1500 [0m                     

                       Computation: 54923 steps/s (collection: 1.638s, learning 0.152s)
             Mean action noise std: 3.31
          Mean value_function loss: 12.0226
               Mean surrogate loss: 0.0218
                 Mean entropy loss: 44.3207
                       Mean reward: 851.87
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 0.6521
    Episode_Reward/rotating_object: 169.7870
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 1.79s
                      Time elapsed: 00:45:45
                               ETA: 00:04:11

################################################################################
                     [1m Learning iteration 1375/1500 [0m                     

                       Computation: 58289 steps/s (collection: 1.592s, learning 0.095s)
             Mean action noise std: 3.31
          Mean value_function loss: 16.4091
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 44.3226
                       Mean reward: 856.39
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 0.6577
    Episode_Reward/rotating_object: 170.2498
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 1.69s
                      Time elapsed: 00:45:47
                               ETA: 00:04:09

################################################################################
                     [1m Learning iteration 1376/1500 [0m                     

                       Computation: 53213 steps/s (collection: 1.700s, learning 0.147s)
             Mean action noise std: 3.31
          Mean value_function loss: 20.2486
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 44.3304
                       Mean reward: 850.81
               Mean episode length: 245.88
    Episode_Reward/reaching_object: 0.6502
    Episode_Reward/rotating_object: 167.7227
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 1.85s
                      Time elapsed: 00:45:49
                               ETA: 00:04:07

################################################################################
                     [1m Learning iteration 1377/1500 [0m                     

                       Computation: 56926 steps/s (collection: 1.623s, learning 0.104s)
             Mean action noise std: 3.32
          Mean value_function loss: 18.9620
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 44.3504
                       Mean reward: 867.64
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6658
    Episode_Reward/rotating_object: 170.0013
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 1.73s
                      Time elapsed: 00:45:51
                               ETA: 00:04:05

################################################################################
                     [1m Learning iteration 1378/1500 [0m                     

                       Computation: 56936 steps/s (collection: 1.611s, learning 0.115s)
             Mean action noise std: 3.32
          Mean value_function loss: 12.1877
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 44.3687
                       Mean reward: 842.05
               Mean episode length: 244.55
    Episode_Reward/reaching_object: 0.6644
    Episode_Reward/rotating_object: 169.8739
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 1.73s
                      Time elapsed: 00:45:52
                               ETA: 00:04:03

################################################################################
                     [1m Learning iteration 1379/1500 [0m                     

                       Computation: 58055 steps/s (collection: 1.602s, learning 0.091s)
             Mean action noise std: 3.32
          Mean value_function loss: 11.1895
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 44.3836
                       Mean reward: 847.68
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.6721
    Episode_Reward/rotating_object: 170.0954
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 1.69s
                      Time elapsed: 00:45:54
                               ETA: 00:04:01

################################################################################
                     [1m Learning iteration 1380/1500 [0m                     

                       Computation: 57055 steps/s (collection: 1.627s, learning 0.096s)
             Mean action noise std: 3.32
          Mean value_function loss: 15.0564
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 44.3954
                       Mean reward: 857.11
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.6808
    Episode_Reward/rotating_object: 170.6784
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 1.72s
                      Time elapsed: 00:45:56
                               ETA: 00:03:59

################################################################################
                     [1m Learning iteration 1381/1500 [0m                     

                       Computation: 57874 steps/s (collection: 1.612s, learning 0.087s)
             Mean action noise std: 3.32
          Mean value_function loss: 17.3232
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 44.4062
                       Mean reward: 860.91
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.6797
    Episode_Reward/rotating_object: 170.5579
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 1.70s
                      Time elapsed: 00:45:57
                               ETA: 00:03:57

################################################################################
                     [1m Learning iteration 1382/1500 [0m                     

                       Computation: 57164 steps/s (collection: 1.624s, learning 0.096s)
             Mean action noise std: 3.33
          Mean value_function loss: 13.8202
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 44.4142
                       Mean reward: 854.82
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 0.6707
    Episode_Reward/rotating_object: 167.4954
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 1.72s
                      Time elapsed: 00:45:59
                               ETA: 00:03:55

################################################################################
                     [1m Learning iteration 1383/1500 [0m                     

                       Computation: 57083 steps/s (collection: 1.626s, learning 0.097s)
             Mean action noise std: 3.33
          Mean value_function loss: 12.7405
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 44.4235
                       Mean reward: 852.31
               Mean episode length: 245.50
    Episode_Reward/reaching_object: 0.6930
    Episode_Reward/rotating_object: 170.3816
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 1.72s
                      Time elapsed: 00:46:01
                               ETA: 00:03:53

################################################################################
                     [1m Learning iteration 1384/1500 [0m                     

                       Computation: 57355 steps/s (collection: 1.622s, learning 0.092s)
             Mean action noise std: 3.33
          Mean value_function loss: 14.5440
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 44.4353
                       Mean reward: 847.65
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.6972
    Episode_Reward/rotating_object: 170.3477
        Episode_Reward/action_rate: -0.0551
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 1.71s
                      Time elapsed: 00:46:03
                               ETA: 00:03:51

################################################################################
                     [1m Learning iteration 1385/1500 [0m                     

                       Computation: 57425 steps/s (collection: 1.617s, learning 0.095s)
             Mean action noise std: 3.33
          Mean value_function loss: 18.0677
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 44.4458
                       Mean reward: 842.42
               Mean episode length: 243.44
    Episode_Reward/reaching_object: 0.6919
    Episode_Reward/rotating_object: 169.1412
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 1.71s
                      Time elapsed: 00:46:04
                               ETA: 00:03:49

################################################################################
                     [1m Learning iteration 1386/1500 [0m                     

                       Computation: 56320 steps/s (collection: 1.657s, learning 0.088s)
             Mean action noise std: 3.34
          Mean value_function loss: 14.2276
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 44.4638
                       Mean reward: 840.99
               Mean episode length: 247.57
    Episode_Reward/reaching_object: 0.6975
    Episode_Reward/rotating_object: 169.1669
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 1.75s
                      Time elapsed: 00:46:06
                               ETA: 00:03:47

################################################################################
                     [1m Learning iteration 1387/1500 [0m                     

                       Computation: 56934 steps/s (collection: 1.630s, learning 0.097s)
             Mean action noise std: 3.34
          Mean value_function loss: 7.2510
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 44.4751
                       Mean reward: 866.38
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7056
    Episode_Reward/rotating_object: 171.6037
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 1.73s
                      Time elapsed: 00:46:08
                               ETA: 00:03:45

################################################################################
                     [1m Learning iteration 1388/1500 [0m                     

                       Computation: 54000 steps/s (collection: 1.684s, learning 0.136s)
             Mean action noise std: 3.34
          Mean value_function loss: 16.4332
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 44.4771
                       Mean reward: 863.24
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7070
    Episode_Reward/rotating_object: 171.0320
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 1.82s
                      Time elapsed: 00:46:10
                               ETA: 00:03:43

################################################################################
                     [1m Learning iteration 1389/1500 [0m                     

                       Computation: 56354 steps/s (collection: 1.629s, learning 0.116s)
             Mean action noise std: 3.34
          Mean value_function loss: 12.8310
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 44.4864
                       Mean reward: 838.95
               Mean episode length: 245.02
    Episode_Reward/reaching_object: 0.7036
    Episode_Reward/rotating_object: 169.6430
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 1.74s
                      Time elapsed: 00:46:11
                               ETA: 00:03:41

################################################################################
                     [1m Learning iteration 1390/1500 [0m                     

                       Computation: 55926 steps/s (collection: 1.655s, learning 0.102s)
             Mean action noise std: 3.34
          Mean value_function loss: 9.4507
               Mean surrogate loss: 0.0035
                 Mean entropy loss: 44.4952
                       Mean reward: 866.72
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7065
    Episode_Reward/rotating_object: 169.9880
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 1.76s
                      Time elapsed: 00:46:13
                               ETA: 00:03:39

################################################################################
                     [1m Learning iteration 1391/1500 [0m                     

                       Computation: 54780 steps/s (collection: 1.696s, learning 0.099s)
             Mean action noise std: 3.34
          Mean value_function loss: 10.0088
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 44.4975
                       Mean reward: 871.31
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7173
    Episode_Reward/rotating_object: 173.1142
        Episode_Reward/action_rate: -0.0561
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 1.79s
                      Time elapsed: 00:46:15
                               ETA: 00:03:37

################################################################################
                     [1m Learning iteration 1392/1500 [0m                     

                       Computation: 56826 steps/s (collection: 1.642s, learning 0.088s)
             Mean action noise std: 3.35
          Mean value_function loss: 14.6906
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 44.5033
                       Mean reward: 842.71
               Mean episode length: 246.32
    Episode_Reward/reaching_object: 0.7097
    Episode_Reward/rotating_object: 170.1674
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 1.73s
                      Time elapsed: 00:46:17
                               ETA: 00:03:35

################################################################################
                     [1m Learning iteration 1393/1500 [0m                     

                       Computation: 56982 steps/s (collection: 1.613s, learning 0.113s)
             Mean action noise std: 3.35
          Mean value_function loss: 10.0307
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 44.5181
                       Mean reward: 854.09
               Mean episode length: 248.42
    Episode_Reward/reaching_object: 0.7157
    Episode_Reward/rotating_object: 171.0657
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 1.73s
                      Time elapsed: 00:46:18
                               ETA: 00:03:33

################################################################################
                     [1m Learning iteration 1394/1500 [0m                     

                       Computation: 57069 steps/s (collection: 1.625s, learning 0.097s)
             Mean action noise std: 3.35
          Mean value_function loss: 10.4912
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 44.5288
                       Mean reward: 858.39
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7149
    Episode_Reward/rotating_object: 171.1161
        Episode_Reward/action_rate: -0.0560
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 1.72s
                      Time elapsed: 00:46:20
                               ETA: 00:03:31

################################################################################
                     [1m Learning iteration 1395/1500 [0m                     

                       Computation: 56620 steps/s (collection: 1.641s, learning 0.096s)
             Mean action noise std: 3.35
          Mean value_function loss: 10.5093
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 44.5413
                       Mean reward: 850.13
               Mean episode length: 245.87
    Episode_Reward/reaching_object: 0.7126
    Episode_Reward/rotating_object: 169.9751
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 1.74s
                      Time elapsed: 00:46:22
                               ETA: 00:03:29

################################################################################
                     [1m Learning iteration 1396/1500 [0m                     

                       Computation: 54699 steps/s (collection: 1.696s, learning 0.102s)
             Mean action noise std: 3.36
          Mean value_function loss: 14.4404
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 44.5571
                       Mean reward: 868.26
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7211
    Episode_Reward/rotating_object: 171.3295
        Episode_Reward/action_rate: -0.0563
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 1.80s
                      Time elapsed: 00:46:24
                               ETA: 00:03:27

################################################################################
                     [1m Learning iteration 1397/1500 [0m                     

                       Computation: 55271 steps/s (collection: 1.688s, learning 0.091s)
             Mean action noise std: 3.36
          Mean value_function loss: 23.4860
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 44.5715
                       Mean reward: 858.85
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 0.7122
    Episode_Reward/rotating_object: 169.1795
        Episode_Reward/action_rate: -0.0556
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 1.78s
                      Time elapsed: 00:46:25
                               ETA: 00:03:25

################################################################################
                     [1m Learning iteration 1398/1500 [0m                     

                       Computation: 56648 steps/s (collection: 1.626s, learning 0.110s)
             Mean action noise std: 3.36
          Mean value_function loss: 15.6706
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 44.5914
                       Mean reward: 858.24
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 0.7108
    Episode_Reward/rotating_object: 169.3751
        Episode_Reward/action_rate: -0.0558
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 1.74s
                      Time elapsed: 00:46:27
                               ETA: 00:03:23

################################################################################
                     [1m Learning iteration 1399/1500 [0m                     

                       Computation: 54788 steps/s (collection: 1.698s, learning 0.096s)
             Mean action noise std: 3.36
          Mean value_function loss: 18.2832
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 44.6028
                       Mean reward: 839.73
               Mean episode length: 243.86
    Episode_Reward/reaching_object: 0.7107
    Episode_Reward/rotating_object: 169.1733
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 1.79s
                      Time elapsed: 00:46:29
                               ETA: 00:03:21

################################################################################
                     [1m Learning iteration 1400/1500 [0m                     

                       Computation: 55714 steps/s (collection: 1.666s, learning 0.099s)
             Mean action noise std: 3.37
          Mean value_function loss: 13.4106
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 44.6122
                       Mean reward: 865.32
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7197
    Episode_Reward/rotating_object: 170.7070
        Episode_Reward/action_rate: -0.0561
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 1.76s
                      Time elapsed: 00:46:31
                               ETA: 00:03:19

################################################################################
                     [1m Learning iteration 1401/1500 [0m                     

                       Computation: 56663 steps/s (collection: 1.636s, learning 0.099s)
             Mean action noise std: 3.37
          Mean value_function loss: 13.2882
               Mean surrogate loss: 0.0017
                 Mean entropy loss: 44.6243
                       Mean reward: 851.48
               Mean episode length: 245.78
    Episode_Reward/reaching_object: 0.7197
    Episode_Reward/rotating_object: 170.4858
        Episode_Reward/action_rate: -0.0563
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 1.73s
                      Time elapsed: 00:46:32
                               ETA: 00:03:17

################################################################################
                     [1m Learning iteration 1402/1500 [0m                     

                       Computation: 56976 steps/s (collection: 1.619s, learning 0.106s)
             Mean action noise std: 3.37
          Mean value_function loss: 19.8897
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 44.6297
                       Mean reward: 844.53
               Mean episode length: 243.37
    Episode_Reward/reaching_object: 0.7111
    Episode_Reward/rotating_object: 168.6834
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 1.73s
                      Time elapsed: 00:46:34
                               ETA: 00:03:15

################################################################################
                     [1m Learning iteration 1403/1500 [0m                     

                       Computation: 56295 steps/s (collection: 1.654s, learning 0.092s)
             Mean action noise std: 3.37
          Mean value_function loss: 13.6412
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 44.6437
                       Mean reward: 855.99
               Mean episode length: 248.78
    Episode_Reward/reaching_object: 0.7141
    Episode_Reward/rotating_object: 168.6756
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 1.75s
                      Time elapsed: 00:46:36
                               ETA: 00:03:13

################################################################################
                     [1m Learning iteration 1404/1500 [0m                     

                       Computation: 56184 steps/s (collection: 1.652s, learning 0.098s)
             Mean action noise std: 3.37
          Mean value_function loss: 9.1219
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 44.6585
                       Mean reward: 867.62
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7276
    Episode_Reward/rotating_object: 171.4876
        Episode_Reward/action_rate: -0.0567
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 1.75s
                      Time elapsed: 00:46:38
                               ETA: 00:03:11

################################################################################
                     [1m Learning iteration 1405/1500 [0m                     

                       Computation: 55960 steps/s (collection: 1.617s, learning 0.140s)
             Mean action noise std: 3.38
          Mean value_function loss: 6.1279
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 44.6651
                       Mean reward: 868.33
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7301
    Episode_Reward/rotating_object: 171.3622
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 1.76s
                      Time elapsed: 00:46:39
                               ETA: 00:03:09

################################################################################
                     [1m Learning iteration 1406/1500 [0m                     

                       Computation: 56859 steps/s (collection: 1.641s, learning 0.088s)
             Mean action noise std: 3.38
          Mean value_function loss: 12.8195
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 44.6709
                       Mean reward: 840.98
               Mean episode length: 243.25
    Episode_Reward/reaching_object: 0.7254
    Episode_Reward/rotating_object: 169.6238
        Episode_Reward/action_rate: -0.0565
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 1.73s
                      Time elapsed: 00:46:41
                               ETA: 00:03:07

################################################################################
                     [1m Learning iteration 1407/1500 [0m                     

                       Computation: 56290 steps/s (collection: 1.628s, learning 0.118s)
             Mean action noise std: 3.38
          Mean value_function loss: 9.0065
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.6792
                       Mean reward: 865.73
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7327
    Episode_Reward/rotating_object: 170.8606
        Episode_Reward/action_rate: -0.0572
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 1.75s
                      Time elapsed: 00:46:43
                               ETA: 00:03:05

################################################################################
                     [1m Learning iteration 1408/1500 [0m                     

                       Computation: 56606 steps/s (collection: 1.624s, learning 0.113s)
             Mean action noise std: 3.38
          Mean value_function loss: 20.3780
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 44.6914
                       Mean reward: 868.97
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7286
    Episode_Reward/rotating_object: 170.0589
        Episode_Reward/action_rate: -0.0566
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 1.74s
                      Time elapsed: 00:46:45
                               ETA: 00:03:03

################################################################################
                     [1m Learning iteration 1409/1500 [0m                     

                       Computation: 56300 steps/s (collection: 1.620s, learning 0.126s)
             Mean action noise std: 3.39
          Mean value_function loss: 13.7410
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 44.7123
                       Mean reward: 846.02
               Mean episode length: 248.15
    Episode_Reward/reaching_object: 0.7265
    Episode_Reward/rotating_object: 169.6066
        Episode_Reward/action_rate: -0.0564
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 1.75s
                      Time elapsed: 00:46:46
                               ETA: 00:03:01

################################################################################
                     [1m Learning iteration 1410/1500 [0m                     

                       Computation: 56238 steps/s (collection: 1.652s, learning 0.096s)
             Mean action noise std: 3.39
          Mean value_function loss: 17.6250
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 44.7311
                       Mean reward: 848.06
               Mean episode length: 246.33
    Episode_Reward/reaching_object: 0.7344
    Episode_Reward/rotating_object: 171.3858
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 1.75s
                      Time elapsed: 00:46:48
                               ETA: 00:02:59

################################################################################
                     [1m Learning iteration 1411/1500 [0m                     

                       Computation: 50944 steps/s (collection: 1.783s, learning 0.147s)
             Mean action noise std: 3.39
          Mean value_function loss: 18.3148
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 44.7507
                       Mean reward: 844.34
               Mean episode length: 243.21
    Episode_Reward/reaching_object: 0.7293
    Episode_Reward/rotating_object: 169.5932
        Episode_Reward/action_rate: -0.0567
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 1.93s
                      Time elapsed: 00:46:50
                               ETA: 00:02:57

################################################################################
                     [1m Learning iteration 1412/1500 [0m                     

                       Computation: 56276 steps/s (collection: 1.640s, learning 0.107s)
             Mean action noise std: 3.39
          Mean value_function loss: 22.8954
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 44.7620
                       Mean reward: 815.21
               Mean episode length: 236.48
    Episode_Reward/reaching_object: 0.7301
    Episode_Reward/rotating_object: 168.7289
        Episode_Reward/action_rate: -0.0564
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 1.75s
                      Time elapsed: 00:46:52
                               ETA: 00:02:55

################################################################################
                     [1m Learning iteration 1413/1500 [0m                     

                       Computation: 56414 steps/s (collection: 1.645s, learning 0.098s)
             Mean action noise std: 3.39
          Mean value_function loss: 7.1013
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 44.7737
                       Mean reward: 859.69
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.7459
    Episode_Reward/rotating_object: 170.9973
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 1.74s
                      Time elapsed: 00:46:53
                               ETA: 00:02:53

################################################################################
                     [1m Learning iteration 1414/1500 [0m                     

                       Computation: 56982 steps/s (collection: 1.635s, learning 0.090s)
             Mean action noise std: 3.40
          Mean value_function loss: 12.6432
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 44.7824
                       Mean reward: 849.46
               Mean episode length: 245.43
    Episode_Reward/reaching_object: 0.7392
    Episode_Reward/rotating_object: 170.9362
        Episode_Reward/action_rate: -0.0573
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 1.73s
                      Time elapsed: 00:46:55
                               ETA: 00:02:51

################################################################################
                     [1m Learning iteration 1415/1500 [0m                     

                       Computation: 56250 steps/s (collection: 1.630s, learning 0.118s)
             Mean action noise std: 3.40
          Mean value_function loss: 10.5414
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 44.7939
                       Mean reward: 848.31
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 0.7388
    Episode_Reward/rotating_object: 169.8741
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 1.75s
                      Time elapsed: 00:46:57
                               ETA: 00:02:49

################################################################################
                     [1m Learning iteration 1416/1500 [0m                     

                       Computation: 53596 steps/s (collection: 1.711s, learning 0.124s)
             Mean action noise std: 3.40
          Mean value_function loss: 12.7116
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.8025
                       Mean reward: 850.60
               Mean episode length: 247.09
    Episode_Reward/reaching_object: 0.7353
    Episode_Reward/rotating_object: 169.5854
        Episode_Reward/action_rate: -0.0572
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 1.83s
                      Time elapsed: 00:46:59
                               ETA: 00:02:47

################################################################################
                     [1m Learning iteration 1417/1500 [0m                     

                       Computation: 57065 steps/s (collection: 1.634s, learning 0.089s)
             Mean action noise std: 3.40
          Mean value_function loss: 14.0198
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 44.8146
                       Mean reward: 846.08
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.7401
    Episode_Reward/rotating_object: 170.1166
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 1.72s
                      Time elapsed: 00:47:01
                               ETA: 00:02:45

################################################################################
                     [1m Learning iteration 1418/1500 [0m                     

                       Computation: 55934 steps/s (collection: 1.644s, learning 0.113s)
             Mean action noise std: 3.40
          Mean value_function loss: 8.9611
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 44.8260
                       Mean reward: 864.69
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7436
    Episode_Reward/rotating_object: 170.9309
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 1.76s
                      Time elapsed: 00:47:02
                               ETA: 00:02:43

################################################################################
                     [1m Learning iteration 1419/1500 [0m                     

                       Computation: 56916 steps/s (collection: 1.637s, learning 0.090s)
             Mean action noise std: 3.41
          Mean value_function loss: 12.9494
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 44.8327
                       Mean reward: 866.45
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7482
    Episode_Reward/rotating_object: 172.8019
        Episode_Reward/action_rate: -0.0581
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 1.73s
                      Time elapsed: 00:47:04
                               ETA: 00:02:41

################################################################################
                     [1m Learning iteration 1420/1500 [0m                     

                       Computation: 57048 steps/s (collection: 1.632s, learning 0.092s)
             Mean action noise std: 3.41
          Mean value_function loss: 7.2953
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 44.8438
                       Mean reward: 859.03
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 0.7400
    Episode_Reward/rotating_object: 169.9301
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 1.72s
                      Time elapsed: 00:47:06
                               ETA: 00:02:39

################################################################################
                     [1m Learning iteration 1421/1500 [0m                     

                       Computation: 56721 steps/s (collection: 1.637s, learning 0.096s)
             Mean action noise std: 3.41
          Mean value_function loss: 22.5998
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 44.8498
                       Mean reward: 833.66
               Mean episode length: 243.10
    Episode_Reward/reaching_object: 0.7320
    Episode_Reward/rotating_object: 167.6860
        Episode_Reward/action_rate: -0.0574
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 1.73s
                      Time elapsed: 00:47:07
                               ETA: 00:02:37

################################################################################
                     [1m Learning iteration 1422/1500 [0m                     

                       Computation: 55578 steps/s (collection: 1.674s, learning 0.094s)
             Mean action noise std: 3.41
          Mean value_function loss: 19.3125
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 44.8578
                       Mean reward: 834.44
               Mean episode length: 243.68
    Episode_Reward/reaching_object: 0.7308
    Episode_Reward/rotating_object: 167.6319
        Episode_Reward/action_rate: -0.0574
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 1.77s
                      Time elapsed: 00:47:09
                               ETA: 00:02:35

################################################################################
                     [1m Learning iteration 1423/1500 [0m                     

                       Computation: 56305 steps/s (collection: 1.651s, learning 0.095s)
             Mean action noise std: 3.41
          Mean value_function loss: 13.0158
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 44.8716
                       Mean reward: 850.48
               Mean episode length: 245.63
    Episode_Reward/reaching_object: 0.7393
    Episode_Reward/rotating_object: 169.9019
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 1.75s
                      Time elapsed: 00:47:11
                               ETA: 00:02:33

################################################################################
                     [1m Learning iteration 1424/1500 [0m                     

                       Computation: 56292 steps/s (collection: 1.651s, learning 0.096s)
             Mean action noise std: 3.42
          Mean value_function loss: 20.2508
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 44.8866
                       Mean reward: 849.12
               Mean episode length: 245.45
    Episode_Reward/reaching_object: 0.7367
    Episode_Reward/rotating_object: 169.2874
        Episode_Reward/action_rate: -0.0579
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 1.75s
                      Time elapsed: 00:47:13
                               ETA: 00:02:31

################################################################################
                     [1m Learning iteration 1425/1500 [0m                     

                       Computation: 55831 steps/s (collection: 1.633s, learning 0.128s)
             Mean action noise std: 3.42
          Mean value_function loss: 11.6231
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 44.9043
                       Mean reward: 842.26
               Mean episode length: 244.35
    Episode_Reward/reaching_object: 0.7386
    Episode_Reward/rotating_object: 169.8370
        Episode_Reward/action_rate: -0.0580
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 1.76s
                      Time elapsed: 00:47:14
                               ETA: 00:02:29

################################################################################
                     [1m Learning iteration 1426/1500 [0m                     

                       Computation: 56399 steps/s (collection: 1.652s, learning 0.091s)
             Mean action noise std: 3.42
          Mean value_function loss: 13.4895
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 44.9111
                       Mean reward: 861.28
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 0.7355
    Episode_Reward/rotating_object: 170.6729
        Episode_Reward/action_rate: -0.0585
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 1.74s
                      Time elapsed: 00:47:16
                               ETA: 00:02:27

################################################################################
                     [1m Learning iteration 1427/1500 [0m                     

                       Computation: 57480 steps/s (collection: 1.619s, learning 0.091s)
             Mean action noise std: 3.42
          Mean value_function loss: 11.6776
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 44.9121
                       Mean reward: 857.90
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 0.7363
    Episode_Reward/rotating_object: 170.1440
        Episode_Reward/action_rate: -0.0581
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 1.71s
                      Time elapsed: 00:47:18
                               ETA: 00:02:25

################################################################################
                     [1m Learning iteration 1428/1500 [0m                     

                       Computation: 55127 steps/s (collection: 1.626s, learning 0.157s)
             Mean action noise std: 3.42
          Mean value_function loss: 18.7500
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 44.9144
                       Mean reward: 851.43
               Mean episode length: 245.52
    Episode_Reward/reaching_object: 0.7334
    Episode_Reward/rotating_object: 169.2323
        Episode_Reward/action_rate: -0.0582
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 1.78s
                      Time elapsed: 00:47:20
                               ETA: 00:02:23

################################################################################
                     [1m Learning iteration 1429/1500 [0m                     

                       Computation: 54912 steps/s (collection: 1.693s, learning 0.097s)
             Mean action noise std: 3.42
          Mean value_function loss: 13.2101
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 44.9225
                       Mean reward: 867.99
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7345
    Episode_Reward/rotating_object: 170.2159
        Episode_Reward/action_rate: -0.0585
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 1.79s
                      Time elapsed: 00:47:22
                               ETA: 00:02:21

################################################################################
                     [1m Learning iteration 1430/1500 [0m                     

                       Computation: 54991 steps/s (collection: 1.689s, learning 0.099s)
             Mean action noise std: 3.43
          Mean value_function loss: 14.1347
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 44.9386
                       Mean reward: 855.87
               Mean episode length: 247.97
    Episode_Reward/reaching_object: 0.7391
    Episode_Reward/rotating_object: 170.1627
        Episode_Reward/action_rate: -0.0586
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 1.79s
                      Time elapsed: 00:47:23
                               ETA: 00:02:19

################################################################################
                     [1m Learning iteration 1431/1500 [0m                     

                       Computation: 53768 steps/s (collection: 1.684s, learning 0.145s)
             Mean action noise std: 3.43
          Mean value_function loss: 18.2079
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 44.9498
                       Mean reward: 859.77
               Mean episode length: 248.08
    Episode_Reward/reaching_object: 0.7380
    Episode_Reward/rotating_object: 169.9291
        Episode_Reward/action_rate: -0.0588
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 1.83s
                      Time elapsed: 00:47:25
                               ETA: 00:02:17

################################################################################
                     [1m Learning iteration 1432/1500 [0m                     

                       Computation: 54661 steps/s (collection: 1.709s, learning 0.090s)
             Mean action noise std: 3.43
          Mean value_function loss: 17.7771
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 44.9563
                       Mean reward: 860.31
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7269
    Episode_Reward/rotating_object: 168.4193
        Episode_Reward/action_rate: -0.0580
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 1.80s
                      Time elapsed: 00:47:27
                               ETA: 00:02:15

################################################################################
                     [1m Learning iteration 1433/1500 [0m                     

                       Computation: 55577 steps/s (collection: 1.651s, learning 0.118s)
             Mean action noise std: 3.43
          Mean value_function loss: 14.5638
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 44.9725
                       Mean reward: 857.88
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 0.7224
    Episode_Reward/rotating_object: 168.0397
        Episode_Reward/action_rate: -0.0582
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 1.77s
                      Time elapsed: 00:47:29
                               ETA: 00:02:13

################################################################################
                     [1m Learning iteration 1434/1500 [0m                     

                       Computation: 56628 steps/s (collection: 1.635s, learning 0.101s)
             Mean action noise std: 3.43
          Mean value_function loss: 15.2204
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 44.9792
                       Mean reward: 852.04
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7363
    Episode_Reward/rotating_object: 169.9674
        Episode_Reward/action_rate: -0.0588
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 1.74s
                      Time elapsed: 00:47:30
                               ETA: 00:02:11

################################################################################
                     [1m Learning iteration 1435/1500 [0m                     

                       Computation: 57227 steps/s (collection: 1.623s, learning 0.095s)
             Mean action noise std: 3.43
          Mean value_function loss: 12.6884
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 44.9815
                       Mean reward: 848.76
               Mean episode length: 246.77
    Episode_Reward/reaching_object: 0.7326
    Episode_Reward/rotating_object: 170.5166
        Episode_Reward/action_rate: -0.0591
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 1.72s
                      Time elapsed: 00:47:32
                               ETA: 00:02:09

################################################################################
                     [1m Learning iteration 1436/1500 [0m                     

                       Computation: 56342 steps/s (collection: 1.646s, learning 0.099s)
             Mean action noise std: 3.44
          Mean value_function loss: 16.3229
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 44.9869
                       Mean reward: 860.93
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7366
    Episode_Reward/rotating_object: 171.3721
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 1.74s
                      Time elapsed: 00:47:34
                               ETA: 00:02:07

################################################################################
                     [1m Learning iteration 1437/1500 [0m                     

                       Computation: 56001 steps/s (collection: 1.625s, learning 0.131s)
             Mean action noise std: 3.44
          Mean value_function loss: 7.0226
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 44.9966
                       Mean reward: 868.19
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7331
    Episode_Reward/rotating_object: 170.9126
        Episode_Reward/action_rate: -0.0593
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 1.76s
                      Time elapsed: 00:47:36
                               ETA: 00:02:05

################################################################################
                     [1m Learning iteration 1438/1500 [0m                     

                       Computation: 56741 steps/s (collection: 1.632s, learning 0.101s)
             Mean action noise std: 3.44
          Mean value_function loss: 18.0549
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.0048
                       Mean reward: 868.09
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7292
    Episode_Reward/rotating_object: 171.1223
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 1.73s
                      Time elapsed: 00:47:37
                               ETA: 00:02:03

################################################################################
                     [1m Learning iteration 1439/1500 [0m                     

                       Computation: 56814 steps/s (collection: 1.640s, learning 0.091s)
             Mean action noise std: 3.44
          Mean value_function loss: 18.7367
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 45.0168
                       Mean reward: 841.92
               Mean episode length: 247.03
    Episode_Reward/reaching_object: 0.7244
    Episode_Reward/rotating_object: 169.5859
        Episode_Reward/action_rate: -0.0592
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 1.73s
                      Time elapsed: 00:47:39
                               ETA: 00:02:01

################################################################################
                     [1m Learning iteration 1440/1500 [0m                     

                       Computation: 56788 steps/s (collection: 1.641s, learning 0.091s)
             Mean action noise std: 3.44
          Mean value_function loss: 15.0509
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 45.0272
                       Mean reward: 854.68
               Mean episode length: 247.67
    Episode_Reward/reaching_object: 0.7276
    Episode_Reward/rotating_object: 169.8399
        Episode_Reward/action_rate: -0.0593
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 1.73s
                      Time elapsed: 00:47:41
                               ETA: 00:01:59

################################################################################
                     [1m Learning iteration 1441/1500 [0m                     

                       Computation: 57048 steps/s (collection: 1.611s, learning 0.112s)
             Mean action noise std: 3.44
          Mean value_function loss: 16.9911
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 45.0375
                       Mean reward: 856.72
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 0.7272
    Episode_Reward/rotating_object: 169.1136
        Episode_Reward/action_rate: -0.0593
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 1.72s
                      Time elapsed: 00:47:43
                               ETA: 00:01:57

################################################################################
                     [1m Learning iteration 1442/1500 [0m                     

                       Computation: 56504 steps/s (collection: 1.650s, learning 0.090s)
             Mean action noise std: 3.45
          Mean value_function loss: 17.5632
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 45.0485
                       Mean reward: 868.37
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7352
    Episode_Reward/rotating_object: 170.8467
        Episode_Reward/action_rate: -0.0595
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 1.74s
                      Time elapsed: 00:47:44
                               ETA: 00:01:55

################################################################################
                     [1m Learning iteration 1443/1500 [0m                     

                       Computation: 55437 steps/s (collection: 1.682s, learning 0.092s)
             Mean action noise std: 3.45
          Mean value_function loss: 17.0815
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 45.0609
                       Mean reward: 859.74
               Mean episode length: 248.01
    Episode_Reward/reaching_object: 0.7329
    Episode_Reward/rotating_object: 170.2655
        Episode_Reward/action_rate: -0.0595
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 1.77s
                      Time elapsed: 00:47:46
                               ETA: 00:01:53

################################################################################
                     [1m Learning iteration 1444/1500 [0m                     

                       Computation: 56666 steps/s (collection: 1.630s, learning 0.105s)
             Mean action noise std: 3.45
          Mean value_function loss: 17.6971
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 45.0783
                       Mean reward: 855.65
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.7336
    Episode_Reward/rotating_object: 168.9617
        Episode_Reward/action_rate: -0.0588
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 1.73s
                      Time elapsed: 00:47:48
                               ETA: 00:01:51

################################################################################
                     [1m Learning iteration 1445/1500 [0m                     

                       Computation: 51719 steps/s (collection: 1.722s, learning 0.178s)
             Mean action noise std: 3.45
          Mean value_function loss: 11.9346
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 45.0900
                       Mean reward: 837.84
               Mean episode length: 245.68
    Episode_Reward/reaching_object: 0.7408
    Episode_Reward/rotating_object: 168.8026
        Episode_Reward/action_rate: -0.0592
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 1.90s
                      Time elapsed: 00:47:50
                               ETA: 00:01:49

################################################################################
                     [1m Learning iteration 1446/1500 [0m                     

                       Computation: 51818 steps/s (collection: 1.753s, learning 0.144s)
             Mean action noise std: 3.45
          Mean value_function loss: 23.8725
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 45.0919
                       Mean reward: 850.36
               Mean episode length: 245.98
    Episode_Reward/reaching_object: 0.7303
    Episode_Reward/rotating_object: 168.7481
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 1.90s
                      Time elapsed: 00:47:52
                               ETA: 00:01:47

################################################################################
                     [1m Learning iteration 1447/1500 [0m                     

                       Computation: 56474 steps/s (collection: 1.647s, learning 0.094s)
             Mean action noise std: 3.46
          Mean value_function loss: 11.3313
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 45.1041
                       Mean reward: 865.05
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7395
    Episode_Reward/rotating_object: 169.9050
        Episode_Reward/action_rate: -0.0593
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 1.74s
                      Time elapsed: 00:47:53
                               ETA: 00:01:45

################################################################################
                     [1m Learning iteration 1448/1500 [0m                     

                       Computation: 56164 steps/s (collection: 1.646s, learning 0.104s)
             Mean action noise std: 3.46
          Mean value_function loss: 24.9114
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 45.1161
                       Mean reward: 851.39
               Mean episode length: 245.50
    Episode_Reward/reaching_object: 0.7290
    Episode_Reward/rotating_object: 167.0951
        Episode_Reward/action_rate: -0.0588
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 1.75s
                      Time elapsed: 00:47:55
                               ETA: 00:01:43

################################################################################
                     [1m Learning iteration 1449/1500 [0m                     

                       Computation: 56292 steps/s (collection: 1.641s, learning 0.106s)
             Mean action noise std: 3.46
          Mean value_function loss: 19.1437
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 45.1296
                       Mean reward: 838.11
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 0.7324
    Episode_Reward/rotating_object: 168.0246
        Episode_Reward/action_rate: -0.0596
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 1.75s
                      Time elapsed: 00:47:57
                               ETA: 00:01:41

################################################################################
                     [1m Learning iteration 1450/1500 [0m                     

                       Computation: 55202 steps/s (collection: 1.682s, learning 0.098s)
             Mean action noise std: 3.47
          Mean value_function loss: 14.9788
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 45.1445
                       Mean reward: 859.62
               Mean episode length: 248.14
    Episode_Reward/reaching_object: 0.7390
    Episode_Reward/rotating_object: 169.0276
        Episode_Reward/action_rate: -0.0598
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 1.78s
                      Time elapsed: 00:47:59
                               ETA: 00:01:39

################################################################################
                     [1m Learning iteration 1451/1500 [0m                     

                       Computation: 56335 steps/s (collection: 1.633s, learning 0.112s)
             Mean action noise std: 3.47
          Mean value_function loss: 15.4627
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 45.1540
                       Mean reward: 848.14
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 0.7406
    Episode_Reward/rotating_object: 170.4538
        Episode_Reward/action_rate: -0.0601
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 1.74s
                      Time elapsed: 00:48:00
                               ETA: 00:01:37

################################################################################
                     [1m Learning iteration 1452/1500 [0m                     

                       Computation: 56373 steps/s (collection: 1.643s, learning 0.101s)
             Mean action noise std: 3.47
          Mean value_function loss: 17.6268
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 45.1614
                       Mean reward: 862.35
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7375
    Episode_Reward/rotating_object: 169.5795
        Episode_Reward/action_rate: -0.0606
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 1.74s
                      Time elapsed: 00:48:02
                               ETA: 00:01:35

################################################################################
                     [1m Learning iteration 1453/1500 [0m                     

                       Computation: 56870 steps/s (collection: 1.624s, learning 0.105s)
             Mean action noise std: 3.47
          Mean value_function loss: 21.3421
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.1681
                       Mean reward: 857.17
               Mean episode length: 248.77
    Episode_Reward/reaching_object: 0.7249
    Episode_Reward/rotating_object: 167.7739
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 1.73s
                      Time elapsed: 00:48:04
                               ETA: 00:01:33

################################################################################
                     [1m Learning iteration 1454/1500 [0m                     

                       Computation: 54268 steps/s (collection: 1.692s, learning 0.119s)
             Mean action noise std: 3.47
          Mean value_function loss: 21.9218
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 45.1801
                       Mean reward: 843.23
               Mean episode length: 245.65
    Episode_Reward/reaching_object: 0.7208
    Episode_Reward/rotating_object: 167.4260
        Episode_Reward/action_rate: -0.0595
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 1.81s
                      Time elapsed: 00:48:06
                               ETA: 00:01:31

################################################################################
                     [1m Learning iteration 1455/1500 [0m                     

                       Computation: 56005 steps/s (collection: 1.632s, learning 0.123s)
             Mean action noise std: 3.47
          Mean value_function loss: 20.3011
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 45.1984
                       Mean reward: 832.03
               Mean episode length: 242.52
    Episode_Reward/reaching_object: 0.7298
    Episode_Reward/rotating_object: 169.7470
        Episode_Reward/action_rate: -0.0603
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 1.76s
                      Time elapsed: 00:48:07
                               ETA: 00:01:29

################################################################################
                     [1m Learning iteration 1456/1500 [0m                     

                       Computation: 57061 steps/s (collection: 1.632s, learning 0.091s)
             Mean action noise std: 3.47
          Mean value_function loss: 14.0520
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 45.2023
                       Mean reward: 866.67
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7251
    Episode_Reward/rotating_object: 170.1485
        Episode_Reward/action_rate: -0.0602
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 1.72s
                      Time elapsed: 00:48:09
                               ETA: 00:01:27

################################################################################
                     [1m Learning iteration 1457/1500 [0m                     

                       Computation: 56591 steps/s (collection: 1.645s, learning 0.092s)
             Mean action noise std: 3.48
          Mean value_function loss: 14.1672
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 45.2092
                       Mean reward: 840.66
               Mean episode length: 244.55
    Episode_Reward/reaching_object: 0.7314
    Episode_Reward/rotating_object: 170.2970
        Episode_Reward/action_rate: -0.0606
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 1.74s
                      Time elapsed: 00:48:11
                               ETA: 00:01:25

################################################################################
                     [1m Learning iteration 1458/1500 [0m                     

                       Computation: 55193 steps/s (collection: 1.644s, learning 0.137s)
             Mean action noise std: 3.48
          Mean value_function loss: 7.5154
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 45.2190
                       Mean reward: 858.28
               Mean episode length: 248.17
    Episode_Reward/reaching_object: 0.7288
    Episode_Reward/rotating_object: 170.9390
        Episode_Reward/action_rate: -0.0608
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 1.78s
                      Time elapsed: 00:48:13
                               ETA: 00:01:23

################################################################################
                     [1m Learning iteration 1459/1500 [0m                     

                       Computation: 56392 steps/s (collection: 1.639s, learning 0.104s)
             Mean action noise std: 3.48
          Mean value_function loss: 14.3762
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 45.2213
                       Mean reward: 862.33
               Mean episode length: 248.27
    Episode_Reward/reaching_object: 0.7240
    Episode_Reward/rotating_object: 168.5893
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 1.74s
                      Time elapsed: 00:48:14
                               ETA: 00:01:21

################################################################################
                     [1m Learning iteration 1460/1500 [0m                     

                       Computation: 56807 steps/s (collection: 1.642s, learning 0.088s)
             Mean action noise std: 3.48
          Mean value_function loss: 14.7726
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 45.2239
                       Mean reward: 858.29
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.7316
    Episode_Reward/rotating_object: 169.4395
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 1.73s
                      Time elapsed: 00:48:16
                               ETA: 00:01:19

################################################################################
                     [1m Learning iteration 1461/1500 [0m                     

                       Computation: 55827 steps/s (collection: 1.645s, learning 0.116s)
             Mean action noise std: 3.48
          Mean value_function loss: 13.4608
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 45.2301
                       Mean reward: 863.30
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7382
    Episode_Reward/rotating_object: 171.4028
        Episode_Reward/action_rate: -0.0611
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 1.76s
                      Time elapsed: 00:48:18
                               ETA: 00:01:17

################################################################################
                     [1m Learning iteration 1462/1500 [0m                     

                       Computation: 56123 steps/s (collection: 1.658s, learning 0.094s)
             Mean action noise std: 3.49
          Mean value_function loss: 21.9118
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 45.2399
                       Mean reward: 850.68
               Mean episode length: 245.45
    Episode_Reward/reaching_object: 0.7283
    Episode_Reward/rotating_object: 168.9085
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 1.75s
                      Time elapsed: 00:48:20
                               ETA: 00:01:15

################################################################################
                     [1m Learning iteration 1463/1500 [0m                     

                       Computation: 52171 steps/s (collection: 1.792s, learning 0.092s)
             Mean action noise std: 3.49
          Mean value_function loss: 12.9515
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 45.2539
                       Mean reward: 866.56
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7278
    Episode_Reward/rotating_object: 169.2706
        Episode_Reward/action_rate: -0.0603
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 1.88s
                      Time elapsed: 00:48:22
                               ETA: 00:01:13

################################################################################
                     [1m Learning iteration 1464/1500 [0m                     

                       Computation: 54701 steps/s (collection: 1.687s, learning 0.110s)
             Mean action noise std: 3.49
          Mean value_function loss: 24.9018
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.2594
                       Mean reward: 842.19
               Mean episode length: 243.29
    Episode_Reward/reaching_object: 0.7203
    Episode_Reward/rotating_object: 167.6658
        Episode_Reward/action_rate: -0.0599
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 1.80s
                      Time elapsed: 00:48:23
                               ETA: 00:01:11

################################################################################
                     [1m Learning iteration 1465/1500 [0m                     

                       Computation: 52783 steps/s (collection: 1.695s, learning 0.167s)
             Mean action noise std: 3.49
          Mean value_function loss: 16.3160
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 45.2730
                       Mean reward: 837.28
               Mean episode length: 242.03
    Episode_Reward/reaching_object: 0.7273
    Episode_Reward/rotating_object: 169.5655
        Episode_Reward/action_rate: -0.0605
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 1.86s
                      Time elapsed: 00:48:25
                               ETA: 00:01:09

################################################################################
                     [1m Learning iteration 1466/1500 [0m                     

                       Computation: 54303 steps/s (collection: 1.719s, learning 0.092s)
             Mean action noise std: 3.49
          Mean value_function loss: 15.2344
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 45.2817
                       Mean reward: 858.97
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7334
    Episode_Reward/rotating_object: 170.6459
        Episode_Reward/action_rate: -0.0612
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 1.81s
                      Time elapsed: 00:48:27
                               ETA: 00:01:07

################################################################################
                     [1m Learning iteration 1467/1500 [0m                     

                       Computation: 55258 steps/s (collection: 1.671s, learning 0.108s)
             Mean action noise std: 3.49
          Mean value_function loss: 12.7434
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.2867
                       Mean reward: 863.34
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7292
    Episode_Reward/rotating_object: 169.6536
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 1.78s
                      Time elapsed: 00:48:29
                               ETA: 00:01:05

################################################################################
                     [1m Learning iteration 1468/1500 [0m                     

                       Computation: 56235 steps/s (collection: 1.655s, learning 0.093s)
             Mean action noise std: 3.50
          Mean value_function loss: 9.8912
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 45.2944
                       Mean reward: 864.03
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7380
    Episode_Reward/rotating_object: 171.8856
        Episode_Reward/action_rate: -0.0613
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 1.75s
                      Time elapsed: 00:48:31
                               ETA: 00:01:03

################################################################################
                     [1m Learning iteration 1469/1500 [0m                     

                       Computation: 54657 steps/s (collection: 1.649s, learning 0.149s)
             Mean action noise std: 3.50
          Mean value_function loss: 7.6388
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.3036
                       Mean reward: 847.72
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7333
    Episode_Reward/rotating_object: 170.5662
        Episode_Reward/action_rate: -0.0613
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 1.80s
                      Time elapsed: 00:48:32
                               ETA: 00:01:01

################################################################################
                     [1m Learning iteration 1470/1500 [0m                     

                       Computation: 52505 steps/s (collection: 1.778s, learning 0.094s)
             Mean action noise std: 3.50
          Mean value_function loss: 8.3721
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 45.3116
                       Mean reward: 865.74
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7386
    Episode_Reward/rotating_object: 171.0941
        Episode_Reward/action_rate: -0.0613
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 1.87s
                      Time elapsed: 00:48:34
                               ETA: 00:00:59

################################################################################
                     [1m Learning iteration 1471/1500 [0m                     

                       Computation: 55228 steps/s (collection: 1.661s, learning 0.119s)
             Mean action noise std: 3.50
          Mean value_function loss: 12.3503
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 45.3168
                       Mean reward: 864.38
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7315
    Episode_Reward/rotating_object: 170.1528
        Episode_Reward/action_rate: -0.0613
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 1.78s
                      Time elapsed: 00:48:36
                               ETA: 00:00:57

################################################################################
                     [1m Learning iteration 1472/1500 [0m                     

                       Computation: 55281 steps/s (collection: 1.646s, learning 0.133s)
             Mean action noise std: 3.50
          Mean value_function loss: 19.1666
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 45.3265
                       Mean reward: 850.15
               Mean episode length: 245.78
    Episode_Reward/reaching_object: 0.7193
    Episode_Reward/rotating_object: 168.4984
        Episode_Reward/action_rate: -0.0609
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 1.78s
                      Time elapsed: 00:48:38
                               ETA: 00:00:55

################################################################################
                     [1m Learning iteration 1473/1500 [0m                     

                       Computation: 55591 steps/s (collection: 1.650s, learning 0.118s)
             Mean action noise std: 3.51
          Mean value_function loss: 20.9875
               Mean surrogate loss: 0.0025
                 Mean entropy loss: 45.3381
                       Mean reward: 839.71
               Mean episode length: 243.57
    Episode_Reward/reaching_object: 0.7188
    Episode_Reward/rotating_object: 170.2415
        Episode_Reward/action_rate: -0.0612
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 1.77s
                      Time elapsed: 00:48:40
                               ETA: 00:00:53

################################################################################
                     [1m Learning iteration 1474/1500 [0m                     

                       Computation: 55732 steps/s (collection: 1.656s, learning 0.108s)
             Mean action noise std: 3.51
          Mean value_function loss: 20.6841
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 45.3412
                       Mean reward: 850.55
               Mean episode length: 246.47
    Episode_Reward/reaching_object: 0.7207
    Episode_Reward/rotating_object: 169.2502
        Episode_Reward/action_rate: -0.0613
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 1.76s
                      Time elapsed: 00:48:41
                               ETA: 00:00:51

################################################################################
                     [1m Learning iteration 1475/1500 [0m                     

                       Computation: 57524 steps/s (collection: 1.617s, learning 0.092s)
             Mean action noise std: 3.51
          Mean value_function loss: 16.0943
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 45.3449
                       Mean reward: 842.90
               Mean episode length: 243.75
    Episode_Reward/reaching_object: 0.7153
    Episode_Reward/rotating_object: 171.0173
        Episode_Reward/action_rate: -0.0615
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 1.71s
                      Time elapsed: 00:48:43
                               ETA: 00:00:49

################################################################################
                     [1m Learning iteration 1476/1500 [0m                     

                       Computation: 56301 steps/s (collection: 1.598s, learning 0.148s)
             Mean action noise std: 3.51
          Mean value_function loss: 13.9697
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 45.3528
                       Mean reward: 833.03
               Mean episode length: 244.45
    Episode_Reward/reaching_object: 0.6982
    Episode_Reward/rotating_object: 168.9709
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 1.75s
                      Time elapsed: 00:48:45
                               ETA: 00:00:47

################################################################################
                     [1m Learning iteration 1477/1500 [0m                     

                       Computation: 57361 steps/s (collection: 1.624s, learning 0.090s)
             Mean action noise std: 3.51
          Mean value_function loss: 11.3674
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 45.3627
                       Mean reward: 851.08
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.7051
    Episode_Reward/rotating_object: 170.5266
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 1.71s
                      Time elapsed: 00:48:46
                               ETA: 00:00:45

################################################################################
                     [1m Learning iteration 1478/1500 [0m                     

                       Computation: 57516 steps/s (collection: 1.617s, learning 0.092s)
             Mean action noise std: 3.51
          Mean value_function loss: 12.0272
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 45.3748
                       Mean reward: 853.68
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.6986
    Episode_Reward/rotating_object: 170.3482
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 1.71s
                      Time elapsed: 00:48:48
                               ETA: 00:00:43

################################################################################
                     [1m Learning iteration 1479/1500 [0m                     

                       Computation: 54361 steps/s (collection: 1.690s, learning 0.119s)
             Mean action noise std: 3.51
          Mean value_function loss: 10.1611
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 45.3799
                       Mean reward: 860.84
               Mean episode length: 248.10
    Episode_Reward/reaching_object: 0.7036
    Episode_Reward/rotating_object: 171.6976
        Episode_Reward/action_rate: -0.0623
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 1.81s
                      Time elapsed: 00:48:50
                               ETA: 00:00:41

################################################################################
                     [1m Learning iteration 1480/1500 [0m                     

                       Computation: 51144 steps/s (collection: 1.707s, learning 0.215s)
             Mean action noise std: 3.52
          Mean value_function loss: 8.2245
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 45.3857
                       Mean reward: 866.81
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7008
    Episode_Reward/rotating_object: 170.8582
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 1.92s
                      Time elapsed: 00:48:52
                               ETA: 00:00:39

################################################################################
                     [1m Learning iteration 1481/1500 [0m                     

                       Computation: 53432 steps/s (collection: 1.680s, learning 0.159s)
             Mean action noise std: 3.52
          Mean value_function loss: 12.9452
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 45.3947
                       Mean reward: 857.60
               Mean episode length: 248.42
    Episode_Reward/reaching_object: 0.7071
    Episode_Reward/rotating_object: 171.8128
        Episode_Reward/action_rate: -0.0621
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 1.84s
                      Time elapsed: 00:48:54
                               ETA: 00:00:37

################################################################################
                     [1m Learning iteration 1482/1500 [0m                     

                       Computation: 57363 steps/s (collection: 1.617s, learning 0.097s)
             Mean action noise std: 3.52
          Mean value_function loss: 13.1425
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 45.4051
                       Mean reward: 850.91
               Mean episode length: 245.56
    Episode_Reward/reaching_object: 0.6964
    Episode_Reward/rotating_object: 169.9516
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 1.71s
                      Time elapsed: 00:48:55
                               ETA: 00:00:35

################################################################################
                     [1m Learning iteration 1483/1500 [0m                     

                       Computation: 54234 steps/s (collection: 1.718s, learning 0.094s)
             Mean action noise std: 3.52
          Mean value_function loss: 10.5137
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 45.4137
                       Mean reward: 848.96
               Mean episode length: 245.49
    Episode_Reward/reaching_object: 0.6993
    Episode_Reward/rotating_object: 171.2151
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 1.81s
                      Time elapsed: 00:48:57
                               ETA: 00:00:33

################################################################################
                     [1m Learning iteration 1484/1500 [0m                     

                       Computation: 55948 steps/s (collection: 1.645s, learning 0.112s)
             Mean action noise std: 3.52
          Mean value_function loss: 13.8101
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 45.4251
                       Mean reward: 849.90
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 0.7003
    Episode_Reward/rotating_object: 171.1212
        Episode_Reward/action_rate: -0.0622
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 1.76s
                      Time elapsed: 00:48:59
                               ETA: 00:00:31

################################################################################
                     [1m Learning iteration 1485/1500 [0m                     

                       Computation: 55403 steps/s (collection: 1.653s, learning 0.122s)
             Mean action noise std: 3.53
          Mean value_function loss: 20.9087
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 45.4368
                       Mean reward: 847.00
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.6972
    Episode_Reward/rotating_object: 168.6904
        Episode_Reward/action_rate: -0.0616
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 1.77s
                      Time elapsed: 00:49:01
                               ETA: 00:00:29

################################################################################
                     [1m Learning iteration 1486/1500 [0m                     

                       Computation: 55183 steps/s (collection: 1.671s, learning 0.111s)
             Mean action noise std: 3.53
          Mean value_function loss: 6.2487
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 45.4493
                       Mean reward: 858.26
               Mean episode length: 248.02
    Episode_Reward/reaching_object: 0.7021
    Episode_Reward/rotating_object: 170.6317
        Episode_Reward/action_rate: -0.0622
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 1.78s
                      Time elapsed: 00:49:03
                               ETA: 00:00:27

################################################################################
                     [1m Learning iteration 1487/1500 [0m                     

                       Computation: 54439 steps/s (collection: 1.674s, learning 0.132s)
             Mean action noise std: 3.53
          Mean value_function loss: 12.8158
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 45.4558
                       Mean reward: 859.12
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7002
    Episode_Reward/rotating_object: 171.0811
        Episode_Reward/action_rate: -0.0622
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 1.81s
                      Time elapsed: 00:49:04
                               ETA: 00:00:25

################################################################################
                     [1m Learning iteration 1488/1500 [0m                     

                       Computation: 56966 steps/s (collection: 1.626s, learning 0.100s)
             Mean action noise std: 3.53
          Mean value_function loss: 12.6500
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 45.4689
                       Mean reward: 856.61
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7011
    Episode_Reward/rotating_object: 171.7438
        Episode_Reward/action_rate: -0.0625
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 1.73s
                      Time elapsed: 00:49:06
                               ETA: 00:00:23

################################################################################
                     [1m Learning iteration 1489/1500 [0m                     

                       Computation: 54526 steps/s (collection: 1.658s, learning 0.145s)
             Mean action noise std: 3.53
          Mean value_function loss: 18.6515
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 45.4772
                       Mean reward: 851.31
               Mean episode length: 245.59
    Episode_Reward/reaching_object: 0.6987
    Episode_Reward/rotating_object: 170.6587
        Episode_Reward/action_rate: -0.0623
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 1.80s
                      Time elapsed: 00:49:08
                               ETA: 00:00:21

################################################################################
                     [1m Learning iteration 1490/1500 [0m                     

                       Computation: 55281 steps/s (collection: 1.684s, learning 0.094s)
             Mean action noise std: 3.53
          Mean value_function loss: 11.2706
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 45.4863
                       Mean reward: 858.01
               Mean episode length: 248.10
    Episode_Reward/reaching_object: 0.6988
    Episode_Reward/rotating_object: 170.2034
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 1.78s
                      Time elapsed: 00:49:10
                               ETA: 00:00:19

################################################################################
                     [1m Learning iteration 1491/1500 [0m                     

                       Computation: 56596 steps/s (collection: 1.631s, learning 0.106s)
             Mean action noise std: 3.54
          Mean value_function loss: 12.6523
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 45.4907
                       Mean reward: 856.13
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7013
    Episode_Reward/rotating_object: 171.2972
        Episode_Reward/action_rate: -0.0625
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 1.74s
                      Time elapsed: 00:49:11
                               ETA: 00:00:17

################################################################################
                     [1m Learning iteration 1492/1500 [0m                     

                       Computation: 55119 steps/s (collection: 1.660s, learning 0.124s)
             Mean action noise std: 3.54
          Mean value_function loss: 19.2391
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 45.4960
                       Mean reward: 862.07
               Mean episode length: 247.67
    Episode_Reward/reaching_object: 0.6974
    Episode_Reward/rotating_object: 170.7835
        Episode_Reward/action_rate: -0.0623
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 1.78s
                      Time elapsed: 00:49:13
                               ETA: 00:00:15

################################################################################
                     [1m Learning iteration 1493/1500 [0m                     

                       Computation: 54816 steps/s (collection: 1.654s, learning 0.140s)
             Mean action noise std: 3.54
          Mean value_function loss: 19.0170
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 45.5047
                       Mean reward: 829.41
               Mean episode length: 243.26
    Episode_Reward/reaching_object: 0.6957
    Episode_Reward/rotating_object: 169.0018
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 1.79s
                      Time elapsed: 00:49:15
                               ETA: 00:00:13

################################################################################
                     [1m Learning iteration 1494/1500 [0m                     

                       Computation: 55256 steps/s (collection: 1.653s, learning 0.126s)
             Mean action noise std: 3.54
          Mean value_function loss: 14.8337
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 45.5223
                       Mean reward: 841.90
               Mean episode length: 243.62
    Episode_Reward/reaching_object: 0.6997
    Episode_Reward/rotating_object: 170.3067
        Episode_Reward/action_rate: -0.0625
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 1.78s
                      Time elapsed: 00:49:17
                               ETA: 00:00:11

################################################################################
                     [1m Learning iteration 1495/1500 [0m                     

                       Computation: 57013 steps/s (collection: 1.635s, learning 0.090s)
             Mean action noise std: 3.54
          Mean value_function loss: 17.3227
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 45.5414
                       Mean reward: 844.40
               Mean episode length: 245.41
    Episode_Reward/reaching_object: 0.6932
    Episode_Reward/rotating_object: 169.3560
        Episode_Reward/action_rate: -0.0624
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 1.72s
                      Time elapsed: 00:49:18
                               ETA: 00:00:09

################################################################################
                     [1m Learning iteration 1496/1500 [0m                     

                       Computation: 56798 steps/s (collection: 1.636s, learning 0.095s)
             Mean action noise std: 3.54
          Mean value_function loss: 11.9420
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 45.5454
                       Mean reward: 851.72
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.6945
    Episode_Reward/rotating_object: 171.3081
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 1.73s
                      Time elapsed: 00:49:20
                               ETA: 00:00:07

################################################################################
                     [1m Learning iteration 1497/1500 [0m                     

                       Computation: 53184 steps/s (collection: 1.720s, learning 0.128s)
             Mean action noise std: 3.55
          Mean value_function loss: 17.6203
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 45.5505
                       Mean reward: 858.49
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6928
    Episode_Reward/rotating_object: 169.4717
        Episode_Reward/action_rate: -0.0627
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 1.85s
                      Time elapsed: 00:49:22
                               ETA: 00:00:05

################################################################################
                     [1m Learning iteration 1498/1500 [0m                     

                       Computation: 55378 steps/s (collection: 1.638s, learning 0.137s)
             Mean action noise std: 3.55
          Mean value_function loss: 11.9333
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 45.5599
                       Mean reward: 851.97
               Mean episode length: 247.24
    Episode_Reward/reaching_object: 0.6880
    Episode_Reward/rotating_object: 169.3064
        Episode_Reward/action_rate: -0.0625
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 1.78s
                      Time elapsed: 00:49:24
                               ETA: 00:00:03

################################################################################
                     [1m Learning iteration 1499/1500 [0m                     

                       Computation: 55223 steps/s (collection: 1.679s, learning 0.101s)
             Mean action noise std: 3.55
          Mean value_function loss: 15.2767
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 45.5711
                       Mean reward: 861.09
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.6860
    Episode_Reward/rotating_object: 169.3275
        Episode_Reward/action_rate: -0.0627
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 1.78s
                      Time elapsed: 00:49:26
                               ETA: 00:00:01

