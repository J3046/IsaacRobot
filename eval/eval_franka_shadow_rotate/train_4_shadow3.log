################################################################################
                      [1m Learning iteration 0/1500 [0m                       

                       Computation: 10491 steps/s (collection: 9.028s, learning 0.342s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0050
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 31.2483
                       Mean reward: 0.00
               Mean episode length: 21.94
    Episode_Reward/reaching_object: 0.0007
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0002
          Episode_Reward/joint_vel: -0.0003
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 9.37s
                      Time elapsed: 00:00:09
                               ETA: 03:54:14

################################################################################
                      [1m Learning iteration 1/1500 [0m                       

                       Computation: 11551 steps/s (collection: 8.305s, learning 0.205s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0004
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 31.3417
                       Mean reward: 0.00
               Mean episode length: 45.00
    Episode_Reward/reaching_object: 0.0021
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0006
          Episode_Reward/joint_vel: -0.0008
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 8.51s
                      Time elapsed: 00:00:17
                               ETA: 03:43:20

################################################################################
                      [1m Learning iteration 2/1500 [0m                       

                       Computation: 14068 steps/s (collection: 6.837s, learning 0.150s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 31.4133
                       Mean reward: 0.01
               Mean episode length: 69.37
    Episode_Reward/reaching_object: 0.0037
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0011
          Episode_Reward/joint_vel: -0.0014
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 6.99s
                      Time elapsed: 00:00:24
                               ETA: 03:26:57

################################################################################
                      [1m Learning iteration 3/1500 [0m                       

                       Computation: 14579 steps/s (collection: 6.613s, learning 0.130s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 31.4154
                       Mean reward: 0.01
               Mean episode length: 93.77
    Episode_Reward/reaching_object: 0.0055
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0015
          Episode_Reward/joint_vel: -0.0019
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 6.74s
                      Time elapsed: 00:00:31
                               ETA: 03:17:10

################################################################################
                      [1m Learning iteration 4/1500 [0m                       

                       Computation: 14515 steps/s (collection: 6.642s, learning 0.131s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 31.4197
                       Mean reward: 0.02
               Mean episode length: 117.34
    Episode_Reward/reaching_object: 0.0077
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0019
          Episode_Reward/joint_vel: -0.0025
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 6.77s
                      Time elapsed: 00:00:38
                               ETA: 03:11:23

################################################################################
                      [1m Learning iteration 5/1500 [0m                       

                       Computation: 14392 steps/s (collection: 6.652s, learning 0.178s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 31.4524
                       Mean reward: 0.03
               Mean episode length: 141.43
    Episode_Reward/reaching_object: 0.0104
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0024
          Episode_Reward/joint_vel: -0.0031
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 6.83s
                      Time elapsed: 00:00:45
                               ETA: 03:07:45

################################################################################
                      [1m Learning iteration 6/1500 [0m                       

                       Computation: 14177 steps/s (collection: 6.772s, learning 0.162s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 31.4754
                       Mean reward: 0.05
               Mean episode length: 165.01
    Episode_Reward/reaching_object: 0.0151
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0028
          Episode_Reward/joint_vel: -0.0036
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 6.93s
                      Time elapsed: 00:00:52
                               ETA: 03:05:29

################################################################################
                      [1m Learning iteration 7/1500 [0m                       

                       Computation: 14651 steps/s (collection: 6.570s, learning 0.139s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 31.4616
                       Mean reward: 0.07
               Mean episode length: 189.52
    Episode_Reward/reaching_object: 0.0188
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0032
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 6.71s
                      Time elapsed: 00:00:58
                               ETA: 03:03:03

################################################################################
                      [1m Learning iteration 8/1500 [0m                       

                       Computation: 16506 steps/s (collection: 5.828s, learning 0.127s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 31.4843
                       Mean reward: 0.11
               Mean episode length: 213.81
    Episode_Reward/reaching_object: 0.0261
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 5.96s
                      Time elapsed: 00:01:04
                               ETA: 02:59:04

################################################################################
                      [1m Learning iteration 9/1500 [0m                       

                       Computation: 57973 steps/s (collection: 1.593s, learning 0.103s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 31.5017
                       Mean reward: 0.15
               Mean episode length: 237.09
    Episode_Reward/reaching_object: 0.0354
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 1.70s
                      Time elapsed: 00:01:06
                               ETA: 02:45:16

################################################################################
                      [1m Learning iteration 10/1500 [0m                      

                       Computation: 54016 steps/s (collection: 1.657s, learning 0.163s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0003
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 31.5382
                       Mean reward: 0.23
               Mean episode length: 249.78
    Episode_Reward/reaching_object: 0.0467
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 1.82s
                      Time elapsed: 00:01:08
                               ETA: 02:34:15

################################################################################
                      [1m Learning iteration 11/1500 [0m                      

                       Computation: 55115 steps/s (collection: 1.627s, learning 0.157s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0009
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 31.6232
                       Mean reward: 0.27
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0551
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 1.78s
                      Time elapsed: 00:01:10
                               ETA: 02:24:59

################################################################################
                      [1m Learning iteration 12/1500 [0m                      

                       Computation: 53251 steps/s (collection: 1.644s, learning 0.202s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0007
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 31.6627
                       Mean reward: 0.33
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0747
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 1.85s
                      Time elapsed: 00:01:11
                               ETA: 02:17:16

################################################################################
                      [1m Learning iteration 13/1500 [0m                      

                       Computation: 57220 steps/s (collection: 1.625s, learning 0.093s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0012
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 31.7461
                       Mean reward: 0.48
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0984
    Episode_Reward/rotating_object: 0.0017
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 1.72s
                      Time elapsed: 00:01:13
                               ETA: 02:10:25

################################################################################
                      [1m Learning iteration 14/1500 [0m                      

                       Computation: 53927 steps/s (collection: 1.720s, learning 0.103s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0010
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 31.8238
                       Mean reward: 0.60
               Mean episode length: 246.97
    Episode_Reward/reaching_object: 0.1179
    Episode_Reward/rotating_object: 0.0002
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 1.82s
                      Time elapsed: 00:01:15
                               ETA: 02:04:39

################################################################################
                      [1m Learning iteration 15/1500 [0m                      

                       Computation: 49681 steps/s (collection: 1.885s, learning 0.094s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0079
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 31.8652
                       Mean reward: 0.72
               Mean episode length: 245.26
    Episode_Reward/reaching_object: 0.1409
    Episode_Reward/rotating_object: 0.0004
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 1.98s
                      Time elapsed: 00:01:17
                               ETA: 01:59:50

################################################################################
                      [1m Learning iteration 16/1500 [0m                      

                       Computation: 51725 steps/s (collection: 1.800s, learning 0.101s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0027
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 31.9076
                       Mean reward: 0.79
               Mean episode length: 244.45
    Episode_Reward/reaching_object: 0.1709
    Episode_Reward/rotating_object: 0.0006
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 1.90s
                      Time elapsed: 00:01:19
                               ETA: 01:55:29

################################################################################
                      [1m Learning iteration 17/1500 [0m                      

                       Computation: 48848 steps/s (collection: 1.901s, learning 0.112s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0039
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 31.9985
                       Mean reward: 0.90
               Mean episode length: 242.52
    Episode_Reward/reaching_object: 0.1910
    Episode_Reward/rotating_object: 0.0029
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.4583
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 2.01s
                      Time elapsed: 00:01:21
                               ETA: 01:51:45

################################################################################
                      [1m Learning iteration 18/1500 [0m                      

                       Computation: 49786 steps/s (collection: 1.865s, learning 0.110s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0044
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 32.0311
                       Mean reward: 1.03
               Mean episode length: 234.37
    Episode_Reward/reaching_object: 0.2038
    Episode_Reward/rotating_object: 0.0038
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 10.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.7083
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 1.97s
                      Time elapsed: 00:01:23
                               ETA: 01:48:22

################################################################################
                      [1m Learning iteration 19/1500 [0m                      

                       Computation: 51269 steps/s (collection: 1.760s, learning 0.157s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0042
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 32.0813
                       Mean reward: 1.13
               Mean episode length: 227.89
    Episode_Reward/reaching_object: 0.2311
    Episode_Reward/rotating_object: 0.0110
        Episode_Reward/action_rate: -0.0043
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 8.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 1.92s
                      Time elapsed: 00:01:25
                               ETA: 01:45:15

################################################################################
                      [1m Learning iteration 20/1500 [0m                      

                       Computation: 51177 steps/s (collection: 1.798s, learning 0.123s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0048
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 32.1566
                       Mean reward: 1.20
               Mean episode length: 218.64
    Episode_Reward/reaching_object: 0.2420
    Episode_Reward/rotating_object: 0.0038
        Episode_Reward/action_rate: -0.0042
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 6.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 1.92s
                      Time elapsed: 00:01:27
                               ETA: 01:42:25

################################################################################
                      [1m Learning iteration 21/1500 [0m                      

                       Computation: 49494 steps/s (collection: 1.817s, learning 0.169s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0060
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 32.1667
                       Mean reward: 1.38
               Mean episode length: 221.21
    Episode_Reward/reaching_object: 0.2607
    Episode_Reward/rotating_object: 0.0063
        Episode_Reward/action_rate: -0.0042
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 5.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 1.99s
                      Time elapsed: 00:01:29
                               ETA: 01:39:55

################################################################################
                      [1m Learning iteration 22/1500 [0m                      

                       Computation: 49848 steps/s (collection: 1.846s, learning 0.126s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0067
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 32.2605
                       Mean reward: 1.42
               Mean episode length: 219.15
    Episode_Reward/reaching_object: 0.2653
    Episode_Reward/rotating_object: 0.0130
        Episode_Reward/action_rate: -0.0042
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 4.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 1.97s
                      Time elapsed: 00:01:31
                               ETA: 01:37:37

################################################################################
                      [1m Learning iteration 23/1500 [0m                      

                       Computation: 48954 steps/s (collection: 1.849s, learning 0.159s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0088
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 32.3405
                       Mean reward: 1.65
               Mean episode length: 214.31
    Episode_Reward/reaching_object: 0.2933
    Episode_Reward/rotating_object: 0.0212
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 4.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 2.01s
                      Time elapsed: 00:01:33
                               ETA: 01:35:33

################################################################################
                      [1m Learning iteration 24/1500 [0m                      

                       Computation: 47033 steps/s (collection: 1.950s, learning 0.140s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0111
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 32.3906
                       Mean reward: 1.60
               Mean episode length: 210.88
    Episode_Reward/reaching_object: 0.2954
    Episode_Reward/rotating_object: 0.0178
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 4.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 2.09s
                      Time elapsed: 00:01:35
                               ETA: 01:33:44

################################################################################
                      [1m Learning iteration 25/1500 [0m                      

                       Computation: 49281 steps/s (collection: 1.882s, learning 0.113s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0137
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 32.4710
                       Mean reward: 1.70
               Mean episode length: 210.69
    Episode_Reward/reaching_object: 0.3269
    Episode_Reward/rotating_object: 0.0275
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 4.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 1.99s
                      Time elapsed: 00:01:37
                               ETA: 01:31:57

################################################################################
                      [1m Learning iteration 26/1500 [0m                      

                       Computation: 48772 steps/s (collection: 1.866s, learning 0.149s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.0183
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 32.5760
                       Mean reward: 1.96
               Mean episode length: 208.88
    Episode_Reward/reaching_object: 0.3289
    Episode_Reward/rotating_object: 0.0470
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 5.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 11.6250
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 2.02s
                      Time elapsed: 00:01:39
                               ETA: 01:30:19

################################################################################
                      [1m Learning iteration 27/1500 [0m                      

                       Computation: 47822 steps/s (collection: 1.918s, learning 0.138s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.0244
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 32.6623
                       Mean reward: 2.26
               Mean episode length: 212.29
    Episode_Reward/reaching_object: 0.3910
    Episode_Reward/rotating_object: 0.0436
        Episode_Reward/action_rate: -0.0042
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 8.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 11.7083
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 2.06s
                      Time elapsed: 00:01:41
                               ETA: 01:28:50

################################################################################
                      [1m Learning iteration 28/1500 [0m                      

                       Computation: 47223 steps/s (collection: 1.950s, learning 0.132s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.1120
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 32.7442
                       Mean reward: 2.50
               Mean episode length: 215.91
    Episode_Reward/reaching_object: 0.4317
    Episode_Reward/rotating_object: 0.0703
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0065
      Episode_Termination/time_out: 9.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.3750
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 2.08s
                      Time elapsed: 00:01:43
                               ETA: 01:27:28

################################################################################
                      [1m Learning iteration 29/1500 [0m                      

                       Computation: 48656 steps/s (collection: 1.886s, learning 0.135s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.3371
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 32.9007
                       Mean reward: 3.47
               Mean episode length: 224.27
    Episode_Reward/reaching_object: 0.4827
    Episode_Reward/rotating_object: 0.0807
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 10.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 2.02s
                      Time elapsed: 00:01:45
                               ETA: 01:26:09

################################################################################
                      [1m Learning iteration 30/1500 [0m                      

                       Computation: 48910 steps/s (collection: 1.876s, learning 0.134s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.3005
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 33.0420
                       Mean reward: 3.55
               Mean episode length: 226.61
    Episode_Reward/reaching_object: 0.5444
    Episode_Reward/rotating_object: 0.1945
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0071
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 2.01s
                      Time elapsed: 00:01:47
                               ETA: 01:24:54

################################################################################
                      [1m Learning iteration 31/1500 [0m                      

                       Computation: 40384 steps/s (collection: 2.262s, learning 0.172s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.3284
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 33.1844
                       Mean reward: 4.70
               Mean episode length: 237.26
    Episode_Reward/reaching_object: 0.5607
    Episode_Reward/rotating_object: 0.2080
        Episode_Reward/action_rate: -0.0047
          Episode_Reward/joint_vel: -0.0073
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 2.43s
                      Time elapsed: 00:01:49
                               ETA: 01:24:03

################################################################################
                      [1m Learning iteration 32/1500 [0m                      

                       Computation: 41380 steps/s (collection: 2.174s, learning 0.201s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.5872
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 33.3283
                       Mean reward: 4.67
               Mean episode length: 229.77
    Episode_Reward/reaching_object: 0.6148
    Episode_Reward/rotating_object: 0.2662
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 2.38s
                      Time elapsed: 00:01:52
                               ETA: 01:23:13

################################################################################
                      [1m Learning iteration 33/1500 [0m                      

                       Computation: 43703 steps/s (collection: 2.116s, learning 0.134s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.3823
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.4446
                       Mean reward: 6.21
               Mean episode length: 236.86
    Episode_Reward/reaching_object: 0.6592
    Episode_Reward/rotating_object: 0.8045
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 2.25s
                      Time elapsed: 00:01:54
                               ETA: 01:22:20

################################################################################
                      [1m Learning iteration 34/1500 [0m                      

                       Computation: 48439 steps/s (collection: 1.934s, learning 0.095s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.5611
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 33.6015
                       Mean reward: 5.75
               Mean episode length: 237.49
    Episode_Reward/reaching_object: 0.6930
    Episode_Reward/rotating_object: 0.4119
        Episode_Reward/action_rate: -0.0050
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 2.03s
                      Time elapsed: 00:01:56
                               ETA: 01:21:20

################################################################################
                      [1m Learning iteration 35/1500 [0m                      

                       Computation: 44376 steps/s (collection: 2.100s, learning 0.115s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.7764
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 33.7076
                       Mean reward: 5.29
               Mean episode length: 246.89
    Episode_Reward/reaching_object: 0.7259
    Episode_Reward/rotating_object: 0.4247
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 12.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 2.22s
                      Time elapsed: 00:01:58
                               ETA: 01:20:32

################################################################################
                      [1m Learning iteration 36/1500 [0m                      

                       Computation: 50051 steps/s (collection: 1.841s, learning 0.123s)
             Mean action noise std: 1.13
          Mean value_function loss: 1.1752
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 33.7802
                       Mean reward: 6.76
               Mean episode length: 242.94
    Episode_Reward/reaching_object: 0.7429
    Episode_Reward/rotating_object: 0.7997
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 1.96s
                      Time elapsed: 00:02:00
                               ETA: 01:19:35

################################################################################
                      [1m Learning iteration 37/1500 [0m                      

                       Computation: 47797 steps/s (collection: 1.883s, learning 0.174s)
             Mean action noise std: 1.13
          Mean value_function loss: 1.4807
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 33.8839
                       Mean reward: 5.77
               Mean episode length: 241.31
    Episode_Reward/reaching_object: 0.7843
    Episode_Reward/rotating_object: 0.8268
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 2.06s
                      Time elapsed: 00:02:02
                               ETA: 01:18:46

################################################################################
                      [1m Learning iteration 38/1500 [0m                      

                       Computation: 49845 steps/s (collection: 1.883s, learning 0.089s)
             Mean action noise std: 1.14
          Mean value_function loss: 1.9012
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 33.9710
                       Mean reward: 9.02
               Mean episode length: 240.94
    Episode_Reward/reaching_object: 0.8013
    Episode_Reward/rotating_object: 1.0631
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 1.97s
                      Time elapsed: 00:02:04
                               ETA: 01:17:55

################################################################################
                      [1m Learning iteration 39/1500 [0m                      

                       Computation: 49878 steps/s (collection: 1.869s, learning 0.102s)
             Mean action noise std: 1.14
          Mean value_function loss: 1.9281
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 34.0502
                       Mean reward: 9.11
               Mean episode length: 235.47
    Episode_Reward/reaching_object: 0.7821
    Episode_Reward/rotating_object: 1.2560
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 1.97s
                      Time elapsed: 00:02:06
                               ETA: 01:17:07

################################################################################
                      [1m Learning iteration 40/1500 [0m                      

                       Computation: 49698 steps/s (collection: 1.871s, learning 0.107s)
             Mean action noise std: 1.15
          Mean value_function loss: 2.0237
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 34.1537
                       Mean reward: 16.77
               Mean episode length: 242.53
    Episode_Reward/reaching_object: 0.8109
    Episode_Reward/rotating_object: 1.5220
        Episode_Reward/action_rate: -0.0055
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 1.98s
                      Time elapsed: 00:02:08
                               ETA: 01:16:22

################################################################################
                      [1m Learning iteration 41/1500 [0m                      

                       Computation: 47746 steps/s (collection: 1.969s, learning 0.090s)
             Mean action noise std: 1.15
          Mean value_function loss: 1.4017
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 34.2566
                       Mean reward: 8.31
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 0.8230
    Episode_Reward/rotating_object: 1.1664
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 2.06s
                      Time elapsed: 00:02:10
                               ETA: 01:15:41

################################################################################
                      [1m Learning iteration 42/1500 [0m                      

                       Computation: 47915 steps/s (collection: 1.939s, learning 0.113s)
             Mean action noise std: 1.15
          Mean value_function loss: 1.1972
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 34.3326
                       Mean reward: 14.03
               Mean episode length: 244.39
    Episode_Reward/reaching_object: 0.8173
    Episode_Reward/rotating_object: 1.3717
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 2.05s
                      Time elapsed: 00:02:12
                               ETA: 01:15:02

################################################################################
                      [1m Learning iteration 43/1500 [0m                      

                       Computation: 45074 steps/s (collection: 2.072s, learning 0.109s)
             Mean action noise std: 1.16
          Mean value_function loss: 1.3956
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 34.3964
                       Mean reward: 9.59
               Mean episode length: 246.54
    Episode_Reward/reaching_object: 0.8151
    Episode_Reward/rotating_object: 0.9224
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 2.18s
                      Time elapsed: 00:02:14
                               ETA: 01:14:29

################################################################################
                      [1m Learning iteration 44/1500 [0m                      

                       Computation: 49834 steps/s (collection: 1.879s, learning 0.094s)
             Mean action noise std: 1.16
          Mean value_function loss: 1.6758
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 34.4201
                       Mean reward: 7.73
               Mean episode length: 245.30
    Episode_Reward/reaching_object: 0.8003
    Episode_Reward/rotating_object: 1.2961
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 1.97s
                      Time elapsed: 00:02:16
                               ETA: 01:13:50

################################################################################
                      [1m Learning iteration 45/1500 [0m                      

                       Computation: 49578 steps/s (collection: 1.888s, learning 0.095s)
             Mean action noise std: 1.16
          Mean value_function loss: 2.0125
               Mean surrogate loss: 0.0070
                 Mean entropy loss: 34.4647
                       Mean reward: 11.75
               Mean episode length: 240.11
    Episode_Reward/reaching_object: 0.8070
    Episode_Reward/rotating_object: 1.2196
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 1.98s
                      Time elapsed: 00:02:18
                               ETA: 01:13:14

################################################################################
                      [1m Learning iteration 46/1500 [0m                      

                       Computation: 50267 steps/s (collection: 1.854s, learning 0.102s)
             Mean action noise std: 1.16
          Mean value_function loss: 2.2693
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 34.4806
                       Mean reward: 9.60
               Mean episode length: 233.74
    Episode_Reward/reaching_object: 0.7750
    Episode_Reward/rotating_object: 1.4226
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 1.96s
                      Time elapsed: 00:02:20
                               ETA: 01:12:38

################################################################################
                      [1m Learning iteration 47/1500 [0m                      

                       Computation: 49840 steps/s (collection: 1.874s, learning 0.098s)
             Mean action noise std: 1.16
          Mean value_function loss: 1.9627
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 34.5187
                       Mean reward: 18.45
               Mean episode length: 227.74
    Episode_Reward/reaching_object: 0.7655
    Episode_Reward/rotating_object: 2.1876
        Episode_Reward/action_rate: -0.0055
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.3750
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 1.97s
                      Time elapsed: 00:02:22
                               ETA: 01:12:04

################################################################################
                      [1m Learning iteration 48/1500 [0m                      

                       Computation: 48456 steps/s (collection: 1.931s, learning 0.098s)
             Mean action noise std: 1.17
          Mean value_function loss: 1.8149
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 34.6021
                       Mean reward: 13.61
               Mean episode length: 228.37
    Episode_Reward/reaching_object: 0.7670
    Episode_Reward/rotating_object: 1.4507
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 2.03s
                      Time elapsed: 00:02:24
                               ETA: 01:11:33

################################################################################
                      [1m Learning iteration 49/1500 [0m                      

                       Computation: 50335 steps/s (collection: 1.845s, learning 0.108s)
             Mean action noise std: 1.17
          Mean value_function loss: 2.0281
               Mean surrogate loss: 0.0020
                 Mean entropy loss: 34.7104
                       Mean reward: 9.68
               Mean episode length: 236.83
    Episode_Reward/reaching_object: 0.7793
    Episode_Reward/rotating_object: 1.2384
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 1.95s
                      Time elapsed: 00:02:26
                               ETA: 01:11:01

################################################################################
                      [1m Learning iteration 50/1500 [0m                      

                       Computation: 48817 steps/s (collection: 1.911s, learning 0.103s)
             Mean action noise std: 1.17
          Mean value_function loss: 2.8004
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 34.7384
                       Mean reward: 12.49
               Mean episode length: 246.45
    Episode_Reward/reaching_object: 0.8259
    Episode_Reward/rotating_object: 1.6097
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 2.01s
                      Time elapsed: 00:02:28
                               ETA: 01:10:32

################################################################################
                      [1m Learning iteration 51/1500 [0m                      

                       Computation: 45266 steps/s (collection: 2.065s, learning 0.107s)
             Mean action noise std: 1.18
          Mean value_function loss: 4.0180
               Mean surrogate loss: 0.0018
                 Mean entropy loss: 34.7774
                       Mean reward: 12.20
               Mean episode length: 245.55
    Episode_Reward/reaching_object: 0.8462
    Episode_Reward/rotating_object: 1.3073
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 2.17s
                      Time elapsed: 00:02:31
                               ETA: 01:10:08

################################################################################
                      [1m Learning iteration 52/1500 [0m                      

                       Computation: 46701 steps/s (collection: 1.950s, learning 0.155s)
             Mean action noise std: 1.18
          Mean value_function loss: 4.8750
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 34.8117
                       Mean reward: 14.57
               Mean episode length: 246.28
    Episode_Reward/reaching_object: 0.8394
    Episode_Reward/rotating_object: 2.0741
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 2.10s
                      Time elapsed: 00:02:33
                               ETA: 01:09:43

################################################################################
                      [1m Learning iteration 53/1500 [0m                      

                       Computation: 45511 steps/s (collection: 2.067s, learning 0.093s)
             Mean action noise std: 1.18
          Mean value_function loss: 5.5255
               Mean surrogate loss: 0.0083
                 Mean entropy loss: 34.8772
                       Mean reward: 12.60
               Mean episode length: 244.78
    Episode_Reward/reaching_object: 0.8191
    Episode_Reward/rotating_object: 2.2130
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 2.16s
                      Time elapsed: 00:02:35
                               ETA: 01:09:21

################################################################################
                      [1m Learning iteration 54/1500 [0m                      

                       Computation: 47570 steps/s (collection: 1.929s, learning 0.138s)
             Mean action noise std: 1.18
          Mean value_function loss: 5.8683
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 34.9007
                       Mean reward: 25.94
               Mean episode length: 246.66
    Episode_Reward/reaching_object: 0.8117
    Episode_Reward/rotating_object: 3.3213
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 2.07s
                      Time elapsed: 00:02:37
                               ETA: 01:08:56

################################################################################
                      [1m Learning iteration 55/1500 [0m                      

                       Computation: 49675 steps/s (collection: 1.866s, learning 0.113s)
             Mean action noise std: 1.19
          Mean value_function loss: 6.8739
               Mean surrogate loss: 0.0025
                 Mean entropy loss: 34.9450
                       Mean reward: 18.19
               Mean episode length: 247.09
    Episode_Reward/reaching_object: 0.8061
    Episode_Reward/rotating_object: 3.2649
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 1.98s
                      Time elapsed: 00:02:39
                               ETA: 01:08:31

################################################################################
                      [1m Learning iteration 56/1500 [0m                      

                       Computation: 50613 steps/s (collection: 1.829s, learning 0.114s)
             Mean action noise std: 1.19
          Mean value_function loss: 7.7232
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 34.9854
                       Mean reward: 18.97
               Mean episode length: 244.04
    Episode_Reward/reaching_object: 0.8244
    Episode_Reward/rotating_object: 3.2525
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 1.94s
                      Time elapsed: 00:02:41
                               ETA: 01:08:05

################################################################################
                      [1m Learning iteration 57/1500 [0m                      

                       Computation: 49681 steps/s (collection: 1.870s, learning 0.109s)
             Mean action noise std: 1.19
          Mean value_function loss: 9.0944
               Mean surrogate loss: 0.0024
                 Mean entropy loss: 35.0417
                       Mean reward: 21.80
               Mean episode length: 246.48
    Episode_Reward/reaching_object: 0.8271
    Episode_Reward/rotating_object: 3.6798
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 19.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 1.98s
                      Time elapsed: 00:02:43
                               ETA: 01:07:41

################################################################################
                      [1m Learning iteration 58/1500 [0m                      

                       Computation: 49142 steps/s (collection: 1.893s, learning 0.107s)
             Mean action noise std: 1.20
          Mean value_function loss: 9.6921
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 35.1021
                       Mean reward: 40.75
               Mean episode length: 247.98
    Episode_Reward/reaching_object: 0.8318
    Episode_Reward/rotating_object: 5.0681
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 20.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 2.00s
                      Time elapsed: 00:02:45
                               ETA: 01:07:18

################################################################################
                      [1m Learning iteration 59/1500 [0m                      

                       Computation: 50400 steps/s (collection: 1.831s, learning 0.120s)
             Mean action noise std: 1.20
          Mean value_function loss: 9.3724
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 35.1741
                       Mean reward: 36.26
               Mean episode length: 245.99
    Episode_Reward/reaching_object: 0.8006
    Episode_Reward/rotating_object: 4.5066
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 18.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 1.95s
                      Time elapsed: 00:02:47
                               ETA: 01:06:55

################################################################################
                      [1m Learning iteration 60/1500 [0m                      

                       Computation: 49495 steps/s (collection: 1.873s, learning 0.113s)
             Mean action noise std: 1.20
          Mean value_function loss: 13.5062
               Mean surrogate loss: 0.0024
                 Mean entropy loss: 35.2323
                       Mean reward: 33.43
               Mean episode length: 242.03
    Episode_Reward/reaching_object: 0.7965
    Episode_Reward/rotating_object: 5.1935
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 1.99s
                      Time elapsed: 00:02:49
                               ETA: 01:06:34

################################################################################
                      [1m Learning iteration 61/1500 [0m                      

                       Computation: 50539 steps/s (collection: 1.842s, learning 0.103s)
             Mean action noise std: 1.21
          Mean value_function loss: 10.0820
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 35.2781
                       Mean reward: 24.92
               Mean episode length: 242.65
    Episode_Reward/reaching_object: 0.8036
    Episode_Reward/rotating_object: 5.0625
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 1.95s
                      Time elapsed: 00:02:51
                               ETA: 01:06:12

################################################################################
                      [1m Learning iteration 62/1500 [0m                      

                       Computation: 49425 steps/s (collection: 1.886s, learning 0.103s)
             Mean action noise std: 1.21
          Mean value_function loss: 10.4218
               Mean surrogate loss: 0.0042
                 Mean entropy loss: 35.3124
                       Mean reward: 34.73
               Mean episode length: 247.54
    Episode_Reward/reaching_object: 0.7902
    Episode_Reward/rotating_object: 5.9047
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 1.99s
                      Time elapsed: 00:02:53
                               ETA: 01:05:51

################################################################################
                      [1m Learning iteration 63/1500 [0m                      

                       Computation: 49817 steps/s (collection: 1.879s, learning 0.095s)
             Mean action noise std: 1.21
          Mean value_function loss: 9.6696
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 35.3431
                       Mean reward: 31.43
               Mean episode length: 239.40
    Episode_Reward/reaching_object: 0.7647
    Episode_Reward/rotating_object: 4.8849
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 1.97s
                      Time elapsed: 00:02:55
                               ETA: 01:05:31

################################################################################
                      [1m Learning iteration 64/1500 [0m                      

                       Computation: 50675 steps/s (collection: 1.847s, learning 0.093s)
             Mean action noise std: 1.21
          Mean value_function loss: 10.8868
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 35.4110
                       Mean reward: 35.15
               Mean episode length: 241.35
    Episode_Reward/reaching_object: 0.7628
    Episode_Reward/rotating_object: 6.2967
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 1.94s
                      Time elapsed: 00:02:57
                               ETA: 01:05:11

################################################################################
                      [1m Learning iteration 65/1500 [0m                      

                       Computation: 51095 steps/s (collection: 1.823s, learning 0.101s)
             Mean action noise std: 1.22
          Mean value_function loss: 11.0832
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 35.4782
                       Mean reward: 29.20
               Mean episode length: 239.93
    Episode_Reward/reaching_object: 0.7613
    Episode_Reward/rotating_object: 6.2835
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 1.92s
                      Time elapsed: 00:02:58
                               ETA: 01:04:51

################################################################################
                      [1m Learning iteration 66/1500 [0m                      

                       Computation: 49596 steps/s (collection: 1.888s, learning 0.095s)
             Mean action noise std: 1.22
          Mean value_function loss: 11.7665
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 35.5421
                       Mean reward: 26.70
               Mean episode length: 228.36
    Episode_Reward/reaching_object: 0.7043
    Episode_Reward/rotating_object: 4.6343
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 11.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 1.98s
                      Time elapsed: 00:03:00
                               ETA: 01:04:32

################################################################################
                      [1m Learning iteration 67/1500 [0m                      

                       Computation: 48913 steps/s (collection: 1.915s, learning 0.095s)
             Mean action noise std: 1.22
          Mean value_function loss: 11.2766
               Mean surrogate loss: 0.0034
                 Mean entropy loss: 35.6012
                       Mean reward: 30.91
               Mean episode length: 242.35
    Episode_Reward/reaching_object: 0.6998
    Episode_Reward/rotating_object: 5.0554
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 2.01s
                      Time elapsed: 00:03:02
                               ETA: 01:04:15

################################################################################
                      [1m Learning iteration 68/1500 [0m                      

                       Computation: 50650 steps/s (collection: 1.846s, learning 0.095s)
             Mean action noise std: 1.22
          Mean value_function loss: 10.1172
               Mean surrogate loss: 0.0258
                 Mean entropy loss: 35.6388
                       Mean reward: 25.09
               Mean episode length: 243.23
    Episode_Reward/reaching_object: 0.7381
    Episode_Reward/rotating_object: 6.3597
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 1.94s
                      Time elapsed: 00:03:04
                               ETA: 01:03:57

################################################################################
                      [1m Learning iteration 69/1500 [0m                      

                       Computation: 49457 steps/s (collection: 1.841s, learning 0.146s)
             Mean action noise std: 1.22
          Mean value_function loss: 7.7774
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 35.6482
                       Mean reward: 28.16
               Mean episode length: 244.16
    Episode_Reward/reaching_object: 0.7318
    Episode_Reward/rotating_object: 5.3462
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 1.99s
                      Time elapsed: 00:03:06
                               ETA: 01:03:40

################################################################################
                      [1m Learning iteration 70/1500 [0m                      

                       Computation: 51580 steps/s (collection: 1.813s, learning 0.093s)
             Mean action noise std: 1.23
          Mean value_function loss: 8.0898
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 35.6720
                       Mean reward: 41.99
               Mean episode length: 234.49
    Episode_Reward/reaching_object: 0.7028
    Episode_Reward/rotating_object: 6.3784
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 1.91s
                      Time elapsed: 00:03:08
                               ETA: 01:03:22

################################################################################
                      [1m Learning iteration 71/1500 [0m                      

                       Computation: 51990 steps/s (collection: 1.770s, learning 0.121s)
             Mean action noise std: 1.23
          Mean value_function loss: 7.3237
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 35.7161
                       Mean reward: 37.66
               Mean episode length: 232.58
    Episode_Reward/reaching_object: 0.6913
    Episode_Reward/rotating_object: 7.0633
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 1.89s
                      Time elapsed: 00:03:10
                               ETA: 01:03:04

################################################################################
                      [1m Learning iteration 72/1500 [0m                      

                       Computation: 51310 steps/s (collection: 1.823s, learning 0.093s)
             Mean action noise std: 1.23
          Mean value_function loss: 9.5052
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 35.7569
                       Mean reward: 28.78
               Mean episode length: 242.31
    Episode_Reward/reaching_object: 0.6566
    Episode_Reward/rotating_object: 5.0269
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 1.92s
                      Time elapsed: 00:03:12
                               ETA: 01:02:47

################################################################################
                      [1m Learning iteration 73/1500 [0m                      

                       Computation: 51454 steps/s (collection: 1.789s, learning 0.122s)
             Mean action noise std: 1.23
          Mean value_function loss: 14.1488
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 35.7937
                       Mean reward: 27.10
               Mean episode length: 245.04
    Episode_Reward/reaching_object: 0.6651
    Episode_Reward/rotating_object: 7.1751
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 1.91s
                      Time elapsed: 00:03:14
                               ETA: 01:02:30

################################################################################
                      [1m Learning iteration 74/1500 [0m                      

                       Computation: 51455 steps/s (collection: 1.798s, learning 0.112s)
             Mean action noise std: 1.23
          Mean value_function loss: 19.6395
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 35.8249
                       Mean reward: 32.19
               Mean episode length: 245.89
    Episode_Reward/reaching_object: 0.6154
    Episode_Reward/rotating_object: 5.8166
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 1.91s
                      Time elapsed: 00:03:16
                               ETA: 01:02:14

################################################################################
                      [1m Learning iteration 75/1500 [0m                      

                       Computation: 50658 steps/s (collection: 1.851s, learning 0.089s)
             Mean action noise std: 1.24
          Mean value_function loss: 24.2084
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 35.8420
                       Mean reward: 38.10
               Mean episode length: 238.30
    Episode_Reward/reaching_object: 0.5997
    Episode_Reward/rotating_object: 6.3032
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 1.94s
                      Time elapsed: 00:03:18
                               ETA: 01:01:59

################################################################################
                      [1m Learning iteration 76/1500 [0m                      

                       Computation: 50426 steps/s (collection: 1.842s, learning 0.107s)
             Mean action noise std: 1.24
          Mean value_function loss: 19.8929
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 35.8722
                       Mean reward: 26.32
               Mean episode length: 243.97
    Episode_Reward/reaching_object: 0.5990
    Episode_Reward/rotating_object: 5.3796
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 1.95s
                      Time elapsed: 00:03:20
                               ETA: 01:01:44

################################################################################
                      [1m Learning iteration 77/1500 [0m                      

                       Computation: 50810 steps/s (collection: 1.831s, learning 0.104s)
             Mean action noise std: 1.24
          Mean value_function loss: 18.4951
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 35.9078
                       Mean reward: 46.53
               Mean episode length: 245.26
    Episode_Reward/reaching_object: 0.6078
    Episode_Reward/rotating_object: 7.1807
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 1.93s
                      Time elapsed: 00:03:22
                               ETA: 01:01:29

################################################################################
                      [1m Learning iteration 78/1500 [0m                      

                       Computation: 49693 steps/s (collection: 1.876s, learning 0.103s)
             Mean action noise std: 1.24
          Mean value_function loss: 16.9555
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 35.9362
                       Mean reward: 34.41
               Mean episode length: 242.37
    Episode_Reward/reaching_object: 0.6040
    Episode_Reward/rotating_object: 6.8476
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 1.98s
                      Time elapsed: 00:03:24
                               ETA: 01:01:15

################################################################################
                      [1m Learning iteration 79/1500 [0m                      

                       Computation: 50247 steps/s (collection: 1.858s, learning 0.099s)
             Mean action noise std: 1.24
          Mean value_function loss: 16.0899
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 35.9674
                       Mean reward: 36.69
               Mean episode length: 240.69
    Episode_Reward/reaching_object: 0.5865
    Episode_Reward/rotating_object: 6.9503
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 1.96s
                      Time elapsed: 00:03:26
                               ETA: 01:01:02

################################################################################
                      [1m Learning iteration 80/1500 [0m                      

                       Computation: 43749 steps/s (collection: 2.080s, learning 0.167s)
             Mean action noise std: 1.25
          Mean value_function loss: 16.3733
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 36.0168
                       Mean reward: 40.32
               Mean episode length: 240.90
    Episode_Reward/reaching_object: 0.6175
    Episode_Reward/rotating_object: 7.6700
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 2.25s
                      Time elapsed: 00:03:28
                               ETA: 01:00:53

################################################################################
                      [1m Learning iteration 81/1500 [0m                      

                       Computation: 42297 steps/s (collection: 2.194s, learning 0.130s)
             Mean action noise std: 1.25
          Mean value_function loss: 18.2525
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 36.0631
                       Mean reward: 36.10
               Mean episode length: 240.14
    Episode_Reward/reaching_object: 0.6219
    Episode_Reward/rotating_object: 7.3937
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 2.32s
                      Time elapsed: 00:03:30
                               ETA: 01:00:46

################################################################################
                      [1m Learning iteration 82/1500 [0m                      

                       Computation: 39368 steps/s (collection: 2.326s, learning 0.171s)
             Mean action noise std: 1.25
          Mean value_function loss: 22.8518
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 36.1024
                       Mean reward: 42.10
               Mean episode length: 241.15
    Episode_Reward/reaching_object: 0.6157
    Episode_Reward/rotating_object: 7.7929
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 2.50s
                      Time elapsed: 00:03:33
                               ETA: 01:00:43

################################################################################
                      [1m Learning iteration 83/1500 [0m                      

                       Computation: 42042 steps/s (collection: 2.157s, learning 0.182s)
             Mean action noise std: 1.25
          Mean value_function loss: 23.6073
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 36.1441
                       Mean reward: 31.07
               Mean episode length: 239.44
    Episode_Reward/reaching_object: 0.6182
    Episode_Reward/rotating_object: 5.8548
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 11.8750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 2.34s
                      Time elapsed: 00:03:35
                               ETA: 01:00:36

################################################################################
                      [1m Learning iteration 84/1500 [0m                      

                       Computation: 42644 steps/s (collection: 2.200s, learning 0.105s)
             Mean action noise std: 1.26
          Mean value_function loss: 23.8321
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 36.2034
                       Mean reward: 52.62
               Mean episode length: 236.80
    Episode_Reward/reaching_object: 0.6233
    Episode_Reward/rotating_object: 7.5540
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 2.31s
                      Time elapsed: 00:03:37
                               ETA: 01:00:29

################################################################################
                      [1m Learning iteration 85/1500 [0m                      

                       Computation: 49432 steps/s (collection: 1.866s, learning 0.123s)
             Mean action noise std: 1.26
          Mean value_function loss: 24.0436
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 36.2452
                       Mean reward: 38.61
               Mean episode length: 238.72
    Episode_Reward/reaching_object: 0.6070
    Episode_Reward/rotating_object: 6.7601
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 1.99s
                      Time elapsed: 00:03:39
                               ETA: 01:00:17

################################################################################
                      [1m Learning iteration 86/1500 [0m                      

                       Computation: 42940 steps/s (collection: 2.122s, learning 0.167s)
             Mean action noise std: 1.26
          Mean value_function loss: 24.1053
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 36.2913
                       Mean reward: 30.99
               Mean episode length: 241.03
    Episode_Reward/reaching_object: 0.6142
    Episode_Reward/rotating_object: 5.6311
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 2.29s
                      Time elapsed: 00:03:42
                               ETA: 01:00:10

################################################################################
                      [1m Learning iteration 87/1500 [0m                      

                       Computation: 45878 steps/s (collection: 2.033s, learning 0.110s)
             Mean action noise std: 1.27
          Mean value_function loss: 20.0619
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 36.3479
                       Mean reward: 38.24
               Mean episode length: 244.63
    Episode_Reward/reaching_object: 0.6360
    Episode_Reward/rotating_object: 6.6415
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 2.14s
                      Time elapsed: 00:03:44
                               ETA: 01:00:01

################################################################################
                      [1m Learning iteration 88/1500 [0m                      

                       Computation: 44327 steps/s (collection: 2.099s, learning 0.118s)
             Mean action noise std: 1.27
          Mean value_function loss: 19.4136
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 36.3936
                       Mean reward: 43.60
               Mean episode length: 244.40
    Episode_Reward/reaching_object: 0.6122
    Episode_Reward/rotating_object: 6.6569
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 2.22s
                      Time elapsed: 00:03:46
                               ETA: 00:59:53

################################################################################
                      [1m Learning iteration 89/1500 [0m                      

                       Computation: 49603 steps/s (collection: 1.874s, learning 0.108s)
             Mean action noise std: 1.27
          Mean value_function loss: 18.7699
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 36.4354
                       Mean reward: 39.23
               Mean episode length: 243.93
    Episode_Reward/reaching_object: 0.6225
    Episode_Reward/rotating_object: 7.1125
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 18.2083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 1.98s
                      Time elapsed: 00:03:48
                               ETA: 00:59:42

################################################################################
                      [1m Learning iteration 90/1500 [0m                      

                       Computation: 51099 steps/s (collection: 1.815s, learning 0.109s)
             Mean action noise std: 1.27
          Mean value_function loss: 16.0573
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 36.4746
                       Mean reward: 22.17
               Mean episode length: 242.16
    Episode_Reward/reaching_object: 0.5708
    Episode_Reward/rotating_object: 5.6216
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 1.92s
                      Time elapsed: 00:03:50
                               ETA: 00:59:30

################################################################################
                      [1m Learning iteration 91/1500 [0m                      

                       Computation: 51299 steps/s (collection: 1.818s, learning 0.098s)
             Mean action noise std: 1.27
          Mean value_function loss: 17.0745
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 36.5048
                       Mean reward: 47.06
               Mean episode length: 241.79
    Episode_Reward/reaching_object: 0.6053
    Episode_Reward/rotating_object: 7.0483
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 1.92s
                      Time elapsed: 00:03:52
                               ETA: 00:59:18

################################################################################
                      [1m Learning iteration 92/1500 [0m                      

                       Computation: 50901 steps/s (collection: 1.839s, learning 0.092s)
             Mean action noise std: 1.28
          Mean value_function loss: 18.9433
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 36.5321
                       Mean reward: 38.66
               Mean episode length: 236.41
    Episode_Reward/reaching_object: 0.5769
    Episode_Reward/rotating_object: 6.9294
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 1.93s
                      Time elapsed: 00:03:54
                               ETA: 00:59:06

################################################################################
                      [1m Learning iteration 93/1500 [0m                      

                       Computation: 50786 steps/s (collection: 1.845s, learning 0.091s)
             Mean action noise std: 1.28
          Mean value_function loss: 19.8501
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 36.5675
                       Mean reward: 37.73
               Mean episode length: 234.62
    Episode_Reward/reaching_object: 0.5756
    Episode_Reward/rotating_object: 6.3253
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 1.94s
                      Time elapsed: 00:03:56
                               ETA: 00:58:55

################################################################################
                      [1m Learning iteration 94/1500 [0m                      

                       Computation: 48917 steps/s (collection: 1.901s, learning 0.109s)
             Mean action noise std: 1.28
          Mean value_function loss: 21.8496
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 36.6030
                       Mean reward: 30.43
               Mean episode length: 234.92
    Episode_Reward/reaching_object: 0.5895
    Episode_Reward/rotating_object: 6.3929
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 2.01s
                      Time elapsed: 00:03:58
                               ETA: 00:58:45

################################################################################
                      [1m Learning iteration 95/1500 [0m                      

                       Computation: 50066 steps/s (collection: 1.866s, learning 0.098s)
             Mean action noise std: 1.28
          Mean value_function loss: 22.8363
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 36.6492
                       Mean reward: 43.99
               Mean episode length: 237.22
    Episode_Reward/reaching_object: 0.6005
    Episode_Reward/rotating_object: 6.8786
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 1.96s
                      Time elapsed: 00:04:00
                               ETA: 00:58:35

################################################################################
                      [1m Learning iteration 96/1500 [0m                      

                       Computation: 50204 steps/s (collection: 1.865s, learning 0.094s)
             Mean action noise std: 1.29
          Mean value_function loss: 21.4570
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 36.6930
                       Mean reward: 39.96
               Mean episode length: 242.66
    Episode_Reward/reaching_object: 0.5898
    Episode_Reward/rotating_object: 7.1960
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 1.96s
                      Time elapsed: 00:04:02
                               ETA: 00:58:24

################################################################################
                      [1m Learning iteration 97/1500 [0m                      

                       Computation: 50001 steps/s (collection: 1.870s, learning 0.096s)
             Mean action noise std: 1.29
          Mean value_function loss: 23.2460
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 36.7265
                       Mean reward: 46.50
               Mean episode length: 239.72
    Episode_Reward/reaching_object: 0.5797
    Episode_Reward/rotating_object: 6.8025
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 1.97s
                      Time elapsed: 00:04:04
                               ETA: 00:58:14

################################################################################
                      [1m Learning iteration 98/1500 [0m                      

                       Computation: 50725 steps/s (collection: 1.844s, learning 0.094s)
             Mean action noise std: 1.29
          Mean value_function loss: 19.0443
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 36.7598
                       Mean reward: 47.13
               Mean episode length: 236.02
    Episode_Reward/reaching_object: 0.5802
    Episode_Reward/rotating_object: 8.4167
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 1.94s
                      Time elapsed: 00:04:06
                               ETA: 00:58:04

################################################################################
                      [1m Learning iteration 99/1500 [0m                      

                       Computation: 48533 steps/s (collection: 1.929s, learning 0.096s)
             Mean action noise std: 1.29
          Mean value_function loss: 21.4652
               Mean surrogate loss: 0.0029
                 Mean entropy loss: 36.7946
                       Mean reward: 37.15
               Mean episode length: 233.83
    Episode_Reward/reaching_object: 0.5945
    Episode_Reward/rotating_object: 8.0655
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 2.03s
                      Time elapsed: 00:04:08
                               ETA: 00:57:55

################################################################################
                     [1m Learning iteration 100/1500 [0m                      

                       Computation: 51213 steps/s (collection: 1.811s, learning 0.108s)
             Mean action noise std: 1.29
          Mean value_function loss: 19.4467
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 36.8110
                       Mean reward: 40.18
               Mean episode length: 242.51
    Episode_Reward/reaching_object: 0.6078
    Episode_Reward/rotating_object: 7.2418
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 1.92s
                      Time elapsed: 00:04:09
                               ETA: 00:57:45

################################################################################
                     [1m Learning iteration 101/1500 [0m                      

                       Computation: 49679 steps/s (collection: 1.870s, learning 0.109s)
             Mean action noise std: 1.29
          Mean value_function loss: 18.2153
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 36.8529
                       Mean reward: 42.24
               Mean episode length: 238.42
    Episode_Reward/reaching_object: 0.6152
    Episode_Reward/rotating_object: 9.3362
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 1.98s
                      Time elapsed: 00:04:11
                               ETA: 00:57:35

################################################################################
                     [1m Learning iteration 102/1500 [0m                      

                       Computation: 49160 steps/s (collection: 1.887s, learning 0.113s)
             Mean action noise std: 1.30
          Mean value_function loss: 17.8519
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 36.8798
                       Mean reward: 36.51
               Mean episode length: 229.44
    Episode_Reward/reaching_object: 0.5801
    Episode_Reward/rotating_object: 7.7276
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 2.00s
                      Time elapsed: 00:04:13
                               ETA: 00:57:27

################################################################################
                     [1m Learning iteration 103/1500 [0m                      

                       Computation: 50575 steps/s (collection: 1.835s, learning 0.109s)
             Mean action noise std: 1.30
          Mean value_function loss: 17.8502
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 36.9155
                       Mean reward: 43.84
               Mean episode length: 237.91
    Episode_Reward/reaching_object: 0.5773
    Episode_Reward/rotating_object: 7.7958
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 11.9167
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 1.94s
                      Time elapsed: 00:04:15
                               ETA: 00:57:17

################################################################################
                     [1m Learning iteration 104/1500 [0m                      

                       Computation: 49435 steps/s (collection: 1.892s, learning 0.097s)
             Mean action noise std: 1.30
          Mean value_function loss: 19.0964
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 36.9676
                       Mean reward: 52.09
               Mean episode length: 236.40
    Episode_Reward/reaching_object: 0.5838
    Episode_Reward/rotating_object: 8.2889
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 1.99s
                      Time elapsed: 00:04:17
                               ETA: 00:57:08

################################################################################
                     [1m Learning iteration 105/1500 [0m                      

                       Computation: 47956 steps/s (collection: 1.937s, learning 0.113s)
             Mean action noise std: 1.31
          Mean value_function loss: 21.6933
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 37.0220
                       Mean reward: 42.40
               Mean episode length: 236.58
    Episode_Reward/reaching_object: 0.6074
    Episode_Reward/rotating_object: 7.9771
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 2.05s
                      Time elapsed: 00:04:19
                               ETA: 00:57:01

################################################################################
                     [1m Learning iteration 106/1500 [0m                      

                       Computation: 48394 steps/s (collection: 1.930s, learning 0.101s)
             Mean action noise std: 1.31
          Mean value_function loss: 19.8838
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 37.0589
                       Mean reward: 38.25
               Mean episode length: 230.68
    Episode_Reward/reaching_object: 0.5823
    Episode_Reward/rotating_object: 8.1312
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 2.03s
                      Time elapsed: 00:04:21
                               ETA: 00:56:53

################################################################################
                     [1m Learning iteration 107/1500 [0m                      

                       Computation: 50112 steps/s (collection: 1.865s, learning 0.097s)
             Mean action noise std: 1.31
          Mean value_function loss: 18.4051
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 37.0900
                       Mean reward: 31.73
               Mean episode length: 232.30
    Episode_Reward/reaching_object: 0.6029
    Episode_Reward/rotating_object: 8.0485
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 1.96s
                      Time elapsed: 00:04:23
                               ETA: 00:56:44

################################################################################
                     [1m Learning iteration 108/1500 [0m                      

                       Computation: 49632 steps/s (collection: 1.878s, learning 0.102s)
             Mean action noise std: 1.31
          Mean value_function loss: 17.3944
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 37.1268
                       Mean reward: 48.33
               Mean episode length: 236.29
    Episode_Reward/reaching_object: 0.5952
    Episode_Reward/rotating_object: 8.7380
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 1.98s
                      Time elapsed: 00:04:25
                               ETA: 00:56:36

################################################################################
                     [1m Learning iteration 109/1500 [0m                      

                       Computation: 49560 steps/s (collection: 1.891s, learning 0.093s)
             Mean action noise std: 1.31
          Mean value_function loss: 16.2794
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 37.1490
                       Mean reward: 46.19
               Mean episode length: 238.23
    Episode_Reward/reaching_object: 0.5911
    Episode_Reward/rotating_object: 7.4673
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 1.98s
                      Time elapsed: 00:04:27
                               ETA: 00:56:27

################################################################################
                     [1m Learning iteration 110/1500 [0m                      

                       Computation: 50687 steps/s (collection: 1.837s, learning 0.103s)
             Mean action noise std: 1.32
          Mean value_function loss: 17.4317
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 37.1915
                       Mean reward: 57.52
               Mean episode length: 238.49
    Episode_Reward/reaching_object: 0.5911
    Episode_Reward/rotating_object: 8.8536
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 1.94s
                      Time elapsed: 00:04:29
                               ETA: 00:56:19

################################################################################
                     [1m Learning iteration 111/1500 [0m                      

                       Computation: 50968 steps/s (collection: 1.818s, learning 0.111s)
             Mean action noise std: 1.32
          Mean value_function loss: 16.9366
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 37.2181
                       Mean reward: 28.44
               Mean episode length: 230.20
    Episode_Reward/reaching_object: 0.5705
    Episode_Reward/rotating_object: 6.0895
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 1.93s
                      Time elapsed: 00:04:31
                               ETA: 00:56:10

################################################################################
                     [1m Learning iteration 112/1500 [0m                      

                       Computation: 50930 steps/s (collection: 1.830s, learning 0.101s)
             Mean action noise std: 1.32
          Mean value_function loss: 17.5907
               Mean surrogate loss: 0.0052
                 Mean entropy loss: 37.2309
                       Mean reward: 27.82
               Mean episode length: 224.80
    Episode_Reward/reaching_object: 0.5585
    Episode_Reward/rotating_object: 7.3611
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 1.93s
                      Time elapsed: 00:04:33
                               ETA: 00:56:02

################################################################################
                     [1m Learning iteration 113/1500 [0m                      

                       Computation: 49215 steps/s (collection: 1.878s, learning 0.119s)
             Mean action noise std: 1.32
          Mean value_function loss: 18.6231
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 37.2372
                       Mean reward: 52.18
               Mean episode length: 229.19
    Episode_Reward/reaching_object: 0.5994
    Episode_Reward/rotating_object: 9.0282
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 11.8333
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 2.00s
                      Time elapsed: 00:04:35
                               ETA: 00:55:54

################################################################################
                     [1m Learning iteration 114/1500 [0m                      

                       Computation: 47977 steps/s (collection: 1.948s, learning 0.101s)
             Mean action noise std: 1.32
          Mean value_function loss: 19.0887
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 37.2810
                       Mean reward: 44.05
               Mean episode length: 227.83
    Episode_Reward/reaching_object: 0.5816
    Episode_Reward/rotating_object: 9.4091
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 2.05s
                      Time elapsed: 00:04:37
                               ETA: 00:55:47

################################################################################
                     [1m Learning iteration 115/1500 [0m                      

                       Computation: 51443 steps/s (collection: 1.818s, learning 0.093s)
             Mean action noise std: 1.32
          Mean value_function loss: 17.7147
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 37.3241
                       Mean reward: 59.78
               Mean episode length: 229.22
    Episode_Reward/reaching_object: 0.5651
    Episode_Reward/rotating_object: 9.3754
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 1.91s
                      Time elapsed: 00:04:39
                               ETA: 00:55:39

################################################################################
                     [1m Learning iteration 116/1500 [0m                      

                       Computation: 49688 steps/s (collection: 1.867s, learning 0.111s)
             Mean action noise std: 1.33
          Mean value_function loss: 19.2374
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 37.3614
                       Mean reward: 45.15
               Mean episode length: 229.26
    Episode_Reward/reaching_object: 0.5516
    Episode_Reward/rotating_object: 7.6853
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 1.98s
                      Time elapsed: 00:04:41
                               ETA: 00:55:31

################################################################################
                     [1m Learning iteration 117/1500 [0m                      

                       Computation: 48385 steps/s (collection: 1.913s, learning 0.119s)
             Mean action noise std: 1.33
          Mean value_function loss: 18.5521
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 37.3964
                       Mean reward: 42.13
               Mean episode length: 221.15
    Episode_Reward/reaching_object: 0.5675
    Episode_Reward/rotating_object: 9.9051
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 2.03s
                      Time elapsed: 00:04:43
                               ETA: 00:55:24

################################################################################
                     [1m Learning iteration 118/1500 [0m                      

                       Computation: 51421 steps/s (collection: 1.802s, learning 0.110s)
             Mean action noise std: 1.33
          Mean value_function loss: 20.2669
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 37.4243
                       Mean reward: 46.96
               Mean episode length: 224.76
    Episode_Reward/reaching_object: 0.5551
    Episode_Reward/rotating_object: 9.4568
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 1.91s
                      Time elapsed: 00:04:45
                               ETA: 00:55:16

################################################################################
                     [1m Learning iteration 119/1500 [0m                      

                       Computation: 50872 steps/s (collection: 1.841s, learning 0.091s)
             Mean action noise std: 1.33
          Mean value_function loss: 17.2512
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 37.4530
                       Mean reward: 54.54
               Mean episode length: 231.06
    Episode_Reward/reaching_object: 0.5601
    Episode_Reward/rotating_object: 9.4160
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 1.93s
                      Time elapsed: 00:04:47
                               ETA: 00:55:08

################################################################################
                     [1m Learning iteration 120/1500 [0m                      

                       Computation: 50353 steps/s (collection: 1.853s, learning 0.100s)
             Mean action noise std: 1.33
          Mean value_function loss: 17.8079
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 37.4905
                       Mean reward: 41.20
               Mean episode length: 217.66
    Episode_Reward/reaching_object: 0.5548
    Episode_Reward/rotating_object: 9.5419
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 1.95s
                      Time elapsed: 00:04:49
                               ETA: 00:55:01

################################################################################
                     [1m Learning iteration 121/1500 [0m                      

                       Computation: 51472 steps/s (collection: 1.815s, learning 0.095s)
             Mean action noise std: 1.34
          Mean value_function loss: 19.0227
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 37.5268
                       Mean reward: 49.07
               Mean episode length: 219.78
    Episode_Reward/reaching_object: 0.5506
    Episode_Reward/rotating_object: 8.5421
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 1.91s
                      Time elapsed: 00:04:51
                               ETA: 00:54:53

################################################################################
                     [1m Learning iteration 122/1500 [0m                      

                       Computation: 51554 steps/s (collection: 1.814s, learning 0.093s)
             Mean action noise std: 1.34
          Mean value_function loss: 21.0464
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 37.5615
                       Mean reward: 44.41
               Mean episode length: 213.65
    Episode_Reward/reaching_object: 0.5604
    Episode_Reward/rotating_object: 8.9597
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 11.8750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 1.91s
                      Time elapsed: 00:04:53
                               ETA: 00:54:45

################################################################################
                     [1m Learning iteration 123/1500 [0m                      

                       Computation: 49668 steps/s (collection: 1.880s, learning 0.099s)
             Mean action noise std: 1.34
          Mean value_function loss: 22.2209
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 37.5989
                       Mean reward: 46.22
               Mean episode length: 208.64
    Episode_Reward/reaching_object: 0.5365
    Episode_Reward/rotating_object: 9.7496
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 11.5833
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 1.98s
                      Time elapsed: 00:04:55
                               ETA: 00:54:38

################################################################################
                     [1m Learning iteration 124/1500 [0m                      

                       Computation: 51097 steps/s (collection: 1.822s, learning 0.102s)
             Mean action noise std: 1.34
          Mean value_function loss: 21.8562
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 37.6375
                       Mean reward: 37.59
               Mean episode length: 228.39
    Episode_Reward/reaching_object: 0.5502
    Episode_Reward/rotating_object: 8.0399
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 10.8750
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 1.92s
                      Time elapsed: 00:04:57
                               ETA: 00:54:31

################################################################################
                     [1m Learning iteration 125/1500 [0m                      

                       Computation: 51038 steps/s (collection: 1.832s, learning 0.094s)
             Mean action noise std: 1.34
          Mean value_function loss: 18.6918
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 37.6735
                       Mean reward: 43.57
               Mean episode length: 223.19
    Episode_Reward/reaching_object: 0.5576
    Episode_Reward/rotating_object: 7.9610
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 12.0417
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 1.93s
                      Time elapsed: 00:04:59
                               ETA: 00:54:24

################################################################################
                     [1m Learning iteration 126/1500 [0m                      

                       Computation: 52194 steps/s (collection: 1.785s, learning 0.099s)
             Mean action noise std: 1.35
          Mean value_function loss: 18.1161
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 37.7039
                       Mean reward: 40.91
               Mean episode length: 229.72
    Episode_Reward/reaching_object: 0.5698
    Episode_Reward/rotating_object: 8.8853
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 11.7917
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 1.88s
                      Time elapsed: 00:05:01
                               ETA: 00:54:16

################################################################################
                     [1m Learning iteration 127/1500 [0m                      

                       Computation: 50658 steps/s (collection: 1.837s, learning 0.104s)
             Mean action noise std: 1.35
          Mean value_function loss: 18.6684
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 37.7534
                       Mean reward: 38.79
               Mean episode length: 230.93
    Episode_Reward/reaching_object: 0.5695
    Episode_Reward/rotating_object: 8.9932
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 1.94s
                      Time elapsed: 00:05:02
                               ETA: 00:54:09

################################################################################
                     [1m Learning iteration 128/1500 [0m                      

                       Computation: 52323 steps/s (collection: 1.785s, learning 0.093s)
             Mean action noise std: 1.35
          Mean value_function loss: 18.8977
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 37.7901
                       Mean reward: 24.29
               Mean episode length: 230.37
    Episode_Reward/reaching_object: 0.5367
    Episode_Reward/rotating_object: 6.9544
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 11.5000
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 1.88s
                      Time elapsed: 00:05:04
                               ETA: 00:54:01

################################################################################
                     [1m Learning iteration 129/1500 [0m                      

                       Computation: 51754 steps/s (collection: 1.804s, learning 0.096s)
             Mean action noise std: 1.35
          Mean value_function loss: 14.6927
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 37.8167
                       Mean reward: 50.62
               Mean episode length: 235.85
    Episode_Reward/reaching_object: 0.5823
    Episode_Reward/rotating_object: 9.7573
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 1.90s
                      Time elapsed: 00:05:06
                               ETA: 00:53:54

################################################################################
                     [1m Learning iteration 130/1500 [0m                      

                       Computation: 51325 steps/s (collection: 1.823s, learning 0.092s)
             Mean action noise std: 1.36
          Mean value_function loss: 15.7705
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 37.8492
                       Mean reward: 27.87
               Mean episode length: 233.67
    Episode_Reward/reaching_object: 0.5273
    Episode_Reward/rotating_object: 6.6853
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 1.92s
                      Time elapsed: 00:05:08
                               ETA: 00:53:47

################################################################################
                     [1m Learning iteration 131/1500 [0m                      

                       Computation: 52158 steps/s (collection: 1.797s, learning 0.088s)
             Mean action noise std: 1.36
          Mean value_function loss: 15.1292
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 37.8769
                       Mean reward: 30.06
               Mean episode length: 224.76
    Episode_Reward/reaching_object: 0.5416
    Episode_Reward/rotating_object: 8.7066
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 1.88s
                      Time elapsed: 00:05:10
                               ETA: 00:53:40

################################################################################
                     [1m Learning iteration 132/1500 [0m                      

                       Computation: 51764 steps/s (collection: 1.784s, learning 0.115s)
             Mean action noise std: 1.36
          Mean value_function loss: 18.0070
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 37.9048
                       Mean reward: 48.70
               Mean episode length: 233.48
    Episode_Reward/reaching_object: 0.5482
    Episode_Reward/rotating_object: 9.4652
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 1.90s
                      Time elapsed: 00:05:12
                               ETA: 00:53:33

################################################################################
                     [1m Learning iteration 133/1500 [0m                      

                       Computation: 51798 steps/s (collection: 1.791s, learning 0.107s)
             Mean action noise std: 1.36
          Mean value_function loss: 18.2806
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 37.9317
                       Mean reward: 45.41
               Mean episode length: 236.15
    Episode_Reward/reaching_object: 0.5681
    Episode_Reward/rotating_object: 9.1743
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 1.90s
                      Time elapsed: 00:05:14
                               ETA: 00:53:26

################################################################################
                     [1m Learning iteration 134/1500 [0m                      

                       Computation: 51871 steps/s (collection: 1.798s, learning 0.098s)
             Mean action noise std: 1.36
          Mean value_function loss: 16.9962
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 37.9713
                       Mean reward: 37.30
               Mean episode length: 232.68
    Episode_Reward/reaching_object: 0.5437
    Episode_Reward/rotating_object: 7.9446
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 1.90s
                      Time elapsed: 00:05:16
                               ETA: 00:53:19

################################################################################
                     [1m Learning iteration 135/1500 [0m                      

                       Computation: 50886 steps/s (collection: 1.807s, learning 0.125s)
             Mean action noise std: 1.37
          Mean value_function loss: 18.2037
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 37.9998
                       Mean reward: 39.15
               Mean episode length: 235.24
    Episode_Reward/reaching_object: 0.5424
    Episode_Reward/rotating_object: 9.0262
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 1.93s
                      Time elapsed: 00:05:18
                               ETA: 00:53:13

################################################################################
                     [1m Learning iteration 136/1500 [0m                      

                       Computation: 50564 steps/s (collection: 1.845s, learning 0.099s)
             Mean action noise std: 1.37
          Mean value_function loss: 17.2133
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 38.0419
                       Mean reward: 46.30
               Mean episode length: 233.34
    Episode_Reward/reaching_object: 0.5628
    Episode_Reward/rotating_object: 8.2468
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 1.94s
                      Time elapsed: 00:05:20
                               ETA: 00:53:06

################################################################################
                     [1m Learning iteration 137/1500 [0m                      

                       Computation: 50201 steps/s (collection: 1.862s, learning 0.096s)
             Mean action noise std: 1.37
          Mean value_function loss: 16.9365
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 38.0829
                       Mean reward: 44.80
               Mean episode length: 233.36
    Episode_Reward/reaching_object: 0.5666
    Episode_Reward/rotating_object: 9.2544
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 1.96s
                      Time elapsed: 00:05:22
                               ETA: 00:53:00

################################################################################
                     [1m Learning iteration 138/1500 [0m                      

                       Computation: 50680 steps/s (collection: 1.845s, learning 0.095s)
             Mean action noise std: 1.37
          Mean value_function loss: 17.8932
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 38.1277
                       Mean reward: 37.93
               Mean episode length: 230.35
    Episode_Reward/reaching_object: 0.5613
    Episode_Reward/rotating_object: 7.2432
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 1.94s
                      Time elapsed: 00:05:23
                               ETA: 00:52:54

################################################################################
                     [1m Learning iteration 139/1500 [0m                      

                       Computation: 50449 steps/s (collection: 1.846s, learning 0.103s)
             Mean action noise std: 1.38
          Mean value_function loss: 18.0126
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 38.1766
                       Mean reward: 50.15
               Mean episode length: 231.94
    Episode_Reward/reaching_object: 0.5663
    Episode_Reward/rotating_object: 7.6033
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 1.95s
                      Time elapsed: 00:05:25
                               ETA: 00:52:48

################################################################################
                     [1m Learning iteration 140/1500 [0m                      

                       Computation: 51264 steps/s (collection: 1.821s, learning 0.097s)
             Mean action noise std: 1.38
          Mean value_function loss: 17.4120
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 38.2064
                       Mean reward: 35.77
               Mean episode length: 228.42
    Episode_Reward/reaching_object: 0.5958
    Episode_Reward/rotating_object: 8.1852
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 1.92s
                      Time elapsed: 00:05:27
                               ETA: 00:52:42

################################################################################
                     [1m Learning iteration 141/1500 [0m                      

                       Computation: 51239 steps/s (collection: 1.822s, learning 0.096s)
             Mean action noise std: 1.38
          Mean value_function loss: 19.2609
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 38.2322
                       Mean reward: 57.99
               Mean episode length: 226.18
    Episode_Reward/reaching_object: 0.5889
    Episode_Reward/rotating_object: 9.1080
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 1.92s
                      Time elapsed: 00:05:29
                               ETA: 00:52:36

################################################################################
                     [1m Learning iteration 142/1500 [0m                      

                       Computation: 51232 steps/s (collection: 1.823s, learning 0.096s)
             Mean action noise std: 1.38
          Mean value_function loss: 19.2038
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 38.2737
                       Mean reward: 41.68
               Mean episode length: 224.08
    Episode_Reward/reaching_object: 0.5743
    Episode_Reward/rotating_object: 8.3329
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 1.92s
                      Time elapsed: 00:05:31
                               ETA: 00:52:29

################################################################################
                     [1m Learning iteration 143/1500 [0m                      

                       Computation: 50327 steps/s (collection: 1.862s, learning 0.092s)
             Mean action noise std: 1.39
          Mean value_function loss: 22.6400
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 38.3240
                       Mean reward: 43.69
               Mean episode length: 233.50
    Episode_Reward/reaching_object: 0.6046
    Episode_Reward/rotating_object: 9.3050
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 1.95s
                      Time elapsed: 00:05:33
                               ETA: 00:52:24

################################################################################
                     [1m Learning iteration 144/1500 [0m                      

                       Computation: 51704 steps/s (collection: 1.810s, learning 0.091s)
             Mean action noise std: 1.39
          Mean value_function loss: 21.2256
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 38.3634
                       Mean reward: 41.87
               Mean episode length: 232.13
    Episode_Reward/reaching_object: 0.6304
    Episode_Reward/rotating_object: 9.7730
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 1.90s
                      Time elapsed: 00:05:35
                               ETA: 00:52:17

################################################################################
                     [1m Learning iteration 145/1500 [0m                      

                       Computation: 51585 steps/s (collection: 1.815s, learning 0.091s)
             Mean action noise std: 1.39
          Mean value_function loss: 19.9389
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 38.4031
                       Mean reward: 49.66
               Mean episode length: 229.54
    Episode_Reward/reaching_object: 0.6054
    Episode_Reward/rotating_object: 9.9867
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 11.3333
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 1.91s
                      Time elapsed: 00:05:37
                               ETA: 00:52:11

################################################################################
                     [1m Learning iteration 146/1500 [0m                      

                       Computation: 51707 steps/s (collection: 1.812s, learning 0.089s)
             Mean action noise std: 1.39
          Mean value_function loss: 22.3030
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 38.4402
                       Mean reward: 40.68
               Mean episode length: 231.18
    Episode_Reward/reaching_object: 0.6077
    Episode_Reward/rotating_object: 8.1373
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 12.0417
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 1.90s
                      Time elapsed: 00:05:39
                               ETA: 00:52:05

################################################################################
                     [1m Learning iteration 147/1500 [0m                      

                       Computation: 52022 steps/s (collection: 1.790s, learning 0.100s)
             Mean action noise std: 1.39
          Mean value_function loss: 22.3660
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 38.4746
                       Mean reward: 54.33
               Mean episode length: 229.98
    Episode_Reward/reaching_object: 0.6378
    Episode_Reward/rotating_object: 11.9360
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 12.0000
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 1.89s
                      Time elapsed: 00:05:41
                               ETA: 00:51:59

################################################################################
                     [1m Learning iteration 148/1500 [0m                      

                       Computation: 51256 steps/s (collection: 1.814s, learning 0.104s)
             Mean action noise std: 1.40
          Mean value_function loss: 20.7810
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 38.5013
                       Mean reward: 49.26
               Mean episode length: 221.42
    Episode_Reward/reaching_object: 0.6224
    Episode_Reward/rotating_object: 8.5914
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 1.92s
                      Time elapsed: 00:05:43
                               ETA: 00:51:53

################################################################################
                     [1m Learning iteration 149/1500 [0m                      

                       Computation: 49729 steps/s (collection: 1.872s, learning 0.105s)
             Mean action noise std: 1.40
          Mean value_function loss: 22.6136
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 38.5187
                       Mean reward: 48.79
               Mean episode length: 219.87
    Episode_Reward/reaching_object: 0.6277
    Episode_Reward/rotating_object: 9.2486
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 1.98s
                      Time elapsed: 00:05:45
                               ETA: 00:51:48

################################################################################
                     [1m Learning iteration 150/1500 [0m                      

                       Computation: 49792 steps/s (collection: 1.860s, learning 0.114s)
             Mean action noise std: 1.40
          Mean value_function loss: 22.2090
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 38.5463
                       Mean reward: 65.14
               Mean episode length: 231.43
    Episode_Reward/reaching_object: 0.6503
    Episode_Reward/rotating_object: 12.0411
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 1.97s
                      Time elapsed: 00:05:47
                               ETA: 00:51:43

################################################################################
                     [1m Learning iteration 151/1500 [0m                      

                       Computation: 51488 steps/s (collection: 1.811s, learning 0.098s)
             Mean action noise std: 1.40
          Mean value_function loss: 25.3081
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 38.5808
                       Mean reward: 64.94
               Mean episode length: 226.95
    Episode_Reward/reaching_object: 0.6432
    Episode_Reward/rotating_object: 11.4299
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 1.91s
                      Time elapsed: 00:05:49
                               ETA: 00:51:37

################################################################################
                     [1m Learning iteration 152/1500 [0m                      

                       Computation: 51350 steps/s (collection: 1.816s, learning 0.098s)
             Mean action noise std: 1.41
          Mean value_function loss: 27.8654
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 38.6317
                       Mean reward: 62.02
               Mean episode length: 224.57
    Episode_Reward/reaching_object: 0.6333
    Episode_Reward/rotating_object: 10.6140
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 1.91s
                      Time elapsed: 00:05:50
                               ETA: 00:51:31

################################################################################
                     [1m Learning iteration 153/1500 [0m                      

                       Computation: 50327 steps/s (collection: 1.852s, learning 0.102s)
             Mean action noise std: 1.41
          Mean value_function loss: 26.7082
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 38.6730
                       Mean reward: 49.70
               Mean episode length: 231.58
    Episode_Reward/reaching_object: 0.6202
    Episode_Reward/rotating_object: 9.8909
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 1.95s
                      Time elapsed: 00:05:52
                               ETA: 00:51:26

################################################################################
                     [1m Learning iteration 154/1500 [0m                      

                       Computation: 51457 steps/s (collection: 1.816s, learning 0.095s)
             Mean action noise std: 1.41
          Mean value_function loss: 22.2722
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 38.6976
                       Mean reward: 83.74
               Mean episode length: 219.45
    Episode_Reward/reaching_object: 0.6370
    Episode_Reward/rotating_object: 12.5706
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 1.91s
                      Time elapsed: 00:05:54
                               ETA: 00:51:21

################################################################################
                     [1m Learning iteration 155/1500 [0m                      

                       Computation: 49311 steps/s (collection: 1.896s, learning 0.097s)
             Mean action noise std: 1.41
          Mean value_function loss: 23.7356
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 38.7370
                       Mean reward: 59.12
               Mean episode length: 229.99
    Episode_Reward/reaching_object: 0.6466
    Episode_Reward/rotating_object: 10.1008
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 1.99s
                      Time elapsed: 00:05:56
                               ETA: 00:51:16

################################################################################
                     [1m Learning iteration 156/1500 [0m                      

                       Computation: 51072 steps/s (collection: 1.835s, learning 0.090s)
             Mean action noise std: 1.41
          Mean value_function loss: 30.4622
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 38.7676
                       Mean reward: 69.49
               Mean episode length: 226.50
    Episode_Reward/reaching_object: 0.6343
    Episode_Reward/rotating_object: 13.5462
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 12.2083
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 1.92s
                      Time elapsed: 00:05:58
                               ETA: 00:51:10

################################################################################
                     [1m Learning iteration 157/1500 [0m                      

                       Computation: 51056 steps/s (collection: 1.826s, learning 0.099s)
             Mean action noise std: 1.42
          Mean value_function loss: 28.4591
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 38.7982
                       Mean reward: 55.78
               Mean episode length: 218.43
    Episode_Reward/reaching_object: 0.6293
    Episode_Reward/rotating_object: 11.8821
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 11.2083
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 1.93s
                      Time elapsed: 00:06:00
                               ETA: 00:51:05

################################################################################
                     [1m Learning iteration 158/1500 [0m                      

                       Computation: 51412 steps/s (collection: 1.821s, learning 0.091s)
             Mean action noise std: 1.42
          Mean value_function loss: 30.6776
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 38.8464
                       Mean reward: 55.08
               Mean episode length: 225.11
    Episode_Reward/reaching_object: 0.6219
    Episode_Reward/rotating_object: 10.6703
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 1.91s
                      Time elapsed: 00:06:02
                               ETA: 00:51:00

################################################################################
                     [1m Learning iteration 159/1500 [0m                      

                       Computation: 51538 steps/s (collection: 1.814s, learning 0.093s)
             Mean action noise std: 1.42
          Mean value_function loss: 29.8569
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 38.8717
                       Mean reward: 69.64
               Mean episode length: 227.52
    Episode_Reward/reaching_object: 0.6299
    Episode_Reward/rotating_object: 12.3000
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 1.91s
                      Time elapsed: 00:06:04
                               ETA: 00:50:54

################################################################################
                     [1m Learning iteration 160/1500 [0m                      

                       Computation: 51097 steps/s (collection: 1.821s, learning 0.103s)
             Mean action noise std: 1.42
          Mean value_function loss: 30.4322
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 38.9039
                       Mean reward: 75.58
               Mean episode length: 219.49
    Episode_Reward/reaching_object: 0.6338
    Episode_Reward/rotating_object: 14.4694
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 1.92s
                      Time elapsed: 00:06:06
                               ETA: 00:50:49

################################################################################
                     [1m Learning iteration 161/1500 [0m                      

                       Computation: 51418 steps/s (collection: 1.815s, learning 0.097s)
             Mean action noise std: 1.42
          Mean value_function loss: 25.4117
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 38.9306
                       Mean reward: 83.22
               Mean episode length: 222.14
    Episode_Reward/reaching_object: 0.6277
    Episode_Reward/rotating_object: 13.1898
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 1.91s
                      Time elapsed: 00:06:08
                               ETA: 00:50:44

################################################################################
                     [1m Learning iteration 162/1500 [0m                      

                       Computation: 50576 steps/s (collection: 1.844s, learning 0.100s)
             Mean action noise std: 1.43
          Mean value_function loss: 29.7190
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 38.9747
                       Mean reward: 59.25
               Mean episode length: 225.48
    Episode_Reward/reaching_object: 0.6610
    Episode_Reward/rotating_object: 11.7829
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 1.94s
                      Time elapsed: 00:06:10
                               ETA: 00:50:39

################################################################################
                     [1m Learning iteration 163/1500 [0m                      

                       Computation: 50576 steps/s (collection: 1.824s, learning 0.119s)
             Mean action noise std: 1.43
          Mean value_function loss: 32.8044
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 39.0161
                       Mean reward: 73.56
               Mean episode length: 222.73
    Episode_Reward/reaching_object: 0.6300
    Episode_Reward/rotating_object: 13.0278
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 1.94s
                      Time elapsed: 00:06:12
                               ETA: 00:50:34

################################################################################
                     [1m Learning iteration 164/1500 [0m                      

                       Computation: 50765 steps/s (collection: 1.833s, learning 0.104s)
             Mean action noise std: 1.43
          Mean value_function loss: 35.4401
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 39.0526
                       Mean reward: 57.68
               Mean episode length: 229.14
    Episode_Reward/reaching_object: 0.6418
    Episode_Reward/rotating_object: 12.8267
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 1.94s
                      Time elapsed: 00:06:14
                               ETA: 00:50:29

################################################################################
                     [1m Learning iteration 165/1500 [0m                      

                       Computation: 50961 steps/s (collection: 1.812s, learning 0.117s)
             Mean action noise std: 1.43
          Mean value_function loss: 35.4051
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 39.0808
                       Mean reward: 76.06
               Mean episode length: 215.60
    Episode_Reward/reaching_object: 0.6204
    Episode_Reward/rotating_object: 12.7040
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 1.93s
                      Time elapsed: 00:06:16
                               ETA: 00:50:24

################################################################################
                     [1m Learning iteration 166/1500 [0m                      

                       Computation: 51081 steps/s (collection: 1.829s, learning 0.095s)
             Mean action noise std: 1.44
          Mean value_function loss: 34.2339
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 39.1218
                       Mean reward: 48.98
               Mean episode length: 215.03
    Episode_Reward/reaching_object: 0.6022
    Episode_Reward/rotating_object: 12.8833
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 10.9583
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 1.92s
                      Time elapsed: 00:06:17
                               ETA: 00:50:19

################################################################################
                     [1m Learning iteration 167/1500 [0m                      

                       Computation: 52044 steps/s (collection: 1.795s, learning 0.094s)
             Mean action noise std: 1.44
          Mean value_function loss: 34.0758
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 39.1504
                       Mean reward: 77.11
               Mean episode length: 229.72
    Episode_Reward/reaching_object: 0.6131
    Episode_Reward/rotating_object: 12.4789
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 1.89s
                      Time elapsed: 00:06:19
                               ETA: 00:50:14

################################################################################
                     [1m Learning iteration 168/1500 [0m                      

                       Computation: 50899 steps/s (collection: 1.837s, learning 0.094s)
             Mean action noise std: 1.44
          Mean value_function loss: 37.2964
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 39.1785
                       Mean reward: 65.32
               Mean episode length: 231.26
    Episode_Reward/reaching_object: 0.6190
    Episode_Reward/rotating_object: 11.8708
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 1.93s
                      Time elapsed: 00:06:21
                               ETA: 00:50:09

################################################################################
                     [1m Learning iteration 169/1500 [0m                      

                       Computation: 51771 steps/s (collection: 1.806s, learning 0.093s)
             Mean action noise std: 1.44
          Mean value_function loss: 44.0141
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 39.2132
                       Mean reward: 90.58
               Mean episode length: 219.61
    Episode_Reward/reaching_object: 0.6301
    Episode_Reward/rotating_object: 13.6919
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 11.8333
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 1.90s
                      Time elapsed: 00:06:23
                               ETA: 00:50:04

################################################################################
                     [1m Learning iteration 170/1500 [0m                      

                       Computation: 51833 steps/s (collection: 1.804s, learning 0.093s)
             Mean action noise std: 1.45
          Mean value_function loss: 43.0397
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 39.2431
                       Mean reward: 82.70
               Mean episode length: 219.83
    Episode_Reward/reaching_object: 0.6184
    Episode_Reward/rotating_object: 14.0128
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.8750
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 1.90s
                      Time elapsed: 00:06:25
                               ETA: 00:49:59

################################################################################
                     [1m Learning iteration 171/1500 [0m                      

                       Computation: 51164 steps/s (collection: 1.820s, learning 0.102s)
             Mean action noise std: 1.45
          Mean value_function loss: 40.3592
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 39.2801
                       Mean reward: 77.14
               Mean episode length: 209.47
    Episode_Reward/reaching_object: 0.6194
    Episode_Reward/rotating_object: 13.5451
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 1.92s
                      Time elapsed: 00:06:27
                               ETA: 00:49:54

################################################################################
                     [1m Learning iteration 172/1500 [0m                      

                       Computation: 50460 steps/s (collection: 1.850s, learning 0.098s)
             Mean action noise std: 1.45
          Mean value_function loss: 43.2831
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 39.3217
                       Mean reward: 63.62
               Mean episode length: 216.25
    Episode_Reward/reaching_object: 0.5955
    Episode_Reward/rotating_object: 14.1729
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 1.95s
                      Time elapsed: 00:06:29
                               ETA: 00:49:49

################################################################################
                     [1m Learning iteration 173/1500 [0m                      

                       Computation: 49378 steps/s (collection: 1.878s, learning 0.112s)
             Mean action noise std: 1.45
          Mean value_function loss: 36.7201
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 39.3487
                       Mean reward: 71.82
               Mean episode length: 224.18
    Episode_Reward/reaching_object: 0.6387
    Episode_Reward/rotating_object: 15.5370
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 1.99s
                      Time elapsed: 00:06:31
                               ETA: 00:49:45

################################################################################
                     [1m Learning iteration 174/1500 [0m                      

                       Computation: 48360 steps/s (collection: 1.886s, learning 0.147s)
             Mean action noise std: 1.45
          Mean value_function loss: 38.2269
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 39.3755
                       Mean reward: 82.49
               Mean episode length: 213.67
    Episode_Reward/reaching_object: 0.6481
    Episode_Reward/rotating_object: 16.0754
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 2.03s
                      Time elapsed: 00:06:33
                               ETA: 00:49:41

################################################################################
                     [1m Learning iteration 175/1500 [0m                      

                       Computation: 49526 steps/s (collection: 1.860s, learning 0.125s)
             Mean action noise std: 1.46
          Mean value_function loss: 36.7094
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 39.3989
                       Mean reward: 77.58
               Mean episode length: 221.26
    Episode_Reward/reaching_object: 0.6454
    Episode_Reward/rotating_object: 14.9422
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 1.98s
                      Time elapsed: 00:06:35
                               ETA: 00:49:37

################################################################################
                     [1m Learning iteration 176/1500 [0m                      

                       Computation: 50713 steps/s (collection: 1.837s, learning 0.102s)
             Mean action noise std: 1.46
          Mean value_function loss: 36.0972
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 39.4319
                       Mean reward: 73.36
               Mean episode length: 212.21
    Episode_Reward/reaching_object: 0.6583
    Episode_Reward/rotating_object: 16.1040
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 1.94s
                      Time elapsed: 00:06:37
                               ETA: 00:49:32

################################################################################
                     [1m Learning iteration 177/1500 [0m                      

                       Computation: 50265 steps/s (collection: 1.855s, learning 0.100s)
             Mean action noise std: 1.46
          Mean value_function loss: 32.5427
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 39.4685
                       Mean reward: 70.38
               Mean episode length: 213.82
    Episode_Reward/reaching_object: 0.6368
    Episode_Reward/rotating_object: 14.8629
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 1.96s
                      Time elapsed: 00:06:39
                               ETA: 00:49:28

################################################################################
                     [1m Learning iteration 178/1500 [0m                      

                       Computation: 47693 steps/s (collection: 1.953s, learning 0.108s)
             Mean action noise std: 1.46
          Mean value_function loss: 30.1709
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 39.5105
                       Mean reward: 92.27
               Mean episode length: 232.02
    Episode_Reward/reaching_object: 0.6758
    Episode_Reward/rotating_object: 14.8119
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 2.06s
                      Time elapsed: 00:06:41
                               ETA: 00:49:24

################################################################################
                     [1m Learning iteration 179/1500 [0m                      

                       Computation: 50146 steps/s (collection: 1.848s, learning 0.112s)
             Mean action noise std: 1.47
          Mean value_function loss: 33.2313
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 39.5444
                       Mean reward: 82.76
               Mean episode length: 212.91
    Episode_Reward/reaching_object: 0.6195
    Episode_Reward/rotating_object: 14.0339
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 1.96s
                      Time elapsed: 00:06:43
                               ETA: 00:49:20

################################################################################
                     [1m Learning iteration 180/1500 [0m                      

                       Computation: 46365 steps/s (collection: 1.966s, learning 0.155s)
             Mean action noise std: 1.47
          Mean value_function loss: 35.1090
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 39.5673
                       Mean reward: 97.81
               Mean episode length: 217.95
    Episode_Reward/reaching_object: 0.6450
    Episode_Reward/rotating_object: 16.1482
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 2.12s
                      Time elapsed: 00:06:45
                               ETA: 00:49:17

################################################################################
                     [1m Learning iteration 181/1500 [0m                      

                       Computation: 47345 steps/s (collection: 1.953s, learning 0.124s)
             Mean action noise std: 1.47
          Mean value_function loss: 38.7877
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 39.5942
                       Mean reward: 98.25
               Mean episode length: 220.61
    Episode_Reward/reaching_object: 0.6563
    Episode_Reward/rotating_object: 15.8286
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 2.08s
                      Time elapsed: 00:06:47
                               ETA: 00:49:13

################################################################################
                     [1m Learning iteration 182/1500 [0m                      

                       Computation: 47735 steps/s (collection: 1.951s, learning 0.108s)
             Mean action noise std: 1.47
          Mean value_function loss: 41.3154
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 39.6355
                       Mean reward: 81.02
               Mean episode length: 224.05
    Episode_Reward/reaching_object: 0.6528
    Episode_Reward/rotating_object: 14.8667
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 2.06s
                      Time elapsed: 00:06:49
                               ETA: 00:49:10

################################################################################
                     [1m Learning iteration 183/1500 [0m                      

                       Computation: 50719 steps/s (collection: 1.829s, learning 0.109s)
             Mean action noise std: 1.47
          Mean value_function loss: 40.8889
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 39.6695
                       Mean reward: 69.92
               Mean episode length: 226.30
    Episode_Reward/reaching_object: 0.6462
    Episode_Reward/rotating_object: 14.4137
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 1.94s
                      Time elapsed: 00:06:51
                               ETA: 00:49:05

################################################################################
                     [1m Learning iteration 184/1500 [0m                      

                       Computation: 49741 steps/s (collection: 1.864s, learning 0.112s)
             Mean action noise std: 1.48
          Mean value_function loss: 44.8732
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 39.6962
                       Mean reward: 78.95
               Mean episode length: 226.80
    Episode_Reward/reaching_object: 0.6359
    Episode_Reward/rotating_object: 15.0902
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 1.98s
                      Time elapsed: 00:06:53
                               ETA: 00:49:01

################################################################################
                     [1m Learning iteration 185/1500 [0m                      

                       Computation: 49200 steps/s (collection: 1.881s, learning 0.117s)
             Mean action noise std: 1.48
          Mean value_function loss: 42.2148
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 39.7223
                       Mean reward: 74.10
               Mean episode length: 213.38
    Episode_Reward/reaching_object: 0.6393
    Episode_Reward/rotating_object: 16.7961
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 2.00s
                      Time elapsed: 00:06:55
                               ETA: 00:48:57

################################################################################
                     [1m Learning iteration 186/1500 [0m                      

                       Computation: 47246 steps/s (collection: 1.931s, learning 0.150s)
             Mean action noise std: 1.48
          Mean value_function loss: 44.3161
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 39.7518
                       Mean reward: 79.12
               Mean episode length: 217.33
    Episode_Reward/reaching_object: 0.6686
    Episode_Reward/rotating_object: 18.5796
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 2.08s
                      Time elapsed: 00:06:57
                               ETA: 00:48:54

################################################################################
                     [1m Learning iteration 187/1500 [0m                      

                       Computation: 48268 steps/s (collection: 1.947s, learning 0.090s)
             Mean action noise std: 1.48
          Mean value_function loss: 50.3516
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 39.7943
                       Mean reward: 96.71
               Mean episode length: 223.92
    Episode_Reward/reaching_object: 0.6606
    Episode_Reward/rotating_object: 16.7295
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 2.04s
                      Time elapsed: 00:06:59
                               ETA: 00:48:50

################################################################################
                     [1m Learning iteration 188/1500 [0m                      

                       Computation: 49108 steps/s (collection: 1.899s, learning 0.103s)
             Mean action noise std: 1.48
          Mean value_function loss: 45.7685
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 39.8311
                       Mean reward: 75.67
               Mean episode length: 212.57
    Episode_Reward/reaching_object: 0.6249
    Episode_Reward/rotating_object: 17.0329
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 2.00s
                      Time elapsed: 00:07:01
                               ETA: 00:48:47

################################################################################
                     [1m Learning iteration 189/1500 [0m                      

                       Computation: 48651 steps/s (collection: 1.921s, learning 0.100s)
             Mean action noise std: 1.49
          Mean value_function loss: 46.2081
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 39.8577
                       Mean reward: 114.92
               Mean episode length: 223.94
    Episode_Reward/reaching_object: 0.6563
    Episode_Reward/rotating_object: 20.4509
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 2.02s
                      Time elapsed: 00:07:03
                               ETA: 00:48:43

################################################################################
                     [1m Learning iteration 190/1500 [0m                      

                       Computation: 47337 steps/s (collection: 1.985s, learning 0.092s)
             Mean action noise std: 1.49
          Mean value_function loss: 48.7467
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 39.8858
                       Mean reward: 98.41
               Mean episode length: 223.93
    Episode_Reward/reaching_object: 0.6569
    Episode_Reward/rotating_object: 19.5746
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 2.08s
                      Time elapsed: 00:07:05
                               ETA: 00:48:40

################################################################################
                     [1m Learning iteration 191/1500 [0m                      

                       Computation: 49167 steps/s (collection: 1.890s, learning 0.109s)
             Mean action noise std: 1.49
          Mean value_function loss: 46.5607
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 39.9183
                       Mean reward: 112.03
               Mean episode length: 217.20
    Episode_Reward/reaching_object: 0.6503
    Episode_Reward/rotating_object: 19.1463
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 2.00s
                      Time elapsed: 00:07:07
                               ETA: 00:48:36

################################################################################
                     [1m Learning iteration 192/1500 [0m                      

                       Computation: 50052 steps/s (collection: 1.834s, learning 0.130s)
             Mean action noise std: 1.49
          Mean value_function loss: 42.0669
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 39.9480
                       Mean reward: 93.05
               Mean episode length: 221.79
    Episode_Reward/reaching_object: 0.6655
    Episode_Reward/rotating_object: 19.2518
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 1.96s
                      Time elapsed: 00:07:09
                               ETA: 00:48:32

################################################################################
                     [1m Learning iteration 193/1500 [0m                      

                       Computation: 48757 steps/s (collection: 1.925s, learning 0.091s)
             Mean action noise std: 1.50
          Mean value_function loss: 37.6304
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 39.9786
                       Mean reward: 103.06
               Mean episode length: 227.57
    Episode_Reward/reaching_object: 0.6523
    Episode_Reward/rotating_object: 19.2248
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 2.02s
                      Time elapsed: 00:07:11
                               ETA: 00:48:28

################################################################################
                     [1m Learning iteration 194/1500 [0m                      

                       Computation: 50285 steps/s (collection: 1.837s, learning 0.118s)
             Mean action noise std: 1.50
          Mean value_function loss: 38.5883
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 40.0119
                       Mean reward: 109.35
               Mean episode length: 216.72
    Episode_Reward/reaching_object: 0.6624
    Episode_Reward/rotating_object: 21.0270
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 1.95s
                      Time elapsed: 00:07:13
                               ETA: 00:48:24

################################################################################
                     [1m Learning iteration 195/1500 [0m                      

                       Computation: 50707 steps/s (collection: 1.806s, learning 0.132s)
             Mean action noise std: 1.50
          Mean value_function loss: 42.3085
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 40.0400
                       Mean reward: 73.11
               Mean episode length: 216.29
    Episode_Reward/reaching_object: 0.6601
    Episode_Reward/rotating_object: 19.2003
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 1.94s
                      Time elapsed: 00:07:15
                               ETA: 00:48:20

################################################################################
                     [1m Learning iteration 196/1500 [0m                      

                       Computation: 50451 steps/s (collection: 1.819s, learning 0.129s)
             Mean action noise std: 1.50
          Mean value_function loss: 43.8097
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 40.0705
                       Mean reward: 91.67
               Mean episode length: 222.82
    Episode_Reward/reaching_object: 0.6606
    Episode_Reward/rotating_object: 18.7623
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 1.95s
                      Time elapsed: 00:07:17
                               ETA: 00:48:16

################################################################################
                     [1m Learning iteration 197/1500 [0m                      

                       Computation: 41791 steps/s (collection: 2.172s, learning 0.180s)
             Mean action noise std: 1.50
          Mean value_function loss: 42.3826
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 40.0994
                       Mean reward: 109.50
               Mean episode length: 218.92
    Episode_Reward/reaching_object: 0.6473
    Episode_Reward/rotating_object: 20.5952
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 2.35s
                      Time elapsed: 00:07:19
                               ETA: 00:48:15

################################################################################
                     [1m Learning iteration 198/1500 [0m                      

                       Computation: 43208 steps/s (collection: 2.152s, learning 0.123s)
             Mean action noise std: 1.51
          Mean value_function loss: 45.0506
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 40.1378
                       Mean reward: 80.04
               Mean episode length: 213.66
    Episode_Reward/reaching_object: 0.6523
    Episode_Reward/rotating_object: 17.9730
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 2.28s
                      Time elapsed: 00:07:22
                               ETA: 00:48:13

################################################################################
                     [1m Learning iteration 199/1500 [0m                      

                       Computation: 48243 steps/s (collection: 1.942s, learning 0.096s)
             Mean action noise std: 1.51
          Mean value_function loss: 47.5065
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 40.1674
                       Mean reward: 103.18
               Mean episode length: 231.55
    Episode_Reward/reaching_object: 0.6508
    Episode_Reward/rotating_object: 18.5300
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 2.04s
                      Time elapsed: 00:07:24
                               ETA: 00:48:09

################################################################################
                     [1m Learning iteration 200/1500 [0m                      

                       Computation: 49329 steps/s (collection: 1.902s, learning 0.090s)
             Mean action noise std: 1.51
          Mean value_function loss: 52.4321
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 40.1899
                       Mean reward: 126.97
               Mean episode length: 221.89
    Episode_Reward/reaching_object: 0.6732
    Episode_Reward/rotating_object: 22.5477
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 1.99s
                      Time elapsed: 00:07:26
                               ETA: 00:48:06

################################################################################
                     [1m Learning iteration 201/1500 [0m                      

                       Computation: 50260 steps/s (collection: 1.862s, learning 0.094s)
             Mean action noise std: 1.51
          Mean value_function loss: 50.0434
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 40.2231
                       Mean reward: 81.00
               Mean episode length: 219.56
    Episode_Reward/reaching_object: 0.6407
    Episode_Reward/rotating_object: 19.0923
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 1.96s
                      Time elapsed: 00:07:28
                               ETA: 00:48:02

################################################################################
                     [1m Learning iteration 202/1500 [0m                      

                       Computation: 50883 steps/s (collection: 1.841s, learning 0.091s)
             Mean action noise std: 1.51
          Mean value_function loss: 52.6281
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 40.2630
                       Mean reward: 110.14
               Mean episode length: 222.86
    Episode_Reward/reaching_object: 0.6598
    Episode_Reward/rotating_object: 21.6826
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 1.93s
                      Time elapsed: 00:07:30
                               ETA: 00:47:58

################################################################################
                     [1m Learning iteration 203/1500 [0m                      

                       Computation: 50182 steps/s (collection: 1.857s, learning 0.102s)
             Mean action noise std: 1.52
          Mean value_function loss: 55.0732
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 40.2996
                       Mean reward: 89.62
               Mean episode length: 220.11
    Episode_Reward/reaching_object: 0.6770
    Episode_Reward/rotating_object: 21.2566
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 1.96s
                      Time elapsed: 00:07:32
                               ETA: 00:47:54

################################################################################
                     [1m Learning iteration 204/1500 [0m                      

                       Computation: 50047 steps/s (collection: 1.866s, learning 0.098s)
             Mean action noise std: 1.52
          Mean value_function loss: 51.8917
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 40.3317
                       Mean reward: 87.38
               Mean episode length: 207.16
    Episode_Reward/reaching_object: 0.6357
    Episode_Reward/rotating_object: 18.9613
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 1.96s
                      Time elapsed: 00:07:34
                               ETA: 00:47:50

################################################################################
                     [1m Learning iteration 205/1500 [0m                      

                       Computation: 50315 steps/s (collection: 1.855s, learning 0.099s)
             Mean action noise std: 1.52
          Mean value_function loss: 54.3049
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 40.3519
                       Mean reward: 120.68
               Mean episode length: 210.61
    Episode_Reward/reaching_object: 0.6476
    Episode_Reward/rotating_object: 21.0789
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 1.95s
                      Time elapsed: 00:07:36
                               ETA: 00:47:46

################################################################################
                     [1m Learning iteration 206/1500 [0m                      

                       Computation: 51276 steps/s (collection: 1.819s, learning 0.099s)
             Mean action noise std: 1.52
          Mean value_function loss: 55.4291
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 40.3771
                       Mean reward: 86.34
               Mean episode length: 225.17
    Episode_Reward/reaching_object: 0.6626
    Episode_Reward/rotating_object: 19.2122
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 1.92s
                      Time elapsed: 00:07:37
                               ETA: 00:47:42

################################################################################
                     [1m Learning iteration 207/1500 [0m                      

                       Computation: 50356 steps/s (collection: 1.861s, learning 0.092s)
             Mean action noise std: 1.52
          Mean value_function loss: 54.2993
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 40.4020
                       Mean reward: 102.03
               Mean episode length: 206.69
    Episode_Reward/reaching_object: 0.6826
    Episode_Reward/rotating_object: 21.4367
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 1.95s
                      Time elapsed: 00:07:39
                               ETA: 00:47:38

################################################################################
                     [1m Learning iteration 208/1500 [0m                      

                       Computation: 51896 steps/s (collection: 1.799s, learning 0.096s)
             Mean action noise std: 1.53
          Mean value_function loss: 49.8439
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 40.4339
                       Mean reward: 134.93
               Mean episode length: 233.92
    Episode_Reward/reaching_object: 0.7010
    Episode_Reward/rotating_object: 22.3503
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 1.89s
                      Time elapsed: 00:07:41
                               ETA: 00:47:34

################################################################################
                     [1m Learning iteration 209/1500 [0m                      

                       Computation: 48528 steps/s (collection: 1.895s, learning 0.131s)
             Mean action noise std: 1.53
          Mean value_function loss: 53.2607
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 40.4691
                       Mean reward: 99.47
               Mean episode length: 228.45
    Episode_Reward/reaching_object: 0.6895
    Episode_Reward/rotating_object: 22.3166
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 2.03s
                      Time elapsed: 00:07:43
                               ETA: 00:47:31

################################################################################
                     [1m Learning iteration 210/1500 [0m                      

                       Computation: 47459 steps/s (collection: 1.953s, learning 0.118s)
             Mean action noise std: 1.53
          Mean value_function loss: 55.6025
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 40.4968
                       Mean reward: 117.21
               Mean episode length: 227.26
    Episode_Reward/reaching_object: 0.6689
    Episode_Reward/rotating_object: 20.6739
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 2.07s
                      Time elapsed: 00:07:45
                               ETA: 00:47:28

################################################################################
                     [1m Learning iteration 211/1500 [0m                      

                       Computation: 49284 steps/s (collection: 1.875s, learning 0.120s)
             Mean action noise std: 1.53
          Mean value_function loss: 52.0683
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 40.5107
                       Mean reward: 133.13
               Mean episode length: 228.32
    Episode_Reward/reaching_object: 0.7124
    Episode_Reward/rotating_object: 22.9900
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 1.99s
                      Time elapsed: 00:07:47
                               ETA: 00:47:24

################################################################################
                     [1m Learning iteration 212/1500 [0m                      

                       Computation: 47771 steps/s (collection: 1.945s, learning 0.113s)
             Mean action noise std: 1.53
          Mean value_function loss: 52.4547
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 40.5324
                       Mean reward: 123.44
               Mean episode length: 223.08
    Episode_Reward/reaching_object: 0.6979
    Episode_Reward/rotating_object: 25.1222
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 2.06s
                      Time elapsed: 00:07:49
                               ETA: 00:47:21

################################################################################
                     [1m Learning iteration 213/1500 [0m                      

                       Computation: 50906 steps/s (collection: 1.840s, learning 0.091s)
             Mean action noise std: 1.53
          Mean value_function loss: 50.7393
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 40.5454
                       Mean reward: 137.23
               Mean episode length: 231.10
    Episode_Reward/reaching_object: 0.7250
    Episode_Reward/rotating_object: 25.8694
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 1.93s
                      Time elapsed: 00:07:51
                               ETA: 00:47:17

################################################################################
                     [1m Learning iteration 214/1500 [0m                      

                       Computation: 46288 steps/s (collection: 1.977s, learning 0.147s)
             Mean action noise std: 1.54
          Mean value_function loss: 63.0129
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 40.5728
                       Mean reward: 145.29
               Mean episode length: 226.97
    Episode_Reward/reaching_object: 0.6957
    Episode_Reward/rotating_object: 25.0839
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 2.12s
                      Time elapsed: 00:07:53
                               ETA: 00:47:15

################################################################################
                     [1m Learning iteration 215/1500 [0m                      

                       Computation: 44471 steps/s (collection: 2.081s, learning 0.130s)
             Mean action noise std: 1.54
          Mean value_function loss: 67.1091
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 40.6044
                       Mean reward: 122.89
               Mean episode length: 226.45
    Episode_Reward/reaching_object: 0.6789
    Episode_Reward/rotating_object: 22.4667
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 2.21s
                      Time elapsed: 00:07:56
                               ETA: 00:47:12

################################################################################
                     [1m Learning iteration 216/1500 [0m                      

                       Computation: 47905 steps/s (collection: 1.938s, learning 0.115s)
             Mean action noise std: 1.54
          Mean value_function loss: 74.9207
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 40.6333
                       Mean reward: 117.79
               Mean episode length: 226.24
    Episode_Reward/reaching_object: 0.6904
    Episode_Reward/rotating_object: 23.6871
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 2.05s
                      Time elapsed: 00:07:58
                               ETA: 00:47:09

################################################################################
                     [1m Learning iteration 217/1500 [0m                      

                       Computation: 49292 steps/s (collection: 1.894s, learning 0.100s)
             Mean action noise std: 1.54
          Mean value_function loss: 68.9942
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 40.6585
                       Mean reward: 104.47
               Mean episode length: 217.46
    Episode_Reward/reaching_object: 0.7242
    Episode_Reward/rotating_object: 26.5820
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 1.99s
                      Time elapsed: 00:08:00
                               ETA: 00:47:06

################################################################################
                     [1m Learning iteration 218/1500 [0m                      

                       Computation: 45125 steps/s (collection: 2.060s, learning 0.119s)
             Mean action noise std: 1.54
          Mean value_function loss: 66.9399
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 40.6834
                       Mean reward: 134.67
               Mean episode length: 225.25
    Episode_Reward/reaching_object: 0.7220
    Episode_Reward/rotating_object: 26.4730
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 2.18s
                      Time elapsed: 00:08:02
                               ETA: 00:47:04

################################################################################
                     [1m Learning iteration 219/1500 [0m                      

                       Computation: 43524 steps/s (collection: 2.041s, learning 0.218s)
             Mean action noise std: 1.55
          Mean value_function loss: 75.6342
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 40.7062
                       Mean reward: 164.23
               Mean episode length: 228.14
    Episode_Reward/reaching_object: 0.7259
    Episode_Reward/rotating_object: 27.6387
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 2.26s
                      Time elapsed: 00:08:04
                               ETA: 00:47:02

################################################################################
                     [1m Learning iteration 220/1500 [0m                      

                       Computation: 48034 steps/s (collection: 1.897s, learning 0.149s)
             Mean action noise std: 1.55
          Mean value_function loss: 69.4987
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 40.7327
                       Mean reward: 161.93
               Mean episode length: 224.38
    Episode_Reward/reaching_object: 0.7215
    Episode_Reward/rotating_object: 29.8115
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 2.05s
                      Time elapsed: 00:08:06
                               ETA: 00:46:59

################################################################################
                     [1m Learning iteration 221/1500 [0m                      

                       Computation: 50966 steps/s (collection: 1.822s, learning 0.107s)
             Mean action noise std: 1.55
          Mean value_function loss: 65.5280
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 40.7580
                       Mean reward: 148.00
               Mean episode length: 218.62
    Episode_Reward/reaching_object: 0.7071
    Episode_Reward/rotating_object: 26.2403
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 1.93s
                      Time elapsed: 00:08:08
                               ETA: 00:46:55

################################################################################
                     [1m Learning iteration 222/1500 [0m                      

                       Computation: 48311 steps/s (collection: 1.914s, learning 0.121s)
             Mean action noise std: 1.55
          Mean value_function loss: 63.8666
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.7841
                       Mean reward: 125.56
               Mean episode length: 226.17
    Episode_Reward/reaching_object: 0.7240
    Episode_Reward/rotating_object: 26.2457
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 2.03s
                      Time elapsed: 00:08:10
                               ETA: 00:46:52

################################################################################
                     [1m Learning iteration 223/1500 [0m                      

                       Computation: 45223 steps/s (collection: 2.058s, learning 0.116s)
             Mean action noise std: 1.55
          Mean value_function loss: 61.9228
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 40.8015
                       Mean reward: 142.17
               Mean episode length: 219.23
    Episode_Reward/reaching_object: 0.7255
    Episode_Reward/rotating_object: 26.3736
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 2.17s
                      Time elapsed: 00:08:12
                               ETA: 00:46:49

################################################################################
                     [1m Learning iteration 224/1500 [0m                      

                       Computation: 46257 steps/s (collection: 2.024s, learning 0.102s)
             Mean action noise std: 1.56
          Mean value_function loss: 66.6003
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 40.8370
                       Mean reward: 196.05
               Mean episode length: 235.04
    Episode_Reward/reaching_object: 0.7519
    Episode_Reward/rotating_object: 31.2371
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 2.13s
                      Time elapsed: 00:08:14
                               ETA: 00:46:47

################################################################################
                     [1m Learning iteration 225/1500 [0m                      

                       Computation: 47569 steps/s (collection: 1.966s, learning 0.101s)
             Mean action noise std: 1.56
          Mean value_function loss: 78.7812
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 40.8682
                       Mean reward: 163.08
               Mean episode length: 220.87
    Episode_Reward/reaching_object: 0.7308
    Episode_Reward/rotating_object: 29.1636
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 2.07s
                      Time elapsed: 00:08:17
                               ETA: 00:46:44

################################################################################
                     [1m Learning iteration 226/1500 [0m                      

                       Computation: 50217 steps/s (collection: 1.856s, learning 0.102s)
             Mean action noise std: 1.56
          Mean value_function loss: 78.0061
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 40.8910
                       Mean reward: 152.36
               Mean episode length: 224.36
    Episode_Reward/reaching_object: 0.7347
    Episode_Reward/rotating_object: 29.3184
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 1.96s
                      Time elapsed: 00:08:19
                               ETA: 00:46:40

################################################################################
                     [1m Learning iteration 227/1500 [0m                      

                       Computation: 48612 steps/s (collection: 1.928s, learning 0.094s)
             Mean action noise std: 1.56
          Mean value_function loss: 76.6670
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 40.9129
                       Mean reward: 167.64
               Mean episode length: 228.87
    Episode_Reward/reaching_object: 0.7459
    Episode_Reward/rotating_object: 32.4825
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 2.02s
                      Time elapsed: 00:08:21
                               ETA: 00:46:37

################################################################################
                     [1m Learning iteration 228/1500 [0m                      

                       Computation: 47222 steps/s (collection: 1.973s, learning 0.109s)
             Mean action noise std: 1.56
          Mean value_function loss: 68.0817
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 40.9307
                       Mean reward: 180.24
               Mean episode length: 225.57
    Episode_Reward/reaching_object: 0.7590
    Episode_Reward/rotating_object: 33.0378
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 2.08s
                      Time elapsed: 00:08:23
                               ETA: 00:46:34

################################################################################
                     [1m Learning iteration 229/1500 [0m                      

                       Computation: 49006 steps/s (collection: 1.907s, learning 0.099s)
             Mean action noise std: 1.57
          Mean value_function loss: 80.2900
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 40.9634
                       Mean reward: 154.24
               Mean episode length: 221.09
    Episode_Reward/reaching_object: 0.7170
    Episode_Reward/rotating_object: 29.1045
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 2.01s
                      Time elapsed: 00:08:25
                               ETA: 00:46:31

################################################################################
                     [1m Learning iteration 230/1500 [0m                      

                       Computation: 48413 steps/s (collection: 1.927s, learning 0.103s)
             Mean action noise std: 1.57
          Mean value_function loss: 91.4841
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 40.9978
                       Mean reward: 155.96
               Mean episode length: 229.13
    Episode_Reward/reaching_object: 0.7025
    Episode_Reward/rotating_object: 29.3939
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 2.03s
                      Time elapsed: 00:08:27
                               ETA: 00:46:28

################################################################################
                     [1m Learning iteration 231/1500 [0m                      

                       Computation: 49736 steps/s (collection: 1.876s, learning 0.100s)
             Mean action noise std: 1.57
          Mean value_function loss: 84.0210
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 41.0221
                       Mean reward: 163.59
               Mean episode length: 216.97
    Episode_Reward/reaching_object: 0.7126
    Episode_Reward/rotating_object: 28.6204
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 1.98s
                      Time elapsed: 00:08:29
                               ETA: 00:46:24

################################################################################
                     [1m Learning iteration 232/1500 [0m                      

                       Computation: 49571 steps/s (collection: 1.879s, learning 0.104s)
             Mean action noise std: 1.57
          Mean value_function loss: 84.8049
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 41.0457
                       Mean reward: 176.76
               Mean episode length: 231.97
    Episode_Reward/reaching_object: 0.7600
    Episode_Reward/rotating_object: 34.0647
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 1.98s
                      Time elapsed: 00:08:31
                               ETA: 00:46:21

################################################################################
                     [1m Learning iteration 233/1500 [0m                      

                       Computation: 49081 steps/s (collection: 1.892s, learning 0.111s)
             Mean action noise std: 1.57
          Mean value_function loss: 87.4091
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.0708
                       Mean reward: 197.84
               Mean episode length: 231.62
    Episode_Reward/reaching_object: 0.7385
    Episode_Reward/rotating_object: 34.0327
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 2.00s
                      Time elapsed: 00:08:33
                               ETA: 00:46:18

################################################################################
                     [1m Learning iteration 234/1500 [0m                      

                       Computation: 49753 steps/s (collection: 1.868s, learning 0.108s)
             Mean action noise std: 1.57
          Mean value_function loss: 93.2038
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 41.0878
                       Mean reward: 166.62
               Mean episode length: 234.01
    Episode_Reward/reaching_object: 0.7532
    Episode_Reward/rotating_object: 31.9640
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 1.98s
                      Time elapsed: 00:08:35
                               ETA: 00:46:14

################################################################################
                     [1m Learning iteration 235/1500 [0m                      

                       Computation: 48620 steps/s (collection: 1.919s, learning 0.103s)
             Mean action noise std: 1.58
          Mean value_function loss: 107.4393
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 41.1194
                       Mean reward: 166.02
               Mean episode length: 228.12
    Episode_Reward/reaching_object: 0.7584
    Episode_Reward/rotating_object: 31.7497
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 2.02s
                      Time elapsed: 00:08:37
                               ETA: 00:46:11

################################################################################
                     [1m Learning iteration 236/1500 [0m                      

                       Computation: 48096 steps/s (collection: 1.933s, learning 0.111s)
             Mean action noise std: 1.58
          Mean value_function loss: 100.3842
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 41.1504
                       Mean reward: 162.35
               Mean episode length: 222.77
    Episode_Reward/reaching_object: 0.7449
    Episode_Reward/rotating_object: 31.9045
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 2.04s
                      Time elapsed: 00:08:39
                               ETA: 00:46:08

################################################################################
                     [1m Learning iteration 237/1500 [0m                      

                       Computation: 47375 steps/s (collection: 1.970s, learning 0.105s)
             Mean action noise std: 1.58
          Mean value_function loss: 82.9132
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 41.1702
                       Mean reward: 156.90
               Mean episode length: 230.66
    Episode_Reward/reaching_object: 0.7806
    Episode_Reward/rotating_object: 33.6491
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 2.07s
                      Time elapsed: 00:08:41
                               ETA: 00:46:06

################################################################################
                     [1m Learning iteration 238/1500 [0m                      

                       Computation: 49055 steps/s (collection: 1.906s, learning 0.098s)
             Mean action noise std: 1.58
          Mean value_function loss: 86.3141
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 41.1832
                       Mean reward: 186.12
               Mean episode length: 229.63
    Episode_Reward/reaching_object: 0.7593
    Episode_Reward/rotating_object: 34.8522
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 2.00s
                      Time elapsed: 00:08:43
                               ETA: 00:46:02

################################################################################
                     [1m Learning iteration 239/1500 [0m                      

                       Computation: 47318 steps/s (collection: 1.970s, learning 0.108s)
             Mean action noise std: 1.58
          Mean value_function loss: 72.7286
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 41.2044
                       Mean reward: 136.62
               Mean episode length: 216.49
    Episode_Reward/reaching_object: 0.7576
    Episode_Reward/rotating_object: 34.1969
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 2.08s
                      Time elapsed: 00:08:45
                               ETA: 00:46:00

################################################################################
                     [1m Learning iteration 240/1500 [0m                      

                       Computation: 47269 steps/s (collection: 1.956s, learning 0.124s)
             Mean action noise std: 1.58
          Mean value_function loss: 85.8265
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 41.2321
                       Mean reward: 142.56
               Mean episode length: 215.36
    Episode_Reward/reaching_object: 0.7286
    Episode_Reward/rotating_object: 32.0480
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 2.08s
                      Time elapsed: 00:08:47
                               ETA: 00:45:57

################################################################################
                     [1m Learning iteration 241/1500 [0m                      

                       Computation: 45648 steps/s (collection: 2.017s, learning 0.136s)
             Mean action noise std: 1.59
          Mean value_function loss: 79.7516
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 41.2563
                       Mean reward: 206.84
               Mean episode length: 233.44
    Episode_Reward/reaching_object: 0.7617
    Episode_Reward/rotating_object: 33.0997
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 2.15s
                      Time elapsed: 00:08:49
                               ETA: 00:45:54

################################################################################
                     [1m Learning iteration 242/1500 [0m                      

                       Computation: 42708 steps/s (collection: 2.148s, learning 0.154s)
             Mean action noise std: 1.59
          Mean value_function loss: 80.8432
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 41.2844
                       Mean reward: 176.73
               Mean episode length: 221.31
    Episode_Reward/reaching_object: 0.7675
    Episode_Reward/rotating_object: 36.3503
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 2.30s
                      Time elapsed: 00:08:51
                               ETA: 00:45:53

################################################################################
                     [1m Learning iteration 243/1500 [0m                      

                       Computation: 44960 steps/s (collection: 2.081s, learning 0.105s)
             Mean action noise std: 1.59
          Mean value_function loss: 86.5950
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 41.3005
                       Mean reward: 163.92
               Mean episode length: 227.22
    Episode_Reward/reaching_object: 0.7740
    Episode_Reward/rotating_object: 35.6778
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 2.19s
                      Time elapsed: 00:08:54
                               ETA: 00:45:51

################################################################################
                     [1m Learning iteration 244/1500 [0m                      

                       Computation: 46701 steps/s (collection: 2.010s, learning 0.095s)
             Mean action noise std: 1.59
          Mean value_function loss: 95.3735
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 41.3111
                       Mean reward: 192.54
               Mean episode length: 224.87
    Episode_Reward/reaching_object: 0.7687
    Episode_Reward/rotating_object: 38.4870
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 2.10s
                      Time elapsed: 00:08:56
                               ETA: 00:45:48

################################################################################
                     [1m Learning iteration 245/1500 [0m                      

                       Computation: 48863 steps/s (collection: 1.909s, learning 0.103s)
             Mean action noise std: 1.59
          Mean value_function loss: 105.4771
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 41.3273
                       Mean reward: 164.71
               Mean episode length: 226.52
    Episode_Reward/reaching_object: 0.7548
    Episode_Reward/rotating_object: 34.2423
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 2.01s
                      Time elapsed: 00:08:58
                               ETA: 00:45:45

################################################################################
                     [1m Learning iteration 246/1500 [0m                      

                       Computation: 46989 steps/s (collection: 1.993s, learning 0.100s)
             Mean action noise std: 1.59
          Mean value_function loss: 90.1898
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 41.3517
                       Mean reward: 204.66
               Mean episode length: 218.82
    Episode_Reward/reaching_object: 0.7960
    Episode_Reward/rotating_object: 39.8230
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 2.09s
                      Time elapsed: 00:09:00
                               ETA: 00:45:42

################################################################################
                     [1m Learning iteration 247/1500 [0m                      

                       Computation: 47953 steps/s (collection: 1.942s, learning 0.108s)
             Mean action noise std: 1.59
          Mean value_function loss: 89.5083
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.3719
                       Mean reward: 171.56
               Mean episode length: 215.51
    Episode_Reward/reaching_object: 0.7711
    Episode_Reward/rotating_object: 39.2105
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 2.05s
                      Time elapsed: 00:09:02
                               ETA: 00:45:39

################################################################################
                     [1m Learning iteration 248/1500 [0m                      

                       Computation: 46984 steps/s (collection: 1.981s, learning 0.111s)
             Mean action noise std: 1.60
          Mean value_function loss: 92.0612
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 41.3907
                       Mean reward: 204.20
               Mean episode length: 213.81
    Episode_Reward/reaching_object: 0.7524
    Episode_Reward/rotating_object: 38.5571
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 2.09s
                      Time elapsed: 00:09:04
                               ETA: 00:45:37

################################################################################
                     [1m Learning iteration 249/1500 [0m                      

                       Computation: 45137 steps/s (collection: 2.052s, learning 0.126s)
             Mean action noise std: 1.60
          Mean value_function loss: 95.5005
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 41.4156
                       Mean reward: 202.70
               Mean episode length: 225.29
    Episode_Reward/reaching_object: 0.7667
    Episode_Reward/rotating_object: 38.7482
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 2.18s
                      Time elapsed: 00:09:06
                               ETA: 00:45:34

################################################################################
                     [1m Learning iteration 250/1500 [0m                      

                       Computation: 43982 steps/s (collection: 2.105s, learning 0.130s)
             Mean action noise std: 1.60
          Mean value_function loss: 106.3040
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 41.4453
                       Mean reward: 213.79
               Mean episode length: 225.77
    Episode_Reward/reaching_object: 0.7657
    Episode_Reward/rotating_object: 40.4126
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 2.24s
                      Time elapsed: 00:09:08
                               ETA: 00:45:33

################################################################################
                     [1m Learning iteration 251/1500 [0m                      

                       Computation: 44819 steps/s (collection: 2.095s, learning 0.098s)
             Mean action noise std: 1.60
          Mean value_function loss: 100.2370
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 41.4672
                       Mean reward: 178.53
               Mean episode length: 209.43
    Episode_Reward/reaching_object: 0.7559
    Episode_Reward/rotating_object: 37.6987
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 2.19s
                      Time elapsed: 00:09:10
                               ETA: 00:45:30

################################################################################
                     [1m Learning iteration 252/1500 [0m                      

                       Computation: 47062 steps/s (collection: 1.977s, learning 0.112s)
             Mean action noise std: 1.60
          Mean value_function loss: 100.0908
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 41.4841
                       Mean reward: 223.56
               Mean episode length: 221.46
    Episode_Reward/reaching_object: 0.7884
    Episode_Reward/rotating_object: 39.2438
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 2.09s
                      Time elapsed: 00:09:13
                               ETA: 00:45:28

################################################################################
                     [1m Learning iteration 253/1500 [0m                      

                       Computation: 47052 steps/s (collection: 1.986s, learning 0.104s)
             Mean action noise std: 1.60
          Mean value_function loss: 107.1352
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 41.4965
                       Mean reward: 175.79
               Mean episode length: 219.59
    Episode_Reward/reaching_object: 0.7779
    Episode_Reward/rotating_object: 39.0542
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 2.09s
                      Time elapsed: 00:09:15
                               ETA: 00:45:25

################################################################################
                     [1m Learning iteration 254/1500 [0m                      

                       Computation: 47121 steps/s (collection: 1.973s, learning 0.113s)
             Mean action noise std: 1.60
          Mean value_function loss: 91.4040
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 41.5060
                       Mean reward: 196.55
               Mean episode length: 212.31
    Episode_Reward/reaching_object: 0.7492
    Episode_Reward/rotating_object: 37.6203
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 2.09s
                      Time elapsed: 00:09:17
                               ETA: 00:45:22

################################################################################
                     [1m Learning iteration 255/1500 [0m                      

                       Computation: 46898 steps/s (collection: 1.976s, learning 0.120s)
             Mean action noise std: 1.61
          Mean value_function loss: 94.0505
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 41.5236
                       Mean reward: 191.31
               Mean episode length: 206.01
    Episode_Reward/reaching_object: 0.7621
    Episode_Reward/rotating_object: 39.4651
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 2.10s
                      Time elapsed: 00:09:19
                               ETA: 00:45:20

################################################################################
                     [1m Learning iteration 256/1500 [0m                      

                       Computation: 46517 steps/s (collection: 2.004s, learning 0.109s)
             Mean action noise std: 1.61
          Mean value_function loss: 99.4232
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 41.5461
                       Mean reward: 207.53
               Mean episode length: 208.06
    Episode_Reward/reaching_object: 0.7701
    Episode_Reward/rotating_object: 38.5089
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 2.11s
                      Time elapsed: 00:09:21
                               ETA: 00:45:17

################################################################################
                     [1m Learning iteration 257/1500 [0m                      

                       Computation: 46441 steps/s (collection: 1.994s, learning 0.123s)
             Mean action noise std: 1.61
          Mean value_function loss: 111.5349
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 41.5631
                       Mean reward: 183.32
               Mean episode length: 213.37
    Episode_Reward/reaching_object: 0.7809
    Episode_Reward/rotating_object: 39.7079
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 2.12s
                      Time elapsed: 00:09:23
                               ETA: 00:45:15

################################################################################
                     [1m Learning iteration 258/1500 [0m                      

                       Computation: 44246 steps/s (collection: 2.103s, learning 0.119s)
             Mean action noise std: 1.61
          Mean value_function loss: 111.7155
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 41.5840
                       Mean reward: 208.42
               Mean episode length: 222.24
    Episode_Reward/reaching_object: 0.8022
    Episode_Reward/rotating_object: 40.3167
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 2.22s
                      Time elapsed: 00:09:25
                               ETA: 00:45:13

################################################################################
                     [1m Learning iteration 259/1500 [0m                      

                       Computation: 47162 steps/s (collection: 1.957s, learning 0.128s)
             Mean action noise std: 1.61
          Mean value_function loss: 107.5233
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 41.6040
                       Mean reward: 238.04
               Mean episode length: 219.77
    Episode_Reward/reaching_object: 0.8003
    Episode_Reward/rotating_object: 45.1637
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 2.08s
                      Time elapsed: 00:09:27
                               ETA: 00:45:10

################################################################################
                     [1m Learning iteration 260/1500 [0m                      

                       Computation: 48010 steps/s (collection: 1.938s, learning 0.109s)
             Mean action noise std: 1.61
          Mean value_function loss: 111.7598
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 41.6193
                       Mean reward: 229.65
               Mean episode length: 213.72
    Episode_Reward/reaching_object: 0.8094
    Episode_Reward/rotating_object: 43.6229
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 2.05s
                      Time elapsed: 00:09:29
                               ETA: 00:45:07

################################################################################
                     [1m Learning iteration 261/1500 [0m                      

                       Computation: 46924 steps/s (collection: 1.977s, learning 0.118s)
             Mean action noise std: 1.61
          Mean value_function loss: 119.2050
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 41.6342
                       Mean reward: 216.36
               Mean episode length: 222.34
    Episode_Reward/reaching_object: 0.8196
    Episode_Reward/rotating_object: 43.7842
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 2.09s
                      Time elapsed: 00:09:32
                               ETA: 00:45:05

################################################################################
                     [1m Learning iteration 262/1500 [0m                      

                       Computation: 41670 steps/s (collection: 2.235s, learning 0.125s)
             Mean action noise std: 1.62
          Mean value_function loss: 117.3440
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 41.6602
                       Mean reward: 241.19
               Mean episode length: 218.77
    Episode_Reward/reaching_object: 0.8182
    Episode_Reward/rotating_object: 47.2841
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 2.36s
                      Time elapsed: 00:09:34
                               ETA: 00:45:03

################################################################################
                     [1m Learning iteration 263/1500 [0m                      

                       Computation: 44808 steps/s (collection: 2.067s, learning 0.127s)
             Mean action noise std: 1.62
          Mean value_function loss: 120.7173
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 41.6880
                       Mean reward: 245.78
               Mean episode length: 220.36
    Episode_Reward/reaching_object: 0.8294
    Episode_Reward/rotating_object: 48.9923
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 2.19s
                      Time elapsed: 00:09:36
                               ETA: 00:45:01

################################################################################
                     [1m Learning iteration 264/1500 [0m                      

                       Computation: 46045 steps/s (collection: 2.028s, learning 0.107s)
             Mean action noise std: 1.62
          Mean value_function loss: 117.7455
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 41.7113
                       Mean reward: 266.23
               Mean episode length: 217.38
    Episode_Reward/reaching_object: 0.8287
    Episode_Reward/rotating_object: 50.0594
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 2.13s
                      Time elapsed: 00:09:38
                               ETA: 00:44:59

################################################################################
                     [1m Learning iteration 265/1500 [0m                      

                       Computation: 48007 steps/s (collection: 1.942s, learning 0.106s)
             Mean action noise std: 1.62
          Mean value_function loss: 107.2067
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 41.7345
                       Mean reward: 222.27
               Mean episode length: 210.55
    Episode_Reward/reaching_object: 0.8021
    Episode_Reward/rotating_object: 42.6989
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 2.05s
                      Time elapsed: 00:09:40
                               ETA: 00:44:56

################################################################################
                     [1m Learning iteration 266/1500 [0m                      

                       Computation: 46437 steps/s (collection: 1.936s, learning 0.181s)
             Mean action noise std: 1.62
          Mean value_function loss: 100.1421
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 41.7510
                       Mean reward: 300.48
               Mean episode length: 218.11
    Episode_Reward/reaching_object: 0.8229
    Episode_Reward/rotating_object: 51.8366
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 2.12s
                      Time elapsed: 00:09:42
                               ETA: 00:44:53

################################################################################
                     [1m Learning iteration 267/1500 [0m                      

                       Computation: 45887 steps/s (collection: 2.035s, learning 0.108s)
             Mean action noise std: 1.62
          Mean value_function loss: 116.4748
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 41.7675
                       Mean reward: 234.59
               Mean episode length: 212.90
    Episode_Reward/reaching_object: 0.8172
    Episode_Reward/rotating_object: 47.8043
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 2.14s
                      Time elapsed: 00:09:45
                               ETA: 00:44:51

################################################################################
                     [1m Learning iteration 268/1500 [0m                      

                       Computation: 46998 steps/s (collection: 1.973s, learning 0.119s)
             Mean action noise std: 1.62
          Mean value_function loss: 103.5454
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 41.7773
                       Mean reward: 253.71
               Mean episode length: 206.87
    Episode_Reward/reaching_object: 0.8250
    Episode_Reward/rotating_object: 49.7693
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 2.09s
                      Time elapsed: 00:09:47
                               ETA: 00:44:48

################################################################################
                     [1m Learning iteration 269/1500 [0m                      

                       Computation: 46537 steps/s (collection: 1.986s, learning 0.126s)
             Mean action noise std: 1.63
          Mean value_function loss: 117.0842
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 41.7890
                       Mean reward: 231.43
               Mean episode length: 213.64
    Episode_Reward/reaching_object: 0.8167
    Episode_Reward/rotating_object: 46.6446
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 2.11s
                      Time elapsed: 00:09:49
                               ETA: 00:44:46

################################################################################
                     [1m Learning iteration 270/1500 [0m                      

                       Computation: 46108 steps/s (collection: 2.008s, learning 0.124s)
             Mean action noise std: 1.63
          Mean value_function loss: 116.3178
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 41.8137
                       Mean reward: 218.95
               Mean episode length: 205.69
    Episode_Reward/reaching_object: 0.8015
    Episode_Reward/rotating_object: 45.4453
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 2.13s
                      Time elapsed: 00:09:51
                               ETA: 00:44:44

################################################################################
                     [1m Learning iteration 271/1500 [0m                      

                       Computation: 42745 steps/s (collection: 2.172s, learning 0.128s)
             Mean action noise std: 1.63
          Mean value_function loss: 113.1849
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 41.8329
                       Mean reward: 259.59
               Mean episode length: 223.31
    Episode_Reward/reaching_object: 0.8253
    Episode_Reward/rotating_object: 48.6697
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 2.30s
                      Time elapsed: 00:09:53
                               ETA: 00:44:42

################################################################################
                     [1m Learning iteration 272/1500 [0m                      

                       Computation: 47038 steps/s (collection: 1.987s, learning 0.103s)
             Mean action noise std: 1.63
          Mean value_function loss: 116.1171
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 41.8456
                       Mean reward: 213.27
               Mean episode length: 206.02
    Episode_Reward/reaching_object: 0.8131
    Episode_Reward/rotating_object: 49.5003
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 2.09s
                      Time elapsed: 00:09:55
                               ETA: 00:44:39

################################################################################
                     [1m Learning iteration 273/1500 [0m                      

                       Computation: 47819 steps/s (collection: 1.938s, learning 0.118s)
             Mean action noise std: 1.63
          Mean value_function loss: 115.3679
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 41.8643
                       Mean reward: 278.09
               Mean episode length: 223.13
    Episode_Reward/reaching_object: 0.8508
    Episode_Reward/rotating_object: 50.7195
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 2.06s
                      Time elapsed: 00:09:57
                               ETA: 00:44:37

################################################################################
                     [1m Learning iteration 274/1500 [0m                      

                       Computation: 45791 steps/s (collection: 2.028s, learning 0.119s)
             Mean action noise std: 1.63
          Mean value_function loss: 116.6429
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 41.8781
                       Mean reward: 275.50
               Mean episode length: 224.40
    Episode_Reward/reaching_object: 0.8436
    Episode_Reward/rotating_object: 51.5339
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 2.15s
                      Time elapsed: 00:09:59
                               ETA: 00:44:34

################################################################################
                     [1m Learning iteration 275/1500 [0m                      

                       Computation: 46020 steps/s (collection: 2.014s, learning 0.123s)
             Mean action noise std: 1.63
          Mean value_function loss: 122.1060
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 41.8886
                       Mean reward: 250.98
               Mean episode length: 218.79
    Episode_Reward/reaching_object: 0.8673
    Episode_Reward/rotating_object: 55.2178
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 2.14s
                      Time elapsed: 00:10:02
                               ETA: 00:44:32

################################################################################
                     [1m Learning iteration 276/1500 [0m                      

                       Computation: 46728 steps/s (collection: 1.999s, learning 0.105s)
             Mean action noise std: 1.63
          Mean value_function loss: 110.4816
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 41.9035
                       Mean reward: 300.43
               Mean episode length: 229.70
    Episode_Reward/reaching_object: 0.8786
    Episode_Reward/rotating_object: 53.9583
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 2.10s
                      Time elapsed: 00:10:04
                               ETA: 00:44:29

################################################################################
                     [1m Learning iteration 277/1500 [0m                      

                       Computation: 46050 steps/s (collection: 2.025s, learning 0.110s)
             Mean action noise std: 1.64
          Mean value_function loss: 130.3350
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 41.9164
                       Mean reward: 293.54
               Mean episode length: 232.24
    Episode_Reward/reaching_object: 0.8929
    Episode_Reward/rotating_object: 59.2662
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 2.13s
                      Time elapsed: 00:10:06
                               ETA: 00:44:27

################################################################################
                     [1m Learning iteration 278/1500 [0m                      

                       Computation: 48633 steps/s (collection: 1.904s, learning 0.117s)
             Mean action noise std: 1.64
          Mean value_function loss: 118.9062
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 41.9296
                       Mean reward: 301.83
               Mean episode length: 218.50
    Episode_Reward/reaching_object: 0.8670
    Episode_Reward/rotating_object: 57.4729
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 2.02s
                      Time elapsed: 00:10:08
                               ETA: 00:44:24

################################################################################
                     [1m Learning iteration 279/1500 [0m                      

                       Computation: 48196 steps/s (collection: 1.923s, learning 0.117s)
             Mean action noise std: 1.64
          Mean value_function loss: 114.5434
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 41.9408
                       Mean reward: 303.15
               Mean episode length: 229.73
    Episode_Reward/reaching_object: 0.8675
    Episode_Reward/rotating_object: 55.3194
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 2.04s
                      Time elapsed: 00:10:10
                               ETA: 00:44:21

################################################################################
                     [1m Learning iteration 280/1500 [0m                      

                       Computation: 42325 steps/s (collection: 2.211s, learning 0.111s)
             Mean action noise std: 1.64
          Mean value_function loss: 136.3405
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 41.9568
                       Mean reward: 287.00
               Mean episode length: 222.12
    Episode_Reward/reaching_object: 0.8708
    Episode_Reward/rotating_object: 56.9835
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 2.32s
                      Time elapsed: 00:10:12
                               ETA: 00:44:20

################################################################################
                     [1m Learning iteration 281/1500 [0m                      

                       Computation: 46458 steps/s (collection: 2.007s, learning 0.109s)
             Mean action noise std: 1.64
          Mean value_function loss: 132.6628
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.9744
                       Mean reward: 311.06
               Mean episode length: 221.79
    Episode_Reward/reaching_object: 0.8492
    Episode_Reward/rotating_object: 55.8978
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 2.12s
                      Time elapsed: 00:10:14
                               ETA: 00:44:17

################################################################################
                     [1m Learning iteration 282/1500 [0m                      

                       Computation: 47778 steps/s (collection: 1.957s, learning 0.100s)
             Mean action noise std: 1.64
          Mean value_function loss: 124.5586
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 41.9837
                       Mean reward: 297.91
               Mean episode length: 214.20
    Episode_Reward/reaching_object: 0.8557
    Episode_Reward/rotating_object: 56.5909
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 2.06s
                      Time elapsed: 00:10:16
                               ETA: 00:44:14

################################################################################
                     [1m Learning iteration 283/1500 [0m                      

                       Computation: 48005 steps/s (collection: 1.940s, learning 0.108s)
             Mean action noise std: 1.64
          Mean value_function loss: 122.6005
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 41.9870
                       Mean reward: 275.67
               Mean episode length: 225.26
    Episode_Reward/reaching_object: 0.8535
    Episode_Reward/rotating_object: 54.9802
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 2.05s
                      Time elapsed: 00:10:18
                               ETA: 00:44:12

################################################################################
                     [1m Learning iteration 284/1500 [0m                      

                       Computation: 45232 steps/s (collection: 2.054s, learning 0.120s)
             Mean action noise std: 1.64
          Mean value_function loss: 109.7191
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 41.9925
                       Mean reward: 284.07
               Mean episode length: 211.99
    Episode_Reward/reaching_object: 0.8456
    Episode_Reward/rotating_object: 58.3063
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 2.17s
                      Time elapsed: 00:10:21
                               ETA: 00:44:10

################################################################################
                     [1m Learning iteration 285/1500 [0m                      

                       Computation: 44543 steps/s (collection: 2.068s, learning 0.139s)
             Mean action noise std: 1.64
          Mean value_function loss: 113.0963
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 42.0039
                       Mean reward: 326.20
               Mean episode length: 223.14
    Episode_Reward/reaching_object: 0.8544
    Episode_Reward/rotating_object: 61.4144
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 2.21s
                      Time elapsed: 00:10:23
                               ETA: 00:44:07

################################################################################
                     [1m Learning iteration 286/1500 [0m                      

                       Computation: 46354 steps/s (collection: 1.999s, learning 0.122s)
             Mean action noise std: 1.64
          Mean value_function loss: 128.9964
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.0197
                       Mean reward: 301.82
               Mean episode length: 222.98
    Episode_Reward/reaching_object: 0.8804
    Episode_Reward/rotating_object: 59.6739
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 2.12s
                      Time elapsed: 00:10:25
                               ETA: 00:44:05

################################################################################
                     [1m Learning iteration 287/1500 [0m                      

                       Computation: 44423 steps/s (collection: 2.077s, learning 0.136s)
             Mean action noise std: 1.64
          Mean value_function loss: 113.3208
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 42.0291
                       Mean reward: 338.07
               Mean episode length: 222.05
    Episode_Reward/reaching_object: 0.8512
    Episode_Reward/rotating_object: 63.2528
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 2.21s
                      Time elapsed: 00:10:27
                               ETA: 00:44:03

################################################################################
                     [1m Learning iteration 288/1500 [0m                      

                       Computation: 46034 steps/s (collection: 2.023s, learning 0.113s)
             Mean action noise std: 1.64
          Mean value_function loss: 119.7771
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 42.0379
                       Mean reward: 331.95
               Mean episode length: 221.16
    Episode_Reward/reaching_object: 0.8707
    Episode_Reward/rotating_object: 60.8443
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 2.14s
                      Time elapsed: 00:10:29
                               ETA: 00:44:01

################################################################################
                     [1m Learning iteration 289/1500 [0m                      

                       Computation: 45361 steps/s (collection: 2.065s, learning 0.103s)
             Mean action noise std: 1.65
          Mean value_function loss: 113.3574
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 42.0484
                       Mean reward: 324.67
               Mean episode length: 226.21
    Episode_Reward/reaching_object: 0.8774
    Episode_Reward/rotating_object: 63.9953
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 2.17s
                      Time elapsed: 00:10:31
                               ETA: 00:43:58

################################################################################
                     [1m Learning iteration 290/1500 [0m                      

                       Computation: 45095 steps/s (collection: 2.059s, learning 0.121s)
             Mean action noise std: 1.65
          Mean value_function loss: 122.9649
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 42.0566
                       Mean reward: 334.28
               Mean episode length: 226.17
    Episode_Reward/reaching_object: 0.8755
    Episode_Reward/rotating_object: 64.1389
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 2.18s
                      Time elapsed: 00:10:34
                               ETA: 00:43:56

################################################################################
                     [1m Learning iteration 291/1500 [0m                      

                       Computation: 44799 steps/s (collection: 2.079s, learning 0.116s)
             Mean action noise std: 1.65
          Mean value_function loss: 133.0179
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.0622
                       Mean reward: 360.32
               Mean episode length: 224.88
    Episode_Reward/reaching_object: 0.8814
    Episode_Reward/rotating_object: 61.9790
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 2.19s
                      Time elapsed: 00:10:36
                               ETA: 00:43:54

################################################################################
                     [1m Learning iteration 292/1500 [0m                      

                       Computation: 47805 steps/s (collection: 1.949s, learning 0.108s)
             Mean action noise std: 1.65
          Mean value_function loss: 131.7358
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 42.0705
                       Mean reward: 338.26
               Mean episode length: 218.27
    Episode_Reward/reaching_object: 0.8770
    Episode_Reward/rotating_object: 67.0341
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 2.06s
                      Time elapsed: 00:10:38
                               ETA: 00:43:51

################################################################################
                     [1m Learning iteration 293/1500 [0m                      

                       Computation: 47103 steps/s (collection: 1.958s, learning 0.129s)
             Mean action noise std: 1.65
          Mean value_function loss: 146.1573
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.0782
                       Mean reward: 313.00
               Mean episode length: 218.69
    Episode_Reward/reaching_object: 0.8839
    Episode_Reward/rotating_object: 66.6680
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 2.09s
                      Time elapsed: 00:10:40
                               ETA: 00:43:49

################################################################################
                     [1m Learning iteration 294/1500 [0m                      

                       Computation: 45005 steps/s (collection: 2.061s, learning 0.123s)
             Mean action noise std: 1.65
          Mean value_function loss: 126.0201
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 42.0878
                       Mean reward: 345.98
               Mean episode length: 220.84
    Episode_Reward/reaching_object: 0.8851
    Episode_Reward/rotating_object: 63.9032
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 2.18s
                      Time elapsed: 00:10:42
                               ETA: 00:43:47

################################################################################
                     [1m Learning iteration 295/1500 [0m                      

                       Computation: 43673 steps/s (collection: 2.132s, learning 0.119s)
             Mean action noise std: 1.65
          Mean value_function loss: 130.0423
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.1000
                       Mean reward: 355.00
               Mean episode length: 223.43
    Episode_Reward/reaching_object: 0.8924
    Episode_Reward/rotating_object: 68.1383
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 2.25s
                      Time elapsed: 00:10:44
                               ETA: 00:43:45

################################################################################
                     [1m Learning iteration 296/1500 [0m                      

                       Computation: 47492 steps/s (collection: 1.962s, learning 0.108s)
             Mean action noise std: 1.65
          Mean value_function loss: 109.9578
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 42.1098
                       Mean reward: 323.87
               Mean episode length: 222.94
    Episode_Reward/reaching_object: 0.8978
    Episode_Reward/rotating_object: 67.4126
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 2.07s
                      Time elapsed: 00:10:46
                               ETA: 00:43:42

################################################################################
                     [1m Learning iteration 297/1500 [0m                      

                       Computation: 45760 steps/s (collection: 2.021s, learning 0.127s)
             Mean action noise std: 1.65
          Mean value_function loss: 95.7503
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 42.1171
                       Mean reward: 318.92
               Mean episode length: 221.70
    Episode_Reward/reaching_object: 0.8709
    Episode_Reward/rotating_object: 67.0363
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 2.15s
                      Time elapsed: 00:10:49
                               ETA: 00:43:40

################################################################################
                     [1m Learning iteration 298/1500 [0m                      

                       Computation: 47083 steps/s (collection: 1.963s, learning 0.125s)
             Mean action noise std: 1.65
          Mean value_function loss: 107.6292
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 42.1309
                       Mean reward: 352.55
               Mean episode length: 217.45
    Episode_Reward/reaching_object: 0.8891
    Episode_Reward/rotating_object: 69.0106
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 2.09s
                      Time elapsed: 00:10:51
                               ETA: 00:43:37

################################################################################
                     [1m Learning iteration 299/1500 [0m                      

                       Computation: 46074 steps/s (collection: 1.998s, learning 0.135s)
             Mean action noise std: 1.65
          Mean value_function loss: 105.3300
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.1424
                       Mean reward: 333.69
               Mean episode length: 209.89
    Episode_Reward/reaching_object: 0.8592
    Episode_Reward/rotating_object: 68.8272
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 2.13s
                      Time elapsed: 00:10:53
                               ETA: 00:43:35

################################################################################
                     [1m Learning iteration 300/1500 [0m                      

                       Computation: 47873 steps/s (collection: 1.941s, learning 0.112s)
             Mean action noise std: 1.65
          Mean value_function loss: 111.6940
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 42.1541
                       Mean reward: 351.88
               Mean episode length: 228.85
    Episode_Reward/reaching_object: 0.8942
    Episode_Reward/rotating_object: 73.1722
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 2.05s
                      Time elapsed: 00:10:55
                               ETA: 00:43:32

################################################################################
                     [1m Learning iteration 301/1500 [0m                      

                       Computation: 48692 steps/s (collection: 1.912s, learning 0.107s)
             Mean action noise std: 1.65
          Mean value_function loss: 120.8246
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.1663
                       Mean reward: 342.79
               Mean episode length: 227.75
    Episode_Reward/reaching_object: 0.8935
    Episode_Reward/rotating_object: 67.9614
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 2.02s
                      Time elapsed: 00:10:57
                               ETA: 00:43:30

################################################################################
                     [1m Learning iteration 302/1500 [0m                      

                       Computation: 40852 steps/s (collection: 2.266s, learning 0.140s)
             Mean action noise std: 1.66
          Mean value_function loss: 122.8683
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 42.1773
                       Mean reward: 347.89
               Mean episode length: 219.70
    Episode_Reward/reaching_object: 0.9022
    Episode_Reward/rotating_object: 72.4407
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 2.41s
                      Time elapsed: 00:10:59
                               ETA: 00:43:28

################################################################################
                     [1m Learning iteration 303/1500 [0m                      

                       Computation: 40198 steps/s (collection: 2.265s, learning 0.180s)
             Mean action noise std: 1.66
          Mean value_function loss: 124.9863
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.1884
                       Mean reward: 315.34
               Mean episode length: 211.25
    Episode_Reward/reaching_object: 0.8563
    Episode_Reward/rotating_object: 65.8835
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 2.45s
                      Time elapsed: 00:11:02
                               ETA: 00:43:27

################################################################################
                     [1m Learning iteration 304/1500 [0m                      

                       Computation: 43474 steps/s (collection: 2.120s, learning 0.141s)
             Mean action noise std: 1.66
          Mean value_function loss: 120.6613
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 42.1979
                       Mean reward: 344.35
               Mean episode length: 207.10
    Episode_Reward/reaching_object: 0.8422
    Episode_Reward/rotating_object: 64.0523
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 2.26s
                      Time elapsed: 00:11:04
                               ETA: 00:43:25

################################################################################
                     [1m Learning iteration 305/1500 [0m                      

                       Computation: 42106 steps/s (collection: 2.231s, learning 0.104s)
             Mean action noise std: 1.66
          Mean value_function loss: 117.8397
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 42.2050
                       Mean reward: 333.68
               Mean episode length: 222.45
    Episode_Reward/reaching_object: 0.8586
    Episode_Reward/rotating_object: 65.0363
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 2.33s
                      Time elapsed: 00:11:06
                               ETA: 00:43:24

################################################################################
                     [1m Learning iteration 306/1500 [0m                      

                       Computation: 47204 steps/s (collection: 1.958s, learning 0.125s)
             Mean action noise std: 1.66
          Mean value_function loss: 112.7547
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 42.2182
                       Mean reward: 344.31
               Mean episode length: 216.89
    Episode_Reward/reaching_object: 0.8575
    Episode_Reward/rotating_object: 67.3579
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 2.08s
                      Time elapsed: 00:11:08
                               ETA: 00:43:21

################################################################################
                     [1m Learning iteration 307/1500 [0m                      

                       Computation: 44859 steps/s (collection: 2.087s, learning 0.105s)
             Mean action noise std: 1.66
          Mean value_function loss: 121.9071
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 42.2280
                       Mean reward: 366.06
               Mean episode length: 228.59
    Episode_Reward/reaching_object: 0.8845
    Episode_Reward/rotating_object: 69.8273
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 2.19s
                      Time elapsed: 00:11:11
                               ETA: 00:43:19

################################################################################
                     [1m Learning iteration 308/1500 [0m                      

                       Computation: 44659 steps/s (collection: 2.087s, learning 0.115s)
             Mean action noise std: 1.66
          Mean value_function loss: 111.7191
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 42.2337
                       Mean reward: 334.24
               Mean episode length: 218.59
    Episode_Reward/reaching_object: 0.8775
    Episode_Reward/rotating_object: 68.4736
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 2.20s
                      Time elapsed: 00:11:13
                               ETA: 00:43:17

################################################################################
                     [1m Learning iteration 309/1500 [0m                      

                       Computation: 44819 steps/s (collection: 2.091s, learning 0.103s)
             Mean action noise std: 1.66
          Mean value_function loss: 114.5755
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 42.2424
                       Mean reward: 355.58
               Mean episode length: 226.90
    Episode_Reward/reaching_object: 0.8922
    Episode_Reward/rotating_object: 70.6748
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 2.19s
                      Time elapsed: 00:11:15
                               ETA: 00:43:15

################################################################################
                     [1m Learning iteration 310/1500 [0m                      

                       Computation: 45780 steps/s (collection: 2.026s, learning 0.122s)
             Mean action noise std: 1.66
          Mean value_function loss: 113.9260
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.2562
                       Mean reward: 367.55
               Mean episode length: 225.64
    Episode_Reward/reaching_object: 0.8901
    Episode_Reward/rotating_object: 71.3823
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 2.15s
                      Time elapsed: 00:11:17
                               ETA: 00:43:13

################################################################################
                     [1m Learning iteration 311/1500 [0m                      

                       Computation: 43529 steps/s (collection: 2.121s, learning 0.137s)
             Mean action noise std: 1.66
          Mean value_function loss: 124.0413
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 42.2657
                       Mean reward: 421.12
               Mean episode length: 233.12
    Episode_Reward/reaching_object: 0.8681
    Episode_Reward/rotating_object: 72.1649
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 2.26s
                      Time elapsed: 00:11:19
                               ETA: 00:43:11

################################################################################
                     [1m Learning iteration 312/1500 [0m                      

                       Computation: 46680 steps/s (collection: 1.994s, learning 0.112s)
             Mean action noise std: 1.66
          Mean value_function loss: 126.8813
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 42.2744
                       Mean reward: 346.87
               Mean episode length: 220.05
    Episode_Reward/reaching_object: 0.8869
    Episode_Reward/rotating_object: 72.6960
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 2.11s
                      Time elapsed: 00:11:22
                               ETA: 00:43:08

################################################################################
                     [1m Learning iteration 313/1500 [0m                      

                       Computation: 48294 steps/s (collection: 1.922s, learning 0.113s)
             Mean action noise std: 1.66
          Mean value_function loss: 125.3442
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.2896
                       Mean reward: 406.05
               Mean episode length: 221.46
    Episode_Reward/reaching_object: 0.8777
    Episode_Reward/rotating_object: 75.3301
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 2.04s
                      Time elapsed: 00:11:24
                               ETA: 00:43:05

################################################################################
                     [1m Learning iteration 314/1500 [0m                      

                       Computation: 46907 steps/s (collection: 1.978s, learning 0.118s)
             Mean action noise std: 1.67
          Mean value_function loss: 126.6823
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 42.3004
                       Mean reward: 353.17
               Mean episode length: 215.14
    Episode_Reward/reaching_object: 0.8824
    Episode_Reward/rotating_object: 72.1038
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 2.10s
                      Time elapsed: 00:11:26
                               ETA: 00:43:03

################################################################################
                     [1m Learning iteration 315/1500 [0m                      

                       Computation: 45181 steps/s (collection: 2.045s, learning 0.131s)
             Mean action noise std: 1.67
          Mean value_function loss: 124.1349
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 42.3167
                       Mean reward: 378.27
               Mean episode length: 212.19
    Episode_Reward/reaching_object: 0.9042
    Episode_Reward/rotating_object: 76.2869
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 2.18s
                      Time elapsed: 00:11:28
                               ETA: 00:43:01

################################################################################
                     [1m Learning iteration 316/1500 [0m                      

                       Computation: 46193 steps/s (collection: 2.019s, learning 0.110s)
             Mean action noise std: 1.67
          Mean value_function loss: 115.3439
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 42.3263
                       Mean reward: 366.42
               Mean episode length: 221.09
    Episode_Reward/reaching_object: 0.9031
    Episode_Reward/rotating_object: 73.7134
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 2.13s
                      Time elapsed: 00:11:30
                               ETA: 00:42:58

################################################################################
                     [1m Learning iteration 317/1500 [0m                      

                       Computation: 46086 steps/s (collection: 2.028s, learning 0.105s)
             Mean action noise std: 1.67
          Mean value_function loss: 121.7141
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 42.3320
                       Mean reward: 392.63
               Mean episode length: 226.71
    Episode_Reward/reaching_object: 0.9189
    Episode_Reward/rotating_object: 78.7324
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 2.13s
                      Time elapsed: 00:11:32
                               ETA: 00:42:56

################################################################################
                     [1m Learning iteration 318/1500 [0m                      

                       Computation: 47042 steps/s (collection: 1.993s, learning 0.097s)
             Mean action noise std: 1.67
          Mean value_function loss: 112.5308
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.3449
                       Mean reward: 346.94
               Mean episode length: 213.39
    Episode_Reward/reaching_object: 0.9090
    Episode_Reward/rotating_object: 74.7978
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 2.09s
                      Time elapsed: 00:11:34
                               ETA: 00:42:54

################################################################################
                     [1m Learning iteration 319/1500 [0m                      

                       Computation: 47166 steps/s (collection: 1.967s, learning 0.117s)
             Mean action noise std: 1.67
          Mean value_function loss: 119.2388
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.3586
                       Mean reward: 361.13
               Mean episode length: 216.38
    Episode_Reward/reaching_object: 0.8828
    Episode_Reward/rotating_object: 73.7519
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 2.08s
                      Time elapsed: 00:11:36
                               ETA: 00:42:51

################################################################################
                     [1m Learning iteration 320/1500 [0m                      

                       Computation: 42413 steps/s (collection: 2.175s, learning 0.143s)
             Mean action noise std: 1.67
          Mean value_function loss: 122.6541
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 42.3665
                       Mean reward: 378.93
               Mean episode length: 221.66
    Episode_Reward/reaching_object: 0.9287
    Episode_Reward/rotating_object: 78.0693
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 2.32s
                      Time elapsed: 00:11:39
                               ETA: 00:42:49

################################################################################
                     [1m Learning iteration 321/1500 [0m                      

                       Computation: 45746 steps/s (collection: 2.029s, learning 0.120s)
             Mean action noise std: 1.67
          Mean value_function loss: 120.0104
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 42.3729
                       Mean reward: 414.74
               Mean episode length: 230.71
    Episode_Reward/reaching_object: 0.9282
    Episode_Reward/rotating_object: 81.0350
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 2.15s
                      Time elapsed: 00:11:41
                               ETA: 00:42:47

################################################################################
                     [1m Learning iteration 322/1500 [0m                      

                       Computation: 46536 steps/s (collection: 1.996s, learning 0.116s)
             Mean action noise std: 1.67
          Mean value_function loss: 123.5092
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.3829
                       Mean reward: 387.94
               Mean episode length: 219.66
    Episode_Reward/reaching_object: 0.9142
    Episode_Reward/rotating_object: 78.3394
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 2.11s
                      Time elapsed: 00:11:43
                               ETA: 00:42:45

################################################################################
                     [1m Learning iteration 323/1500 [0m                      

                       Computation: 48691 steps/s (collection: 1.913s, learning 0.106s)
             Mean action noise std: 1.67
          Mean value_function loss: 120.2770
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.3928
                       Mean reward: 403.57
               Mean episode length: 223.83
    Episode_Reward/reaching_object: 0.9189
    Episode_Reward/rotating_object: 78.1265
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 2.02s
                      Time elapsed: 00:11:45
                               ETA: 00:42:42

################################################################################
                     [1m Learning iteration 324/1500 [0m                      

                       Computation: 47341 steps/s (collection: 1.966s, learning 0.110s)
             Mean action noise std: 1.67
          Mean value_function loss: 112.3534
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 42.4026
                       Mean reward: 379.78
               Mean episode length: 219.08
    Episode_Reward/reaching_object: 0.9119
    Episode_Reward/rotating_object: 81.0393
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 2.08s
                      Time elapsed: 00:11:47
                               ETA: 00:42:39

################################################################################
                     [1m Learning iteration 325/1500 [0m                      

                       Computation: 46519 steps/s (collection: 2.006s, learning 0.108s)
             Mean action noise std: 1.67
          Mean value_function loss: 113.4265
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.4107
                       Mean reward: 425.83
               Mean episode length: 227.99
    Episode_Reward/reaching_object: 0.9038
    Episode_Reward/rotating_object: 76.4112
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 2.11s
                      Time elapsed: 00:11:49
                               ETA: 00:42:37

################################################################################
                     [1m Learning iteration 326/1500 [0m                      

                       Computation: 48180 steps/s (collection: 1.939s, learning 0.102s)
             Mean action noise std: 1.67
          Mean value_function loss: 116.0864
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 42.4144
                       Mean reward: 397.47
               Mean episode length: 226.37
    Episode_Reward/reaching_object: 0.9198
    Episode_Reward/rotating_object: 81.1303
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 2.04s
                      Time elapsed: 00:11:51
                               ETA: 00:42:34

################################################################################
                     [1m Learning iteration 327/1500 [0m                      

                       Computation: 48500 steps/s (collection: 1.913s, learning 0.114s)
             Mean action noise std: 1.68
          Mean value_function loss: 121.6318
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.4218
                       Mean reward: 397.49
               Mean episode length: 205.56
    Episode_Reward/reaching_object: 0.8965
    Episode_Reward/rotating_object: 78.8758
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 2.03s
                      Time elapsed: 00:11:53
                               ETA: 00:42:32

################################################################################
                     [1m Learning iteration 328/1500 [0m                      

                       Computation: 47295 steps/s (collection: 1.948s, learning 0.130s)
             Mean action noise std: 1.68
          Mean value_function loss: 111.8402
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.4326
                       Mean reward: 389.80
               Mean episode length: 218.66
    Episode_Reward/reaching_object: 0.8955
    Episode_Reward/rotating_object: 82.6777
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 2.08s
                      Time elapsed: 00:11:55
                               ETA: 00:42:29

################################################################################
                     [1m Learning iteration 329/1500 [0m                      

                       Computation: 46264 steps/s (collection: 2.014s, learning 0.111s)
             Mean action noise std: 1.68
          Mean value_function loss: 110.8787
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 42.4432
                       Mean reward: 417.91
               Mean episode length: 235.62
    Episode_Reward/reaching_object: 0.9040
    Episode_Reward/rotating_object: 79.2728
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 2.12s
                      Time elapsed: 00:11:57
                               ETA: 00:42:27

################################################################################
                     [1m Learning iteration 330/1500 [0m                      

                       Computation: 45695 steps/s (collection: 2.034s, learning 0.117s)
             Mean action noise std: 1.68
          Mean value_function loss: 117.3284
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 42.4476
                       Mean reward: 427.02
               Mean episode length: 221.61
    Episode_Reward/reaching_object: 0.9165
    Episode_Reward/rotating_object: 82.5823
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 2.15s
                      Time elapsed: 00:11:59
                               ETA: 00:42:24

################################################################################
                     [1m Learning iteration 331/1500 [0m                      

                       Computation: 47829 steps/s (collection: 1.955s, learning 0.100s)
             Mean action noise std: 1.68
          Mean value_function loss: 112.8925
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 42.4526
                       Mean reward: 429.56
               Mean episode length: 225.02
    Episode_Reward/reaching_object: 0.9186
    Episode_Reward/rotating_object: 83.4129
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 2.06s
                      Time elapsed: 00:12:02
                               ETA: 00:42:22

################################################################################
                     [1m Learning iteration 332/1500 [0m                      

                       Computation: 46310 steps/s (collection: 2.011s, learning 0.112s)
             Mean action noise std: 1.68
          Mean value_function loss: 128.7322
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 42.4619
                       Mean reward: 432.02
               Mean episode length: 230.01
    Episode_Reward/reaching_object: 0.9287
    Episode_Reward/rotating_object: 83.5367
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 2.12s
                      Time elapsed: 00:12:04
                               ETA: 00:42:20

################################################################################
                     [1m Learning iteration 333/1500 [0m                      

                       Computation: 19600 steps/s (collection: 4.880s, learning 0.136s)
             Mean action noise std: 1.68
          Mean value_function loss: 120.1239
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.4709
                       Mean reward: 405.69
               Mean episode length: 221.48
    Episode_Reward/reaching_object: 0.9092
    Episode_Reward/rotating_object: 79.4616
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 5.02s
                      Time elapsed: 00:12:09
                               ETA: 00:42:27

################################################################################
                     [1m Learning iteration 334/1500 [0m                      

                       Computation: 14302 steps/s (collection: 6.750s, learning 0.123s)
             Mean action noise std: 1.68
          Mean value_function loss: 124.0610
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 42.4794
                       Mean reward: 418.56
               Mean episode length: 217.24
    Episode_Reward/reaching_object: 0.9246
    Episode_Reward/rotating_object: 84.3140
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 6.87s
                      Time elapsed: 00:12:16
                               ETA: 00:42:41

################################################################################
                     [1m Learning iteration 335/1500 [0m                      

                       Computation: 13668 steps/s (collection: 7.062s, learning 0.130s)
             Mean action noise std: 1.68
          Mean value_function loss: 122.8131
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 42.4909
                       Mean reward: 420.19
               Mean episode length: 219.92
    Episode_Reward/reaching_object: 0.9067
    Episode_Reward/rotating_object: 80.5810
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 7.19s
                      Time elapsed: 00:12:23
                               ETA: 00:42:57

################################################################################
                     [1m Learning iteration 336/1500 [0m                      

                       Computation: 13647 steps/s (collection: 7.072s, learning 0.131s)
             Mean action noise std: 1.68
          Mean value_function loss: 131.7590
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 42.5038
                       Mean reward: 441.50
               Mean episode length: 227.78
    Episode_Reward/reaching_object: 0.9426
    Episode_Reward/rotating_object: 85.6691
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 7.20s
                      Time elapsed: 00:12:30
                               ETA: 00:43:12

################################################################################
                     [1m Learning iteration 337/1500 [0m                      

                       Computation: 14158 steps/s (collection: 6.793s, learning 0.151s)
             Mean action noise std: 1.68
          Mean value_function loss: 133.0380
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 42.5108
                       Mean reward: 399.32
               Mean episode length: 220.88
    Episode_Reward/reaching_object: 0.9095
    Episode_Reward/rotating_object: 82.1200
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 6.94s
                      Time elapsed: 00:12:37
                               ETA: 00:43:26

################################################################################
                     [1m Learning iteration 338/1500 [0m                      

                       Computation: 14180 steps/s (collection: 6.815s, learning 0.118s)
             Mean action noise std: 1.68
          Mean value_function loss: 134.0577
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 42.5165
                       Mean reward: 408.58
               Mean episode length: 220.96
    Episode_Reward/reaching_object: 0.9299
    Episode_Reward/rotating_object: 80.9802
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 6.93s
                      Time elapsed: 00:12:44
                               ETA: 00:43:39

################################################################################
                     [1m Learning iteration 339/1500 [0m                      

                       Computation: 14966 steps/s (collection: 6.439s, learning 0.129s)
             Mean action noise std: 1.68
          Mean value_function loss: 130.0211
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.5243
                       Mean reward: 431.10
               Mean episode length: 211.63
    Episode_Reward/reaching_object: 0.9442
    Episode_Reward/rotating_object: 87.4333
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 6.57s
                      Time elapsed: 00:12:50
                               ETA: 00:43:52

################################################################################
                     [1m Learning iteration 340/1500 [0m                      

                       Computation: 14627 steps/s (collection: 6.601s, learning 0.120s)
             Mean action noise std: 1.68
          Mean value_function loss: 123.7954
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 42.5281
                       Mean reward: 403.60
               Mean episode length: 215.06
    Episode_Reward/reaching_object: 0.9428
    Episode_Reward/rotating_object: 88.0755
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 6.72s
                      Time elapsed: 00:12:57
                               ETA: 00:44:05

################################################################################
                     [1m Learning iteration 341/1500 [0m                      

                       Computation: 13858 steps/s (collection: 6.974s, learning 0.120s)
             Mean action noise std: 1.69
          Mean value_function loss: 121.2915
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 42.5355
                       Mean reward: 463.36
               Mean episode length: 225.74
    Episode_Reward/reaching_object: 0.9481
    Episode_Reward/rotating_object: 89.9961
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 7.09s
                      Time elapsed: 00:13:04
                               ETA: 00:44:19

################################################################################
                     [1m Learning iteration 342/1500 [0m                      

                       Computation: 47834 steps/s (collection: 1.939s, learning 0.116s)
             Mean action noise std: 1.69
          Mean value_function loss: 126.7068
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 42.5490
                       Mean reward: 416.96
               Mean episode length: 221.33
    Episode_Reward/reaching_object: 0.9215
    Episode_Reward/rotating_object: 85.1544
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 2.06s
                      Time elapsed: 00:13:06
                               ETA: 00:44:16

################################################################################
                     [1m Learning iteration 343/1500 [0m                      

                       Computation: 49630 steps/s (collection: 1.865s, learning 0.116s)
             Mean action noise std: 1.69
          Mean value_function loss: 121.4903
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 42.5622
                       Mean reward: 425.76
               Mean episode length: 221.41
    Episode_Reward/reaching_object: 0.9251
    Episode_Reward/rotating_object: 88.0756
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 1.98s
                      Time elapsed: 00:13:08
                               ETA: 00:44:12

################################################################################
                     [1m Learning iteration 344/1500 [0m                      

                       Computation: 48669 steps/s (collection: 1.926s, learning 0.094s)
             Mean action noise std: 1.69
          Mean value_function loss: 128.1756
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.5755
                       Mean reward: 452.77
               Mean episode length: 219.78
    Episode_Reward/reaching_object: 0.9424
    Episode_Reward/rotating_object: 89.7730
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 2.02s
                      Time elapsed: 00:13:10
                               ETA: 00:44:09

################################################################################
                     [1m Learning iteration 345/1500 [0m                      

                       Computation: 50146 steps/s (collection: 1.863s, learning 0.098s)
             Mean action noise std: 1.69
          Mean value_function loss: 112.8867
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 42.5835
                       Mean reward: 460.46
               Mean episode length: 235.85
    Episode_Reward/reaching_object: 0.9375
    Episode_Reward/rotating_object: 89.8835
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 1.96s
                      Time elapsed: 00:13:12
                               ETA: 00:44:06

################################################################################
                     [1m Learning iteration 346/1500 [0m                      

                       Computation: 50818 steps/s (collection: 1.826s, learning 0.109s)
             Mean action noise std: 1.69
          Mean value_function loss: 100.4809
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 42.5928
                       Mean reward: 429.43
               Mean episode length: 224.20
    Episode_Reward/reaching_object: 0.9368
    Episode_Reward/rotating_object: 87.0706
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 1.93s
                      Time elapsed: 00:13:14
                               ETA: 00:44:02

################################################################################
                     [1m Learning iteration 347/1500 [0m                      

                       Computation: 49639 steps/s (collection: 1.873s, learning 0.107s)
             Mean action noise std: 1.69
          Mean value_function loss: 108.6127
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 42.6024
                       Mean reward: 456.72
               Mean episode length: 227.58
    Episode_Reward/reaching_object: 0.9479
    Episode_Reward/rotating_object: 91.1027
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 1.98s
                      Time elapsed: 00:13:16
                               ETA: 00:43:59

################################################################################
                     [1m Learning iteration 348/1500 [0m                      

                       Computation: 51033 steps/s (collection: 1.826s, learning 0.100s)
             Mean action noise std: 1.69
          Mean value_function loss: 108.3309
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 42.6115
                       Mean reward: 495.33
               Mean episode length: 240.01
    Episode_Reward/reaching_object: 0.9642
    Episode_Reward/rotating_object: 91.0587
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 1.93s
                      Time elapsed: 00:13:18
                               ETA: 00:43:55

################################################################################
                     [1m Learning iteration 349/1500 [0m                      

                       Computation: 46807 steps/s (collection: 1.941s, learning 0.159s)
             Mean action noise std: 1.69
          Mean value_function loss: 113.7501
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.6240
                       Mean reward: 487.70
               Mean episode length: 234.01
    Episode_Reward/reaching_object: 0.9519
    Episode_Reward/rotating_object: 89.7068
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 2.10s
                      Time elapsed: 00:13:20
                               ETA: 00:43:53

################################################################################
                     [1m Learning iteration 350/1500 [0m                      

                       Computation: 43863 steps/s (collection: 2.091s, learning 0.150s)
             Mean action noise std: 1.69
          Mean value_function loss: 110.3182
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 42.6310
                       Mean reward: 436.22
               Mean episode length: 222.38
    Episode_Reward/reaching_object: 0.9368
    Episode_Reward/rotating_object: 89.2636
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 2.24s
                      Time elapsed: 00:13:22
                               ETA: 00:43:50

################################################################################
                     [1m Learning iteration 351/1500 [0m                      

                       Computation: 49488 steps/s (collection: 1.839s, learning 0.148s)
             Mean action noise std: 1.69
          Mean value_function loss: 113.4026
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 42.6381
                       Mean reward: 462.46
               Mean episode length: 232.59
    Episode_Reward/reaching_object: 0.9721
    Episode_Reward/rotating_object: 94.2745
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 1.99s
                      Time elapsed: 00:13:24
                               ETA: 00:43:47

################################################################################
                     [1m Learning iteration 352/1500 [0m                      

                       Computation: 50472 steps/s (collection: 1.839s, learning 0.109s)
             Mean action noise std: 1.69
          Mean value_function loss: 115.1739
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.6427
                       Mean reward: 501.22
               Mean episode length: 233.78
    Episode_Reward/reaching_object: 0.9560
    Episode_Reward/rotating_object: 91.9796
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 1.95s
                      Time elapsed: 00:13:26
                               ETA: 00:43:43

################################################################################
                     [1m Learning iteration 353/1500 [0m                      

                       Computation: 51255 steps/s (collection: 1.802s, learning 0.116s)
             Mean action noise std: 1.69
          Mean value_function loss: 114.8069
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 42.6500
                       Mean reward: 421.55
               Mean episode length: 220.93
    Episode_Reward/reaching_object: 0.9415
    Episode_Reward/rotating_object: 87.9673
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 1.92s
                      Time elapsed: 00:13:28
                               ETA: 00:43:40

################################################################################
                     [1m Learning iteration 354/1500 [0m                      

                       Computation: 45570 steps/s (collection: 1.979s, learning 0.179s)
             Mean action noise std: 1.69
          Mean value_function loss: 118.3228
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 42.6549
                       Mean reward: 500.05
               Mean episode length: 231.22
    Episode_Reward/reaching_object: 0.9359
    Episode_Reward/rotating_object: 88.0569
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 2.16s
                      Time elapsed: 00:13:30
                               ETA: 00:43:37

################################################################################
                     [1m Learning iteration 355/1500 [0m                      

                       Computation: 48480 steps/s (collection: 1.861s, learning 0.167s)
             Mean action noise std: 1.70
          Mean value_function loss: 102.1150
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.6648
                       Mean reward: 447.72
               Mean episode length: 219.16
    Episode_Reward/reaching_object: 0.9313
    Episode_Reward/rotating_object: 87.7289
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 2.03s
                      Time elapsed: 00:13:32
                               ETA: 00:43:34

################################################################################
                     [1m Learning iteration 356/1500 [0m                      

                       Computation: 49501 steps/s (collection: 1.878s, learning 0.108s)
             Mean action noise std: 1.70
          Mean value_function loss: 118.0755
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 42.6736
                       Mean reward: 478.51
               Mean episode length: 220.06
    Episode_Reward/reaching_object: 0.9316
    Episode_Reward/rotating_object: 90.3358
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 1.99s
                      Time elapsed: 00:13:34
                               ETA: 00:43:31

################################################################################
                     [1m Learning iteration 357/1500 [0m                      

                       Computation: 51377 steps/s (collection: 1.820s, learning 0.094s)
             Mean action noise std: 1.70
          Mean value_function loss: 120.9228
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 42.6802
                       Mean reward: 434.71
               Mean episode length: 217.84
    Episode_Reward/reaching_object: 0.9495
    Episode_Reward/rotating_object: 91.4099
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 1.91s
                      Time elapsed: 00:13:36
                               ETA: 00:43:27

################################################################################
                     [1m Learning iteration 358/1500 [0m                      

                       Computation: 52164 steps/s (collection: 1.795s, learning 0.089s)
             Mean action noise std: 1.70
          Mean value_function loss: 113.7048
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 42.6879
                       Mean reward: 507.27
               Mean episode length: 232.96
    Episode_Reward/reaching_object: 0.9620
    Episode_Reward/rotating_object: 95.3505
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 1.88s
                      Time elapsed: 00:13:38
                               ETA: 00:43:24

################################################################################
                     [1m Learning iteration 359/1500 [0m                      

                       Computation: 52683 steps/s (collection: 1.772s, learning 0.094s)
             Mean action noise std: 1.70
          Mean value_function loss: 117.2787
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 42.6980
                       Mean reward: 434.21
               Mean episode length: 214.53
    Episode_Reward/reaching_object: 0.9313
    Episode_Reward/rotating_object: 90.2792
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 1.87s
                      Time elapsed: 00:13:40
                               ETA: 00:43:20

################################################################################
                     [1m Learning iteration 360/1500 [0m                      

                       Computation: 51464 steps/s (collection: 1.823s, learning 0.087s)
             Mean action noise std: 1.70
          Mean value_function loss: 117.9827
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 42.7072
                       Mean reward: 508.67
               Mean episode length: 234.25
    Episode_Reward/reaching_object: 0.9587
    Episode_Reward/rotating_object: 95.2281
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 1.91s
                      Time elapsed: 00:13:42
                               ETA: 00:43:17

################################################################################
                     [1m Learning iteration 361/1500 [0m                      

                       Computation: 51130 steps/s (collection: 1.827s, learning 0.096s)
             Mean action noise std: 1.70
          Mean value_function loss: 107.0230
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 42.7114
                       Mean reward: 468.04
               Mean episode length: 221.29
    Episode_Reward/reaching_object: 0.9704
    Episode_Reward/rotating_object: 94.4712
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 1.92s
                      Time elapsed: 00:13:44
                               ETA: 00:43:13

################################################################################
                     [1m Learning iteration 362/1500 [0m                      

                       Computation: 50896 steps/s (collection: 1.843s, learning 0.089s)
             Mean action noise std: 1.70
          Mean value_function loss: 98.0769
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 42.7215
                       Mean reward: 495.60
               Mean episode length: 231.19
    Episode_Reward/reaching_object: 0.9401
    Episode_Reward/rotating_object: 92.2658
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 1.93s
                      Time elapsed: 00:13:46
                               ETA: 00:43:10

################################################################################
                     [1m Learning iteration 363/1500 [0m                      

                       Computation: 51465 steps/s (collection: 1.818s, learning 0.093s)
             Mean action noise std: 1.70
          Mean value_function loss: 108.7983
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 42.7330
                       Mean reward: 488.56
               Mean episode length: 230.91
    Episode_Reward/reaching_object: 0.9646
    Episode_Reward/rotating_object: 95.0404
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 1.91s
                      Time elapsed: 00:13:48
                               ETA: 00:43:07

################################################################################
                     [1m Learning iteration 364/1500 [0m                      

                       Computation: 49688 steps/s (collection: 1.849s, learning 0.129s)
             Mean action noise std: 1.70
          Mean value_function loss: 119.3084
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.7396
                       Mean reward: 495.82
               Mean episode length: 221.62
    Episode_Reward/reaching_object: 0.9268
    Episode_Reward/rotating_object: 90.8987
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 1.98s
                      Time elapsed: 00:13:50
                               ETA: 00:43:03

################################################################################
                     [1m Learning iteration 365/1500 [0m                      

                       Computation: 51288 steps/s (collection: 1.812s, learning 0.105s)
             Mean action noise std: 1.70
          Mean value_function loss: 113.9261
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 42.7464
                       Mean reward: 462.52
               Mean episode length: 223.64
    Episode_Reward/reaching_object: 0.9854
    Episode_Reward/rotating_object: 99.2768
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 1.92s
                      Time elapsed: 00:13:52
                               ETA: 00:43:00

################################################################################
                     [1m Learning iteration 366/1500 [0m                      

                       Computation: 49734 steps/s (collection: 1.807s, learning 0.169s)
             Mean action noise std: 1.70
          Mean value_function loss: 109.8286
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 42.7543
                       Mean reward: 490.62
               Mean episode length: 234.12
    Episode_Reward/reaching_object: 0.9638
    Episode_Reward/rotating_object: 93.4875
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 1.98s
                      Time elapsed: 00:13:54
                               ETA: 00:42:57

################################################################################
                     [1m Learning iteration 367/1500 [0m                      

                       Computation: 48703 steps/s (collection: 1.806s, learning 0.213s)
             Mean action noise std: 1.70
          Mean value_function loss: 119.3998
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 42.7604
                       Mean reward: 527.47
               Mean episode length: 231.40
    Episode_Reward/reaching_object: 0.9577
    Episode_Reward/rotating_object: 94.4521
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 2.02s
                      Time elapsed: 00:13:56
                               ETA: 00:42:54

################################################################################
                     [1m Learning iteration 368/1500 [0m                      

                       Computation: 45237 steps/s (collection: 1.984s, learning 0.190s)
             Mean action noise std: 1.70
          Mean value_function loss: 119.6620
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 42.7668
                       Mean reward: 496.95
               Mean episode length: 226.84
    Episode_Reward/reaching_object: 0.9482
    Episode_Reward/rotating_object: 95.0490
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 2.17s
                      Time elapsed: 00:13:58
                               ETA: 00:42:51

################################################################################
                     [1m Learning iteration 369/1500 [0m                      

                       Computation: 48258 steps/s (collection: 1.931s, learning 0.106s)
             Mean action noise std: 1.71
          Mean value_function loss: 139.3011
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 42.7730
                       Mean reward: 483.22
               Mean episode length: 228.05
    Episode_Reward/reaching_object: 0.9608
    Episode_Reward/rotating_object: 94.1189
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 2.04s
                      Time elapsed: 00:14:00
                               ETA: 00:42:48

################################################################################
                     [1m Learning iteration 370/1500 [0m                      

                       Computation: 47941 steps/s (collection: 1.936s, learning 0.114s)
             Mean action noise std: 1.71
          Mean value_function loss: 118.7491
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.7797
                       Mean reward: 463.90
               Mean episode length: 223.87
    Episode_Reward/reaching_object: 0.9727
    Episode_Reward/rotating_object: 95.4002
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 2.05s
                      Time elapsed: 00:14:02
                               ETA: 00:42:45

################################################################################
                     [1m Learning iteration 371/1500 [0m                      

                       Computation: 48677 steps/s (collection: 1.909s, learning 0.110s)
             Mean action noise std: 1.71
          Mean value_function loss: 114.3821
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 42.7876
                       Mean reward: 482.96
               Mean episode length: 231.56
    Episode_Reward/reaching_object: 0.9828
    Episode_Reward/rotating_object: 97.6770
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 2.02s
                      Time elapsed: 00:14:04
                               ETA: 00:42:42

################################################################################
                     [1m Learning iteration 372/1500 [0m                      

                       Computation: 47934 steps/s (collection: 1.907s, learning 0.144s)
             Mean action noise std: 1.71
          Mean value_function loss: 121.7647
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 42.7992
                       Mean reward: 508.12
               Mean episode length: 225.57
    Episode_Reward/reaching_object: 0.9687
    Episode_Reward/rotating_object: 99.3917
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 2.05s
                      Time elapsed: 00:14:06
                               ETA: 00:42:39

################################################################################
                     [1m Learning iteration 373/1500 [0m                      

                       Computation: 49310 steps/s (collection: 1.899s, learning 0.095s)
             Mean action noise std: 1.71
          Mean value_function loss: 116.4491
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 42.8070
                       Mean reward: 480.96
               Mean episode length: 221.73
    Episode_Reward/reaching_object: 0.9568
    Episode_Reward/rotating_object: 95.8097
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 1.99s
                      Time elapsed: 00:14:08
                               ETA: 00:42:36

################################################################################
                     [1m Learning iteration 374/1500 [0m                      

                       Computation: 48670 steps/s (collection: 1.895s, learning 0.125s)
             Mean action noise std: 1.71
          Mean value_function loss: 104.8467
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 42.8122
                       Mean reward: 474.20
               Mean episode length: 223.09
    Episode_Reward/reaching_object: 0.9778
    Episode_Reward/rotating_object: 96.4446
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 2.02s
                      Time elapsed: 00:14:10
                               ETA: 00:42:33

################################################################################
                     [1m Learning iteration 375/1500 [0m                      

                       Computation: 50862 steps/s (collection: 1.834s, learning 0.099s)
             Mean action noise std: 1.71
          Mean value_function loss: 105.7168
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 42.8183
                       Mean reward: 539.03
               Mean episode length: 230.94
    Episode_Reward/reaching_object: 0.9818
    Episode_Reward/rotating_object: 103.3142
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 1.93s
                      Time elapsed: 00:14:12
                               ETA: 00:42:30

################################################################################
                     [1m Learning iteration 376/1500 [0m                      

                       Computation: 49130 steps/s (collection: 1.908s, learning 0.093s)
             Mean action noise std: 1.71
          Mean value_function loss: 122.2518
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 42.8281
                       Mean reward: 491.65
               Mean episode length: 227.34
    Episode_Reward/reaching_object: 0.9290
    Episode_Reward/rotating_object: 92.7325
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 2.00s
                      Time elapsed: 00:14:14
                               ETA: 00:42:27

################################################################################
                     [1m Learning iteration 377/1500 [0m                      

                       Computation: 49861 steps/s (collection: 1.881s, learning 0.091s)
             Mean action noise std: 1.71
          Mean value_function loss: 113.9880
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 42.8424
                       Mean reward: 508.90
               Mean episode length: 229.66
    Episode_Reward/reaching_object: 0.9784
    Episode_Reward/rotating_object: 99.2028
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 1.97s
                      Time elapsed: 00:14:16
                               ETA: 00:42:24

################################################################################
                     [1m Learning iteration 378/1500 [0m                      

                       Computation: 48749 steps/s (collection: 1.925s, learning 0.092s)
             Mean action noise std: 1.71
          Mean value_function loss: 117.2499
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 42.8545
                       Mean reward: 453.64
               Mean episode length: 218.96
    Episode_Reward/reaching_object: 0.9592
    Episode_Reward/rotating_object: 94.8262
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 2.02s
                      Time elapsed: 00:14:18
                               ETA: 00:42:21

################################################################################
                     [1m Learning iteration 379/1500 [0m                      

                       Computation: 47942 steps/s (collection: 1.935s, learning 0.116s)
             Mean action noise std: 1.71
          Mean value_function loss: 117.9696
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 42.8616
                       Mean reward: 490.11
               Mean episode length: 229.20
    Episode_Reward/reaching_object: 0.9496
    Episode_Reward/rotating_object: 94.2496
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 2.05s
                      Time elapsed: 00:14:20
                               ETA: 00:42:18

################################################################################
                     [1m Learning iteration 380/1500 [0m                      

                       Computation: 49021 steps/s (collection: 1.837s, learning 0.169s)
             Mean action noise std: 1.71
          Mean value_function loss: 119.8558
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.8708
                       Mean reward: 476.72
               Mean episode length: 223.83
    Episode_Reward/reaching_object: 0.9608
    Episode_Reward/rotating_object: 98.2590
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 2.01s
                      Time elapsed: 00:14:22
                               ETA: 00:42:15

################################################################################
                     [1m Learning iteration 381/1500 [0m                      

                       Computation: 46562 steps/s (collection: 2.014s, learning 0.097s)
             Mean action noise std: 1.71
          Mean value_function loss: 122.7036
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.8772
                       Mean reward: 512.22
               Mean episode length: 219.69
    Episode_Reward/reaching_object: 0.9631
    Episode_Reward/rotating_object: 98.6387
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 2.11s
                      Time elapsed: 00:14:24
                               ETA: 00:42:12

################################################################################
                     [1m Learning iteration 382/1500 [0m                      

                       Computation: 48804 steps/s (collection: 1.905s, learning 0.110s)
             Mean action noise std: 1.71
          Mean value_function loss: 105.2401
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 42.8811
                       Mean reward: 522.45
               Mean episode length: 228.37
    Episode_Reward/reaching_object: 0.9516
    Episode_Reward/rotating_object: 97.3991
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 2.01s
                      Time elapsed: 00:14:26
                               ETA: 00:42:09

################################################################################
                     [1m Learning iteration 383/1500 [0m                      

                       Computation: 48682 steps/s (collection: 1.926s, learning 0.093s)
             Mean action noise std: 1.72
          Mean value_function loss: 110.6023
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 42.8871
                       Mean reward: 488.54
               Mean episode length: 226.37
    Episode_Reward/reaching_object: 0.9918
    Episode_Reward/rotating_object: 101.6351
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 2.02s
                      Time elapsed: 00:14:28
                               ETA: 00:42:06

################################################################################
                     [1m Learning iteration 384/1500 [0m                      

                       Computation: 49350 steps/s (collection: 1.875s, learning 0.117s)
             Mean action noise std: 1.72
          Mean value_function loss: 111.3224
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 42.8932
                       Mean reward: 502.02
               Mean episode length: 224.03
    Episode_Reward/reaching_object: 0.9675
    Episode_Reward/rotating_object: 99.3038
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 1.99s
                      Time elapsed: 00:14:30
                               ETA: 00:42:03

################################################################################
                     [1m Learning iteration 385/1500 [0m                      

                       Computation: 49198 steps/s (collection: 1.896s, learning 0.102s)
             Mean action noise std: 1.72
          Mean value_function loss: 114.7645
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.9012
                       Mean reward: 514.45
               Mean episode length: 231.82
    Episode_Reward/reaching_object: 0.9765
    Episode_Reward/rotating_object: 102.7610
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 2.00s
                      Time elapsed: 00:14:32
                               ETA: 00:42:00

################################################################################
                     [1m Learning iteration 386/1500 [0m                      

                       Computation: 49292 steps/s (collection: 1.893s, learning 0.101s)
             Mean action noise std: 1.72
          Mean value_function loss: 115.4730
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 42.9090
                       Mean reward: 484.31
               Mean episode length: 227.09
    Episode_Reward/reaching_object: 0.9770
    Episode_Reward/rotating_object: 98.9305
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 1.99s
                      Time elapsed: 00:14:34
                               ETA: 00:41:57

################################################################################
                     [1m Learning iteration 387/1500 [0m                      

                       Computation: 45500 steps/s (collection: 2.008s, learning 0.153s)
             Mean action noise std: 1.72
          Mean value_function loss: 111.9750
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 42.9181
                       Mean reward: 540.85
               Mean episode length: 233.44
    Episode_Reward/reaching_object: 0.9866
    Episode_Reward/rotating_object: 105.9060
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 2.16s
                      Time elapsed: 00:14:36
                               ETA: 00:41:55

################################################################################
                     [1m Learning iteration 388/1500 [0m                      

                       Computation: 45136 steps/s (collection: 2.040s, learning 0.138s)
             Mean action noise std: 1.72
          Mean value_function loss: 113.3043
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.9297
                       Mean reward: 502.18
               Mean episode length: 220.89
    Episode_Reward/reaching_object: 0.9535
    Episode_Reward/rotating_object: 96.9180
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 2.18s
                      Time elapsed: 00:14:38
                               ETA: 00:41:52

################################################################################
                     [1m Learning iteration 389/1500 [0m                      

                       Computation: 45117 steps/s (collection: 2.044s, learning 0.135s)
             Mean action noise std: 1.72
          Mean value_function loss: 114.2770
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.9390
                       Mean reward: 517.36
               Mean episode length: 230.78
    Episode_Reward/reaching_object: 0.9448
    Episode_Reward/rotating_object: 94.2158
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 2.18s
                      Time elapsed: 00:14:41
                               ETA: 00:41:50

################################################################################
                     [1m Learning iteration 390/1500 [0m                      

                       Computation: 45478 steps/s (collection: 1.980s, learning 0.182s)
             Mean action noise std: 1.72
          Mean value_function loss: 118.8067
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 42.9480
                       Mean reward: 513.10
               Mean episode length: 223.88
    Episode_Reward/reaching_object: 1.0007
    Episode_Reward/rotating_object: 101.0678
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 2.16s
                      Time elapsed: 00:14:43
                               ETA: 00:41:47

################################################################################
                     [1m Learning iteration 391/1500 [0m                      

                       Computation: 47957 steps/s (collection: 1.902s, learning 0.147s)
             Mean action noise std: 1.72
          Mean value_function loss: 127.0261
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 42.9548
                       Mean reward: 463.47
               Mean episode length: 212.64
    Episode_Reward/reaching_object: 0.9613
    Episode_Reward/rotating_object: 98.7413
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 2.05s
                      Time elapsed: 00:14:45
                               ETA: 00:41:44

################################################################################
                     [1m Learning iteration 392/1500 [0m                      

                       Computation: 46441 steps/s (collection: 2.017s, learning 0.100s)
             Mean action noise std: 1.72
          Mean value_function loss: 104.9017
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 42.9652
                       Mean reward: 500.93
               Mean episode length: 221.23
    Episode_Reward/reaching_object: 0.9810
    Episode_Reward/rotating_object: 102.3773
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 2.12s
                      Time elapsed: 00:14:47
                               ETA: 00:41:42

################################################################################
                     [1m Learning iteration 393/1500 [0m                      

                       Computation: 45409 steps/s (collection: 2.038s, learning 0.127s)
             Mean action noise std: 1.72
          Mean value_function loss: 109.8461
               Mean surrogate loss: 0.0016
                 Mean entropy loss: 42.9758
                       Mean reward: 524.75
               Mean episode length: 226.91
    Episode_Reward/reaching_object: 1.0273
    Episode_Reward/rotating_object: 106.3858
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 2.16s
                      Time elapsed: 00:14:49
                               ETA: 00:41:39

################################################################################
                     [1m Learning iteration 394/1500 [0m                      

                       Computation: 46153 steps/s (collection: 2.031s, learning 0.099s)
             Mean action noise std: 1.72
          Mean value_function loss: 104.6982
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 42.9793
                       Mean reward: 502.37
               Mean episode length: 228.44
    Episode_Reward/reaching_object: 1.0027
    Episode_Reward/rotating_object: 102.8530
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 2.13s
                      Time elapsed: 00:14:51
                               ETA: 00:41:36

################################################################################
                     [1m Learning iteration 395/1500 [0m                      

                       Computation: 50857 steps/s (collection: 1.841s, learning 0.092s)
             Mean action noise std: 1.72
          Mean value_function loss: 108.8293
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 42.9855
                       Mean reward: 523.25
               Mean episode length: 233.00
    Episode_Reward/reaching_object: 0.9966
    Episode_Reward/rotating_object: 103.9031
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 1.93s
                      Time elapsed: 00:14:53
                               ETA: 00:41:33

################################################################################
                     [1m Learning iteration 396/1500 [0m                      

                       Computation: 49433 steps/s (collection: 1.878s, learning 0.111s)
             Mean action noise std: 1.72
          Mean value_function loss: 108.4459
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 42.9922
                       Mean reward: 544.01
               Mean episode length: 231.22
    Episode_Reward/reaching_object: 0.9910
    Episode_Reward/rotating_object: 104.2994
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 1.99s
                      Time elapsed: 00:14:55
                               ETA: 00:41:30

################################################################################
                     [1m Learning iteration 397/1500 [0m                      

                       Computation: 51615 steps/s (collection: 1.812s, learning 0.093s)
             Mean action noise std: 1.72
          Mean value_function loss: 104.8643
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 42.9982
                       Mean reward: 524.47
               Mean episode length: 230.20
    Episode_Reward/reaching_object: 1.0070
    Episode_Reward/rotating_object: 106.4687
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 1.90s
                      Time elapsed: 00:14:57
                               ETA: 00:41:27

################################################################################
                     [1m Learning iteration 398/1500 [0m                      

                       Computation: 52140 steps/s (collection: 1.783s, learning 0.102s)
             Mean action noise std: 1.73
          Mean value_function loss: 95.8905
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.0033
                       Mean reward: 528.31
               Mean episode length: 227.71
    Episode_Reward/reaching_object: 1.0012
    Episode_Reward/rotating_object: 105.4704
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 1.89s
                      Time elapsed: 00:14:59
                               ETA: 00:41:24

################################################################################
                     [1m Learning iteration 399/1500 [0m                      

                       Computation: 50613 steps/s (collection: 1.839s, learning 0.103s)
             Mean action noise std: 1.73
          Mean value_function loss: 89.7624
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 43.0127
                       Mean reward: 522.71
               Mean episode length: 226.25
    Episode_Reward/reaching_object: 1.0074
    Episode_Reward/rotating_object: 107.9396
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 1.94s
                      Time elapsed: 00:15:01
                               ETA: 00:41:21

################################################################################
                     [1m Learning iteration 400/1500 [0m                      

                       Computation: 52517 steps/s (collection: 1.773s, learning 0.099s)
             Mean action noise std: 1.73
          Mean value_function loss: 98.4122
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 43.0217
                       Mean reward: 546.31
               Mean episode length: 232.23
    Episode_Reward/reaching_object: 1.0027
    Episode_Reward/rotating_object: 105.6197
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 1.87s
                      Time elapsed: 00:15:03
                               ETA: 00:41:17

################################################################################
                     [1m Learning iteration 401/1500 [0m                      

                       Computation: 52822 steps/s (collection: 1.766s, learning 0.095s)
             Mean action noise std: 1.73
          Mean value_function loss: 103.5445
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 43.0332
                       Mean reward: 554.31
               Mean episode length: 236.18
    Episode_Reward/reaching_object: 0.9919
    Episode_Reward/rotating_object: 107.3609
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 1.86s
                      Time elapsed: 00:15:05
                               ETA: 00:41:14

################################################################################
                     [1m Learning iteration 402/1500 [0m                      

                       Computation: 49080 steps/s (collection: 1.897s, learning 0.106s)
             Mean action noise std: 1.73
          Mean value_function loss: 100.9548
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.0490
                       Mean reward: 521.28
               Mean episode length: 225.80
    Episode_Reward/reaching_object: 0.9950
    Episode_Reward/rotating_object: 108.0369
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 2.00s
                      Time elapsed: 00:15:07
                               ETA: 00:41:11

################################################################################
                     [1m Learning iteration 403/1500 [0m                      

                       Computation: 51609 steps/s (collection: 1.810s, learning 0.095s)
             Mean action noise std: 1.73
          Mean value_function loss: 97.5363
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 43.0580
                       Mean reward: 493.09
               Mean episode length: 222.36
    Episode_Reward/reaching_object: 0.9952
    Episode_Reward/rotating_object: 107.3538
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 1.90s
                      Time elapsed: 00:15:09
                               ETA: 00:41:08

################################################################################
                     [1m Learning iteration 404/1500 [0m                      

                       Computation: 50585 steps/s (collection: 1.833s, learning 0.111s)
             Mean action noise std: 1.73
          Mean value_function loss: 101.3112
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 43.0608
                       Mean reward: 551.53
               Mean episode length: 235.85
    Episode_Reward/reaching_object: 0.9907
    Episode_Reward/rotating_object: 106.4476
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 1.94s
                      Time elapsed: 00:15:10
                               ETA: 00:41:05

################################################################################
                     [1m Learning iteration 405/1500 [0m                      

                       Computation: 52679 steps/s (collection: 1.772s, learning 0.095s)
             Mean action noise std: 1.73
          Mean value_function loss: 94.6193
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 43.0658
                       Mean reward: 516.38
               Mean episode length: 228.24
    Episode_Reward/reaching_object: 0.9737
    Episode_Reward/rotating_object: 103.4131
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 1.87s
                      Time elapsed: 00:15:12
                               ETA: 00:41:02

################################################################################
                     [1m Learning iteration 406/1500 [0m                      

                       Computation: 52951 steps/s (collection: 1.756s, learning 0.100s)
             Mean action noise std: 1.73
          Mean value_function loss: 104.9128
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 43.0763
                       Mean reward: 535.54
               Mean episode length: 236.17
    Episode_Reward/reaching_object: 0.9803
    Episode_Reward/rotating_object: 108.0472
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 1.86s
                      Time elapsed: 00:15:14
                               ETA: 00:40:58

################################################################################
                     [1m Learning iteration 407/1500 [0m                      

                       Computation: 51832 steps/s (collection: 1.792s, learning 0.105s)
             Mean action noise std: 1.73
          Mean value_function loss: 102.5553
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 43.0855
                       Mean reward: 557.77
               Mean episode length: 231.06
    Episode_Reward/reaching_object: 0.9780
    Episode_Reward/rotating_object: 106.7335
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 1.90s
                      Time elapsed: 00:15:16
                               ETA: 00:40:55

################################################################################
                     [1m Learning iteration 408/1500 [0m                      

                       Computation: 53271 steps/s (collection: 1.751s, learning 0.094s)
             Mean action noise std: 1.73
          Mean value_function loss: 98.6664
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 43.0929
                       Mean reward: 498.66
               Mean episode length: 220.91
    Episode_Reward/reaching_object: 0.9808
    Episode_Reward/rotating_object: 110.6407
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 1.85s
                      Time elapsed: 00:15:18
                               ETA: 00:40:52

################################################################################
                     [1m Learning iteration 409/1500 [0m                      

                       Computation: 52255 steps/s (collection: 1.786s, learning 0.096s)
             Mean action noise std: 1.73
          Mean value_function loss: 92.3345
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.0975
                       Mean reward: 533.59
               Mean episode length: 230.28
    Episode_Reward/reaching_object: 0.9871
    Episode_Reward/rotating_object: 107.2169
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 1.88s
                      Time elapsed: 00:15:20
                               ETA: 00:40:48

################################################################################
                     [1m Learning iteration 410/1500 [0m                      

                       Computation: 48155 steps/s (collection: 1.934s, learning 0.108s)
             Mean action noise std: 1.73
          Mean value_function loss: 100.3354
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 43.1088
                       Mean reward: 574.90
               Mean episode length: 230.21
    Episode_Reward/reaching_object: 0.9747
    Episode_Reward/rotating_object: 109.2955
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 2.04s
                      Time elapsed: 00:15:22
                               ETA: 00:40:46

################################################################################
                     [1m Learning iteration 411/1500 [0m                      

                       Computation: 50923 steps/s (collection: 1.825s, learning 0.106s)
             Mean action noise std: 1.74
          Mean value_function loss: 102.1970
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 43.1230
                       Mean reward: 536.90
               Mean episode length: 225.35
    Episode_Reward/reaching_object: 0.9781
    Episode_Reward/rotating_object: 109.8604
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 1.93s
                      Time elapsed: 00:15:24
                               ETA: 00:40:43

################################################################################
                     [1m Learning iteration 412/1500 [0m                      

                       Computation: 50763 steps/s (collection: 1.819s, learning 0.118s)
             Mean action noise std: 1.74
          Mean value_function loss: 88.4151
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.1338
                       Mean reward: 507.00
               Mean episode length: 224.03
    Episode_Reward/reaching_object: 0.9714
    Episode_Reward/rotating_object: 110.6853
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 1.94s
                      Time elapsed: 00:15:26
                               ETA: 00:40:40

################################################################################
                     [1m Learning iteration 413/1500 [0m                      

                       Computation: 51926 steps/s (collection: 1.801s, learning 0.092s)
             Mean action noise std: 1.74
          Mean value_function loss: 87.6374
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.1405
                       Mean reward: 566.06
               Mean episode length: 231.80
    Episode_Reward/reaching_object: 0.9727
    Episode_Reward/rotating_object: 110.0780
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 1.89s
                      Time elapsed: 00:15:28
                               ETA: 00:40:36

################################################################################
                     [1m Learning iteration 414/1500 [0m                      

                       Computation: 51818 steps/s (collection: 1.807s, learning 0.090s)
             Mean action noise std: 1.74
          Mean value_function loss: 98.8369
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 43.1484
                       Mean reward: 581.33
               Mean episode length: 236.86
    Episode_Reward/reaching_object: 0.9784
    Episode_Reward/rotating_object: 111.2495
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 1.90s
                      Time elapsed: 00:15:30
                               ETA: 00:40:33

################################################################################
                     [1m Learning iteration 415/1500 [0m                      

                       Computation: 51206 steps/s (collection: 1.821s, learning 0.099s)
             Mean action noise std: 1.74
          Mean value_function loss: 87.9912
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 43.1554
                       Mean reward: 559.14
               Mean episode length: 225.54
    Episode_Reward/reaching_object: 0.9558
    Episode_Reward/rotating_object: 110.9774
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 1.92s
                      Time elapsed: 00:15:31
                               ETA: 00:40:30

################################################################################
                     [1m Learning iteration 416/1500 [0m                      

                       Computation: 52830 steps/s (collection: 1.769s, learning 0.092s)
             Mean action noise std: 1.74
          Mean value_function loss: 108.4532
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 43.1637
                       Mean reward: 597.93
               Mean episode length: 236.06
    Episode_Reward/reaching_object: 0.9896
    Episode_Reward/rotating_object: 113.6644
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 1.86s
                      Time elapsed: 00:15:33
                               ETA: 00:40:27

################################################################################
                     [1m Learning iteration 417/1500 [0m                      

                       Computation: 51739 steps/s (collection: 1.794s, learning 0.106s)
             Mean action noise std: 1.74
          Mean value_function loss: 98.0117
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.1729
                       Mean reward: 542.41
               Mean episode length: 223.98
    Episode_Reward/reaching_object: 0.9618
    Episode_Reward/rotating_object: 108.4091
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 1.90s
                      Time elapsed: 00:15:35
                               ETA: 00:40:24

################################################################################
                     [1m Learning iteration 418/1500 [0m                      

                       Computation: 51450 steps/s (collection: 1.794s, learning 0.116s)
             Mean action noise std: 1.74
          Mean value_function loss: 101.6435
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 43.1871
                       Mean reward: 538.27
               Mean episode length: 225.10
    Episode_Reward/reaching_object: 0.9515
    Episode_Reward/rotating_object: 109.0652
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 1.91s
                      Time elapsed: 00:15:37
                               ETA: 00:40:21

################################################################################
                     [1m Learning iteration 419/1500 [0m                      

                       Computation: 52233 steps/s (collection: 1.774s, learning 0.108s)
             Mean action noise std: 1.74
          Mean value_function loss: 100.2366
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 43.2020
                       Mean reward: 560.31
               Mean episode length: 225.51
    Episode_Reward/reaching_object: 0.9658
    Episode_Reward/rotating_object: 110.9895
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 1.88s
                      Time elapsed: 00:15:39
                               ETA: 00:40:18

################################################################################
                     [1m Learning iteration 420/1500 [0m                      

                       Computation: 50569 steps/s (collection: 1.833s, learning 0.111s)
             Mean action noise std: 1.74
          Mean value_function loss: 94.9544
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.2191
                       Mean reward: 548.71
               Mean episode length: 226.60
    Episode_Reward/reaching_object: 0.9646
    Episode_Reward/rotating_object: 109.5903
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 1.94s
                      Time elapsed: 00:15:41
                               ETA: 00:40:15

################################################################################
                     [1m Learning iteration 421/1500 [0m                      

                       Computation: 50746 steps/s (collection: 1.819s, learning 0.118s)
             Mean action noise std: 1.75
          Mean value_function loss: 114.7628
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 43.2336
                       Mean reward: 531.32
               Mean episode length: 221.28
    Episode_Reward/reaching_object: 0.9737
    Episode_Reward/rotating_object: 110.2115
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 1.94s
                      Time elapsed: 00:15:43
                               ETA: 00:40:12

################################################################################
                     [1m Learning iteration 422/1500 [0m                      

                       Computation: 49253 steps/s (collection: 1.880s, learning 0.116s)
             Mean action noise std: 1.75
          Mean value_function loss: 111.2512
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 43.2508
                       Mean reward: 583.53
               Mean episode length: 235.38
    Episode_Reward/reaching_object: 0.9902
    Episode_Reward/rotating_object: 114.3344
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 2.00s
                      Time elapsed: 00:15:45
                               ETA: 00:40:09

################################################################################
                     [1m Learning iteration 423/1500 [0m                      

                       Computation: 50969 steps/s (collection: 1.827s, learning 0.102s)
             Mean action noise std: 1.75
          Mean value_function loss: 107.6875
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.2622
                       Mean reward: 563.76
               Mean episode length: 228.17
    Episode_Reward/reaching_object: 0.9942
    Episode_Reward/rotating_object: 112.8596
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 1.93s
                      Time elapsed: 00:15:47
                               ETA: 00:40:06

################################################################################
                     [1m Learning iteration 424/1500 [0m                      

                       Computation: 51574 steps/s (collection: 1.812s, learning 0.094s)
             Mean action noise std: 1.75
          Mean value_function loss: 95.9269
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 43.2690
                       Mean reward: 601.22
               Mean episode length: 234.11
    Episode_Reward/reaching_object: 1.0021
    Episode_Reward/rotating_object: 116.2685
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 1.91s
                      Time elapsed: 00:15:49
                               ETA: 00:40:03

################################################################################
                     [1m Learning iteration 425/1500 [0m                      

                       Computation: 44079 steps/s (collection: 2.035s, learning 0.195s)
             Mean action noise std: 1.75
          Mean value_function loss: 103.2451
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.2820
                       Mean reward: 573.27
               Mean episode length: 232.91
    Episode_Reward/reaching_object: 0.9951
    Episode_Reward/rotating_object: 116.3073
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 2.23s
                      Time elapsed: 00:15:51
                               ETA: 00:40:00

################################################################################
                     [1m Learning iteration 426/1500 [0m                      

                       Computation: 43683 steps/s (collection: 2.071s, learning 0.180s)
             Mean action noise std: 1.75
          Mean value_function loss: 103.8339
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 43.2948
                       Mean reward: 505.94
               Mean episode length: 213.18
    Episode_Reward/reaching_object: 0.9560
    Episode_Reward/rotating_object: 106.2227
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 2.25s
                      Time elapsed: 00:15:53
                               ETA: 00:39:58

################################################################################
                     [1m Learning iteration 427/1500 [0m                      

                       Computation: 44774 steps/s (collection: 2.100s, learning 0.096s)
             Mean action noise std: 1.75
          Mean value_function loss: 106.7065
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.3063
                       Mean reward: 571.21
               Mean episode length: 226.72
    Episode_Reward/reaching_object: 0.9966
    Episode_Reward/rotating_object: 115.0240
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 2.20s
                      Time elapsed: 00:15:55
                               ETA: 00:39:56

################################################################################
                     [1m Learning iteration 428/1500 [0m                      

                       Computation: 47447 steps/s (collection: 1.971s, learning 0.101s)
             Mean action noise std: 1.75
          Mean value_function loss: 92.3179
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 43.3175
                       Mean reward: 538.88
               Mean episode length: 219.39
    Episode_Reward/reaching_object: 0.9624
    Episode_Reward/rotating_object: 107.5512
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 2.07s
                      Time elapsed: 00:15:57
                               ETA: 00:39:53

################################################################################
                     [1m Learning iteration 429/1500 [0m                      

                       Computation: 51561 steps/s (collection: 1.814s, learning 0.093s)
             Mean action noise std: 1.75
          Mean value_function loss: 105.4341
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.3367
                       Mean reward: 575.89
               Mean episode length: 231.18
    Episode_Reward/reaching_object: 1.0000
    Episode_Reward/rotating_object: 115.7986
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 1.91s
                      Time elapsed: 00:15:59
                               ETA: 00:39:50

################################################################################
                     [1m Learning iteration 430/1500 [0m                      

                       Computation: 50098 steps/s (collection: 1.872s, learning 0.090s)
             Mean action noise std: 1.76
          Mean value_function loss: 106.2037
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 43.3477
                       Mean reward: 544.64
               Mean episode length: 227.45
    Episode_Reward/reaching_object: 0.9937
    Episode_Reward/rotating_object: 114.1776
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 1.96s
                      Time elapsed: 00:16:01
                               ETA: 00:39:47

################################################################################
                     [1m Learning iteration 431/1500 [0m                      

                       Computation: 50440 steps/s (collection: 1.843s, learning 0.106s)
             Mean action noise std: 1.76
          Mean value_function loss: 104.6944
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 43.3600
                       Mean reward: 584.39
               Mean episode length: 225.89
    Episode_Reward/reaching_object: 0.9830
    Episode_Reward/rotating_object: 108.9903
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 1.95s
                      Time elapsed: 00:16:03
                               ETA: 00:39:44

################################################################################
                     [1m Learning iteration 432/1500 [0m                      

                       Computation: 49474 steps/s (collection: 1.896s, learning 0.090s)
             Mean action noise std: 1.76
          Mean value_function loss: 107.4145
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 43.3734
                       Mean reward: 569.26
               Mean episode length: 229.86
    Episode_Reward/reaching_object: 0.9672
    Episode_Reward/rotating_object: 106.4915
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 1.99s
                      Time elapsed: 00:16:05
                               ETA: 00:39:42

################################################################################
                     [1m Learning iteration 433/1500 [0m                      

                       Computation: 50288 steps/s (collection: 1.803s, learning 0.152s)
             Mean action noise std: 1.76
          Mean value_function loss: 103.7223
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 43.3844
                       Mean reward: 550.80
               Mean episode length: 224.32
    Episode_Reward/reaching_object: 0.9903
    Episode_Reward/rotating_object: 113.3740
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 1.95s
                      Time elapsed: 00:16:07
                               ETA: 00:39:39

################################################################################
                     [1m Learning iteration 434/1500 [0m                      

                       Computation: 51462 steps/s (collection: 1.779s, learning 0.131s)
             Mean action noise std: 1.76
          Mean value_function loss: 105.7075
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 43.3925
                       Mean reward: 606.37
               Mean episode length: 236.95
    Episode_Reward/reaching_object: 0.9976
    Episode_Reward/rotating_object: 114.8101
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 1.91s
                      Time elapsed: 00:16:09
                               ETA: 00:39:36

################################################################################
                     [1m Learning iteration 435/1500 [0m                      

                       Computation: 50180 steps/s (collection: 1.808s, learning 0.151s)
             Mean action noise std: 1.76
          Mean value_function loss: 94.8583
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.3990
                       Mean reward: 559.46
               Mean episode length: 229.29
    Episode_Reward/reaching_object: 1.0052
    Episode_Reward/rotating_object: 115.8588
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 1.96s
                      Time elapsed: 00:16:11
                               ETA: 00:39:33

################################################################################
                     [1m Learning iteration 436/1500 [0m                      

                       Computation: 47608 steps/s (collection: 1.900s, learning 0.165s)
             Mean action noise std: 1.76
          Mean value_function loss: 93.0893
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 43.4076
                       Mean reward: 579.34
               Mean episode length: 232.38
    Episode_Reward/reaching_object: 1.0115
    Episode_Reward/rotating_object: 114.5093
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 2.06s
                      Time elapsed: 00:16:13
                               ETA: 00:39:30

################################################################################
                     [1m Learning iteration 437/1500 [0m                      

                       Computation: 49175 steps/s (collection: 1.843s, learning 0.156s)
             Mean action noise std: 1.76
          Mean value_function loss: 105.6234
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 43.4139
                       Mean reward: 598.81
               Mean episode length: 237.08
    Episode_Reward/reaching_object: 1.0122
    Episode_Reward/rotating_object: 115.2130
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 2.00s
                      Time elapsed: 00:16:15
                               ETA: 00:39:27

################################################################################
                     [1m Learning iteration 438/1500 [0m                      

                       Computation: 50165 steps/s (collection: 1.794s, learning 0.165s)
             Mean action noise std: 1.76
          Mean value_function loss: 101.4312
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 43.4216
                       Mean reward: 604.01
               Mean episode length: 235.60
    Episode_Reward/reaching_object: 1.0238
    Episode_Reward/rotating_object: 116.4286
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 1.96s
                      Time elapsed: 00:16:17
                               ETA: 00:39:24

################################################################################
                     [1m Learning iteration 439/1500 [0m                      

                       Computation: 50534 steps/s (collection: 1.824s, learning 0.122s)
             Mean action noise std: 1.76
          Mean value_function loss: 110.8012
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 43.4341
                       Mean reward: 538.17
               Mean episode length: 222.48
    Episode_Reward/reaching_object: 0.9849
    Episode_Reward/rotating_object: 110.4544
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 1.95s
                      Time elapsed: 00:16:19
                               ETA: 00:39:22

################################################################################
                     [1m Learning iteration 440/1500 [0m                      

                       Computation: 50158 steps/s (collection: 1.828s, learning 0.132s)
             Mean action noise std: 1.77
          Mean value_function loss: 94.7049
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.4483
                       Mean reward: 616.47
               Mean episode length: 238.90
    Episode_Reward/reaching_object: 1.0420
    Episode_Reward/rotating_object: 120.2723
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 1.96s
                      Time elapsed: 00:16:21
                               ETA: 00:39:19

################################################################################
                     [1m Learning iteration 441/1500 [0m                      

                       Computation: 49795 steps/s (collection: 1.879s, learning 0.096s)
             Mean action noise std: 1.77
          Mean value_function loss: 89.6992
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 43.4538
                       Mean reward: 617.97
               Mean episode length: 238.86
    Episode_Reward/reaching_object: 1.0144
    Episode_Reward/rotating_object: 116.8797
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 1.97s
                      Time elapsed: 00:16:23
                               ETA: 00:39:16

################################################################################
                     [1m Learning iteration 442/1500 [0m                      

                       Computation: 50183 steps/s (collection: 1.851s, learning 0.108s)
             Mean action noise std: 1.77
          Mean value_function loss: 98.8524
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.4645
                       Mean reward: 581.77
               Mean episode length: 233.88
    Episode_Reward/reaching_object: 1.0082
    Episode_Reward/rotating_object: 116.9550
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 1.96s
                      Time elapsed: 00:16:25
                               ETA: 00:39:13

################################################################################
                     [1m Learning iteration 443/1500 [0m                      

                       Computation: 50188 steps/s (collection: 1.854s, learning 0.105s)
             Mean action noise std: 1.77
          Mean value_function loss: 101.5158
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.4788
                       Mean reward: 634.81
               Mean episode length: 238.61
    Episode_Reward/reaching_object: 1.0141
    Episode_Reward/rotating_object: 118.2720
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 1.96s
                      Time elapsed: 00:16:27
                               ETA: 00:39:10

################################################################################
                     [1m Learning iteration 444/1500 [0m                      

                       Computation: 45849 steps/s (collection: 1.973s, learning 0.171s)
             Mean action noise std: 1.77
          Mean value_function loss: 104.2141
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 43.4947
                       Mean reward: 633.03
               Mean episode length: 240.73
    Episode_Reward/reaching_object: 1.0156
    Episode_Reward/rotating_object: 119.6644
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 2.14s
                      Time elapsed: 00:16:29
                               ETA: 00:39:08

################################################################################
                     [1m Learning iteration 445/1500 [0m                      

                       Computation: 44696 steps/s (collection: 2.108s, learning 0.092s)
             Mean action noise std: 1.77
          Mean value_function loss: 94.5473
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 43.5097
                       Mean reward: 584.16
               Mean episode length: 232.67
    Episode_Reward/reaching_object: 1.0195
    Episode_Reward/rotating_object: 118.4782
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 2.20s
                      Time elapsed: 00:16:31
                               ETA: 00:39:05

################################################################################
                     [1m Learning iteration 446/1500 [0m                      

                       Computation: 49094 steps/s (collection: 1.861s, learning 0.142s)
             Mean action noise std: 1.77
          Mean value_function loss: 99.9517
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.5225
                       Mean reward: 601.05
               Mean episode length: 230.09
    Episode_Reward/reaching_object: 1.0284
    Episode_Reward/rotating_object: 118.1240
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 2.00s
                      Time elapsed: 00:16:33
                               ETA: 00:39:03

################################################################################
                     [1m Learning iteration 447/1500 [0m                      

                       Computation: 47435 steps/s (collection: 1.947s, learning 0.125s)
             Mean action noise std: 1.77
          Mean value_function loss: 103.4261
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.5304
                       Mean reward: 590.86
               Mean episode length: 226.40
    Episode_Reward/reaching_object: 1.0035
    Episode_Reward/rotating_object: 118.5006
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 2.07s
                      Time elapsed: 00:16:35
                               ETA: 00:39:00

################################################################################
                     [1m Learning iteration 448/1500 [0m                      

                       Computation: 47744 steps/s (collection: 1.955s, learning 0.104s)
             Mean action noise std: 1.77
          Mean value_function loss: 89.0925
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 43.5339
                       Mean reward: 576.12
               Mean episode length: 225.47
    Episode_Reward/reaching_object: 1.0085
    Episode_Reward/rotating_object: 116.3775
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 2.06s
                      Time elapsed: 00:16:37
                               ETA: 00:38:58

################################################################################
                     [1m Learning iteration 449/1500 [0m                      

                       Computation: 48654 steps/s (collection: 1.920s, learning 0.100s)
             Mean action noise std: 1.77
          Mean value_function loss: 94.0721
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 43.5362
                       Mean reward: 628.49
               Mean episode length: 235.79
    Episode_Reward/reaching_object: 1.0241
    Episode_Reward/rotating_object: 123.0416
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 2.02s
                      Time elapsed: 00:16:39
                               ETA: 00:38:55

################################################################################
                     [1m Learning iteration 450/1500 [0m                      

                       Computation: 48048 steps/s (collection: 1.943s, learning 0.103s)
             Mean action noise std: 1.77
          Mean value_function loss: 84.0203
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 43.5453
                       Mean reward: 620.31
               Mean episode length: 242.18
    Episode_Reward/reaching_object: 1.0385
    Episode_Reward/rotating_object: 121.0902
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 2.05s
                      Time elapsed: 00:16:41
                               ETA: 00:38:52

################################################################################
                     [1m Learning iteration 451/1500 [0m                      

                       Computation: 48742 steps/s (collection: 1.923s, learning 0.094s)
             Mean action noise std: 1.78
          Mean value_function loss: 83.2486
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.5608
                       Mean reward: 598.96
               Mean episode length: 234.95
    Episode_Reward/reaching_object: 1.0087
    Episode_Reward/rotating_object: 118.4246
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 2.02s
                      Time elapsed: 00:16:43
                               ETA: 00:38:50

################################################################################
                     [1m Learning iteration 452/1500 [0m                      

                       Computation: 47783 steps/s (collection: 1.957s, learning 0.101s)
             Mean action noise std: 1.78
          Mean value_function loss: 88.6367
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 43.5744
                       Mean reward: 620.53
               Mean episode length: 237.16
    Episode_Reward/reaching_object: 1.0334
    Episode_Reward/rotating_object: 120.9882
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 2.06s
                      Time elapsed: 00:16:46
                               ETA: 00:38:47

################################################################################
                     [1m Learning iteration 453/1500 [0m                      

                       Computation: 47869 steps/s (collection: 1.936s, learning 0.117s)
             Mean action noise std: 1.78
          Mean value_function loss: 96.5710
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 43.5859
                       Mean reward: 621.72
               Mean episode length: 233.49
    Episode_Reward/reaching_object: 1.0408
    Episode_Reward/rotating_object: 125.8692
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 2.05s
                      Time elapsed: 00:16:48
                               ETA: 00:38:44

################################################################################
                     [1m Learning iteration 454/1500 [0m                      

                       Computation: 47029 steps/s (collection: 1.988s, learning 0.103s)
             Mean action noise std: 1.78
          Mean value_function loss: 98.2530
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 43.6027
                       Mean reward: 575.45
               Mean episode length: 228.17
    Episode_Reward/reaching_object: 1.0240
    Episode_Reward/rotating_object: 118.4936
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 2.09s
                      Time elapsed: 00:16:50
                               ETA: 00:38:42

################################################################################
                     [1m Learning iteration 455/1500 [0m                      

                       Computation: 48959 steps/s (collection: 1.909s, learning 0.099s)
             Mean action noise std: 1.78
          Mean value_function loss: 90.5535
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 43.6190
                       Mean reward: 620.12
               Mean episode length: 243.01
    Episode_Reward/reaching_object: 1.0447
    Episode_Reward/rotating_object: 124.2646
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 2.01s
                      Time elapsed: 00:16:52
                               ETA: 00:38:39

################################################################################
                     [1m Learning iteration 456/1500 [0m                      

                       Computation: 48984 steps/s (collection: 1.910s, learning 0.097s)
             Mean action noise std: 1.78
          Mean value_function loss: 99.1642
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.6279
                       Mean reward: 555.51
               Mean episode length: 229.60
    Episode_Reward/reaching_object: 0.9955
    Episode_Reward/rotating_object: 114.3909
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 2.01s
                      Time elapsed: 00:16:54
                               ETA: 00:38:36

################################################################################
                     [1m Learning iteration 457/1500 [0m                      

                       Computation: 48038 steps/s (collection: 1.952s, learning 0.094s)
             Mean action noise std: 1.78
          Mean value_function loss: 83.1402
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 43.6363
                       Mean reward: 649.59
               Mean episode length: 240.79
    Episode_Reward/reaching_object: 1.0279
    Episode_Reward/rotating_object: 122.3655
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 2.05s
                      Time elapsed: 00:16:56
                               ETA: 00:38:34

################################################################################
                     [1m Learning iteration 458/1500 [0m                      

                       Computation: 45475 steps/s (collection: 2.054s, learning 0.107s)
             Mean action noise std: 1.78
          Mean value_function loss: 87.5273
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 43.6420
                       Mean reward: 604.80
               Mean episode length: 234.99
    Episode_Reward/reaching_object: 1.0301
    Episode_Reward/rotating_object: 121.1641
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 2.16s
                      Time elapsed: 00:16:58
                               ETA: 00:38:31

################################################################################
                     [1m Learning iteration 459/1500 [0m                      

                       Computation: 48299 steps/s (collection: 1.924s, learning 0.112s)
             Mean action noise std: 1.79
          Mean value_function loss: 86.6818
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 43.6584
                       Mean reward: 625.37
               Mean episode length: 234.77
    Episode_Reward/reaching_object: 1.0284
    Episode_Reward/rotating_object: 120.3913
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 2.04s
                      Time elapsed: 00:17:00
                               ETA: 00:38:29

################################################################################
                     [1m Learning iteration 460/1500 [0m                      

                       Computation: 47085 steps/s (collection: 1.985s, learning 0.103s)
             Mean action noise std: 1.79
          Mean value_function loss: 91.6127
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 43.6794
                       Mean reward: 613.53
               Mean episode length: 236.70
    Episode_Reward/reaching_object: 1.0452
    Episode_Reward/rotating_object: 120.6807
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 2.09s
                      Time elapsed: 00:17:02
                               ETA: 00:38:26

################################################################################
                     [1m Learning iteration 461/1500 [0m                      

                       Computation: 49052 steps/s (collection: 1.888s, learning 0.116s)
             Mean action noise std: 1.79
          Mean value_function loss: 87.8669
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 43.6997
                       Mean reward: 603.44
               Mean episode length: 230.19
    Episode_Reward/reaching_object: 1.0081
    Episode_Reward/rotating_object: 116.3521
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 2.00s
                      Time elapsed: 00:17:04
                               ETA: 00:38:24

################################################################################
                     [1m Learning iteration 462/1500 [0m                      

                       Computation: 47567 steps/s (collection: 1.911s, learning 0.155s)
             Mean action noise std: 1.79
          Mean value_function loss: 88.0960
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.7090
                       Mean reward: 658.49
               Mean episode length: 244.56
    Episode_Reward/reaching_object: 1.0403
    Episode_Reward/rotating_object: 123.6297
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 2.07s
                      Time elapsed: 00:17:06
                               ETA: 00:38:21

################################################################################
                     [1m Learning iteration 463/1500 [0m                      

                       Computation: 47530 steps/s (collection: 1.927s, learning 0.141s)
             Mean action noise std: 1.79
          Mean value_function loss: 87.0501
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 43.7225
                       Mean reward: 617.07
               Mean episode length: 234.34
    Episode_Reward/reaching_object: 1.0596
    Episode_Reward/rotating_object: 126.7906
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 2.07s
                      Time elapsed: 00:17:08
                               ETA: 00:38:18

################################################################################
                     [1m Learning iteration 464/1500 [0m                      

                       Computation: 46937 steps/s (collection: 1.940s, learning 0.155s)
             Mean action noise std: 1.79
          Mean value_function loss: 91.8606
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 43.7374
                       Mean reward: 561.24
               Mean episode length: 223.19
    Episode_Reward/reaching_object: 1.0172
    Episode_Reward/rotating_object: 119.5769
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 2.09s
                      Time elapsed: 00:17:10
                               ETA: 00:38:16

################################################################################
                     [1m Learning iteration 465/1500 [0m                      

                       Computation: 47178 steps/s (collection: 1.943s, learning 0.141s)
             Mean action noise std: 1.79
          Mean value_function loss: 85.4096
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 43.7530
                       Mean reward: 634.89
               Mean episode length: 241.03
    Episode_Reward/reaching_object: 1.0373
    Episode_Reward/rotating_object: 119.9791
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 2.08s
                      Time elapsed: 00:17:12
                               ETA: 00:38:13

################################################################################
                     [1m Learning iteration 466/1500 [0m                      

                       Computation: 48024 steps/s (collection: 1.917s, learning 0.130s)
             Mean action noise std: 1.79
          Mean value_function loss: 92.5986
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.7669
                       Mean reward: 607.12
               Mean episode length: 236.43
    Episode_Reward/reaching_object: 1.0202
    Episode_Reward/rotating_object: 121.6969
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 2.05s
                      Time elapsed: 00:17:14
                               ETA: 00:38:11

################################################################################
                     [1m Learning iteration 467/1500 [0m                      

                       Computation: 47880 steps/s (collection: 1.936s, learning 0.118s)
             Mean action noise std: 1.80
          Mean value_function loss: 97.4825
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.7756
                       Mean reward: 684.36
               Mean episode length: 241.74
    Episode_Reward/reaching_object: 1.0497
    Episode_Reward/rotating_object: 126.3288
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 2.05s
                      Time elapsed: 00:17:16
                               ETA: 00:38:08

################################################################################
                     [1m Learning iteration 468/1500 [0m                      

                       Computation: 47584 steps/s (collection: 1.942s, learning 0.124s)
             Mean action noise std: 1.80
          Mean value_function loss: 85.4199
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 43.7921
                       Mean reward: 661.83
               Mean episode length: 242.08
    Episode_Reward/reaching_object: 1.0247
    Episode_Reward/rotating_object: 121.8863
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 2.07s
                      Time elapsed: 00:17:19
                               ETA: 00:38:06

################################################################################
                     [1m Learning iteration 469/1500 [0m                      

                       Computation: 49477 steps/s (collection: 1.891s, learning 0.096s)
             Mean action noise std: 1.80
          Mean value_function loss: 70.8334
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 43.8085
                       Mean reward: 643.04
               Mean episode length: 240.25
    Episode_Reward/reaching_object: 1.0587
    Episode_Reward/rotating_object: 126.5826
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 1.99s
                      Time elapsed: 00:17:20
                               ETA: 00:38:03

################################################################################
                     [1m Learning iteration 470/1500 [0m                      

                       Computation: 48986 steps/s (collection: 1.913s, learning 0.094s)
             Mean action noise std: 1.80
          Mean value_function loss: 85.9157
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.8123
                       Mean reward: 618.85
               Mean episode length: 237.73
    Episode_Reward/reaching_object: 1.0248
    Episode_Reward/rotating_object: 121.9682
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 2.01s
                      Time elapsed: 00:17:22
                               ETA: 00:38:00

################################################################################
                     [1m Learning iteration 471/1500 [0m                      

                       Computation: 47423 steps/s (collection: 1.948s, learning 0.125s)
             Mean action noise std: 1.80
          Mean value_function loss: 80.7993
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 43.8211
                       Mean reward: 617.07
               Mean episode length: 228.45
    Episode_Reward/reaching_object: 0.9946
    Episode_Reward/rotating_object: 120.1302
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 2.07s
                      Time elapsed: 00:17:25
                               ETA: 00:37:58

################################################################################
                     [1m Learning iteration 472/1500 [0m                      

                       Computation: 47687 steps/s (collection: 1.961s, learning 0.101s)
             Mean action noise std: 1.80
          Mean value_function loss: 82.9158
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 43.8343
                       Mean reward: 635.59
               Mean episode length: 233.74
    Episode_Reward/reaching_object: 1.0226
    Episode_Reward/rotating_object: 125.0486
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 2.06s
                      Time elapsed: 00:17:27
                               ETA: 00:37:55

################################################################################
                     [1m Learning iteration 473/1500 [0m                      

                       Computation: 47807 steps/s (collection: 1.912s, learning 0.145s)
             Mean action noise std: 1.80
          Mean value_function loss: 72.4526
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 43.8445
                       Mean reward: 656.12
               Mean episode length: 239.81
    Episode_Reward/reaching_object: 1.0290
    Episode_Reward/rotating_object: 127.7880
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 2.06s
                      Time elapsed: 00:17:29
                               ETA: 00:37:53

################################################################################
                     [1m Learning iteration 474/1500 [0m                      

                       Computation: 47491 steps/s (collection: 1.956s, learning 0.113s)
             Mean action noise std: 1.80
          Mean value_function loss: 78.5506
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 43.8583
                       Mean reward: 639.31
               Mean episode length: 240.89
    Episode_Reward/reaching_object: 1.0339
    Episode_Reward/rotating_object: 127.2296
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 2.07s
                      Time elapsed: 00:17:31
                               ETA: 00:37:50

################################################################################
                     [1m Learning iteration 475/1500 [0m                      

                       Computation: 49269 steps/s (collection: 1.896s, learning 0.099s)
             Mean action noise std: 1.80
          Mean value_function loss: 76.5195
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 43.8712
                       Mean reward: 638.09
               Mean episode length: 236.07
    Episode_Reward/reaching_object: 1.0189
    Episode_Reward/rotating_object: 124.3087
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 2.00s
                      Time elapsed: 00:17:33
                               ETA: 00:37:48

################################################################################
                     [1m Learning iteration 476/1500 [0m                      

                       Computation: 48512 steps/s (collection: 1.911s, learning 0.116s)
             Mean action noise std: 1.80
          Mean value_function loss: 78.7262
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 43.8779
                       Mean reward: 677.57
               Mean episode length: 245.85
    Episode_Reward/reaching_object: 1.0511
    Episode_Reward/rotating_object: 128.8418
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 2.03s
                      Time elapsed: 00:17:35
                               ETA: 00:37:45

################################################################################
                     [1m Learning iteration 477/1500 [0m                      

                       Computation: 47053 steps/s (collection: 1.970s, learning 0.119s)
             Mean action noise std: 1.81
          Mean value_function loss: 80.6228
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.8837
                       Mean reward: 607.29
               Mean episode length: 230.60
    Episode_Reward/reaching_object: 1.0128
    Episode_Reward/rotating_object: 123.9155
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 2.09s
                      Time elapsed: 00:17:37
                               ETA: 00:37:42

################################################################################
                     [1m Learning iteration 478/1500 [0m                      

                       Computation: 49110 steps/s (collection: 1.895s, learning 0.107s)
             Mean action noise std: 1.81
          Mean value_function loss: 85.7693
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 43.8928
                       Mean reward: 652.29
               Mean episode length: 238.65
    Episode_Reward/reaching_object: 1.0401
    Episode_Reward/rotating_object: 125.5302
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 2.00s
                      Time elapsed: 00:17:39
                               ETA: 00:37:40

################################################################################
                     [1m Learning iteration 479/1500 [0m                      

                       Computation: 48722 steps/s (collection: 1.911s, learning 0.107s)
             Mean action noise std: 1.81
          Mean value_function loss: 97.4076
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 43.9007
                       Mean reward: 630.01
               Mean episode length: 234.08
    Episode_Reward/reaching_object: 1.0219
    Episode_Reward/rotating_object: 123.2756
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 2.02s
                      Time elapsed: 00:17:41
                               ETA: 00:37:37

################################################################################
                     [1m Learning iteration 480/1500 [0m                      

                       Computation: 49324 steps/s (collection: 1.896s, learning 0.097s)
             Mean action noise std: 1.81
          Mean value_function loss: 93.9370
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 43.9087
                       Mean reward: 646.47
               Mean episode length: 236.22
    Episode_Reward/reaching_object: 1.0248
    Episode_Reward/rotating_object: 126.3487
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 1.99s
                      Time elapsed: 00:17:43
                               ETA: 00:37:34

################################################################################
                     [1m Learning iteration 481/1500 [0m                      

                       Computation: 48012 steps/s (collection: 1.944s, learning 0.103s)
             Mean action noise std: 1.81
          Mean value_function loss: 77.5517
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 43.9347
                       Mean reward: 641.15
               Mean episode length: 236.19
    Episode_Reward/reaching_object: 1.0159
    Episode_Reward/rotating_object: 122.3374
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 2.05s
                      Time elapsed: 00:17:45
                               ETA: 00:37:32

################################################################################
                     [1m Learning iteration 482/1500 [0m                      

                       Computation: 50108 steps/s (collection: 1.862s, learning 0.100s)
             Mean action noise std: 1.81
          Mean value_function loss: 75.5213
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 43.9529
                       Mean reward: 664.16
               Mean episode length: 237.93
    Episode_Reward/reaching_object: 1.0548
    Episode_Reward/rotating_object: 127.1710
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 1.96s
                      Time elapsed: 00:17:47
                               ETA: 00:37:29

################################################################################
                     [1m Learning iteration 483/1500 [0m                      

                       Computation: 49276 steps/s (collection: 1.881s, learning 0.114s)
             Mean action noise std: 1.81
          Mean value_function loss: 74.6541
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 43.9708
                       Mean reward: 618.77
               Mean episode length: 236.81
    Episode_Reward/reaching_object: 1.0391
    Episode_Reward/rotating_object: 125.1116
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 1.99s
                      Time elapsed: 00:17:49
                               ETA: 00:37:27

################################################################################
                     [1m Learning iteration 484/1500 [0m                      

                       Computation: 47399 steps/s (collection: 1.974s, learning 0.100s)
             Mean action noise std: 1.81
          Mean value_function loss: 77.9198
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 43.9832
                       Mean reward: 649.27
               Mean episode length: 232.40
    Episode_Reward/reaching_object: 1.0215
    Episode_Reward/rotating_object: 125.4043
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 2.07s
                      Time elapsed: 00:17:51
                               ETA: 00:37:24

################################################################################
                     [1m Learning iteration 485/1500 [0m                      

                       Computation: 47403 steps/s (collection: 1.962s, learning 0.112s)
             Mean action noise std: 1.82
          Mean value_function loss: 83.2439
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.9937
                       Mean reward: 655.98
               Mean episode length: 237.41
    Episode_Reward/reaching_object: 1.0438
    Episode_Reward/rotating_object: 128.1688
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 2.07s
                      Time elapsed: 00:17:53
                               ETA: 00:37:22

################################################################################
                     [1m Learning iteration 486/1500 [0m                      

                       Computation: 48833 steps/s (collection: 1.901s, learning 0.112s)
             Mean action noise std: 1.82
          Mean value_function loss: 81.1425
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 44.0030
                       Mean reward: 645.90
               Mean episode length: 237.23
    Episode_Reward/reaching_object: 1.0347
    Episode_Reward/rotating_object: 128.3901
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 2.01s
                      Time elapsed: 00:17:55
                               ETA: 00:37:19

################################################################################
                     [1m Learning iteration 487/1500 [0m                      

                       Computation: 46362 steps/s (collection: 2.006s, learning 0.115s)
             Mean action noise std: 1.82
          Mean value_function loss: 83.6197
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.0231
                       Mean reward: 634.21
               Mean episode length: 235.98
    Episode_Reward/reaching_object: 1.0336
    Episode_Reward/rotating_object: 127.2529
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 2.12s
                      Time elapsed: 00:17:57
                               ETA: 00:37:17

################################################################################
                     [1m Learning iteration 488/1500 [0m                      

                       Computation: 49465 steps/s (collection: 1.873s, learning 0.114s)
             Mean action noise std: 1.82
          Mean value_function loss: 81.7724
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 44.0383
                       Mean reward: 639.06
               Mean episode length: 237.84
    Episode_Reward/reaching_object: 1.0246
    Episode_Reward/rotating_object: 126.1261
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 1.99s
                      Time elapsed: 00:17:59
                               ETA: 00:37:14

################################################################################
                     [1m Learning iteration 489/1500 [0m                      

                       Computation: 48966 steps/s (collection: 1.905s, learning 0.103s)
             Mean action noise std: 1.82
          Mean value_function loss: 76.8256
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.0459
                       Mean reward: 655.90
               Mean episode length: 242.06
    Episode_Reward/reaching_object: 1.0399
    Episode_Reward/rotating_object: 126.7726
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 2.01s
                      Time elapsed: 00:18:01
                               ETA: 00:37:11

################################################################################
                     [1m Learning iteration 490/1500 [0m                      

                       Computation: 45601 steps/s (collection: 2.008s, learning 0.148s)
             Mean action noise std: 1.82
          Mean value_function loss: 75.4324
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 44.0630
                       Mean reward: 689.15
               Mean episode length: 241.13
    Episode_Reward/reaching_object: 1.0478
    Episode_Reward/rotating_object: 130.5077
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 2.16s
                      Time elapsed: 00:18:03
                               ETA: 00:37:09

################################################################################
                     [1m Learning iteration 491/1500 [0m                      

                       Computation: 47143 steps/s (collection: 1.955s, learning 0.130s)
             Mean action noise std: 1.82
          Mean value_function loss: 76.8841
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 44.0685
                       Mean reward: 641.94
               Mean episode length: 238.65
    Episode_Reward/reaching_object: 1.0392
    Episode_Reward/rotating_object: 129.1136
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 2.09s
                      Time elapsed: 00:18:05
                               ETA: 00:37:06

################################################################################
                     [1m Learning iteration 492/1500 [0m                      

                       Computation: 49253 steps/s (collection: 1.857s, learning 0.139s)
             Mean action noise std: 1.82
          Mean value_function loss: 69.3554
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 44.0770
                       Mean reward: 626.85
               Mean episode length: 232.50
    Episode_Reward/reaching_object: 1.0543
    Episode_Reward/rotating_object: 129.3899
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 2.00s
                      Time elapsed: 00:18:07
                               ETA: 00:37:04

################################################################################
                     [1m Learning iteration 493/1500 [0m                      

                       Computation: 48064 steps/s (collection: 1.877s, learning 0.168s)
             Mean action noise std: 1.82
          Mean value_function loss: 74.9533
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 44.0882
                       Mean reward: 694.79
               Mean episode length: 242.65
    Episode_Reward/reaching_object: 1.0406
    Episode_Reward/rotating_object: 130.7870
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 2.05s
                      Time elapsed: 00:18:09
                               ETA: 00:37:01

################################################################################
                     [1m Learning iteration 494/1500 [0m                      

                       Computation: 48712 steps/s (collection: 1.838s, learning 0.180s)
             Mean action noise std: 1.83
          Mean value_function loss: 87.9010
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 44.0985
                       Mean reward: 590.28
               Mean episode length: 226.64
    Episode_Reward/reaching_object: 1.0265
    Episode_Reward/rotating_object: 124.6862
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 2.02s
                      Time elapsed: 00:18:11
                               ETA: 00:36:59

################################################################################
                     [1m Learning iteration 495/1500 [0m                      

                       Computation: 46628 steps/s (collection: 1.971s, learning 0.138s)
             Mean action noise std: 1.83
          Mean value_function loss: 79.2839
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 44.1157
                       Mean reward: 654.62
               Mean episode length: 238.51
    Episode_Reward/reaching_object: 1.0406
    Episode_Reward/rotating_object: 126.2634
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 2.11s
                      Time elapsed: 00:18:14
                               ETA: 00:36:56

################################################################################
                     [1m Learning iteration 496/1500 [0m                      

                       Computation: 47682 steps/s (collection: 1.966s, learning 0.095s)
             Mean action noise std: 1.83
          Mean value_function loss: 80.2443
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 44.1224
                       Mean reward: 678.11
               Mean episode length: 242.23
    Episode_Reward/reaching_object: 1.0485
    Episode_Reward/rotating_object: 126.8743
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 2.06s
                      Time elapsed: 00:18:16
                               ETA: 00:36:54

################################################################################
                     [1m Learning iteration 497/1500 [0m                      

                       Computation: 48284 steps/s (collection: 1.921s, learning 0.115s)
             Mean action noise std: 1.83
          Mean value_function loss: 73.0225
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 44.1338
                       Mean reward: 677.00
               Mean episode length: 238.47
    Episode_Reward/reaching_object: 1.0458
    Episode_Reward/rotating_object: 131.4541
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 2.04s
                      Time elapsed: 00:18:18
                               ETA: 00:36:51

################################################################################
                     [1m Learning iteration 498/1500 [0m                      

                       Computation: 47712 steps/s (collection: 1.951s, learning 0.110s)
             Mean action noise std: 1.83
          Mean value_function loss: 74.6589
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 44.1468
                       Mean reward: 665.38
               Mean episode length: 238.90
    Episode_Reward/reaching_object: 1.0448
    Episode_Reward/rotating_object: 129.4089
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 2.06s
                      Time elapsed: 00:18:20
                               ETA: 00:36:49

################################################################################
                     [1m Learning iteration 499/1500 [0m                      

                       Computation: 48203 steps/s (collection: 1.922s, learning 0.118s)
             Mean action noise std: 1.83
          Mean value_function loss: 79.3072
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 44.1568
                       Mean reward: 607.22
               Mean episode length: 229.62
    Episode_Reward/reaching_object: 1.0331
    Episode_Reward/rotating_object: 126.5300
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 2.04s
                      Time elapsed: 00:18:22
                               ETA: 00:36:46

################################################################################
                     [1m Learning iteration 500/1500 [0m                      

                       Computation: 48359 steps/s (collection: 1.937s, learning 0.096s)
             Mean action noise std: 1.83
          Mean value_function loss: 81.8512
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 44.1760
                       Mean reward: 642.42
               Mean episode length: 236.34
    Episode_Reward/reaching_object: 1.0319
    Episode_Reward/rotating_object: 126.0380
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 2.03s
                      Time elapsed: 00:18:24
                               ETA: 00:36:44

################################################################################
                     [1m Learning iteration 501/1500 [0m                      

                       Computation: 44062 steps/s (collection: 2.092s, learning 0.139s)
             Mean action noise std: 1.83
          Mean value_function loss: 90.0142
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 44.1861
                       Mean reward: 662.89
               Mean episode length: 235.97
    Episode_Reward/reaching_object: 1.0564
    Episode_Reward/rotating_object: 129.6825
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 2.23s
                      Time elapsed: 00:18:26
                               ETA: 00:36:42

################################################################################
                     [1m Learning iteration 502/1500 [0m                      

                       Computation: 45396 steps/s (collection: 2.043s, learning 0.122s)
             Mean action noise std: 1.83
          Mean value_function loss: 83.8902
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 44.1956
                       Mean reward: 683.04
               Mean episode length: 237.90
    Episode_Reward/reaching_object: 1.0632
    Episode_Reward/rotating_object: 129.9863
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 2.17s
                      Time elapsed: 00:18:28
                               ETA: 00:36:39

################################################################################
                     [1m Learning iteration 503/1500 [0m                      

                       Computation: 43307 steps/s (collection: 2.131s, learning 0.139s)
             Mean action noise std: 1.84
          Mean value_function loss: 92.2547
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 44.2070
                       Mean reward: 632.85
               Mean episode length: 231.72
    Episode_Reward/reaching_object: 1.0510
    Episode_Reward/rotating_object: 127.4766
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 2.27s
                      Time elapsed: 00:18:30
                               ETA: 00:36:37

################################################################################
                     [1m Learning iteration 504/1500 [0m                      

                       Computation: 45456 steps/s (collection: 2.044s, learning 0.119s)
             Mean action noise std: 1.84
          Mean value_function loss: 73.7655
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.2177
                       Mean reward: 657.93
               Mean episode length: 236.44
    Episode_Reward/reaching_object: 1.0394
    Episode_Reward/rotating_object: 127.2545
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 2.16s
                      Time elapsed: 00:18:33
                               ETA: 00:36:35

################################################################################
                     [1m Learning iteration 505/1500 [0m                      

                       Computation: 47669 steps/s (collection: 1.967s, learning 0.096s)
             Mean action noise std: 1.84
          Mean value_function loss: 82.4623
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.2333
                       Mean reward: 684.24
               Mean episode length: 241.44
    Episode_Reward/reaching_object: 1.0686
    Episode_Reward/rotating_object: 132.1819
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 2.06s
                      Time elapsed: 00:18:35
                               ETA: 00:36:32

################################################################################
                     [1m Learning iteration 506/1500 [0m                      

                       Computation: 43183 steps/s (collection: 2.160s, learning 0.116s)
             Mean action noise std: 1.84
          Mean value_function loss: 89.9794
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.2520
                       Mean reward: 657.45
               Mean episode length: 237.56
    Episode_Reward/reaching_object: 1.0545
    Episode_Reward/rotating_object: 130.8793
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 2.28s
                      Time elapsed: 00:18:37
                               ETA: 00:36:30

################################################################################
                     [1m Learning iteration 507/1500 [0m                      

                       Computation: 48725 steps/s (collection: 1.908s, learning 0.109s)
             Mean action noise std: 1.84
          Mean value_function loss: 85.3262
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 44.2759
                       Mean reward: 666.62
               Mean episode length: 243.07
    Episode_Reward/reaching_object: 1.0749
    Episode_Reward/rotating_object: 129.6954
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 2.02s
                      Time elapsed: 00:18:39
                               ETA: 00:36:28

################################################################################
                     [1m Learning iteration 508/1500 [0m                      

                       Computation: 49886 steps/s (collection: 1.871s, learning 0.099s)
             Mean action noise std: 1.84
          Mean value_function loss: 74.5723
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 44.2924
                       Mean reward: 603.18
               Mean episode length: 227.08
    Episode_Reward/reaching_object: 1.0571
    Episode_Reward/rotating_object: 126.0004
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 1.97s
                      Time elapsed: 00:18:41
                               ETA: 00:36:25

################################################################################
                     [1m Learning iteration 509/1500 [0m                      

                       Computation: 48940 steps/s (collection: 1.912s, learning 0.097s)
             Mean action noise std: 1.85
          Mean value_function loss: 68.8952
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 44.3019
                       Mean reward: 641.22
               Mean episode length: 239.06
    Episode_Reward/reaching_object: 1.0882
    Episode_Reward/rotating_object: 133.0012
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 2.01s
                      Time elapsed: 00:18:43
                               ETA: 00:36:23

################################################################################
                     [1m Learning iteration 510/1500 [0m                      

                       Computation: 48440 steps/s (collection: 1.934s, learning 0.096s)
             Mean action noise std: 1.85
          Mean value_function loss: 74.4990
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 44.3128
                       Mean reward: 661.83
               Mean episode length: 237.89
    Episode_Reward/reaching_object: 1.1049
    Episode_Reward/rotating_object: 136.3377
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 2.03s
                      Time elapsed: 00:18:45
                               ETA: 00:36:20

################################################################################
                     [1m Learning iteration 511/1500 [0m                      

                       Computation: 49259 steps/s (collection: 1.895s, learning 0.101s)
             Mean action noise std: 1.85
          Mean value_function loss: 85.4413
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 44.3317
                       Mean reward: 649.61
               Mean episode length: 234.94
    Episode_Reward/reaching_object: 1.0733
    Episode_Reward/rotating_object: 129.5815
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 2.00s
                      Time elapsed: 00:18:47
                               ETA: 00:36:17

################################################################################
                     [1m Learning iteration 512/1500 [0m                      

                       Computation: 47051 steps/s (collection: 1.988s, learning 0.102s)
             Mean action noise std: 1.85
          Mean value_function loss: 77.2608
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 44.3535
                       Mean reward: 681.38
               Mean episode length: 241.57
    Episode_Reward/reaching_object: 1.0571
    Episode_Reward/rotating_object: 129.5887
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 2.09s
                      Time elapsed: 00:18:49
                               ETA: 00:36:15

################################################################################
                     [1m Learning iteration 513/1500 [0m                      

                       Computation: 47788 steps/s (collection: 1.931s, learning 0.126s)
             Mean action noise std: 1.85
          Mean value_function loss: 77.1667
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.3758
                       Mean reward: 671.47
               Mean episode length: 244.16
    Episode_Reward/reaching_object: 1.0695
    Episode_Reward/rotating_object: 131.8288
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 2.06s
                      Time elapsed: 00:18:51
                               ETA: 00:36:12

################################################################################
                     [1m Learning iteration 514/1500 [0m                      

                       Computation: 47735 steps/s (collection: 1.959s, learning 0.100s)
             Mean action noise std: 1.85
          Mean value_function loss: 74.0919
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 44.3951
                       Mean reward: 667.34
               Mean episode length: 241.41
    Episode_Reward/reaching_object: 1.0845
    Episode_Reward/rotating_object: 131.7759
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 2.06s
                      Time elapsed: 00:18:53
                               ETA: 00:36:10

################################################################################
                     [1m Learning iteration 515/1500 [0m                      

                       Computation: 48810 steps/s (collection: 1.913s, learning 0.101s)
             Mean action noise std: 1.86
          Mean value_function loss: 71.5017
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 44.4133
                       Mean reward: 643.52
               Mean episode length: 234.72
    Episode_Reward/reaching_object: 1.0696
    Episode_Reward/rotating_object: 130.4306
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 2.01s
                      Time elapsed: 00:18:55
                               ETA: 00:36:07

################################################################################
                     [1m Learning iteration 516/1500 [0m                      

                       Computation: 49380 steps/s (collection: 1.888s, learning 0.103s)
             Mean action noise std: 1.86
          Mean value_function loss: 76.3986
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 44.4234
                       Mean reward: 648.33
               Mean episode length: 235.78
    Episode_Reward/reaching_object: 1.0750
    Episode_Reward/rotating_object: 130.9897
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 1.99s
                      Time elapsed: 00:18:57
                               ETA: 00:36:05

################################################################################
                     [1m Learning iteration 517/1500 [0m                      

                       Computation: 46140 steps/s (collection: 2.024s, learning 0.107s)
             Mean action noise std: 1.86
          Mean value_function loss: 77.8690
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.4394
                       Mean reward: 638.19
               Mean episode length: 235.67
    Episode_Reward/reaching_object: 1.0771
    Episode_Reward/rotating_object: 131.3388
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 2.13s
                      Time elapsed: 00:18:59
                               ETA: 00:36:03

################################################################################
                     [1m Learning iteration 518/1500 [0m                      

                       Computation: 48078 steps/s (collection: 1.917s, learning 0.127s)
             Mean action noise std: 1.86
          Mean value_function loss: 72.2522
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.4613
                       Mean reward: 668.10
               Mean episode length: 242.20
    Episode_Reward/reaching_object: 1.0714
    Episode_Reward/rotating_object: 132.3098
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 2.04s
                      Time elapsed: 00:19:01
                               ETA: 00:36:00

################################################################################
                     [1m Learning iteration 519/1500 [0m                      

                       Computation: 48539 steps/s (collection: 1.896s, learning 0.130s)
             Mean action noise std: 1.86
          Mean value_function loss: 73.6948
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 44.4838
                       Mean reward: 648.42
               Mean episode length: 237.43
    Episode_Reward/reaching_object: 1.0685
    Episode_Reward/rotating_object: 129.5094
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 2.03s
                      Time elapsed: 00:19:03
                               ETA: 00:35:58

################################################################################
                     [1m Learning iteration 520/1500 [0m                      

                       Computation: 48529 steps/s (collection: 1.892s, learning 0.134s)
             Mean action noise std: 1.86
          Mean value_function loss: 86.0406
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.5048
                       Mean reward: 675.22
               Mean episode length: 240.35
    Episode_Reward/reaching_object: 1.0589
    Episode_Reward/rotating_object: 131.2212
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 2.03s
                      Time elapsed: 00:19:05
                               ETA: 00:35:55

################################################################################
                     [1m Learning iteration 521/1500 [0m                      

                       Computation: 47766 steps/s (collection: 1.938s, learning 0.120s)
             Mean action noise std: 1.87
          Mean value_function loss: 73.5409
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.5241
                       Mean reward: 679.44
               Mean episode length: 235.48
    Episode_Reward/reaching_object: 1.0691
    Episode_Reward/rotating_object: 133.8257
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 2.06s
                      Time elapsed: 00:19:07
                               ETA: 00:35:53

################################################################################
                     [1m Learning iteration 522/1500 [0m                      

                       Computation: 48268 steps/s (collection: 1.877s, learning 0.160s)
             Mean action noise std: 1.87
          Mean value_function loss: 73.6513
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.5546
                       Mean reward: 656.68
               Mean episode length: 237.52
    Episode_Reward/reaching_object: 1.0734
    Episode_Reward/rotating_object: 133.7876
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 2.04s
                      Time elapsed: 00:19:10
                               ETA: 00:35:50

################################################################################
                     [1m Learning iteration 523/1500 [0m                      

                       Computation: 48418 steps/s (collection: 1.909s, learning 0.122s)
             Mean action noise std: 1.87
          Mean value_function loss: 75.4013
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 44.5876
                       Mean reward: 664.29
               Mean episode length: 235.61
    Episode_Reward/reaching_object: 1.0671
    Episode_Reward/rotating_object: 129.9828
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 2.03s
                      Time elapsed: 00:19:12
                               ETA: 00:35:47

################################################################################
                     [1m Learning iteration 524/1500 [0m                      

                       Computation: 48811 steps/s (collection: 1.902s, learning 0.112s)
             Mean action noise std: 1.87
          Mean value_function loss: 81.0705
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 44.6132
                       Mean reward: 662.83
               Mean episode length: 236.90
    Episode_Reward/reaching_object: 1.0623
    Episode_Reward/rotating_object: 130.0874
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 2.01s
                      Time elapsed: 00:19:14
                               ETA: 00:35:45

################################################################################
                     [1m Learning iteration 525/1500 [0m                      

                       Computation: 47914 steps/s (collection: 1.957s, learning 0.095s)
             Mean action noise std: 1.88
          Mean value_function loss: 73.6541
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 44.6294
                       Mean reward: 631.94
               Mean episode length: 232.92
    Episode_Reward/reaching_object: 1.0700
    Episode_Reward/rotating_object: 130.1408
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 2.05s
                      Time elapsed: 00:19:16
                               ETA: 00:35:42

################################################################################
                     [1m Learning iteration 526/1500 [0m                      

                       Computation: 47549 steps/s (collection: 1.941s, learning 0.127s)
             Mean action noise std: 1.88
          Mean value_function loss: 78.3307
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 44.6419
                       Mean reward: 627.15
               Mean episode length: 224.63
    Episode_Reward/reaching_object: 1.0799
    Episode_Reward/rotating_object: 131.9268
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 2.07s
                      Time elapsed: 00:19:18
                               ETA: 00:35:40

################################################################################
                     [1m Learning iteration 527/1500 [0m                      

                       Computation: 45166 steps/s (collection: 1.988s, learning 0.189s)
             Mean action noise std: 1.88
          Mean value_function loss: 77.3009
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 44.6573
                       Mean reward: 651.50
               Mean episode length: 237.24
    Episode_Reward/reaching_object: 1.0698
    Episode_Reward/rotating_object: 131.1790
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 2.18s
                      Time elapsed: 00:19:20
                               ETA: 00:35:38

################################################################################
                     [1m Learning iteration 528/1500 [0m                      

                       Computation: 48110 steps/s (collection: 1.929s, learning 0.114s)
             Mean action noise std: 1.88
          Mean value_function loss: 73.5557
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 44.6739
                       Mean reward: 683.96
               Mean episode length: 239.83
    Episode_Reward/reaching_object: 1.0925
    Episode_Reward/rotating_object: 136.3250
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 2.04s
                      Time elapsed: 00:19:22
                               ETA: 00:35:35

################################################################################
                     [1m Learning iteration 529/1500 [0m                      

                       Computation: 48117 steps/s (collection: 1.932s, learning 0.111s)
             Mean action noise std: 1.88
          Mean value_function loss: 81.7529
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 44.6930
                       Mean reward: 668.56
               Mean episode length: 238.52
    Episode_Reward/reaching_object: 1.0742
    Episode_Reward/rotating_object: 130.0936
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 2.04s
                      Time elapsed: 00:19:24
                               ETA: 00:35:33

################################################################################
                     [1m Learning iteration 530/1500 [0m                      

                       Computation: 48038 steps/s (collection: 1.941s, learning 0.105s)
             Mean action noise std: 1.88
          Mean value_function loss: 84.1299
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 44.7241
                       Mean reward: 673.26
               Mean episode length: 240.36
    Episode_Reward/reaching_object: 1.0993
    Episode_Reward/rotating_object: 137.7045
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 2.05s
                      Time elapsed: 00:19:26
                               ETA: 00:35:30

################################################################################
                     [1m Learning iteration 531/1500 [0m                      

                       Computation: 48264 steps/s (collection: 1.925s, learning 0.112s)
             Mean action noise std: 1.89
          Mean value_function loss: 80.3254
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 44.7488
                       Mean reward: 677.71
               Mean episode length: 240.31
    Episode_Reward/reaching_object: 1.0753
    Episode_Reward/rotating_object: 130.7142
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 2.04s
                      Time elapsed: 00:19:28
                               ETA: 00:35:28

################################################################################
                     [1m Learning iteration 532/1500 [0m                      

                       Computation: 44993 steps/s (collection: 2.073s, learning 0.112s)
             Mean action noise std: 1.89
          Mean value_function loss: 80.0855
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.7620
                       Mean reward: 668.26
               Mean episode length: 237.26
    Episode_Reward/reaching_object: 1.0709
    Episode_Reward/rotating_object: 130.6150
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 2.18s
                      Time elapsed: 00:19:30
                               ETA: 00:35:26

################################################################################
                     [1m Learning iteration 533/1500 [0m                      

                       Computation: 46861 steps/s (collection: 1.972s, learning 0.126s)
             Mean action noise std: 1.89
          Mean value_function loss: 89.9040
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 44.7793
                       Mean reward: 700.93
               Mean episode length: 241.54
    Episode_Reward/reaching_object: 1.0578
    Episode_Reward/rotating_object: 130.4646
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 2.10s
                      Time elapsed: 00:19:32
                               ETA: 00:35:23

################################################################################
                     [1m Learning iteration 534/1500 [0m                      

                       Computation: 47473 steps/s (collection: 1.948s, learning 0.123s)
             Mean action noise std: 1.89
          Mean value_function loss: 66.5134
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 44.8043
                       Mean reward: 665.36
               Mean episode length: 242.73
    Episode_Reward/reaching_object: 1.0876
    Episode_Reward/rotating_object: 132.9734
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 2.07s
                      Time elapsed: 00:19:34
                               ETA: 00:35:21

################################################################################
                     [1m Learning iteration 535/1500 [0m                      

                       Computation: 41098 steps/s (collection: 2.123s, learning 0.269s)
             Mean action noise std: 1.89
          Mean value_function loss: 60.6877
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.8279
                       Mean reward: 700.39
               Mean episode length: 241.54
    Episode_Reward/reaching_object: 1.0800
    Episode_Reward/rotating_object: 133.1100
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 2.39s
                      Time elapsed: 00:19:37
                               ETA: 00:35:19

################################################################################
                     [1m Learning iteration 536/1500 [0m                      

                       Computation: 45746 steps/s (collection: 2.013s, learning 0.136s)
             Mean action noise std: 1.90
          Mean value_function loss: 78.6327
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 44.8574
                       Mean reward: 618.85
               Mean episode length: 226.92
    Episode_Reward/reaching_object: 1.0609
    Episode_Reward/rotating_object: 131.1320
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 2.15s
                      Time elapsed: 00:19:39
                               ETA: 00:35:17

################################################################################
                     [1m Learning iteration 537/1500 [0m                      

                       Computation: 45763 steps/s (collection: 2.001s, learning 0.147s)
             Mean action noise std: 1.90
          Mean value_function loss: 70.5484
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.8827
                       Mean reward: 645.42
               Mean episode length: 237.60
    Episode_Reward/reaching_object: 1.0983
    Episode_Reward/rotating_object: 138.1692
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 2.15s
                      Time elapsed: 00:19:41
                               ETA: 00:35:14

################################################################################
                     [1m Learning iteration 538/1500 [0m                      

                       Computation: 47203 steps/s (collection: 1.965s, learning 0.118s)
             Mean action noise std: 1.90
          Mean value_function loss: 82.3401
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 44.9054
                       Mean reward: 594.43
               Mean episode length: 221.34
    Episode_Reward/reaching_object: 1.0668
    Episode_Reward/rotating_object: 129.3444
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 2.08s
                      Time elapsed: 00:19:43
                               ETA: 00:35:12

################################################################################
                     [1m Learning iteration 539/1500 [0m                      

                       Computation: 47588 steps/s (collection: 1.936s, learning 0.130s)
             Mean action noise std: 1.90
          Mean value_function loss: 73.9423
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 44.9180
                       Mean reward: 700.88
               Mean episode length: 240.58
    Episode_Reward/reaching_object: 1.0859
    Episode_Reward/rotating_object: 134.7265
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 2.07s
                      Time elapsed: 00:19:45
                               ETA: 00:35:10

################################################################################
                     [1m Learning iteration 540/1500 [0m                      

                       Computation: 40569 steps/s (collection: 2.300s, learning 0.123s)
             Mean action noise std: 1.91
          Mean value_function loss: 69.0528
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 44.9462
                       Mean reward: 671.95
               Mean episode length: 235.56
    Episode_Reward/reaching_object: 1.0882
    Episode_Reward/rotating_object: 137.2523
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 2.42s
                      Time elapsed: 00:19:48
                               ETA: 00:35:08

################################################################################
                     [1m Learning iteration 541/1500 [0m                      

                       Computation: 47638 steps/s (collection: 1.938s, learning 0.125s)
             Mean action noise std: 1.91
          Mean value_function loss: 74.7857
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 44.9781
                       Mean reward: 644.60
               Mean episode length: 242.33
    Episode_Reward/reaching_object: 1.0736
    Episode_Reward/rotating_object: 131.5662
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 2.06s
                      Time elapsed: 00:19:50
                               ETA: 00:35:05

################################################################################
                     [1m Learning iteration 542/1500 [0m                      

                       Computation: 49371 steps/s (collection: 1.856s, learning 0.135s)
             Mean action noise std: 1.91
          Mean value_function loss: 73.5510
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 44.9986
                       Mean reward: 674.89
               Mean episode length: 240.13
    Episode_Reward/reaching_object: 1.0830
    Episode_Reward/rotating_object: 135.8319
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 1.99s
                      Time elapsed: 00:19:52
                               ETA: 00:35:03

################################################################################
                     [1m Learning iteration 543/1500 [0m                      

                       Computation: 49282 steps/s (collection: 1.840s, learning 0.155s)
             Mean action noise std: 1.91
          Mean value_function loss: 76.5933
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 45.0093
                       Mean reward: 678.22
               Mean episode length: 237.75
    Episode_Reward/reaching_object: 1.0667
    Episode_Reward/rotating_object: 134.1853
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 1.99s
                      Time elapsed: 00:19:54
                               ETA: 00:35:00

################################################################################
                     [1m Learning iteration 544/1500 [0m                      

                       Computation: 47411 steps/s (collection: 1.961s, learning 0.113s)
             Mean action noise std: 1.91
          Mean value_function loss: 62.0708
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 45.0241
                       Mean reward: 697.92
               Mean episode length: 242.10
    Episode_Reward/reaching_object: 1.0830
    Episode_Reward/rotating_object: 134.4719
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 2.07s
                      Time elapsed: 00:19:56
                               ETA: 00:34:58

################################################################################
                     [1m Learning iteration 545/1500 [0m                      

                       Computation: 48460 steps/s (collection: 1.914s, learning 0.115s)
             Mean action noise std: 1.91
          Mean value_function loss: 72.3334
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 45.0459
                       Mean reward: 683.20
               Mean episode length: 238.36
    Episode_Reward/reaching_object: 1.0926
    Episode_Reward/rotating_object: 138.2497
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 2.03s
                      Time elapsed: 00:19:58
                               ETA: 00:34:55

################################################################################
                     [1m Learning iteration 546/1500 [0m                      

                       Computation: 46612 steps/s (collection: 1.963s, learning 0.146s)
             Mean action noise std: 1.92
          Mean value_function loss: 73.7246
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 45.0646
                       Mean reward: 713.40
               Mean episode length: 243.26
    Episode_Reward/reaching_object: 1.0882
    Episode_Reward/rotating_object: 136.0053
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 2.11s
                      Time elapsed: 00:20:00
                               ETA: 00:34:53

################################################################################
                     [1m Learning iteration 547/1500 [0m                      

                       Computation: 49673 steps/s (collection: 1.877s, learning 0.102s)
             Mean action noise std: 1.92
          Mean value_function loss: 77.4867
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 45.0875
                       Mean reward: 695.06
               Mean episode length: 243.79
    Episode_Reward/reaching_object: 1.0725
    Episode_Reward/rotating_object: 133.2287
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 1.98s
                      Time elapsed: 00:20:02
                               ETA: 00:34:51

################################################################################
                     [1m Learning iteration 548/1500 [0m                      

                       Computation: 47672 steps/s (collection: 1.941s, learning 0.121s)
             Mean action noise std: 1.92
          Mean value_function loss: 100.0498
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 45.1116
                       Mean reward: 625.50
               Mean episode length: 222.94
    Episode_Reward/reaching_object: 1.0578
    Episode_Reward/rotating_object: 133.0372
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 2.06s
                      Time elapsed: 00:20:04
                               ETA: 00:34:48

################################################################################
                     [1m Learning iteration 549/1500 [0m                      

                       Computation: 46871 steps/s (collection: 1.979s, learning 0.119s)
             Mean action noise std: 1.92
          Mean value_function loss: 64.8177
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 45.1313
                       Mean reward: 689.31
               Mean episode length: 240.05
    Episode_Reward/reaching_object: 1.0773
    Episode_Reward/rotating_object: 136.2440
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 2.10s
                      Time elapsed: 00:20:06
                               ETA: 00:34:46

################################################################################
                     [1m Learning iteration 550/1500 [0m                      

                       Computation: 46641 steps/s (collection: 1.997s, learning 0.111s)
             Mean action noise std: 1.93
          Mean value_function loss: 71.5781
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 45.1543
                       Mean reward: 698.26
               Mean episode length: 237.36
    Episode_Reward/reaching_object: 1.0780
    Episode_Reward/rotating_object: 136.3978
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 2.11s
                      Time elapsed: 00:20:08
                               ETA: 00:34:43

################################################################################
                     [1m Learning iteration 551/1500 [0m                      

                       Computation: 43237 steps/s (collection: 2.066s, learning 0.208s)
             Mean action noise std: 1.93
          Mean value_function loss: 60.1877
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 45.1768
                       Mean reward: 707.98
               Mean episode length: 244.49
    Episode_Reward/reaching_object: 1.0790
    Episode_Reward/rotating_object: 136.2831
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 2.27s
                      Time elapsed: 00:20:10
                               ETA: 00:34:41

################################################################################
                     [1m Learning iteration 552/1500 [0m                      

                       Computation: 42389 steps/s (collection: 2.142s, learning 0.177s)
             Mean action noise std: 1.93
          Mean value_function loss: 67.5349
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 45.1994
                       Mean reward: 621.59
               Mean episode length: 225.60
    Episode_Reward/reaching_object: 1.0548
    Episode_Reward/rotating_object: 134.1305
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 2.32s
                      Time elapsed: 00:20:13
                               ETA: 00:34:39

################################################################################
                     [1m Learning iteration 553/1500 [0m                      

                       Computation: 41896 steps/s (collection: 2.150s, learning 0.197s)
             Mean action noise std: 1.93
          Mean value_function loss: 69.5968
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 45.2137
                       Mean reward: 681.33
               Mean episode length: 237.17
    Episode_Reward/reaching_object: 1.0754
    Episode_Reward/rotating_object: 136.2294
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 2.35s
                      Time elapsed: 00:20:15
                               ETA: 00:34:37

################################################################################
                     [1m Learning iteration 554/1500 [0m                      

                       Computation: 36404 steps/s (collection: 2.434s, learning 0.267s)
             Mean action noise std: 1.93
          Mean value_function loss: 80.5669
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 45.2236
                       Mean reward: 683.01
               Mean episode length: 243.15
    Episode_Reward/reaching_object: 1.0644
    Episode_Reward/rotating_object: 132.1152
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 2.70s
                      Time elapsed: 00:20:18
                               ETA: 00:34:36

################################################################################
                     [1m Learning iteration 555/1500 [0m                      

                       Computation: 37484 steps/s (collection: 2.381s, learning 0.241s)
             Mean action noise std: 1.93
          Mean value_function loss: 73.1278
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 45.2448
                       Mean reward: 683.55
               Mean episode length: 241.23
    Episode_Reward/reaching_object: 1.0718
    Episode_Reward/rotating_object: 136.2234
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 2.62s
                      Time elapsed: 00:20:20
                               ETA: 00:34:35

################################################################################
                     [1m Learning iteration 556/1500 [0m                      

                       Computation: 45169 steps/s (collection: 2.075s, learning 0.102s)
             Mean action noise std: 1.94
          Mean value_function loss: 77.8515
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 45.2743
                       Mean reward: 702.01
               Mean episode length: 241.50
    Episode_Reward/reaching_object: 1.0749
    Episode_Reward/rotating_object: 136.6615
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 2.18s
                      Time elapsed: 00:20:23
                               ETA: 00:34:32

################################################################################
                     [1m Learning iteration 557/1500 [0m                      

                       Computation: 50948 steps/s (collection: 1.832s, learning 0.097s)
             Mean action noise std: 1.94
          Mean value_function loss: 69.4131
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 45.3024
                       Mean reward: 683.20
               Mean episode length: 234.04
    Episode_Reward/reaching_object: 1.0756
    Episode_Reward/rotating_object: 135.8353
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 1.93s
                      Time elapsed: 00:20:25
                               ETA: 00:34:30

################################################################################
                     [1m Learning iteration 558/1500 [0m                      

                       Computation: 50096 steps/s (collection: 1.865s, learning 0.098s)
             Mean action noise std: 1.94
          Mean value_function loss: 70.3584
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 45.3274
                       Mean reward: 678.12
               Mean episode length: 233.97
    Episode_Reward/reaching_object: 1.0636
    Episode_Reward/rotating_object: 129.8091
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 1.96s
                      Time elapsed: 00:20:26
                               ETA: 00:34:27

################################################################################
                     [1m Learning iteration 559/1500 [0m                      

                       Computation: 49683 steps/s (collection: 1.879s, learning 0.100s)
             Mean action noise std: 1.94
          Mean value_function loss: 82.1202
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 45.3518
                       Mean reward: 649.37
               Mean episode length: 232.77
    Episode_Reward/reaching_object: 1.0570
    Episode_Reward/rotating_object: 131.6562
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 1.98s
                      Time elapsed: 00:20:28
                               ETA: 00:34:25

################################################################################
                     [1m Learning iteration 560/1500 [0m                      

                       Computation: 49487 steps/s (collection: 1.880s, learning 0.106s)
             Mean action noise std: 1.95
          Mean value_function loss: 65.0455
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 45.3655
                       Mean reward: 701.94
               Mean episode length: 241.87
    Episode_Reward/reaching_object: 1.0847
    Episode_Reward/rotating_object: 137.5101
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 1.99s
                      Time elapsed: 00:20:30
                               ETA: 00:34:22

################################################################################
                     [1m Learning iteration 561/1500 [0m                      

                       Computation: 49545 steps/s (collection: 1.884s, learning 0.100s)
             Mean action noise std: 1.95
          Mean value_function loss: 75.5757
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 45.3901
                       Mean reward: 676.35
               Mean episode length: 236.29
    Episode_Reward/reaching_object: 1.0746
    Episode_Reward/rotating_object: 135.3828
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 1.98s
                      Time elapsed: 00:20:32
                               ETA: 00:34:19

################################################################################
                     [1m Learning iteration 562/1500 [0m                      

                       Computation: 49494 steps/s (collection: 1.887s, learning 0.099s)
             Mean action noise std: 1.95
          Mean value_function loss: 73.3505
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 45.4187
                       Mean reward: 660.02
               Mean episode length: 230.96
    Episode_Reward/reaching_object: 1.0827
    Episode_Reward/rotating_object: 135.2653
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 1.99s
                      Time elapsed: 00:20:34
                               ETA: 00:34:17

################################################################################
                     [1m Learning iteration 563/1500 [0m                      

                       Computation: 50428 steps/s (collection: 1.843s, learning 0.107s)
             Mean action noise std: 1.95
          Mean value_function loss: 75.3715
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 45.4324
                       Mean reward: 663.44
               Mean episode length: 231.18
    Episode_Reward/reaching_object: 1.0695
    Episode_Reward/rotating_object: 134.2002
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 1.95s
                      Time elapsed: 00:20:36
                               ETA: 00:34:14

################################################################################
                     [1m Learning iteration 564/1500 [0m                      

                       Computation: 51664 steps/s (collection: 1.806s, learning 0.097s)
             Mean action noise std: 1.95
          Mean value_function loss: 64.4316
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 45.4472
                       Mean reward: 687.17
               Mean episode length: 234.45
    Episode_Reward/reaching_object: 1.0875
    Episode_Reward/rotating_object: 138.5569
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 1.90s
                      Time elapsed: 00:20:38
                               ETA: 00:34:12

################################################################################
                     [1m Learning iteration 565/1500 [0m                      

                       Computation: 50629 steps/s (collection: 1.846s, learning 0.096s)
             Mean action noise std: 1.96
          Mean value_function loss: 76.4180
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 45.4703
                       Mean reward: 675.16
               Mean episode length: 241.90
    Episode_Reward/reaching_object: 1.0862
    Episode_Reward/rotating_object: 135.8858
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 1.94s
                      Time elapsed: 00:20:40
                               ETA: 00:34:09

################################################################################
                     [1m Learning iteration 566/1500 [0m                      

                       Computation: 50754 steps/s (collection: 1.838s, learning 0.099s)
             Mean action noise std: 1.96
          Mean value_function loss: 82.2513
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 45.5034
                       Mean reward: 649.86
               Mean episode length: 229.74
    Episode_Reward/reaching_object: 1.0802
    Episode_Reward/rotating_object: 136.5010
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 1.94s
                      Time elapsed: 00:20:42
                               ETA: 00:34:06

################################################################################
                     [1m Learning iteration 567/1500 [0m                      

                       Computation: 50903 steps/s (collection: 1.830s, learning 0.101s)
             Mean action noise std: 1.96
          Mean value_function loss: 79.8458
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 45.5227
                       Mean reward: 672.65
               Mean episode length: 232.66
    Episode_Reward/reaching_object: 1.0582
    Episode_Reward/rotating_object: 131.2228
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 1.93s
                      Time elapsed: 00:20:44
                               ETA: 00:34:04

################################################################################
                     [1m Learning iteration 568/1500 [0m                      

                       Computation: 49205 steps/s (collection: 1.893s, learning 0.104s)
             Mean action noise std: 1.96
          Mean value_function loss: 72.7774
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 45.5451
                       Mean reward: 650.80
               Mean episode length: 226.56
    Episode_Reward/reaching_object: 1.0705
    Episode_Reward/rotating_object: 134.0771
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 2.00s
                      Time elapsed: 00:20:46
                               ETA: 00:34:01

################################################################################
                     [1m Learning iteration 569/1500 [0m                      

                       Computation: 48529 steps/s (collection: 1.905s, learning 0.121s)
             Mean action noise std: 1.96
          Mean value_function loss: 77.8928
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 45.5703
                       Mean reward: 659.30
               Mean episode length: 235.02
    Episode_Reward/reaching_object: 1.0703
    Episode_Reward/rotating_object: 131.5591
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 2.03s
                      Time elapsed: 00:20:48
                               ETA: 00:33:59

################################################################################
                     [1m Learning iteration 570/1500 [0m                      

                       Computation: 49497 steps/s (collection: 1.860s, learning 0.126s)
             Mean action noise std: 1.97
          Mean value_function loss: 68.9134
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 45.5831
                       Mean reward: 656.53
               Mean episode length: 231.41
    Episode_Reward/reaching_object: 1.0890
    Episode_Reward/rotating_object: 134.9892
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 1.99s
                      Time elapsed: 00:20:50
                               ETA: 00:33:56

################################################################################
                     [1m Learning iteration 571/1500 [0m                      

                       Computation: 49635 steps/s (collection: 1.863s, learning 0.117s)
             Mean action noise std: 1.97
          Mean value_function loss: 73.9004
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 45.6016
                       Mean reward: 667.02
               Mean episode length: 229.66
    Episode_Reward/reaching_object: 1.0698
    Episode_Reward/rotating_object: 135.2366
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 1.98s
                      Time elapsed: 00:20:52
                               ETA: 00:33:54

################################################################################
                     [1m Learning iteration 572/1500 [0m                      

                       Computation: 49934 steps/s (collection: 1.850s, learning 0.119s)
             Mean action noise std: 1.97
          Mean value_function loss: 75.1322
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 45.6233
                       Mean reward: 652.24
               Mean episode length: 234.58
    Episode_Reward/reaching_object: 1.0679
    Episode_Reward/rotating_object: 131.8819
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 1.97s
                      Time elapsed: 00:20:54
                               ETA: 00:33:51

################################################################################
                     [1m Learning iteration 573/1500 [0m                      

                       Computation: 49041 steps/s (collection: 1.860s, learning 0.144s)
             Mean action noise std: 1.97
          Mean value_function loss: 76.4218
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 45.6590
                       Mean reward: 653.50
               Mean episode length: 234.43
    Episode_Reward/reaching_object: 1.0843
    Episode_Reward/rotating_object: 136.9732
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 2.00s
                      Time elapsed: 00:20:56
                               ETA: 00:33:49

################################################################################
                     [1m Learning iteration 574/1500 [0m                      

                       Computation: 48898 steps/s (collection: 1.886s, learning 0.125s)
             Mean action noise std: 1.98
          Mean value_function loss: 62.2384
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 45.6939
                       Mean reward: 676.25
               Mean episode length: 239.66
    Episode_Reward/reaching_object: 1.0773
    Episode_Reward/rotating_object: 133.8563
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 2.01s
                      Time elapsed: 00:20:58
                               ETA: 00:33:46

################################################################################
                     [1m Learning iteration 575/1500 [0m                      

                       Computation: 48960 steps/s (collection: 1.897s, learning 0.111s)
             Mean action noise std: 1.98
          Mean value_function loss: 80.1431
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 45.7228
                       Mean reward: 611.44
               Mean episode length: 222.15
    Episode_Reward/reaching_object: 1.0611
    Episode_Reward/rotating_object: 132.0646
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 2.01s
                      Time elapsed: 00:21:00
                               ETA: 00:33:44

################################################################################
                     [1m Learning iteration 576/1500 [0m                      

                       Computation: 49717 steps/s (collection: 1.873s, learning 0.104s)
             Mean action noise std: 1.98
          Mean value_function loss: 72.1375
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 45.7568
                       Mean reward: 675.77
               Mean episode length: 237.22
    Episode_Reward/reaching_object: 1.0703
    Episode_Reward/rotating_object: 133.6454
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 1.98s
                      Time elapsed: 00:21:02
                               ETA: 00:33:41

################################################################################
                     [1m Learning iteration 577/1500 [0m                      

                       Computation: 50848 steps/s (collection: 1.829s, learning 0.104s)
             Mean action noise std: 1.98
          Mean value_function loss: 69.2150
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 45.7799
                       Mean reward: 696.55
               Mean episode length: 238.10
    Episode_Reward/reaching_object: 1.0844
    Episode_Reward/rotating_object: 134.9494
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 1.93s
                      Time elapsed: 00:21:04
                               ETA: 00:33:39

################################################################################
                     [1m Learning iteration 578/1500 [0m                      

                       Computation: 51038 steps/s (collection: 1.824s, learning 0.102s)
             Mean action noise std: 1.99
          Mean value_function loss: 74.5143
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 45.7978
                       Mean reward: 655.72
               Mean episode length: 235.10
    Episode_Reward/reaching_object: 1.0656
    Episode_Reward/rotating_object: 132.9723
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 1.93s
                      Time elapsed: 00:21:06
                               ETA: 00:33:36

################################################################################
                     [1m Learning iteration 579/1500 [0m                      

                       Computation: 50722 steps/s (collection: 1.833s, learning 0.105s)
             Mean action noise std: 1.99
          Mean value_function loss: 78.1054
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 45.8284
                       Mean reward: 708.22
               Mean episode length: 238.37
    Episode_Reward/reaching_object: 1.0659
    Episode_Reward/rotating_object: 135.0877
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 1.94s
                      Time elapsed: 00:21:08
                               ETA: 00:33:34

################################################################################
                     [1m Learning iteration 580/1500 [0m                      

                       Computation: 49212 steps/s (collection: 1.882s, learning 0.116s)
             Mean action noise std: 1.99
          Mean value_function loss: 83.5860
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 45.8588
                       Mean reward: 663.91
               Mean episode length: 234.31
    Episode_Reward/reaching_object: 1.0701
    Episode_Reward/rotating_object: 132.7390
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 2.00s
                      Time elapsed: 00:21:10
                               ETA: 00:33:31

################################################################################
                     [1m Learning iteration 581/1500 [0m                      

                       Computation: 49325 steps/s (collection: 1.888s, learning 0.105s)
             Mean action noise std: 2.00
          Mean value_function loss: 76.6456
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 45.8985
                       Mean reward: 674.43
               Mean episode length: 235.79
    Episode_Reward/reaching_object: 1.0753
    Episode_Reward/rotating_object: 134.6219
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 1.99s
                      Time elapsed: 00:21:12
                               ETA: 00:33:29

################################################################################
                     [1m Learning iteration 582/1500 [0m                      

                       Computation: 48964 steps/s (collection: 1.899s, learning 0.109s)
             Mean action noise std: 2.00
          Mean value_function loss: 83.5367
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 45.9296
                       Mean reward: 687.40
               Mean episode length: 239.46
    Episode_Reward/reaching_object: 1.0794
    Episode_Reward/rotating_object: 135.1559
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 2.01s
                      Time elapsed: 00:21:14
                               ETA: 00:33:26

################################################################################
                     [1m Learning iteration 583/1500 [0m                      

                       Computation: 48984 steps/s (collection: 1.900s, learning 0.107s)
             Mean action noise std: 2.00
          Mean value_function loss: 76.8617
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 45.9519
                       Mean reward: 675.02
               Mean episode length: 228.03
    Episode_Reward/reaching_object: 1.0753
    Episode_Reward/rotating_object: 136.8694
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 2.01s
                      Time elapsed: 00:21:16
                               ETA: 00:33:24

################################################################################
                     [1m Learning iteration 584/1500 [0m                      

                       Computation: 49256 steps/s (collection: 1.876s, learning 0.120s)
             Mean action noise std: 2.00
          Mean value_function loss: 75.7109
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 45.9750
                       Mean reward: 656.02
               Mean episode length: 229.16
    Episode_Reward/reaching_object: 1.0706
    Episode_Reward/rotating_object: 134.8897
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 2.00s
                      Time elapsed: 00:21:18
                               ETA: 00:33:21

################################################################################
                     [1m Learning iteration 585/1500 [0m                      

                       Computation: 49017 steps/s (collection: 1.887s, learning 0.119s)
             Mean action noise std: 2.01
          Mean value_function loss: 74.3320
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 46.0025
                       Mean reward: 674.24
               Mean episode length: 238.62
    Episode_Reward/reaching_object: 1.0824
    Episode_Reward/rotating_object: 134.8566
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 2.01s
                      Time elapsed: 00:21:20
                               ETA: 00:33:19

################################################################################
                     [1m Learning iteration 586/1500 [0m                      

                       Computation: 49281 steps/s (collection: 1.880s, learning 0.115s)
             Mean action noise std: 2.01
          Mean value_function loss: 73.7964
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 46.0229
                       Mean reward: 703.97
               Mean episode length: 240.55
    Episode_Reward/reaching_object: 1.0935
    Episode_Reward/rotating_object: 135.6610
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 1.99s
                      Time elapsed: 00:21:22
                               ETA: 00:33:16

################################################################################
                     [1m Learning iteration 587/1500 [0m                      

                       Computation: 48345 steps/s (collection: 1.920s, learning 0.114s)
             Mean action noise std: 2.01
          Mean value_function loss: 84.5542
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 46.0425
                       Mean reward: 678.76
               Mean episode length: 239.42
    Episode_Reward/reaching_object: 1.0750
    Episode_Reward/rotating_object: 134.6693
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 2.03s
                      Time elapsed: 00:21:24
                               ETA: 00:33:14

################################################################################
                     [1m Learning iteration 588/1500 [0m                      

                       Computation: 49633 steps/s (collection: 1.883s, learning 0.097s)
             Mean action noise std: 2.01
          Mean value_function loss: 69.6881
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 46.0581
                       Mean reward: 684.82
               Mean episode length: 237.40
    Episode_Reward/reaching_object: 1.0847
    Episode_Reward/rotating_object: 134.8579
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 1.98s
                      Time elapsed: 00:21:26
                               ETA: 00:33:11

################################################################################
                     [1m Learning iteration 589/1500 [0m                      

                       Computation: 49565 steps/s (collection: 1.865s, learning 0.118s)
             Mean action noise std: 2.01
          Mean value_function loss: 81.6754
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 46.0739
                       Mean reward: 685.55
               Mean episode length: 235.42
    Episode_Reward/reaching_object: 1.0759
    Episode_Reward/rotating_object: 133.2222
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 1.98s
                      Time elapsed: 00:21:28
                               ETA: 00:33:09

################################################################################
                     [1m Learning iteration 590/1500 [0m                      

                       Computation: 48727 steps/s (collection: 1.902s, learning 0.115s)
             Mean action noise std: 2.02
          Mean value_function loss: 73.0289
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 46.0910
                       Mean reward: 701.50
               Mean episode length: 241.74
    Episode_Reward/reaching_object: 1.1095
    Episode_Reward/rotating_object: 136.4041
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 2.02s
                      Time elapsed: 00:21:30
                               ETA: 00:33:06

################################################################################
                     [1m Learning iteration 591/1500 [0m                      

                       Computation: 49553 steps/s (collection: 1.880s, learning 0.104s)
             Mean action noise std: 2.02
          Mean value_function loss: 86.5128
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 46.1151
                       Mean reward: 658.24
               Mean episode length: 238.10
    Episode_Reward/reaching_object: 1.1052
    Episode_Reward/rotating_object: 134.7151
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 1.98s
                      Time elapsed: 00:21:32
                               ETA: 00:33:04

################################################################################
                     [1m Learning iteration 592/1500 [0m                      

                       Computation: 48779 steps/s (collection: 1.906s, learning 0.109s)
             Mean action noise std: 2.02
          Mean value_function loss: 94.5710
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 46.1381
                       Mean reward: 665.16
               Mean episode length: 227.02
    Episode_Reward/reaching_object: 1.0704
    Episode_Reward/rotating_object: 134.7314
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 2.02s
                      Time elapsed: 00:21:34
                               ETA: 00:33:01

################################################################################
                     [1m Learning iteration 593/1500 [0m                      

                       Computation: 48239 steps/s (collection: 1.934s, learning 0.104s)
             Mean action noise std: 2.02
          Mean value_function loss: 71.5543
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 46.1605
                       Mean reward: 634.70
               Mean episode length: 233.36
    Episode_Reward/reaching_object: 1.0824
    Episode_Reward/rotating_object: 131.0797
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 2.04s
                      Time elapsed: 00:21:36
                               ETA: 00:32:59

################################################################################
                     [1m Learning iteration 594/1500 [0m                      

                       Computation: 49921 steps/s (collection: 1.870s, learning 0.099s)
             Mean action noise std: 2.03
          Mean value_function loss: 81.3350
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 46.1896
                       Mean reward: 684.60
               Mean episode length: 240.03
    Episode_Reward/reaching_object: 1.0902
    Episode_Reward/rotating_object: 137.4534
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 1.97s
                      Time elapsed: 00:21:38
                               ETA: 00:32:56

################################################################################
                     [1m Learning iteration 595/1500 [0m                      

                       Computation: 50321 steps/s (collection: 1.844s, learning 0.109s)
             Mean action noise std: 2.03
          Mean value_function loss: 72.6274
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 46.2162
                       Mean reward: 703.63
               Mean episode length: 242.73
    Episode_Reward/reaching_object: 1.0709
    Episode_Reward/rotating_object: 133.0844
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 1.95s
                      Time elapsed: 00:21:40
                               ETA: 00:32:54

################################################################################
                     [1m Learning iteration 596/1500 [0m                      

                       Computation: 50592 steps/s (collection: 1.844s, learning 0.099s)
             Mean action noise std: 2.03
          Mean value_function loss: 78.1018
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 46.2390
                       Mean reward: 679.71
               Mean episode length: 237.47
    Episode_Reward/reaching_object: 1.0902
    Episode_Reward/rotating_object: 136.1623
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 1.94s
                      Time elapsed: 00:21:42
                               ETA: 00:32:51

################################################################################
                     [1m Learning iteration 597/1500 [0m                      

                       Computation: 48227 steps/s (collection: 1.935s, learning 0.103s)
             Mean action noise std: 2.03
          Mean value_function loss: 72.7542
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 46.2546
                       Mean reward: 690.71
               Mean episode length: 237.31
    Episode_Reward/reaching_object: 1.0664
    Episode_Reward/rotating_object: 134.7125
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 2.04s
                      Time elapsed: 00:21:44
                               ETA: 00:32:49

################################################################################
                     [1m Learning iteration 598/1500 [0m                      

                       Computation: 48261 steps/s (collection: 1.931s, learning 0.106s)
             Mean action noise std: 2.03
          Mean value_function loss: 65.6891
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 46.2835
                       Mean reward: 666.62
               Mean episode length: 236.41
    Episode_Reward/reaching_object: 1.0796
    Episode_Reward/rotating_object: 136.2825
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 2.04s
                      Time elapsed: 00:21:46
                               ETA: 00:32:47

################################################################################
                     [1m Learning iteration 599/1500 [0m                      

                       Computation: 48160 steps/s (collection: 1.932s, learning 0.109s)
             Mean action noise std: 2.04
          Mean value_function loss: 79.0001
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 46.3189
                       Mean reward: 639.32
               Mean episode length: 230.28
    Episode_Reward/reaching_object: 1.0661
    Episode_Reward/rotating_object: 133.7285
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 2.04s
                      Time elapsed: 00:21:48
                               ETA: 00:32:44

################################################################################
                     [1m Learning iteration 600/1500 [0m                      

                       Computation: 47981 steps/s (collection: 1.921s, learning 0.128s)
             Mean action noise std: 2.04
          Mean value_function loss: 77.0321
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 46.3378
                       Mean reward: 645.59
               Mean episode length: 234.14
    Episode_Reward/reaching_object: 1.0757
    Episode_Reward/rotating_object: 134.9870
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 2.05s
                      Time elapsed: 00:21:50
                               ETA: 00:32:42

################################################################################
                     [1m Learning iteration 601/1500 [0m                      

                       Computation: 47965 steps/s (collection: 1.932s, learning 0.117s)
             Mean action noise std: 2.04
          Mean value_function loss: 75.5770
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 46.3532
                       Mean reward: 642.90
               Mean episode length: 231.41
    Episode_Reward/reaching_object: 1.0824
    Episode_Reward/rotating_object: 133.8467
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 2.05s
                      Time elapsed: 00:21:52
                               ETA: 00:32:39

################################################################################
                     [1m Learning iteration 602/1500 [0m                      

                       Computation: 49275 steps/s (collection: 1.891s, learning 0.104s)
             Mean action noise std: 2.04
          Mean value_function loss: 78.3641
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 46.3849
                       Mean reward: 652.59
               Mean episode length: 231.30
    Episode_Reward/reaching_object: 1.0676
    Episode_Reward/rotating_object: 129.6234
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 1.99s
                      Time elapsed: 00:21:54
                               ETA: 00:32:37

################################################################################
                     [1m Learning iteration 603/1500 [0m                      

                       Computation: 49166 steps/s (collection: 1.895s, learning 0.104s)
             Mean action noise std: 2.05
          Mean value_function loss: 71.5894
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 46.4119
                       Mean reward: 715.41
               Mean episode length: 243.34
    Episode_Reward/reaching_object: 1.0777
    Episode_Reward/rotating_object: 134.3421
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 2.00s
                      Time elapsed: 00:21:56
                               ETA: 00:32:35

################################################################################
                     [1m Learning iteration 604/1500 [0m                      

                       Computation: 50234 steps/s (collection: 1.850s, learning 0.107s)
             Mean action noise std: 2.05
          Mean value_function loss: 67.1379
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 46.4347
                       Mean reward: 696.90
               Mean episode length: 237.02
    Episode_Reward/reaching_object: 1.0716
    Episode_Reward/rotating_object: 136.0297
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 1.96s
                      Time elapsed: 00:21:58
                               ETA: 00:32:32

################################################################################
                     [1m Learning iteration 605/1500 [0m                      

                       Computation: 48687 steps/s (collection: 1.907s, learning 0.112s)
             Mean action noise std: 2.05
          Mean value_function loss: 58.4292
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 46.4501
                       Mean reward: 708.43
               Mean episode length: 241.03
    Episode_Reward/reaching_object: 1.0821
    Episode_Reward/rotating_object: 137.5748
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 2.02s
                      Time elapsed: 00:22:00
                               ETA: 00:32:30

################################################################################
                     [1m Learning iteration 606/1500 [0m                      

                       Computation: 47432 steps/s (collection: 1.951s, learning 0.121s)
             Mean action noise std: 2.05
          Mean value_function loss: 58.3544
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 46.4731
                       Mean reward: 697.52
               Mean episode length: 239.65
    Episode_Reward/reaching_object: 1.0813
    Episode_Reward/rotating_object: 135.9105
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 2.07s
                      Time elapsed: 00:22:02
                               ETA: 00:32:27

################################################################################
                     [1m Learning iteration 607/1500 [0m                      

                       Computation: 48960 steps/s (collection: 1.892s, learning 0.116s)
             Mean action noise std: 2.06
          Mean value_function loss: 69.1872
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 46.4957
                       Mean reward: 697.90
               Mean episode length: 238.45
    Episode_Reward/reaching_object: 1.1071
    Episode_Reward/rotating_object: 141.4253
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 2.01s
                      Time elapsed: 00:22:04
                               ETA: 00:32:25

################################################################################
                     [1m Learning iteration 608/1500 [0m                      

                       Computation: 47961 steps/s (collection: 1.921s, learning 0.129s)
             Mean action noise std: 2.06
          Mean value_function loss: 66.6389
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 46.5171
                       Mean reward: 701.24
               Mean episode length: 243.42
    Episode_Reward/reaching_object: 1.0882
    Episode_Reward/rotating_object: 136.5201
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 2.05s
                      Time elapsed: 00:22:06
                               ETA: 00:32:23

################################################################################
                     [1m Learning iteration 609/1500 [0m                      

                       Computation: 48721 steps/s (collection: 1.899s, learning 0.118s)
             Mean action noise std: 2.06
          Mean value_function loss: 62.9123
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 46.5429
                       Mean reward: 712.20
               Mean episode length: 243.64
    Episode_Reward/reaching_object: 1.0903
    Episode_Reward/rotating_object: 140.0806
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 2.02s
                      Time elapsed: 00:22:08
                               ETA: 00:32:20

################################################################################
                     [1m Learning iteration 610/1500 [0m                      

                       Computation: 47900 steps/s (collection: 1.945s, learning 0.108s)
             Mean action noise std: 2.06
          Mean value_function loss: 63.4446
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 46.5644
                       Mean reward: 675.35
               Mean episode length: 243.35
    Episode_Reward/reaching_object: 1.1007
    Episode_Reward/rotating_object: 138.2373
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 2.05s
                      Time elapsed: 00:22:10
                               ETA: 00:32:18

################################################################################
                     [1m Learning iteration 611/1500 [0m                      

                       Computation: 49710 steps/s (collection: 1.869s, learning 0.108s)
             Mean action noise std: 2.06
          Mean value_function loss: 69.8832
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 46.5897
                       Mean reward: 728.81
               Mean episode length: 241.06
    Episode_Reward/reaching_object: 1.0952
    Episode_Reward/rotating_object: 141.9080
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 1.98s
                      Time elapsed: 00:22:12
                               ETA: 00:32:15

################################################################################
                     [1m Learning iteration 612/1500 [0m                      

                       Computation: 48954 steps/s (collection: 1.885s, learning 0.123s)
             Mean action noise std: 2.07
          Mean value_function loss: 58.3948
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 46.6151
                       Mean reward: 712.93
               Mean episode length: 239.29
    Episode_Reward/reaching_object: 1.0825
    Episode_Reward/rotating_object: 140.3733
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 2.01s
                      Time elapsed: 00:22:14
                               ETA: 00:32:13

################################################################################
                     [1m Learning iteration 613/1500 [0m                      

                       Computation: 48975 steps/s (collection: 1.892s, learning 0.115s)
             Mean action noise std: 2.07
          Mean value_function loss: 62.8947
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 46.6309
                       Mean reward: 701.56
               Mean episode length: 242.51
    Episode_Reward/reaching_object: 1.0826
    Episode_Reward/rotating_object: 138.5727
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 2.01s
                      Time elapsed: 00:22:16
                               ETA: 00:32:10

################################################################################
                     [1m Learning iteration 614/1500 [0m                      

                       Computation: 49128 steps/s (collection: 1.903s, learning 0.098s)
             Mean action noise std: 2.07
          Mean value_function loss: 59.4064
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 46.6473
                       Mean reward: 730.53
               Mean episode length: 242.22
    Episode_Reward/reaching_object: 1.0843
    Episode_Reward/rotating_object: 140.3500
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 2.00s
                      Time elapsed: 00:22:18
                               ETA: 00:32:08

################################################################################
                     [1m Learning iteration 615/1500 [0m                      

                       Computation: 48424 steps/s (collection: 1.904s, learning 0.126s)
             Mean action noise std: 2.07
          Mean value_function loss: 66.4678
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 46.6686
                       Mean reward: 695.25
               Mean episode length: 240.06
    Episode_Reward/reaching_object: 1.0802
    Episode_Reward/rotating_object: 138.2724
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 2.03s
                      Time elapsed: 00:22:20
                               ETA: 00:32:06

################################################################################
                     [1m Learning iteration 616/1500 [0m                      

                       Computation: 49049 steps/s (collection: 1.876s, learning 0.128s)
             Mean action noise std: 2.08
          Mean value_function loss: 67.3736
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 46.7035
                       Mean reward: 713.82
               Mean episode length: 241.45
    Episode_Reward/reaching_object: 1.0770
    Episode_Reward/rotating_object: 139.2964
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 2.00s
                      Time elapsed: 00:22:22
                               ETA: 00:32:03

################################################################################
                     [1m Learning iteration 617/1500 [0m                      

                       Computation: 49360 steps/s (collection: 1.880s, learning 0.112s)
             Mean action noise std: 2.08
          Mean value_function loss: 70.0371
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 46.7307
                       Mean reward: 665.46
               Mean episode length: 232.77
    Episode_Reward/reaching_object: 1.0758
    Episode_Reward/rotating_object: 135.7117
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 1.99s
                      Time elapsed: 00:22:24
                               ETA: 00:32:01

################################################################################
                     [1m Learning iteration 618/1500 [0m                      

                       Computation: 50145 steps/s (collection: 1.852s, learning 0.108s)
             Mean action noise std: 2.08
          Mean value_function loss: 60.7154
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 46.7530
                       Mean reward: 710.67
               Mean episode length: 240.42
    Episode_Reward/reaching_object: 1.0935
    Episode_Reward/rotating_object: 142.1712
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 1.96s
                      Time elapsed: 00:22:26
                               ETA: 00:31:58

################################################################################
                     [1m Learning iteration 619/1500 [0m                      

                       Computation: 49070 steps/s (collection: 1.884s, learning 0.119s)
             Mean action noise std: 2.08
          Mean value_function loss: 65.7211
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 46.7754
                       Mean reward: 722.85
               Mean episode length: 242.69
    Episode_Reward/reaching_object: 1.0863
    Episode_Reward/rotating_object: 137.1081
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 2.00s
                      Time elapsed: 00:22:28
                               ETA: 00:31:56

################################################################################
                     [1m Learning iteration 620/1500 [0m                      

                       Computation: 49788 steps/s (collection: 1.862s, learning 0.112s)
             Mean action noise std: 2.09
          Mean value_function loss: 74.6117
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 46.7956
                       Mean reward: 735.14
               Mean episode length: 245.93
    Episode_Reward/reaching_object: 1.0926
    Episode_Reward/rotating_object: 139.3518
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 1.97s
                      Time elapsed: 00:22:30
                               ETA: 00:31:53

################################################################################
                     [1m Learning iteration 621/1500 [0m                      

                       Computation: 47400 steps/s (collection: 1.957s, learning 0.117s)
             Mean action noise std: 2.09
          Mean value_function loss: 60.1022
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 46.8163
                       Mean reward: 715.94
               Mean episode length: 242.22
    Episode_Reward/reaching_object: 1.0819
    Episode_Reward/rotating_object: 140.3580
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 2.07s
                      Time elapsed: 00:22:32
                               ETA: 00:31:51

################################################################################
                     [1m Learning iteration 622/1500 [0m                      

                       Computation: 49214 steps/s (collection: 1.882s, learning 0.116s)
             Mean action noise std: 2.09
          Mean value_function loss: 70.2210
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 46.8427
                       Mean reward: 670.80
               Mean episode length: 229.45
    Episode_Reward/reaching_object: 1.0677
    Episode_Reward/rotating_object: 137.8304
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 2.00s
                      Time elapsed: 00:22:34
                               ETA: 00:31:49

################################################################################
                     [1m Learning iteration 623/1500 [0m                      

                       Computation: 47526 steps/s (collection: 1.932s, learning 0.136s)
             Mean action noise std: 2.09
          Mean value_function loss: 69.7754
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 46.8663
                       Mean reward: 675.67
               Mean episode length: 237.23
    Episode_Reward/reaching_object: 1.0853
    Episode_Reward/rotating_object: 137.3380
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 2.07s
                      Time elapsed: 00:22:36
                               ETA: 00:31:46

################################################################################
                     [1m Learning iteration 624/1500 [0m                      

                       Computation: 44473 steps/s (collection: 2.068s, learning 0.143s)
             Mean action noise std: 2.10
          Mean value_function loss: 64.2116
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 46.8904
                       Mean reward: 709.32
               Mean episode length: 241.00
    Episode_Reward/reaching_object: 1.0761
    Episode_Reward/rotating_object: 135.3686
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 2.21s
                      Time elapsed: 00:22:38
                               ETA: 00:31:44

################################################################################
                     [1m Learning iteration 625/1500 [0m                      

                       Computation: 41438 steps/s (collection: 2.225s, learning 0.147s)
             Mean action noise std: 2.10
          Mean value_function loss: 61.4841
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 46.9198
                       Mean reward: 709.99
               Mean episode length: 242.34
    Episode_Reward/reaching_object: 1.0925
    Episode_Reward/rotating_object: 140.3137
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 2.37s
                      Time elapsed: 00:22:41
                               ETA: 00:31:42

################################################################################
                     [1m Learning iteration 626/1500 [0m                      

                       Computation: 40723 steps/s (collection: 2.264s, learning 0.150s)
             Mean action noise std: 2.10
          Mean value_function loss: 65.0390
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 46.9357
                       Mean reward: 694.57
               Mean episode length: 242.64
    Episode_Reward/reaching_object: 1.0756
    Episode_Reward/rotating_object: 135.7269
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 2.41s
                      Time elapsed: 00:22:43
                               ETA: 00:31:40

################################################################################
                     [1m Learning iteration 627/1500 [0m                      

                       Computation: 36764 steps/s (collection: 2.511s, learning 0.163s)
             Mean action noise std: 2.10
          Mean value_function loss: 69.4394
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 46.9503
                       Mean reward: 648.01
               Mean episode length: 222.97
    Episode_Reward/reaching_object: 1.0641
    Episode_Reward/rotating_object: 135.4109
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 2.67s
                      Time elapsed: 00:22:46
                               ETA: 00:31:39

################################################################################
                     [1m Learning iteration 628/1500 [0m                      

                       Computation: 40023 steps/s (collection: 2.289s, learning 0.168s)
             Mean action noise std: 2.11
          Mean value_function loss: 73.5998
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 46.9842
                       Mean reward: 704.16
               Mean episode length: 242.58
    Episode_Reward/reaching_object: 1.0714
    Episode_Reward/rotating_object: 135.0261
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 2.46s
                      Time elapsed: 00:22:48
                               ETA: 00:31:37

################################################################################
                     [1m Learning iteration 629/1500 [0m                      

                       Computation: 41326 steps/s (collection: 2.252s, learning 0.127s)
             Mean action noise std: 2.11
          Mean value_function loss: 56.6010
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 47.0234
                       Mean reward: 632.75
               Mean episode length: 231.88
    Episode_Reward/reaching_object: 1.0742
    Episode_Reward/rotating_object: 133.1553
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 2.38s
                      Time elapsed: 00:22:51
                               ETA: 00:31:35

################################################################################
                     [1m Learning iteration 630/1500 [0m                      

                       Computation: 42911 steps/s (collection: 2.165s, learning 0.125s)
             Mean action noise std: 2.11
          Mean value_function loss: 60.5995
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 47.0449
                       Mean reward: 711.69
               Mean episode length: 245.30
    Episode_Reward/reaching_object: 1.0951
    Episode_Reward/rotating_object: 140.5516
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 2.29s
                      Time elapsed: 00:22:53
                               ETA: 00:31:33

################################################################################
                     [1m Learning iteration 631/1500 [0m                      

                       Computation: 41520 steps/s (collection: 2.236s, learning 0.132s)
             Mean action noise std: 2.11
          Mean value_function loss: 60.8371
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 47.0633
                       Mean reward: 706.65
               Mean episode length: 240.63
    Episode_Reward/reaching_object: 1.0824
    Episode_Reward/rotating_object: 136.5159
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 2.37s
                      Time elapsed: 00:22:55
                               ETA: 00:31:31

################################################################################
                     [1m Learning iteration 632/1500 [0m                      

                       Computation: 48293 steps/s (collection: 1.926s, learning 0.110s)
             Mean action noise std: 2.12
          Mean value_function loss: 73.0354
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 47.0967
                       Mean reward: 676.96
               Mean episode length: 234.98
    Episode_Reward/reaching_object: 1.0787
    Episode_Reward/rotating_object: 139.7365
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 2.04s
                      Time elapsed: 00:22:57
                               ETA: 00:31:29

################################################################################
                     [1m Learning iteration 633/1500 [0m                      

                       Computation: 49426 steps/s (collection: 1.881s, learning 0.108s)
             Mean action noise std: 2.12
          Mean value_function loss: 63.6928
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 47.1280
                       Mean reward: 665.71
               Mean episode length: 231.87
    Episode_Reward/reaching_object: 1.0605
    Episode_Reward/rotating_object: 134.9820
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 1.99s
                      Time elapsed: 00:22:59
                               ETA: 00:31:27

################################################################################
                     [1m Learning iteration 634/1500 [0m                      

                       Computation: 48243 steps/s (collection: 1.927s, learning 0.111s)
             Mean action noise std: 2.12
          Mean value_function loss: 57.7651
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 47.1450
                       Mean reward: 710.99
               Mean episode length: 242.63
    Episode_Reward/reaching_object: 1.1108
    Episode_Reward/rotating_object: 143.9996
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 2.04s
                      Time elapsed: 00:23:01
                               ETA: 00:31:24

################################################################################
                     [1m Learning iteration 635/1500 [0m                      

                       Computation: 50361 steps/s (collection: 1.854s, learning 0.098s)
             Mean action noise std: 2.12
          Mean value_function loss: 57.4637
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 47.1565
                       Mean reward: 729.02
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 1.0836
    Episode_Reward/rotating_object: 140.0736
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 1.95s
                      Time elapsed: 00:23:03
                               ETA: 00:31:22

################################################################################
                     [1m Learning iteration 636/1500 [0m                      

                       Computation: 50280 steps/s (collection: 1.857s, learning 0.099s)
             Mean action noise std: 2.13
          Mean value_function loss: 70.0197
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 47.1749
                       Mean reward: 697.80
               Mean episode length: 240.21
    Episode_Reward/reaching_object: 1.0844
    Episode_Reward/rotating_object: 138.4712
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 1.96s
                      Time elapsed: 00:23:05
                               ETA: 00:31:19

################################################################################
                     [1m Learning iteration 637/1500 [0m                      

                       Computation: 50475 steps/s (collection: 1.837s, learning 0.110s)
             Mean action noise std: 2.13
          Mean value_function loss: 74.3425
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 47.2000
                       Mean reward: 677.25
               Mean episode length: 234.88
    Episode_Reward/reaching_object: 1.0849
    Episode_Reward/rotating_object: 137.2889
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 1.95s
                      Time elapsed: 00:23:07
                               ETA: 00:31:17

################################################################################
                     [1m Learning iteration 638/1500 [0m                      

                       Computation: 49703 steps/s (collection: 1.871s, learning 0.106s)
             Mean action noise std: 2.13
          Mean value_function loss: 73.5276
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 47.2198
                       Mean reward: 708.93
               Mean episode length: 237.96
    Episode_Reward/reaching_object: 1.0844
    Episode_Reward/rotating_object: 139.1074
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 1.98s
                      Time elapsed: 00:23:09
                               ETA: 00:31:14

################################################################################
                     [1m Learning iteration 639/1500 [0m                      

                       Computation: 49892 steps/s (collection: 1.861s, learning 0.109s)
             Mean action noise std: 2.13
          Mean value_function loss: 62.1891
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 47.2399
                       Mean reward: 704.71
               Mean episode length: 238.26
    Episode_Reward/reaching_object: 1.0704
    Episode_Reward/rotating_object: 137.2815
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 1.97s
                      Time elapsed: 00:23:11
                               ETA: 00:31:12

################################################################################
                     [1m Learning iteration 640/1500 [0m                      

                       Computation: 49706 steps/s (collection: 1.878s, learning 0.100s)
             Mean action noise std: 2.13
          Mean value_function loss: 58.0632
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 47.2592
                       Mean reward: 706.01
               Mean episode length: 235.60
    Episode_Reward/reaching_object: 1.0953
    Episode_Reward/rotating_object: 139.8372
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 1.98s
                      Time elapsed: 00:23:13
                               ETA: 00:31:09

################################################################################
                     [1m Learning iteration 641/1500 [0m                      

                       Computation: 49988 steps/s (collection: 1.863s, learning 0.103s)
             Mean action noise std: 2.14
          Mean value_function loss: 64.0383
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 47.2892
                       Mean reward: 704.03
               Mean episode length: 243.67
    Episode_Reward/reaching_object: 1.0875
    Episode_Reward/rotating_object: 134.3131
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 1.97s
                      Time elapsed: 00:23:15
                               ETA: 00:31:07

################################################################################
                     [1m Learning iteration 642/1500 [0m                      

                       Computation: 49569 steps/s (collection: 1.883s, learning 0.100s)
             Mean action noise std: 2.14
          Mean value_function loss: 67.4619
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 47.3184
                       Mean reward: 746.28
               Mean episode length: 244.06
    Episode_Reward/reaching_object: 1.0851
    Episode_Reward/rotating_object: 140.6589
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 1.98s
                      Time elapsed: 00:23:17
                               ETA: 00:31:05

################################################################################
                     [1m Learning iteration 643/1500 [0m                      

                       Computation: 49095 steps/s (collection: 1.901s, learning 0.102s)
             Mean action noise std: 2.14
          Mean value_function loss: 80.1158
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 47.3366
                       Mean reward: 697.74
               Mean episode length: 238.33
    Episode_Reward/reaching_object: 1.0756
    Episode_Reward/rotating_object: 137.3852
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 2.00s
                      Time elapsed: 00:23:19
                               ETA: 00:31:02

################################################################################
                     [1m Learning iteration 644/1500 [0m                      

                       Computation: 48855 steps/s (collection: 1.907s, learning 0.105s)
             Mean action noise std: 2.15
          Mean value_function loss: 61.3332
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 47.3546
                       Mean reward: 696.47
               Mean episode length: 235.58
    Episode_Reward/reaching_object: 1.0907
    Episode_Reward/rotating_object: 139.8399
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 2.01s
                      Time elapsed: 00:23:21
                               ETA: 00:31:00

################################################################################
                     [1m Learning iteration 645/1500 [0m                      

                       Computation: 49109 steps/s (collection: 1.890s, learning 0.112s)
             Mean action noise std: 2.15
          Mean value_function loss: 65.9402
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 47.3851
                       Mean reward: 694.97
               Mean episode length: 239.95
    Episode_Reward/reaching_object: 1.0992
    Episode_Reward/rotating_object: 140.4014
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 2.00s
                      Time elapsed: 00:23:23
                               ETA: 00:30:57

################################################################################
                     [1m Learning iteration 646/1500 [0m                      

                       Computation: 49778 steps/s (collection: 1.861s, learning 0.114s)
             Mean action noise std: 2.15
          Mean value_function loss: 66.7842
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 47.4176
                       Mean reward: 712.98
               Mean episode length: 238.56
    Episode_Reward/reaching_object: 1.0926
    Episode_Reward/rotating_object: 139.9059
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 1.97s
                      Time elapsed: 00:23:25
                               ETA: 00:30:55

################################################################################
                     [1m Learning iteration 647/1500 [0m                      

                       Computation: 48977 steps/s (collection: 1.896s, learning 0.111s)
             Mean action noise std: 2.15
          Mean value_function loss: 58.5881
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 47.4438
                       Mean reward: 724.10
               Mean episode length: 246.15
    Episode_Reward/reaching_object: 1.1052
    Episode_Reward/rotating_object: 142.5620
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 2.01s
                      Time elapsed: 00:23:27
                               ETA: 00:30:53

################################################################################
                     [1m Learning iteration 648/1500 [0m                      

                       Computation: 49125 steps/s (collection: 1.888s, learning 0.113s)
             Mean action noise std: 2.16
          Mean value_function loss: 68.6813
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 47.4644
                       Mean reward: 702.72
               Mean episode length: 238.48
    Episode_Reward/reaching_object: 1.0798
    Episode_Reward/rotating_object: 136.5936
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 2.00s
                      Time elapsed: 00:23:29
                               ETA: 00:30:50

################################################################################
                     [1m Learning iteration 649/1500 [0m                      

                       Computation: 48655 steps/s (collection: 1.919s, learning 0.102s)
             Mean action noise std: 2.16
          Mean value_function loss: 78.0409
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 47.4897
                       Mean reward: 700.77
               Mean episode length: 236.22
    Episode_Reward/reaching_object: 1.0845
    Episode_Reward/rotating_object: 139.9590
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 2.02s
                      Time elapsed: 00:23:31
                               ETA: 00:30:48

################################################################################
                     [1m Learning iteration 650/1500 [0m                      

                       Computation: 49003 steps/s (collection: 1.898s, learning 0.108s)
             Mean action noise std: 2.16
          Mean value_function loss: 62.2546
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 47.5088
                       Mean reward: 676.48
               Mean episode length: 236.41
    Episode_Reward/reaching_object: 1.0673
    Episode_Reward/rotating_object: 135.4398
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 2.01s
                      Time elapsed: 00:23:33
                               ETA: 00:30:45

################################################################################
                     [1m Learning iteration 651/1500 [0m                      

                       Computation: 47479 steps/s (collection: 1.967s, learning 0.104s)
             Mean action noise std: 2.16
          Mean value_function loss: 67.9199
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 47.5318
                       Mean reward: 669.86
               Mean episode length: 237.40
    Episode_Reward/reaching_object: 1.0869
    Episode_Reward/rotating_object: 136.3901
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 2.07s
                      Time elapsed: 00:23:35
                               ETA: 00:30:43

################################################################################
                     [1m Learning iteration 652/1500 [0m                      

                       Computation: 47666 steps/s (collection: 1.962s, learning 0.101s)
             Mean action noise std: 2.17
          Mean value_function loss: 72.2063
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 47.5599
                       Mean reward: 684.39
               Mean episode length: 239.40
    Episode_Reward/reaching_object: 1.0893
    Episode_Reward/rotating_object: 137.5967
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 2.06s
                      Time elapsed: 00:23:37
                               ETA: 00:30:41

################################################################################
                     [1m Learning iteration 653/1500 [0m                      

                       Computation: 50690 steps/s (collection: 1.844s, learning 0.096s)
             Mean action noise std: 2.17
          Mean value_function loss: 61.0807
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 47.5937
                       Mean reward: 677.16
               Mean episode length: 238.62
    Episode_Reward/reaching_object: 1.0768
    Episode_Reward/rotating_object: 133.9361
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 1.94s
                      Time elapsed: 00:23:39
                               ETA: 00:30:38

################################################################################
                     [1m Learning iteration 654/1500 [0m                      

                       Computation: 50303 steps/s (collection: 1.856s, learning 0.098s)
             Mean action noise std: 2.17
          Mean value_function loss: 67.1403
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 47.6282
                       Mean reward: 687.89
               Mean episode length: 238.63
    Episode_Reward/reaching_object: 1.0928
    Episode_Reward/rotating_object: 139.9297
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 1.95s
                      Time elapsed: 00:23:41
                               ETA: 00:30:36

################################################################################
                     [1m Learning iteration 655/1500 [0m                      

                       Computation: 49141 steps/s (collection: 1.901s, learning 0.100s)
             Mean action noise std: 2.18
          Mean value_function loss: 63.4166
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 47.6529
                       Mean reward: 713.31
               Mean episode length: 245.67
    Episode_Reward/reaching_object: 1.0867
    Episode_Reward/rotating_object: 136.6606
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 2.00s
                      Time elapsed: 00:23:43
                               ETA: 00:30:33

################################################################################
                     [1m Learning iteration 656/1500 [0m                      

                       Computation: 50559 steps/s (collection: 1.843s, learning 0.102s)
             Mean action noise std: 2.18
          Mean value_function loss: 75.5418
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 47.6674
                       Mean reward: 721.44
               Mean episode length: 246.48
    Episode_Reward/reaching_object: 1.0840
    Episode_Reward/rotating_object: 139.2339
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 1.94s
                      Time elapsed: 00:23:45
                               ETA: 00:30:31

################################################################################
                     [1m Learning iteration 657/1500 [0m                      

                       Computation: 50495 steps/s (collection: 1.850s, learning 0.097s)
             Mean action noise std: 2.18
          Mean value_function loss: 53.1205
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 47.6901
                       Mean reward: 673.01
               Mean episode length: 235.02
    Episode_Reward/reaching_object: 1.0836
    Episode_Reward/rotating_object: 140.3044
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 1.95s
                      Time elapsed: 00:23:47
                               ETA: 00:30:29

################################################################################
                     [1m Learning iteration 658/1500 [0m                      

                       Computation: 48102 steps/s (collection: 1.946s, learning 0.098s)
             Mean action noise std: 2.18
          Mean value_function loss: 63.8385
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 47.7137
                       Mean reward: 677.02
               Mean episode length: 238.54
    Episode_Reward/reaching_object: 1.0870
    Episode_Reward/rotating_object: 139.7240
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 2.04s
                      Time elapsed: 00:23:49
                               ETA: 00:30:26

################################################################################
                     [1m Learning iteration 659/1500 [0m                      

                       Computation: 48189 steps/s (collection: 1.918s, learning 0.122s)
             Mean action noise std: 2.18
          Mean value_function loss: 71.8014
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 47.7346
                       Mean reward: 667.44
               Mean episode length: 233.57
    Episode_Reward/reaching_object: 1.0726
    Episode_Reward/rotating_object: 135.8466
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 2.04s
                      Time elapsed: 00:23:51
                               ETA: 00:30:24

################################################################################
                     [1m Learning iteration 660/1500 [0m                      

                       Computation: 49308 steps/s (collection: 1.845s, learning 0.149s)
             Mean action noise std: 2.19
          Mean value_function loss: 76.3696
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 47.7494
                       Mean reward: 712.54
               Mean episode length: 237.55
    Episode_Reward/reaching_object: 1.0732
    Episode_Reward/rotating_object: 139.1819
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 1.99s
                      Time elapsed: 00:23:53
                               ETA: 00:30:21

################################################################################
                     [1m Learning iteration 661/1500 [0m                      

                       Computation: 47175 steps/s (collection: 1.983s, learning 0.101s)
             Mean action noise std: 2.19
          Mean value_function loss: 75.7428
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 47.7663
                       Mean reward: 670.28
               Mean episode length: 234.24
    Episode_Reward/reaching_object: 1.0564
    Episode_Reward/rotating_object: 135.0273
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 2.08s
                      Time elapsed: 00:23:55
                               ETA: 00:30:19

################################################################################
                     [1m Learning iteration 662/1500 [0m                      

                       Computation: 48812 steps/s (collection: 1.900s, learning 0.114s)
             Mean action noise std: 2.19
          Mean value_function loss: 56.6567
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 47.7847
                       Mean reward: 719.38
               Mean episode length: 247.16
    Episode_Reward/reaching_object: 1.1004
    Episode_Reward/rotating_object: 143.6664
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 2.01s
                      Time elapsed: 00:23:57
                               ETA: 00:30:17

################################################################################
                     [1m Learning iteration 663/1500 [0m                      

                       Computation: 48670 steps/s (collection: 1.919s, learning 0.101s)
             Mean action noise std: 2.19
          Mean value_function loss: 54.8131
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 47.8048
                       Mean reward: 715.75
               Mean episode length: 241.99
    Episode_Reward/reaching_object: 1.0960
    Episode_Reward/rotating_object: 140.2467
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 2.02s
                      Time elapsed: 00:23:59
                               ETA: 00:30:14

################################################################################
                     [1m Learning iteration 664/1500 [0m                      

                       Computation: 46998 steps/s (collection: 1.972s, learning 0.120s)
             Mean action noise std: 2.19
          Mean value_function loss: 66.6107
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 47.8244
                       Mean reward: 720.19
               Mean episode length: 239.41
    Episode_Reward/reaching_object: 1.0734
    Episode_Reward/rotating_object: 139.9185
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 2.09s
                      Time elapsed: 00:24:01
                               ETA: 00:30:12

################################################################################
                     [1m Learning iteration 665/1500 [0m                      

                       Computation: 48046 steps/s (collection: 1.943s, learning 0.103s)
             Mean action noise std: 2.20
          Mean value_function loss: 58.0242
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 47.8439
                       Mean reward: 690.92
               Mean episode length: 237.58
    Episode_Reward/reaching_object: 1.0829
    Episode_Reward/rotating_object: 138.5461
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 2.05s
                      Time elapsed: 00:24:03
                               ETA: 00:30:10

################################################################################
                     [1m Learning iteration 666/1500 [0m                      

                       Computation: 27583 steps/s (collection: 3.455s, learning 0.109s)
             Mean action noise std: 2.20
          Mean value_function loss: 66.6648
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 47.8660
                       Mean reward: 659.63
               Mean episode length: 234.14
    Episode_Reward/reaching_object: 1.0509
    Episode_Reward/rotating_object: 134.0458
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 3.56s
                      Time elapsed: 00:24:07
                               ETA: 00:30:09

################################################################################
                     [1m Learning iteration 667/1500 [0m                      

                       Computation: 14578 steps/s (collection: 6.608s, learning 0.135s)
             Mean action noise std: 2.20
          Mean value_function loss: 60.2726
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 47.9009
                       Mean reward: 696.74
               Mean episode length: 236.35
    Episode_Reward/reaching_object: 1.0796
    Episode_Reward/rotating_object: 141.2510
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 6.74s
                      Time elapsed: 00:24:14
                               ETA: 00:30:13

################################################################################
                     [1m Learning iteration 668/1500 [0m                      

                       Computation: 14519 steps/s (collection: 6.641s, learning 0.130s)
             Mean action noise std: 2.21
          Mean value_function loss: 59.9629
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 47.9393
                       Mean reward: 715.56
               Mean episode length: 241.06
    Episode_Reward/reaching_object: 1.1009
    Episode_Reward/rotating_object: 144.0486
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 6.77s
                      Time elapsed: 00:24:21
                               ETA: 00:30:17

################################################################################
                     [1m Learning iteration 669/1500 [0m                      

                       Computation: 14453 steps/s (collection: 6.639s, learning 0.162s)
             Mean action noise std: 2.21
          Mean value_function loss: 72.4176
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 47.9681
                       Mean reward: 710.15
               Mean episode length: 241.43
    Episode_Reward/reaching_object: 1.0879
    Episode_Reward/rotating_object: 141.5665
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 6.80s
                      Time elapsed: 00:24:27
                               ETA: 00:30:20

################################################################################
                     [1m Learning iteration 670/1500 [0m                      

                       Computation: 14560 steps/s (collection: 6.572s, learning 0.180s)
             Mean action noise std: 2.21
          Mean value_function loss: 59.5794
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 47.9944
                       Mean reward: 705.50
               Mean episode length: 245.27
    Episode_Reward/reaching_object: 1.0678
    Episode_Reward/rotating_object: 137.6632
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 6.75s
                      Time elapsed: 00:24:34
                               ETA: 00:30:24

################################################################################
                     [1m Learning iteration 671/1500 [0m                      

                       Computation: 14310 steps/s (collection: 6.712s, learning 0.158s)
             Mean action noise std: 2.22
          Mean value_function loss: 61.6245
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 48.0269
                       Mean reward: 703.84
               Mean episode length: 236.51
    Episode_Reward/reaching_object: 1.0682
    Episode_Reward/rotating_object: 141.1283
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 6.87s
                      Time elapsed: 00:24:41
                               ETA: 00:30:27

################################################################################
                     [1m Learning iteration 672/1500 [0m                      

                       Computation: 13459 steps/s (collection: 7.096s, learning 0.207s)
             Mean action noise std: 2.22
          Mean value_function loss: 56.3171
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 48.0566
                       Mean reward: 725.21
               Mean episode length: 244.06
    Episode_Reward/reaching_object: 1.0905
    Episode_Reward/rotating_object: 141.7281
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 7.30s
                      Time elapsed: 00:24:48
                               ETA: 00:30:31

################################################################################
                     [1m Learning iteration 673/1500 [0m                      

                       Computation: 14122 steps/s (collection: 6.802s, learning 0.159s)
             Mean action noise std: 2.22
          Mean value_function loss: 70.7899
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 48.0738
                       Mean reward: 716.54
               Mean episode length: 243.48
    Episode_Reward/reaching_object: 1.0811
    Episode_Reward/rotating_object: 139.5637
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 6.96s
                      Time elapsed: 00:24:55
                               ETA: 00:30:35

################################################################################
                     [1m Learning iteration 674/1500 [0m                      

                       Computation: 14527 steps/s (collection: 6.637s, learning 0.130s)
             Mean action noise std: 2.22
          Mean value_function loss: 60.9293
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 48.0964
                       Mean reward: 696.32
               Mean episode length: 238.02
    Episode_Reward/reaching_object: 1.0674
    Episode_Reward/rotating_object: 140.4276
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 6.77s
                      Time elapsed: 00:25:02
                               ETA: 00:30:38

################################################################################
                     [1m Learning iteration 675/1500 [0m                      

                       Computation: 22769 steps/s (collection: 4.182s, learning 0.136s)
             Mean action noise std: 2.23
          Mean value_function loss: 65.2291
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 48.1376
                       Mean reward: 716.63
               Mean episode length: 240.31
    Episode_Reward/reaching_object: 1.0761
    Episode_Reward/rotating_object: 139.6298
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 4.32s
                      Time elapsed: 00:25:06
                               ETA: 00:30:38

################################################################################
                     [1m Learning iteration 676/1500 [0m                      

                       Computation: 51993 steps/s (collection: 1.780s, learning 0.111s)
             Mean action noise std: 2.23
          Mean value_function loss: 75.7017
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 48.1641
                       Mean reward: 664.91
               Mean episode length: 231.07
    Episode_Reward/reaching_object: 1.0507
    Episode_Reward/rotating_object: 136.6088
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 1.89s
                      Time elapsed: 00:25:08
                               ETA: 00:30:36

################################################################################
                     [1m Learning iteration 677/1500 [0m                      

                       Computation: 51593 steps/s (collection: 1.777s, learning 0.129s)
             Mean action noise std: 2.23
          Mean value_function loss: 69.4323
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 48.1812
                       Mean reward: 737.47
               Mean episode length: 244.24
    Episode_Reward/reaching_object: 1.0754
    Episode_Reward/rotating_object: 139.9325
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 1.91s
                      Time elapsed: 00:25:10
                               ETA: 00:30:33

################################################################################
                     [1m Learning iteration 678/1500 [0m                      

                       Computation: 52466 steps/s (collection: 1.770s, learning 0.104s)
             Mean action noise std: 2.23
          Mean value_function loss: 67.2736
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 48.1967
                       Mean reward: 702.83
               Mean episode length: 238.63
    Episode_Reward/reaching_object: 1.0653
    Episode_Reward/rotating_object: 138.4038
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 1.87s
                      Time elapsed: 00:25:12
                               ETA: 00:30:31

################################################################################
                     [1m Learning iteration 679/1500 [0m                      

                       Computation: 51553 steps/s (collection: 1.813s, learning 0.094s)
             Mean action noise std: 2.24
          Mean value_function loss: 59.0313
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 48.2193
                       Mean reward: 667.51
               Mean episode length: 234.01
    Episode_Reward/reaching_object: 1.0576
    Episode_Reward/rotating_object: 135.4522
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 1.91s
                      Time elapsed: 00:25:14
                               ETA: 00:30:28

################################################################################
                     [1m Learning iteration 680/1500 [0m                      

                       Computation: 52534 steps/s (collection: 1.783s, learning 0.088s)
             Mean action noise std: 2.24
          Mean value_function loss: 65.5956
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 48.2457
                       Mean reward: 711.60
               Mean episode length: 237.67
    Episode_Reward/reaching_object: 1.0758
    Episode_Reward/rotating_object: 143.5128
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 1.87s
                      Time elapsed: 00:25:16
                               ETA: 00:30:25

################################################################################
                     [1m Learning iteration 681/1500 [0m                      

                       Computation: 48686 steps/s (collection: 1.849s, learning 0.171s)
             Mean action noise std: 2.24
          Mean value_function loss: 67.0669
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 48.2667
                       Mean reward: 693.46
               Mean episode length: 234.76
    Episode_Reward/reaching_object: 1.0708
    Episode_Reward/rotating_object: 139.6201
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 2.02s
                      Time elapsed: 00:25:18
                               ETA: 00:30:23

################################################################################
                     [1m Learning iteration 682/1500 [0m                      

                       Computation: 47185 steps/s (collection: 1.951s, learning 0.133s)
             Mean action noise std: 2.24
          Mean value_function loss: 58.7794
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 48.2951
                       Mean reward: 704.74
               Mean episode length: 244.39
    Episode_Reward/reaching_object: 1.1018
    Episode_Reward/rotating_object: 141.1253
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 2.08s
                      Time elapsed: 00:25:20
                               ETA: 00:30:20

################################################################################
                     [1m Learning iteration 683/1500 [0m                      

                       Computation: 45901 steps/s (collection: 2.021s, learning 0.121s)
             Mean action noise std: 2.25
          Mean value_function loss: 64.3667
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 48.3103
                       Mean reward: 687.18
               Mean episode length: 235.92
    Episode_Reward/reaching_object: 1.0909
    Episode_Reward/rotating_object: 141.9532
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 2.14s
                      Time elapsed: 00:25:22
                               ETA: 00:30:18

################################################################################
                     [1m Learning iteration 684/1500 [0m                      

                       Computation: 51657 steps/s (collection: 1.798s, learning 0.104s)
             Mean action noise std: 2.25
          Mean value_function loss: 68.8122
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 48.3335
                       Mean reward: 697.86
               Mean episode length: 238.94
    Episode_Reward/reaching_object: 1.0853
    Episode_Reward/rotating_object: 138.1753
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 1.90s
                      Time elapsed: 00:25:24
                               ETA: 00:30:15

################################################################################
                     [1m Learning iteration 685/1500 [0m                      

                       Computation: 52707 steps/s (collection: 1.754s, learning 0.111s)
             Mean action noise std: 2.25
          Mean value_function loss: 56.5593
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 48.3668
                       Mean reward: 733.48
               Mean episode length: 242.17
    Episode_Reward/reaching_object: 1.0749
    Episode_Reward/rotating_object: 141.5552
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 1.87s
                      Time elapsed: 00:25:26
                               ETA: 00:30:13

################################################################################
                     [1m Learning iteration 686/1500 [0m                      

                       Computation: 51305 steps/s (collection: 1.794s, learning 0.122s)
             Mean action noise std: 2.25
          Mean value_function loss: 60.0236
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 48.3923
                       Mean reward: 714.94
               Mean episode length: 242.87
    Episode_Reward/reaching_object: 1.0735
    Episode_Reward/rotating_object: 139.7315
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 1.92s
                      Time elapsed: 00:25:28
                               ETA: 00:30:10

################################################################################
                     [1m Learning iteration 687/1500 [0m                      

                       Computation: 52246 steps/s (collection: 1.783s, learning 0.098s)
             Mean action noise std: 2.26
          Mean value_function loss: 73.6245
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 48.4089
                       Mean reward: 698.73
               Mean episode length: 236.28
    Episode_Reward/reaching_object: 1.0700
    Episode_Reward/rotating_object: 140.3832
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 1.88s
                      Time elapsed: 00:25:30
                               ETA: 00:30:08

################################################################################
                     [1m Learning iteration 688/1500 [0m                      

                       Computation: 53078 steps/s (collection: 1.765s, learning 0.087s)
             Mean action noise std: 2.26
          Mean value_function loss: 63.9900
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 48.4297
                       Mean reward: 717.95
               Mean episode length: 238.52
    Episode_Reward/reaching_object: 1.0686
    Episode_Reward/rotating_object: 142.7628
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 1.85s
                      Time elapsed: 00:25:31
                               ETA: 00:30:05

################################################################################
                     [1m Learning iteration 689/1500 [0m                      

                       Computation: 52017 steps/s (collection: 1.760s, learning 0.130s)
             Mean action noise std: 2.26
          Mean value_function loss: 55.7983
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 48.4553
                       Mean reward: 687.55
               Mean episode length: 234.84
    Episode_Reward/reaching_object: 1.0668
    Episode_Reward/rotating_object: 138.0300
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 1.89s
                      Time elapsed: 00:25:33
                               ETA: 00:30:02

################################################################################
                     [1m Learning iteration 690/1500 [0m                      

                       Computation: 51317 steps/s (collection: 1.746s, learning 0.170s)
             Mean action noise std: 2.26
          Mean value_function loss: 63.3362
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 48.4786
                       Mean reward: 676.59
               Mean episode length: 237.04
    Episode_Reward/reaching_object: 1.0683
    Episode_Reward/rotating_object: 138.4734
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 1.92s
                      Time elapsed: 00:25:35
                               ETA: 00:30:00

################################################################################
                     [1m Learning iteration 691/1500 [0m                      

                       Computation: 52243 steps/s (collection: 1.790s, learning 0.092s)
             Mean action noise std: 2.27
          Mean value_function loss: 65.7239
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 48.5010
                       Mean reward: 695.46
               Mean episode length: 240.49
    Episode_Reward/reaching_object: 1.0670
    Episode_Reward/rotating_object: 140.6630
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 1.88s
                      Time elapsed: 00:25:37
                               ETA: 00:29:57

################################################################################
                     [1m Learning iteration 692/1500 [0m                      

                       Computation: 51978 steps/s (collection: 1.768s, learning 0.123s)
             Mean action noise std: 2.27
          Mean value_function loss: 73.0228
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 48.5322
                       Mean reward: 723.18
               Mean episode length: 246.44
    Episode_Reward/reaching_object: 1.0673
    Episode_Reward/rotating_object: 138.6078
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 1.89s
                      Time elapsed: 00:25:39
                               ETA: 00:29:54

################################################################################
                     [1m Learning iteration 693/1500 [0m                      

                       Computation: 50757 steps/s (collection: 1.834s, learning 0.103s)
             Mean action noise std: 2.27
          Mean value_function loss: 69.6892
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 48.5659
                       Mean reward: 655.03
               Mean episode length: 232.94
    Episode_Reward/reaching_object: 1.0597
    Episode_Reward/rotating_object: 136.4823
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 1.94s
                      Time elapsed: 00:25:41
                               ETA: 00:29:52

################################################################################
                     [1m Learning iteration 694/1500 [0m                      

                       Computation: 52762 steps/s (collection: 1.766s, learning 0.098s)
             Mean action noise std: 2.28
          Mean value_function loss: 68.4317
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 48.5981
                       Mean reward: 672.85
               Mean episode length: 229.74
    Episode_Reward/reaching_object: 1.0529
    Episode_Reward/rotating_object: 138.1809
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 1.86s
                      Time elapsed: 00:25:43
                               ETA: 00:29:49

################################################################################
                     [1m Learning iteration 695/1500 [0m                      

                       Computation: 50309 steps/s (collection: 1.827s, learning 0.127s)
             Mean action noise std: 2.28
          Mean value_function loss: 67.6394
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 48.6120
                       Mean reward: 733.10
               Mean episode length: 240.07
    Episode_Reward/reaching_object: 1.0744
    Episode_Reward/rotating_object: 141.8017
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 1.95s
                      Time elapsed: 00:25:45
                               ETA: 00:29:47

################################################################################
                     [1m Learning iteration 696/1500 [0m                      

                       Computation: 51593 steps/s (collection: 1.816s, learning 0.089s)
             Mean action noise std: 2.28
          Mean value_function loss: 70.7213
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 48.6307
                       Mean reward: 681.74
               Mean episode length: 238.23
    Episode_Reward/reaching_object: 1.0576
    Episode_Reward/rotating_object: 137.6673
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 1.91s
                      Time elapsed: 00:25:47
                               ETA: 00:29:44

################################################################################
                     [1m Learning iteration 697/1500 [0m                      

                       Computation: 51995 steps/s (collection: 1.784s, learning 0.107s)
             Mean action noise std: 2.28
          Mean value_function loss: 71.2497
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 48.6638
                       Mean reward: 686.02
               Mean episode length: 235.02
    Episode_Reward/reaching_object: 1.0648
    Episode_Reward/rotating_object: 139.4060
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 1.89s
                      Time elapsed: 00:25:49
                               ETA: 00:29:42

################################################################################
                     [1m Learning iteration 698/1500 [0m                      

                       Computation: 49327 steps/s (collection: 1.850s, learning 0.143s)
             Mean action noise std: 2.29
          Mean value_function loss: 65.4843
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 48.6961
                       Mean reward: 683.29
               Mean episode length: 234.04
    Episode_Reward/reaching_object: 1.0831
    Episode_Reward/rotating_object: 143.0765
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 1.99s
                      Time elapsed: 00:25:51
                               ETA: 00:29:39

################################################################################
                     [1m Learning iteration 699/1500 [0m                      

                       Computation: 49501 steps/s (collection: 1.875s, learning 0.111s)
             Mean action noise std: 2.29
          Mean value_function loss: 64.1881
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 48.7211
                       Mean reward: 723.06
               Mean episode length: 237.41
    Episode_Reward/reaching_object: 1.0608
    Episode_Reward/rotating_object: 139.1275
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 1.99s
                      Time elapsed: 00:25:53
                               ETA: 00:29:37

################################################################################
                     [1m Learning iteration 700/1500 [0m                      

                       Computation: 50653 steps/s (collection: 1.792s, learning 0.149s)
             Mean action noise std: 2.29
          Mean value_function loss: 71.5374
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 48.7366
                       Mean reward: 705.51
               Mean episode length: 239.08
    Episode_Reward/reaching_object: 1.0752
    Episode_Reward/rotating_object: 142.5711
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 1.94s
                      Time elapsed: 00:25:54
                               ETA: 00:29:34

################################################################################
                     [1m Learning iteration 701/1500 [0m                      

                       Computation: 51670 steps/s (collection: 1.788s, learning 0.115s)
             Mean action noise std: 2.29
          Mean value_function loss: 65.5575
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 48.7567
                       Mean reward: 721.41
               Mean episode length: 242.89
    Episode_Reward/reaching_object: 1.0702
    Episode_Reward/rotating_object: 137.3051
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 1.90s
                      Time elapsed: 00:25:56
                               ETA: 00:29:31

################################################################################
                     [1m Learning iteration 702/1500 [0m                      

                       Computation: 49445 steps/s (collection: 1.853s, learning 0.135s)
             Mean action noise std: 2.30
          Mean value_function loss: 62.0111
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 48.7804
                       Mean reward: 672.43
               Mean episode length: 230.19
    Episode_Reward/reaching_object: 1.0594
    Episode_Reward/rotating_object: 134.6544
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 1.99s
                      Time elapsed: 00:25:58
                               ETA: 00:29:29

################################################################################
                     [1m Learning iteration 703/1500 [0m                      

                       Computation: 52209 steps/s (collection: 1.770s, learning 0.113s)
             Mean action noise std: 2.30
          Mean value_function loss: 62.2233
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 48.8069
                       Mean reward: 702.57
               Mean episode length: 241.87
    Episode_Reward/reaching_object: 1.0783
    Episode_Reward/rotating_object: 141.3802
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 1.88s
                      Time elapsed: 00:26:00
                               ETA: 00:29:26

################################################################################
                     [1m Learning iteration 704/1500 [0m                      

                       Computation: 52803 steps/s (collection: 1.763s, learning 0.099s)
             Mean action noise std: 2.30
          Mean value_function loss: 75.0625
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 48.8317
                       Mean reward: 712.59
               Mean episode length: 246.11
    Episode_Reward/reaching_object: 1.0907
    Episode_Reward/rotating_object: 142.1704
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 1.86s
                      Time elapsed: 00:26:02
                               ETA: 00:29:24

################################################################################
                     [1m Learning iteration 705/1500 [0m                      

                       Computation: 48717 steps/s (collection: 1.896s, learning 0.122s)
             Mean action noise std: 2.31
          Mean value_function loss: 65.4412
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 48.8621
                       Mean reward: 711.12
               Mean episode length: 238.07
    Episode_Reward/reaching_object: 1.0618
    Episode_Reward/rotating_object: 139.2662
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 2.02s
                      Time elapsed: 00:26:04
                               ETA: 00:29:21

################################################################################
                     [1m Learning iteration 706/1500 [0m                      

                       Computation: 46364 steps/s (collection: 1.988s, learning 0.132s)
             Mean action noise std: 2.31
          Mean value_function loss: 57.2167
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 48.8929
                       Mean reward: 724.70
               Mean episode length: 244.73
    Episode_Reward/reaching_object: 1.0642
    Episode_Reward/rotating_object: 139.7699
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 2.12s
                      Time elapsed: 00:26:06
                               ETA: 00:29:19

################################################################################
                     [1m Learning iteration 707/1500 [0m                      

                       Computation: 51378 steps/s (collection: 1.815s, learning 0.099s)
             Mean action noise std: 2.31
          Mean value_function loss: 66.9042
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 48.9283
                       Mean reward: 690.33
               Mean episode length: 232.40
    Episode_Reward/reaching_object: 1.0656
    Episode_Reward/rotating_object: 138.1119
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 1.91s
                      Time elapsed: 00:26:08
                               ETA: 00:29:16

################################################################################
                     [1m Learning iteration 708/1500 [0m                      

                       Computation: 51143 steps/s (collection: 1.829s, learning 0.094s)
             Mean action noise std: 2.32
          Mean value_function loss: 76.1413
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 48.9606
                       Mean reward: 672.45
               Mean episode length: 234.61
    Episode_Reward/reaching_object: 1.0637
    Episode_Reward/rotating_object: 139.1593
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 1.92s
                      Time elapsed: 00:26:10
                               ETA: 00:29:14

################################################################################
                     [1m Learning iteration 709/1500 [0m                      

                       Computation: 52844 steps/s (collection: 1.769s, learning 0.091s)
             Mean action noise std: 2.32
          Mean value_function loss: 62.8943
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 48.9893
                       Mean reward: 677.69
               Mean episode length: 242.09
    Episode_Reward/reaching_object: 1.0794
    Episode_Reward/rotating_object: 138.5706
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 1.86s
                      Time elapsed: 00:26:12
                               ETA: 00:29:11

################################################################################
                     [1m Learning iteration 710/1500 [0m                      

                       Computation: 53181 steps/s (collection: 1.761s, learning 0.088s)
             Mean action noise std: 2.32
          Mean value_function loss: 58.1959
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 49.0046
                       Mean reward: 671.53
               Mean episode length: 231.98
    Episode_Reward/reaching_object: 1.0681
    Episode_Reward/rotating_object: 140.7160
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 1.85s
                      Time elapsed: 00:26:14
                               ETA: 00:29:09

################################################################################
                     [1m Learning iteration 711/1500 [0m                      

                       Computation: 50767 steps/s (collection: 1.831s, learning 0.106s)
             Mean action noise std: 2.32
          Mean value_function loss: 65.9022
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 49.0269
                       Mean reward: 728.72
               Mean episode length: 243.46
    Episode_Reward/reaching_object: 1.0832
    Episode_Reward/rotating_object: 141.0349
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 1.94s
                      Time elapsed: 00:26:16
                               ETA: 00:29:06

################################################################################
                     [1m Learning iteration 712/1500 [0m                      

                       Computation: 52683 steps/s (collection: 1.774s, learning 0.092s)
             Mean action noise std: 2.33
          Mean value_function loss: 73.9282
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 49.0463
                       Mean reward: 723.31
               Mean episode length: 242.35
    Episode_Reward/reaching_object: 1.0737
    Episode_Reward/rotating_object: 141.4645
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 1.87s
                      Time elapsed: 00:26:18
                               ETA: 00:29:04

################################################################################
                     [1m Learning iteration 713/1500 [0m                      

                       Computation: 50920 steps/s (collection: 1.832s, learning 0.099s)
             Mean action noise std: 2.33
          Mean value_function loss: 66.7327
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 49.0769
                       Mean reward: 722.52
               Mean episode length: 243.58
    Episode_Reward/reaching_object: 1.0773
    Episode_Reward/rotating_object: 141.5305
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 1.93s
                      Time elapsed: 00:26:20
                               ETA: 00:29:01

################################################################################
                     [1m Learning iteration 714/1500 [0m                      

                       Computation: 44442 steps/s (collection: 2.009s, learning 0.203s)
             Mean action noise std: 2.33
          Mean value_function loss: 55.1302
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 49.1013
                       Mean reward: 706.68
               Mean episode length: 237.82
    Episode_Reward/reaching_object: 1.0588
    Episode_Reward/rotating_object: 137.3202
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 2.21s
                      Time elapsed: 00:26:22
                               ETA: 00:28:59

################################################################################
                     [1m Learning iteration 715/1500 [0m                      

                       Computation: 42093 steps/s (collection: 2.191s, learning 0.144s)
             Mean action noise std: 2.34
          Mean value_function loss: 63.3972
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 49.1239
                       Mean reward: 742.91
               Mean episode length: 247.42
    Episode_Reward/reaching_object: 1.0768
    Episode_Reward/rotating_object: 142.4972
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 2.34s
                      Time elapsed: 00:26:24
                               ETA: 00:28:57

################################################################################
                     [1m Learning iteration 716/1500 [0m                      

                       Computation: 51315 steps/s (collection: 1.816s, learning 0.100s)
             Mean action noise std: 2.34
          Mean value_function loss: 64.6094
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 49.1501
                       Mean reward: 686.31
               Mean episode length: 235.92
    Episode_Reward/reaching_object: 1.0546
    Episode_Reward/rotating_object: 138.8423
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 1.92s
                      Time elapsed: 00:26:26
                               ETA: 00:28:54

################################################################################
                     [1m Learning iteration 717/1500 [0m                      

                       Computation: 48362 steps/s (collection: 1.935s, learning 0.097s)
             Mean action noise std: 2.34
          Mean value_function loss: 66.3307
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 49.1693
                       Mean reward: 689.51
               Mean episode length: 232.77
    Episode_Reward/reaching_object: 1.0432
    Episode_Reward/rotating_object: 137.1077
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 2.03s
                      Time elapsed: 00:26:28
                               ETA: 00:28:52

################################################################################
                     [1m Learning iteration 718/1500 [0m                      

                       Computation: 52170 steps/s (collection: 1.789s, learning 0.095s)
             Mean action noise std: 2.34
          Mean value_function loss: 50.1493
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 49.1819
                       Mean reward: 727.39
               Mean episode length: 244.00
    Episode_Reward/reaching_object: 1.0747
    Episode_Reward/rotating_object: 142.0475
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 1.88s
                      Time elapsed: 00:26:30
                               ETA: 00:28:49

################################################################################
                     [1m Learning iteration 719/1500 [0m                      

                       Computation: 52056 steps/s (collection: 1.796s, learning 0.092s)
             Mean action noise std: 2.34
          Mean value_function loss: 63.3508
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 49.2018
                       Mean reward: 694.32
               Mean episode length: 232.89
    Episode_Reward/reaching_object: 1.0713
    Episode_Reward/rotating_object: 142.6430
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 1.89s
                      Time elapsed: 00:26:32
                               ETA: 00:28:47

################################################################################
                     [1m Learning iteration 720/1500 [0m                      

                       Computation: 50373 steps/s (collection: 1.854s, learning 0.097s)
             Mean action noise std: 2.35
          Mean value_function loss: 60.6573
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 49.2239
                       Mean reward: 686.48
               Mean episode length: 242.19
    Episode_Reward/reaching_object: 1.0662
    Episode_Reward/rotating_object: 141.7488
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 1.95s
                      Time elapsed: 00:26:34
                               ETA: 00:28:44

################################################################################
                     [1m Learning iteration 721/1500 [0m                      

                       Computation: 49894 steps/s (collection: 1.820s, learning 0.150s)
             Mean action noise std: 2.35
          Mean value_function loss: 65.0065
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 49.2527
                       Mean reward: 670.54
               Mean episode length: 236.92
    Episode_Reward/reaching_object: 1.0589
    Episode_Reward/rotating_object: 137.6720
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 1.97s
                      Time elapsed: 00:26:36
                               ETA: 00:28:42

################################################################################
                     [1m Learning iteration 722/1500 [0m                      

                       Computation: 50922 steps/s (collection: 1.799s, learning 0.131s)
             Mean action noise std: 2.36
          Mean value_function loss: 65.1916
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 49.2848
                       Mean reward: 734.96
               Mean episode length: 241.44
    Episode_Reward/reaching_object: 1.0541
    Episode_Reward/rotating_object: 139.6613
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 1.93s
                      Time elapsed: 00:26:38
                               ETA: 00:28:39

################################################################################
                     [1m Learning iteration 723/1500 [0m                      

                       Computation: 52207 steps/s (collection: 1.792s, learning 0.091s)
             Mean action noise std: 2.36
          Mean value_function loss: 55.6461
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 49.3159
                       Mean reward: 705.63
               Mean episode length: 237.25
    Episode_Reward/reaching_object: 1.0701
    Episode_Reward/rotating_object: 143.0233
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 1.88s
                      Time elapsed: 00:26:40
                               ETA: 00:28:37

################################################################################
                     [1m Learning iteration 724/1500 [0m                      

                       Computation: 50205 steps/s (collection: 1.826s, learning 0.132s)
             Mean action noise std: 2.36
          Mean value_function loss: 56.3741
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 49.3371
                       Mean reward: 695.50
               Mean episode length: 242.73
    Episode_Reward/reaching_object: 1.0678
    Episode_Reward/rotating_object: 139.8754
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 1.96s
                      Time elapsed: 00:26:41
                               ETA: 00:28:34

################################################################################
                     [1m Learning iteration 725/1500 [0m                      

                       Computation: 50494 steps/s (collection: 1.836s, learning 0.111s)
             Mean action noise std: 2.36
          Mean value_function loss: 63.5570
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 49.3555
                       Mean reward: 699.26
               Mean episode length: 234.07
    Episode_Reward/reaching_object: 1.0492
    Episode_Reward/rotating_object: 142.4675
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 1.95s
                      Time elapsed: 00:26:43
                               ETA: 00:28:32

################################################################################
                     [1m Learning iteration 726/1500 [0m                      

                       Computation: 49409 steps/s (collection: 1.894s, learning 0.096s)
             Mean action noise std: 2.36
          Mean value_function loss: 70.3854
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 49.3738
                       Mean reward: 681.31
               Mean episode length: 235.13
    Episode_Reward/reaching_object: 1.0492
    Episode_Reward/rotating_object: 138.0909
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 1.99s
                      Time elapsed: 00:26:45
                               ETA: 00:28:29

################################################################################
                     [1m Learning iteration 727/1500 [0m                      

                       Computation: 49463 steps/s (collection: 1.861s, learning 0.127s)
             Mean action noise std: 2.37
          Mean value_function loss: 56.5236
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 49.3894
                       Mean reward: 720.44
               Mean episode length: 242.51
    Episode_Reward/reaching_object: 1.0692
    Episode_Reward/rotating_object: 142.8741
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 1.99s
                      Time elapsed: 00:26:47
                               ETA: 00:28:27

################################################################################
                     [1m Learning iteration 728/1500 [0m                      

                       Computation: 50692 steps/s (collection: 1.816s, learning 0.123s)
             Mean action noise std: 2.37
          Mean value_function loss: 59.7153
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 49.4206
                       Mean reward: 742.68
               Mean episode length: 248.25
    Episode_Reward/reaching_object: 1.0735
    Episode_Reward/rotating_object: 145.0390
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 1.94s
                      Time elapsed: 00:26:49
                               ETA: 00:28:24

################################################################################
                     [1m Learning iteration 729/1500 [0m                      

                       Computation: 49979 steps/s (collection: 1.843s, learning 0.124s)
             Mean action noise std: 2.38
          Mean value_function loss: 62.6632
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 49.4634
                       Mean reward: 692.87
               Mean episode length: 240.21
    Episode_Reward/reaching_object: 1.0524
    Episode_Reward/rotating_object: 138.1828
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 1.97s
                      Time elapsed: 00:26:51
                               ETA: 00:28:22

################################################################################
                     [1m Learning iteration 730/1500 [0m                      

                       Computation: 51373 steps/s (collection: 1.793s, learning 0.121s)
             Mean action noise std: 2.38
          Mean value_function loss: 65.8979
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 49.4993
                       Mean reward: 665.39
               Mean episode length: 235.09
    Episode_Reward/reaching_object: 1.0453
    Episode_Reward/rotating_object: 137.6321
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 1.91s
                      Time elapsed: 00:26:53
                               ETA: 00:28:19

################################################################################
                     [1m Learning iteration 731/1500 [0m                      

                       Computation: 51793 steps/s (collection: 1.807s, learning 0.091s)
             Mean action noise std: 2.38
          Mean value_function loss: 66.2839
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 49.5177
                       Mean reward: 680.56
               Mean episode length: 231.15
    Episode_Reward/reaching_object: 1.0523
    Episode_Reward/rotating_object: 139.9224
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 1.90s
                      Time elapsed: 00:26:55
                               ETA: 00:28:17

################################################################################
                     [1m Learning iteration 732/1500 [0m                      

                       Computation: 50129 steps/s (collection: 1.865s, learning 0.096s)
             Mean action noise std: 2.38
          Mean value_function loss: 71.7093
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 49.5469
                       Mean reward: 701.45
               Mean episode length: 236.18
    Episode_Reward/reaching_object: 1.0447
    Episode_Reward/rotating_object: 138.1570
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 1.96s
                      Time elapsed: 00:26:57
                               ETA: 00:28:14

################################################################################
                     [1m Learning iteration 733/1500 [0m                      

                       Computation: 52202 steps/s (collection: 1.790s, learning 0.093s)
             Mean action noise std: 2.39
          Mean value_function loss: 62.8139
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 49.5753
                       Mean reward: 717.46
               Mean episode length: 240.90
    Episode_Reward/reaching_object: 1.0432
    Episode_Reward/rotating_object: 140.6391
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 1.88s
                      Time elapsed: 00:26:59
                               ETA: 00:28:12

################################################################################
                     [1m Learning iteration 734/1500 [0m                      

                       Computation: 50574 steps/s (collection: 1.850s, learning 0.094s)
             Mean action noise std: 2.39
          Mean value_function loss: 83.0577
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 49.5953
                       Mean reward: 669.93
               Mean episode length: 235.62
    Episode_Reward/reaching_object: 1.0376
    Episode_Reward/rotating_object: 138.5340
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 1.94s
                      Time elapsed: 00:27:01
                               ETA: 00:28:09

################################################################################
                     [1m Learning iteration 735/1500 [0m                      

                       Computation: 52075 steps/s (collection: 1.793s, learning 0.095s)
             Mean action noise std: 2.39
          Mean value_function loss: 74.9833
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 49.6163
                       Mean reward: 699.15
               Mean episode length: 237.07
    Episode_Reward/reaching_object: 1.0313
    Episode_Reward/rotating_object: 137.5163
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 1.89s
                      Time elapsed: 00:27:03
                               ETA: 00:28:07

################################################################################
                     [1m Learning iteration 736/1500 [0m                      

                       Computation: 49810 steps/s (collection: 1.809s, learning 0.165s)
             Mean action noise std: 2.39
          Mean value_function loss: 62.5100
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 49.6348
                       Mean reward: 711.95
               Mean episode length: 241.30
    Episode_Reward/reaching_object: 1.0316
    Episode_Reward/rotating_object: 138.0271
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 1.97s
                      Time elapsed: 00:27:05
                               ETA: 00:28:04

################################################################################
                     [1m Learning iteration 737/1500 [0m                      

                       Computation: 50507 steps/s (collection: 1.789s, learning 0.157s)
             Mean action noise std: 2.40
          Mean value_function loss: 69.0465
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 49.6482
                       Mean reward: 720.61
               Mean episode length: 241.99
    Episode_Reward/reaching_object: 1.0605
    Episode_Reward/rotating_object: 143.9847
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 1.95s
                      Time elapsed: 00:27:07
                               ETA: 00:28:02

################################################################################
                     [1m Learning iteration 738/1500 [0m                      

                       Computation: 52329 steps/s (collection: 1.787s, learning 0.091s)
             Mean action noise std: 2.40
          Mean value_function loss: 58.7256
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 49.6571
                       Mean reward: 713.93
               Mean episode length: 244.27
    Episode_Reward/reaching_object: 1.0581
    Episode_Reward/rotating_object: 141.5818
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 1.88s
                      Time elapsed: 00:27:09
                               ETA: 00:27:59

################################################################################
                     [1m Learning iteration 739/1500 [0m                      

                       Computation: 51823 steps/s (collection: 1.777s, learning 0.120s)
             Mean action noise std: 2.40
          Mean value_function loss: 59.3847
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 49.6705
                       Mean reward: 707.47
               Mean episode length: 245.02
    Episode_Reward/reaching_object: 1.0640
    Episode_Reward/rotating_object: 141.3749
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 1.90s
                      Time elapsed: 00:27:10
                               ETA: 00:27:57

################################################################################
                     [1m Learning iteration 740/1500 [0m                      

                       Computation: 52310 steps/s (collection: 1.791s, learning 0.088s)
             Mean action noise std: 2.40
          Mean value_function loss: 59.8061
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 49.6972
                       Mean reward: 701.56
               Mean episode length: 239.02
    Episode_Reward/reaching_object: 1.0544
    Episode_Reward/rotating_object: 139.3968
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 1.88s
                      Time elapsed: 00:27:12
                               ETA: 00:27:54

################################################################################
                     [1m Learning iteration 741/1500 [0m                      

                       Computation: 52506 steps/s (collection: 1.771s, learning 0.101s)
             Mean action noise std: 2.40
          Mean value_function loss: 52.7101
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 49.7205
                       Mean reward: 694.40
               Mean episode length: 237.89
    Episode_Reward/reaching_object: 1.0751
    Episode_Reward/rotating_object: 142.2725
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 1.87s
                      Time elapsed: 00:27:14
                               ETA: 00:27:52

################################################################################
                     [1m Learning iteration 742/1500 [0m                      

                       Computation: 51726 steps/s (collection: 1.783s, learning 0.118s)
             Mean action noise std: 2.41
          Mean value_function loss: 67.1709
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 49.7445
                       Mean reward: 710.11
               Mean episode length: 235.46
    Episode_Reward/reaching_object: 1.0469
    Episode_Reward/rotating_object: 141.7598
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 1.90s
                      Time elapsed: 00:27:16
                               ETA: 00:27:49

################################################################################
                     [1m Learning iteration 743/1500 [0m                      

                       Computation: 52662 steps/s (collection: 1.764s, learning 0.103s)
             Mean action noise std: 2.41
          Mean value_function loss: 60.8712
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 49.7771
                       Mean reward: 702.46
               Mean episode length: 242.02
    Episode_Reward/reaching_object: 1.0634
    Episode_Reward/rotating_object: 140.0338
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 1.87s
                      Time elapsed: 00:27:18
                               ETA: 00:27:47

################################################################################
                     [1m Learning iteration 744/1500 [0m                      

                       Computation: 52101 steps/s (collection: 1.794s, learning 0.093s)
             Mean action noise std: 2.42
          Mean value_function loss: 64.1632
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 49.8112
                       Mean reward: 705.97
               Mean episode length: 231.50
    Episode_Reward/reaching_object: 1.0557
    Episode_Reward/rotating_object: 140.4977
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 1.89s
                      Time elapsed: 00:27:20
                               ETA: 00:27:44

################################################################################
                     [1m Learning iteration 745/1500 [0m                      

                       Computation: 52414 steps/s (collection: 1.780s, learning 0.096s)
             Mean action noise std: 2.42
          Mean value_function loss: 56.6378
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 49.8335
                       Mean reward: 715.14
               Mean episode length: 239.64
    Episode_Reward/reaching_object: 1.0615
    Episode_Reward/rotating_object: 140.6114
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 1.88s
                      Time elapsed: 00:27:22
                               ETA: 00:27:42

################################################################################
                     [1m Learning iteration 746/1500 [0m                      

                       Computation: 48378 steps/s (collection: 1.866s, learning 0.166s)
             Mean action noise std: 2.42
          Mean value_function loss: 59.4403
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 49.8489
                       Mean reward: 713.03
               Mean episode length: 242.13
    Episode_Reward/reaching_object: 1.0661
    Episode_Reward/rotating_object: 140.1078
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 2.03s
                      Time elapsed: 00:27:24
                               ETA: 00:27:39

################################################################################
                     [1m Learning iteration 747/1500 [0m                      

                       Computation: 49566 steps/s (collection: 1.851s, learning 0.132s)
             Mean action noise std: 2.42
          Mean value_function loss: 58.5805
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 49.8684
                       Mean reward: 709.37
               Mean episode length: 246.24
    Episode_Reward/reaching_object: 1.0652
    Episode_Reward/rotating_object: 141.0167
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 1.98s
                      Time elapsed: 00:27:26
                               ETA: 00:27:37

################################################################################
                     [1m Learning iteration 748/1500 [0m                      

                       Computation: 48772 steps/s (collection: 1.863s, learning 0.152s)
             Mean action noise std: 2.43
          Mean value_function loss: 55.5366
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 49.8929
                       Mean reward: 725.81
               Mean episode length: 241.72
    Episode_Reward/reaching_object: 1.0645
    Episode_Reward/rotating_object: 141.7450
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 2.02s
                      Time elapsed: 00:27:28
                               ETA: 00:27:34

################################################################################
                     [1m Learning iteration 749/1500 [0m                      

                       Computation: 51694 steps/s (collection: 1.775s, learning 0.127s)
             Mean action noise std: 2.43
          Mean value_function loss: 62.8631
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 49.9169
                       Mean reward: 720.14
               Mean episode length: 239.25
    Episode_Reward/reaching_object: 1.0639
    Episode_Reward/rotating_object: 141.5504
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 1.90s
                      Time elapsed: 00:27:30
                               ETA: 00:27:32

################################################################################
                     [1m Learning iteration 750/1500 [0m                      

                       Computation: 52098 steps/s (collection: 1.773s, learning 0.114s)
             Mean action noise std: 2.43
          Mean value_function loss: 77.2625
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 49.9378
                       Mean reward: 734.36
               Mean episode length: 244.50
    Episode_Reward/reaching_object: 1.0435
    Episode_Reward/rotating_object: 138.9617
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 1.89s
                      Time elapsed: 00:27:32
                               ETA: 00:27:29

################################################################################
                     [1m Learning iteration 751/1500 [0m                      

                       Computation: 50902 steps/s (collection: 1.835s, learning 0.096s)
             Mean action noise std: 2.44
          Mean value_function loss: 60.3847
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 49.9710
                       Mean reward: 698.00
               Mean episode length: 239.15
    Episode_Reward/reaching_object: 1.0615
    Episode_Reward/rotating_object: 141.2093
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 1.93s
                      Time elapsed: 00:27:34
                               ETA: 00:27:27

################################################################################
                     [1m Learning iteration 752/1500 [0m                      

                       Computation: 52449 steps/s (collection: 1.769s, learning 0.106s)
             Mean action noise std: 2.44
          Mean value_function loss: 67.5397
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 50.0018
                       Mean reward: 704.06
               Mean episode length: 237.67
    Episode_Reward/reaching_object: 1.0474
    Episode_Reward/rotating_object: 138.2671
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 1.87s
                      Time elapsed: 00:27:35
                               ETA: 00:27:24

################################################################################
                     [1m Learning iteration 753/1500 [0m                      

                       Computation: 51825 steps/s (collection: 1.794s, learning 0.103s)
             Mean action noise std: 2.44
          Mean value_function loss: 64.6909
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 50.0200
                       Mean reward: 698.86
               Mean episode length: 236.08
    Episode_Reward/reaching_object: 1.0529
    Episode_Reward/rotating_object: 139.8719
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 1.90s
                      Time elapsed: 00:27:37
                               ETA: 00:27:22

################################################################################
                     [1m Learning iteration 754/1500 [0m                      

                       Computation: 53312 steps/s (collection: 1.752s, learning 0.092s)
             Mean action noise std: 2.44
          Mean value_function loss: 68.6570
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 50.0452
                       Mean reward: 704.52
               Mean episode length: 244.02
    Episode_Reward/reaching_object: 1.0632
    Episode_Reward/rotating_object: 141.1582
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 1.84s
                      Time elapsed: 00:27:39
                               ETA: 00:27:19

################################################################################
                     [1m Learning iteration 755/1500 [0m                      

                       Computation: 51985 steps/s (collection: 1.773s, learning 0.118s)
             Mean action noise std: 2.45
          Mean value_function loss: 64.9449
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 50.0682
                       Mean reward: 715.69
               Mean episode length: 239.84
    Episode_Reward/reaching_object: 1.0558
    Episode_Reward/rotating_object: 142.8282
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 1.89s
                      Time elapsed: 00:27:41
                               ETA: 00:27:17

################################################################################
                     [1m Learning iteration 756/1500 [0m                      

                       Computation: 52411 steps/s (collection: 1.773s, learning 0.103s)
             Mean action noise std: 2.45
          Mean value_function loss: 65.3583
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 50.0866
                       Mean reward: 713.51
               Mean episode length: 240.07
    Episode_Reward/reaching_object: 1.0487
    Episode_Reward/rotating_object: 139.7755
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 1.88s
                      Time elapsed: 00:27:43
                               ETA: 00:27:14

################################################################################
                     [1m Learning iteration 757/1500 [0m                      

                       Computation: 49715 steps/s (collection: 1.818s, learning 0.159s)
             Mean action noise std: 2.45
          Mean value_function loss: 62.1250
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 50.1055
                       Mean reward: 708.46
               Mean episode length: 238.25
    Episode_Reward/reaching_object: 1.0527
    Episode_Reward/rotating_object: 140.5161
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 1.98s
                      Time elapsed: 00:27:45
                               ETA: 00:27:12

################################################################################
                     [1m Learning iteration 758/1500 [0m                      

                       Computation: 49562 steps/s (collection: 1.851s, learning 0.132s)
             Mean action noise std: 2.45
          Mean value_function loss: 49.2261
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 50.1227
                       Mean reward: 714.13
               Mean episode length: 241.88
    Episode_Reward/reaching_object: 1.0712
    Episode_Reward/rotating_object: 143.9980
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 1.98s
                      Time elapsed: 00:27:47
                               ETA: 00:27:10

################################################################################
                     [1m Learning iteration 759/1500 [0m                      

                       Computation: 51621 steps/s (collection: 1.787s, learning 0.117s)
             Mean action noise std: 2.45
          Mean value_function loss: 69.2601
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 50.1367
                       Mean reward: 686.61
               Mean episode length: 241.06
    Episode_Reward/reaching_object: 1.0533
    Episode_Reward/rotating_object: 138.7205
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 1.90s
                      Time elapsed: 00:27:49
                               ETA: 00:27:07

################################################################################
                     [1m Learning iteration 760/1500 [0m                      

                       Computation: 50540 steps/s (collection: 1.798s, learning 0.147s)
             Mean action noise std: 2.46
          Mean value_function loss: 71.8025
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 50.1514
                       Mean reward: 676.95
               Mean episode length: 235.03
    Episode_Reward/reaching_object: 1.0299
    Episode_Reward/rotating_object: 134.1121
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 1.95s
                      Time elapsed: 00:27:51
                               ETA: 00:27:05

################################################################################
                     [1m Learning iteration 761/1500 [0m                      

                       Computation: 49733 steps/s (collection: 1.810s, learning 0.167s)
             Mean action noise std: 2.46
          Mean value_function loss: 64.0761
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 50.1608
                       Mean reward: 697.72
               Mean episode length: 237.65
    Episode_Reward/reaching_object: 1.0580
    Episode_Reward/rotating_object: 142.8855
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 1.98s
                      Time elapsed: 00:27:53
                               ETA: 00:27:02

################################################################################
                     [1m Learning iteration 762/1500 [0m                      

                       Computation: 51059 steps/s (collection: 1.811s, learning 0.114s)
             Mean action noise std: 2.46
          Mean value_function loss: 77.7658
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 50.1825
                       Mean reward: 728.68
               Mean episode length: 241.91
    Episode_Reward/reaching_object: 1.0517
    Episode_Reward/rotating_object: 142.9780
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 1.93s
                      Time elapsed: 00:27:55
                               ETA: 00:27:00

################################################################################
                     [1m Learning iteration 763/1500 [0m                      

                       Computation: 50560 steps/s (collection: 1.842s, learning 0.102s)
             Mean action noise std: 2.46
          Mean value_function loss: 62.2624
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 50.2054
                       Mean reward: 696.23
               Mean episode length: 236.08
    Episode_Reward/reaching_object: 1.0481
    Episode_Reward/rotating_object: 139.6792
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 1.94s
                      Time elapsed: 00:27:57
                               ETA: 00:26:57

################################################################################
                     [1m Learning iteration 764/1500 [0m                      

                       Computation: 49066 steps/s (collection: 1.856s, learning 0.148s)
             Mean action noise std: 2.47
          Mean value_function loss: 77.9576
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 50.2320
                       Mean reward: 707.38
               Mean episode length: 236.09
    Episode_Reward/reaching_object: 1.0486
    Episode_Reward/rotating_object: 142.0105
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 2.00s
                      Time elapsed: 00:27:59
                               ETA: 00:26:55

################################################################################
                     [1m Learning iteration 765/1500 [0m                      

                       Computation: 50230 steps/s (collection: 1.841s, learning 0.116s)
             Mean action noise std: 2.47
          Mean value_function loss: 70.1661
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.2599
                       Mean reward: 694.92
               Mean episode length: 233.03
    Episode_Reward/reaching_object: 1.0573
    Episode_Reward/rotating_object: 141.2450
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 1.96s
                      Time elapsed: 00:28:01
                               ETA: 00:26:52

################################################################################
                     [1m Learning iteration 766/1500 [0m                      

                       Computation: 49735 steps/s (collection: 1.859s, learning 0.118s)
             Mean action noise std: 2.47
          Mean value_function loss: 65.9798
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 50.2894
                       Mean reward: 711.29
               Mean episode length: 239.74
    Episode_Reward/reaching_object: 1.0408
    Episode_Reward/rotating_object: 137.8218
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 1.98s
                      Time elapsed: 00:28:02
                               ETA: 00:26:50

################################################################################
                     [1m Learning iteration 767/1500 [0m                      

                       Computation: 49658 steps/s (collection: 1.875s, learning 0.105s)
             Mean action noise std: 2.47
          Mean value_function loss: 61.5225
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 50.3108
                       Mean reward: 718.40
               Mean episode length: 241.99
    Episode_Reward/reaching_object: 1.0545
    Episode_Reward/rotating_object: 141.8224
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 1.98s
                      Time elapsed: 00:28:04
                               ETA: 00:26:48

################################################################################
                     [1m Learning iteration 768/1500 [0m                      

                       Computation: 49254 steps/s (collection: 1.882s, learning 0.114s)
             Mean action noise std: 2.48
          Mean value_function loss: 65.5774
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 50.3308
                       Mean reward: 678.49
               Mean episode length: 239.97
    Episode_Reward/reaching_object: 1.0688
    Episode_Reward/rotating_object: 141.5337
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 2.00s
                      Time elapsed: 00:28:06
                               ETA: 00:26:45

################################################################################
                     [1m Learning iteration 769/1500 [0m                      

                       Computation: 49839 steps/s (collection: 1.858s, learning 0.115s)
             Mean action noise std: 2.48
          Mean value_function loss: 60.1487
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 50.3544
                       Mean reward: 696.87
               Mean episode length: 236.97
    Episode_Reward/reaching_object: 1.0540
    Episode_Reward/rotating_object: 140.4852
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 1.97s
                      Time elapsed: 00:28:08
                               ETA: 00:26:43

################################################################################
                     [1m Learning iteration 770/1500 [0m                      

                       Computation: 51710 steps/s (collection: 1.760s, learning 0.141s)
             Mean action noise std: 2.48
          Mean value_function loss: 63.4082
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.3827
                       Mean reward: 710.87
               Mean episode length: 235.91
    Episode_Reward/reaching_object: 1.0531
    Episode_Reward/rotating_object: 139.9297
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 1.90s
                      Time elapsed: 00:28:10
                               ETA: 00:26:40

################################################################################
                     [1m Learning iteration 771/1500 [0m                      

                       Computation: 51823 steps/s (collection: 1.801s, learning 0.096s)
             Mean action noise std: 2.49
          Mean value_function loss: 59.7706
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 50.4067
                       Mean reward: 712.10
               Mean episode length: 241.32
    Episode_Reward/reaching_object: 1.0538
    Episode_Reward/rotating_object: 141.6898
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 1.90s
                      Time elapsed: 00:28:12
                               ETA: 00:26:38

################################################################################
                     [1m Learning iteration 772/1500 [0m                      

                       Computation: 49494 steps/s (collection: 1.848s, learning 0.139s)
             Mean action noise std: 2.49
          Mean value_function loss: 63.0976
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 50.4210
                       Mean reward: 716.48
               Mean episode length: 240.33
    Episode_Reward/reaching_object: 1.0545
    Episode_Reward/rotating_object: 139.7781
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 1.99s
                      Time elapsed: 00:28:14
                               ETA: 00:26:36

################################################################################
                     [1m Learning iteration 773/1500 [0m                      

                       Computation: 48199 steps/s (collection: 1.905s, learning 0.135s)
             Mean action noise std: 2.49
          Mean value_function loss: 63.9857
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 50.4335
                       Mean reward: 693.45
               Mean episode length: 240.14
    Episode_Reward/reaching_object: 1.0510
    Episode_Reward/rotating_object: 137.3361
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 2.04s
                      Time elapsed: 00:28:16
                               ETA: 00:26:33

################################################################################
                     [1m Learning iteration 774/1500 [0m                      

                       Computation: 46229 steps/s (collection: 1.937s, learning 0.189s)
             Mean action noise std: 2.49
          Mean value_function loss: 88.0722
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 50.4548
                       Mean reward: 696.15
               Mean episode length: 233.39
    Episode_Reward/reaching_object: 1.0404
    Episode_Reward/rotating_object: 135.0167
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 2.13s
                      Time elapsed: 00:28:18
                               ETA: 00:26:31

################################################################################
                     [1m Learning iteration 775/1500 [0m                      

                       Computation: 38372 steps/s (collection: 2.338s, learning 0.224s)
             Mean action noise std: 2.49
          Mean value_function loss: 62.5010
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.4824
                       Mean reward: 706.23
               Mean episode length: 240.07
    Episode_Reward/reaching_object: 1.0488
    Episode_Reward/rotating_object: 139.4654
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 2.56s
                      Time elapsed: 00:28:21
                               ETA: 00:26:29

################################################################################
                     [1m Learning iteration 776/1500 [0m                      

                       Computation: 48340 steps/s (collection: 1.898s, learning 0.135s)
             Mean action noise std: 2.50
          Mean value_function loss: 49.2424
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 50.5043
                       Mean reward: 683.87
               Mean episode length: 239.50
    Episode_Reward/reaching_object: 1.0695
    Episode_Reward/rotating_object: 142.6813
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 2.03s
                      Time elapsed: 00:28:23
                               ETA: 00:26:27

################################################################################
                     [1m Learning iteration 777/1500 [0m                      

                       Computation: 46900 steps/s (collection: 1.972s, learning 0.124s)
             Mean action noise std: 2.50
          Mean value_function loss: 66.2262
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.5182
                       Mean reward: 680.70
               Mean episode length: 235.34
    Episode_Reward/reaching_object: 1.0678
    Episode_Reward/rotating_object: 141.6961
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 2.10s
                      Time elapsed: 00:28:25
                               ETA: 00:26:25

################################################################################
                     [1m Learning iteration 778/1500 [0m                      

                       Computation: 44190 steps/s (collection: 2.122s, learning 0.102s)
             Mean action noise std: 2.50
          Mean value_function loss: 65.3781
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 50.5363
                       Mean reward: 726.27
               Mean episode length: 240.37
    Episode_Reward/reaching_object: 1.0600
    Episode_Reward/rotating_object: 142.4322
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 2.22s
                      Time elapsed: 00:28:27
                               ETA: 00:26:22

################################################################################
                     [1m Learning iteration 779/1500 [0m                      

                       Computation: 47411 steps/s (collection: 1.891s, learning 0.183s)
             Mean action noise std: 2.50
          Mean value_function loss: 66.0622
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 50.5504
                       Mean reward: 744.60
               Mean episode length: 245.96
    Episode_Reward/reaching_object: 1.0643
    Episode_Reward/rotating_object: 140.0557
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 2.07s
                      Time elapsed: 00:28:29
                               ETA: 00:26:20

################################################################################
                     [1m Learning iteration 780/1500 [0m                      

                       Computation: 30751 steps/s (collection: 2.930s, learning 0.267s)
             Mean action noise std: 2.51
          Mean value_function loss: 70.7743
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 50.5690
                       Mean reward: 738.04
               Mean episode length: 243.90
    Episode_Reward/reaching_object: 1.0620
    Episode_Reward/rotating_object: 142.7930
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 3.20s
                      Time elapsed: 00:28:33
                               ETA: 00:26:19

################################################################################
                     [1m Learning iteration 781/1500 [0m                      

                       Computation: 38889 steps/s (collection: 2.381s, learning 0.147s)
             Mean action noise std: 2.51
          Mean value_function loss: 57.0413
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 50.5789
                       Mean reward: 700.38
               Mean episode length: 235.50
    Episode_Reward/reaching_object: 1.0450
    Episode_Reward/rotating_object: 140.1218
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 2.53s
                      Time elapsed: 00:28:35
                               ETA: 00:26:17

################################################################################
                     [1m Learning iteration 782/1500 [0m                      

                       Computation: 39285 steps/s (collection: 2.275s, learning 0.227s)
             Mean action noise std: 2.51
          Mean value_function loss: 62.5392
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 50.5896
                       Mean reward: 704.34
               Mean episode length: 243.45
    Episode_Reward/reaching_object: 1.0716
    Episode_Reward/rotating_object: 141.3549
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 2.50s
                      Time elapsed: 00:28:38
                               ETA: 00:26:15

################################################################################
                     [1m Learning iteration 783/1500 [0m                      

                       Computation: 40677 steps/s (collection: 2.218s, learning 0.199s)
             Mean action noise std: 2.51
          Mean value_function loss: 62.5275
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 50.6101
                       Mean reward: 698.61
               Mean episode length: 241.67
    Episode_Reward/reaching_object: 1.0588
    Episode_Reward/rotating_object: 139.4890
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 2.42s
                      Time elapsed: 00:28:40
                               ETA: 00:26:13

################################################################################
                     [1m Learning iteration 784/1500 [0m                      

                       Computation: 42746 steps/s (collection: 2.177s, learning 0.123s)
             Mean action noise std: 2.52
          Mean value_function loss: 59.0772
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.6377
                       Mean reward: 717.60
               Mean episode length: 243.21
    Episode_Reward/reaching_object: 1.0686
    Episode_Reward/rotating_object: 143.5453
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 2.30s
                      Time elapsed: 00:28:42
                               ETA: 00:26:11

################################################################################
                     [1m Learning iteration 785/1500 [0m                      

                       Computation: 40769 steps/s (collection: 2.199s, learning 0.212s)
             Mean action noise std: 2.52
          Mean value_function loss: 77.0162
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 50.6599
                       Mean reward: 700.82
               Mean episode length: 233.00
    Episode_Reward/reaching_object: 1.0436
    Episode_Reward/rotating_object: 139.8279
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 2.41s
                      Time elapsed: 00:28:45
                               ETA: 00:26:09

################################################################################
                     [1m Learning iteration 786/1500 [0m                      

                       Computation: 42187 steps/s (collection: 2.145s, learning 0.185s)
             Mean action noise std: 2.52
          Mean value_function loss: 83.3096
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 50.6958
                       Mean reward: 711.93
               Mean episode length: 242.59
    Episode_Reward/reaching_object: 1.0630
    Episode_Reward/rotating_object: 141.2414
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 2.33s
                      Time elapsed: 00:28:47
                               ETA: 00:26:07

################################################################################
                     [1m Learning iteration 787/1500 [0m                      

                       Computation: 44556 steps/s (collection: 2.048s, learning 0.158s)
             Mean action noise std: 2.53
          Mean value_function loss: 64.6054
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 50.7323
                       Mean reward: 676.54
               Mean episode length: 236.32
    Episode_Reward/reaching_object: 1.0331
    Episode_Reward/rotating_object: 136.0234
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 2.21s
                      Time elapsed: 00:28:49
                               ETA: 00:26:05

################################################################################
                     [1m Learning iteration 788/1500 [0m                      

                       Computation: 44652 steps/s (collection: 2.103s, learning 0.098s)
             Mean action noise std: 2.53
          Mean value_function loss: 67.0736
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 50.7546
                       Mean reward: 693.63
               Mean episode length: 241.21
    Episode_Reward/reaching_object: 1.0604
    Episode_Reward/rotating_object: 139.7004
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 2.20s
                      Time elapsed: 00:28:51
                               ETA: 00:26:02

################################################################################
                     [1m Learning iteration 789/1500 [0m                      

                       Computation: 45503 steps/s (collection: 2.000s, learning 0.160s)
             Mean action noise std: 2.53
          Mean value_function loss: 63.8867
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.7779
                       Mean reward: 710.39
               Mean episode length: 245.95
    Episode_Reward/reaching_object: 1.0598
    Episode_Reward/rotating_object: 139.0561
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 2.16s
                      Time elapsed: 00:28:54
                               ETA: 00:26:00

################################################################################
                     [1m Learning iteration 790/1500 [0m                      

                       Computation: 47927 steps/s (collection: 1.949s, learning 0.103s)
             Mean action noise std: 2.53
          Mean value_function loss: 69.3995
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.8032
                       Mean reward: 707.25
               Mean episode length: 235.93
    Episode_Reward/reaching_object: 1.0591
    Episode_Reward/rotating_object: 140.6255
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 2.05s
                      Time elapsed: 00:28:56
                               ETA: 00:25:58

################################################################################
                     [1m Learning iteration 791/1500 [0m                      

                       Computation: 48132 steps/s (collection: 1.949s, learning 0.094s)
             Mean action noise std: 2.54
          Mean value_function loss: 67.3722
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 50.8232
                       Mean reward: 668.42
               Mean episode length: 236.39
    Episode_Reward/reaching_object: 1.0661
    Episode_Reward/rotating_object: 139.4885
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 2.04s
                      Time elapsed: 00:28:58
                               ETA: 00:25:56

################################################################################
                     [1m Learning iteration 792/1500 [0m                      

                       Computation: 51058 steps/s (collection: 1.828s, learning 0.098s)
             Mean action noise std: 2.54
          Mean value_function loss: 65.2334
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 50.8445
                       Mean reward: 684.27
               Mean episode length: 241.56
    Episode_Reward/reaching_object: 1.0561
    Episode_Reward/rotating_object: 136.8827
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 1.93s
                      Time elapsed: 00:29:00
                               ETA: 00:25:53

################################################################################
                     [1m Learning iteration 793/1500 [0m                      

                       Computation: 48329 steps/s (collection: 1.899s, learning 0.135s)
             Mean action noise std: 2.54
          Mean value_function loss: 76.3726
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 50.8714
                       Mean reward: 680.95
               Mean episode length: 235.71
    Episode_Reward/reaching_object: 1.0471
    Episode_Reward/rotating_object: 136.6372
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 2.03s
                      Time elapsed: 00:29:02
                               ETA: 00:25:51

################################################################################
                     [1m Learning iteration 794/1500 [0m                      

                       Computation: 44704 steps/s (collection: 2.050s, learning 0.149s)
             Mean action noise std: 2.55
          Mean value_function loss: 57.8613
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 50.8904
                       Mean reward: 710.43
               Mean episode length: 243.39
    Episode_Reward/reaching_object: 1.0502
    Episode_Reward/rotating_object: 137.4892
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 2.20s
                      Time elapsed: 00:29:04
                               ETA: 00:25:49

################################################################################
                     [1m Learning iteration 795/1500 [0m                      

                       Computation: 46607 steps/s (collection: 1.970s, learning 0.139s)
             Mean action noise std: 2.55
          Mean value_function loss: 72.7955
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 50.9185
                       Mean reward: 723.25
               Mean episode length: 243.51
    Episode_Reward/reaching_object: 1.0835
    Episode_Reward/rotating_object: 142.7077
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 2.11s
                      Time elapsed: 00:29:06
                               ETA: 00:25:46

################################################################################
                     [1m Learning iteration 796/1500 [0m                      

                       Computation: 47982 steps/s (collection: 1.890s, learning 0.159s)
             Mean action noise std: 2.55
          Mean value_function loss: 69.9355
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 50.9510
                       Mean reward: 695.57
               Mean episode length: 236.16
    Episode_Reward/reaching_object: 1.0594
    Episode_Reward/rotating_object: 139.2361
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 2.05s
                      Time elapsed: 00:29:08
                               ETA: 00:25:44

################################################################################
                     [1m Learning iteration 797/1500 [0m                      

                       Computation: 46927 steps/s (collection: 1.968s, learning 0.127s)
             Mean action noise std: 2.56
          Mean value_function loss: 67.7367
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 50.9857
                       Mean reward: 700.09
               Mean episode length: 238.81
    Episode_Reward/reaching_object: 1.0702
    Episode_Reward/rotating_object: 137.3065
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 2.09s
                      Time elapsed: 00:29:10
                               ETA: 00:25:42

################################################################################
                     [1m Learning iteration 798/1500 [0m                      

                       Computation: 50302 steps/s (collection: 1.862s, learning 0.092s)
             Mean action noise std: 2.56
          Mean value_function loss: 63.5010
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 51.0153
                       Mean reward: 688.61
               Mean episode length: 235.24
    Episode_Reward/reaching_object: 1.0618
    Episode_Reward/rotating_object: 138.7123
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 1.95s
                      Time elapsed: 00:29:12
                               ETA: 00:25:39

################################################################################
                     [1m Learning iteration 799/1500 [0m                      

                       Computation: 49862 steps/s (collection: 1.844s, learning 0.127s)
             Mean action noise std: 2.56
          Mean value_function loss: 79.0705
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 51.0317
                       Mean reward: 660.05
               Mean episode length: 227.18
    Episode_Reward/reaching_object: 1.0600
    Episode_Reward/rotating_object: 138.9877
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 1.97s
                      Time elapsed: 00:29:14
                               ETA: 00:25:37

################################################################################
                     [1m Learning iteration 800/1500 [0m                      

                       Computation: 50423 steps/s (collection: 1.793s, learning 0.157s)
             Mean action noise std: 2.56
          Mean value_function loss: 63.7254
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 51.0494
                       Mean reward: 724.02
               Mean episode length: 246.13
    Episode_Reward/reaching_object: 1.0547
    Episode_Reward/rotating_object: 138.1188
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 1.95s
                      Time elapsed: 00:29:16
                               ETA: 00:25:35

################################################################################
                     [1m Learning iteration 801/1500 [0m                      

                       Computation: 47577 steps/s (collection: 1.864s, learning 0.202s)
             Mean action noise std: 2.57
          Mean value_function loss: 73.1849
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 51.0715
                       Mean reward: 718.18
               Mean episode length: 237.99
    Episode_Reward/reaching_object: 1.0658
    Episode_Reward/rotating_object: 143.1372
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 2.07s
                      Time elapsed: 00:29:18
                               ETA: 00:25:32

################################################################################
                     [1m Learning iteration 802/1500 [0m                      

                       Computation: 47293 steps/s (collection: 1.949s, learning 0.130s)
             Mean action noise std: 2.57
          Mean value_function loss: 69.3448
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 51.0956
                       Mean reward: 638.06
               Mean episode length: 230.16
    Episode_Reward/reaching_object: 1.0452
    Episode_Reward/rotating_object: 136.8200
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 2.08s
                      Time elapsed: 00:29:20
                               ETA: 00:25:30

################################################################################
                     [1m Learning iteration 803/1500 [0m                      

                       Computation: 50677 steps/s (collection: 1.828s, learning 0.112s)
             Mean action noise std: 2.57
          Mean value_function loss: 66.3266
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 51.1201
                       Mean reward: 728.04
               Mean episode length: 242.11
    Episode_Reward/reaching_object: 1.0690
    Episode_Reward/rotating_object: 139.2055
        Episode_Reward/action_rate: -0.0355
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 1.94s
                      Time elapsed: 00:29:22
                               ETA: 00:25:28

################################################################################
                     [1m Learning iteration 804/1500 [0m                      

                       Computation: 50752 steps/s (collection: 1.799s, learning 0.138s)
             Mean action noise std: 2.58
          Mean value_function loss: 76.8033
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 51.1565
                       Mean reward: 685.53
               Mean episode length: 241.07
    Episode_Reward/reaching_object: 1.0562
    Episode_Reward/rotating_object: 136.8578
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 1.94s
                      Time elapsed: 00:29:24
                               ETA: 00:25:25

################################################################################
                     [1m Learning iteration 805/1500 [0m                      

                       Computation: 48611 steps/s (collection: 1.859s, learning 0.164s)
             Mean action noise std: 2.58
          Mean value_function loss: 70.3397
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 51.1918
                       Mean reward: 684.32
               Mean episode length: 233.84
    Episode_Reward/reaching_object: 1.0495
    Episode_Reward/rotating_object: 135.9310
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 2.02s
                      Time elapsed: 00:29:26
                               ETA: 00:25:23

################################################################################
                     [1m Learning iteration 806/1500 [0m                      

                       Computation: 51115 steps/s (collection: 1.808s, learning 0.116s)
             Mean action noise std: 2.59
          Mean value_function loss: 71.7175
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 51.2196
                       Mean reward: 696.19
               Mean episode length: 236.85
    Episode_Reward/reaching_object: 1.0539
    Episode_Reward/rotating_object: 139.5919
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 1.92s
                      Time elapsed: 00:29:28
                               ETA: 00:25:20

################################################################################
                     [1m Learning iteration 807/1500 [0m                      

                       Computation: 51693 steps/s (collection: 1.794s, learning 0.107s)
             Mean action noise std: 2.59
          Mean value_function loss: 69.1648
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 51.2429
                       Mean reward: 721.69
               Mean episode length: 244.23
    Episode_Reward/reaching_object: 1.0527
    Episode_Reward/rotating_object: 141.1256
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 1.90s
                      Time elapsed: 00:29:30
                               ETA: 00:25:18

################################################################################
                     [1m Learning iteration 808/1500 [0m                      

                       Computation: 51570 steps/s (collection: 1.809s, learning 0.098s)
             Mean action noise std: 2.59
          Mean value_function loss: 64.7784
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 51.2590
                       Mean reward: 692.80
               Mean episode length: 237.78
    Episode_Reward/reaching_object: 1.0572
    Episode_Reward/rotating_object: 139.7263
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 1.91s
                      Time elapsed: 00:29:32
                               ETA: 00:25:15

################################################################################
                     [1m Learning iteration 809/1500 [0m                      

                       Computation: 49847 steps/s (collection: 1.856s, learning 0.117s)
             Mean action noise std: 2.59
          Mean value_function loss: 64.8954
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 51.2850
                       Mean reward: 697.20
               Mean episode length: 240.32
    Episode_Reward/reaching_object: 1.0422
    Episode_Reward/rotating_object: 135.5823
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 1.97s
                      Time elapsed: 00:29:34
                               ETA: 00:25:13

################################################################################
                     [1m Learning iteration 810/1500 [0m                      

                       Computation: 48709 steps/s (collection: 1.891s, learning 0.127s)
             Mean action noise std: 2.59
          Mean value_function loss: 74.4201
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 51.3018
                       Mean reward: 681.12
               Mean episode length: 237.76
    Episode_Reward/reaching_object: 1.0401
    Episode_Reward/rotating_object: 134.3136
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 2.02s
                      Time elapsed: 00:29:36
                               ETA: 00:25:11

################################################################################
                     [1m Learning iteration 811/1500 [0m                      

                       Computation: 48923 steps/s (collection: 1.894s, learning 0.115s)
             Mean action noise std: 2.60
          Mean value_function loss: 68.0325
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 51.3147
                       Mean reward: 704.63
               Mean episode length: 240.04
    Episode_Reward/reaching_object: 1.0528
    Episode_Reward/rotating_object: 139.7020
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 2.01s
                      Time elapsed: 00:29:38
                               ETA: 00:25:08

################################################################################
                     [1m Learning iteration 812/1500 [0m                      

                       Computation: 49165 steps/s (collection: 1.896s, learning 0.103s)
             Mean action noise std: 2.60
          Mean value_function loss: 72.8705
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 51.3404
                       Mean reward: 703.95
               Mean episode length: 241.18
    Episode_Reward/reaching_object: 1.0469
    Episode_Reward/rotating_object: 138.6135
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 2.00s
                      Time elapsed: 00:29:40
                               ETA: 00:25:06

################################################################################
                     [1m Learning iteration 813/1500 [0m                      

                       Computation: 48716 steps/s (collection: 1.921s, learning 0.097s)
             Mean action noise std: 2.61
          Mean value_function loss: 76.4795
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 51.3748
                       Mean reward: 710.74
               Mean episode length: 238.65
    Episode_Reward/reaching_object: 1.0531
    Episode_Reward/rotating_object: 135.4124
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 2.02s
                      Time elapsed: 00:29:42
                               ETA: 00:25:04

################################################################################
                     [1m Learning iteration 814/1500 [0m                      

                       Computation: 49077 steps/s (collection: 1.831s, learning 0.172s)
             Mean action noise std: 2.61
          Mean value_function loss: 65.4662
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 51.4084
                       Mean reward: 703.54
               Mean episode length: 234.91
    Episode_Reward/reaching_object: 1.0436
    Episode_Reward/rotating_object: 137.0106
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 2.00s
                      Time elapsed: 00:29:44
                               ETA: 00:25:01

################################################################################
                     [1m Learning iteration 815/1500 [0m                      

                       Computation: 51175 steps/s (collection: 1.830s, learning 0.091s)
             Mean action noise std: 2.61
          Mean value_function loss: 73.0802
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 51.4345
                       Mean reward: 724.36
               Mean episode length: 241.00
    Episode_Reward/reaching_object: 1.0674
    Episode_Reward/rotating_object: 140.3130
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 1.92s
                      Time elapsed: 00:29:46
                               ETA: 00:24:59

################################################################################
                     [1m Learning iteration 816/1500 [0m                      

                       Computation: 51938 steps/s (collection: 1.806s, learning 0.087s)
             Mean action noise std: 2.61
          Mean value_function loss: 73.2346
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 51.4598
                       Mean reward: 674.80
               Mean episode length: 236.44
    Episode_Reward/reaching_object: 1.0471
    Episode_Reward/rotating_object: 138.0392
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 1.89s
                      Time elapsed: 00:29:48
                               ETA: 00:24:57

################################################################################
                     [1m Learning iteration 817/1500 [0m                      

                       Computation: 51711 steps/s (collection: 1.810s, learning 0.092s)
             Mean action noise std: 2.62
          Mean value_function loss: 92.1503
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 51.4781
                       Mean reward: 684.36
               Mean episode length: 233.30
    Episode_Reward/reaching_object: 1.0592
    Episode_Reward/rotating_object: 139.6954
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 1.90s
                      Time elapsed: 00:29:50
                               ETA: 00:24:54

################################################################################
                     [1m Learning iteration 818/1500 [0m                      

                       Computation: 51181 steps/s (collection: 1.827s, learning 0.094s)
             Mean action noise std: 2.62
          Mean value_function loss: 68.5123
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 51.5113
                       Mean reward: 684.97
               Mean episode length: 236.29
    Episode_Reward/reaching_object: 1.0402
    Episode_Reward/rotating_object: 133.2745
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 1.92s
                      Time elapsed: 00:29:51
                               ETA: 00:24:52

################################################################################
                     [1m Learning iteration 819/1500 [0m                      

                       Computation: 51361 steps/s (collection: 1.812s, learning 0.102s)
             Mean action noise std: 2.62
          Mean value_function loss: 70.0683
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 51.5365
                       Mean reward: 672.61
               Mean episode length: 238.43
    Episode_Reward/reaching_object: 1.0633
    Episode_Reward/rotating_object: 139.6729
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 1.91s
                      Time elapsed: 00:29:53
                               ETA: 00:24:49

################################################################################
                     [1m Learning iteration 820/1500 [0m                      

                       Computation: 50736 steps/s (collection: 1.799s, learning 0.138s)
             Mean action noise std: 2.63
          Mean value_function loss: 88.3575
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 51.5598
                       Mean reward: 674.80
               Mean episode length: 231.55
    Episode_Reward/reaching_object: 1.0484
    Episode_Reward/rotating_object: 136.9722
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 1.94s
                      Time elapsed: 00:29:55
                               ETA: 00:24:47

################################################################################
                     [1m Learning iteration 821/1500 [0m                      

                       Computation: 51633 steps/s (collection: 1.778s, learning 0.126s)
             Mean action noise std: 2.63
          Mean value_function loss: 65.2659
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 51.5836
                       Mean reward: 727.12
               Mean episode length: 244.09
    Episode_Reward/reaching_object: 1.0572
    Episode_Reward/rotating_object: 138.5061
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 1.90s
                      Time elapsed: 00:29:57
                               ETA: 00:24:44

################################################################################
                     [1m Learning iteration 822/1500 [0m                      

                       Computation: 52258 steps/s (collection: 1.772s, learning 0.109s)
             Mean action noise std: 2.63
          Mean value_function loss: 79.5825
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 51.6013
                       Mean reward: 692.42
               Mean episode length: 240.71
    Episode_Reward/reaching_object: 1.0640
    Episode_Reward/rotating_object: 139.9252
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 1.88s
                      Time elapsed: 00:29:59
                               ETA: 00:24:42

################################################################################
                     [1m Learning iteration 823/1500 [0m                      

                       Computation: 51662 steps/s (collection: 1.806s, learning 0.097s)
             Mean action noise std: 2.63
          Mean value_function loss: 59.8267
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 51.6187
                       Mean reward: 718.90
               Mean episode length: 240.85
    Episode_Reward/reaching_object: 1.0469
    Episode_Reward/rotating_object: 137.9424
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 1.90s
                      Time elapsed: 00:30:01
                               ETA: 00:24:40

################################################################################
                     [1m Learning iteration 824/1500 [0m                      

                       Computation: 51916 steps/s (collection: 1.801s, learning 0.093s)
             Mean action noise std: 2.64
          Mean value_function loss: 61.0443
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 51.6400
                       Mean reward: 689.55
               Mean episode length: 240.04
    Episode_Reward/reaching_object: 1.0524
    Episode_Reward/rotating_object: 140.8505
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 1.89s
                      Time elapsed: 00:30:03
                               ETA: 00:24:37

################################################################################
                     [1m Learning iteration 825/1500 [0m                      

                       Computation: 51946 steps/s (collection: 1.794s, learning 0.099s)
             Mean action noise std: 2.64
          Mean value_function loss: 72.8220
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 51.6579
                       Mean reward: 696.89
               Mean episode length: 233.17
    Episode_Reward/reaching_object: 1.0349
    Episode_Reward/rotating_object: 136.2487
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 1.89s
                      Time elapsed: 00:30:05
                               ETA: 00:24:35

################################################################################
                     [1m Learning iteration 826/1500 [0m                      

                       Computation: 51250 steps/s (collection: 1.822s, learning 0.096s)
             Mean action noise std: 2.64
          Mean value_function loss: 66.3512
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 51.6692
                       Mean reward: 717.99
               Mean episode length: 240.43
    Episode_Reward/reaching_object: 1.0619
    Episode_Reward/rotating_object: 142.0388
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 1.92s
                      Time elapsed: 00:30:07
                               ETA: 00:24:32

################################################################################
                     [1m Learning iteration 827/1500 [0m                      

                       Computation: 50541 steps/s (collection: 1.852s, learning 0.094s)
             Mean action noise std: 2.64
          Mean value_function loss: 84.4223
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 51.6941
                       Mean reward: 708.82
               Mean episode length: 236.15
    Episode_Reward/reaching_object: 1.0287
    Episode_Reward/rotating_object: 136.6302
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 1.95s
                      Time elapsed: 00:30:09
                               ETA: 00:24:30

################################################################################
                     [1m Learning iteration 828/1500 [0m                      

                       Computation: 50949 steps/s (collection: 1.838s, learning 0.092s)
             Mean action noise std: 2.65
          Mean value_function loss: 79.6800
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 51.7241
                       Mean reward: 636.33
               Mean episode length: 225.21
    Episode_Reward/reaching_object: 1.0305
    Episode_Reward/rotating_object: 137.6953
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 1.93s
                      Time elapsed: 00:30:11
                               ETA: 00:24:28

################################################################################
                     [1m Learning iteration 829/1500 [0m                      

                       Computation: 51205 steps/s (collection: 1.830s, learning 0.090s)
             Mean action noise std: 2.65
          Mean value_function loss: 79.4129
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 51.7510
                       Mean reward: 692.45
               Mean episode length: 241.68
    Episode_Reward/reaching_object: 1.0374
    Episode_Reward/rotating_object: 137.8412
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 1.92s
                      Time elapsed: 00:30:12
                               ETA: 00:24:25

################################################################################
                     [1m Learning iteration 830/1500 [0m                      

                       Computation: 49682 steps/s (collection: 1.883s, learning 0.096s)
             Mean action noise std: 2.65
          Mean value_function loss: 58.9461
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 51.7781
                       Mean reward: 727.15
               Mean episode length: 239.89
    Episode_Reward/reaching_object: 1.0624
    Episode_Reward/rotating_object: 141.5527
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 1.98s
                      Time elapsed: 00:30:14
                               ETA: 00:24:23

################################################################################
                     [1m Learning iteration 831/1500 [0m                      

                       Computation: 51068 steps/s (collection: 1.811s, learning 0.114s)
             Mean action noise std: 2.66
          Mean value_function loss: 63.2746
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 51.7954
                       Mean reward: 699.75
               Mean episode length: 248.19
    Episode_Reward/reaching_object: 1.0617
    Episode_Reward/rotating_object: 138.8272
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 1.92s
                      Time elapsed: 00:30:16
                               ETA: 00:24:20

################################################################################
                     [1m Learning iteration 832/1500 [0m                      

                       Computation: 47450 steps/s (collection: 1.899s, learning 0.173s)
             Mean action noise std: 2.66
          Mean value_function loss: 57.1074
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 51.8164
                       Mean reward: 683.04
               Mean episode length: 235.55
    Episode_Reward/reaching_object: 1.0619
    Episode_Reward/rotating_object: 143.8051
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 2.07s
                      Time elapsed: 00:30:18
                               ETA: 00:24:18

################################################################################
                     [1m Learning iteration 833/1500 [0m                      

                       Computation: 50232 steps/s (collection: 1.855s, learning 0.102s)
             Mean action noise std: 2.66
          Mean value_function loss: 59.5897
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 51.8394
                       Mean reward: 723.72
               Mean episode length: 236.51
    Episode_Reward/reaching_object: 1.0562
    Episode_Reward/rotating_object: 141.8379
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 1.96s
                      Time elapsed: 00:30:20
                               ETA: 00:24:16

################################################################################
                     [1m Learning iteration 834/1500 [0m                      

                       Computation: 48937 steps/s (collection: 1.855s, learning 0.154s)
             Mean action noise std: 2.66
          Mean value_function loss: 75.0635
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 51.8504
                       Mean reward: 716.78
               Mean episode length: 238.75
    Episode_Reward/reaching_object: 1.0374
    Episode_Reward/rotating_object: 137.6080
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 2.01s
                      Time elapsed: 00:30:22
                               ETA: 00:24:13

################################################################################
                     [1m Learning iteration 835/1500 [0m                      

                       Computation: 50953 steps/s (collection: 1.835s, learning 0.094s)
             Mean action noise std: 2.67
          Mean value_function loss: 70.3363
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 51.8744
                       Mean reward: 704.27
               Mean episode length: 238.15
    Episode_Reward/reaching_object: 1.0538
    Episode_Reward/rotating_object: 140.8593
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 1.93s
                      Time elapsed: 00:30:24
                               ETA: 00:24:11

################################################################################
                     [1m Learning iteration 836/1500 [0m                      

                       Computation: 49326 steps/s (collection: 1.893s, learning 0.100s)
             Mean action noise std: 2.67
          Mean value_function loss: 68.6638
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 51.9060
                       Mean reward: 664.23
               Mean episode length: 242.08
    Episode_Reward/reaching_object: 1.0459
    Episode_Reward/rotating_object: 133.9704
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 1.99s
                      Time elapsed: 00:30:26
                               ETA: 00:24:09

################################################################################
                     [1m Learning iteration 837/1500 [0m                      

                       Computation: 48817 steps/s (collection: 1.867s, learning 0.147s)
             Mean action noise std: 2.67
          Mean value_function loss: 71.5533
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 51.9279
                       Mean reward: 702.75
               Mean episode length: 235.14
    Episode_Reward/reaching_object: 1.0621
    Episode_Reward/rotating_object: 139.6953
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 2.01s
                      Time elapsed: 00:30:28
                               ETA: 00:24:06

################################################################################
                     [1m Learning iteration 838/1500 [0m                      

                       Computation: 47858 steps/s (collection: 1.888s, learning 0.166s)
             Mean action noise std: 2.68
          Mean value_function loss: 60.5988
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 51.9473
                       Mean reward: 723.01
               Mean episode length: 244.16
    Episode_Reward/reaching_object: 1.0549
    Episode_Reward/rotating_object: 139.8692
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 2.05s
                      Time elapsed: 00:30:30
                               ETA: 00:24:04

################################################################################
                     [1m Learning iteration 839/1500 [0m                      

                       Computation: 48050 steps/s (collection: 1.916s, learning 0.130s)
             Mean action noise std: 2.68
          Mean value_function loss: 68.0498
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 51.9655
                       Mean reward: 714.69
               Mean episode length: 238.89
    Episode_Reward/reaching_object: 1.0539
    Episode_Reward/rotating_object: 141.2382
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 2.05s
                      Time elapsed: 00:30:32
                               ETA: 00:24:02

################################################################################
                     [1m Learning iteration 840/1500 [0m                      

                       Computation: 50749 steps/s (collection: 1.836s, learning 0.101s)
             Mean action noise std: 2.68
          Mean value_function loss: 65.8010
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 51.9818
                       Mean reward: 690.34
               Mean episode length: 236.75
    Episode_Reward/reaching_object: 1.0608
    Episode_Reward/rotating_object: 141.0196
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 1.94s
                      Time elapsed: 00:30:34
                               ETA: 00:23:59

################################################################################
                     [1m Learning iteration 841/1500 [0m                      

                       Computation: 49680 steps/s (collection: 1.814s, learning 0.165s)
             Mean action noise std: 2.68
          Mean value_function loss: 70.8170
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 51.9994
                       Mean reward: 719.34
               Mean episode length: 238.96
    Episode_Reward/reaching_object: 1.0370
    Episode_Reward/rotating_object: 139.0266
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 1.98s
                      Time elapsed: 00:30:36
                               ETA: 00:23:57

################################################################################
                     [1m Learning iteration 842/1500 [0m                      

                       Computation: 50200 steps/s (collection: 1.842s, learning 0.117s)
             Mean action noise std: 2.69
          Mean value_function loss: 65.1854
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.0167
                       Mean reward: 709.08
               Mean episode length: 238.06
    Episode_Reward/reaching_object: 1.0552
    Episode_Reward/rotating_object: 142.7946
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 1.96s
                      Time elapsed: 00:30:38
                               ETA: 00:23:55

################################################################################
                     [1m Learning iteration 843/1500 [0m                      

                       Computation: 51007 steps/s (collection: 1.790s, learning 0.137s)
             Mean action noise std: 2.69
          Mean value_function loss: 63.6899
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 52.0300
                       Mean reward: 674.97
               Mean episode length: 231.76
    Episode_Reward/reaching_object: 1.0428
    Episode_Reward/rotating_object: 139.9443
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 1.93s
                      Time elapsed: 00:30:40
                               ETA: 00:23:52

################################################################################
                     [1m Learning iteration 844/1500 [0m                      

                       Computation: 50361 steps/s (collection: 1.822s, learning 0.130s)
             Mean action noise std: 2.69
          Mean value_function loss: 72.1604
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 52.0478
                       Mean reward: 660.67
               Mean episode length: 234.30
    Episode_Reward/reaching_object: 1.0508
    Episode_Reward/rotating_object: 136.3961
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 1.95s
                      Time elapsed: 00:30:42
                               ETA: 00:23:50

################################################################################
                     [1m Learning iteration 845/1500 [0m                      

                       Computation: 51052 steps/s (collection: 1.818s, learning 0.107s)
             Mean action noise std: 2.69
          Mean value_function loss: 69.5345
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 52.0695
                       Mean reward: 688.36
               Mean episode length: 238.37
    Episode_Reward/reaching_object: 1.0342
    Episode_Reward/rotating_object: 134.9640
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 1.93s
                      Time elapsed: 00:30:44
                               ETA: 00:23:48

################################################################################
                     [1m Learning iteration 846/1500 [0m                      

                       Computation: 50278 steps/s (collection: 1.839s, learning 0.117s)
             Mean action noise std: 2.70
          Mean value_function loss: 72.3864
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.0869
                       Mean reward: 697.49
               Mean episode length: 237.98
    Episode_Reward/reaching_object: 1.0448
    Episode_Reward/rotating_object: 137.0119
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 1.96s
                      Time elapsed: 00:30:46
                               ETA: 00:23:45

################################################################################
                     [1m Learning iteration 847/1500 [0m                      

                       Computation: 47519 steps/s (collection: 1.935s, learning 0.134s)
             Mean action noise std: 2.70
          Mean value_function loss: 68.0443
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 52.1078
                       Mean reward: 687.64
               Mean episode length: 237.00
    Episode_Reward/reaching_object: 1.0564
    Episode_Reward/rotating_object: 138.6527
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 2.07s
                      Time elapsed: 00:30:48
                               ETA: 00:23:43

################################################################################
                     [1m Learning iteration 848/1500 [0m                      

                       Computation: 50808 steps/s (collection: 1.840s, learning 0.095s)
             Mean action noise std: 2.70
          Mean value_function loss: 72.7844
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 52.1317
                       Mean reward: 698.38
               Mean episode length: 243.89
    Episode_Reward/reaching_object: 1.0554
    Episode_Reward/rotating_object: 138.1608
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 1.93s
                      Time elapsed: 00:30:50
                               ETA: 00:23:41

################################################################################
                     [1m Learning iteration 849/1500 [0m                      

                       Computation: 52006 steps/s (collection: 1.801s, learning 0.089s)
             Mean action noise std: 2.71
          Mean value_function loss: 85.8858
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 52.1574
                       Mean reward: 683.03
               Mean episode length: 236.48
    Episode_Reward/reaching_object: 1.0371
    Episode_Reward/rotating_object: 136.2187
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 1.89s
                      Time elapsed: 00:30:52
                               ETA: 00:23:38

################################################################################
                     [1m Learning iteration 850/1500 [0m                      

                       Computation: 49338 steps/s (collection: 1.864s, learning 0.128s)
             Mean action noise std: 2.71
          Mean value_function loss: 69.1271
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.1838
                       Mean reward: 714.44
               Mean episode length: 238.77
    Episode_Reward/reaching_object: 1.0593
    Episode_Reward/rotating_object: 140.1205
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 1.99s
                      Time elapsed: 00:30:54
                               ETA: 00:23:36

################################################################################
                     [1m Learning iteration 851/1500 [0m                      

                       Computation: 49498 steps/s (collection: 1.873s, learning 0.113s)
             Mean action noise std: 2.71
          Mean value_function loss: 75.3503
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 52.2107
                       Mean reward: 707.12
               Mean episode length: 237.18
    Episode_Reward/reaching_object: 1.0498
    Episode_Reward/rotating_object: 139.2911
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 1.99s
                      Time elapsed: 00:30:56
                               ETA: 00:23:34

################################################################################
                     [1m Learning iteration 852/1500 [0m                      

                       Computation: 45623 steps/s (collection: 1.973s, learning 0.182s)
             Mean action noise std: 2.72
          Mean value_function loss: 66.8360
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 52.2324
                       Mean reward: 690.29
               Mean episode length: 235.51
    Episode_Reward/reaching_object: 1.0596
    Episode_Reward/rotating_object: 138.5876
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 2.15s
                      Time elapsed: 00:30:58
                               ETA: 00:23:31

################################################################################
                     [1m Learning iteration 853/1500 [0m                      

                       Computation: 40497 steps/s (collection: 2.245s, learning 0.183s)
             Mean action noise std: 2.72
          Mean value_function loss: 93.2195
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 52.2577
                       Mean reward: 660.41
               Mean episode length: 235.39
    Episode_Reward/reaching_object: 1.0561
    Episode_Reward/rotating_object: 138.1334
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 2.43s
                      Time elapsed: 00:31:01
                               ETA: 00:23:29

################################################################################
                     [1m Learning iteration 854/1500 [0m                      

                       Computation: 45662 steps/s (collection: 2.024s, learning 0.129s)
             Mean action noise std: 2.72
          Mean value_function loss: 73.1801
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 52.2796
                       Mean reward: 697.52
               Mean episode length: 238.04
    Episode_Reward/reaching_object: 1.0556
    Episode_Reward/rotating_object: 138.7922
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 2.15s
                      Time elapsed: 00:31:03
                               ETA: 00:23:27

################################################################################
                     [1m Learning iteration 855/1500 [0m                      

                       Computation: 43456 steps/s (collection: 2.167s, learning 0.095s)
             Mean action noise std: 2.72
          Mean value_function loss: 66.6749
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 52.2976
                       Mean reward: 679.88
               Mean episode length: 238.00
    Episode_Reward/reaching_object: 1.0636
    Episode_Reward/rotating_object: 139.7281
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 2.26s
                      Time elapsed: 00:31:05
                               ETA: 00:23:25

################################################################################
                     [1m Learning iteration 856/1500 [0m                      

                       Computation: 40871 steps/s (collection: 2.211s, learning 0.194s)
             Mean action noise std: 2.72
          Mean value_function loss: 78.2309
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 52.3130
                       Mean reward: 685.21
               Mean episode length: 231.71
    Episode_Reward/reaching_object: 1.0610
    Episode_Reward/rotating_object: 138.9675
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 2.41s
                      Time elapsed: 00:31:07
                               ETA: 00:23:23

################################################################################
                     [1m Learning iteration 857/1500 [0m                      

                       Computation: 35279 steps/s (collection: 2.528s, learning 0.258s)
             Mean action noise std: 2.73
          Mean value_function loss: 75.8658
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 52.3272
                       Mean reward: 679.04
               Mean episode length: 235.92
    Episode_Reward/reaching_object: 1.0612
    Episode_Reward/rotating_object: 137.2393
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 2.79s
                      Time elapsed: 00:31:10
                               ETA: 00:23:21

################################################################################
                     [1m Learning iteration 858/1500 [0m                      

                       Computation: 45219 steps/s (collection: 2.018s, learning 0.156s)
             Mean action noise std: 2.73
          Mean value_function loss: 80.1371
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.3436
                       Mean reward: 701.31
               Mean episode length: 236.84
    Episode_Reward/reaching_object: 1.0618
    Episode_Reward/rotating_object: 138.8100
        Episode_Reward/action_rate: -0.0393
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 2.17s
                      Time elapsed: 00:31:12
                               ETA: 00:23:19

################################################################################
                     [1m Learning iteration 859/1500 [0m                      

                       Computation: 44845 steps/s (collection: 2.073s, learning 0.119s)
             Mean action noise std: 2.73
          Mean value_function loss: 72.9008
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 52.3604
                       Mean reward: 727.32
               Mean episode length: 244.68
    Episode_Reward/reaching_object: 1.0925
    Episode_Reward/rotating_object: 140.4170
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 2.19s
                      Time elapsed: 00:31:15
                               ETA: 00:23:17

################################################################################
                     [1m Learning iteration 860/1500 [0m                      

                       Computation: 47826 steps/s (collection: 1.921s, learning 0.135s)
             Mean action noise std: 2.74
          Mean value_function loss: 79.0275
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.3843
                       Mean reward: 687.73
               Mean episode length: 236.78
    Episode_Reward/reaching_object: 1.0378
    Episode_Reward/rotating_object: 134.3358
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 2.06s
                      Time elapsed: 00:31:17
                               ETA: 00:23:15

################################################################################
                     [1m Learning iteration 861/1500 [0m                      

                       Computation: 49037 steps/s (collection: 1.893s, learning 0.112s)
             Mean action noise std: 2.74
          Mean value_function loss: 70.4068
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 52.4097
                       Mean reward: 663.01
               Mean episode length: 232.84
    Episode_Reward/reaching_object: 1.0614
    Episode_Reward/rotating_object: 137.6432
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 2.00s
                      Time elapsed: 00:31:19
                               ETA: 00:23:12

################################################################################
                     [1m Learning iteration 862/1500 [0m                      

                       Computation: 49848 steps/s (collection: 1.864s, learning 0.109s)
             Mean action noise std: 2.74
          Mean value_function loss: 82.3493
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 52.4315
                       Mean reward: 683.42
               Mean episode length: 233.26
    Episode_Reward/reaching_object: 1.0639
    Episode_Reward/rotating_object: 140.0600
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 1.97s
                      Time elapsed: 00:31:21
                               ETA: 00:23:10

################################################################################
                     [1m Learning iteration 863/1500 [0m                      

                       Computation: 49838 steps/s (collection: 1.820s, learning 0.152s)
             Mean action noise std: 2.74
          Mean value_function loss: 75.0667
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 52.4561
                       Mean reward: 692.10
               Mean episode length: 233.95
    Episode_Reward/reaching_object: 1.0716
    Episode_Reward/rotating_object: 139.1760
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 1.97s
                      Time elapsed: 00:31:23
                               ETA: 00:23:08

################################################################################
                     [1m Learning iteration 864/1500 [0m                      

                       Computation: 48649 steps/s (collection: 1.856s, learning 0.165s)
             Mean action noise std: 2.75
          Mean value_function loss: 75.3711
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 52.4784
                       Mean reward: 694.39
               Mean episode length: 236.69
    Episode_Reward/reaching_object: 1.0603
    Episode_Reward/rotating_object: 136.7723
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 2.02s
                      Time elapsed: 00:31:25
                               ETA: 00:23:06

################################################################################
                     [1m Learning iteration 865/1500 [0m                      

                       Computation: 48550 steps/s (collection: 1.919s, learning 0.106s)
             Mean action noise std: 2.75
          Mean value_function loss: 61.4431
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 52.5043
                       Mean reward: 740.77
               Mean episode length: 244.56
    Episode_Reward/reaching_object: 1.0631
    Episode_Reward/rotating_object: 141.4526
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 2.02s
                      Time elapsed: 00:31:27
                               ETA: 00:23:03

################################################################################
                     [1m Learning iteration 866/1500 [0m                      

                       Computation: 49469 steps/s (collection: 1.874s, learning 0.113s)
             Mean action noise std: 2.75
          Mean value_function loss: 73.8816
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 52.5267
                       Mean reward: 657.50
               Mean episode length: 234.98
    Episode_Reward/reaching_object: 1.0357
    Episode_Reward/rotating_object: 131.5923
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 1.99s
                      Time elapsed: 00:31:29
                               ETA: 00:23:01

################################################################################
                     [1m Learning iteration 867/1500 [0m                      

                       Computation: 50274 steps/s (collection: 1.856s, learning 0.099s)
             Mean action noise std: 2.76
          Mean value_function loss: 69.7113
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 52.5537
                       Mean reward: 682.34
               Mean episode length: 240.89
    Episode_Reward/reaching_object: 1.0825
    Episode_Reward/rotating_object: 138.4339
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 1.96s
                      Time elapsed: 00:31:31
                               ETA: 00:22:59

################################################################################
                     [1m Learning iteration 868/1500 [0m                      

                       Computation: 47940 steps/s (collection: 1.859s, learning 0.192s)
             Mean action noise std: 2.76
          Mean value_function loss: 63.4091
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 52.5878
                       Mean reward: 676.67
               Mean episode length: 233.24
    Episode_Reward/reaching_object: 1.0671
    Episode_Reward/rotating_object: 140.9615
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 2.05s
                      Time elapsed: 00:31:33
                               ETA: 00:22:56

################################################################################
                     [1m Learning iteration 869/1500 [0m                      

                       Computation: 47971 steps/s (collection: 1.932s, learning 0.118s)
             Mean action noise std: 2.77
          Mean value_function loss: 66.0110
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 52.6196
                       Mean reward: 687.73
               Mean episode length: 240.84
    Episode_Reward/reaching_object: 1.0797
    Episode_Reward/rotating_object: 141.8574
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 2.05s
                      Time elapsed: 00:31:35
                               ETA: 00:22:54

################################################################################
                     [1m Learning iteration 870/1500 [0m                      

                       Computation: 50854 steps/s (collection: 1.804s, learning 0.129s)
             Mean action noise std: 2.77
          Mean value_function loss: 79.6336
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 52.6463
                       Mean reward: 699.93
               Mean episode length: 231.05
    Episode_Reward/reaching_object: 1.0347
    Episode_Reward/rotating_object: 134.4086
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 1.93s
                      Time elapsed: 00:31:37
                               ETA: 00:22:52

################################################################################
                     [1m Learning iteration 871/1500 [0m                      

                       Computation: 45783 steps/s (collection: 2.028s, learning 0.119s)
             Mean action noise std: 2.77
          Mean value_function loss: 75.7971
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 52.6663
                       Mean reward: 697.60
               Mean episode length: 235.94
    Episode_Reward/reaching_object: 1.0636
    Episode_Reward/rotating_object: 136.9747
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 2.15s
                      Time elapsed: 00:31:39
                               ETA: 00:22:49

################################################################################
                     [1m Learning iteration 872/1500 [0m                      

                       Computation: 51195 steps/s (collection: 1.808s, learning 0.112s)
             Mean action noise std: 2.77
          Mean value_function loss: 79.4349
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 52.6833
                       Mean reward: 699.06
               Mean episode length: 229.61
    Episode_Reward/reaching_object: 1.0721
    Episode_Reward/rotating_object: 140.4183
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 1.92s
                      Time elapsed: 00:31:41
                               ETA: 00:22:47

################################################################################
                     [1m Learning iteration 873/1500 [0m                      

                       Computation: 50967 steps/s (collection: 1.810s, learning 0.119s)
             Mean action noise std: 2.78
          Mean value_function loss: 76.3812
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.6982
                       Mean reward: 683.24
               Mean episode length: 237.65
    Episode_Reward/reaching_object: 1.0518
    Episode_Reward/rotating_object: 135.4994
        Episode_Reward/action_rate: -0.0401
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 1.93s
                      Time elapsed: 00:31:43
                               ETA: 00:22:45

################################################################################
                     [1m Learning iteration 874/1500 [0m                      

                       Computation: 51740 steps/s (collection: 1.774s, learning 0.126s)
             Mean action noise std: 2.78
          Mean value_function loss: 64.4711
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.7217
                       Mean reward: 751.75
               Mean episode length: 242.49
    Episode_Reward/reaching_object: 1.0650
    Episode_Reward/rotating_object: 142.6398
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 1.90s
                      Time elapsed: 00:31:44
                               ETA: 00:22:42

################################################################################
                     [1m Learning iteration 875/1500 [0m                      

                       Computation: 49440 steps/s (collection: 1.826s, learning 0.163s)
             Mean action noise std: 2.78
          Mean value_function loss: 77.3093
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 52.7466
                       Mean reward: 682.71
               Mean episode length: 236.69
    Episode_Reward/reaching_object: 1.0637
    Episode_Reward/rotating_object: 139.3270
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 1.99s
                      Time elapsed: 00:31:46
                               ETA: 00:22:40

################################################################################
                     [1m Learning iteration 876/1500 [0m                      

                       Computation: 50071 steps/s (collection: 1.830s, learning 0.134s)
             Mean action noise std: 2.78
          Mean value_function loss: 68.0137
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 52.7645
                       Mean reward: 670.33
               Mean episode length: 229.40
    Episode_Reward/reaching_object: 1.0375
    Episode_Reward/rotating_object: 133.8967
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 1.96s
                      Time elapsed: 00:31:48
                               ETA: 00:22:38

################################################################################
                     [1m Learning iteration 877/1500 [0m                      

                       Computation: 50805 steps/s (collection: 1.824s, learning 0.111s)
             Mean action noise std: 2.79
          Mean value_function loss: 74.2140
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 52.7802
                       Mean reward: 659.07
               Mean episode length: 233.80
    Episode_Reward/reaching_object: 1.0461
    Episode_Reward/rotating_object: 135.3530
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 1.93s
                      Time elapsed: 00:31:50
                               ETA: 00:22:35

################################################################################
                     [1m Learning iteration 878/1500 [0m                      

                       Computation: 51856 steps/s (collection: 1.806s, learning 0.090s)
             Mean action noise std: 2.79
          Mean value_function loss: 76.4896
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 52.7986
                       Mean reward: 690.31
               Mean episode length: 230.49
    Episode_Reward/reaching_object: 1.0622
    Episode_Reward/rotating_object: 142.4768
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 1.90s
                      Time elapsed: 00:31:52
                               ETA: 00:22:33

################################################################################
                     [1m Learning iteration 879/1500 [0m                      

                       Computation: 49034 steps/s (collection: 1.905s, learning 0.100s)
             Mean action noise std: 2.79
          Mean value_function loss: 63.3778
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 52.8205
                       Mean reward: 651.68
               Mean episode length: 234.34
    Episode_Reward/reaching_object: 1.0534
    Episode_Reward/rotating_object: 137.5033
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 2.00s
                      Time elapsed: 00:31:54
                               ETA: 00:22:31

################################################################################
                     [1m Learning iteration 880/1500 [0m                      

                       Computation: 39770 steps/s (collection: 2.235s, learning 0.237s)
             Mean action noise std: 2.79
          Mean value_function loss: 71.3366
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 52.8513
                       Mean reward: 707.20
               Mean episode length: 237.97
    Episode_Reward/reaching_object: 1.0415
    Episode_Reward/rotating_object: 137.0136
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 2.47s
                      Time elapsed: 00:31:57
                               ETA: 00:22:29

################################################################################
                     [1m Learning iteration 881/1500 [0m                      

                       Computation: 42488 steps/s (collection: 2.184s, learning 0.130s)
             Mean action noise std: 2.80
          Mean value_function loss: 64.5782
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 52.8847
                       Mean reward: 710.73
               Mean episode length: 239.52
    Episode_Reward/reaching_object: 1.0528
    Episode_Reward/rotating_object: 139.7077
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 2.31s
                      Time elapsed: 00:31:59
                               ETA: 00:22:27

################################################################################
                     [1m Learning iteration 882/1500 [0m                      

                       Computation: 48582 steps/s (collection: 1.917s, learning 0.106s)
             Mean action noise std: 2.80
          Mean value_function loss: 77.8923
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 52.9214
                       Mean reward: 702.52
               Mean episode length: 237.78
    Episode_Reward/reaching_object: 1.0465
    Episode_Reward/rotating_object: 139.1567
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 2.02s
                      Time elapsed: 00:32:01
                               ETA: 00:22:24

################################################################################
                     [1m Learning iteration 883/1500 [0m                      

                       Computation: 49024 steps/s (collection: 1.905s, learning 0.101s)
             Mean action noise std: 2.81
          Mean value_function loss: 82.0587
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 52.9421
                       Mean reward: 712.35
               Mean episode length: 243.39
    Episode_Reward/reaching_object: 1.0689
    Episode_Reward/rotating_object: 141.6080
        Episode_Reward/action_rate: -0.0423
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 2.01s
                      Time elapsed: 00:32:03
                               ETA: 00:22:22

################################################################################
                     [1m Learning iteration 884/1500 [0m                      

                       Computation: 47027 steps/s (collection: 1.977s, learning 0.113s)
             Mean action noise std: 2.81
          Mean value_function loss: 66.3839
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 52.9602
                       Mean reward: 669.14
               Mean episode length: 230.90
    Episode_Reward/reaching_object: 1.0489
    Episode_Reward/rotating_object: 134.5428
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 2.09s
                      Time elapsed: 00:32:05
                               ETA: 00:22:20

################################################################################
                     [1m Learning iteration 885/1500 [0m                      

                       Computation: 47975 steps/s (collection: 1.936s, learning 0.113s)
             Mean action noise std: 2.81
          Mean value_function loss: 58.9683
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 52.9866
                       Mean reward: 708.74
               Mean episode length: 240.28
    Episode_Reward/reaching_object: 1.0601
    Episode_Reward/rotating_object: 141.9366
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 2.05s
                      Time elapsed: 00:32:07
                               ETA: 00:22:18

################################################################################
                     [1m Learning iteration 886/1500 [0m                      

                       Computation: 42321 steps/s (collection: 2.214s, learning 0.109s)
             Mean action noise std: 2.82
          Mean value_function loss: 77.1756
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 53.0166
                       Mean reward: 708.82
               Mean episode length: 240.58
    Episode_Reward/reaching_object: 1.0534
    Episode_Reward/rotating_object: 137.2686
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 2.32s
                      Time elapsed: 00:32:10
                               ETA: 00:22:15

################################################################################
                     [1m Learning iteration 887/1500 [0m                      

                       Computation: 43050 steps/s (collection: 2.181s, learning 0.102s)
             Mean action noise std: 2.82
          Mean value_function loss: 63.7576
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 53.0425
                       Mean reward: 690.52
               Mean episode length: 237.48
    Episode_Reward/reaching_object: 1.0658
    Episode_Reward/rotating_object: 138.3794
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 2.28s
                      Time elapsed: 00:32:12
                               ETA: 00:22:13

################################################################################
                     [1m Learning iteration 888/1500 [0m                      

                       Computation: 43750 steps/s (collection: 2.150s, learning 0.097s)
             Mean action noise std: 2.82
          Mean value_function loss: 57.1493
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.0703
                       Mean reward: 723.77
               Mean episode length: 245.42
    Episode_Reward/reaching_object: 1.0711
    Episode_Reward/rotating_object: 143.5266
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 2.25s
                      Time elapsed: 00:32:14
                               ETA: 00:22:11

################################################################################
                     [1m Learning iteration 889/1500 [0m                      

                       Computation: 48958 steps/s (collection: 1.914s, learning 0.094s)
             Mean action noise std: 2.83
          Mean value_function loss: 65.7453
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 53.0971
                       Mean reward: 656.67
               Mean episode length: 232.68
    Episode_Reward/reaching_object: 1.0563
    Episode_Reward/rotating_object: 137.1105
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 2.01s
                      Time elapsed: 00:32:16
                               ETA: 00:22:09

################################################################################
                     [1m Learning iteration 890/1500 [0m                      

                       Computation: 45565 steps/s (collection: 2.060s, learning 0.098s)
             Mean action noise std: 2.83
          Mean value_function loss: 62.9251
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 53.1190
                       Mean reward: 700.57
               Mean episode length: 235.53
    Episode_Reward/reaching_object: 1.0594
    Episode_Reward/rotating_object: 139.8195
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 2.16s
                      Time elapsed: 00:32:18
                               ETA: 00:22:07

################################################################################
                     [1m Learning iteration 891/1500 [0m                      

                       Computation: 49854 steps/s (collection: 1.876s, learning 0.096s)
             Mean action noise std: 2.83
          Mean value_function loss: 74.7626
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 53.1341
                       Mean reward: 669.58
               Mean episode length: 237.45
    Episode_Reward/reaching_object: 1.0488
    Episode_Reward/rotating_object: 138.3154
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 1.97s
                      Time elapsed: 00:32:20
                               ETA: 00:22:04

################################################################################
                     [1m Learning iteration 892/1500 [0m                      

                       Computation: 48988 steps/s (collection: 1.915s, learning 0.092s)
             Mean action noise std: 2.83
          Mean value_function loss: 79.0676
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.1447
                       Mean reward: 674.19
               Mean episode length: 240.24
    Episode_Reward/reaching_object: 1.0498
    Episode_Reward/rotating_object: 137.0740
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 2.01s
                      Time elapsed: 00:32:22
                               ETA: 00:22:02

################################################################################
                     [1m Learning iteration 893/1500 [0m                      

                       Computation: 48747 steps/s (collection: 1.895s, learning 0.122s)
             Mean action noise std: 2.84
          Mean value_function loss: 61.2095
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 53.1681
                       Mean reward: 686.89
               Mean episode length: 234.76
    Episode_Reward/reaching_object: 1.0609
    Episode_Reward/rotating_object: 138.1498
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 2.02s
                      Time elapsed: 00:32:24
                               ETA: 00:22:00

################################################################################
                     [1m Learning iteration 894/1500 [0m                      

                       Computation: 44977 steps/s (collection: 1.995s, learning 0.191s)
             Mean action noise std: 2.84
          Mean value_function loss: 62.5418
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 53.1944
                       Mean reward: 672.74
               Mean episode length: 232.77
    Episode_Reward/reaching_object: 1.0545
    Episode_Reward/rotating_object: 138.3178
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 2.19s
                      Time elapsed: 00:32:26
                               ETA: 00:21:58

################################################################################
                     [1m Learning iteration 895/1500 [0m                      

                       Computation: 46178 steps/s (collection: 1.977s, learning 0.151s)
             Mean action noise std: 2.84
          Mean value_function loss: 74.2838
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 53.2095
                       Mean reward: 661.34
               Mean episode length: 230.07
    Episode_Reward/reaching_object: 1.0546
    Episode_Reward/rotating_object: 138.1068
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 2.13s
                      Time elapsed: 00:32:29
                               ETA: 00:21:56

################################################################################
                     [1m Learning iteration 896/1500 [0m                      

                       Computation: 47325 steps/s (collection: 1.897s, learning 0.180s)
             Mean action noise std: 2.85
          Mean value_function loss: 80.7830
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 53.2281
                       Mean reward: 704.83
               Mean episode length: 236.69
    Episode_Reward/reaching_object: 1.0515
    Episode_Reward/rotating_object: 138.6566
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 2.08s
                      Time elapsed: 00:32:31
                               ETA: 00:21:53

################################################################################
                     [1m Learning iteration 897/1500 [0m                      

                       Computation: 47244 steps/s (collection: 1.898s, learning 0.183s)
             Mean action noise std: 2.85
          Mean value_function loss: 81.8512
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 53.2496
                       Mean reward: 700.59
               Mean episode length: 240.59
    Episode_Reward/reaching_object: 1.0581
    Episode_Reward/rotating_object: 138.4867
        Episode_Reward/action_rate: -0.0434
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 2.08s
                      Time elapsed: 00:32:33
                               ETA: 00:21:51

################################################################################
                     [1m Learning iteration 898/1500 [0m                      

                       Computation: 45437 steps/s (collection: 1.952s, learning 0.211s)
             Mean action noise std: 2.85
          Mean value_function loss: 78.3339
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 53.2647
                       Mean reward: 708.23
               Mean episode length: 235.46
    Episode_Reward/reaching_object: 1.0587
    Episode_Reward/rotating_object: 143.2263
        Episode_Reward/action_rate: -0.0436
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 2.16s
                      Time elapsed: 00:32:35
                               ETA: 00:21:49

################################################################################
                     [1m Learning iteration 899/1500 [0m                      

                       Computation: 48120 steps/s (collection: 1.931s, learning 0.112s)
             Mean action noise std: 2.85
          Mean value_function loss: 63.9828
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 53.2786
                       Mean reward: 722.90
               Mean episode length: 240.57
    Episode_Reward/reaching_object: 1.0475
    Episode_Reward/rotating_object: 137.3020
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 2.04s
                      Time elapsed: 00:32:37
                               ETA: 00:21:47

################################################################################
                     [1m Learning iteration 900/1500 [0m                      

                       Computation: 49570 steps/s (collection: 1.873s, learning 0.110s)
             Mean action noise std: 2.85
          Mean value_function loss: 72.9073
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.2951
                       Mean reward: 717.17
               Mean episode length: 241.18
    Episode_Reward/reaching_object: 1.0699
    Episode_Reward/rotating_object: 140.0017
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 1.98s
                      Time elapsed: 00:32:39
                               ETA: 00:21:44

################################################################################
                     [1m Learning iteration 901/1500 [0m                      

                       Computation: 48047 steps/s (collection: 1.934s, learning 0.112s)
             Mean action noise std: 2.86
          Mean value_function loss: 75.7753
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 53.3205
                       Mean reward: 664.55
               Mean episode length: 237.77
    Episode_Reward/reaching_object: 1.0578
    Episode_Reward/rotating_object: 138.1953
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 2.05s
                      Time elapsed: 00:32:41
                               ETA: 00:21:42

################################################################################
                     [1m Learning iteration 902/1500 [0m                      

                       Computation: 48987 steps/s (collection: 1.895s, learning 0.112s)
             Mean action noise std: 2.86
          Mean value_function loss: 75.2631
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 53.3471
                       Mean reward: 681.94
               Mean episode length: 237.20
    Episode_Reward/reaching_object: 1.0640
    Episode_Reward/rotating_object: 139.2011
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 2.01s
                      Time elapsed: 00:32:43
                               ETA: 00:21:40

################################################################################
                     [1m Learning iteration 903/1500 [0m                      

                       Computation: 49150 steps/s (collection: 1.886s, learning 0.114s)
             Mean action noise std: 2.86
          Mean value_function loss: 70.1365
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 53.3684
                       Mean reward: 706.77
               Mean episode length: 239.31
    Episode_Reward/reaching_object: 1.0340
    Episode_Reward/rotating_object: 136.5196
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 2.00s
                      Time elapsed: 00:32:45
                               ETA: 00:21:37

################################################################################
                     [1m Learning iteration 904/1500 [0m                      

                       Computation: 47080 steps/s (collection: 1.923s, learning 0.165s)
             Mean action noise std: 2.87
          Mean value_function loss: 73.0128
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.3874
                       Mean reward: 685.51
               Mean episode length: 230.10
    Episode_Reward/reaching_object: 1.0703
    Episode_Reward/rotating_object: 143.0670
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 2.09s
                      Time elapsed: 00:32:47
                               ETA: 00:21:35

################################################################################
                     [1m Learning iteration 905/1500 [0m                      

                       Computation: 50042 steps/s (collection: 1.862s, learning 0.102s)
             Mean action noise std: 2.87
          Mean value_function loss: 77.2793
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 53.4018
                       Mean reward: 669.96
               Mean episode length: 231.98
    Episode_Reward/reaching_object: 1.0492
    Episode_Reward/rotating_object: 135.3158
        Episode_Reward/action_rate: -0.0436
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 1.96s
                      Time elapsed: 00:32:49
                               ETA: 00:21:33

################################################################################
                     [1m Learning iteration 906/1500 [0m                      

                       Computation: 47789 steps/s (collection: 1.896s, learning 0.161s)
             Mean action noise std: 2.87
          Mean value_function loss: 74.7847
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 53.4186
                       Mean reward: 688.04
               Mean episode length: 232.33
    Episode_Reward/reaching_object: 1.0418
    Episode_Reward/rotating_object: 135.5301
        Episode_Reward/action_rate: -0.0436
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 2.06s
                      Time elapsed: 00:32:51
                               ETA: 00:21:31

################################################################################
                     [1m Learning iteration 907/1500 [0m                      

                       Computation: 50574 steps/s (collection: 1.831s, learning 0.113s)
             Mean action noise std: 2.87
          Mean value_function loss: 69.1293
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 53.4323
                       Mean reward: 704.85
               Mean episode length: 238.54
    Episode_Reward/reaching_object: 1.0618
    Episode_Reward/rotating_object: 136.5614
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 1.94s
                      Time elapsed: 00:32:53
                               ETA: 00:21:28

################################################################################
                     [1m Learning iteration 908/1500 [0m                      

                       Computation: 48663 steps/s (collection: 1.898s, learning 0.122s)
             Mean action noise std: 2.88
          Mean value_function loss: 53.1812
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 53.4487
                       Mean reward: 706.20
               Mean episode length: 240.92
    Episode_Reward/reaching_object: 1.0872
    Episode_Reward/rotating_object: 145.3178
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 2.02s
                      Time elapsed: 00:32:55
                               ETA: 00:21:26

################################################################################
                     [1m Learning iteration 909/1500 [0m                      

                       Computation: 48451 steps/s (collection: 1.933s, learning 0.096s)
             Mean action noise std: 2.88
          Mean value_function loss: 82.4386
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 53.4693
                       Mean reward: 664.76
               Mean episode length: 236.19
    Episode_Reward/reaching_object: 1.0472
    Episode_Reward/rotating_object: 137.3128
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 2.03s
                      Time elapsed: 00:32:57
                               ETA: 00:21:24

################################################################################
                     [1m Learning iteration 910/1500 [0m                      

                       Computation: 49693 steps/s (collection: 1.882s, learning 0.096s)
             Mean action noise std: 2.88
          Mean value_function loss: 76.8681
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 53.4919
                       Mean reward: 693.60
               Mean episode length: 234.72
    Episode_Reward/reaching_object: 1.0497
    Episode_Reward/rotating_object: 135.1584
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 1.98s
                      Time elapsed: 00:32:59
                               ETA: 00:21:21

################################################################################
                     [1m Learning iteration 911/1500 [0m                      

                       Computation: 49362 steps/s (collection: 1.869s, learning 0.123s)
             Mean action noise std: 2.88
          Mean value_function loss: 74.7917
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 53.5120
                       Mean reward: 709.30
               Mean episode length: 237.35
    Episode_Reward/reaching_object: 1.0595
    Episode_Reward/rotating_object: 137.6407
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 1.99s
                      Time elapsed: 00:33:01
                               ETA: 00:21:19

################################################################################
                     [1m Learning iteration 912/1500 [0m                      

                       Computation: 46356 steps/s (collection: 2.022s, learning 0.099s)
             Mean action noise std: 2.89
          Mean value_function loss: 57.5155
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.5276
                       Mean reward: 715.21
               Mean episode length: 243.31
    Episode_Reward/reaching_object: 1.0659
    Episode_Reward/rotating_object: 138.3063
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 2.12s
                      Time elapsed: 00:33:03
                               ETA: 00:21:17

################################################################################
                     [1m Learning iteration 913/1500 [0m                      

                       Computation: 50261 steps/s (collection: 1.862s, learning 0.094s)
             Mean action noise std: 2.89
          Mean value_function loss: 59.9722
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 53.5421
                       Mean reward: 714.05
               Mean episode length: 238.48
    Episode_Reward/reaching_object: 1.0724
    Episode_Reward/rotating_object: 140.4365
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 1.96s
                      Time elapsed: 00:33:05
                               ETA: 00:21:15

################################################################################
                     [1m Learning iteration 914/1500 [0m                      

                       Computation: 48539 steps/s (collection: 1.914s, learning 0.111s)
             Mean action noise std: 2.89
          Mean value_function loss: 66.0203
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 53.5519
                       Mean reward: 696.34
               Mean episode length: 238.60
    Episode_Reward/reaching_object: 1.0734
    Episode_Reward/rotating_object: 140.3481
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 2.03s
                      Time elapsed: 00:33:07
                               ETA: 00:21:12

################################################################################
                     [1m Learning iteration 915/1500 [0m                      

                       Computation: 49595 steps/s (collection: 1.887s, learning 0.095s)
             Mean action noise std: 2.89
          Mean value_function loss: 66.6122
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 53.5698
                       Mean reward: 702.43
               Mean episode length: 231.51
    Episode_Reward/reaching_object: 1.0584
    Episode_Reward/rotating_object: 139.6289
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 1.98s
                      Time elapsed: 00:33:09
                               ETA: 00:21:10

################################################################################
                     [1m Learning iteration 916/1500 [0m                      

                       Computation: 47137 steps/s (collection: 1.989s, learning 0.096s)
             Mean action noise std: 2.90
          Mean value_function loss: 66.4555
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 53.5950
                       Mean reward: 694.35
               Mean episode length: 238.99
    Episode_Reward/reaching_object: 1.0490
    Episode_Reward/rotating_object: 137.5891
        Episode_Reward/action_rate: -0.0437
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 2.09s
                      Time elapsed: 00:33:11
                               ETA: 00:21:08

################################################################################
                     [1m Learning iteration 917/1500 [0m                      

                       Computation: 47541 steps/s (collection: 1.968s, learning 0.100s)
             Mean action noise std: 2.90
          Mean value_function loss: 67.5209
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 53.6194
                       Mean reward: 716.84
               Mean episode length: 240.77
    Episode_Reward/reaching_object: 1.0564
    Episode_Reward/rotating_object: 139.8062
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 2.07s
                      Time elapsed: 00:33:13
                               ETA: 00:21:06

################################################################################
                     [1m Learning iteration 918/1500 [0m                      

                       Computation: 48058 steps/s (collection: 1.938s, learning 0.107s)
             Mean action noise std: 2.90
          Mean value_function loss: 72.4524
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 53.6381
                       Mean reward: 657.78
               Mean episode length: 232.44
    Episode_Reward/reaching_object: 1.0647
    Episode_Reward/rotating_object: 138.8279
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 2.05s
                      Time elapsed: 00:33:15
                               ETA: 00:21:03

################################################################################
                     [1m Learning iteration 919/1500 [0m                      

                       Computation: 47769 steps/s (collection: 1.923s, learning 0.135s)
             Mean action noise std: 2.91
          Mean value_function loss: 70.5028
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.6558
                       Mean reward: 688.48
               Mean episode length: 236.81
    Episode_Reward/reaching_object: 1.0677
    Episode_Reward/rotating_object: 139.7308
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 2.06s
                      Time elapsed: 00:33:17
                               ETA: 00:21:01

################################################################################
                     [1m Learning iteration 920/1500 [0m                      

                       Computation: 49826 steps/s (collection: 1.873s, learning 0.100s)
             Mean action noise std: 2.91
          Mean value_function loss: 67.1284
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.6789
                       Mean reward: 744.81
               Mean episode length: 242.21
    Episode_Reward/reaching_object: 1.0734
    Episode_Reward/rotating_object: 140.2255
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 1.97s
                      Time elapsed: 00:33:19
                               ETA: 00:20:59

################################################################################
                     [1m Learning iteration 921/1500 [0m                      

                       Computation: 49709 steps/s (collection: 1.883s, learning 0.094s)
             Mean action noise std: 2.91
          Mean value_function loss: 78.0609
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 53.6967
                       Mean reward: 749.90
               Mean episode length: 246.27
    Episode_Reward/reaching_object: 1.0753
    Episode_Reward/rotating_object: 142.8848
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 1.98s
                      Time elapsed: 00:33:21
                               ETA: 00:20:57

################################################################################
                     [1m Learning iteration 922/1500 [0m                      

                       Computation: 48079 steps/s (collection: 1.949s, learning 0.096s)
             Mean action noise std: 2.91
          Mean value_function loss: 77.6428
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 53.7058
                       Mean reward: 671.98
               Mean episode length: 230.71
    Episode_Reward/reaching_object: 1.0612
    Episode_Reward/rotating_object: 141.3574
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 2.04s
                      Time elapsed: 00:33:23
                               ETA: 00:20:54

################################################################################
                     [1m Learning iteration 923/1500 [0m                      

                       Computation: 47484 steps/s (collection: 1.919s, learning 0.152s)
             Mean action noise std: 2.92
          Mean value_function loss: 77.2395
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 53.7182
                       Mean reward: 690.92
               Mean episode length: 237.96
    Episode_Reward/reaching_object: 1.0626
    Episode_Reward/rotating_object: 137.2458
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 2.07s
                      Time elapsed: 00:33:25
                               ETA: 00:20:52

################################################################################
                     [1m Learning iteration 924/1500 [0m                      

                       Computation: 48550 steps/s (collection: 1.924s, learning 0.101s)
             Mean action noise std: 2.92
          Mean value_function loss: 67.8602
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 53.7415
                       Mean reward: 694.23
               Mean episode length: 237.43
    Episode_Reward/reaching_object: 1.0646
    Episode_Reward/rotating_object: 138.5204
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 2.02s
                      Time elapsed: 00:33:27
                               ETA: 00:20:50

################################################################################
                     [1m Learning iteration 925/1500 [0m                      

                       Computation: 42888 steps/s (collection: 2.097s, learning 0.195s)
             Mean action noise std: 2.92
          Mean value_function loss: 80.6893
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 53.7570
                       Mean reward: 710.50
               Mean episode length: 235.00
    Episode_Reward/reaching_object: 1.0603
    Episode_Reward/rotating_object: 137.2619
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 2.29s
                      Time elapsed: 00:33:30
                               ETA: 00:20:48

################################################################################
                     [1m Learning iteration 926/1500 [0m                      

                       Computation: 42443 steps/s (collection: 2.156s, learning 0.160s)
             Mean action noise std: 2.92
          Mean value_function loss: 62.9694
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 53.7763
                       Mean reward: 718.21
               Mean episode length: 241.10
    Episode_Reward/reaching_object: 1.0785
    Episode_Reward/rotating_object: 142.6382
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 2.32s
                      Time elapsed: 00:33:32
                               ETA: 00:20:46

################################################################################
                     [1m Learning iteration 927/1500 [0m                      

                       Computation: 42717 steps/s (collection: 2.176s, learning 0.126s)
             Mean action noise std: 2.93
          Mean value_function loss: 68.9387
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 53.7934
                       Mean reward: 715.71
               Mean episode length: 235.50
    Episode_Reward/reaching_object: 1.0667
    Episode_Reward/rotating_object: 138.5799
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 2.30s
                      Time elapsed: 00:33:34
                               ETA: 00:20:44

################################################################################
                     [1m Learning iteration 928/1500 [0m                      

                       Computation: 41064 steps/s (collection: 2.216s, learning 0.178s)
             Mean action noise std: 2.93
          Mean value_function loss: 74.5544
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 53.8079
                       Mean reward: 712.41
               Mean episode length: 240.64
    Episode_Reward/reaching_object: 1.0696
    Episode_Reward/rotating_object: 137.5107
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 2.39s
                      Time elapsed: 00:33:37
                               ETA: 00:20:42

################################################################################
                     [1m Learning iteration 929/1500 [0m                      

                       Computation: 42131 steps/s (collection: 2.159s, learning 0.174s)
             Mean action noise std: 2.93
          Mean value_function loss: 72.0091
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.8183
                       Mean reward: 732.32
               Mean episode length: 244.43
    Episode_Reward/reaching_object: 1.0800
    Episode_Reward/rotating_object: 143.7374
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 2.33s
                      Time elapsed: 00:33:39
                               ETA: 00:20:39

################################################################################
                     [1m Learning iteration 930/1500 [0m                      

                       Computation: 43838 steps/s (collection: 2.121s, learning 0.121s)
             Mean action noise std: 2.93
          Mean value_function loss: 93.6525
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 53.8350
                       Mean reward: 660.92
               Mean episode length: 226.45
    Episode_Reward/reaching_object: 1.0513
    Episode_Reward/rotating_object: 136.5969
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 2.24s
                      Time elapsed: 00:33:41
                               ETA: 00:20:37

################################################################################
                     [1m Learning iteration 931/1500 [0m                      

                       Computation: 42759 steps/s (collection: 2.117s, learning 0.182s)
             Mean action noise std: 2.93
          Mean value_function loss: 66.6991
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 53.8525
                       Mean reward: 712.08
               Mean episode length: 238.19
    Episode_Reward/reaching_object: 1.0813
    Episode_Reward/rotating_object: 141.4612
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 2.30s
                      Time elapsed: 00:33:44
                               ETA: 00:20:35

################################################################################
                     [1m Learning iteration 932/1500 [0m                      

                       Computation: 41534 steps/s (collection: 2.152s, learning 0.215s)
             Mean action noise std: 2.94
          Mean value_function loss: 65.3226
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.8657
                       Mean reward: 705.61
               Mean episode length: 240.05
    Episode_Reward/reaching_object: 1.0913
    Episode_Reward/rotating_object: 142.9378
        Episode_Reward/action_rate: -0.0459
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 2.37s
                      Time elapsed: 00:33:46
                               ETA: 00:20:33

################################################################################
                     [1m Learning iteration 933/1500 [0m                      

                       Computation: 44620 steps/s (collection: 2.105s, learning 0.098s)
             Mean action noise std: 2.94
          Mean value_function loss: 65.2981
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 53.8811
                       Mean reward: 720.34
               Mean episode length: 244.33
    Episode_Reward/reaching_object: 1.0824
    Episode_Reward/rotating_object: 142.4273
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 2.20s
                      Time elapsed: 00:33:48
                               ETA: 00:20:31

################################################################################
                     [1m Learning iteration 934/1500 [0m                      

                       Computation: 46089 steps/s (collection: 2.004s, learning 0.129s)
             Mean action noise std: 2.94
          Mean value_function loss: 70.3993
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 53.8951
                       Mean reward: 731.41
               Mean episode length: 243.82
    Episode_Reward/reaching_object: 1.0837
    Episode_Reward/rotating_object: 141.8500
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 2.13s
                      Time elapsed: 00:33:50
                               ETA: 00:20:29

################################################################################
                     [1m Learning iteration 935/1500 [0m                      

                       Computation: 49145 steps/s (collection: 1.896s, learning 0.105s)
             Mean action noise std: 2.94
          Mean value_function loss: 79.0985
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 53.9120
                       Mean reward: 692.89
               Mean episode length: 235.04
    Episode_Reward/reaching_object: 1.0610
    Episode_Reward/rotating_object: 140.7082
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 2.00s
                      Time elapsed: 00:33:52
                               ETA: 00:20:27

################################################################################
                     [1m Learning iteration 936/1500 [0m                      

                       Computation: 47268 steps/s (collection: 1.975s, learning 0.105s)
             Mean action noise std: 2.95
          Mean value_function loss: 69.5614
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.9310
                       Mean reward: 699.29
               Mean episode length: 238.05
    Episode_Reward/reaching_object: 1.0679
    Episode_Reward/rotating_object: 138.0992
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 2.08s
                      Time elapsed: 00:33:54
                               ETA: 00:20:24

################################################################################
                     [1m Learning iteration 937/1500 [0m                      

                       Computation: 47284 steps/s (collection: 1.961s, learning 0.118s)
             Mean action noise std: 2.95
          Mean value_function loss: 67.9823
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.9476
                       Mean reward: 706.65
               Mean episode length: 237.69
    Episode_Reward/reaching_object: 1.0545
    Episode_Reward/rotating_object: 138.1185
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 2.08s
                      Time elapsed: 00:33:56
                               ETA: 00:20:22

################################################################################
                     [1m Learning iteration 938/1500 [0m                      

                       Computation: 48639 steps/s (collection: 1.900s, learning 0.121s)
             Mean action noise std: 2.95
          Mean value_function loss: 63.1058
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 53.9696
                       Mean reward: 723.55
               Mean episode length: 245.01
    Episode_Reward/reaching_object: 1.0979
    Episode_Reward/rotating_object: 146.2231
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 2.02s
                      Time elapsed: 00:33:58
                               ETA: 00:20:20

################################################################################
                     [1m Learning iteration 939/1500 [0m                      

                       Computation: 47248 steps/s (collection: 1.938s, learning 0.143s)
             Mean action noise std: 2.95
          Mean value_function loss: 69.3368
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 53.9893
                       Mean reward: 710.69
               Mean episode length: 238.17
    Episode_Reward/reaching_object: 1.0642
    Episode_Reward/rotating_object: 142.1906
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 2.08s
                      Time elapsed: 00:34:01
                               ETA: 00:20:18

################################################################################
                     [1m Learning iteration 940/1500 [0m                      

                       Computation: 44534 steps/s (collection: 2.028s, learning 0.180s)
             Mean action noise std: 2.96
          Mean value_function loss: 67.8937
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 54.0107
                       Mean reward: 669.38
               Mean episode length: 227.52
    Episode_Reward/reaching_object: 1.0577
    Episode_Reward/rotating_object: 140.1177
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 2.21s
                      Time elapsed: 00:34:03
                               ETA: 00:20:15

################################################################################
                     [1m Learning iteration 941/1500 [0m                      

                       Computation: 45988 steps/s (collection: 1.975s, learning 0.163s)
             Mean action noise std: 2.96
          Mean value_function loss: 82.7183
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 54.0321
                       Mean reward: 682.92
               Mean episode length: 232.97
    Episode_Reward/reaching_object: 1.0703
    Episode_Reward/rotating_object: 139.4647
        Episode_Reward/action_rate: -0.0456
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 2.14s
                      Time elapsed: 00:34:05
                               ETA: 00:20:13

################################################################################
                     [1m Learning iteration 942/1500 [0m                      

                       Computation: 47738 steps/s (collection: 1.895s, learning 0.164s)
             Mean action noise std: 2.96
          Mean value_function loss: 68.4511
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 54.0439
                       Mean reward: 751.85
               Mean episode length: 245.63
    Episode_Reward/reaching_object: 1.0539
    Episode_Reward/rotating_object: 139.6343
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 2.06s
                      Time elapsed: 00:34:07
                               ETA: 00:20:11

################################################################################
                     [1m Learning iteration 943/1500 [0m                      

                       Computation: 49113 steps/s (collection: 1.893s, learning 0.109s)
             Mean action noise std: 2.97
          Mean value_function loss: 66.3584
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 54.0643
                       Mean reward: 684.07
               Mean episode length: 236.38
    Episode_Reward/reaching_object: 1.0633
    Episode_Reward/rotating_object: 137.3906
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 2.00s
                      Time elapsed: 00:34:09
                               ETA: 00:20:09

################################################################################
                     [1m Learning iteration 944/1500 [0m                      

                       Computation: 47096 steps/s (collection: 1.913s, learning 0.174s)
             Mean action noise std: 2.97
          Mean value_function loss: 83.9990
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 54.0884
                       Mean reward: 664.07
               Mean episode length: 229.08
    Episode_Reward/reaching_object: 1.0542
    Episode_Reward/rotating_object: 135.8880
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 2.09s
                      Time elapsed: 00:34:11
                               ETA: 00:20:07

################################################################################
                     [1m Learning iteration 945/1500 [0m                      

                       Computation: 47461 steps/s (collection: 1.974s, learning 0.097s)
             Mean action noise std: 2.97
          Mean value_function loss: 77.9881
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 54.1033
                       Mean reward: 693.25
               Mean episode length: 232.71
    Episode_Reward/reaching_object: 1.0485
    Episode_Reward/rotating_object: 136.6013
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 2.07s
                      Time elapsed: 00:34:13
                               ETA: 00:20:04

################################################################################
                     [1m Learning iteration 946/1500 [0m                      

                       Computation: 47805 steps/s (collection: 1.942s, learning 0.115s)
             Mean action noise std: 2.97
          Mean value_function loss: 74.2074
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 54.1127
                       Mean reward: 697.10
               Mean episode length: 237.63
    Episode_Reward/reaching_object: 1.0584
    Episode_Reward/rotating_object: 137.4207
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 2.06s
                      Time elapsed: 00:34:15
                               ETA: 00:20:02

################################################################################
                     [1m Learning iteration 947/1500 [0m                      

                       Computation: 46186 steps/s (collection: 2.024s, learning 0.105s)
             Mean action noise std: 2.97
          Mean value_function loss: 73.2248
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 54.1300
                       Mean reward: 683.40
               Mean episode length: 234.93
    Episode_Reward/reaching_object: 1.0568
    Episode_Reward/rotating_object: 136.6702
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 2.13s
                      Time elapsed: 00:34:17
                               ETA: 00:20:00

################################################################################
                     [1m Learning iteration 948/1500 [0m                      

                       Computation: 48709 steps/s (collection: 1.896s, learning 0.123s)
             Mean action noise std: 2.98
          Mean value_function loss: 71.8502
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 54.1505
                       Mean reward: 727.57
               Mean episode length: 243.96
    Episode_Reward/reaching_object: 1.0568
    Episode_Reward/rotating_object: 138.1884
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 2.02s
                      Time elapsed: 00:34:19
                               ETA: 00:19:58

################################################################################
                     [1m Learning iteration 949/1500 [0m                      

                       Computation: 49385 steps/s (collection: 1.894s, learning 0.096s)
             Mean action noise std: 2.98
          Mean value_function loss: 63.1616
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 54.1679
                       Mean reward: 761.28
               Mean episode length: 247.01
    Episode_Reward/reaching_object: 1.0937
    Episode_Reward/rotating_object: 142.8331
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 1.99s
                      Time elapsed: 00:34:21
                               ETA: 00:19:55

################################################################################
                     [1m Learning iteration 950/1500 [0m                      

                       Computation: 48106 steps/s (collection: 1.932s, learning 0.111s)
             Mean action noise std: 2.98
          Mean value_function loss: 67.3626
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 54.1830
                       Mean reward: 690.79
               Mean episode length: 235.18
    Episode_Reward/reaching_object: 1.0829
    Episode_Reward/rotating_object: 139.2941
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 2.04s
                      Time elapsed: 00:34:23
                               ETA: 00:19:53

################################################################################
                     [1m Learning iteration 951/1500 [0m                      

                       Computation: 47111 steps/s (collection: 1.977s, learning 0.110s)
             Mean action noise std: 2.98
          Mean value_function loss: 65.4705
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 54.1928
                       Mean reward: 690.31
               Mean episode length: 231.06
    Episode_Reward/reaching_object: 1.0873
    Episode_Reward/rotating_object: 142.7892
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 2.09s
                      Time elapsed: 00:34:25
                               ETA: 00:19:51

################################################################################
                     [1m Learning iteration 952/1500 [0m                      

                       Computation: 46702 steps/s (collection: 1.961s, learning 0.144s)
             Mean action noise std: 2.99
          Mean value_function loss: 54.3067
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 54.2084
                       Mean reward: 765.09
               Mean episode length: 246.13
    Episode_Reward/reaching_object: 1.1017
    Episode_Reward/rotating_object: 146.0789
        Episode_Reward/action_rate: -0.0470
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 2.10s
                      Time elapsed: 00:34:28
                               ETA: 00:19:49

################################################################################
                     [1m Learning iteration 953/1500 [0m                      

                       Computation: 47850 steps/s (collection: 1.943s, learning 0.112s)
             Mean action noise std: 2.99
          Mean value_function loss: 82.6926
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 54.2279
                       Mean reward: 692.65
               Mean episode length: 233.55
    Episode_Reward/reaching_object: 1.0631
    Episode_Reward/rotating_object: 138.6997
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 2.05s
                      Time elapsed: 00:34:30
                               ETA: 00:19:46

################################################################################
                     [1m Learning iteration 954/1500 [0m                      

                       Computation: 45862 steps/s (collection: 2.042s, learning 0.101s)
             Mean action noise std: 2.99
          Mean value_function loss: 78.2156
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 54.2511
                       Mean reward: 720.83
               Mean episode length: 237.74
    Episode_Reward/reaching_object: 1.1003
    Episode_Reward/rotating_object: 144.2838
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 2.14s
                      Time elapsed: 00:34:32
                               ETA: 00:19:44

################################################################################
                     [1m Learning iteration 955/1500 [0m                      

                       Computation: 44885 steps/s (collection: 1.935s, learning 0.255s)
             Mean action noise std: 3.00
          Mean value_function loss: 85.6684
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 54.2752
                       Mean reward: 727.85
               Mean episode length: 234.04
    Episode_Reward/reaching_object: 1.0960
    Episode_Reward/rotating_object: 145.6345
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 2.19s
                      Time elapsed: 00:34:34
                               ETA: 00:19:42

################################################################################
                     [1m Learning iteration 956/1500 [0m                      

                       Computation: 47597 steps/s (collection: 1.917s, learning 0.148s)
             Mean action noise std: 3.00
          Mean value_function loss: 81.6144
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 54.2919
                       Mean reward: 682.64
               Mean episode length: 234.45
    Episode_Reward/reaching_object: 1.0614
    Episode_Reward/rotating_object: 136.2527
        Episode_Reward/action_rate: -0.0456
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 2.07s
                      Time elapsed: 00:34:36
                               ETA: 00:19:40

################################################################################
                     [1m Learning iteration 957/1500 [0m                      

                       Computation: 46823 steps/s (collection: 1.944s, learning 0.155s)
             Mean action noise std: 3.00
          Mean value_function loss: 68.9157
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 54.3089
                       Mean reward: 717.00
               Mean episode length: 239.81
    Episode_Reward/reaching_object: 1.0843
    Episode_Reward/rotating_object: 141.8339
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 2.10s
                      Time elapsed: 00:34:38
                               ETA: 00:19:38

################################################################################
                     [1m Learning iteration 958/1500 [0m                      

                       Computation: 46582 steps/s (collection: 1.991s, learning 0.119s)
             Mean action noise std: 3.00
          Mean value_function loss: 62.9183
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 54.3185
                       Mean reward: 697.95
               Mean episode length: 234.04
    Episode_Reward/reaching_object: 1.0851
    Episode_Reward/rotating_object: 141.8359
        Episode_Reward/action_rate: -0.0468
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 2.11s
                      Time elapsed: 00:34:40
                               ETA: 00:19:35

################################################################################
                     [1m Learning iteration 959/1500 [0m                      

                       Computation: 47120 steps/s (collection: 1.945s, learning 0.142s)
             Mean action noise std: 3.00
          Mean value_function loss: 61.8502
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 54.3239
                       Mean reward: 728.53
               Mean episode length: 240.30
    Episode_Reward/reaching_object: 1.0783
    Episode_Reward/rotating_object: 141.3342
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 2.09s
                      Time elapsed: 00:34:42
                               ETA: 00:19:33

################################################################################
                     [1m Learning iteration 960/1500 [0m                      

                       Computation: 47562 steps/s (collection: 1.968s, learning 0.099s)
             Mean action noise std: 3.01
          Mean value_function loss: 73.6471
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 54.3326
                       Mean reward: 699.16
               Mean episode length: 232.88
    Episode_Reward/reaching_object: 1.0908
    Episode_Reward/rotating_object: 142.7723
        Episode_Reward/action_rate: -0.0472
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 2.07s
                      Time elapsed: 00:34:44
                               ETA: 00:19:31

################################################################################
                     [1m Learning iteration 961/1500 [0m                      

                       Computation: 48111 steps/s (collection: 1.929s, learning 0.114s)
             Mean action noise std: 3.01
          Mean value_function loss: 73.2171
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 54.3428
                       Mean reward: 669.80
               Mean episode length: 230.58
    Episode_Reward/reaching_object: 1.0700
    Episode_Reward/rotating_object: 137.5272
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 2.04s
                      Time elapsed: 00:34:46
                               ETA: 00:19:29

################################################################################
                     [1m Learning iteration 962/1500 [0m                      

                       Computation: 48211 steps/s (collection: 1.939s, learning 0.100s)
             Mean action noise std: 3.01
          Mean value_function loss: 76.4251
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 54.3701
                       Mean reward: 704.08
               Mean episode length: 237.67
    Episode_Reward/reaching_object: 1.0560
    Episode_Reward/rotating_object: 137.9961
        Episode_Reward/action_rate: -0.0459
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 2.04s
                      Time elapsed: 00:34:48
                               ETA: 00:19:27

################################################################################
                     [1m Learning iteration 963/1500 [0m                      

                       Computation: 45764 steps/s (collection: 1.950s, learning 0.198s)
             Mean action noise std: 3.01
          Mean value_function loss: 74.4912
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 54.3914
                       Mean reward: 741.08
               Mean episode length: 241.06
    Episode_Reward/reaching_object: 1.0801
    Episode_Reward/rotating_object: 142.0755
        Episode_Reward/action_rate: -0.0470
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 2.15s
                      Time elapsed: 00:34:51
                               ETA: 00:19:24

################################################################################
                     [1m Learning iteration 964/1500 [0m                      

                       Computation: 43190 steps/s (collection: 2.135s, learning 0.141s)
             Mean action noise std: 3.02
          Mean value_function loss: 75.0454
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 54.4086
                       Mean reward: 690.85
               Mean episode length: 240.60
    Episode_Reward/reaching_object: 1.0724
    Episode_Reward/rotating_object: 139.6025
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 2.28s
                      Time elapsed: 00:34:53
                               ETA: 00:19:22

################################################################################
                     [1m Learning iteration 965/1500 [0m                      

                       Computation: 46966 steps/s (collection: 2.000s, learning 0.094s)
             Mean action noise std: 3.02
          Mean value_function loss: 74.6934
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 54.4258
                       Mean reward: 704.48
               Mean episode length: 233.54
    Episode_Reward/reaching_object: 1.0808
    Episode_Reward/rotating_object: 142.1366
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 2.09s
                      Time elapsed: 00:34:55
                               ETA: 00:19:20

################################################################################
                     [1m Learning iteration 966/1500 [0m                      

                       Computation: 47178 steps/s (collection: 1.983s, learning 0.101s)
             Mean action noise std: 3.02
          Mean value_function loss: 56.9656
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 54.4430
                       Mean reward: 689.46
               Mean episode length: 239.65
    Episode_Reward/reaching_object: 1.0638
    Episode_Reward/rotating_object: 137.5628
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 2.08s
                      Time elapsed: 00:34:57
                               ETA: 00:19:18

################################################################################
                     [1m Learning iteration 967/1500 [0m                      

                       Computation: 43637 steps/s (collection: 2.144s, learning 0.109s)
             Mean action noise std: 3.03
          Mean value_function loss: 69.2835
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 54.4641
                       Mean reward: 647.76
               Mean episode length: 224.27
    Episode_Reward/reaching_object: 1.0710
    Episode_Reward/rotating_object: 139.2078
        Episode_Reward/action_rate: -0.0472
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 2.25s
                      Time elapsed: 00:34:59
                               ETA: 00:19:16

################################################################################
                     [1m Learning iteration 968/1500 [0m                      

                       Computation: 38439 steps/s (collection: 2.289s, learning 0.268s)
             Mean action noise std: 3.03
          Mean value_function loss: 90.7497
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 54.4781
                       Mean reward: 716.20
               Mean episode length: 235.63
    Episode_Reward/reaching_object: 1.0680
    Episode_Reward/rotating_object: 140.5361
        Episode_Reward/action_rate: -0.0471
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 2.56s
                      Time elapsed: 00:35:02
                               ETA: 00:19:14

################################################################################
                     [1m Learning iteration 969/1500 [0m                      

                       Computation: 41383 steps/s (collection: 2.250s, learning 0.126s)
             Mean action noise std: 3.03
          Mean value_function loss: 64.6092
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 54.4872
                       Mean reward: 742.79
               Mean episode length: 237.85
    Episode_Reward/reaching_object: 1.0759
    Episode_Reward/rotating_object: 141.7487
        Episode_Reward/action_rate: -0.0475
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 2.38s
                      Time elapsed: 00:35:04
                               ETA: 00:19:12

################################################################################
                     [1m Learning iteration 970/1500 [0m                      

                       Computation: 43823 steps/s (collection: 2.145s, learning 0.099s)
             Mean action noise std: 3.03
          Mean value_function loss: 74.6881
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.4940
                       Mean reward: 657.65
               Mean episode length: 224.37
    Episode_Reward/reaching_object: 1.0795
    Episode_Reward/rotating_object: 140.2159
        Episode_Reward/action_rate: -0.0477
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 2.24s
                      Time elapsed: 00:35:06
                               ETA: 00:19:10

################################################################################
                     [1m Learning iteration 971/1500 [0m                      

                       Computation: 45648 steps/s (collection: 2.058s, learning 0.096s)
             Mean action noise std: 3.03
          Mean value_function loss: 71.6000
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 54.5096
                       Mean reward: 671.59
               Mean episode length: 227.96
    Episode_Reward/reaching_object: 1.0782
    Episode_Reward/rotating_object: 140.3325
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 2.15s
                      Time elapsed: 00:35:09
                               ETA: 00:19:07

################################################################################
                     [1m Learning iteration 972/1500 [0m                      

                       Computation: 49112 steps/s (collection: 1.898s, learning 0.104s)
             Mean action noise std: 3.04
          Mean value_function loss: 66.7115
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 54.5284
                       Mean reward: 713.42
               Mean episode length: 236.59
    Episode_Reward/reaching_object: 1.0763
    Episode_Reward/rotating_object: 140.9557
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 2.00s
                      Time elapsed: 00:35:11
                               ETA: 00:19:05

################################################################################
                     [1m Learning iteration 973/1500 [0m                      

                       Computation: 44087 steps/s (collection: 2.081s, learning 0.149s)
             Mean action noise std: 3.04
          Mean value_function loss: 60.1397
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 54.5467
                       Mean reward: 727.57
               Mean episode length: 237.88
    Episode_Reward/reaching_object: 1.0809
    Episode_Reward/rotating_object: 141.1179
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 2.23s
                      Time elapsed: 00:35:13
                               ETA: 00:19:03

################################################################################
                     [1m Learning iteration 974/1500 [0m                      

                       Computation: 42193 steps/s (collection: 2.161s, learning 0.169s)
             Mean action noise std: 3.04
          Mean value_function loss: 74.0243
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 54.5612
                       Mean reward: 723.74
               Mean episode length: 242.26
    Episode_Reward/reaching_object: 1.0937
    Episode_Reward/rotating_object: 143.3006
        Episode_Reward/action_rate: -0.0485
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 2.33s
                      Time elapsed: 00:35:15
                               ETA: 00:19:01

################################################################################
                     [1m Learning iteration 975/1500 [0m                      

                       Computation: 43239 steps/s (collection: 2.109s, learning 0.165s)
             Mean action noise std: 3.04
          Mean value_function loss: 68.2857
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 54.5732
                       Mean reward: 742.81
               Mean episode length: 238.04
    Episode_Reward/reaching_object: 1.0747
    Episode_Reward/rotating_object: 144.3249
        Episode_Reward/action_rate: -0.0482
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 2.27s
                      Time elapsed: 00:35:17
                               ETA: 00:18:59

################################################################################
                     [1m Learning iteration 976/1500 [0m                      

                       Computation: 39116 steps/s (collection: 2.282s, learning 0.231s)
             Mean action noise std: 3.05
          Mean value_function loss: 61.6332
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 54.5867
                       Mean reward: 691.92
               Mean episode length: 230.16
    Episode_Reward/reaching_object: 1.0805
    Episode_Reward/rotating_object: 143.7737
        Episode_Reward/action_rate: -0.0485
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 2.51s
                      Time elapsed: 00:35:20
                               ETA: 00:18:57

################################################################################
                     [1m Learning iteration 977/1500 [0m                      

                       Computation: 43971 steps/s (collection: 2.087s, learning 0.149s)
             Mean action noise std: 3.05
          Mean value_function loss: 75.2126
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 54.6048
                       Mean reward: 720.13
               Mean episode length: 235.60
    Episode_Reward/reaching_object: 1.0636
    Episode_Reward/rotating_object: 141.9563
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 2.24s
                      Time elapsed: 00:35:22
                               ETA: 00:18:55

################################################################################
                     [1m Learning iteration 978/1500 [0m                      

                       Computation: 45695 steps/s (collection: 1.983s, learning 0.169s)
             Mean action noise std: 3.05
          Mean value_function loss: 78.9605
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 54.6377
                       Mean reward: 705.37
               Mean episode length: 232.92
    Episode_Reward/reaching_object: 1.0445
    Episode_Reward/rotating_object: 136.7450
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 2.15s
                      Time elapsed: 00:35:24
                               ETA: 00:18:52

################################################################################
                     [1m Learning iteration 979/1500 [0m                      

                       Computation: 45415 steps/s (collection: 2.066s, learning 0.099s)
             Mean action noise std: 3.06
          Mean value_function loss: 70.7185
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 54.6646
                       Mean reward: 705.67
               Mean episode length: 234.03
    Episode_Reward/reaching_object: 1.0639
    Episode_Reward/rotating_object: 141.3921
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 2.16s
                      Time elapsed: 00:35:27
                               ETA: 00:18:50

################################################################################
                     [1m Learning iteration 980/1500 [0m                      

                       Computation: 45934 steps/s (collection: 1.978s, learning 0.162s)
             Mean action noise std: 3.06
          Mean value_function loss: 70.0415
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 54.6864
                       Mean reward: 679.59
               Mean episode length: 229.29
    Episode_Reward/reaching_object: 1.0715
    Episode_Reward/rotating_object: 141.2740
        Episode_Reward/action_rate: -0.0485
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 2.14s
                      Time elapsed: 00:35:29
                               ETA: 00:18:48

################################################################################
                     [1m Learning iteration 981/1500 [0m                      

                       Computation: 46382 steps/s (collection: 1.945s, learning 0.175s)
             Mean action noise std: 3.06
          Mean value_function loss: 71.7004
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 54.7040
                       Mean reward: 712.62
               Mean episode length: 235.95
    Episode_Reward/reaching_object: 1.0662
    Episode_Reward/rotating_object: 142.6772
        Episode_Reward/action_rate: -0.0482
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 2.12s
                      Time elapsed: 00:35:31
                               ETA: 00:18:46

################################################################################
                     [1m Learning iteration 982/1500 [0m                      

                       Computation: 46335 steps/s (collection: 1.993s, learning 0.129s)
             Mean action noise std: 3.07
          Mean value_function loss: 73.6312
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 54.7261
                       Mean reward: 704.53
               Mean episode length: 236.52
    Episode_Reward/reaching_object: 1.0604
    Episode_Reward/rotating_object: 142.0204
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 2.12s
                      Time elapsed: 00:35:33
                               ETA: 00:18:44

################################################################################
                     [1m Learning iteration 983/1500 [0m                      

                       Computation: 40200 steps/s (collection: 2.210s, learning 0.236s)
             Mean action noise std: 3.07
          Mean value_function loss: 71.1501
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 54.7448
                       Mean reward: 712.13
               Mean episode length: 234.59
    Episode_Reward/reaching_object: 1.0857
    Episode_Reward/rotating_object: 146.5621
        Episode_Reward/action_rate: -0.0495
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 2.45s
                      Time elapsed: 00:35:35
                               ETA: 00:18:42

################################################################################
                     [1m Learning iteration 984/1500 [0m                      

                       Computation: 43354 steps/s (collection: 2.098s, learning 0.169s)
             Mean action noise std: 3.07
          Mean value_function loss: 66.7851
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 54.7602
                       Mean reward: 731.37
               Mean episode length: 238.13
    Episode_Reward/reaching_object: 1.0804
    Episode_Reward/rotating_object: 142.5748
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 2.27s
                      Time elapsed: 00:35:38
                               ETA: 00:18:40

################################################################################
                     [1m Learning iteration 985/1500 [0m                      

                       Computation: 41575 steps/s (collection: 2.174s, learning 0.191s)
             Mean action noise std: 3.07
          Mean value_function loss: 77.9603
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 54.7732
                       Mean reward: 703.97
               Mean episode length: 231.17
    Episode_Reward/reaching_object: 1.0553
    Episode_Reward/rotating_object: 140.5834
        Episode_Reward/action_rate: -0.0484
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 2.36s
                      Time elapsed: 00:35:40
                               ETA: 00:18:38

################################################################################
                     [1m Learning iteration 986/1500 [0m                      

                       Computation: 47539 steps/s (collection: 1.955s, learning 0.113s)
             Mean action noise std: 3.08
          Mean value_function loss: 64.5419
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 54.7962
                       Mean reward: 739.36
               Mean episode length: 246.37
    Episode_Reward/reaching_object: 1.0601
    Episode_Reward/rotating_object: 141.2596
        Episode_Reward/action_rate: -0.0490
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 2.07s
                      Time elapsed: 00:35:42
                               ETA: 00:18:35

################################################################################
                     [1m Learning iteration 987/1500 [0m                      

                       Computation: 46899 steps/s (collection: 1.969s, learning 0.127s)
             Mean action noise std: 3.08
          Mean value_function loss: 57.0433
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 54.8142
                       Mean reward: 730.05
               Mean episode length: 240.41
    Episode_Reward/reaching_object: 1.0905
    Episode_Reward/rotating_object: 146.3771
        Episode_Reward/action_rate: -0.0501
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 2.10s
                      Time elapsed: 00:35:44
                               ETA: 00:18:33

################################################################################
                     [1m Learning iteration 988/1500 [0m                      

                       Computation: 47344 steps/s (collection: 1.921s, learning 0.156s)
             Mean action noise std: 3.08
          Mean value_function loss: 58.2460
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 54.8311
                       Mean reward: 724.86
               Mean episode length: 241.22
    Episode_Reward/reaching_object: 1.0836
    Episode_Reward/rotating_object: 147.9913
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 2.08s
                      Time elapsed: 00:35:46
                               ETA: 00:18:31

################################################################################
                     [1m Learning iteration 989/1500 [0m                      

                       Computation: 45948 steps/s (collection: 1.975s, learning 0.165s)
             Mean action noise std: 3.09
          Mean value_function loss: 71.7870
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 54.8580
                       Mean reward: 699.75
               Mean episode length: 233.80
    Episode_Reward/reaching_object: 1.0489
    Episode_Reward/rotating_object: 141.5664
        Episode_Reward/action_rate: -0.0486
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 2.14s
                      Time elapsed: 00:35:48
                               ETA: 00:18:29

################################################################################
                     [1m Learning iteration 990/1500 [0m                      

                       Computation: 47103 steps/s (collection: 1.953s, learning 0.134s)
             Mean action noise std: 3.09
          Mean value_function loss: 56.8917
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 54.8902
                       Mean reward: 702.29
               Mean episode length: 234.25
    Episode_Reward/reaching_object: 1.0771
    Episode_Reward/rotating_object: 144.7458
        Episode_Reward/action_rate: -0.0500
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 2.09s
                      Time elapsed: 00:35:50
                               ETA: 00:18:26

################################################################################
                     [1m Learning iteration 991/1500 [0m                      

                       Computation: 46556 steps/s (collection: 1.990s, learning 0.121s)
             Mean action noise std: 3.09
          Mean value_function loss: 64.5353
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 54.9101
                       Mean reward: 700.39
               Mean episode length: 234.84
    Episode_Reward/reaching_object: 1.0551
    Episode_Reward/rotating_object: 138.6509
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 2.11s
                      Time elapsed: 00:35:53
                               ETA: 00:18:24

################################################################################
                     [1m Learning iteration 992/1500 [0m                      

                       Computation: 46708 steps/s (collection: 1.989s, learning 0.115s)
             Mean action noise std: 3.09
          Mean value_function loss: 73.9573
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 54.9254
                       Mean reward: 668.54
               Mean episode length: 231.48
    Episode_Reward/reaching_object: 1.0558
    Episode_Reward/rotating_object: 136.0195
        Episode_Reward/action_rate: -0.0490
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 2.10s
                      Time elapsed: 00:35:55
                               ETA: 00:18:22

################################################################################
                     [1m Learning iteration 993/1500 [0m                      

                       Computation: 45285 steps/s (collection: 1.999s, learning 0.172s)
             Mean action noise std: 3.10
          Mean value_function loss: 72.1824
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 54.9430
                       Mean reward: 708.45
               Mean episode length: 235.74
    Episode_Reward/reaching_object: 1.0659
    Episode_Reward/rotating_object: 139.8286
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 2.17s
                      Time elapsed: 00:35:57
                               ETA: 00:18:20

################################################################################
                     [1m Learning iteration 994/1500 [0m                      

                       Computation: 46932 steps/s (collection: 1.963s, learning 0.132s)
             Mean action noise std: 3.10
          Mean value_function loss: 63.4899
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.9561
                       Mean reward: 747.47
               Mean episode length: 244.00
    Episode_Reward/reaching_object: 1.0618
    Episode_Reward/rotating_object: 139.1638
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 2.09s
                      Time elapsed: 00:35:59
                               ETA: 00:18:18

################################################################################
                     [1m Learning iteration 995/1500 [0m                      

                       Computation: 48587 steps/s (collection: 1.917s, learning 0.107s)
             Mean action noise std: 3.10
          Mean value_function loss: 75.5290
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 54.9799
                       Mean reward: 721.86
               Mean episode length: 240.15
    Episode_Reward/reaching_object: 1.0788
    Episode_Reward/rotating_object: 142.5889
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 2.02s
                      Time elapsed: 00:36:01
                               ETA: 00:18:15

################################################################################
                     [1m Learning iteration 996/1500 [0m                      

                       Computation: 47195 steps/s (collection: 1.938s, learning 0.145s)
             Mean action noise std: 3.11
          Mean value_function loss: 72.2662
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 54.9943
                       Mean reward: 728.20
               Mean episode length: 236.63
    Episode_Reward/reaching_object: 1.0806
    Episode_Reward/rotating_object: 146.6010
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 2.08s
                      Time elapsed: 00:36:03
                               ETA: 00:18:13

################################################################################
                     [1m Learning iteration 997/1500 [0m                      

                       Computation: 44243 steps/s (collection: 2.003s, learning 0.219s)
             Mean action noise std: 3.11
          Mean value_function loss: 61.5913
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 55.0093
                       Mean reward: 710.78
               Mean episode length: 232.90
    Episode_Reward/reaching_object: 1.0603
    Episode_Reward/rotating_object: 141.8431
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 2.22s
                      Time elapsed: 00:36:05
                               ETA: 00:18:11

################################################################################
                     [1m Learning iteration 998/1500 [0m                      

                       Computation: 44554 steps/s (collection: 2.084s, learning 0.122s)
             Mean action noise std: 3.11
          Mean value_function loss: 77.4333
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 55.0355
                       Mean reward: 706.69
               Mean episode length: 232.15
    Episode_Reward/reaching_object: 1.0509
    Episode_Reward/rotating_object: 140.5735
        Episode_Reward/action_rate: -0.0492
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 2.21s
                      Time elapsed: 00:36:07
                               ETA: 00:18:09

################################################################################
                     [1m Learning iteration 999/1500 [0m                      

                       Computation: 47286 steps/s (collection: 1.978s, learning 0.101s)
             Mean action noise std: 3.11
          Mean value_function loss: 75.9114
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 55.0572
                       Mean reward: 752.83
               Mean episode length: 238.42
    Episode_Reward/reaching_object: 1.0497
    Episode_Reward/rotating_object: 139.5234
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 2.08s
                      Time elapsed: 00:36:10
                               ETA: 00:18:07

################################################################################
                     [1m Learning iteration 1000/1500 [0m                     

                       Computation: 14242 steps/s (collection: 6.724s, learning 0.178s)
             Mean action noise std: 3.12
          Mean value_function loss: 80.7755
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.0744
                       Mean reward: 696.70
               Mean episode length: 228.82
    Episode_Reward/reaching_object: 1.0462
    Episode_Reward/rotating_object: 139.2111
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 6.90s
                      Time elapsed: 00:36:16
                               ETA: 00:18:07

################################################################################
                     [1m Learning iteration 1001/1500 [0m                     

                       Computation: 14562 steps/s (collection: 6.623s, learning 0.127s)
             Mean action noise std: 3.12
          Mean value_function loss: 73.0802
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 55.0973
                       Mean reward: 751.35
               Mean episode length: 244.49
    Episode_Reward/reaching_object: 1.0390
    Episode_Reward/rotating_object: 136.5774
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 6.75s
                      Time elapsed: 00:36:23
                               ETA: 00:18:07

################################################################################
                     [1m Learning iteration 1002/1500 [0m                     

                       Computation: 14498 steps/s (collection: 6.662s, learning 0.118s)
             Mean action noise std: 3.12
          Mean value_function loss: 84.1360
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 55.1208
                       Mean reward: 745.08
               Mean episode length: 239.63
    Episode_Reward/reaching_object: 1.0498
    Episode_Reward/rotating_object: 138.2824
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 6.78s
                      Time elapsed: 00:36:30
                               ETA: 00:18:07

################################################################################
                     [1m Learning iteration 1003/1500 [0m                     

                       Computation: 14521 steps/s (collection: 6.643s, learning 0.127s)
             Mean action noise std: 3.13
          Mean value_function loss: 80.1207
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 55.1425
                       Mean reward: 671.26
               Mean episode length: 223.75
    Episode_Reward/reaching_object: 1.0746
    Episode_Reward/rotating_object: 144.3378
        Episode_Reward/action_rate: -0.0504
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 6.77s
                      Time elapsed: 00:36:37
                               ETA: 00:18:07

################################################################################
                     [1m Learning iteration 1004/1500 [0m                     

                       Computation: 14416 steps/s (collection: 6.646s, learning 0.173s)
             Mean action noise std: 3.13
          Mean value_function loss: 77.2307
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 55.1586
                       Mean reward: 713.09
               Mean episode length: 233.03
    Episode_Reward/reaching_object: 1.0507
    Episode_Reward/rotating_object: 139.1896
        Episode_Reward/action_rate: -0.0495
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 6.82s
                      Time elapsed: 00:36:44
                               ETA: 00:18:07

################################################################################
                     [1m Learning iteration 1005/1500 [0m                     

                       Computation: 14306 steps/s (collection: 6.727s, learning 0.144s)
             Mean action noise std: 3.13
          Mean value_function loss: 77.8220
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 55.1799
                       Mean reward: 681.33
               Mean episode length: 229.41
    Episode_Reward/reaching_object: 1.0601
    Episode_Reward/rotating_object: 139.5533
        Episode_Reward/action_rate: -0.0500
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 6.87s
                      Time elapsed: 00:36:50
                               ETA: 00:18:07

################################################################################
                     [1m Learning iteration 1006/1500 [0m                     

                       Computation: 14601 steps/s (collection: 6.605s, learning 0.127s)
             Mean action noise std: 3.14
          Mean value_function loss: 80.7702
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 55.1952
                       Mean reward: 707.28
               Mean episode length: 231.66
    Episode_Reward/reaching_object: 1.0449
    Episode_Reward/rotating_object: 137.4138
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 6.73s
                      Time elapsed: 00:36:57
                               ETA: 00:18:07

################################################################################
                     [1m Learning iteration 1007/1500 [0m                     

                       Computation: 14498 steps/s (collection: 6.654s, learning 0.126s)
             Mean action noise std: 3.14
          Mean value_function loss: 69.4107
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 55.2109
                       Mean reward: 706.06
               Mean episode length: 239.59
    Episode_Reward/reaching_object: 1.0752
    Episode_Reward/rotating_object: 139.4129
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 6.78s
                      Time elapsed: 00:37:04
                               ETA: 00:18:07

################################################################################
                     [1m Learning iteration 1008/1500 [0m                     

                       Computation: 16914 steps/s (collection: 5.683s, learning 0.129s)
             Mean action noise std: 3.14
          Mean value_function loss: 73.6134
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 55.2218
                       Mean reward: 702.47
               Mean episode length: 233.34
    Episode_Reward/reaching_object: 1.0697
    Episode_Reward/rotating_object: 140.6976
        Episode_Reward/action_rate: -0.0504
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 5.81s
                      Time elapsed: 00:37:10
                               ETA: 00:18:07

################################################################################
                     [1m Learning iteration 1009/1500 [0m                     

                       Computation: 52379 steps/s (collection: 1.787s, learning 0.089s)
             Mean action noise std: 3.14
          Mean value_function loss: 69.5651
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 55.2324
                       Mean reward: 672.03
               Mean episode length: 229.26
    Episode_Reward/reaching_object: 1.0374
    Episode_Reward/rotating_object: 136.5997
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 1.88s
                      Time elapsed: 00:37:12
                               ETA: 00:18:05

################################################################################
                     [1m Learning iteration 1010/1500 [0m                     

                       Computation: 51365 steps/s (collection: 1.799s, learning 0.115s)
             Mean action noise std: 3.15
          Mean value_function loss: 76.9113
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 55.2502
                       Mean reward: 743.23
               Mean episode length: 240.20
    Episode_Reward/reaching_object: 1.0691
    Episode_Reward/rotating_object: 142.5989
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 1.91s
                      Time elapsed: 00:37:14
                               ETA: 00:18:02

################################################################################
                     [1m Learning iteration 1011/1500 [0m                     

                       Computation: 51358 steps/s (collection: 1.803s, learning 0.111s)
             Mean action noise std: 3.15
          Mean value_function loss: 63.9443
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 55.2690
                       Mean reward: 731.07
               Mean episode length: 237.35
    Episode_Reward/reaching_object: 1.0773
    Episode_Reward/rotating_object: 144.4857
        Episode_Reward/action_rate: -0.0509
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 1.91s
                      Time elapsed: 00:37:15
                               ETA: 00:18:00

################################################################################
                     [1m Learning iteration 1012/1500 [0m                     

                       Computation: 51288 steps/s (collection: 1.822s, learning 0.094s)
             Mean action noise std: 3.15
          Mean value_function loss: 69.7472
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 55.2794
                       Mean reward: 726.47
               Mean episode length: 242.56
    Episode_Reward/reaching_object: 1.0898
    Episode_Reward/rotating_object: 145.1589
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 1.92s
                      Time elapsed: 00:37:17
                               ETA: 00:17:58

################################################################################
                     [1m Learning iteration 1013/1500 [0m                     

                       Computation: 52225 steps/s (collection: 1.779s, learning 0.103s)
             Mean action noise std: 3.15
          Mean value_function loss: 80.6004
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.2903
                       Mean reward: 700.53
               Mean episode length: 231.46
    Episode_Reward/reaching_object: 1.0594
    Episode_Reward/rotating_object: 140.8421
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 1.88s
                      Time elapsed: 00:37:19
                               ETA: 00:17:55

################################################################################
                     [1m Learning iteration 1014/1500 [0m                     

                       Computation: 51609 steps/s (collection: 1.805s, learning 0.100s)
             Mean action noise std: 3.15
          Mean value_function loss: 75.1547
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 55.3095
                       Mean reward: 762.17
               Mean episode length: 240.81
    Episode_Reward/reaching_object: 1.0831
    Episode_Reward/rotating_object: 144.7107
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 1.90s
                      Time elapsed: 00:37:21
                               ETA: 00:17:53

################################################################################
                     [1m Learning iteration 1015/1500 [0m                     

                       Computation: 51334 steps/s (collection: 1.828s, learning 0.087s)
             Mean action noise std: 3.16
          Mean value_function loss: 71.7999
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 55.3218
                       Mean reward: 691.24
               Mean episode length: 226.61
    Episode_Reward/reaching_object: 1.0541
    Episode_Reward/rotating_object: 139.4191
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 1.91s
                      Time elapsed: 00:37:23
                               ETA: 00:17:51

################################################################################
                     [1m Learning iteration 1016/1500 [0m                     

                       Computation: 50143 steps/s (collection: 1.870s, learning 0.091s)
             Mean action noise std: 3.16
          Mean value_function loss: 66.5684
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 55.3346
                       Mean reward: 704.33
               Mean episode length: 234.00
    Episode_Reward/reaching_object: 1.0910
    Episode_Reward/rotating_object: 145.3871
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 1.96s
                      Time elapsed: 00:37:25
                               ETA: 00:17:48

################################################################################
                     [1m Learning iteration 1017/1500 [0m                     

                       Computation: 52134 steps/s (collection: 1.797s, learning 0.089s)
             Mean action noise std: 3.16
          Mean value_function loss: 68.4534
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 55.3470
                       Mean reward: 732.37
               Mean episode length: 238.89
    Episode_Reward/reaching_object: 1.0755
    Episode_Reward/rotating_object: 143.7928
        Episode_Reward/action_rate: -0.0514
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 1.89s
                      Time elapsed: 00:37:27
                               ETA: 00:17:46

################################################################################
                     [1m Learning iteration 1018/1500 [0m                     

                       Computation: 51768 steps/s (collection: 1.809s, learning 0.090s)
             Mean action noise std: 3.16
          Mean value_function loss: 72.0074
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 55.3605
                       Mean reward: 702.14
               Mean episode length: 230.62
    Episode_Reward/reaching_object: 1.0461
    Episode_Reward/rotating_object: 138.8886
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 1.90s
                      Time elapsed: 00:37:29
                               ETA: 00:17:43

################################################################################
                     [1m Learning iteration 1019/1500 [0m                     

                       Computation: 50636 steps/s (collection: 1.816s, learning 0.125s)
             Mean action noise std: 3.16
          Mean value_function loss: 51.7575
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 55.3715
                       Mean reward: 765.35
               Mean episode length: 243.11
    Episode_Reward/reaching_object: 1.0907
    Episode_Reward/rotating_object: 145.9579
        Episode_Reward/action_rate: -0.0522
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 1.94s
                      Time elapsed: 00:37:31
                               ETA: 00:17:41

################################################################################
                     [1m Learning iteration 1020/1500 [0m                     

                       Computation: 50393 steps/s (collection: 1.840s, learning 0.111s)
             Mean action noise std: 3.17
          Mean value_function loss: 50.0807
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 55.3855
                       Mean reward: 755.75
               Mean episode length: 241.63
    Episode_Reward/reaching_object: 1.0831
    Episode_Reward/rotating_object: 144.7931
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 1.95s
                      Time elapsed: 00:37:33
                               ETA: 00:17:39

################################################################################
                     [1m Learning iteration 1021/1500 [0m                     

                       Computation: 51159 steps/s (collection: 1.780s, learning 0.141s)
             Mean action noise std: 3.17
          Mean value_function loss: 73.2406
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 55.4016
                       Mean reward: 755.34
               Mean episode length: 241.38
    Episode_Reward/reaching_object: 1.0906
    Episode_Reward/rotating_object: 147.7926
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 1.92s
                      Time elapsed: 00:37:35
                               ETA: 00:17:36

################################################################################
                     [1m Learning iteration 1022/1500 [0m                     

                       Computation: 51017 steps/s (collection: 1.800s, learning 0.127s)
             Mean action noise std: 3.17
          Mean value_function loss: 73.8590
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.4165
                       Mean reward: 704.17
               Mean episode length: 226.87
    Episode_Reward/reaching_object: 1.0658
    Episode_Reward/rotating_object: 141.7036
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 1.93s
                      Time elapsed: 00:37:37
                               ETA: 00:17:34

################################################################################
                     [1m Learning iteration 1023/1500 [0m                     

                       Computation: 50749 steps/s (collection: 1.831s, learning 0.107s)
             Mean action noise std: 3.17
          Mean value_function loss: 73.0180
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 55.4315
                       Mean reward: 739.54
               Mean episode length: 243.75
    Episode_Reward/reaching_object: 1.0694
    Episode_Reward/rotating_object: 142.1953
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 1.94s
                      Time elapsed: 00:37:39
                               ETA: 00:17:32

################################################################################
                     [1m Learning iteration 1024/1500 [0m                     

                       Computation: 52210 steps/s (collection: 1.786s, learning 0.097s)
             Mean action noise std: 3.18
          Mean value_function loss: 62.3135
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 55.4528
                       Mean reward: 693.62
               Mean episode length: 235.22
    Episode_Reward/reaching_object: 1.0849
    Episode_Reward/rotating_object: 142.9111
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 1.88s
                      Time elapsed: 00:37:40
                               ETA: 00:17:29

################################################################################
                     [1m Learning iteration 1025/1500 [0m                     

                       Computation: 50396 steps/s (collection: 1.825s, learning 0.125s)
             Mean action noise std: 3.18
          Mean value_function loss: 55.5938
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 55.4620
                       Mean reward: 741.31
               Mean episode length: 235.45
    Episode_Reward/reaching_object: 1.0879
    Episode_Reward/rotating_object: 147.1880
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 1.95s
                      Time elapsed: 00:37:42
                               ETA: 00:17:27

################################################################################
                     [1m Learning iteration 1026/1500 [0m                     

                       Computation: 51719 steps/s (collection: 1.809s, learning 0.092s)
             Mean action noise std: 3.18
          Mean value_function loss: 51.1973
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.4713
                       Mean reward: 710.09
               Mean episode length: 238.22
    Episode_Reward/reaching_object: 1.0691
    Episode_Reward/rotating_object: 140.9319
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 1.90s
                      Time elapsed: 00:37:44
                               ETA: 00:17:25

################################################################################
                     [1m Learning iteration 1027/1500 [0m                     

                       Computation: 50803 steps/s (collection: 1.842s, learning 0.093s)
             Mean action noise std: 3.18
          Mean value_function loss: 67.6393
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 55.4818
                       Mean reward: 708.16
               Mean episode length: 240.81
    Episode_Reward/reaching_object: 1.0761
    Episode_Reward/rotating_object: 141.9631
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 1.93s
                      Time elapsed: 00:37:46
                               ETA: 00:17:22

################################################################################
                     [1m Learning iteration 1028/1500 [0m                     

                       Computation: 49019 steps/s (collection: 1.856s, learning 0.149s)
             Mean action noise std: 3.19
          Mean value_function loss: 53.5239
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 55.4979
                       Mean reward: 727.20
               Mean episode length: 234.80
    Episode_Reward/reaching_object: 1.0715
    Episode_Reward/rotating_object: 141.7662
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 2.01s
                      Time elapsed: 00:37:48
                               ETA: 00:17:20

################################################################################
                     [1m Learning iteration 1029/1500 [0m                     

                       Computation: 50079 steps/s (collection: 1.831s, learning 0.132s)
             Mean action noise std: 3.19
          Mean value_function loss: 58.5120
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 55.5171
                       Mean reward: 731.14
               Mean episode length: 234.53
    Episode_Reward/reaching_object: 1.0679
    Episode_Reward/rotating_object: 143.4628
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 1.96s
                      Time elapsed: 00:37:50
                               ETA: 00:17:18

################################################################################
                     [1m Learning iteration 1030/1500 [0m                     

                       Computation: 51060 steps/s (collection: 1.827s, learning 0.099s)
             Mean action noise std: 3.19
          Mean value_function loss: 65.2063
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 55.5342
                       Mean reward: 708.34
               Mean episode length: 234.98
    Episode_Reward/reaching_object: 1.0847
    Episode_Reward/rotating_object: 145.7657
        Episode_Reward/action_rate: -0.0529
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 1.93s
                      Time elapsed: 00:37:52
                               ETA: 00:17:15

################################################################################
                     [1m Learning iteration 1031/1500 [0m                     

                       Computation: 47723 steps/s (collection: 1.967s, learning 0.093s)
             Mean action noise std: 3.19
          Mean value_function loss: 55.3674
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 55.5515
                       Mean reward: 743.62
               Mean episode length: 240.20
    Episode_Reward/reaching_object: 1.0783
    Episode_Reward/rotating_object: 145.2188
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 2.06s
                      Time elapsed: 00:37:54
                               ETA: 00:17:13

################################################################################
                     [1m Learning iteration 1032/1500 [0m                     

                       Computation: 50993 steps/s (collection: 1.819s, learning 0.109s)
             Mean action noise std: 3.20
          Mean value_function loss: 64.6389
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 55.5687
                       Mean reward: 712.47
               Mean episode length: 232.98
    Episode_Reward/reaching_object: 1.0774
    Episode_Reward/rotating_object: 142.6811
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 1.93s
                      Time elapsed: 00:37:56
                               ETA: 00:17:11

################################################################################
                     [1m Learning iteration 1033/1500 [0m                     

                       Computation: 50707 steps/s (collection: 1.829s, learning 0.110s)
             Mean action noise std: 3.20
          Mean value_function loss: 69.7342
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 55.5797
                       Mean reward: 718.03
               Mean episode length: 237.08
    Episode_Reward/reaching_object: 1.0812
    Episode_Reward/rotating_object: 143.3603
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 1.94s
                      Time elapsed: 00:37:58
                               ETA: 00:17:09

################################################################################
                     [1m Learning iteration 1034/1500 [0m                     

                       Computation: 51282 steps/s (collection: 1.808s, learning 0.109s)
             Mean action noise std: 3.20
          Mean value_function loss: 77.9105
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 55.5938
                       Mean reward: 707.91
               Mean episode length: 231.93
    Episode_Reward/reaching_object: 1.0773
    Episode_Reward/rotating_object: 146.4045
        Episode_Reward/action_rate: -0.0528
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 1.92s
                      Time elapsed: 00:38:00
                               ETA: 00:17:06

################################################################################
                     [1m Learning iteration 1035/1500 [0m                     

                       Computation: 51660 steps/s (collection: 1.798s, learning 0.105s)
             Mean action noise std: 3.20
          Mean value_function loss: 81.2970
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 55.6124
                       Mean reward: 727.62
               Mean episode length: 232.38
    Episode_Reward/reaching_object: 1.0751
    Episode_Reward/rotating_object: 144.2852
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 1.90s
                      Time elapsed: 00:38:02
                               ETA: 00:17:04

################################################################################
                     [1m Learning iteration 1036/1500 [0m                     

                       Computation: 51456 steps/s (collection: 1.815s, learning 0.095s)
             Mean action noise std: 3.21
          Mean value_function loss: 79.1498
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 55.6281
                       Mean reward: 693.81
               Mean episode length: 230.74
    Episode_Reward/reaching_object: 1.0640
    Episode_Reward/rotating_object: 140.7529
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 1.91s
                      Time elapsed: 00:38:04
                               ETA: 00:17:02

################################################################################
                     [1m Learning iteration 1037/1500 [0m                     

                       Computation: 49362 steps/s (collection: 1.838s, learning 0.154s)
             Mean action noise std: 3.21
          Mean value_function loss: 71.6363
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 55.6476
                       Mean reward: 723.64
               Mean episode length: 237.57
    Episode_Reward/reaching_object: 1.0538
    Episode_Reward/rotating_object: 141.2070
        Episode_Reward/action_rate: -0.0517
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 1.99s
                      Time elapsed: 00:38:06
                               ETA: 00:16:59

################################################################################
                     [1m Learning iteration 1038/1500 [0m                     

                       Computation: 50619 steps/s (collection: 1.827s, learning 0.115s)
             Mean action noise std: 3.21
          Mean value_function loss: 68.3540
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 55.6693
                       Mean reward: 683.05
               Mean episode length: 233.06
    Episode_Reward/reaching_object: 1.0737
    Episode_Reward/rotating_object: 143.4615
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 1.94s
                      Time elapsed: 00:38:08
                               ETA: 00:16:57

################################################################################
                     [1m Learning iteration 1039/1500 [0m                     

                       Computation: 51446 steps/s (collection: 1.815s, learning 0.096s)
             Mean action noise std: 3.22
          Mean value_function loss: 63.8841
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 55.6849
                       Mean reward: 734.38
               Mean episode length: 236.05
    Episode_Reward/reaching_object: 1.0542
    Episode_Reward/rotating_object: 141.7557
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 1.91s
                      Time elapsed: 00:38:10
                               ETA: 00:16:55

################################################################################
                     [1m Learning iteration 1040/1500 [0m                     

                       Computation: 52908 steps/s (collection: 1.766s, learning 0.092s)
             Mean action noise std: 3.22
          Mean value_function loss: 74.0566
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 55.7020
                       Mean reward: 685.01
               Mean episode length: 226.13
    Episode_Reward/reaching_object: 1.0548
    Episode_Reward/rotating_object: 140.4167
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 1.86s
                      Time elapsed: 00:38:11
                               ETA: 00:16:52

################################################################################
                     [1m Learning iteration 1041/1500 [0m                     

                       Computation: 52334 steps/s (collection: 1.790s, learning 0.088s)
             Mean action noise std: 3.22
          Mean value_function loss: 73.4882
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 55.7190
                       Mean reward: 746.68
               Mean episode length: 240.01
    Episode_Reward/reaching_object: 1.0615
    Episode_Reward/rotating_object: 140.4675
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 1.88s
                      Time elapsed: 00:38:13
                               ETA: 00:16:50

################################################################################
                     [1m Learning iteration 1042/1500 [0m                     

                       Computation: 50191 steps/s (collection: 1.847s, learning 0.112s)
             Mean action noise std: 3.22
          Mean value_function loss: 70.1088
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 55.7381
                       Mean reward: 721.99
               Mean episode length: 234.11
    Episode_Reward/reaching_object: 1.0564
    Episode_Reward/rotating_object: 138.8234
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 1.96s
                      Time elapsed: 00:38:15
                               ETA: 00:16:48

################################################################################
                     [1m Learning iteration 1043/1500 [0m                     

                       Computation: 49311 steps/s (collection: 1.890s, learning 0.104s)
             Mean action noise std: 3.23
          Mean value_function loss: 70.8061
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 55.7559
                       Mean reward: 735.91
               Mean episode length: 242.79
    Episode_Reward/reaching_object: 1.0723
    Episode_Reward/rotating_object: 143.1812
        Episode_Reward/action_rate: -0.0534
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 1.99s
                      Time elapsed: 00:38:17
                               ETA: 00:16:45

################################################################################
                     [1m Learning iteration 1044/1500 [0m                     

                       Computation: 50650 steps/s (collection: 1.850s, learning 0.091s)
             Mean action noise std: 3.23
          Mean value_function loss: 53.7896
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 55.7813
                       Mean reward: 722.56
               Mean episode length: 237.71
    Episode_Reward/reaching_object: 1.0854
    Episode_Reward/rotating_object: 144.2910
        Episode_Reward/action_rate: -0.0536
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 1.94s
                      Time elapsed: 00:38:19
                               ETA: 00:16:43

################################################################################
                     [1m Learning iteration 1045/1500 [0m                     

                       Computation: 50249 steps/s (collection: 1.860s, learning 0.097s)
             Mean action noise std: 3.24
          Mean value_function loss: 65.1606
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 55.8106
                       Mean reward: 748.52
               Mean episode length: 238.83
    Episode_Reward/reaching_object: 1.0833
    Episode_Reward/rotating_object: 145.3806
        Episode_Reward/action_rate: -0.0535
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 1.96s
                      Time elapsed: 00:38:21
                               ETA: 00:16:41

################################################################################
                     [1m Learning iteration 1046/1500 [0m                     

                       Computation: 49186 steps/s (collection: 1.871s, learning 0.128s)
             Mean action noise std: 3.24
          Mean value_function loss: 67.7118
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 55.8323
                       Mean reward: 696.99
               Mean episode length: 233.86
    Episode_Reward/reaching_object: 1.0915
    Episode_Reward/rotating_object: 145.2165
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 2.00s
                      Time elapsed: 00:38:23
                               ETA: 00:16:38

################################################################################
                     [1m Learning iteration 1047/1500 [0m                     

                       Computation: 49448 steps/s (collection: 1.898s, learning 0.090s)
             Mean action noise std: 3.24
          Mean value_function loss: 69.1023
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 55.8458
                       Mean reward: 754.91
               Mean episode length: 239.98
    Episode_Reward/reaching_object: 1.0800
    Episode_Reward/rotating_object: 143.6690
        Episode_Reward/action_rate: -0.0536
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 1.99s
                      Time elapsed: 00:38:25
                               ETA: 00:16:36

################################################################################
                     [1m Learning iteration 1048/1500 [0m                     

                       Computation: 50759 steps/s (collection: 1.830s, learning 0.107s)
             Mean action noise std: 3.24
          Mean value_function loss: 64.7522
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 55.8667
                       Mean reward: 762.65
               Mean episode length: 240.22
    Episode_Reward/reaching_object: 1.0770
    Episode_Reward/rotating_object: 143.4883
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 1.94s
                      Time elapsed: 00:38:27
                               ETA: 00:16:34

################################################################################
                     [1m Learning iteration 1049/1500 [0m                     

                       Computation: 50731 steps/s (collection: 1.827s, learning 0.111s)
             Mean action noise std: 3.25
          Mean value_function loss: 74.2670
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 55.8872
                       Mean reward: 709.65
               Mean episode length: 232.63
    Episode_Reward/reaching_object: 1.0734
    Episode_Reward/rotating_object: 142.9278
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 1.94s
                      Time elapsed: 00:38:29
                               ETA: 00:16:31

################################################################################
                     [1m Learning iteration 1050/1500 [0m                     

                       Computation: 49438 steps/s (collection: 1.879s, learning 0.110s)
             Mean action noise std: 3.25
          Mean value_function loss: 66.9867
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 55.9039
                       Mean reward: 719.78
               Mean episode length: 237.36
    Episode_Reward/reaching_object: 1.0812
    Episode_Reward/rotating_object: 142.8009
        Episode_Reward/action_rate: -0.0544
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 1.99s
                      Time elapsed: 00:38:31
                               ETA: 00:16:29

################################################################################
                     [1m Learning iteration 1051/1500 [0m                     

                       Computation: 45733 steps/s (collection: 2.019s, learning 0.131s)
             Mean action noise std: 3.25
          Mean value_function loss: 72.3862
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 55.9231
                       Mean reward: 703.68
               Mean episode length: 230.17
    Episode_Reward/reaching_object: 1.0680
    Episode_Reward/rotating_object: 142.2420
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 2.15s
                      Time elapsed: 00:38:33
                               ETA: 00:16:27

################################################################################
                     [1m Learning iteration 1052/1500 [0m                     

                       Computation: 47364 steps/s (collection: 1.985s, learning 0.091s)
             Mean action noise std: 3.26
          Mean value_function loss: 68.0947
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 55.9457
                       Mean reward: 730.37
               Mean episode length: 236.52
    Episode_Reward/reaching_object: 1.0786
    Episode_Reward/rotating_object: 143.4233
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 2.08s
                      Time elapsed: 00:38:35
                               ETA: 00:16:25

################################################################################
                     [1m Learning iteration 1053/1500 [0m                     

                       Computation: 51302 steps/s (collection: 1.821s, learning 0.096s)
             Mean action noise std: 3.26
          Mean value_function loss: 76.3752
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 55.9729
                       Mean reward: 747.00
               Mean episode length: 238.03
    Episode_Reward/reaching_object: 1.0586
    Episode_Reward/rotating_object: 139.1725
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 1.92s
                      Time elapsed: 00:38:37
                               ETA: 00:16:22

################################################################################
                     [1m Learning iteration 1054/1500 [0m                     

                       Computation: 44506 steps/s (collection: 1.971s, learning 0.238s)
             Mean action noise std: 3.26
          Mean value_function loss: 71.3479
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 55.9957
                       Mean reward: 754.35
               Mean episode length: 244.36
    Episode_Reward/reaching_object: 1.0752
    Episode_Reward/rotating_object: 143.8183
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 2.21s
                      Time elapsed: 00:38:39
                               ETA: 00:16:20

################################################################################
                     [1m Learning iteration 1055/1500 [0m                     

                       Computation: 49752 steps/s (collection: 1.877s, learning 0.098s)
             Mean action noise std: 3.27
          Mean value_function loss: 68.1334
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 56.0138
                       Mean reward: 686.68
               Mean episode length: 228.07
    Episode_Reward/reaching_object: 1.0705
    Episode_Reward/rotating_object: 141.3984
        Episode_Reward/action_rate: -0.0545
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 1.98s
                      Time elapsed: 00:38:41
                               ETA: 00:16:18

################################################################################
                     [1m Learning iteration 1056/1500 [0m                     

                       Computation: 50807 steps/s (collection: 1.845s, learning 0.090s)
             Mean action noise std: 3.27
          Mean value_function loss: 70.8313
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 56.0357
                       Mean reward: 705.58
               Mean episode length: 232.90
    Episode_Reward/reaching_object: 1.0680
    Episode_Reward/rotating_object: 142.1886
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 1.93s
                      Time elapsed: 00:38:43
                               ETA: 00:16:16

################################################################################
                     [1m Learning iteration 1057/1500 [0m                     

                       Computation: 50185 steps/s (collection: 1.847s, learning 0.112s)
             Mean action noise std: 3.27
          Mean value_function loss: 60.8892
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 56.0531
                       Mean reward: 749.69
               Mean episode length: 242.73
    Episode_Reward/reaching_object: 1.0802
    Episode_Reward/rotating_object: 145.6068
        Episode_Reward/action_rate: -0.0551
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 1.96s
                      Time elapsed: 00:38:45
                               ETA: 00:16:13

################################################################################
                     [1m Learning iteration 1058/1500 [0m                     

                       Computation: 51363 steps/s (collection: 1.812s, learning 0.102s)
             Mean action noise std: 3.27
          Mean value_function loss: 78.6513
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 56.0645
                       Mean reward: 719.03
               Mean episode length: 232.61
    Episode_Reward/reaching_object: 1.0675
    Episode_Reward/rotating_object: 142.0641
        Episode_Reward/action_rate: -0.0550
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 1.91s
                      Time elapsed: 00:38:47
                               ETA: 00:16:11

################################################################################
                     [1m Learning iteration 1059/1500 [0m                     

                       Computation: 49851 steps/s (collection: 1.855s, learning 0.117s)
             Mean action noise std: 3.28
          Mean value_function loss: 70.8185
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 56.0794
                       Mean reward: 736.54
               Mean episode length: 243.24
    Episode_Reward/reaching_object: 1.0664
    Episode_Reward/rotating_object: 143.4316
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 1.97s
                      Time elapsed: 00:38:49
                               ETA: 00:16:09

################################################################################
                     [1m Learning iteration 1060/1500 [0m                     

                       Computation: 50909 steps/s (collection: 1.805s, learning 0.126s)
             Mean action noise std: 3.28
          Mean value_function loss: 61.7299
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 56.1052
                       Mean reward: 711.59
               Mean episode length: 235.10
    Episode_Reward/reaching_object: 1.0881
    Episode_Reward/rotating_object: 144.9282
        Episode_Reward/action_rate: -0.0558
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 1.93s
                      Time elapsed: 00:38:51
                               ETA: 00:16:06

################################################################################
                     [1m Learning iteration 1061/1500 [0m                     

                       Computation: 48376 steps/s (collection: 1.916s, learning 0.117s)
             Mean action noise std: 3.28
          Mean value_function loss: 67.6752
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 56.1294
                       Mean reward: 727.87
               Mean episode length: 241.22
    Episode_Reward/reaching_object: 1.0646
    Episode_Reward/rotating_object: 141.0769
        Episode_Reward/action_rate: -0.0551
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 2.03s
                      Time elapsed: 00:38:53
                               ETA: 00:16:04

################################################################################
                     [1m Learning iteration 1062/1500 [0m                     

                       Computation: 49292 steps/s (collection: 1.846s, learning 0.149s)
             Mean action noise std: 3.29
          Mean value_function loss: 56.9098
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 56.1558
                       Mean reward: 718.85
               Mean episode length: 235.25
    Episode_Reward/reaching_object: 1.0836
    Episode_Reward/rotating_object: 143.5628
        Episode_Reward/action_rate: -0.0558
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 1.99s
                      Time elapsed: 00:38:55
                               ETA: 00:16:02

################################################################################
                     [1m Learning iteration 1063/1500 [0m                     

                       Computation: 50735 steps/s (collection: 1.838s, learning 0.100s)
             Mean action noise std: 3.29
          Mean value_function loss: 69.2924
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 56.1841
                       Mean reward: 717.96
               Mean episode length: 239.68
    Episode_Reward/reaching_object: 1.0860
    Episode_Reward/rotating_object: 144.0796
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 1.94s
                      Time elapsed: 00:38:57
                               ETA: 00:16:00

################################################################################
                     [1m Learning iteration 1064/1500 [0m                     

                       Computation: 50352 steps/s (collection: 1.824s, learning 0.128s)
             Mean action noise std: 3.30
          Mean value_function loss: 67.0142
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 56.2092
                       Mean reward: 728.62
               Mean episode length: 240.80
    Episode_Reward/reaching_object: 1.0816
    Episode_Reward/rotating_object: 142.3717
        Episode_Reward/action_rate: -0.0561
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 1.95s
                      Time elapsed: 00:38:59
                               ETA: 00:15:57

################################################################################
                     [1m Learning iteration 1065/1500 [0m                     

                       Computation: 49885 steps/s (collection: 1.861s, learning 0.109s)
             Mean action noise std: 3.30
          Mean value_function loss: 64.0941
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 56.2333
                       Mean reward: 729.06
               Mean episode length: 239.47
    Episode_Reward/reaching_object: 1.0841
    Episode_Reward/rotating_object: 143.3377
        Episode_Reward/action_rate: -0.0560
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 1.97s
                      Time elapsed: 00:39:01
                               ETA: 00:15:55

################################################################################
                     [1m Learning iteration 1066/1500 [0m                     

                       Computation: 49540 steps/s (collection: 1.863s, learning 0.121s)
             Mean action noise std: 3.30
          Mean value_function loss: 69.0651
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 56.2503
                       Mean reward: 748.64
               Mean episode length: 237.30
    Episode_Reward/reaching_object: 1.0819
    Episode_Reward/rotating_object: 145.3155
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 1.98s
                      Time elapsed: 00:39:03
                               ETA: 00:15:53

################################################################################
                     [1m Learning iteration 1067/1500 [0m                     

                       Computation: 51394 steps/s (collection: 1.816s, learning 0.097s)
             Mean action noise std: 3.30
          Mean value_function loss: 79.8399
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 56.2687
                       Mean reward: 742.55
               Mean episode length: 238.93
    Episode_Reward/reaching_object: 1.0861
    Episode_Reward/rotating_object: 145.3847
        Episode_Reward/action_rate: -0.0562
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 1.91s
                      Time elapsed: 00:39:05
                               ETA: 00:15:50

################################################################################
                     [1m Learning iteration 1068/1500 [0m                     

                       Computation: 46126 steps/s (collection: 1.969s, learning 0.162s)
             Mean action noise std: 3.31
          Mean value_function loss: 67.9355
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 56.2769
                       Mean reward: 746.86
               Mean episode length: 244.39
    Episode_Reward/reaching_object: 1.0731
    Episode_Reward/rotating_object: 141.6211
        Episode_Reward/action_rate: -0.0562
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 2.13s
                      Time elapsed: 00:39:07
                               ETA: 00:15:48

################################################################################
                     [1m Learning iteration 1069/1500 [0m                     

                       Computation: 45490 steps/s (collection: 2.036s, learning 0.125s)
             Mean action noise std: 3.31
          Mean value_function loss: 64.2003
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 56.2887
                       Mean reward: 737.61
               Mean episode length: 239.13
    Episode_Reward/reaching_object: 1.0614
    Episode_Reward/rotating_object: 141.0322
        Episode_Reward/action_rate: -0.0556
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 2.16s
                      Time elapsed: 00:39:09
                               ETA: 00:15:46

################################################################################
                     [1m Learning iteration 1070/1500 [0m                     

                       Computation: 49218 steps/s (collection: 1.893s, learning 0.105s)
             Mean action noise std: 3.31
          Mean value_function loss: 54.2900
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 56.3078
                       Mean reward: 691.57
               Mean episode length: 229.81
    Episode_Reward/reaching_object: 1.0974
    Episode_Reward/rotating_object: 143.0708
        Episode_Reward/action_rate: -0.0567
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 2.00s
                      Time elapsed: 00:39:11
                               ETA: 00:15:44

################################################################################
                     [1m Learning iteration 1071/1500 [0m                     

                       Computation: 50026 steps/s (collection: 1.866s, learning 0.099s)
             Mean action noise std: 3.31
          Mean value_function loss: 57.9207
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 56.3176
                       Mean reward: 738.02
               Mean episode length: 241.34
    Episode_Reward/reaching_object: 1.0840
    Episode_Reward/rotating_object: 144.4944
        Episode_Reward/action_rate: -0.0568
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 1.97s
                      Time elapsed: 00:39:13
                               ETA: 00:15:41

################################################################################
                     [1m Learning iteration 1072/1500 [0m                     

                       Computation: 50451 steps/s (collection: 1.828s, learning 0.121s)
             Mean action noise std: 3.31
          Mean value_function loss: 56.8926
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 56.3344
                       Mean reward: 734.09
               Mean episode length: 237.59
    Episode_Reward/reaching_object: 1.1072
    Episode_Reward/rotating_object: 147.3295
        Episode_Reward/action_rate: -0.0576
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 1.95s
                      Time elapsed: 00:39:15
                               ETA: 00:15:39

################################################################################
                     [1m Learning iteration 1073/1500 [0m                     

                       Computation: 50237 steps/s (collection: 1.828s, learning 0.129s)
             Mean action noise std: 3.32
          Mean value_function loss: 52.9548
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 56.3523
                       Mean reward: 702.28
               Mean episode length: 235.42
    Episode_Reward/reaching_object: 1.1042
    Episode_Reward/rotating_object: 146.7160
        Episode_Reward/action_rate: -0.0576
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 1.96s
                      Time elapsed: 00:39:17
                               ETA: 00:15:37

################################################################################
                     [1m Learning iteration 1074/1500 [0m                     

                       Computation: 50645 steps/s (collection: 1.828s, learning 0.113s)
             Mean action noise std: 3.32
          Mean value_function loss: 61.0765
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 56.3768
                       Mean reward: 730.61
               Mean episode length: 239.16
    Episode_Reward/reaching_object: 1.0800
    Episode_Reward/rotating_object: 143.4534
        Episode_Reward/action_rate: -0.0567
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 1.94s
                      Time elapsed: 00:39:19
                               ETA: 00:15:34

################################################################################
                     [1m Learning iteration 1075/1500 [0m                     

                       Computation: 51434 steps/s (collection: 1.803s, learning 0.109s)
             Mean action noise std: 3.33
          Mean value_function loss: 65.4655
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 56.4088
                       Mean reward: 727.08
               Mean episode length: 235.40
    Episode_Reward/reaching_object: 1.0717
    Episode_Reward/rotating_object: 143.9768
        Episode_Reward/action_rate: -0.0565
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 1.91s
                      Time elapsed: 00:39:21
                               ETA: 00:15:32

################################################################################
                     [1m Learning iteration 1076/1500 [0m                     

                       Computation: 50515 steps/s (collection: 1.852s, learning 0.094s)
             Mean action noise std: 3.33
          Mean value_function loss: 76.6259
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 56.4246
                       Mean reward: 714.99
               Mean episode length: 235.85
    Episode_Reward/reaching_object: 1.0802
    Episode_Reward/rotating_object: 143.8237
        Episode_Reward/action_rate: -0.0567
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 1.95s
                      Time elapsed: 00:39:23
                               ETA: 00:15:30

################################################################################
                     [1m Learning iteration 1077/1500 [0m                     

                       Computation: 50107 steps/s (collection: 1.870s, learning 0.092s)
             Mean action noise std: 3.33
          Mean value_function loss: 74.5278
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 56.4406
                       Mean reward: 707.19
               Mean episode length: 233.05
    Episode_Reward/reaching_object: 1.0750
    Episode_Reward/rotating_object: 141.7175
        Episode_Reward/action_rate: -0.0568
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 1.96s
                      Time elapsed: 00:39:25
                               ETA: 00:15:28

################################################################################
                     [1m Learning iteration 1078/1500 [0m                     

                       Computation: 50620 steps/s (collection: 1.846s, learning 0.096s)
             Mean action noise std: 3.34
          Mean value_function loss: 65.0651
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.4548
                       Mean reward: 685.11
               Mean episode length: 230.41
    Episode_Reward/reaching_object: 1.0901
    Episode_Reward/rotating_object: 142.6872
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 1.94s
                      Time elapsed: 00:39:27
                               ETA: 00:15:25

################################################################################
                     [1m Learning iteration 1079/1500 [0m                     

                       Computation: 51219 steps/s (collection: 1.822s, learning 0.097s)
             Mean action noise std: 3.34
          Mean value_function loss: 73.8926
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 56.4754
                       Mean reward: 692.90
               Mean episode length: 232.12
    Episode_Reward/reaching_object: 1.0603
    Episode_Reward/rotating_object: 139.9985
        Episode_Reward/action_rate: -0.0565
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 1.92s
                      Time elapsed: 00:39:29
                               ETA: 00:15:23

################################################################################
                     [1m Learning iteration 1080/1500 [0m                     

                       Computation: 50701 steps/s (collection: 1.835s, learning 0.104s)
             Mean action noise std: 3.34
          Mean value_function loss: 70.5213
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 56.4921
                       Mean reward: 744.73
               Mean episode length: 244.28
    Episode_Reward/reaching_object: 1.0755
    Episode_Reward/rotating_object: 143.5712
        Episode_Reward/action_rate: -0.0572
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 1.94s
                      Time elapsed: 00:39:31
                               ETA: 00:15:21

################################################################################
                     [1m Learning iteration 1081/1500 [0m                     

                       Computation: 52528 steps/s (collection: 1.783s, learning 0.089s)
             Mean action noise std: 3.34
          Mean value_function loss: 67.8387
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 56.5174
                       Mean reward: 701.04
               Mean episode length: 238.57
    Episode_Reward/reaching_object: 1.0474
    Episode_Reward/rotating_object: 135.2645
        Episode_Reward/action_rate: -0.0566
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 1.87s
                      Time elapsed: 00:39:32
                               ETA: 00:15:18

################################################################################
                     [1m Learning iteration 1082/1500 [0m                     

                       Computation: 51734 steps/s (collection: 1.807s, learning 0.094s)
             Mean action noise std: 3.35
          Mean value_function loss: 72.8505
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 56.5344
                       Mean reward: 694.78
               Mean episode length: 234.59
    Episode_Reward/reaching_object: 1.0612
    Episode_Reward/rotating_object: 142.1271
        Episode_Reward/action_rate: -0.0571
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 1.90s
                      Time elapsed: 00:39:34
                               ETA: 00:15:16

################################################################################
                     [1m Learning iteration 1083/1500 [0m                     

                       Computation: 50991 steps/s (collection: 1.815s, learning 0.113s)
             Mean action noise std: 3.35
          Mean value_function loss: 61.4306
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 56.5501
                       Mean reward: 751.39
               Mean episode length: 245.89
    Episode_Reward/reaching_object: 1.0861
    Episode_Reward/rotating_object: 146.5632
        Episode_Reward/action_rate: -0.0582
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 1.93s
                      Time elapsed: 00:39:36
                               ETA: 00:15:14

################################################################################
                     [1m Learning iteration 1084/1500 [0m                     

                       Computation: 47147 steps/s (collection: 1.918s, learning 0.167s)
             Mean action noise std: 3.35
          Mean value_function loss: 58.9414
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 56.5656
                       Mean reward: 735.28
               Mean episode length: 233.96
    Episode_Reward/reaching_object: 1.0759
    Episode_Reward/rotating_object: 147.5387
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 2.09s
                      Time elapsed: 00:39:38
                               ETA: 00:15:12

################################################################################
                     [1m Learning iteration 1085/1500 [0m                     

                       Computation: 37668 steps/s (collection: 2.442s, learning 0.168s)
             Mean action noise std: 3.35
          Mean value_function loss: 58.3744
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 56.5807
                       Mean reward: 718.16
               Mean episode length: 236.11
    Episode_Reward/reaching_object: 1.0925
    Episode_Reward/rotating_object: 146.8021
        Episode_Reward/action_rate: -0.0589
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 2.61s
                      Time elapsed: 00:39:41
                               ETA: 00:15:10

################################################################################
                     [1m Learning iteration 1086/1500 [0m                     

                       Computation: 36075 steps/s (collection: 2.526s, learning 0.199s)
             Mean action noise std: 3.36
          Mean value_function loss: 71.2678
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 56.5999
                       Mean reward: 736.42
               Mean episode length: 238.66
    Episode_Reward/reaching_object: 1.0747
    Episode_Reward/rotating_object: 143.3751
        Episode_Reward/action_rate: -0.0582
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 2.72s
                      Time elapsed: 00:39:44
                               ETA: 00:15:08

################################################################################
                     [1m Learning iteration 1087/1500 [0m                     

                       Computation: 36086 steps/s (collection: 2.495s, learning 0.230s)
             Mean action noise std: 3.36
          Mean value_function loss: 81.0238
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 56.6179
                       Mean reward: 703.36
               Mean episode length: 234.54
    Episode_Reward/reaching_object: 1.0747
    Episode_Reward/rotating_object: 141.8968
        Episode_Reward/action_rate: -0.0583
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 2.72s
                      Time elapsed: 00:39:46
                               ETA: 00:15:06

################################################################################
                     [1m Learning iteration 1088/1500 [0m                     

                       Computation: 35307 steps/s (collection: 2.657s, learning 0.127s)
             Mean action noise std: 3.36
          Mean value_function loss: 64.1627
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 56.6349
                       Mean reward: 736.39
               Mean episode length: 237.58
    Episode_Reward/reaching_object: 1.0608
    Episode_Reward/rotating_object: 139.7505
        Episode_Reward/action_rate: -0.0572
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 2.78s
                      Time elapsed: 00:39:49
                               ETA: 00:15:04

################################################################################
                     [1m Learning iteration 1089/1500 [0m                     

                       Computation: 36872 steps/s (collection: 2.452s, learning 0.214s)
             Mean action noise std: 3.37
          Mean value_function loss: 73.0748
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.6580
                       Mean reward: 724.75
               Mean episode length: 238.25
    Episode_Reward/reaching_object: 1.0801
    Episode_Reward/rotating_object: 144.4829
        Episode_Reward/action_rate: -0.0583
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 2.67s
                      Time elapsed: 00:39:52
                               ETA: 00:15:02

################################################################################
                     [1m Learning iteration 1090/1500 [0m                     

                       Computation: 41516 steps/s (collection: 2.193s, learning 0.175s)
             Mean action noise std: 3.37
          Mean value_function loss: 72.3214
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.6844
                       Mean reward: 738.90
               Mean episode length: 235.69
    Episode_Reward/reaching_object: 1.0813
    Episode_Reward/rotating_object: 143.8751
        Episode_Reward/action_rate: -0.0586
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 2.37s
                      Time elapsed: 00:39:54
                               ETA: 00:14:59

################################################################################
                     [1m Learning iteration 1091/1500 [0m                     

                       Computation: 39362 steps/s (collection: 2.278s, learning 0.219s)
             Mean action noise std: 3.37
          Mean value_function loss: 68.7265
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 56.7035
                       Mean reward: 714.97
               Mean episode length: 234.48
    Episode_Reward/reaching_object: 1.0673
    Episode_Reward/rotating_object: 143.0831
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 2.50s
                      Time elapsed: 00:39:57
                               ETA: 00:14:57

################################################################################
                     [1m Learning iteration 1092/1500 [0m                     

                       Computation: 38077 steps/s (collection: 2.360s, learning 0.222s)
             Mean action noise std: 3.38
          Mean value_function loss: 63.8317
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 56.7330
                       Mean reward: 753.98
               Mean episode length: 240.91
    Episode_Reward/reaching_object: 1.0588
    Episode_Reward/rotating_object: 142.2224
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 2.58s
                      Time elapsed: 00:39:59
                               ETA: 00:14:55

################################################################################
                     [1m Learning iteration 1093/1500 [0m                     

                       Computation: 39528 steps/s (collection: 2.302s, learning 0.185s)
             Mean action noise std: 3.38
          Mean value_function loss: 65.1113
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 56.7561
                       Mean reward: 756.06
               Mean episode length: 244.61
    Episode_Reward/reaching_object: 1.0703
    Episode_Reward/rotating_object: 141.2307
        Episode_Reward/action_rate: -0.0585
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 2.49s
                      Time elapsed: 00:40:02
                               ETA: 00:14:53

################################################################################
                     [1m Learning iteration 1094/1500 [0m                     

                       Computation: 44548 steps/s (collection: 2.022s, learning 0.185s)
             Mean action noise std: 3.38
          Mean value_function loss: 64.3750
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 56.7709
                       Mean reward: 743.71
               Mean episode length: 237.45
    Episode_Reward/reaching_object: 1.0763
    Episode_Reward/rotating_object: 144.1361
        Episode_Reward/action_rate: -0.0588
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 2.21s
                      Time elapsed: 00:40:04
                               ETA: 00:14:51

################################################################################
                     [1m Learning iteration 1095/1500 [0m                     

                       Computation: 43285 steps/s (collection: 2.137s, learning 0.135s)
             Mean action noise std: 3.39
          Mean value_function loss: 76.5733
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 56.7866
                       Mean reward: 692.15
               Mean episode length: 232.20
    Episode_Reward/reaching_object: 1.0730
    Episode_Reward/rotating_object: 142.5165
        Episode_Reward/action_rate: -0.0583
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 2.27s
                      Time elapsed: 00:40:06
                               ETA: 00:14:49

################################################################################
                     [1m Learning iteration 1096/1500 [0m                     

                       Computation: 41460 steps/s (collection: 2.154s, learning 0.217s)
             Mean action noise std: 3.39
          Mean value_function loss: 60.5649
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 56.8035
                       Mean reward: 709.55
               Mean episode length: 242.39
    Episode_Reward/reaching_object: 1.0976
    Episode_Reward/rotating_object: 143.2662
        Episode_Reward/action_rate: -0.0599
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 2.37s
                      Time elapsed: 00:40:09
                               ETA: 00:14:47

################################################################################
                     [1m Learning iteration 1097/1500 [0m                     

                       Computation: 44117 steps/s (collection: 2.091s, learning 0.138s)
             Mean action noise std: 3.39
          Mean value_function loss: 88.3341
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 56.8145
                       Mean reward: 729.63
               Mean episode length: 234.09
    Episode_Reward/reaching_object: 1.0728
    Episode_Reward/rotating_object: 141.7882
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 2.23s
                      Time elapsed: 00:40:11
                               ETA: 00:14:45

################################################################################
                     [1m Learning iteration 1098/1500 [0m                     

                       Computation: 46250 steps/s (collection: 1.972s, learning 0.154s)
             Mean action noise std: 3.39
          Mean value_function loss: 69.8636
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 56.8245
                       Mean reward: 745.26
               Mean episode length: 239.21
    Episode_Reward/reaching_object: 1.0688
    Episode_Reward/rotating_object: 142.4147
        Episode_Reward/action_rate: -0.0583
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 2.13s
                      Time elapsed: 00:40:13
                               ETA: 00:14:42

################################################################################
                     [1m Learning iteration 1099/1500 [0m                     

                       Computation: 46100 steps/s (collection: 2.018s, learning 0.115s)
             Mean action noise std: 3.40
          Mean value_function loss: 84.7192
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 56.8439
                       Mean reward: 682.71
               Mean episode length: 230.34
    Episode_Reward/reaching_object: 1.0680
    Episode_Reward/rotating_object: 141.0846
        Episode_Reward/action_rate: -0.0586
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 2.13s
                      Time elapsed: 00:40:15
                               ETA: 00:14:40

################################################################################
                     [1m Learning iteration 1100/1500 [0m                     

                       Computation: 42884 steps/s (collection: 2.019s, learning 0.274s)
             Mean action noise std: 3.40
          Mean value_function loss: 67.3128
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 56.8697
                       Mean reward: 686.75
               Mean episode length: 229.56
    Episode_Reward/reaching_object: 1.0513
    Episode_Reward/rotating_object: 138.6436
        Episode_Reward/action_rate: -0.0576
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 2.29s
                      Time elapsed: 00:40:17
                               ETA: 00:14:38

################################################################################
                     [1m Learning iteration 1101/1500 [0m                     

                       Computation: 44411 steps/s (collection: 2.122s, learning 0.092s)
             Mean action noise std: 3.40
          Mean value_function loss: 66.7877
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 56.8883
                       Mean reward: 724.02
               Mean episode length: 234.52
    Episode_Reward/reaching_object: 1.0663
    Episode_Reward/rotating_object: 143.4101
        Episode_Reward/action_rate: -0.0583
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 2.21s
                      Time elapsed: 00:40:20
                               ETA: 00:14:36

################################################################################
                     [1m Learning iteration 1102/1500 [0m                     

                       Computation: 49217 steps/s (collection: 1.883s, learning 0.114s)
             Mean action noise std: 3.41
          Mean value_function loss: 72.0498
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 56.9035
                       Mean reward: 722.79
               Mean episode length: 235.25
    Episode_Reward/reaching_object: 1.0782
    Episode_Reward/rotating_object: 143.4262
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 2.00s
                      Time elapsed: 00:40:22
                               ETA: 00:14:33

################################################################################
                     [1m Learning iteration 1103/1500 [0m                     

                       Computation: 46358 steps/s (collection: 1.959s, learning 0.161s)
             Mean action noise std: 3.41
          Mean value_function loss: 91.3318
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 56.9272
                       Mean reward: 670.49
               Mean episode length: 224.11
    Episode_Reward/reaching_object: 1.0724
    Episode_Reward/rotating_object: 141.9431
        Episode_Reward/action_rate: -0.0589
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 2.12s
                      Time elapsed: 00:40:24
                               ETA: 00:14:31

################################################################################
                     [1m Learning iteration 1104/1500 [0m                     

                       Computation: 48208 steps/s (collection: 1.938s, learning 0.101s)
             Mean action noise std: 3.41
          Mean value_function loss: 78.0635
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 56.9461
                       Mean reward: 690.66
               Mean episode length: 229.92
    Episode_Reward/reaching_object: 1.0563
    Episode_Reward/rotating_object: 141.5917
        Episode_Reward/action_rate: -0.0581
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 2.04s
                      Time elapsed: 00:40:26
                               ETA: 00:14:29

################################################################################
                     [1m Learning iteration 1105/1500 [0m                     

                       Computation: 51214 steps/s (collection: 1.820s, learning 0.100s)
             Mean action noise std: 3.41
          Mean value_function loss: 56.8204
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.9583
                       Mean reward: 696.14
               Mean episode length: 232.86
    Episode_Reward/reaching_object: 1.0742
    Episode_Reward/rotating_object: 141.0098
        Episode_Reward/action_rate: -0.0593
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 1.92s
                      Time elapsed: 00:40:28
                               ETA: 00:14:27

################################################################################
                     [1m Learning iteration 1106/1500 [0m                     

                       Computation: 49054 steps/s (collection: 1.866s, learning 0.138s)
             Mean action noise std: 3.42
          Mean value_function loss: 72.3749
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 56.9738
                       Mean reward: 682.12
               Mean episode length: 227.74
    Episode_Reward/reaching_object: 1.0581
    Episode_Reward/rotating_object: 140.3225
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 2.00s
                      Time elapsed: 00:40:30
                               ETA: 00:14:24

################################################################################
                     [1m Learning iteration 1107/1500 [0m                     

                       Computation: 49083 steps/s (collection: 1.889s, learning 0.114s)
             Mean action noise std: 3.42
          Mean value_function loss: 65.1411
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 56.9929
                       Mean reward: 767.33
               Mean episode length: 243.22
    Episode_Reward/reaching_object: 1.0913
    Episode_Reward/rotating_object: 145.8107
        Episode_Reward/action_rate: -0.0602
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 2.00s
                      Time elapsed: 00:40:32
                               ETA: 00:14:22

################################################################################
                     [1m Learning iteration 1108/1500 [0m                     

                       Computation: 49215 steps/s (collection: 1.892s, learning 0.105s)
             Mean action noise std: 3.42
          Mean value_function loss: 58.7989
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 57.0054
                       Mean reward: 686.63
               Mean episode length: 231.55
    Episode_Reward/reaching_object: 1.0933
    Episode_Reward/rotating_object: 143.8339
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 2.00s
                      Time elapsed: 00:40:34
                               ETA: 00:14:20

################################################################################
                     [1m Learning iteration 1109/1500 [0m                     

                       Computation: 51525 steps/s (collection: 1.817s, learning 0.091s)
             Mean action noise std: 3.42
          Mean value_function loss: 73.4466
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 57.0180
                       Mean reward: 764.12
               Mean episode length: 241.83
    Episode_Reward/reaching_object: 1.1055
    Episode_Reward/rotating_object: 150.1222
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 1.91s
                      Time elapsed: 00:40:36
                               ETA: 00:14:18

################################################################################
                     [1m Learning iteration 1110/1500 [0m                     

                       Computation: 49427 steps/s (collection: 1.880s, learning 0.109s)
             Mean action noise std: 3.43
          Mean value_function loss: 70.1203
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 57.0336
                       Mean reward: 713.67
               Mean episode length: 230.98
    Episode_Reward/reaching_object: 1.0878
    Episode_Reward/rotating_object: 146.6949
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 1.99s
                      Time elapsed: 00:40:38
                               ETA: 00:14:15

################################################################################
                     [1m Learning iteration 1111/1500 [0m                     

                       Computation: 49687 steps/s (collection: 1.868s, learning 0.111s)
             Mean action noise std: 3.43
          Mean value_function loss: 72.9888
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 57.0552
                       Mean reward: 675.07
               Mean episode length: 232.10
    Episode_Reward/reaching_object: 1.0761
    Episode_Reward/rotating_object: 136.9082
        Episode_Reward/action_rate: -0.0595
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 1.98s
                      Time elapsed: 00:40:40
                               ETA: 00:14:13

################################################################################
                     [1m Learning iteration 1112/1500 [0m                     

                       Computation: 49846 steps/s (collection: 1.857s, learning 0.115s)
             Mean action noise std: 3.43
          Mean value_function loss: 66.9066
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 57.0681
                       Mean reward: 719.15
               Mean episode length: 240.47
    Episode_Reward/reaching_object: 1.0815
    Episode_Reward/rotating_object: 139.2863
        Episode_Reward/action_rate: -0.0597
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 1.97s
                      Time elapsed: 00:40:42
                               ETA: 00:14:11

################################################################################
                     [1m Learning iteration 1113/1500 [0m                     

                       Computation: 49599 steps/s (collection: 1.884s, learning 0.098s)
             Mean action noise std: 3.43
          Mean value_function loss: 60.0636
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 57.0847
                       Mean reward: 728.43
               Mean episode length: 235.23
    Episode_Reward/reaching_object: 1.0761
    Episode_Reward/rotating_object: 141.7997
        Episode_Reward/action_rate: -0.0596
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 1.98s
                      Time elapsed: 00:40:44
                               ETA: 00:14:09

################################################################################
                     [1m Learning iteration 1114/1500 [0m                     

                       Computation: 46796 steps/s (collection: 1.925s, learning 0.176s)
             Mean action noise std: 3.44
          Mean value_function loss: 62.3612
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.1061
                       Mean reward: 731.33
               Mean episode length: 235.33
    Episode_Reward/reaching_object: 1.0900
    Episode_Reward/rotating_object: 145.3290
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 2.10s
                      Time elapsed: 00:40:46
                               ETA: 00:14:06

################################################################################
                     [1m Learning iteration 1115/1500 [0m                     

                       Computation: 47639 steps/s (collection: 1.955s, learning 0.109s)
             Mean action noise std: 3.44
          Mean value_function loss: 57.7587
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 57.1258
                       Mean reward: 705.50
               Mean episode length: 233.92
    Episode_Reward/reaching_object: 1.1082
    Episode_Reward/rotating_object: 148.2962
        Episode_Reward/action_rate: -0.0615
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 2.06s
                      Time elapsed: 00:40:48
                               ETA: 00:14:04

################################################################################
                     [1m Learning iteration 1116/1500 [0m                     

                       Computation: 48945 steps/s (collection: 1.885s, learning 0.123s)
             Mean action noise std: 3.44
          Mean value_function loss: 69.4113
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 57.1414
                       Mean reward: 736.79
               Mean episode length: 233.75
    Episode_Reward/reaching_object: 1.1015
    Episode_Reward/rotating_object: 148.0530
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 2.01s
                      Time elapsed: 00:40:50
                               ETA: 00:14:02

################################################################################
                     [1m Learning iteration 1117/1500 [0m                     

                       Computation: 49098 steps/s (collection: 1.896s, learning 0.106s)
             Mean action noise std: 3.44
          Mean value_function loss: 75.5433
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 57.1507
                       Mean reward: 742.71
               Mean episode length: 235.21
    Episode_Reward/reaching_object: 1.0820
    Episode_Reward/rotating_object: 143.9959
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 2.00s
                      Time elapsed: 00:40:52
                               ETA: 00:14:00

################################################################################
                     [1m Learning iteration 1118/1500 [0m                     

                       Computation: 48895 steps/s (collection: 1.885s, learning 0.126s)
             Mean action noise std: 3.45
          Mean value_function loss: 80.1909
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 57.1620
                       Mean reward: 729.63
               Mean episode length: 236.23
    Episode_Reward/reaching_object: 1.0655
    Episode_Reward/rotating_object: 141.8146
        Episode_Reward/action_rate: -0.0598
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 2.01s
                      Time elapsed: 00:40:54
                               ETA: 00:13:57

################################################################################
                     [1m Learning iteration 1119/1500 [0m                     

                       Computation: 48695 steps/s (collection: 1.892s, learning 0.127s)
             Mean action noise std: 3.45
          Mean value_function loss: 70.9731
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 57.1829
                       Mean reward: 776.94
               Mean episode length: 245.49
    Episode_Reward/reaching_object: 1.0901
    Episode_Reward/rotating_object: 147.8483
        Episode_Reward/action_rate: -0.0609
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 2.02s
                      Time elapsed: 00:40:56
                               ETA: 00:13:55

################################################################################
                     [1m Learning iteration 1120/1500 [0m                     

                       Computation: 48288 steps/s (collection: 1.919s, learning 0.117s)
             Mean action noise std: 3.45
          Mean value_function loss: 81.8889
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 57.2020
                       Mean reward: 727.91
               Mean episode length: 235.69
    Episode_Reward/reaching_object: 1.0595
    Episode_Reward/rotating_object: 139.0331
        Episode_Reward/action_rate: -0.0599
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 2.04s
                      Time elapsed: 00:40:58
                               ETA: 00:13:53

################################################################################
                     [1m Learning iteration 1121/1500 [0m                     

                       Computation: 49887 steps/s (collection: 1.878s, learning 0.093s)
             Mean action noise std: 3.46
          Mean value_function loss: 69.1560
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 57.2185
                       Mean reward: 718.02
               Mean episode length: 238.40
    Episode_Reward/reaching_object: 1.0963
    Episode_Reward/rotating_object: 144.1294
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 1.97s
                      Time elapsed: 00:41:00
                               ETA: 00:13:51

################################################################################
                     [1m Learning iteration 1122/1500 [0m                     

                       Computation: 48301 steps/s (collection: 1.942s, learning 0.094s)
             Mean action noise std: 3.46
          Mean value_function loss: 54.7339
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 57.2355
                       Mean reward: 729.40
               Mean episode length: 236.23
    Episode_Reward/reaching_object: 1.0756
    Episode_Reward/rotating_object: 143.6629
        Episode_Reward/action_rate: -0.0608
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 2.04s
                      Time elapsed: 00:41:02
                               ETA: 00:13:48

################################################################################
                     [1m Learning iteration 1123/1500 [0m                     

                       Computation: 47682 steps/s (collection: 1.970s, learning 0.092s)
             Mean action noise std: 3.46
          Mean value_function loss: 66.2722
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 57.2562
                       Mean reward: 731.25
               Mean episode length: 238.24
    Episode_Reward/reaching_object: 1.1069
    Episode_Reward/rotating_object: 148.5673
        Episode_Reward/action_rate: -0.0627
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 2.06s
                      Time elapsed: 00:41:04
                               ETA: 00:13:46

################################################################################
                     [1m Learning iteration 1124/1500 [0m                     

                       Computation: 47166 steps/s (collection: 1.976s, learning 0.108s)
             Mean action noise std: 3.47
          Mean value_function loss: 60.8946
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 57.2759
                       Mean reward: 725.70
               Mean episode length: 236.38
    Episode_Reward/reaching_object: 1.0793
    Episode_Reward/rotating_object: 142.6392
        Episode_Reward/action_rate: -0.0609
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 2.08s
                      Time elapsed: 00:41:06
                               ETA: 00:13:44

################################################################################
                     [1m Learning iteration 1125/1500 [0m                     

                       Computation: 49388 steps/s (collection: 1.894s, learning 0.096s)
             Mean action noise std: 3.47
          Mean value_function loss: 67.6128
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.2935
                       Mean reward: 728.67
               Mean episode length: 239.34
    Episode_Reward/reaching_object: 1.0849
    Episode_Reward/rotating_object: 144.4119
        Episode_Reward/action_rate: -0.0614
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 1.99s
                      Time elapsed: 00:41:08
                               ETA: 00:13:42

################################################################################
                     [1m Learning iteration 1126/1500 [0m                     

                       Computation: 51231 steps/s (collection: 1.820s, learning 0.099s)
             Mean action noise std: 3.47
          Mean value_function loss: 66.8170
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 57.3118
                       Mean reward: 707.77
               Mean episode length: 232.87
    Episode_Reward/reaching_object: 1.0945
    Episode_Reward/rotating_object: 143.5725
        Episode_Reward/action_rate: -0.0621
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 1.92s
                      Time elapsed: 00:41:10
                               ETA: 00:13:39

################################################################################
                     [1m Learning iteration 1127/1500 [0m                     

                       Computation: 50727 steps/s (collection: 1.820s, learning 0.118s)
             Mean action noise std: 3.48
          Mean value_function loss: 64.5513
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 57.3269
                       Mean reward: 750.51
               Mean episode length: 243.51
    Episode_Reward/reaching_object: 1.0746
    Episode_Reward/rotating_object: 140.0496
        Episode_Reward/action_rate: -0.0613
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 1.94s
                      Time elapsed: 00:41:12
                               ETA: 00:13:37

################################################################################
                     [1m Learning iteration 1128/1500 [0m                     

                       Computation: 50132 steps/s (collection: 1.869s, learning 0.092s)
             Mean action noise std: 3.48
          Mean value_function loss: 77.8447
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 57.3450
                       Mean reward: 636.39
               Mean episode length: 224.90
    Episode_Reward/reaching_object: 1.0783
    Episode_Reward/rotating_object: 138.9644
        Episode_Reward/action_rate: -0.0615
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 1.96s
                      Time elapsed: 00:41:14
                               ETA: 00:13:35

################################################################################
                     [1m Learning iteration 1129/1500 [0m                     

                       Computation: 51005 steps/s (collection: 1.830s, learning 0.097s)
             Mean action noise std: 3.48
          Mean value_function loss: 68.0067
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 57.3648
                       Mean reward: 718.66
               Mean episode length: 238.94
    Episode_Reward/reaching_object: 1.0818
    Episode_Reward/rotating_object: 141.9826
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 1.93s
                      Time elapsed: 00:41:16
                               ETA: 00:13:32

################################################################################
                     [1m Learning iteration 1130/1500 [0m                     

                       Computation: 49662 steps/s (collection: 1.883s, learning 0.096s)
             Mean action noise std: 3.48
          Mean value_function loss: 61.2246
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 57.3820
                       Mean reward: 747.00
               Mean episode length: 244.62
    Episode_Reward/reaching_object: 1.1055
    Episode_Reward/rotating_object: 147.3902
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 1.98s
                      Time elapsed: 00:41:18
                               ETA: 00:13:30

################################################################################
                     [1m Learning iteration 1131/1500 [0m                     

                       Computation: 49517 steps/s (collection: 1.863s, learning 0.122s)
             Mean action noise std: 3.49
          Mean value_function loss: 59.6193
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 57.3951
                       Mean reward: 746.30
               Mean episode length: 237.64
    Episode_Reward/reaching_object: 1.1071
    Episode_Reward/rotating_object: 147.9572
        Episode_Reward/action_rate: -0.0631
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 1.99s
                      Time elapsed: 00:41:20
                               ETA: 00:13:28

################################################################################
                     [1m Learning iteration 1132/1500 [0m                     

                       Computation: 49151 steps/s (collection: 1.874s, learning 0.126s)
             Mean action noise std: 3.49
          Mean value_function loss: 63.9586
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 57.4022
                       Mean reward: 751.49
               Mean episode length: 245.04
    Episode_Reward/reaching_object: 1.1068
    Episode_Reward/rotating_object: 146.1170
        Episode_Reward/action_rate: -0.0631
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 2.00s
                      Time elapsed: 00:41:22
                               ETA: 00:13:26

################################################################################
                     [1m Learning iteration 1133/1500 [0m                     

                       Computation: 49333 steps/s (collection: 1.896s, learning 0.097s)
             Mean action noise std: 3.49
          Mean value_function loss: 69.1327
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 57.4098
                       Mean reward: 697.11
               Mean episode length: 232.99
    Episode_Reward/reaching_object: 1.0777
    Episode_Reward/rotating_object: 139.9742
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 1.99s
                      Time elapsed: 00:41:24
                               ETA: 00:13:23

################################################################################
                     [1m Learning iteration 1134/1500 [0m                     

                       Computation: 51197 steps/s (collection: 1.829s, learning 0.091s)
             Mean action noise std: 3.49
          Mean value_function loss: 71.3077
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 57.4289
                       Mean reward: 729.24
               Mean episode length: 236.33
    Episode_Reward/reaching_object: 1.0667
    Episode_Reward/rotating_object: 139.3622
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 1.92s
                      Time elapsed: 00:41:26
                               ETA: 00:13:21

################################################################################
                     [1m Learning iteration 1135/1500 [0m                     

                       Computation: 51533 steps/s (collection: 1.798s, learning 0.110s)
             Mean action noise std: 3.50
          Mean value_function loss: 63.5209
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 57.4489
                       Mean reward: 714.00
               Mean episode length: 238.62
    Episode_Reward/reaching_object: 1.0983
    Episode_Reward/rotating_object: 144.2672
        Episode_Reward/action_rate: -0.0631
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 1.91s
                      Time elapsed: 00:41:27
                               ETA: 00:13:19

################################################################################
                     [1m Learning iteration 1136/1500 [0m                     

                       Computation: 50228 steps/s (collection: 1.827s, learning 0.131s)
             Mean action noise std: 3.50
          Mean value_function loss: 86.5243
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 57.4596
                       Mean reward: 713.14
               Mean episode length: 236.53
    Episode_Reward/reaching_object: 1.0902
    Episode_Reward/rotating_object: 144.7570
        Episode_Reward/action_rate: -0.0626
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 1.96s
                      Time elapsed: 00:41:29
                               ETA: 00:13:17

################################################################################
                     [1m Learning iteration 1137/1500 [0m                     

                       Computation: 51183 steps/s (collection: 1.816s, learning 0.105s)
             Mean action noise std: 3.50
          Mean value_function loss: 72.1106
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 57.4736
                       Mean reward: 668.38
               Mean episode length: 226.52
    Episode_Reward/reaching_object: 1.0810
    Episode_Reward/rotating_object: 142.3680
        Episode_Reward/action_rate: -0.0624
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 1.92s
                      Time elapsed: 00:41:31
                               ETA: 00:13:14

################################################################################
                     [1m Learning iteration 1138/1500 [0m                     

                       Computation: 51315 steps/s (collection: 1.808s, learning 0.108s)
             Mean action noise std: 3.50
          Mean value_function loss: 69.5502
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 57.4900
                       Mean reward: 730.07
               Mean episode length: 238.91
    Episode_Reward/reaching_object: 1.0812
    Episode_Reward/rotating_object: 143.8012
        Episode_Reward/action_rate: -0.0625
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 1.92s
                      Time elapsed: 00:41:33
                               ETA: 00:13:12

################################################################################
                     [1m Learning iteration 1139/1500 [0m                     

                       Computation: 51364 steps/s (collection: 1.824s, learning 0.090s)
             Mean action noise std: 3.51
          Mean value_function loss: 70.9569
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 57.5020
                       Mean reward: 683.63
               Mean episode length: 227.54
    Episode_Reward/reaching_object: 1.0745
    Episode_Reward/rotating_object: 140.6197
        Episode_Reward/action_rate: -0.0623
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 1.91s
                      Time elapsed: 00:41:35
                               ETA: 00:13:10

################################################################################
                     [1m Learning iteration 1140/1500 [0m                     

                       Computation: 49590 steps/s (collection: 1.883s, learning 0.099s)
             Mean action noise std: 3.51
          Mean value_function loss: 75.6783
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 57.5126
                       Mean reward: 725.20
               Mean episode length: 235.97
    Episode_Reward/reaching_object: 1.0963
    Episode_Reward/rotating_object: 144.4686
        Episode_Reward/action_rate: -0.0637
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 1.98s
                      Time elapsed: 00:41:37
                               ETA: 00:13:08

################################################################################
                     [1m Learning iteration 1141/1500 [0m                     

                       Computation: 49626 steps/s (collection: 1.889s, learning 0.092s)
             Mean action noise std: 3.51
          Mean value_function loss: 57.3514
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 57.5208
                       Mean reward: 729.28
               Mean episode length: 239.61
    Episode_Reward/reaching_object: 1.0808
    Episode_Reward/rotating_object: 143.3717
        Episode_Reward/action_rate: -0.0626
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 1.98s
                      Time elapsed: 00:41:39
                               ETA: 00:13:05

################################################################################
                     [1m Learning iteration 1142/1500 [0m                     

                       Computation: 50703 steps/s (collection: 1.843s, learning 0.096s)
             Mean action noise std: 3.51
          Mean value_function loss: 68.9865
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 57.5309
                       Mean reward: 702.02
               Mean episode length: 230.32
    Episode_Reward/reaching_object: 1.0783
    Episode_Reward/rotating_object: 143.0982
        Episode_Reward/action_rate: -0.0627
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 1.94s
                      Time elapsed: 00:41:41
                               ETA: 00:13:03

################################################################################
                     [1m Learning iteration 1143/1500 [0m                     

                       Computation: 50827 steps/s (collection: 1.846s, learning 0.089s)
             Mean action noise std: 3.51
          Mean value_function loss: 73.9633
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 57.5448
                       Mean reward: 719.56
               Mean episode length: 233.81
    Episode_Reward/reaching_object: 1.0871
    Episode_Reward/rotating_object: 143.3412
        Episode_Reward/action_rate: -0.0635
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 1.93s
                      Time elapsed: 00:41:43
                               ETA: 00:13:01

################################################################################
                     [1m Learning iteration 1144/1500 [0m                     

                       Computation: 49430 steps/s (collection: 1.863s, learning 0.126s)
             Mean action noise std: 3.52
          Mean value_function loss: 57.5236
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 57.5620
                       Mean reward: 766.40
               Mean episode length: 241.14
    Episode_Reward/reaching_object: 1.0930
    Episode_Reward/rotating_object: 143.3640
        Episode_Reward/action_rate: -0.0637
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 1.99s
                      Time elapsed: 00:41:45
                               ETA: 00:12:58

################################################################################
                     [1m Learning iteration 1145/1500 [0m                     

                       Computation: 48036 steps/s (collection: 1.955s, learning 0.091s)
             Mean action noise std: 3.52
          Mean value_function loss: 65.3286
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 57.5766
                       Mean reward: 726.90
               Mean episode length: 239.32
    Episode_Reward/reaching_object: 1.0921
    Episode_Reward/rotating_object: 144.8953
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 2.05s
                      Time elapsed: 00:41:47
                               ETA: 00:12:56

################################################################################
                     [1m Learning iteration 1146/1500 [0m                     

                       Computation: 50427 steps/s (collection: 1.861s, learning 0.089s)
             Mean action noise std: 3.52
          Mean value_function loss: 61.6306
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 57.5915
                       Mean reward: 744.90
               Mean episode length: 237.86
    Episode_Reward/reaching_object: 1.0812
    Episode_Reward/rotating_object: 146.2067
        Episode_Reward/action_rate: -0.0635
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 1.95s
                      Time elapsed: 00:41:49
                               ETA: 00:12:54

################################################################################
                     [1m Learning iteration 1147/1500 [0m                     

                       Computation: 49046 steps/s (collection: 1.882s, learning 0.123s)
             Mean action noise std: 3.53
          Mean value_function loss: 66.1376
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 57.6094
                       Mean reward: 712.48
               Mean episode length: 236.91
    Episode_Reward/reaching_object: 1.0964
    Episode_Reward/rotating_object: 147.7570
        Episode_Reward/action_rate: -0.0643
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 2.00s
                      Time elapsed: 00:41:51
                               ETA: 00:12:52

################################################################################
                     [1m Learning iteration 1148/1500 [0m                     

                       Computation: 51153 steps/s (collection: 1.825s, learning 0.096s)
             Mean action noise std: 3.53
          Mean value_function loss: 65.2011
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 57.6330
                       Mean reward: 704.46
               Mean episode length: 234.98
    Episode_Reward/reaching_object: 1.0888
    Episode_Reward/rotating_object: 145.7269
        Episode_Reward/action_rate: -0.0646
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 1.92s
                      Time elapsed: 00:41:53
                               ETA: 00:12:49

################################################################################
                     [1m Learning iteration 1149/1500 [0m                     

                       Computation: 49801 steps/s (collection: 1.879s, learning 0.095s)
             Mean action noise std: 3.53
          Mean value_function loss: 60.8111
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 57.6483
                       Mean reward: 725.85
               Mean episode length: 235.58
    Episode_Reward/reaching_object: 1.0814
    Episode_Reward/rotating_object: 143.0914
        Episode_Reward/action_rate: -0.0639
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 1.97s
                      Time elapsed: 00:41:55
                               ETA: 00:12:47

################################################################################
                     [1m Learning iteration 1150/1500 [0m                     

                       Computation: 51144 steps/s (collection: 1.830s, learning 0.092s)
             Mean action noise std: 3.53
          Mean value_function loss: 72.4178
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 57.6587
                       Mean reward: 730.24
               Mean episode length: 238.94
    Episode_Reward/reaching_object: 1.0771
    Episode_Reward/rotating_object: 144.7621
        Episode_Reward/action_rate: -0.0638
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 1.92s
                      Time elapsed: 00:41:57
                               ETA: 00:12:45

################################################################################
                     [1m Learning iteration 1151/1500 [0m                     

                       Computation: 48572 steps/s (collection: 1.928s, learning 0.096s)
             Mean action noise std: 3.54
          Mean value_function loss: 65.4119
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.6806
                       Mean reward: 695.03
               Mean episode length: 238.69
    Episode_Reward/reaching_object: 1.0689
    Episode_Reward/rotating_object: 141.7721
        Episode_Reward/action_rate: -0.0637
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 2.02s
                      Time elapsed: 00:41:59
                               ETA: 00:12:43

################################################################################
                     [1m Learning iteration 1152/1500 [0m                     

                       Computation: 51008 steps/s (collection: 1.826s, learning 0.101s)
             Mean action noise std: 3.54
          Mean value_function loss: 79.1652
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.7061
                       Mean reward: 752.28
               Mean episode length: 244.38
    Episode_Reward/reaching_object: 1.0835
    Episode_Reward/rotating_object: 144.9933
        Episode_Reward/action_rate: -0.0645
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 1.93s
                      Time elapsed: 00:42:01
                               ETA: 00:12:40

################################################################################
                     [1m Learning iteration 1153/1500 [0m                     

                       Computation: 50299 steps/s (collection: 1.861s, learning 0.094s)
             Mean action noise std: 3.54
          Mean value_function loss: 59.0260
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 57.7302
                       Mean reward: 747.03
               Mean episode length: 241.55
    Episode_Reward/reaching_object: 1.0724
    Episode_Reward/rotating_object: 144.7454
        Episode_Reward/action_rate: -0.0639
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 1.95s
                      Time elapsed: 00:42:03
                               ETA: 00:12:38

################################################################################
                     [1m Learning iteration 1154/1500 [0m                     

                       Computation: 50724 steps/s (collection: 1.849s, learning 0.089s)
             Mean action noise std: 3.55
          Mean value_function loss: 66.0771
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 57.7469
                       Mean reward: 753.95
               Mean episode length: 241.21
    Episode_Reward/reaching_object: 1.0950
    Episode_Reward/rotating_object: 149.2107
        Episode_Reward/action_rate: -0.0654
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 1.94s
                      Time elapsed: 00:42:05
                               ETA: 00:12:36

################################################################################
                     [1m Learning iteration 1155/1500 [0m                     

                       Computation: 50592 steps/s (collection: 1.848s, learning 0.096s)
             Mean action noise std: 3.55
          Mean value_function loss: 66.2733
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 57.7632
                       Mean reward: 739.75
               Mean episode length: 241.36
    Episode_Reward/reaching_object: 1.0850
    Episode_Reward/rotating_object: 146.1336
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 1.94s
                      Time elapsed: 00:42:07
                               ETA: 00:12:34

################################################################################
                     [1m Learning iteration 1156/1500 [0m                     

                       Computation: 51349 steps/s (collection: 1.798s, learning 0.117s)
             Mean action noise std: 3.55
          Mean value_function loss: 75.3004
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 57.7753
                       Mean reward: 714.43
               Mean episode length: 234.31
    Episode_Reward/reaching_object: 1.0623
    Episode_Reward/rotating_object: 143.4475
        Episode_Reward/action_rate: -0.0640
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 1.91s
                      Time elapsed: 00:42:08
                               ETA: 00:12:31

################################################################################
                     [1m Learning iteration 1157/1500 [0m                     

                       Computation: 49858 steps/s (collection: 1.826s, learning 0.145s)
             Mean action noise std: 3.56
          Mean value_function loss: 63.0390
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.7895
                       Mean reward: 722.29
               Mean episode length: 240.25
    Episode_Reward/reaching_object: 1.0658
    Episode_Reward/rotating_object: 138.7193
        Episode_Reward/action_rate: -0.0645
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 1.97s
                      Time elapsed: 00:42:10
                               ETA: 00:12:29

################################################################################
                     [1m Learning iteration 1158/1500 [0m                     

                       Computation: 50836 steps/s (collection: 1.836s, learning 0.098s)
             Mean action noise std: 3.56
          Mean value_function loss: 68.4617
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 57.8165
                       Mean reward: 725.53
               Mean episode length: 232.86
    Episode_Reward/reaching_object: 1.0833
    Episode_Reward/rotating_object: 147.1607
        Episode_Reward/action_rate: -0.0651
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 1.93s
                      Time elapsed: 00:42:12
                               ETA: 00:12:27

################################################################################
                     [1m Learning iteration 1159/1500 [0m                     

                       Computation: 50687 steps/s (collection: 1.841s, learning 0.099s)
             Mean action noise std: 3.56
          Mean value_function loss: 67.1889
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 57.8370
                       Mean reward: 769.52
               Mean episode length: 245.53
    Episode_Reward/reaching_object: 1.0738
    Episode_Reward/rotating_object: 142.8073
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 1.94s
                      Time elapsed: 00:42:14
                               ETA: 00:12:25

################################################################################
                     [1m Learning iteration 1160/1500 [0m                     

                       Computation: 50398 steps/s (collection: 1.855s, learning 0.096s)
             Mean action noise std: 3.57
          Mean value_function loss: 60.5190
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 57.8569
                       Mean reward: 702.72
               Mean episode length: 239.93
    Episode_Reward/reaching_object: 1.0732
    Episode_Reward/rotating_object: 141.2145
        Episode_Reward/action_rate: -0.0648
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 1.95s
                      Time elapsed: 00:42:16
                               ETA: 00:12:22

################################################################################
                     [1m Learning iteration 1161/1500 [0m                     

                       Computation: 48771 steps/s (collection: 1.914s, learning 0.101s)
             Mean action noise std: 3.57
          Mean value_function loss: 58.1886
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 57.8675
                       Mean reward: 690.36
               Mean episode length: 232.05
    Episode_Reward/reaching_object: 1.0850
    Episode_Reward/rotating_object: 142.4852
        Episode_Reward/action_rate: -0.0655
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 2.02s
                      Time elapsed: 00:42:18
                               ETA: 00:12:20

################################################################################
                     [1m Learning iteration 1162/1500 [0m                     

                       Computation: 48274 steps/s (collection: 1.878s, learning 0.158s)
             Mean action noise std: 3.57
          Mean value_function loss: 59.4263
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 57.8778
                       Mean reward: 751.23
               Mean episode length: 240.34
    Episode_Reward/reaching_object: 1.0847
    Episode_Reward/rotating_object: 144.7539
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 2.04s
                      Time elapsed: 00:42:20
                               ETA: 00:12:18

################################################################################
                     [1m Learning iteration 1163/1500 [0m                     

                       Computation: 47828 steps/s (collection: 1.899s, learning 0.156s)
             Mean action noise std: 3.57
          Mean value_function loss: 69.2624
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 57.8952
                       Mean reward: 721.62
               Mean episode length: 235.64
    Episode_Reward/reaching_object: 1.0827
    Episode_Reward/rotating_object: 145.2507
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 2.06s
                      Time elapsed: 00:42:22
                               ETA: 00:12:16

################################################################################
                     [1m Learning iteration 1164/1500 [0m                     

                       Computation: 48128 steps/s (collection: 1.935s, learning 0.107s)
             Mean action noise std: 3.58
          Mean value_function loss: 63.9868
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.9158
                       Mean reward: 721.99
               Mean episode length: 233.21
    Episode_Reward/reaching_object: 1.0845
    Episode_Reward/rotating_object: 145.9635
        Episode_Reward/action_rate: -0.0660
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 2.04s
                      Time elapsed: 00:42:24
                               ETA: 00:12:13

################################################################################
                     [1m Learning iteration 1165/1500 [0m                     

                       Computation: 49788 steps/s (collection: 1.880s, learning 0.095s)
             Mean action noise std: 3.58
          Mean value_function loss: 60.9935
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 57.9308
                       Mean reward: 704.68
               Mean episode length: 238.34
    Episode_Reward/reaching_object: 1.0902
    Episode_Reward/rotating_object: 144.0834
        Episode_Reward/action_rate: -0.0663
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 1.97s
                      Time elapsed: 00:42:26
                               ETA: 00:12:11

################################################################################
                     [1m Learning iteration 1166/1500 [0m                     

                       Computation: 49220 steps/s (collection: 1.882s, learning 0.116s)
             Mean action noise std: 3.58
          Mean value_function loss: 64.1136
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 57.9483
                       Mean reward: 721.57
               Mean episode length: 231.62
    Episode_Reward/reaching_object: 1.0593
    Episode_Reward/rotating_object: 139.5946
        Episode_Reward/action_rate: -0.0648
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 2.00s
                      Time elapsed: 00:42:28
                               ETA: 00:12:09

################################################################################
                     [1m Learning iteration 1167/1500 [0m                     

                       Computation: 49032 steps/s (collection: 1.891s, learning 0.114s)
             Mean action noise std: 3.58
          Mean value_function loss: 69.7156
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 57.9651
                       Mean reward: 719.76
               Mean episode length: 240.11
    Episode_Reward/reaching_object: 1.0895
    Episode_Reward/rotating_object: 145.4018
        Episode_Reward/action_rate: -0.0668
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 2.00s
                      Time elapsed: 00:42:30
                               ETA: 00:12:07

################################################################################
                     [1m Learning iteration 1168/1500 [0m                     

                       Computation: 47415 steps/s (collection: 1.953s, learning 0.120s)
             Mean action noise std: 3.59
          Mean value_function loss: 64.5036
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 57.9751
                       Mean reward: 758.64
               Mean episode length: 241.84
    Episode_Reward/reaching_object: 1.0858
    Episode_Reward/rotating_object: 146.1652
        Episode_Reward/action_rate: -0.0665
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 2.07s
                      Time elapsed: 00:42:32
                               ETA: 00:12:05

################################################################################
                     [1m Learning iteration 1169/1500 [0m                     

                       Computation: 48132 steps/s (collection: 1.920s, learning 0.123s)
             Mean action noise std: 3.59
          Mean value_function loss: 71.5894
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 57.9913
                       Mean reward: 733.93
               Mean episode length: 239.59
    Episode_Reward/reaching_object: 1.0812
    Episode_Reward/rotating_object: 144.1978
        Episode_Reward/action_rate: -0.0660
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 2.04s
                      Time elapsed: 00:42:35
                               ETA: 00:12:02

################################################################################
                     [1m Learning iteration 1170/1500 [0m                     

                       Computation: 51271 steps/s (collection: 1.815s, learning 0.103s)
             Mean action noise std: 3.59
          Mean value_function loss: 57.6824
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 58.0043
                       Mean reward: 780.43
               Mean episode length: 245.99
    Episode_Reward/reaching_object: 1.0902
    Episode_Reward/rotating_object: 149.0121
        Episode_Reward/action_rate: -0.0668
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 1.92s
                      Time elapsed: 00:42:36
                               ETA: 00:12:00

################################################################################
                     [1m Learning iteration 1171/1500 [0m                     

                       Computation: 46756 steps/s (collection: 1.937s, learning 0.165s)
             Mean action noise std: 3.59
          Mean value_function loss: 61.6618
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 58.0147
                       Mean reward: 775.96
               Mean episode length: 248.21
    Episode_Reward/reaching_object: 1.1009
    Episode_Reward/rotating_object: 150.1042
        Episode_Reward/action_rate: -0.0676
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 2.10s
                      Time elapsed: 00:42:39
                               ETA: 00:11:58

################################################################################
                     [1m Learning iteration 1172/1500 [0m                     

                       Computation: 50097 steps/s (collection: 1.864s, learning 0.099s)
             Mean action noise std: 3.60
          Mean value_function loss: 64.3800
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 58.0305
                       Mean reward: 691.70
               Mean episode length: 239.19
    Episode_Reward/reaching_object: 1.0566
    Episode_Reward/rotating_object: 140.1598
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 1.96s
                      Time elapsed: 00:42:41
                               ETA: 00:11:56

################################################################################
                     [1m Learning iteration 1173/1500 [0m                     

                       Computation: 50186 steps/s (collection: 1.852s, learning 0.107s)
             Mean action noise std: 3.60
          Mean value_function loss: 66.5718
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 58.0530
                       Mean reward: 752.11
               Mean episode length: 244.38
    Episode_Reward/reaching_object: 1.0774
    Episode_Reward/rotating_object: 143.1652
        Episode_Reward/action_rate: -0.0667
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 1.96s
                      Time elapsed: 00:42:42
                               ETA: 00:11:53

################################################################################
                     [1m Learning iteration 1174/1500 [0m                     

                       Computation: 50823 steps/s (collection: 1.839s, learning 0.096s)
             Mean action noise std: 3.60
          Mean value_function loss: 69.1814
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 58.0792
                       Mean reward: 707.48
               Mean episode length: 236.14
    Episode_Reward/reaching_object: 1.0596
    Episode_Reward/rotating_object: 139.9698
        Episode_Reward/action_rate: -0.0658
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 1.93s
                      Time elapsed: 00:42:44
                               ETA: 00:11:51

################################################################################
                     [1m Learning iteration 1175/1500 [0m                     

                       Computation: 50537 steps/s (collection: 1.846s, learning 0.099s)
             Mean action noise std: 3.61
          Mean value_function loss: 75.0536
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 58.0996
                       Mean reward: 709.59
               Mean episode length: 231.84
    Episode_Reward/reaching_object: 1.0898
    Episode_Reward/rotating_object: 147.1251
        Episode_Reward/action_rate: -0.0673
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 1.95s
                      Time elapsed: 00:42:46
                               ETA: 00:11:49

################################################################################
                     [1m Learning iteration 1176/1500 [0m                     

                       Computation: 50757 steps/s (collection: 1.843s, learning 0.094s)
             Mean action noise std: 3.61
          Mean value_function loss: 49.7540
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 58.1187
                       Mean reward: 733.52
               Mean episode length: 242.02
    Episode_Reward/reaching_object: 1.0702
    Episode_Reward/rotating_object: 144.8851
        Episode_Reward/action_rate: -0.0663
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 1.94s
                      Time elapsed: 00:42:48
                               ETA: 00:11:47

################################################################################
                     [1m Learning iteration 1177/1500 [0m                     

                       Computation: 50419 steps/s (collection: 1.857s, learning 0.093s)
             Mean action noise std: 3.61
          Mean value_function loss: 57.5087
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 58.1416
                       Mean reward: 714.52
               Mean episode length: 236.06
    Episode_Reward/reaching_object: 1.0825
    Episode_Reward/rotating_object: 142.1603
        Episode_Reward/action_rate: -0.0671
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 1.95s
                      Time elapsed: 00:42:50
                               ETA: 00:11:44

################################################################################
                     [1m Learning iteration 1178/1500 [0m                     

                       Computation: 50307 steps/s (collection: 1.865s, learning 0.089s)
             Mean action noise std: 3.62
          Mean value_function loss: 84.7026
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.1652
                       Mean reward: 738.07
               Mean episode length: 242.60
    Episode_Reward/reaching_object: 1.0723
    Episode_Reward/rotating_object: 144.9315
        Episode_Reward/action_rate: -0.0670
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 1.95s
                      Time elapsed: 00:42:52
                               ETA: 00:11:42

################################################################################
                     [1m Learning iteration 1179/1500 [0m                     

                       Computation: 52093 steps/s (collection: 1.798s, learning 0.090s)
             Mean action noise std: 3.62
          Mean value_function loss: 74.6792
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 58.1829
                       Mean reward: 719.48
               Mean episode length: 239.40
    Episode_Reward/reaching_object: 1.0636
    Episode_Reward/rotating_object: 141.8811
        Episode_Reward/action_rate: -0.0663
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 1.89s
                      Time elapsed: 00:42:54
                               ETA: 00:11:40

################################################################################
                     [1m Learning iteration 1180/1500 [0m                     

                       Computation: 50912 steps/s (collection: 1.836s, learning 0.095s)
             Mean action noise std: 3.62
          Mean value_function loss: 70.3886
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 58.1945
                       Mean reward: 738.42
               Mean episode length: 241.82
    Episode_Reward/reaching_object: 1.0767
    Episode_Reward/rotating_object: 144.5402
        Episode_Reward/action_rate: -0.0673
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 1.93s
                      Time elapsed: 00:42:56
                               ETA: 00:11:38

################################################################################
                     [1m Learning iteration 1181/1500 [0m                     

                       Computation: 50366 steps/s (collection: 1.847s, learning 0.104s)
             Mean action noise std: 3.62
          Mean value_function loss: 58.1482
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 58.2047
                       Mean reward: 738.32
               Mean episode length: 240.23
    Episode_Reward/reaching_object: 1.0787
    Episode_Reward/rotating_object: 145.7887
        Episode_Reward/action_rate: -0.0679
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 1.95s
                      Time elapsed: 00:42:58
                               ETA: 00:11:35

################################################################################
                     [1m Learning iteration 1182/1500 [0m                     

                       Computation: 49923 steps/s (collection: 1.859s, learning 0.110s)
             Mean action noise std: 3.63
          Mean value_function loss: 59.8318
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 58.2205
                       Mean reward: 728.82
               Mean episode length: 239.71
    Episode_Reward/reaching_object: 1.0732
    Episode_Reward/rotating_object: 145.9411
        Episode_Reward/action_rate: -0.0679
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 1.97s
                      Time elapsed: 00:43:00
                               ETA: 00:11:33

################################################################################
                     [1m Learning iteration 1183/1500 [0m                     

                       Computation: 50406 steps/s (collection: 1.829s, learning 0.122s)
             Mean action noise std: 3.63
          Mean value_function loss: 72.3658
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 58.2362
                       Mean reward: 747.64
               Mean episode length: 241.62
    Episode_Reward/reaching_object: 1.0730
    Episode_Reward/rotating_object: 144.5067
        Episode_Reward/action_rate: -0.0677
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 1.95s
                      Time elapsed: 00:43:02
                               ETA: 00:11:31

################################################################################
                     [1m Learning iteration 1184/1500 [0m                     

                       Computation: 50169 steps/s (collection: 1.873s, learning 0.087s)
             Mean action noise std: 3.63
          Mean value_function loss: 70.8917
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 58.2489
                       Mean reward: 708.35
               Mean episode length: 233.24
    Episode_Reward/reaching_object: 1.0677
    Episode_Reward/rotating_object: 142.1122
        Episode_Reward/action_rate: -0.0673
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 1.96s
                      Time elapsed: 00:43:04
                               ETA: 00:11:29

################################################################################
                     [1m Learning iteration 1185/1500 [0m                     

                       Computation: 48462 steps/s (collection: 1.871s, learning 0.157s)
             Mean action noise std: 3.63
          Mean value_function loss: 61.0323
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 58.2599
                       Mean reward: 749.99
               Mean episode length: 240.93
    Episode_Reward/reaching_object: 1.0661
    Episode_Reward/rotating_object: 145.4498
        Episode_Reward/action_rate: -0.0672
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 2.03s
                      Time elapsed: 00:43:06
                               ETA: 00:11:26

################################################################################
                     [1m Learning iteration 1186/1500 [0m                     

                       Computation: 51563 steps/s (collection: 1.799s, learning 0.108s)
             Mean action noise std: 3.64
          Mean value_function loss: 69.1380
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 58.2684
                       Mean reward: 734.80
               Mean episode length: 237.61
    Episode_Reward/reaching_object: 1.0811
    Episode_Reward/rotating_object: 146.9979
        Episode_Reward/action_rate: -0.0683
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 1.91s
                      Time elapsed: 00:43:08
                               ETA: 00:11:24

################################################################################
                     [1m Learning iteration 1187/1500 [0m                     

                       Computation: 50268 steps/s (collection: 1.832s, learning 0.124s)
             Mean action noise std: 3.64
          Mean value_function loss: 77.7005
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 58.2752
                       Mean reward: 732.83
               Mean episode length: 237.82
    Episode_Reward/reaching_object: 1.0676
    Episode_Reward/rotating_object: 142.7422
        Episode_Reward/action_rate: -0.0673
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 1.96s
                      Time elapsed: 00:43:10
                               ETA: 00:11:22

################################################################################
                     [1m Learning iteration 1188/1500 [0m                     

                       Computation: 49674 steps/s (collection: 1.842s, learning 0.137s)
             Mean action noise std: 3.64
          Mean value_function loss: 55.6499
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 58.2872
                       Mean reward: 729.09
               Mean episode length: 239.70
    Episode_Reward/reaching_object: 1.0778
    Episode_Reward/rotating_object: 146.2355
        Episode_Reward/action_rate: -0.0681
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 1.98s
                      Time elapsed: 00:43:12
                               ETA: 00:11:20

################################################################################
                     [1m Learning iteration 1189/1500 [0m                     

                       Computation: 49245 steps/s (collection: 1.854s, learning 0.143s)
             Mean action noise std: 3.64
          Mean value_function loss: 55.6530
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.2995
                       Mean reward: 718.72
               Mean episode length: 242.10
    Episode_Reward/reaching_object: 1.0937
    Episode_Reward/rotating_object: 144.5212
        Episode_Reward/action_rate: -0.0691
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 2.00s
                      Time elapsed: 00:43:14
                               ETA: 00:11:17

################################################################################
                     [1m Learning iteration 1190/1500 [0m                     

                       Computation: 50657 steps/s (collection: 1.816s, learning 0.124s)
             Mean action noise std: 3.64
          Mean value_function loss: 69.3621
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 58.3125
                       Mean reward: 727.90
               Mean episode length: 238.79
    Episode_Reward/reaching_object: 1.0736
    Episode_Reward/rotating_object: 144.9678
        Episode_Reward/action_rate: -0.0680
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 1.94s
                      Time elapsed: 00:43:16
                               ETA: 00:11:15

################################################################################
                     [1m Learning iteration 1191/1500 [0m                     

                       Computation: 51265 steps/s (collection: 1.822s, learning 0.096s)
             Mean action noise std: 3.65
          Mean value_function loss: 83.6332
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 58.3191
                       Mean reward: 749.08
               Mean episode length: 240.44
    Episode_Reward/reaching_object: 1.0750
    Episode_Reward/rotating_object: 142.7512
        Episode_Reward/action_rate: -0.0680
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 1.92s
                      Time elapsed: 00:43:18
                               ETA: 00:11:13

################################################################################
                     [1m Learning iteration 1192/1500 [0m                     

                       Computation: 50577 steps/s (collection: 1.850s, learning 0.094s)
             Mean action noise std: 3.65
          Mean value_function loss: 74.7464
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 58.3323
                       Mean reward: 705.48
               Mean episode length: 229.31
    Episode_Reward/reaching_object: 1.0708
    Episode_Reward/rotating_object: 142.8199
        Episode_Reward/action_rate: -0.0677
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 1.94s
                      Time elapsed: 00:43:20
                               ETA: 00:11:11

################################################################################
                     [1m Learning iteration 1193/1500 [0m                     

                       Computation: 50506 steps/s (collection: 1.844s, learning 0.103s)
             Mean action noise std: 3.65
          Mean value_function loss: 75.1605
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 58.3484
                       Mean reward: 703.00
               Mean episode length: 232.38
    Episode_Reward/reaching_object: 1.0817
    Episode_Reward/rotating_object: 147.4465
        Episode_Reward/action_rate: -0.0687
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 1.95s
                      Time elapsed: 00:43:21
                               ETA: 00:11:09

################################################################################
                     [1m Learning iteration 1194/1500 [0m                     

                       Computation: 49951 steps/s (collection: 1.875s, learning 0.093s)
             Mean action noise std: 3.66
          Mean value_function loss: 57.3321
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 58.3668
                       Mean reward: 783.99
               Mean episode length: 248.40
    Episode_Reward/reaching_object: 1.0936
    Episode_Reward/rotating_object: 147.1629
        Episode_Reward/action_rate: -0.0693
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 1.97s
                      Time elapsed: 00:43:23
                               ETA: 00:11:06

################################################################################
                     [1m Learning iteration 1195/1500 [0m                     

                       Computation: 49189 steps/s (collection: 1.904s, learning 0.095s)
             Mean action noise std: 3.66
          Mean value_function loss: 74.8651
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 58.3832
                       Mean reward: 697.79
               Mean episode length: 233.09
    Episode_Reward/reaching_object: 1.0611
    Episode_Reward/rotating_object: 142.7510
        Episode_Reward/action_rate: -0.0675
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 2.00s
                      Time elapsed: 00:43:25
                               ETA: 00:11:04

################################################################################
                     [1m Learning iteration 1196/1500 [0m                     

                       Computation: 48481 steps/s (collection: 1.931s, learning 0.097s)
             Mean action noise std: 3.66
          Mean value_function loss: 75.3836
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 58.3933
                       Mean reward: 757.19
               Mean episode length: 241.92
    Episode_Reward/reaching_object: 1.0686
    Episode_Reward/rotating_object: 144.2284
        Episode_Reward/action_rate: -0.0681
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 2.03s
                      Time elapsed: 00:43:27
                               ETA: 00:11:02

################################################################################
                     [1m Learning iteration 1197/1500 [0m                     

                       Computation: 50242 steps/s (collection: 1.860s, learning 0.097s)
             Mean action noise std: 3.66
          Mean value_function loss: 72.0089
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 58.4029
                       Mean reward: 725.91
               Mean episode length: 238.81
    Episode_Reward/reaching_object: 1.0874
    Episode_Reward/rotating_object: 145.9266
        Episode_Reward/action_rate: -0.0692
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 1.96s
                      Time elapsed: 00:43:29
                               ETA: 00:11:00

################################################################################
                     [1m Learning iteration 1198/1500 [0m                     

                       Computation: 45177 steps/s (collection: 1.950s, learning 0.226s)
             Mean action noise std: 3.66
          Mean value_function loss: 70.8788
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 58.4159
                       Mean reward: 746.09
               Mean episode length: 235.47
    Episode_Reward/reaching_object: 1.0654
    Episode_Reward/rotating_object: 144.3859
        Episode_Reward/action_rate: -0.0682
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 2.18s
                      Time elapsed: 00:43:32
                               ETA: 00:10:57

################################################################################
                     [1m Learning iteration 1199/1500 [0m                     

                       Computation: 40486 steps/s (collection: 2.273s, learning 0.156s)
             Mean action noise std: 3.67
          Mean value_function loss: 74.6237
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 58.4287
                       Mean reward: 704.26
               Mean episode length: 237.32
    Episode_Reward/reaching_object: 1.0726
    Episode_Reward/rotating_object: 141.6940
        Episode_Reward/action_rate: -0.0689
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 2.43s
                      Time elapsed: 00:43:34
                               ETA: 00:10:55

################################################################################
                     [1m Learning iteration 1200/1500 [0m                     

                       Computation: 45832 steps/s (collection: 2.020s, learning 0.125s)
             Mean action noise std: 3.67
          Mean value_function loss: 70.6492
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 58.4426
                       Mean reward: 715.96
               Mean episode length: 241.08
    Episode_Reward/reaching_object: 1.0858
    Episode_Reward/rotating_object: 143.4344
        Episode_Reward/action_rate: -0.0697
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 18.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 2.14s
                      Time elapsed: 00:43:36
                               ETA: 00:10:53

################################################################################
                     [1m Learning iteration 1201/1500 [0m                     

                       Computation: 48950 steps/s (collection: 1.895s, learning 0.114s)
             Mean action noise std: 3.67
          Mean value_function loss: 72.1062
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 58.4578
                       Mean reward: 735.23
               Mean episode length: 237.69
    Episode_Reward/reaching_object: 1.0833
    Episode_Reward/rotating_object: 143.9077
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 2.01s
                      Time elapsed: 00:43:38
                               ETA: 00:10:51

################################################################################
                     [1m Learning iteration 1202/1500 [0m                     

                       Computation: 49080 steps/s (collection: 1.882s, learning 0.121s)
             Mean action noise std: 3.68
          Mean value_function loss: 56.6033
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 58.4718
                       Mean reward: 739.62
               Mean episode length: 231.83
    Episode_Reward/reaching_object: 1.0585
    Episode_Reward/rotating_object: 143.9578
        Episode_Reward/action_rate: -0.0683
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 2.00s
                      Time elapsed: 00:43:40
                               ETA: 00:10:49

################################################################################
                     [1m Learning iteration 1203/1500 [0m                     

                       Computation: 49425 steps/s (collection: 1.896s, learning 0.093s)
             Mean action noise std: 3.68
          Mean value_function loss: 74.7338
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.4881
                       Mean reward: 734.80
               Mean episode length: 238.19
    Episode_Reward/reaching_object: 1.0797
    Episode_Reward/rotating_object: 146.1120
        Episode_Reward/action_rate: -0.0704
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 1.99s
                      Time elapsed: 00:43:42
                               ETA: 00:10:46

################################################################################
                     [1m Learning iteration 1204/1500 [0m                     

                       Computation: 49974 steps/s (collection: 1.871s, learning 0.096s)
             Mean action noise std: 3.68
          Mean value_function loss: 65.0087
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 58.5070
                       Mean reward: 733.49
               Mean episode length: 240.76
    Episode_Reward/reaching_object: 1.0799
    Episode_Reward/rotating_object: 148.6116
        Episode_Reward/action_rate: -0.0706
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 1.97s
                      Time elapsed: 00:43:44
                               ETA: 00:10:44

################################################################################
                     [1m Learning iteration 1205/1500 [0m                     

                       Computation: 50070 steps/s (collection: 1.851s, learning 0.113s)
             Mean action noise std: 3.69
          Mean value_function loss: 51.1918
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 58.5257
                       Mean reward: 728.62
               Mean episode length: 236.40
    Episode_Reward/reaching_object: 1.0722
    Episode_Reward/rotating_object: 145.4227
        Episode_Reward/action_rate: -0.0700
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 1.96s
                      Time elapsed: 00:43:46
                               ETA: 00:10:42

################################################################################
                     [1m Learning iteration 1206/1500 [0m                     

                       Computation: 49892 steps/s (collection: 1.873s, learning 0.098s)
             Mean action noise std: 3.69
          Mean value_function loss: 64.9805
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 58.5460
                       Mean reward: 680.29
               Mean episode length: 231.96
    Episode_Reward/reaching_object: 1.0549
    Episode_Reward/rotating_object: 140.8064
        Episode_Reward/action_rate: -0.0694
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 1.97s
                      Time elapsed: 00:43:48
                               ETA: 00:10:40

################################################################################
                     [1m Learning iteration 1207/1500 [0m                     

                       Computation: 45713 steps/s (collection: 2.027s, learning 0.123s)
             Mean action noise std: 3.69
          Mean value_function loss: 69.7602
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 58.5556
                       Mean reward: 728.14
               Mean episode length: 242.93
    Episode_Reward/reaching_object: 1.0591
    Episode_Reward/rotating_object: 144.2894
        Episode_Reward/action_rate: -0.0697
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 2.15s
                      Time elapsed: 00:43:50
                               ETA: 00:10:38

################################################################################
                     [1m Learning iteration 1208/1500 [0m                     

                       Computation: 47049 steps/s (collection: 1.994s, learning 0.095s)
             Mean action noise std: 3.69
          Mean value_function loss: 73.6330
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.5671
                       Mean reward: 710.69
               Mean episode length: 231.88
    Episode_Reward/reaching_object: 1.0677
    Episode_Reward/rotating_object: 145.0065
        Episode_Reward/action_rate: -0.0700
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 2.09s
                      Time elapsed: 00:43:52
                               ETA: 00:10:35

################################################################################
                     [1m Learning iteration 1209/1500 [0m                     

                       Computation: 48908 steps/s (collection: 1.905s, learning 0.105s)
             Mean action noise std: 3.70
          Mean value_function loss: 70.7086
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 58.5849
                       Mean reward: 724.35
               Mean episode length: 241.04
    Episode_Reward/reaching_object: 1.0786
    Episode_Reward/rotating_object: 146.3936
        Episode_Reward/action_rate: -0.0709
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 2.01s
                      Time elapsed: 00:43:54
                               ETA: 00:10:33

################################################################################
                     [1m Learning iteration 1210/1500 [0m                     

                       Computation: 49595 steps/s (collection: 1.886s, learning 0.097s)
             Mean action noise std: 3.70
          Mean value_function loss: 65.5516
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 58.6060
                       Mean reward: 703.26
               Mean episode length: 232.37
    Episode_Reward/reaching_object: 1.0437
    Episode_Reward/rotating_object: 143.1626
        Episode_Reward/action_rate: -0.0690
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 1.98s
                      Time elapsed: 00:43:56
                               ETA: 00:10:31

################################################################################
                     [1m Learning iteration 1211/1500 [0m                     

                       Computation: 50218 steps/s (collection: 1.857s, learning 0.101s)
             Mean action noise std: 3.70
          Mean value_function loss: 59.2122
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 58.6330
                       Mean reward: 762.50
               Mean episode length: 240.14
    Episode_Reward/reaching_object: 1.0754
    Episode_Reward/rotating_object: 148.8377
        Episode_Reward/action_rate: -0.0715
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 1.96s
                      Time elapsed: 00:43:58
                               ETA: 00:10:29

################################################################################
                     [1m Learning iteration 1212/1500 [0m                     

                       Computation: 47658 steps/s (collection: 1.968s, learning 0.095s)
             Mean action noise std: 3.71
          Mean value_function loss: 56.7503
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.6556
                       Mean reward: 736.92
               Mean episode length: 243.36
    Episode_Reward/reaching_object: 1.0900
    Episode_Reward/rotating_object: 147.1688
        Episode_Reward/action_rate: -0.0718
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 2.06s
                      Time elapsed: 00:44:00
                               ETA: 00:10:27

################################################################################
                     [1m Learning iteration 1213/1500 [0m                     

                       Computation: 47537 steps/s (collection: 1.948s, learning 0.120s)
             Mean action noise std: 3.71
          Mean value_function loss: 71.8148
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 58.6715
                       Mean reward: 762.50
               Mean episode length: 243.70
    Episode_Reward/reaching_object: 1.0705
    Episode_Reward/rotating_object: 147.0715
        Episode_Reward/action_rate: -0.0708
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 2.07s
                      Time elapsed: 00:44:02
                               ETA: 00:10:24

################################################################################
                     [1m Learning iteration 1214/1500 [0m                     

                       Computation: 49396 steps/s (collection: 1.896s, learning 0.095s)
             Mean action noise std: 3.71
          Mean value_function loss: 72.2095
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 58.6841
                       Mean reward: 711.30
               Mean episode length: 235.32
    Episode_Reward/reaching_object: 1.0524
    Episode_Reward/rotating_object: 142.6330
        Episode_Reward/action_rate: -0.0701
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 1.99s
                      Time elapsed: 00:44:04
                               ETA: 00:10:22

################################################################################
                     [1m Learning iteration 1215/1500 [0m                     

                       Computation: 48924 steps/s (collection: 1.917s, learning 0.093s)
             Mean action noise std: 3.71
          Mean value_function loss: 69.0006
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 58.6960
                       Mean reward: 700.54
               Mean episode length: 233.63
    Episode_Reward/reaching_object: 1.0494
    Episode_Reward/rotating_object: 141.5618
        Episode_Reward/action_rate: -0.0700
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 2.01s
                      Time elapsed: 00:44:06
                               ETA: 00:10:20

################################################################################
                     [1m Learning iteration 1216/1500 [0m                     

                       Computation: 48862 steps/s (collection: 1.904s, learning 0.108s)
             Mean action noise std: 3.72
          Mean value_function loss: 71.2174
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 58.7137
                       Mean reward: 755.40
               Mean episode length: 245.62
    Episode_Reward/reaching_object: 1.0900
    Episode_Reward/rotating_object: 147.6509
        Episode_Reward/action_rate: -0.0726
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 2.01s
                      Time elapsed: 00:44:08
                               ETA: 00:10:18

################################################################################
                     [1m Learning iteration 1217/1500 [0m                     

                       Computation: 49281 steps/s (collection: 1.884s, learning 0.111s)
             Mean action noise std: 3.72
          Mean value_function loss: 56.6054
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 58.7343
                       Mean reward: 746.06
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 1.0796
    Episode_Reward/rotating_object: 145.1073
        Episode_Reward/action_rate: -0.0723
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 1.99s
                      Time elapsed: 00:44:10
                               ETA: 00:10:15

################################################################################
                     [1m Learning iteration 1218/1500 [0m                     

                       Computation: 48540 steps/s (collection: 1.913s, learning 0.112s)
             Mean action noise std: 3.72
          Mean value_function loss: 55.2303
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 58.7468
                       Mean reward: 755.06
               Mean episode length: 245.33
    Episode_Reward/reaching_object: 1.0773
    Episode_Reward/rotating_object: 145.5938
        Episode_Reward/action_rate: -0.0722
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 2.03s
                      Time elapsed: 00:44:12
                               ETA: 00:10:13

################################################################################
                     [1m Learning iteration 1219/1500 [0m                     

                       Computation: 50638 steps/s (collection: 1.847s, learning 0.095s)
             Mean action noise std: 3.72
          Mean value_function loss: 58.8376
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 58.7573
                       Mean reward: 746.89
               Mean episode length: 243.39
    Episode_Reward/reaching_object: 1.0788
    Episode_Reward/rotating_object: 146.0521
        Episode_Reward/action_rate: -0.0722
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 1.94s
                      Time elapsed: 00:44:14
                               ETA: 00:10:11

################################################################################
                     [1m Learning iteration 1220/1500 [0m                     

                       Computation: 48857 steps/s (collection: 1.918s, learning 0.095s)
             Mean action noise std: 3.73
          Mean value_function loss: 57.8314
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 58.7725
                       Mean reward: 757.87
               Mean episode length: 242.47
    Episode_Reward/reaching_object: 1.0777
    Episode_Reward/rotating_object: 147.6836
        Episode_Reward/action_rate: -0.0728
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 2.01s
                      Time elapsed: 00:44:16
                               ETA: 00:10:09

################################################################################
                     [1m Learning iteration 1221/1500 [0m                     

                       Computation: 47929 steps/s (collection: 1.918s, learning 0.133s)
             Mean action noise std: 3.73
          Mean value_function loss: 50.6047
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 58.7902
                       Mean reward: 732.65
               Mean episode length: 238.37
    Episode_Reward/reaching_object: 1.0838
    Episode_Reward/rotating_object: 146.4746
        Episode_Reward/action_rate: -0.0730
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 2.05s
                      Time elapsed: 00:44:18
                               ETA: 00:10:07

################################################################################
                     [1m Learning iteration 1222/1500 [0m                     

                       Computation: 48796 steps/s (collection: 1.896s, learning 0.118s)
             Mean action noise std: 3.73
          Mean value_function loss: 70.3733
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 58.8034
                       Mean reward: 702.92
               Mean episode length: 228.15
    Episode_Reward/reaching_object: 1.0692
    Episode_Reward/rotating_object: 143.2258
        Episode_Reward/action_rate: -0.0722
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 2.01s
                      Time elapsed: 00:44:20
                               ETA: 00:10:04

################################################################################
                     [1m Learning iteration 1223/1500 [0m                     

                       Computation: 46513 steps/s (collection: 1.959s, learning 0.155s)
             Mean action noise std: 3.73
          Mean value_function loss: 55.1931
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 58.8158
                       Mean reward: 745.81
               Mean episode length: 237.62
    Episode_Reward/reaching_object: 1.0714
    Episode_Reward/rotating_object: 144.3287
        Episode_Reward/action_rate: -0.0724
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 2.11s
                      Time elapsed: 00:44:23
                               ETA: 00:10:02

################################################################################
                     [1m Learning iteration 1224/1500 [0m                     

                       Computation: 48840 steps/s (collection: 1.912s, learning 0.101s)
             Mean action noise std: 3.74
          Mean value_function loss: 59.2129
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 58.8287
                       Mean reward: 721.84
               Mean episode length: 238.39
    Episode_Reward/reaching_object: 1.0710
    Episode_Reward/rotating_object: 148.3564
        Episode_Reward/action_rate: -0.0728
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 2.01s
                      Time elapsed: 00:44:25
                               ETA: 00:10:00

################################################################################
                     [1m Learning iteration 1225/1500 [0m                     

                       Computation: 49342 steps/s (collection: 1.892s, learning 0.101s)
             Mean action noise std: 3.74
          Mean value_function loss: 60.1457
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 58.8403
                       Mean reward: 689.67
               Mean episode length: 238.60
    Episode_Reward/reaching_object: 1.0724
    Episode_Reward/rotating_object: 144.0804
        Episode_Reward/action_rate: -0.0728
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 1.99s
                      Time elapsed: 00:44:27
                               ETA: 00:09:58

################################################################################
                     [1m Learning iteration 1226/1500 [0m                     

                       Computation: 47636 steps/s (collection: 1.904s, learning 0.160s)
             Mean action noise std: 3.74
          Mean value_function loss: 76.3472
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 58.8633
                       Mean reward: 741.76
               Mean episode length: 240.86
    Episode_Reward/reaching_object: 1.0701
    Episode_Reward/rotating_object: 144.6549
        Episode_Reward/action_rate: -0.0722
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 2.06s
                      Time elapsed: 00:44:29
                               ETA: 00:09:56

################################################################################
                     [1m Learning iteration 1227/1500 [0m                     

                       Computation: 48514 steps/s (collection: 1.928s, learning 0.098s)
             Mean action noise std: 3.75
          Mean value_function loss: 78.2169
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 58.8788
                       Mean reward: 724.86
               Mean episode length: 235.59
    Episode_Reward/reaching_object: 1.0643
    Episode_Reward/rotating_object: 143.7905
        Episode_Reward/action_rate: -0.0721
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 2.03s
                      Time elapsed: 00:44:31
                               ETA: 00:09:53

################################################################################
                     [1m Learning iteration 1228/1500 [0m                     

                       Computation: 48868 steps/s (collection: 1.903s, learning 0.109s)
             Mean action noise std: 3.75
          Mean value_function loss: 58.6872
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 58.8851
                       Mean reward: 759.96
               Mean episode length: 241.59
    Episode_Reward/reaching_object: 1.0908
    Episode_Reward/rotating_object: 149.3572
        Episode_Reward/action_rate: -0.0737
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 2.01s
                      Time elapsed: 00:44:33
                               ETA: 00:09:51

################################################################################
                     [1m Learning iteration 1229/1500 [0m                     

                       Computation: 49477 steps/s (collection: 1.885s, learning 0.102s)
             Mean action noise std: 3.75
          Mean value_function loss: 48.4405
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 58.8963
                       Mean reward: 707.96
               Mean episode length: 236.00
    Episode_Reward/reaching_object: 1.0756
    Episode_Reward/rotating_object: 144.2451
        Episode_Reward/action_rate: -0.0731
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 1.99s
                      Time elapsed: 00:44:35
                               ETA: 00:09:49

################################################################################
                     [1m Learning iteration 1230/1500 [0m                     

                       Computation: 49144 steps/s (collection: 1.901s, learning 0.100s)
             Mean action noise std: 3.75
          Mean value_function loss: 56.0234
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 58.9174
                       Mean reward: 747.58
               Mean episode length: 238.21
    Episode_Reward/reaching_object: 1.0794
    Episode_Reward/rotating_object: 147.1229
        Episode_Reward/action_rate: -0.0733
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 2.00s
                      Time elapsed: 00:44:37
                               ETA: 00:09:47

################################################################################
                     [1m Learning iteration 1231/1500 [0m                     

                       Computation: 48623 steps/s (collection: 1.900s, learning 0.122s)
             Mean action noise std: 3.76
          Mean value_function loss: 66.0947
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 58.9320
                       Mean reward: 751.04
               Mean episode length: 239.29
    Episode_Reward/reaching_object: 1.0811
    Episode_Reward/rotating_object: 146.4865
        Episode_Reward/action_rate: -0.0733
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 2.02s
                      Time elapsed: 00:44:39
                               ETA: 00:09:44

################################################################################
                     [1m Learning iteration 1232/1500 [0m                     

                       Computation: 43091 steps/s (collection: 2.137s, learning 0.144s)
             Mean action noise std: 3.76
          Mean value_function loss: 57.4516
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 58.9437
                       Mean reward: 722.65
               Mean episode length: 242.39
    Episode_Reward/reaching_object: 1.0757
    Episode_Reward/rotating_object: 143.9057
        Episode_Reward/action_rate: -0.0736
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 2.28s
                      Time elapsed: 00:44:41
                               ETA: 00:09:42

################################################################################
                     [1m Learning iteration 1233/1500 [0m                     

                       Computation: 45372 steps/s (collection: 2.021s, learning 0.145s)
             Mean action noise std: 3.76
          Mean value_function loss: 69.7171
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 58.9560
                       Mean reward: 706.09
               Mean episode length: 230.44
    Episode_Reward/reaching_object: 1.0731
    Episode_Reward/rotating_object: 145.1816
        Episode_Reward/action_rate: -0.0732
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 2.17s
                      Time elapsed: 00:44:43
                               ETA: 00:09:40

################################################################################
                     [1m Learning iteration 1234/1500 [0m                     

                       Computation: 47626 steps/s (collection: 1.950s, learning 0.114s)
             Mean action noise std: 3.76
          Mean value_function loss: 63.5047
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 58.9675
                       Mean reward: 722.45
               Mean episode length: 241.55
    Episode_Reward/reaching_object: 1.0914
    Episode_Reward/rotating_object: 148.4639
        Episode_Reward/action_rate: -0.0742
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 2.06s
                      Time elapsed: 00:44:45
                               ETA: 00:09:38

################################################################################
                     [1m Learning iteration 1235/1500 [0m                     

                       Computation: 46903 steps/s (collection: 1.975s, learning 0.121s)
             Mean action noise std: 3.77
          Mean value_function loss: 58.3593
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 58.9818
                       Mean reward: 702.43
               Mean episode length: 236.23
    Episode_Reward/reaching_object: 1.0844
    Episode_Reward/rotating_object: 144.1412
        Episode_Reward/action_rate: -0.0740
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 2.10s
                      Time elapsed: 00:44:47
                               ETA: 00:09:36

################################################################################
                     [1m Learning iteration 1236/1500 [0m                     

                       Computation: 47874 steps/s (collection: 1.944s, learning 0.109s)
             Mean action noise std: 3.77
          Mean value_function loss: 55.6741
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 58.9929
                       Mean reward: 722.73
               Mean episode length: 238.78
    Episode_Reward/reaching_object: 1.0732
    Episode_Reward/rotating_object: 145.4931
        Episode_Reward/action_rate: -0.0735
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 2.05s
                      Time elapsed: 00:44:49
                               ETA: 00:09:34

################################################################################
                     [1m Learning iteration 1237/1500 [0m                     

                       Computation: 36809 steps/s (collection: 2.482s, learning 0.188s)
             Mean action noise std: 3.77
          Mean value_function loss: 78.4163
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 59.0039
                       Mean reward: 716.70
               Mean episode length: 236.39
    Episode_Reward/reaching_object: 1.0788
    Episode_Reward/rotating_object: 142.8554
        Episode_Reward/action_rate: -0.0738
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 2.67s
                      Time elapsed: 00:44:52
                               ETA: 00:09:31

################################################################################
                     [1m Learning iteration 1238/1500 [0m                     

                       Computation: 41648 steps/s (collection: 2.236s, learning 0.124s)
             Mean action noise std: 3.77
          Mean value_function loss: 66.8027
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 59.0163
                       Mean reward: 711.69
               Mean episode length: 239.35
    Episode_Reward/reaching_object: 1.0890
    Episode_Reward/rotating_object: 145.8639
        Episode_Reward/action_rate: -0.0742
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 2.36s
                      Time elapsed: 00:44:54
                               ETA: 00:09:29

################################################################################
                     [1m Learning iteration 1239/1500 [0m                     

                       Computation: 47365 steps/s (collection: 1.975s, learning 0.100s)
             Mean action noise std: 3.78
          Mean value_function loss: 60.9296
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 59.0327
                       Mean reward: 782.03
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 1.0837
    Episode_Reward/rotating_object: 145.7810
        Episode_Reward/action_rate: -0.0740
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 2.08s
                      Time elapsed: 00:44:56
                               ETA: 00:09:27

################################################################################
                     [1m Learning iteration 1240/1500 [0m                     

                       Computation: 47909 steps/s (collection: 1.949s, learning 0.103s)
             Mean action noise std: 3.78
          Mean value_function loss: 60.6131
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.0533
                       Mean reward: 768.08
               Mean episode length: 238.27
    Episode_Reward/reaching_object: 1.0629
    Episode_Reward/rotating_object: 145.4326
        Episode_Reward/action_rate: -0.0728
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 2.05s
                      Time elapsed: 00:44:58
                               ETA: 00:09:25

################################################################################
                     [1m Learning iteration 1241/1500 [0m                     

                       Computation: 47563 steps/s (collection: 1.965s, learning 0.102s)
             Mean action noise std: 3.78
          Mean value_function loss: 63.8445
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 59.0675
                       Mean reward: 731.40
               Mean episode length: 244.61
    Episode_Reward/reaching_object: 1.0799
    Episode_Reward/rotating_object: 144.4086
        Episode_Reward/action_rate: -0.0740
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 2.07s
                      Time elapsed: 00:45:01
                               ETA: 00:09:23

################################################################################
                     [1m Learning iteration 1242/1500 [0m                     

                       Computation: 47192 steps/s (collection: 1.980s, learning 0.103s)
             Mean action noise std: 3.79
          Mean value_function loss: 55.2921
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 59.0897
                       Mean reward: 761.81
               Mean episode length: 243.67
    Episode_Reward/reaching_object: 1.0866
    Episode_Reward/rotating_object: 146.7311
        Episode_Reward/action_rate: -0.0744
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 2.08s
                      Time elapsed: 00:45:03
                               ETA: 00:09:21

################################################################################
                     [1m Learning iteration 1243/1500 [0m                     

                       Computation: 46526 steps/s (collection: 1.970s, learning 0.143s)
             Mean action noise std: 3.79
          Mean value_function loss: 67.3267
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.1126
                       Mean reward: 732.60
               Mean episode length: 235.80
    Episode_Reward/reaching_object: 1.0807
    Episode_Reward/rotating_object: 146.0700
        Episode_Reward/action_rate: -0.0738
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 2.11s
                      Time elapsed: 00:45:05
                               ETA: 00:09:18

################################################################################
                     [1m Learning iteration 1244/1500 [0m                     

                       Computation: 47743 steps/s (collection: 1.956s, learning 0.103s)
             Mean action noise std: 3.79
          Mean value_function loss: 66.2958
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 59.1267
                       Mean reward: 751.11
               Mean episode length: 239.68
    Episode_Reward/reaching_object: 1.0816
    Episode_Reward/rotating_object: 143.9377
        Episode_Reward/action_rate: -0.0739
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 2.06s
                      Time elapsed: 00:45:07
                               ETA: 00:09:16

################################################################################
                     [1m Learning iteration 1245/1500 [0m                     

                       Computation: 47947 steps/s (collection: 1.952s, learning 0.099s)
             Mean action noise std: 3.80
          Mean value_function loss: 47.0022
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 59.1378
                       Mean reward: 740.58
               Mean episode length: 240.66
    Episode_Reward/reaching_object: 1.0693
    Episode_Reward/rotating_object: 142.9955
        Episode_Reward/action_rate: -0.0732
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 2.05s
                      Time elapsed: 00:45:09
                               ETA: 00:09:14

################################################################################
                     [1m Learning iteration 1246/1500 [0m                     

                       Computation: 47307 steps/s (collection: 1.962s, learning 0.116s)
             Mean action noise std: 3.80
          Mean value_function loss: 66.0021
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 59.1479
                       Mean reward: 706.06
               Mean episode length: 237.60
    Episode_Reward/reaching_object: 1.0883
    Episode_Reward/rotating_object: 146.1420
        Episode_Reward/action_rate: -0.0746
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 2.08s
                      Time elapsed: 00:45:11
                               ETA: 00:09:12

################################################################################
                     [1m Learning iteration 1247/1500 [0m                     

                       Computation: 48175 steps/s (collection: 1.941s, learning 0.100s)
             Mean action noise std: 3.80
          Mean value_function loss: 49.3652
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 59.1603
                       Mean reward: 771.25
               Mean episode length: 242.67
    Episode_Reward/reaching_object: 1.0997
    Episode_Reward/rotating_object: 147.7525
        Episode_Reward/action_rate: -0.0753
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 2.04s
                      Time elapsed: 00:45:13
                               ETA: 00:09:10

################################################################################
                     [1m Learning iteration 1248/1500 [0m                     

                       Computation: 46277 steps/s (collection: 1.954s, learning 0.170s)
             Mean action noise std: 3.80
          Mean value_function loss: 67.3311
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 59.1750
                       Mean reward: 776.92
               Mean episode length: 247.07
    Episode_Reward/reaching_object: 1.0871
    Episode_Reward/rotating_object: 146.8255
        Episode_Reward/action_rate: -0.0749
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 2.12s
                      Time elapsed: 00:45:15
                               ETA: 00:09:07

################################################################################
                     [1m Learning iteration 1249/1500 [0m                     

                       Computation: 46903 steps/s (collection: 1.945s, learning 0.151s)
             Mean action noise std: 3.80
          Mean value_function loss: 70.8632
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 59.1879
                       Mean reward: 755.31
               Mean episode length: 242.02
    Episode_Reward/reaching_object: 1.0989
    Episode_Reward/rotating_object: 150.9933
        Episode_Reward/action_rate: -0.0753
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 2.10s
                      Time elapsed: 00:45:17
                               ETA: 00:09:05

################################################################################
                     [1m Learning iteration 1250/1500 [0m                     

                       Computation: 46484 steps/s (collection: 1.964s, learning 0.151s)
             Mean action noise std: 3.81
          Mean value_function loss: 46.6875
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 59.2007
                       Mean reward: 778.72
               Mean episode length: 246.38
    Episode_Reward/reaching_object: 1.1097
    Episode_Reward/rotating_object: 149.2018
        Episode_Reward/action_rate: -0.0765
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 2.11s
                      Time elapsed: 00:45:19
                               ETA: 00:09:03

################################################################################
                     [1m Learning iteration 1251/1500 [0m                     

                       Computation: 46876 steps/s (collection: 1.947s, learning 0.150s)
             Mean action noise std: 3.81
          Mean value_function loss: 69.6547
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.2121
                       Mean reward: 731.95
               Mean episode length: 232.66
    Episode_Reward/reaching_object: 1.1034
    Episode_Reward/rotating_object: 149.5709
        Episode_Reward/action_rate: -0.0758
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 2.10s
                      Time elapsed: 00:45:21
                               ETA: 00:09:01

################################################################################
                     [1m Learning iteration 1252/1500 [0m                     

                       Computation: 45339 steps/s (collection: 2.058s, learning 0.111s)
             Mean action noise std: 3.81
          Mean value_function loss: 63.8296
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 59.2242
                       Mean reward: 730.85
               Mean episode length: 238.61
    Episode_Reward/reaching_object: 1.0989
    Episode_Reward/rotating_object: 148.8982
        Episode_Reward/action_rate: -0.0757
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 2.17s
                      Time elapsed: 00:45:24
                               ETA: 00:08:59

################################################################################
                     [1m Learning iteration 1253/1500 [0m                     

                       Computation: 47497 steps/s (collection: 1.951s, learning 0.119s)
             Mean action noise std: 3.81
          Mean value_function loss: 65.0747
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.2359
                       Mean reward: 716.34
               Mean episode length: 232.94
    Episode_Reward/reaching_object: 1.0856
    Episode_Reward/rotating_object: 144.3653
        Episode_Reward/action_rate: -0.0753
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 2.07s
                      Time elapsed: 00:45:26
                               ETA: 00:08:56

################################################################################
                     [1m Learning iteration 1254/1500 [0m                     

                       Computation: 48258 steps/s (collection: 1.914s, learning 0.123s)
             Mean action noise std: 3.82
          Mean value_function loss: 53.3406
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 59.2527
                       Mean reward: 766.00
               Mean episode length: 246.78
    Episode_Reward/reaching_object: 1.1201
    Episode_Reward/rotating_object: 151.2268
        Episode_Reward/action_rate: -0.0775
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 2.04s
                      Time elapsed: 00:45:28
                               ETA: 00:08:54

################################################################################
                     [1m Learning iteration 1255/1500 [0m                     

                       Computation: 47136 steps/s (collection: 1.965s, learning 0.121s)
             Mean action noise std: 3.82
          Mean value_function loss: 57.1537
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 59.2703
                       Mean reward: 741.98
               Mean episode length: 241.79
    Episode_Reward/reaching_object: 1.0870
    Episode_Reward/rotating_object: 143.9669
        Episode_Reward/action_rate: -0.0753
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 2.09s
                      Time elapsed: 00:45:30
                               ETA: 00:08:52

################################################################################
                     [1m Learning iteration 1256/1500 [0m                     

                       Computation: 47450 steps/s (collection: 1.961s, learning 0.110s)
             Mean action noise std: 3.82
          Mean value_function loss: 71.6602
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 59.2884
                       Mean reward: 732.91
               Mean episode length: 236.18
    Episode_Reward/reaching_object: 1.0928
    Episode_Reward/rotating_object: 144.4814
        Episode_Reward/action_rate: -0.0760
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 2.07s
                      Time elapsed: 00:45:32
                               ETA: 00:08:50

################################################################################
                     [1m Learning iteration 1257/1500 [0m                     

                       Computation: 47047 steps/s (collection: 1.991s, learning 0.098s)
             Mean action noise std: 3.83
          Mean value_function loss: 61.4659
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.2969
                       Mean reward: 700.68
               Mean episode length: 235.24
    Episode_Reward/reaching_object: 1.0632
    Episode_Reward/rotating_object: 139.9871
        Episode_Reward/action_rate: -0.0739
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 2.09s
                      Time elapsed: 00:45:34
                               ETA: 00:08:48

################################################################################
                     [1m Learning iteration 1258/1500 [0m                     

                       Computation: 48280 steps/s (collection: 1.940s, learning 0.096s)
             Mean action noise std: 3.83
          Mean value_function loss: 63.6327
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 59.3094
                       Mean reward: 738.53
               Mean episode length: 238.24
    Episode_Reward/reaching_object: 1.0918
    Episode_Reward/rotating_object: 142.4178
        Episode_Reward/action_rate: -0.0761
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 2.04s
                      Time elapsed: 00:45:36
                               ETA: 00:08:45

################################################################################
                     [1m Learning iteration 1259/1500 [0m                     

                       Computation: 48516 steps/s (collection: 1.925s, learning 0.101s)
             Mean action noise std: 3.83
          Mean value_function loss: 65.0466
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 59.3247
                       Mean reward: 709.69
               Mean episode length: 232.77
    Episode_Reward/reaching_object: 1.0805
    Episode_Reward/rotating_object: 142.8004
        Episode_Reward/action_rate: -0.0754
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 2.03s
                      Time elapsed: 00:45:38
                               ETA: 00:08:43

################################################################################
                     [1m Learning iteration 1260/1500 [0m                     

                       Computation: 40837 steps/s (collection: 2.258s, learning 0.149s)
             Mean action noise std: 3.83
          Mean value_function loss: 54.5689
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.3391
                       Mean reward: 722.67
               Mean episode length: 244.97
    Episode_Reward/reaching_object: 1.0967
    Episode_Reward/rotating_object: 146.5365
        Episode_Reward/action_rate: -0.0766
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 2.41s
                      Time elapsed: 00:45:40
                               ETA: 00:08:41

################################################################################
                     [1m Learning iteration 1261/1500 [0m                     

                       Computation: 47543 steps/s (collection: 1.959s, learning 0.109s)
             Mean action noise std: 3.84
          Mean value_function loss: 56.5341
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 59.3557
                       Mean reward: 740.66
               Mean episode length: 235.57
    Episode_Reward/reaching_object: 1.1015
    Episode_Reward/rotating_object: 145.6909
        Episode_Reward/action_rate: -0.0767
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 2.07s
                      Time elapsed: 00:45:42
                               ETA: 00:08:39

################################################################################
                     [1m Learning iteration 1262/1500 [0m                     

                       Computation: 48709 steps/s (collection: 1.911s, learning 0.107s)
             Mean action noise std: 3.84
          Mean value_function loss: 62.3367
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 59.3800
                       Mean reward: 765.44
               Mean episode length: 245.56
    Episode_Reward/reaching_object: 1.1048
    Episode_Reward/rotating_object: 149.3952
        Episode_Reward/action_rate: -0.0772
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 2.02s
                      Time elapsed: 00:45:44
                               ETA: 00:08:37

################################################################################
                     [1m Learning iteration 1263/1500 [0m                     

                       Computation: 44564 steps/s (collection: 2.099s, learning 0.107s)
             Mean action noise std: 3.85
          Mean value_function loss: 59.2714
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 59.4011
                       Mean reward: 746.76
               Mean episode length: 239.92
    Episode_Reward/reaching_object: 1.0826
    Episode_Reward/rotating_object: 145.9687
        Episode_Reward/action_rate: -0.0763
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 2.21s
                      Time elapsed: 00:45:47
                               ETA: 00:08:35

################################################################################
                     [1m Learning iteration 1264/1500 [0m                     

                       Computation: 45101 steps/s (collection: 2.039s, learning 0.141s)
             Mean action noise std: 3.85
          Mean value_function loss: 70.3864
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.4174
                       Mean reward: 708.27
               Mean episode length: 234.30
    Episode_Reward/reaching_object: 1.0761
    Episode_Reward/rotating_object: 144.9182
        Episode_Reward/action_rate: -0.0758
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 2.18s
                      Time elapsed: 00:45:49
                               ETA: 00:08:32

################################################################################
                     [1m Learning iteration 1265/1500 [0m                     

                       Computation: 46169 steps/s (collection: 2.032s, learning 0.098s)
             Mean action noise std: 3.85
          Mean value_function loss: 61.0064
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 59.4294
                       Mean reward: 730.20
               Mean episode length: 236.31
    Episode_Reward/reaching_object: 1.0865
    Episode_Reward/rotating_object: 146.4284
        Episode_Reward/action_rate: -0.0766
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 2.13s
                      Time elapsed: 00:45:51
                               ETA: 00:08:30

################################################################################
                     [1m Learning iteration 1266/1500 [0m                     

                       Computation: 46893 steps/s (collection: 1.981s, learning 0.116s)
             Mean action noise std: 3.85
          Mean value_function loss: 53.2511
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 59.4394
                       Mean reward: 777.84
               Mean episode length: 246.25
    Episode_Reward/reaching_object: 1.0683
    Episode_Reward/rotating_object: 143.1331
        Episode_Reward/action_rate: -0.0759
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 2.10s
                      Time elapsed: 00:45:53
                               ETA: 00:08:28

################################################################################
                     [1m Learning iteration 1267/1500 [0m                     

                       Computation: 47591 steps/s (collection: 1.960s, learning 0.106s)
             Mean action noise std: 3.86
          Mean value_function loss: 75.5273
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.4588
                       Mean reward: 739.42
               Mean episode length: 233.23
    Episode_Reward/reaching_object: 1.0779
    Episode_Reward/rotating_object: 146.7800
        Episode_Reward/action_rate: -0.0767
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 2.07s
                      Time elapsed: 00:45:55
                               ETA: 00:08:26

################################################################################
                     [1m Learning iteration 1268/1500 [0m                     

                       Computation: 48643 steps/s (collection: 1.907s, learning 0.114s)
             Mean action noise std: 3.86
          Mean value_function loss: 62.3522
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 59.4753
                       Mean reward: 754.96
               Mean episode length: 242.76
    Episode_Reward/reaching_object: 1.0775
    Episode_Reward/rotating_object: 144.3387
        Episode_Reward/action_rate: -0.0764
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 2.02s
                      Time elapsed: 00:45:57
                               ETA: 00:08:24

################################################################################
                     [1m Learning iteration 1269/1500 [0m                     

                       Computation: 48116 steps/s (collection: 1.942s, learning 0.101s)
             Mean action noise std: 3.86
          Mean value_function loss: 73.9092
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 59.4853
                       Mean reward: 720.28
               Mean episode length: 235.98
    Episode_Reward/reaching_object: 1.0826
    Episode_Reward/rotating_object: 146.4726
        Episode_Reward/action_rate: -0.0769
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 2.04s
                      Time elapsed: 00:45:59
                               ETA: 00:08:21

################################################################################
                     [1m Learning iteration 1270/1500 [0m                     

                       Computation: 48321 steps/s (collection: 1.914s, learning 0.121s)
             Mean action noise std: 3.86
          Mean value_function loss: 72.8162
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.4944
                       Mean reward: 711.51
               Mean episode length: 234.59
    Episode_Reward/reaching_object: 1.0609
    Episode_Reward/rotating_object: 142.6571
        Episode_Reward/action_rate: -0.0754
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 2.03s
                      Time elapsed: 00:46:01
                               ETA: 00:08:19

################################################################################
                     [1m Learning iteration 1271/1500 [0m                     

                       Computation: 47966 steps/s (collection: 1.945s, learning 0.105s)
             Mean action noise std: 3.87
          Mean value_function loss: 67.4045
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 59.5112
                       Mean reward: 701.57
               Mean episode length: 231.89
    Episode_Reward/reaching_object: 1.0535
    Episode_Reward/rotating_object: 142.9603
        Episode_Reward/action_rate: -0.0752
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 2.05s
                      Time elapsed: 00:46:03
                               ETA: 00:08:17

################################################################################
                     [1m Learning iteration 1272/1500 [0m                     

                       Computation: 46185 steps/s (collection: 1.936s, learning 0.193s)
             Mean action noise std: 3.87
          Mean value_function loss: 66.2846
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 59.5306
                       Mean reward: 728.80
               Mean episode length: 240.10
    Episode_Reward/reaching_object: 1.0739
    Episode_Reward/rotating_object: 143.6447
        Episode_Reward/action_rate: -0.0763
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 2.13s
                      Time elapsed: 00:46:05
                               ETA: 00:08:15

################################################################################
                     [1m Learning iteration 1273/1500 [0m                     

                       Computation: 44255 steps/s (collection: 2.067s, learning 0.154s)
             Mean action noise std: 3.87
          Mean value_function loss: 65.8466
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 59.5472
                       Mean reward: 764.15
               Mean episode length: 242.42
    Episode_Reward/reaching_object: 1.0973
    Episode_Reward/rotating_object: 148.5128
        Episode_Reward/action_rate: -0.0778
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 2.22s
                      Time elapsed: 00:46:08
                               ETA: 00:08:13

################################################################################
                     [1m Learning iteration 1274/1500 [0m                     

                       Computation: 47452 steps/s (collection: 1.976s, learning 0.096s)
             Mean action noise std: 3.87
          Mean value_function loss: 86.3830
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 59.5626
                       Mean reward: 702.44
               Mean episode length: 226.81
    Episode_Reward/reaching_object: 1.0704
    Episode_Reward/rotating_object: 143.4138
        Episode_Reward/action_rate: -0.0760
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 2.07s
                      Time elapsed: 00:46:10
                               ETA: 00:08:11

################################################################################
                     [1m Learning iteration 1275/1500 [0m                     

                       Computation: 46819 steps/s (collection: 1.989s, learning 0.111s)
             Mean action noise std: 3.88
          Mean value_function loss: 77.8622
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 59.5727
                       Mean reward: 676.24
               Mean episode length: 229.01
    Episode_Reward/reaching_object: 1.0676
    Episode_Reward/rotating_object: 144.3020
        Episode_Reward/action_rate: -0.0765
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 2.10s
                      Time elapsed: 00:46:12
                               ETA: 00:08:08

################################################################################
                     [1m Learning iteration 1276/1500 [0m                     

                       Computation: 48137 steps/s (collection: 1.927s, learning 0.115s)
             Mean action noise std: 3.88
          Mean value_function loss: 78.4196
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 59.5864
                       Mean reward: 701.65
               Mean episode length: 231.14
    Episode_Reward/reaching_object: 1.0485
    Episode_Reward/rotating_object: 140.2311
        Episode_Reward/action_rate: -0.0747
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 2.04s
                      Time elapsed: 00:46:14
                               ETA: 00:08:06

################################################################################
                     [1m Learning iteration 1277/1500 [0m                     

                       Computation: 47662 steps/s (collection: 1.954s, learning 0.108s)
             Mean action noise std: 3.88
          Mean value_function loss: 70.3187
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.5987
                       Mean reward: 710.94
               Mean episode length: 235.21
    Episode_Reward/reaching_object: 1.0921
    Episode_Reward/rotating_object: 147.6816
        Episode_Reward/action_rate: -0.0781
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 2.06s
                      Time elapsed: 00:46:16
                               ETA: 00:08:04

################################################################################
                     [1m Learning iteration 1278/1500 [0m                     

                       Computation: 46710 steps/s (collection: 1.995s, learning 0.109s)
             Mean action noise std: 3.88
          Mean value_function loss: 70.3753
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 59.6078
                       Mean reward: 758.74
               Mean episode length: 241.73
    Episode_Reward/reaching_object: 1.0781
    Episode_Reward/rotating_object: 146.5361
        Episode_Reward/action_rate: -0.0771
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 2.10s
                      Time elapsed: 00:46:18
                               ETA: 00:08:02

################################################################################
                     [1m Learning iteration 1279/1500 [0m                     

                       Computation: 48414 steps/s (collection: 1.917s, learning 0.113s)
             Mean action noise std: 3.88
          Mean value_function loss: 64.4062
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.6174
                       Mean reward: 708.83
               Mean episode length: 236.13
    Episode_Reward/reaching_object: 1.0660
    Episode_Reward/rotating_object: 143.7963
        Episode_Reward/action_rate: -0.0766
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 2.03s
                      Time elapsed: 00:46:20
                               ETA: 00:08:00

################################################################################
                     [1m Learning iteration 1280/1500 [0m                     

                       Computation: 46368 steps/s (collection: 1.996s, learning 0.125s)
             Mean action noise std: 3.89
          Mean value_function loss: 54.2376
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 59.6339
                       Mean reward: 733.28
               Mean episode length: 236.89
    Episode_Reward/reaching_object: 1.0763
    Episode_Reward/rotating_object: 142.5109
        Episode_Reward/action_rate: -0.0774
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 2.12s
                      Time elapsed: 00:46:22
                               ETA: 00:07:57

################################################################################
                     [1m Learning iteration 1281/1500 [0m                     

                       Computation: 47569 steps/s (collection: 1.947s, learning 0.119s)
             Mean action noise std: 3.89
          Mean value_function loss: 79.6834
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 59.6507
                       Mean reward: 699.30
               Mean episode length: 235.28
    Episode_Reward/reaching_object: 1.0713
    Episode_Reward/rotating_object: 143.2216
        Episode_Reward/action_rate: -0.0770
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 2.07s
                      Time elapsed: 00:46:24
                               ETA: 00:07:55

################################################################################
                     [1m Learning iteration 1282/1500 [0m                     

                       Computation: 48596 steps/s (collection: 1.887s, learning 0.136s)
             Mean action noise std: 3.89
          Mean value_function loss: 77.3913
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.6653
                       Mean reward: 709.61
               Mean episode length: 231.21
    Episode_Reward/reaching_object: 1.0692
    Episode_Reward/rotating_object: 141.7038
        Episode_Reward/action_rate: -0.0767
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 2.02s
                      Time elapsed: 00:46:26
                               ETA: 00:07:53

################################################################################
                     [1m Learning iteration 1283/1500 [0m                     

                       Computation: 47392 steps/s (collection: 1.918s, learning 0.156s)
             Mean action noise std: 3.89
          Mean value_function loss: 62.1846
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 59.6806
                       Mean reward: 724.06
               Mean episode length: 233.93
    Episode_Reward/reaching_object: 1.0855
    Episode_Reward/rotating_object: 143.9887
        Episode_Reward/action_rate: -0.0784
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 2.07s
                      Time elapsed: 00:46:28
                               ETA: 00:07:51

################################################################################
                     [1m Learning iteration 1284/1500 [0m                     

                       Computation: 46372 steps/s (collection: 1.999s, learning 0.121s)
             Mean action noise std: 3.90
          Mean value_function loss: 73.5416
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.6912
                       Mean reward: 697.93
               Mean episode length: 231.77
    Episode_Reward/reaching_object: 1.0654
    Episode_Reward/rotating_object: 139.7769
        Episode_Reward/action_rate: -0.0766
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 2.12s
                      Time elapsed: 00:46:30
                               ETA: 00:07:49

################################################################################
                     [1m Learning iteration 1285/1500 [0m                     

                       Computation: 48461 steps/s (collection: 1.919s, learning 0.110s)
             Mean action noise std: 3.90
          Mean value_function loss: 72.3238
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 59.7060
                       Mean reward: 771.18
               Mean episode length: 245.57
    Episode_Reward/reaching_object: 1.0862
    Episode_Reward/rotating_object: 146.0597
        Episode_Reward/action_rate: -0.0782
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 2.03s
                      Time elapsed: 00:46:32
                               ETA: 00:07:46

################################################################################
                     [1m Learning iteration 1286/1500 [0m                     

                       Computation: 48623 steps/s (collection: 1.924s, learning 0.098s)
             Mean action noise std: 3.90
          Mean value_function loss: 68.5664
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 59.7192
                       Mean reward: 743.86
               Mean episode length: 240.73
    Episode_Reward/reaching_object: 1.0841
    Episode_Reward/rotating_object: 143.7186
        Episode_Reward/action_rate: -0.0780
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 2.02s
                      Time elapsed: 00:46:35
                               ETA: 00:07:44

################################################################################
                     [1m Learning iteration 1287/1500 [0m                     

                       Computation: 49254 steps/s (collection: 1.896s, learning 0.100s)
             Mean action noise std: 3.90
          Mean value_function loss: 81.9326
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 59.7316
                       Mean reward: 744.50
               Mean episode length: 238.25
    Episode_Reward/reaching_object: 1.0737
    Episode_Reward/rotating_object: 142.6945
        Episode_Reward/action_rate: -0.0774
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 2.00s
                      Time elapsed: 00:46:37
                               ETA: 00:07:42

################################################################################
                     [1m Learning iteration 1288/1500 [0m                     

                       Computation: 48754 steps/s (collection: 1.910s, learning 0.107s)
             Mean action noise std: 3.91
          Mean value_function loss: 70.7614
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 59.7504
                       Mean reward: 714.91
               Mean episode length: 241.88
    Episode_Reward/reaching_object: 1.0727
    Episode_Reward/rotating_object: 142.3228
        Episode_Reward/action_rate: -0.0776
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 2.02s
                      Time elapsed: 00:46:39
                               ETA: 00:07:40

################################################################################
                     [1m Learning iteration 1289/1500 [0m                     

                       Computation: 47820 steps/s (collection: 1.946s, learning 0.110s)
             Mean action noise std: 3.91
          Mean value_function loss: 65.2489
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 59.7735
                       Mean reward: 740.50
               Mean episode length: 239.84
    Episode_Reward/reaching_object: 1.0814
    Episode_Reward/rotating_object: 141.2806
        Episode_Reward/action_rate: -0.0781
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 2.06s
                      Time elapsed: 00:46:41
                               ETA: 00:07:38

################################################################################
                     [1m Learning iteration 1290/1500 [0m                     

                       Computation: 47882 steps/s (collection: 1.956s, learning 0.097s)
             Mean action noise std: 3.92
          Mean value_function loss: 71.2588
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 59.7962
                       Mean reward: 709.70
               Mean episode length: 237.17
    Episode_Reward/reaching_object: 1.0856
    Episode_Reward/rotating_object: 145.7088
        Episode_Reward/action_rate: -0.0784
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 2.05s
                      Time elapsed: 00:46:43
                               ETA: 00:07:35

################################################################################
                     [1m Learning iteration 1291/1500 [0m                     

                       Computation: 47903 steps/s (collection: 1.925s, learning 0.127s)
             Mean action noise std: 3.92
          Mean value_function loss: 72.8522
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 59.8096
                       Mean reward: 722.33
               Mean episode length: 231.09
    Episode_Reward/reaching_object: 1.0706
    Episode_Reward/rotating_object: 142.1672
        Episode_Reward/action_rate: -0.0776
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 2.05s
                      Time elapsed: 00:46:45
                               ETA: 00:07:33

################################################################################
                     [1m Learning iteration 1292/1500 [0m                     

                       Computation: 47555 steps/s (collection: 1.935s, learning 0.132s)
             Mean action noise std: 3.92
          Mean value_function loss: 65.2443
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 59.8256
                       Mean reward: 707.35
               Mean episode length: 233.48
    Episode_Reward/reaching_object: 1.0766
    Episode_Reward/rotating_object: 143.8455
        Episode_Reward/action_rate: -0.0783
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 2.07s
                      Time elapsed: 00:46:47
                               ETA: 00:07:31

################################################################################
                     [1m Learning iteration 1293/1500 [0m                     

                       Computation: 48480 steps/s (collection: 1.932s, learning 0.096s)
             Mean action noise std: 3.93
          Mean value_function loss: 63.4226
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.8435
                       Mean reward: 728.13
               Mean episode length: 238.38
    Episode_Reward/reaching_object: 1.0818
    Episode_Reward/rotating_object: 144.6647
        Episode_Reward/action_rate: -0.0787
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 2.03s
                      Time elapsed: 00:46:49
                               ETA: 00:07:29

################################################################################
                     [1m Learning iteration 1294/1500 [0m                     

                       Computation: 48420 steps/s (collection: 1.921s, learning 0.109s)
             Mean action noise std: 3.93
          Mean value_function loss: 62.7025
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 59.8619
                       Mean reward: 759.80
               Mean episode length: 244.11
    Episode_Reward/reaching_object: 1.1089
    Episode_Reward/rotating_object: 147.7437
        Episode_Reward/action_rate: -0.0804
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 2.03s
                      Time elapsed: 00:46:51
                               ETA: 00:07:27

################################################################################
                     [1m Learning iteration 1295/1500 [0m                     

                       Computation: 47752 steps/s (collection: 1.962s, learning 0.097s)
             Mean action noise std: 3.93
          Mean value_function loss: 64.5332
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 59.8759
                       Mean reward: 729.37
               Mean episode length: 235.21
    Episode_Reward/reaching_object: 1.0709
    Episode_Reward/rotating_object: 142.5453
        Episode_Reward/action_rate: -0.0779
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 2.06s
                      Time elapsed: 00:46:53
                               ETA: 00:07:25

################################################################################
                     [1m Learning iteration 1296/1500 [0m                     

                       Computation: 48522 steps/s (collection: 1.919s, learning 0.107s)
             Mean action noise std: 3.93
          Mean value_function loss: 74.1982
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.8903
                       Mean reward: 714.18
               Mean episode length: 238.29
    Episode_Reward/reaching_object: 1.0843
    Episode_Reward/rotating_object: 143.7347
        Episode_Reward/action_rate: -0.0787
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 2.03s
                      Time elapsed: 00:46:55
                               ETA: 00:07:22

################################################################################
                     [1m Learning iteration 1297/1500 [0m                     

                       Computation: 48489 steps/s (collection: 1.928s, learning 0.099s)
             Mean action noise std: 3.94
          Mean value_function loss: 75.0297
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.9072
                       Mean reward: 720.31
               Mean episode length: 233.84
    Episode_Reward/reaching_object: 1.0945
    Episode_Reward/rotating_object: 145.9321
        Episode_Reward/action_rate: -0.0800
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 2.03s
                      Time elapsed: 00:46:57
                               ETA: 00:07:20

################################################################################
                     [1m Learning iteration 1298/1500 [0m                     

                       Computation: 47814 steps/s (collection: 1.941s, learning 0.115s)
             Mean action noise std: 3.94
          Mean value_function loss: 71.1641
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 59.9228
                       Mean reward: 704.91
               Mean episode length: 232.06
    Episode_Reward/reaching_object: 1.0727
    Episode_Reward/rotating_object: 144.4376
        Episode_Reward/action_rate: -0.0792
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 2.06s
                      Time elapsed: 00:46:59
                               ETA: 00:07:18

################################################################################
                     [1m Learning iteration 1299/1500 [0m                     

                       Computation: 48499 steps/s (collection: 1.925s, learning 0.102s)
             Mean action noise std: 3.94
          Mean value_function loss: 75.6043
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 59.9311
                       Mean reward: 726.15
               Mean episode length: 235.71
    Episode_Reward/reaching_object: 1.1021
    Episode_Reward/rotating_object: 149.6577
        Episode_Reward/action_rate: -0.0805
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 2.03s
                      Time elapsed: 00:47:01
                               ETA: 00:07:16

################################################################################
                     [1m Learning iteration 1300/1500 [0m                     

                       Computation: 48158 steps/s (collection: 1.944s, learning 0.098s)
             Mean action noise std: 3.94
          Mean value_function loss: 61.8162
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.9383
                       Mean reward: 742.49
               Mean episode length: 243.12
    Episode_Reward/reaching_object: 1.0765
    Episode_Reward/rotating_object: 143.8466
        Episode_Reward/action_rate: -0.0796
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 2.04s
                      Time elapsed: 00:47:03
                               ETA: 00:07:14

################################################################################
                     [1m Learning iteration 1301/1500 [0m                     

                       Computation: 47930 steps/s (collection: 1.956s, learning 0.095s)
             Mean action noise std: 3.95
          Mean value_function loss: 62.0781
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 59.9589
                       Mean reward: 727.57
               Mean episode length: 233.57
    Episode_Reward/reaching_object: 1.0753
    Episode_Reward/rotating_object: 145.3600
        Episode_Reward/action_rate: -0.0799
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 2.05s
                      Time elapsed: 00:47:05
                               ETA: 00:07:11

################################################################################
                     [1m Learning iteration 1302/1500 [0m                     

                       Computation: 46676 steps/s (collection: 1.963s, learning 0.143s)
             Mean action noise std: 3.95
          Mean value_function loss: 60.5818
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 59.9808
                       Mean reward: 770.05
               Mean episode length: 246.08
    Episode_Reward/reaching_object: 1.0923
    Episode_Reward/rotating_object: 148.3560
        Episode_Reward/action_rate: -0.0807
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 2.11s
                      Time elapsed: 00:47:07
                               ETA: 00:07:09

################################################################################
                     [1m Learning iteration 1303/1500 [0m                     

                       Computation: 48265 steps/s (collection: 1.940s, learning 0.097s)
             Mean action noise std: 3.95
          Mean value_function loss: 71.7616
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.0033
                       Mean reward: 742.52
               Mean episode length: 233.56
    Episode_Reward/reaching_object: 1.0675
    Episode_Reward/rotating_object: 142.8086
        Episode_Reward/action_rate: -0.0793
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 2.04s
                      Time elapsed: 00:47:09
                               ETA: 00:07:07

################################################################################
                     [1m Learning iteration 1304/1500 [0m                     

                       Computation: 48873 steps/s (collection: 1.917s, learning 0.095s)
             Mean action noise std: 3.96
          Mean value_function loss: 80.4221
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 60.0239
                       Mean reward: 711.09
               Mean episode length: 232.02
    Episode_Reward/reaching_object: 1.0773
    Episode_Reward/rotating_object: 144.8666
        Episode_Reward/action_rate: -0.0798
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 2.01s
                      Time elapsed: 00:47:11
                               ETA: 00:07:05

################################################################################
                     [1m Learning iteration 1305/1500 [0m                     

                       Computation: 47657 steps/s (collection: 1.954s, learning 0.109s)
             Mean action noise std: 3.96
          Mean value_function loss: 62.8291
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.0361
                       Mean reward: 720.96
               Mean episode length: 237.29
    Episode_Reward/reaching_object: 1.0770
    Episode_Reward/rotating_object: 142.0389
        Episode_Reward/action_rate: -0.0796
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 2.06s
                      Time elapsed: 00:47:13
                               ETA: 00:07:03

################################################################################
                     [1m Learning iteration 1306/1500 [0m                     

                       Computation: 47682 steps/s (collection: 1.930s, learning 0.132s)
             Mean action noise std: 3.96
          Mean value_function loss: 77.0634
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 60.0558
                       Mean reward: 777.18
               Mean episode length: 241.73
    Episode_Reward/reaching_object: 1.0817
    Episode_Reward/rotating_object: 143.8427
        Episode_Reward/action_rate: -0.0804
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 2.06s
                      Time elapsed: 00:47:15
                               ETA: 00:07:00

################################################################################
                     [1m Learning iteration 1307/1500 [0m                     

                       Computation: 47644 steps/s (collection: 1.928s, learning 0.135s)
             Mean action noise std: 3.97
          Mean value_function loss: 74.6998
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.0762
                       Mean reward: 692.96
               Mean episode length: 229.34
    Episode_Reward/reaching_object: 1.0633
    Episode_Reward/rotating_object: 138.8751
        Episode_Reward/action_rate: -0.0791
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 2.06s
                      Time elapsed: 00:47:17
                               ETA: 00:06:58

################################################################################
                     [1m Learning iteration 1308/1500 [0m                     

                       Computation: 47735 steps/s (collection: 1.917s, learning 0.143s)
             Mean action noise std: 3.97
          Mean value_function loss: 56.5099
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 60.0885
                       Mean reward: 687.05
               Mean episode length: 236.36
    Episode_Reward/reaching_object: 1.0830
    Episode_Reward/rotating_object: 143.2373
        Episode_Reward/action_rate: -0.0805
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 2.06s
                      Time elapsed: 00:47:19
                               ETA: 00:06:56

################################################################################
                     [1m Learning iteration 1309/1500 [0m                     

                       Computation: 45047 steps/s (collection: 2.016s, learning 0.166s)
             Mean action noise std: 3.97
          Mean value_function loss: 62.6080
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 60.0993
                       Mean reward: 693.30
               Mean episode length: 239.07
    Episode_Reward/reaching_object: 1.0947
    Episode_Reward/rotating_object: 142.9008
        Episode_Reward/action_rate: -0.0810
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 2.18s
                      Time elapsed: 00:47:22
                               ETA: 00:06:54

################################################################################
                     [1m Learning iteration 1310/1500 [0m                     

                       Computation: 49243 steps/s (collection: 1.894s, learning 0.102s)
             Mean action noise std: 3.97
          Mean value_function loss: 60.9655
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 60.1151
                       Mean reward: 728.67
               Mean episode length: 240.69
    Episode_Reward/reaching_object: 1.0975
    Episode_Reward/rotating_object: 145.4502
        Episode_Reward/action_rate: -0.0812
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 2.00s
                      Time elapsed: 00:47:24
                               ETA: 00:06:52

################################################################################
                     [1m Learning iteration 1311/1500 [0m                     

                       Computation: 48142 steps/s (collection: 1.932s, learning 0.110s)
             Mean action noise std: 3.98
          Mean value_function loss: 68.9212
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 60.1274
                       Mean reward: 744.66
               Mean episode length: 240.86
    Episode_Reward/reaching_object: 1.0943
    Episode_Reward/rotating_object: 146.6032
        Episode_Reward/action_rate: -0.0814
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 2.04s
                      Time elapsed: 00:47:26
                               ETA: 00:06:50

################################################################################
                     [1m Learning iteration 1312/1500 [0m                     

                       Computation: 48954 steps/s (collection: 1.898s, learning 0.110s)
             Mean action noise std: 3.98
          Mean value_function loss: 56.3359
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 60.1377
                       Mean reward: 739.67
               Mean episode length: 238.18
    Episode_Reward/reaching_object: 1.0865
    Episode_Reward/rotating_object: 143.4524
        Episode_Reward/action_rate: -0.0807
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 2.01s
                      Time elapsed: 00:47:28
                               ETA: 00:06:47

################################################################################
                     [1m Learning iteration 1313/1500 [0m                     

                       Computation: 47645 steps/s (collection: 1.934s, learning 0.130s)
             Mean action noise std: 3.98
          Mean value_function loss: 58.6072
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 60.1463
                       Mean reward: 691.54
               Mean episode length: 235.54
    Episode_Reward/reaching_object: 1.0683
    Episode_Reward/rotating_object: 139.2394
        Episode_Reward/action_rate: -0.0798
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 2.06s
                      Time elapsed: 00:47:30
                               ETA: 00:06:45

################################################################################
                     [1m Learning iteration 1314/1500 [0m                     

                       Computation: 48911 steps/s (collection: 1.914s, learning 0.096s)
             Mean action noise std: 3.98
          Mean value_function loss: 74.0849
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 60.1569
                       Mean reward: 718.06
               Mean episode length: 232.89
    Episode_Reward/reaching_object: 1.0763
    Episode_Reward/rotating_object: 144.0175
        Episode_Reward/action_rate: -0.0803
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 2.01s
                      Time elapsed: 00:47:32
                               ETA: 00:06:43

################################################################################
                     [1m Learning iteration 1315/1500 [0m                     

                       Computation: 48055 steps/s (collection: 1.949s, learning 0.097s)
             Mean action noise std: 3.99
          Mean value_function loss: 50.2341
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.1710
                       Mean reward: 727.11
               Mean episode length: 238.61
    Episode_Reward/reaching_object: 1.0914
    Episode_Reward/rotating_object: 143.6054
        Episode_Reward/action_rate: -0.0816
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 2.05s
                      Time elapsed: 00:47:34
                               ETA: 00:06:41

################################################################################
                     [1m Learning iteration 1316/1500 [0m                     

                       Computation: 48097 steps/s (collection: 1.944s, learning 0.100s)
             Mean action noise std: 3.99
          Mean value_function loss: 60.8076
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 60.1843
                       Mean reward: 740.73
               Mean episode length: 233.42
    Episode_Reward/reaching_object: 1.1023
    Episode_Reward/rotating_object: 147.8218
        Episode_Reward/action_rate: -0.0823
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 2.04s
                      Time elapsed: 00:47:36
                               ETA: 00:06:39

################################################################################
                     [1m Learning iteration 1317/1500 [0m                     

                       Computation: 47943 steps/s (collection: 1.949s, learning 0.102s)
             Mean action noise std: 3.99
          Mean value_function loss: 71.8542
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 60.1996
                       Mean reward: 775.83
               Mean episode length: 245.53
    Episode_Reward/reaching_object: 1.0838
    Episode_Reward/rotating_object: 144.3156
        Episode_Reward/action_rate: -0.0813
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 2.05s
                      Time elapsed: 00:47:38
                               ETA: 00:06:36

################################################################################
                     [1m Learning iteration 1318/1500 [0m                     

                       Computation: 47598 steps/s (collection: 1.955s, learning 0.110s)
             Mean action noise std: 4.00
          Mean value_function loss: 59.6040
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 60.2180
                       Mean reward: 744.10
               Mean episode length: 239.95
    Episode_Reward/reaching_object: 1.0886
    Episode_Reward/rotating_object: 145.4355
        Episode_Reward/action_rate: -0.0818
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 2.07s
                      Time elapsed: 00:47:40
                               ETA: 00:06:34

################################################################################
                     [1m Learning iteration 1319/1500 [0m                     

                       Computation: 47357 steps/s (collection: 1.976s, learning 0.100s)
             Mean action noise std: 4.00
          Mean value_function loss: 63.0791
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 60.2337
                       Mean reward: 711.21
               Mean episode length: 233.46
    Episode_Reward/reaching_object: 1.0721
    Episode_Reward/rotating_object: 142.3260
        Episode_Reward/action_rate: -0.0807
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 2.08s
                      Time elapsed: 00:47:42
                               ETA: 00:06:32

################################################################################
                     [1m Learning iteration 1320/1500 [0m                     

                       Computation: 48134 steps/s (collection: 1.932s, learning 0.111s)
             Mean action noise std: 4.00
          Mean value_function loss: 58.1125
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 60.2445
                       Mean reward: 771.12
               Mean episode length: 247.24
    Episode_Reward/reaching_object: 1.1043
    Episode_Reward/rotating_object: 149.2803
        Episode_Reward/action_rate: -0.0829
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 2.04s
                      Time elapsed: 00:47:44
                               ETA: 00:06:30

################################################################################
                     [1m Learning iteration 1321/1500 [0m                     

                       Computation: 49059 steps/s (collection: 1.904s, learning 0.100s)
             Mean action noise std: 4.00
          Mean value_function loss: 70.6647
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 60.2602
                       Mean reward: 728.94
               Mean episode length: 240.34
    Episode_Reward/reaching_object: 1.0825
    Episode_Reward/rotating_object: 143.9167
        Episode_Reward/action_rate: -0.0814
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 2.00s
                      Time elapsed: 00:47:46
                               ETA: 00:06:28

################################################################################
                     [1m Learning iteration 1322/1500 [0m                     

                       Computation: 46471 steps/s (collection: 2.013s, learning 0.102s)
             Mean action noise std: 4.01
          Mean value_function loss: 71.4922
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 60.2787
                       Mean reward: 771.38
               Mean episode length: 241.40
    Episode_Reward/reaching_object: 1.0893
    Episode_Reward/rotating_object: 147.9901
        Episode_Reward/action_rate: -0.0822
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 2.12s
                      Time elapsed: 00:47:48
                               ETA: 00:06:25

################################################################################
                     [1m Learning iteration 1323/1500 [0m                     

                       Computation: 48541 steps/s (collection: 1.914s, learning 0.111s)
             Mean action noise std: 4.01
          Mean value_function loss: 52.0722
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 60.2905
                       Mean reward: 748.12
               Mean episode length: 243.43
    Episode_Reward/reaching_object: 1.0910
    Episode_Reward/rotating_object: 145.1291
        Episode_Reward/action_rate: -0.0823
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 2.03s
                      Time elapsed: 00:47:50
                               ETA: 00:06:23

################################################################################
                     [1m Learning iteration 1324/1500 [0m                     

                       Computation: 48826 steps/s (collection: 1.918s, learning 0.095s)
             Mean action noise std: 4.01
          Mean value_function loss: 57.4239
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 60.3008
                       Mean reward: 712.05
               Mean episode length: 234.52
    Episode_Reward/reaching_object: 1.0874
    Episode_Reward/rotating_object: 143.0012
        Episode_Reward/action_rate: -0.0818
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 2.01s
                      Time elapsed: 00:47:52
                               ETA: 00:06:21

################################################################################
                     [1m Learning iteration 1325/1500 [0m                     

                       Computation: 49464 steps/s (collection: 1.889s, learning 0.099s)
             Mean action noise std: 4.02
          Mean value_function loss: 68.0201
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.3175
                       Mean reward: 753.03
               Mean episode length: 240.27
    Episode_Reward/reaching_object: 1.0836
    Episode_Reward/rotating_object: 145.9080
        Episode_Reward/action_rate: -0.0821
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 1.99s
                      Time elapsed: 00:47:54
                               ETA: 00:06:19

################################################################################
                     [1m Learning iteration 1326/1500 [0m                     

                       Computation: 47654 steps/s (collection: 1.945s, learning 0.118s)
             Mean action noise std: 4.02
          Mean value_function loss: 66.4062
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 60.3303
                       Mean reward: 753.11
               Mean episode length: 236.85
    Episode_Reward/reaching_object: 1.0743
    Episode_Reward/rotating_object: 143.8243
        Episode_Reward/action_rate: -0.0816
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 2.06s
                      Time elapsed: 00:47:56
                               ETA: 00:06:17

################################################################################
                     [1m Learning iteration 1327/1500 [0m                     

                       Computation: 48043 steps/s (collection: 1.948s, learning 0.099s)
             Mean action noise std: 4.02
          Mean value_function loss: 58.5237
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.3390
                       Mean reward: 741.38
               Mean episode length: 238.91
    Episode_Reward/reaching_object: 1.1058
    Episode_Reward/rotating_object: 147.9471
        Episode_Reward/action_rate: -0.0843
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 2.05s
                      Time elapsed: 00:47:58
                               ETA: 00:06:15

################################################################################
                     [1m Learning iteration 1328/1500 [0m                     

                       Computation: 48492 steps/s (collection: 1.932s, learning 0.096s)
             Mean action noise std: 4.02
          Mean value_function loss: 70.7885
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 60.3474
                       Mean reward: 663.06
               Mean episode length: 227.35
    Episode_Reward/reaching_object: 1.0618
    Episode_Reward/rotating_object: 141.9976
        Episode_Reward/action_rate: -0.0809
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 2.03s
                      Time elapsed: 00:48:00
                               ETA: 00:06:12

################################################################################
                     [1m Learning iteration 1329/1500 [0m                     

                       Computation: 48365 steps/s (collection: 1.922s, learning 0.111s)
             Mean action noise std: 4.02
          Mean value_function loss: 71.3360
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 60.3549
                       Mean reward: 712.17
               Mean episode length: 237.89
    Episode_Reward/reaching_object: 1.0692
    Episode_Reward/rotating_object: 142.6979
        Episode_Reward/action_rate: -0.0816
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 2.03s
                      Time elapsed: 00:48:02
                               ETA: 00:06:10

################################################################################
                     [1m Learning iteration 1330/1500 [0m                     

                       Computation: 48221 steps/s (collection: 1.939s, learning 0.100s)
             Mean action noise std: 4.03
          Mean value_function loss: 50.8784
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 60.3687
                       Mean reward: 745.45
               Mean episode length: 240.20
    Episode_Reward/reaching_object: 1.1033
    Episode_Reward/rotating_object: 148.0735
        Episode_Reward/action_rate: -0.0843
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 2.04s
                      Time elapsed: 00:48:04
                               ETA: 00:06:08

################################################################################
                     [1m Learning iteration 1331/1500 [0m                     

                       Computation: 48677 steps/s (collection: 1.910s, learning 0.110s)
             Mean action noise std: 4.03
          Mean value_function loss: 68.4875
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 60.3874
                       Mean reward: 742.18
               Mean episode length: 235.86
    Episode_Reward/reaching_object: 1.0724
    Episode_Reward/rotating_object: 144.3901
        Episode_Reward/action_rate: -0.0818
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 2.02s
                      Time elapsed: 00:48:06
                               ETA: 00:06:06

################################################################################
                     [1m Learning iteration 1332/1500 [0m                     

                       Computation: 43750 steps/s (collection: 2.105s, learning 0.142s)
             Mean action noise std: 4.03
          Mean value_function loss: 65.7732
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 60.4049
                       Mean reward: 772.16
               Mean episode length: 241.71
    Episode_Reward/reaching_object: 1.0830
    Episode_Reward/rotating_object: 145.3206
        Episode_Reward/action_rate: -0.0827
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 2.25s
                      Time elapsed: 00:48:09
                               ETA: 00:06:04

################################################################################
                     [1m Learning iteration 1333/1500 [0m                     

                       Computation: 18904 steps/s (collection: 5.019s, learning 0.182s)
             Mean action noise std: 4.03
          Mean value_function loss: 62.7391
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 60.4167
                       Mean reward: 720.97
               Mean episode length: 233.31
    Episode_Reward/reaching_object: 1.0943
    Episode_Reward/rotating_object: 148.3065
        Episode_Reward/action_rate: -0.0837
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 5.20s
                      Time elapsed: 00:48:14
                               ETA: 00:06:02

################################################################################
                     [1m Learning iteration 1334/1500 [0m                     

                       Computation: 14198 steps/s (collection: 6.718s, learning 0.206s)
             Mean action noise std: 4.04
          Mean value_function loss: 67.9558
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 60.4318
                       Mean reward: 737.13
               Mean episode length: 239.10
    Episode_Reward/reaching_object: 1.0977
    Episode_Reward/rotating_object: 147.4619
        Episode_Reward/action_rate: -0.0838
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 6.92s
                      Time elapsed: 00:48:21
                               ETA: 00:06:00

################################################################################
                     [1m Learning iteration 1335/1500 [0m                     

                       Computation: 14593 steps/s (collection: 6.617s, learning 0.119s)
             Mean action noise std: 4.04
          Mean value_function loss: 71.6356
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 60.4495
                       Mean reward: 744.43
               Mean episode length: 238.69
    Episode_Reward/reaching_object: 1.0941
    Episode_Reward/rotating_object: 145.4112
        Episode_Reward/action_rate: -0.0834
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 6.74s
                      Time elapsed: 00:48:28
                               ETA: 00:05:59

################################################################################
                     [1m Learning iteration 1336/1500 [0m                     

                       Computation: 14696 steps/s (collection: 6.577s, learning 0.113s)
             Mean action noise std: 4.04
          Mean value_function loss: 64.3883
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.4647
                       Mean reward: 745.07
               Mean episode length: 239.03
    Episode_Reward/reaching_object: 1.0988
    Episode_Reward/rotating_object: 146.4042
        Episode_Reward/action_rate: -0.0839
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 6.69s
                      Time elapsed: 00:48:34
                               ETA: 00:05:57

################################################################################
                     [1m Learning iteration 1337/1500 [0m                     

                       Computation: 14764 steps/s (collection: 6.530s, learning 0.128s)
             Mean action noise std: 4.05
          Mean value_function loss: 63.2344
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 60.4744
                       Mean reward: 739.74
               Mean episode length: 237.87
    Episode_Reward/reaching_object: 1.0866
    Episode_Reward/rotating_object: 142.5410
        Episode_Reward/action_rate: -0.0828
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 6.66s
                      Time elapsed: 00:48:41
                               ETA: 00:05:55

################################################################################
                     [1m Learning iteration 1338/1500 [0m                     

                       Computation: 14245 steps/s (collection: 6.750s, learning 0.150s)
             Mean action noise std: 4.05
          Mean value_function loss: 67.4575
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 60.4822
                       Mean reward: 713.13
               Mean episode length: 231.46
    Episode_Reward/reaching_object: 1.0767
    Episode_Reward/rotating_object: 145.4697
        Episode_Reward/action_rate: -0.0827
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 6.90s
                      Time elapsed: 00:48:48
                               ETA: 00:05:54

################################################################################
                     [1m Learning iteration 1339/1500 [0m                     

                       Computation: 13496 steps/s (collection: 7.166s, learning 0.118s)
             Mean action noise std: 4.05
          Mean value_function loss: 66.7839
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 60.4911
                       Mean reward: 711.57
               Mean episode length: 234.41
    Episode_Reward/reaching_object: 1.0677
    Episode_Reward/rotating_object: 140.9767
        Episode_Reward/action_rate: -0.0819
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 7.28s
                      Time elapsed: 00:48:55
                               ETA: 00:05:52

################################################################################
                     [1m Learning iteration 1340/1500 [0m                     

                       Computation: 14872 steps/s (collection: 6.449s, learning 0.161s)
             Mean action noise std: 4.05
          Mean value_function loss: 56.4982
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 60.5050
                       Mean reward: 683.61
               Mean episode length: 225.18
    Episode_Reward/reaching_object: 1.0702
    Episode_Reward/rotating_object: 139.3503
        Episode_Reward/action_rate: -0.0822
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 6.61s
                      Time elapsed: 00:49:02
                               ETA: 00:05:51

################################################################################
                     [1m Learning iteration 1341/1500 [0m                     

                       Computation: 12837 steps/s (collection: 7.525s, learning 0.132s)
             Mean action noise std: 4.05
          Mean value_function loss: 58.4032
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 60.5121
                       Mean reward: 738.42
               Mean episode length: 236.31
    Episode_Reward/reaching_object: 1.0886
    Episode_Reward/rotating_object: 148.2024
        Episode_Reward/action_rate: -0.0834
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 7.66s
                      Time elapsed: 00:49:09
                               ETA: 00:05:49

################################################################################
                     [1m Learning iteration 1342/1500 [0m                     

                       Computation: 50413 steps/s (collection: 1.828s, learning 0.122s)
             Mean action noise std: 4.05
          Mean value_function loss: 75.0696
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 60.5171
                       Mean reward: 673.04
               Mean episode length: 227.18
    Episode_Reward/reaching_object: 1.0795
    Episode_Reward/rotating_object: 143.9809
        Episode_Reward/action_rate: -0.0828
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 1.95s
                      Time elapsed: 00:49:11
                               ETA: 00:05:47

################################################################################
                     [1m Learning iteration 1343/1500 [0m                     

                       Computation: 52742 steps/s (collection: 1.763s, learning 0.101s)
             Mean action noise std: 4.06
          Mean value_function loss: 73.2720
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 60.5237
                       Mean reward: 731.11
               Mean episode length: 233.90
    Episode_Reward/reaching_object: 1.0928
    Episode_Reward/rotating_object: 148.6469
        Episode_Reward/action_rate: -0.0837
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 1.86s
                      Time elapsed: 00:49:13
                               ETA: 00:05:45

################################################################################
                     [1m Learning iteration 1344/1500 [0m                     

                       Computation: 51734 steps/s (collection: 1.796s, learning 0.104s)
             Mean action noise std: 4.06
          Mean value_function loss: 69.5069
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 60.5306
                       Mean reward: 736.58
               Mean episode length: 232.65
    Episode_Reward/reaching_object: 1.0838
    Episode_Reward/rotating_object: 146.3204
        Episode_Reward/action_rate: -0.0833
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 1.90s
                      Time elapsed: 00:49:15
                               ETA: 00:05:42

################################################################################
                     [1m Learning iteration 1345/1500 [0m                     

                       Computation: 49581 steps/s (collection: 1.837s, learning 0.146s)
             Mean action noise std: 4.06
          Mean value_function loss: 59.6801
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.5461
                       Mean reward: 742.85
               Mean episode length: 237.32
    Episode_Reward/reaching_object: 1.0801
    Episode_Reward/rotating_object: 145.3080
        Episode_Reward/action_rate: -0.0829
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 1.98s
                      Time elapsed: 00:49:17
                               ETA: 00:05:40

################################################################################
                     [1m Learning iteration 1346/1500 [0m                     

                       Computation: 51058 steps/s (collection: 1.812s, learning 0.113s)
             Mean action noise std: 4.06
          Mean value_function loss: 65.6974
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 60.5615
                       Mean reward: 753.28
               Mean episode length: 236.65
    Episode_Reward/reaching_object: 1.1000
    Episode_Reward/rotating_object: 150.3037
        Episode_Reward/action_rate: -0.0842
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 1.93s
                      Time elapsed: 00:49:19
                               ETA: 00:05:38

################################################################################
                     [1m Learning iteration 1347/1500 [0m                     

                       Computation: 48088 steps/s (collection: 1.852s, learning 0.192s)
             Mean action noise std: 4.07
          Mean value_function loss: 57.2507
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 60.5723
                       Mean reward: 767.15
               Mean episode length: 241.19
    Episode_Reward/reaching_object: 1.0873
    Episode_Reward/rotating_object: 147.0213
        Episode_Reward/action_rate: -0.0837
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 2.04s
                      Time elapsed: 00:49:21
                               ETA: 00:05:36

################################################################################
                     [1m Learning iteration 1348/1500 [0m                     

                       Computation: 50658 steps/s (collection: 1.845s, learning 0.096s)
             Mean action noise std: 4.07
          Mean value_function loss: 50.4684
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.5814
                       Mean reward: 738.05
               Mean episode length: 237.07
    Episode_Reward/reaching_object: 1.0884
    Episode_Reward/rotating_object: 147.5723
        Episode_Reward/action_rate: -0.0842
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 1.94s
                      Time elapsed: 00:49:23
                               ETA: 00:05:33

################################################################################
                     [1m Learning iteration 1349/1500 [0m                     

                       Computation: 50840 steps/s (collection: 1.831s, learning 0.102s)
             Mean action noise std: 4.07
          Mean value_function loss: 66.7678
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 60.5922
                       Mean reward: 752.11
               Mean episode length: 236.05
    Episode_Reward/reaching_object: 1.0822
    Episode_Reward/rotating_object: 147.4282
        Episode_Reward/action_rate: -0.0835
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 1.93s
                      Time elapsed: 00:49:25
                               ETA: 00:05:31

################################################################################
                     [1m Learning iteration 1350/1500 [0m                     

                       Computation: 51188 steps/s (collection: 1.828s, learning 0.093s)
             Mean action noise std: 4.07
          Mean value_function loss: 64.5591
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 60.6021
                       Mean reward: 719.39
               Mean episode length: 230.53
    Episode_Reward/reaching_object: 1.0909
    Episode_Reward/rotating_object: 148.5312
        Episode_Reward/action_rate: -0.0843
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 1.92s
                      Time elapsed: 00:49:27
                               ETA: 00:05:29

################################################################################
                     [1m Learning iteration 1351/1500 [0m                     

                       Computation: 50599 steps/s (collection: 1.837s, learning 0.106s)
             Mean action noise std: 4.08
          Mean value_function loss: 57.5215
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 60.6139
                       Mean reward: 764.80
               Mean episode length: 238.08
    Episode_Reward/reaching_object: 1.0939
    Episode_Reward/rotating_object: 148.2256
        Episode_Reward/action_rate: -0.0845
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 1.94s
                      Time elapsed: 00:49:29
                               ETA: 00:05:27

################################################################################
                     [1m Learning iteration 1352/1500 [0m                     

                       Computation: 51902 steps/s (collection: 1.805s, learning 0.089s)
             Mean action noise std: 4.08
          Mean value_function loss: 64.5492
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 60.6240
                       Mean reward: 708.38
               Mean episode length: 227.79
    Episode_Reward/reaching_object: 1.1007
    Episode_Reward/rotating_object: 150.8117
        Episode_Reward/action_rate: -0.0853
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 1.89s
                      Time elapsed: 00:49:31
                               ETA: 00:05:25

################################################################################
                     [1m Learning iteration 1353/1500 [0m                     

                       Computation: 51169 steps/s (collection: 1.819s, learning 0.102s)
             Mean action noise std: 4.08
          Mean value_function loss: 62.5615
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 60.6344
                       Mean reward: 735.03
               Mean episode length: 234.11
    Episode_Reward/reaching_object: 1.0826
    Episode_Reward/rotating_object: 148.3401
        Episode_Reward/action_rate: -0.0843
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 1.92s
                      Time elapsed: 00:49:33
                               ETA: 00:05:22

################################################################################
                     [1m Learning iteration 1354/1500 [0m                     

                       Computation: 52135 steps/s (collection: 1.786s, learning 0.099s)
             Mean action noise std: 4.08
          Mean value_function loss: 51.5337
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 60.6453
                       Mean reward: 744.72
               Mean episode length: 242.43
    Episode_Reward/reaching_object: 1.1012
    Episode_Reward/rotating_object: 150.4933
        Episode_Reward/action_rate: -0.0856
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 1.89s
                      Time elapsed: 00:49:35
                               ETA: 00:05:20

################################################################################
                     [1m Learning iteration 1355/1500 [0m                     

                       Computation: 51983 steps/s (collection: 1.784s, learning 0.108s)
             Mean action noise std: 4.09
          Mean value_function loss: 60.5586
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 60.6588
                       Mean reward: 742.73
               Mean episode length: 237.30
    Episode_Reward/reaching_object: 1.0880
    Episode_Reward/rotating_object: 147.6837
        Episode_Reward/action_rate: -0.0853
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 1.89s
                      Time elapsed: 00:49:36
                               ETA: 00:05:18

################################################################################
                     [1m Learning iteration 1356/1500 [0m                     

                       Computation: 49792 steps/s (collection: 1.771s, learning 0.204s)
             Mean action noise std: 4.09
          Mean value_function loss: 61.6174
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 60.6713
                       Mean reward: 700.29
               Mean episode length: 233.43
    Episode_Reward/reaching_object: 1.0685
    Episode_Reward/rotating_object: 143.7818
        Episode_Reward/action_rate: -0.0838
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 1.97s
                      Time elapsed: 00:49:38
                               ETA: 00:05:16

################################################################################
                     [1m Learning iteration 1357/1500 [0m                     

                       Computation: 50390 steps/s (collection: 1.826s, learning 0.125s)
             Mean action noise std: 4.09
          Mean value_function loss: 57.4696
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 60.6870
                       Mean reward: 744.41
               Mean episode length: 239.43
    Episode_Reward/reaching_object: 1.0993
    Episode_Reward/rotating_object: 150.9924
        Episode_Reward/action_rate: -0.0863
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 1.95s
                      Time elapsed: 00:49:40
                               ETA: 00:05:13

################################################################################
                     [1m Learning iteration 1358/1500 [0m                     

                       Computation: 49237 steps/s (collection: 1.851s, learning 0.146s)
             Mean action noise std: 4.10
          Mean value_function loss: 75.2929
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 60.7077
                       Mean reward: 692.93
               Mean episode length: 228.00
    Episode_Reward/reaching_object: 1.0599
    Episode_Reward/rotating_object: 143.0239
        Episode_Reward/action_rate: -0.0834
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 2.00s
                      Time elapsed: 00:49:42
                               ETA: 00:05:11

################################################################################
                     [1m Learning iteration 1359/1500 [0m                     

                       Computation: 50926 steps/s (collection: 1.817s, learning 0.114s)
             Mean action noise std: 4.10
          Mean value_function loss: 57.8123
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 60.7252
                       Mean reward: 733.87
               Mean episode length: 237.16
    Episode_Reward/reaching_object: 1.0755
    Episode_Reward/rotating_object: 144.5905
        Episode_Reward/action_rate: -0.0846
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 1.93s
                      Time elapsed: 00:49:44
                               ETA: 00:05:09

################################################################################
                     [1m Learning iteration 1360/1500 [0m                     

                       Computation: 52253 steps/s (collection: 1.760s, learning 0.122s)
             Mean action noise std: 4.10
          Mean value_function loss: 56.4382
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.7345
                       Mean reward: 711.69
               Mean episode length: 232.21
    Episode_Reward/reaching_object: 1.0806
    Episode_Reward/rotating_object: 147.2722
        Episode_Reward/action_rate: -0.0853
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 1.88s
                      Time elapsed: 00:49:46
                               ETA: 00:05:07

################################################################################
                     [1m Learning iteration 1361/1500 [0m                     

                       Computation: 51637 steps/s (collection: 1.793s, learning 0.111s)
             Mean action noise std: 4.10
          Mean value_function loss: 74.5612
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 60.7444
                       Mean reward: 677.94
               Mean episode length: 224.15
    Episode_Reward/reaching_object: 1.0599
    Episode_Reward/rotating_object: 142.2641
        Episode_Reward/action_rate: -0.0835
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 1.90s
                      Time elapsed: 00:49:48
                               ETA: 00:05:04

################################################################################
                     [1m Learning iteration 1362/1500 [0m                     

                       Computation: 51186 steps/s (collection: 1.829s, learning 0.091s)
             Mean action noise std: 4.10
          Mean value_function loss: 61.4531
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 60.7562
                       Mean reward: 775.82
               Mean episode length: 245.00
    Episode_Reward/reaching_object: 1.0881
    Episode_Reward/rotating_object: 147.1971
        Episode_Reward/action_rate: -0.0857
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 1.92s
                      Time elapsed: 00:49:50
                               ETA: 00:05:02

################################################################################
                     [1m Learning iteration 1363/1500 [0m                     

                       Computation: 52376 steps/s (collection: 1.779s, learning 0.098s)
             Mean action noise std: 4.11
          Mean value_function loss: 62.6379
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 60.7690
                       Mean reward: 749.51
               Mean episode length: 238.94
    Episode_Reward/reaching_object: 1.0876
    Episode_Reward/rotating_object: 145.6931
        Episode_Reward/action_rate: -0.0855
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 1.88s
                      Time elapsed: 00:49:52
                               ETA: 00:05:00

################################################################################
                     [1m Learning iteration 1364/1500 [0m                     

                       Computation: 53818 steps/s (collection: 1.734s, learning 0.093s)
             Mean action noise std: 4.11
          Mean value_function loss: 77.8695
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 60.7831
                       Mean reward: 727.69
               Mean episode length: 229.53
    Episode_Reward/reaching_object: 1.0460
    Episode_Reward/rotating_object: 141.0539
        Episode_Reward/action_rate: -0.0828
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 1.83s
                      Time elapsed: 00:49:54
                               ETA: 00:04:58

################################################################################
                     [1m Learning iteration 1365/1500 [0m                     

                       Computation: 52892 steps/s (collection: 1.749s, learning 0.110s)
             Mean action noise std: 4.11
          Mean value_function loss: 68.7037
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 60.7944
                       Mean reward: 714.82
               Mean episode length: 228.29
    Episode_Reward/reaching_object: 1.0628
    Episode_Reward/rotating_object: 145.2249
        Episode_Reward/action_rate: -0.0845
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 1.86s
                      Time elapsed: 00:49:56
                               ETA: 00:04:56

################################################################################
                     [1m Learning iteration 1366/1500 [0m                     

                       Computation: 50698 steps/s (collection: 1.783s, learning 0.156s)
             Mean action noise std: 4.11
          Mean value_function loss: 73.9392
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 60.8020
                       Mean reward: 719.37
               Mean episode length: 230.40
    Episode_Reward/reaching_object: 1.0635
    Episode_Reward/rotating_object: 143.1716
        Episode_Reward/action_rate: -0.0842
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 1.94s
                      Time elapsed: 00:49:57
                               ETA: 00:04:53

################################################################################
                     [1m Learning iteration 1367/1500 [0m                     

                       Computation: 51386 steps/s (collection: 1.766s, learning 0.147s)
             Mean action noise std: 4.12
          Mean value_function loss: 55.4433
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 60.8087
                       Mean reward: 723.35
               Mean episode length: 232.21
    Episode_Reward/reaching_object: 1.0546
    Episode_Reward/rotating_object: 141.9057
        Episode_Reward/action_rate: -0.0838
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 1.91s
                      Time elapsed: 00:49:59
                               ETA: 00:04:51

################################################################################
                     [1m Learning iteration 1368/1500 [0m                     

                       Computation: 52668 steps/s (collection: 1.766s, learning 0.101s)
             Mean action noise std: 4.12
          Mean value_function loss: 71.5053
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.8209
                       Mean reward: 772.82
               Mean episode length: 244.40
    Episode_Reward/reaching_object: 1.0749
    Episode_Reward/rotating_object: 144.6421
        Episode_Reward/action_rate: -0.0856
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 1.87s
                      Time elapsed: 00:50:01
                               ETA: 00:04:49

################################################################################
                     [1m Learning iteration 1369/1500 [0m                     

                       Computation: 47576 steps/s (collection: 1.915s, learning 0.152s)
             Mean action noise std: 4.12
          Mean value_function loss: 61.6022
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 60.8348
                       Mean reward: 762.32
               Mean episode length: 239.25
    Episode_Reward/reaching_object: 1.0771
    Episode_Reward/rotating_object: 147.4071
        Episode_Reward/action_rate: -0.0860
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 2.07s
                      Time elapsed: 00:50:03
                               ETA: 00:04:47

################################################################################
                     [1m Learning iteration 1370/1500 [0m                     

                       Computation: 53322 steps/s (collection: 1.749s, learning 0.095s)
             Mean action noise std: 4.12
          Mean value_function loss: 59.0492
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.8444
                       Mean reward: 778.49
               Mean episode length: 244.57
    Episode_Reward/reaching_object: 1.0633
    Episode_Reward/rotating_object: 145.1832
        Episode_Reward/action_rate: -0.0853
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 1.84s
                      Time elapsed: 00:50:05
                               ETA: 00:04:44

################################################################################
                     [1m Learning iteration 1371/1500 [0m                     

                       Computation: 52878 steps/s (collection: 1.758s, learning 0.101s)
             Mean action noise std: 4.12
          Mean value_function loss: 59.5653
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 60.8548
                       Mean reward: 772.05
               Mean episode length: 244.69
    Episode_Reward/reaching_object: 1.0910
    Episode_Reward/rotating_object: 149.8275
        Episode_Reward/action_rate: -0.0874
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 1.86s
                      Time elapsed: 00:50:07
                               ETA: 00:04:42

################################################################################
                     [1m Learning iteration 1372/1500 [0m                     

                       Computation: 51351 steps/s (collection: 1.798s, learning 0.117s)
             Mean action noise std: 4.13
          Mean value_function loss: 56.3623
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 60.8660
                       Mean reward: 747.55
               Mean episode length: 242.30
    Episode_Reward/reaching_object: 1.0867
    Episode_Reward/rotating_object: 149.9795
        Episode_Reward/action_rate: -0.0872
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 1.91s
                      Time elapsed: 00:50:09
                               ETA: 00:04:40

################################################################################
                     [1m Learning iteration 1373/1500 [0m                     

                       Computation: 50847 steps/s (collection: 1.826s, learning 0.107s)
             Mean action noise std: 4.13
          Mean value_function loss: 68.1224
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 60.8828
                       Mean reward: 758.73
               Mean episode length: 237.85
    Episode_Reward/reaching_object: 1.0598
    Episode_Reward/rotating_object: 146.1074
        Episode_Reward/action_rate: -0.0850
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 1.93s
                      Time elapsed: 00:50:11
                               ETA: 00:04:38

################################################################################
                     [1m Learning iteration 1374/1500 [0m                     

                       Computation: 52390 steps/s (collection: 1.775s, learning 0.101s)
             Mean action noise std: 4.13
          Mean value_function loss: 71.2053
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 60.8999
                       Mean reward: 703.97
               Mean episode length: 231.40
    Episode_Reward/reaching_object: 1.0600
    Episode_Reward/rotating_object: 145.7610
        Episode_Reward/action_rate: -0.0858
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 1.88s
                      Time elapsed: 00:50:13
                               ETA: 00:04:36

################################################################################
                     [1m Learning iteration 1375/1500 [0m                     

                       Computation: 52702 steps/s (collection: 1.772s, learning 0.094s)
             Mean action noise std: 4.14
          Mean value_function loss: 54.4121
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 60.9195
                       Mean reward: 731.34
               Mean episode length: 236.42
    Episode_Reward/reaching_object: 1.0672
    Episode_Reward/rotating_object: 146.3084
        Episode_Reward/action_rate: -0.0864
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 1.87s
                      Time elapsed: 00:50:15
                               ETA: 00:04:33

################################################################################
                     [1m Learning iteration 1376/1500 [0m                     

                       Computation: 51049 steps/s (collection: 1.796s, learning 0.130s)
             Mean action noise std: 4.14
          Mean value_function loss: 67.4702
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 60.9423
                       Mean reward: 757.11
               Mean episode length: 235.86
    Episode_Reward/reaching_object: 1.0552
    Episode_Reward/rotating_object: 144.6144
        Episode_Reward/action_rate: -0.0855
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 1.93s
                      Time elapsed: 00:50:17
                               ETA: 00:04:31

################################################################################
                     [1m Learning iteration 1377/1500 [0m                     

                       Computation: 50273 steps/s (collection: 1.834s, learning 0.122s)
             Mean action noise std: 4.15
          Mean value_function loss: 65.5083
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.9612
                       Mean reward: 742.21
               Mean episode length: 236.04
    Episode_Reward/reaching_object: 1.0770
    Episode_Reward/rotating_object: 147.4351
        Episode_Reward/action_rate: -0.0872
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 1.96s
                      Time elapsed: 00:50:18
                               ETA: 00:04:29

################################################################################
                     [1m Learning iteration 1378/1500 [0m                     

                       Computation: 51423 steps/s (collection: 1.787s, learning 0.125s)
             Mean action noise std: 4.15
          Mean value_function loss: 68.5582
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 60.9766
                       Mean reward: 728.41
               Mean episode length: 230.72
    Episode_Reward/reaching_object: 1.0618
    Episode_Reward/rotating_object: 144.7024
        Episode_Reward/action_rate: -0.0859
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 1.91s
                      Time elapsed: 00:50:20
                               ETA: 00:04:27

################################################################################
                     [1m Learning iteration 1379/1500 [0m                     

                       Computation: 48060 steps/s (collection: 1.955s, learning 0.091s)
             Mean action noise std: 4.15
          Mean value_function loss: 64.3261
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.9908
                       Mean reward: 730.50
               Mean episode length: 229.04
    Episode_Reward/reaching_object: 1.0704
    Episode_Reward/rotating_object: 149.0755
        Episode_Reward/action_rate: -0.0868
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 2.05s
                      Time elapsed: 00:50:22
                               ETA: 00:04:25

################################################################################
                     [1m Learning iteration 1380/1500 [0m                     

                       Computation: 52460 steps/s (collection: 1.754s, learning 0.120s)
             Mean action noise std: 4.15
          Mean value_function loss: 65.6205
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 61.0075
                       Mean reward: 742.68
               Mean episode length: 239.53
    Episode_Reward/reaching_object: 1.0661
    Episode_Reward/rotating_object: 142.6916
        Episode_Reward/action_rate: -0.0863
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 1.87s
                      Time elapsed: 00:50:24
                               ETA: 00:04:22

################################################################################
                     [1m Learning iteration 1381/1500 [0m                     

                       Computation: 52422 steps/s (collection: 1.787s, learning 0.088s)
             Mean action noise std: 4.16
          Mean value_function loss: 66.8945
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 61.0228
                       Mean reward: 727.95
               Mean episode length: 233.38
    Episode_Reward/reaching_object: 1.0828
    Episode_Reward/rotating_object: 147.0574
        Episode_Reward/action_rate: -0.0876
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 1.88s
                      Time elapsed: 00:50:26
                               ETA: 00:04:20

################################################################################
                     [1m Learning iteration 1382/1500 [0m                     

                       Computation: 52072 steps/s (collection: 1.794s, learning 0.094s)
             Mean action noise std: 4.16
          Mean value_function loss: 72.7547
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 61.0328
                       Mean reward: 746.80
               Mean episode length: 241.37
    Episode_Reward/reaching_object: 1.0872
    Episode_Reward/rotating_object: 146.1632
        Episode_Reward/action_rate: -0.0880
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 1.89s
                      Time elapsed: 00:50:28
                               ETA: 00:04:18

################################################################################
                     [1m Learning iteration 1383/1500 [0m                     

                       Computation: 51345 steps/s (collection: 1.823s, learning 0.092s)
             Mean action noise std: 4.16
          Mean value_function loss: 65.3957
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 61.0403
                       Mean reward: 733.98
               Mean episode length: 237.37
    Episode_Reward/reaching_object: 1.0731
    Episode_Reward/rotating_object: 145.9676
        Episode_Reward/action_rate: -0.0869
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 1.91s
                      Time elapsed: 00:50:30
                               ETA: 00:04:16

################################################################################
                     [1m Learning iteration 1384/1500 [0m                     

                       Computation: 51136 steps/s (collection: 1.807s, learning 0.115s)
             Mean action noise std: 4.16
          Mean value_function loss: 54.6309
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 61.0508
                       Mean reward: 737.98
               Mean episode length: 236.32
    Episode_Reward/reaching_object: 1.0880
    Episode_Reward/rotating_object: 147.2652
        Episode_Reward/action_rate: -0.0883
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 1.92s
                      Time elapsed: 00:50:32
                               ETA: 00:04:13

################################################################################
                     [1m Learning iteration 1385/1500 [0m                     

                       Computation: 51500 steps/s (collection: 1.811s, learning 0.098s)
             Mean action noise std: 4.16
          Mean value_function loss: 70.7009
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 61.0585
                       Mean reward: 723.54
               Mean episode length: 232.94
    Episode_Reward/reaching_object: 1.0794
    Episode_Reward/rotating_object: 146.1202
        Episode_Reward/action_rate: -0.0877
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 1.91s
                      Time elapsed: 00:50:34
                               ETA: 00:04:11

################################################################################
                     [1m Learning iteration 1386/1500 [0m                     

                       Computation: 51854 steps/s (collection: 1.793s, learning 0.103s)
             Mean action noise std: 4.17
          Mean value_function loss: 58.5627
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 61.0729
                       Mean reward: 701.01
               Mean episode length: 227.50
    Episode_Reward/reaching_object: 1.0751
    Episode_Reward/rotating_object: 145.0634
        Episode_Reward/action_rate: -0.0874
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 1.90s
                      Time elapsed: 00:50:36
                               ETA: 00:04:09

################################################################################
                     [1m Learning iteration 1387/1500 [0m                     

                       Computation: 51483 steps/s (collection: 1.808s, learning 0.101s)
             Mean action noise std: 4.17
          Mean value_function loss: 61.5360
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 61.0863
                       Mean reward: 751.03
               Mean episode length: 237.79
    Episode_Reward/reaching_object: 1.0918
    Episode_Reward/rotating_object: 146.9025
        Episode_Reward/action_rate: -0.0887
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 1.91s
                      Time elapsed: 00:50:38
                               ETA: 00:04:07

################################################################################
                     [1m Learning iteration 1388/1500 [0m                     

                       Computation: 50883 steps/s (collection: 1.786s, learning 0.145s)
             Mean action noise std: 4.17
          Mean value_function loss: 64.6821
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 61.0963
                       Mean reward: 703.96
               Mean episode length: 227.21
    Episode_Reward/reaching_object: 1.0881
    Episode_Reward/rotating_object: 146.3930
        Episode_Reward/action_rate: -0.0883
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 1.93s
                      Time elapsed: 00:50:40
                               ETA: 00:04:05

################################################################################
                     [1m Learning iteration 1389/1500 [0m                     

                       Computation: 50356 steps/s (collection: 1.801s, learning 0.151s)
             Mean action noise std: 4.17
          Mean value_function loss: 48.1843
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.1083
                       Mean reward: 751.06
               Mean episode length: 239.88
    Episode_Reward/reaching_object: 1.0871
    Episode_Reward/rotating_object: 145.2616
        Episode_Reward/action_rate: -0.0882
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 1.95s
                      Time elapsed: 00:50:42
                               ETA: 00:04:02

################################################################################
                     [1m Learning iteration 1390/1500 [0m                     

                       Computation: 48433 steps/s (collection: 1.845s, learning 0.185s)
             Mean action noise std: 4.17
          Mean value_function loss: 69.0072
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 61.1186
                       Mean reward: 697.15
               Mean episode length: 229.15
    Episode_Reward/reaching_object: 1.0868
    Episode_Reward/rotating_object: 146.2385
        Episode_Reward/action_rate: -0.0885
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 2.03s
                      Time elapsed: 00:50:44
                               ETA: 00:04:00

################################################################################
                     [1m Learning iteration 1391/1500 [0m                     

                       Computation: 47142 steps/s (collection: 1.924s, learning 0.161s)
             Mean action noise std: 4.18
          Mean value_function loss: 65.0949
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 61.1275
                       Mean reward: 715.43
               Mean episode length: 232.84
    Episode_Reward/reaching_object: 1.0782
    Episode_Reward/rotating_object: 142.8647
        Episode_Reward/action_rate: -0.0878
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 2.09s
                      Time elapsed: 00:50:46
                               ETA: 00:03:58

################################################################################
                     [1m Learning iteration 1392/1500 [0m                     

                       Computation: 49475 steps/s (collection: 1.867s, learning 0.120s)
             Mean action noise std: 4.18
          Mean value_function loss: 63.0230
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 61.1352
                       Mean reward: 767.27
               Mean episode length: 242.03
    Episode_Reward/reaching_object: 1.1042
    Episode_Reward/rotating_object: 149.7452
        Episode_Reward/action_rate: -0.0899
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 1.99s
                      Time elapsed: 00:50:48
                               ETA: 00:03:56

################################################################################
                     [1m Learning iteration 1393/1500 [0m                     

                       Computation: 50178 steps/s (collection: 1.788s, learning 0.171s)
             Mean action noise std: 4.18
          Mean value_function loss: 63.2258
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 61.1455
                       Mean reward: 752.71
               Mean episode length: 240.22
    Episode_Reward/reaching_object: 1.0881
    Episode_Reward/rotating_object: 146.1450
        Episode_Reward/action_rate: -0.0888
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 1.96s
                      Time elapsed: 00:50:50
                               ETA: 00:03:54

################################################################################
                     [1m Learning iteration 1394/1500 [0m                     

                       Computation: 50307 steps/s (collection: 1.798s, learning 0.156s)
             Mean action noise std: 4.18
          Mean value_function loss: 80.3747
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 61.1536
                       Mean reward: 753.69
               Mean episode length: 240.51
    Episode_Reward/reaching_object: 1.0928
    Episode_Reward/rotating_object: 148.6572
        Episode_Reward/action_rate: -0.0884
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 1.95s
                      Time elapsed: 00:50:52
                               ETA: 00:03:51

################################################################################
                     [1m Learning iteration 1395/1500 [0m                     

                       Computation: 48501 steps/s (collection: 1.838s, learning 0.188s)
             Mean action noise std: 4.19
          Mean value_function loss: 71.1584
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 61.1648
                       Mean reward: 779.07
               Mean episode length: 244.98
    Episode_Reward/reaching_object: 1.0975
    Episode_Reward/rotating_object: 148.5690
        Episode_Reward/action_rate: -0.0892
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 2.03s
                      Time elapsed: 00:50:54
                               ETA: 00:03:49

################################################################################
                     [1m Learning iteration 1396/1500 [0m                     

                       Computation: 49320 steps/s (collection: 1.864s, learning 0.130s)
             Mean action noise std: 4.19
          Mean value_function loss: 58.2076
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 61.1787
                       Mean reward: 750.92
               Mean episode length: 238.44
    Episode_Reward/reaching_object: 1.0969
    Episode_Reward/rotating_object: 146.8938
        Episode_Reward/action_rate: -0.0898
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 1.99s
                      Time elapsed: 00:50:56
                               ETA: 00:03:47

################################################################################
                     [1m Learning iteration 1397/1500 [0m                     

                       Computation: 51896 steps/s (collection: 1.794s, learning 0.100s)
             Mean action noise std: 4.19
          Mean value_function loss: 45.7974
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 61.1947
                       Mean reward: 741.50
               Mean episode length: 238.25
    Episode_Reward/reaching_object: 1.0953
    Episode_Reward/rotating_object: 145.6559
        Episode_Reward/action_rate: -0.0893
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 1.89s
                      Time elapsed: 00:50:57
                               ETA: 00:03:45

################################################################################
                     [1m Learning iteration 1398/1500 [0m                     

                       Computation: 51065 steps/s (collection: 1.800s, learning 0.125s)
             Mean action noise std: 4.19
          Mean value_function loss: 69.2104
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 61.2099
                       Mean reward: 747.79
               Mean episode length: 242.54
    Episode_Reward/reaching_object: 1.1025
    Episode_Reward/rotating_object: 148.1185
        Episode_Reward/action_rate: -0.0899
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 1.93s
                      Time elapsed: 00:50:59
                               ETA: 00:03:43

################################################################################
                     [1m Learning iteration 1399/1500 [0m                     

                       Computation: 50260 steps/s (collection: 1.848s, learning 0.108s)
             Mean action noise std: 4.20
          Mean value_function loss: 59.7071
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 61.2170
                       Mean reward: 771.01
               Mean episode length: 240.48
    Episode_Reward/reaching_object: 1.1083
    Episode_Reward/rotating_object: 152.1317
        Episode_Reward/action_rate: -0.0904
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 1.96s
                      Time elapsed: 00:51:01
                               ETA: 00:03:40

################################################################################
                     [1m Learning iteration 1400/1500 [0m                     

                       Computation: 50083 steps/s (collection: 1.869s, learning 0.094s)
             Mean action noise std: 4.20
          Mean value_function loss: 49.0844
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 61.2245
                       Mean reward: 753.28
               Mean episode length: 240.06
    Episode_Reward/reaching_object: 1.1220
    Episode_Reward/rotating_object: 148.4834
        Episode_Reward/action_rate: -0.0914
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 1.96s
                      Time elapsed: 00:51:03
                               ETA: 00:03:38

################################################################################
                     [1m Learning iteration 1401/1500 [0m                     

                       Computation: 49940 steps/s (collection: 1.870s, learning 0.098s)
             Mean action noise std: 4.20
          Mean value_function loss: 52.2868
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 61.2344
                       Mean reward: 735.73
               Mean episode length: 245.12
    Episode_Reward/reaching_object: 1.1014
    Episode_Reward/rotating_object: 146.9218
        Episode_Reward/action_rate: -0.0902
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 1.97s
                      Time elapsed: 00:51:05
                               ETA: 00:03:36

################################################################################
                     [1m Learning iteration 1402/1500 [0m                     

                       Computation: 50935 steps/s (collection: 1.830s, learning 0.100s)
             Mean action noise std: 4.20
          Mean value_function loss: 70.5337
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 61.2501
                       Mean reward: 727.82
               Mean episode length: 234.68
    Episode_Reward/reaching_object: 1.0880
    Episode_Reward/rotating_object: 143.9281
        Episode_Reward/action_rate: -0.0895
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 1.93s
                      Time elapsed: 00:51:07
                               ETA: 00:03:34

################################################################################
                     [1m Learning iteration 1403/1500 [0m                     

                       Computation: 50749 steps/s (collection: 1.843s, learning 0.095s)
             Mean action noise std: 4.21
          Mean value_function loss: 51.5393
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 61.2655
                       Mean reward: 705.19
               Mean episode length: 236.72
    Episode_Reward/reaching_object: 1.1006
    Episode_Reward/rotating_object: 144.5407
        Episode_Reward/action_rate: -0.0903
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 1.94s
                      Time elapsed: 00:51:09
                               ETA: 00:03:32

################################################################################
                     [1m Learning iteration 1404/1500 [0m                     

                       Computation: 51450 steps/s (collection: 1.815s, learning 0.096s)
             Mean action noise std: 4.21
          Mean value_function loss: 54.9266
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 61.2782
                       Mean reward: 747.47
               Mean episode length: 240.31
    Episode_Reward/reaching_object: 1.0979
    Episode_Reward/rotating_object: 145.6990
        Episode_Reward/action_rate: -0.0906
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 1.91s
                      Time elapsed: 00:51:11
                               ETA: 00:03:29

################################################################################
                     [1m Learning iteration 1405/1500 [0m                     

                       Computation: 51089 steps/s (collection: 1.825s, learning 0.100s)
             Mean action noise std: 4.21
          Mean value_function loss: 44.8071
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 61.2938
                       Mean reward: 729.33
               Mean episode length: 235.79
    Episode_Reward/reaching_object: 1.0963
    Episode_Reward/rotating_object: 143.5216
        Episode_Reward/action_rate: -0.0904
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 1.92s
                      Time elapsed: 00:51:13
                               ETA: 00:03:27

################################################################################
                     [1m Learning iteration 1406/1500 [0m                     

                       Computation: 51499 steps/s (collection: 1.818s, learning 0.091s)
             Mean action noise std: 4.21
          Mean value_function loss: 63.5282
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 61.3092
                       Mean reward: 737.74
               Mean episode length: 235.63
    Episode_Reward/reaching_object: 1.1033
    Episode_Reward/rotating_object: 150.2948
        Episode_Reward/action_rate: -0.0913
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 1.91s
                      Time elapsed: 00:51:15
                               ETA: 00:03:25

################################################################################
                     [1m Learning iteration 1407/1500 [0m                     

                       Computation: 51512 steps/s (collection: 1.792s, learning 0.116s)
             Mean action noise std: 4.22
          Mean value_function loss: 47.9449
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 61.3278
                       Mean reward: 700.20
               Mean episode length: 231.31
    Episode_Reward/reaching_object: 1.0886
    Episode_Reward/rotating_object: 145.8074
        Episode_Reward/action_rate: -0.0902
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 1.91s
                      Time elapsed: 00:51:17
                               ETA: 00:03:23

################################################################################
                     [1m Learning iteration 1408/1500 [0m                     

                       Computation: 50979 steps/s (collection: 1.805s, learning 0.124s)
             Mean action noise std: 4.22
          Mean value_function loss: 58.0581
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 61.3462
                       Mean reward: 743.41
               Mean episode length: 236.57
    Episode_Reward/reaching_object: 1.0803
    Episode_Reward/rotating_object: 146.3319
        Episode_Reward/action_rate: -0.0899
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 1.93s
                      Time elapsed: 00:51:19
                               ETA: 00:03:21

################################################################################
                     [1m Learning iteration 1409/1500 [0m                     

                       Computation: 48555 steps/s (collection: 1.861s, learning 0.164s)
             Mean action noise std: 4.22
          Mean value_function loss: 58.1838
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 61.3613
                       Mean reward: 763.90
               Mean episode length: 238.07
    Episode_Reward/reaching_object: 1.1068
    Episode_Reward/rotating_object: 151.8734
        Episode_Reward/action_rate: -0.0920
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 2.02s
                      Time elapsed: 00:51:21
                               ETA: 00:03:18

################################################################################
                     [1m Learning iteration 1410/1500 [0m                     

                       Computation: 50536 steps/s (collection: 1.843s, learning 0.102s)
             Mean action noise std: 4.23
          Mean value_function loss: 62.5160
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.3688
                       Mean reward: 710.06
               Mean episode length: 227.60
    Episode_Reward/reaching_object: 1.0950
    Episode_Reward/rotating_object: 148.4125
        Episode_Reward/action_rate: -0.0911
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 1.95s
                      Time elapsed: 00:51:23
                               ETA: 00:03:16

################################################################################
                     [1m Learning iteration 1411/1500 [0m                     

                       Computation: 50427 steps/s (collection: 1.839s, learning 0.110s)
             Mean action noise std: 4.23
          Mean value_function loss: 56.1011
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 61.3785
                       Mean reward: 685.37
               Mean episode length: 234.52
    Episode_Reward/reaching_object: 1.0860
    Episode_Reward/rotating_object: 144.8467
        Episode_Reward/action_rate: -0.0909
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 1.95s
                      Time elapsed: 00:51:25
                               ETA: 00:03:14

################################################################################
                     [1m Learning iteration 1412/1500 [0m                     

                       Computation: 51016 steps/s (collection: 1.817s, learning 0.110s)
             Mean action noise std: 4.23
          Mean value_function loss: 56.4315
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.3943
                       Mean reward: 753.26
               Mean episode length: 242.56
    Episode_Reward/reaching_object: 1.0950
    Episode_Reward/rotating_object: 148.1153
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 1.93s
                      Time elapsed: 00:51:27
                               ETA: 00:03:12

################################################################################
                     [1m Learning iteration 1413/1500 [0m                     

                       Computation: 50871 steps/s (collection: 1.834s, learning 0.098s)
             Mean action noise std: 4.23
          Mean value_function loss: 57.8218
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 61.4080
                       Mean reward: 735.36
               Mean episode length: 238.45
    Episode_Reward/reaching_object: 1.1167
    Episode_Reward/rotating_object: 153.2175
        Episode_Reward/action_rate: -0.0931
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 1.93s
                      Time elapsed: 00:51:28
                               ETA: 00:03:10

################################################################################
                     [1m Learning iteration 1414/1500 [0m                     

                       Computation: 51542 steps/s (collection: 1.809s, learning 0.099s)
             Mean action noise std: 4.23
          Mean value_function loss: 63.4183
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 61.4160
                       Mean reward: 746.48
               Mean episode length: 238.02
    Episode_Reward/reaching_object: 1.0788
    Episode_Reward/rotating_object: 146.1412
        Episode_Reward/action_rate: -0.0902
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 1.91s
                      Time elapsed: 00:51:30
                               ETA: 00:03:07

################################################################################
                     [1m Learning iteration 1415/1500 [0m                     

                       Computation: 51765 steps/s (collection: 1.801s, learning 0.098s)
             Mean action noise std: 4.24
          Mean value_function loss: 55.8505
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 61.4254
                       Mean reward: 719.49
               Mean episode length: 234.62
    Episode_Reward/reaching_object: 1.0899
    Episode_Reward/rotating_object: 146.1983
        Episode_Reward/action_rate: -0.0913
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 1.90s
                      Time elapsed: 00:51:32
                               ETA: 00:03:05

################################################################################
                     [1m Learning iteration 1416/1500 [0m                     

                       Computation: 50798 steps/s (collection: 1.790s, learning 0.145s)
             Mean action noise std: 4.24
          Mean value_function loss: 73.3791
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 61.4402
                       Mean reward: 739.23
               Mean episode length: 232.97
    Episode_Reward/reaching_object: 1.0683
    Episode_Reward/rotating_object: 145.0618
        Episode_Reward/action_rate: -0.0895
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 1.94s
                      Time elapsed: 00:51:34
                               ETA: 00:03:03

################################################################################
                     [1m Learning iteration 1417/1500 [0m                     

                       Computation: 49727 steps/s (collection: 1.883s, learning 0.094s)
             Mean action noise std: 4.24
          Mean value_function loss: 61.3137
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 61.4522
                       Mean reward: 697.18
               Mean episode length: 230.09
    Episode_Reward/reaching_object: 1.0818
    Episode_Reward/rotating_object: 147.7403
        Episode_Reward/action_rate: -0.0912
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 1.98s
                      Time elapsed: 00:51:36
                               ETA: 00:03:01

################################################################################
                     [1m Learning iteration 1418/1500 [0m                     

                       Computation: 50110 steps/s (collection: 1.872s, learning 0.090s)
             Mean action noise std: 4.24
          Mean value_function loss: 64.5534
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 61.4548
                       Mean reward: 734.60
               Mean episode length: 236.84
    Episode_Reward/reaching_object: 1.0734
    Episode_Reward/rotating_object: 142.9756
        Episode_Reward/action_rate: -0.0907
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 1.96s
                      Time elapsed: 00:51:38
                               ETA: 00:02:59

################################################################################
                     [1m Learning iteration 1419/1500 [0m                     

                       Computation: 51319 steps/s (collection: 1.807s, learning 0.109s)
             Mean action noise std: 4.25
          Mean value_function loss: 71.8478
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 61.4624
                       Mean reward: 719.07
               Mean episode length: 230.38
    Episode_Reward/reaching_object: 1.0901
    Episode_Reward/rotating_object: 145.4637
        Episode_Reward/action_rate: -0.0916
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 1.92s
                      Time elapsed: 00:51:40
                               ETA: 00:02:56

################################################################################
                     [1m Learning iteration 1420/1500 [0m                     

                       Computation: 50932 steps/s (collection: 1.830s, learning 0.101s)
             Mean action noise std: 4.25
          Mean value_function loss: 60.2932
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 61.4752
                       Mean reward: 737.19
               Mean episode length: 238.01
    Episode_Reward/reaching_object: 1.0913
    Episode_Reward/rotating_object: 148.1568
        Episode_Reward/action_rate: -0.0920
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 1.93s
                      Time elapsed: 00:51:42
                               ETA: 00:02:54

################################################################################
                     [1m Learning iteration 1421/1500 [0m                     

                       Computation: 51261 steps/s (collection: 1.825s, learning 0.093s)
             Mean action noise std: 4.25
          Mean value_function loss: 69.8018
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 61.4853
                       Mean reward: 739.06
               Mean episode length: 232.45
    Episode_Reward/reaching_object: 1.0687
    Episode_Reward/rotating_object: 145.3517
        Episode_Reward/action_rate: -0.0902
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 1.92s
                      Time elapsed: 00:51:44
                               ETA: 00:02:52

################################################################################
                     [1m Learning iteration 1422/1500 [0m                     

                       Computation: 50510 steps/s (collection: 1.828s, learning 0.118s)
             Mean action noise std: 4.25
          Mean value_function loss: 53.3450
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 61.5004
                       Mean reward: 739.57
               Mean episode length: 238.27
    Episode_Reward/reaching_object: 1.0940
    Episode_Reward/rotating_object: 147.5524
        Episode_Reward/action_rate: -0.0925
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 1.95s
                      Time elapsed: 00:51:46
                               ETA: 00:02:50

################################################################################
                     [1m Learning iteration 1423/1500 [0m                     

                       Computation: 48577 steps/s (collection: 1.926s, learning 0.098s)
             Mean action noise std: 4.25
          Mean value_function loss: 57.4874
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 61.5080
                       Mean reward: 730.43
               Mean episode length: 232.66
    Episode_Reward/reaching_object: 1.0845
    Episode_Reward/rotating_object: 145.4457
        Episode_Reward/action_rate: -0.0916
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 2.02s
                      Time elapsed: 00:51:48
                               ETA: 00:02:48

################################################################################
                     [1m Learning iteration 1424/1500 [0m                     

                       Computation: 49436 steps/s (collection: 1.891s, learning 0.098s)
             Mean action noise std: 4.26
          Mean value_function loss: 68.5109
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 61.5180
                       Mean reward: 761.97
               Mean episode length: 239.22
    Episode_Reward/reaching_object: 1.0876
    Episode_Reward/rotating_object: 148.2272
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 1.99s
                      Time elapsed: 00:51:50
                               ETA: 00:02:45

################################################################################
                     [1m Learning iteration 1425/1500 [0m                     

                       Computation: 49250 steps/s (collection: 1.834s, learning 0.162s)
             Mean action noise std: 4.26
          Mean value_function loss: 64.6120
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 61.5324
                       Mean reward: 777.33
               Mean episode length: 240.95
    Episode_Reward/reaching_object: 1.0975
    Episode_Reward/rotating_object: 149.4713
        Episode_Reward/action_rate: -0.0927
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 2.00s
                      Time elapsed: 00:51:52
                               ETA: 00:02:43

################################################################################
                     [1m Learning iteration 1426/1500 [0m                     

                       Computation: 50605 steps/s (collection: 1.809s, learning 0.133s)
             Mean action noise std: 4.26
          Mean value_function loss: 63.2587
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 61.5429
                       Mean reward: 745.85
               Mean episode length: 234.66
    Episode_Reward/reaching_object: 1.0785
    Episode_Reward/rotating_object: 146.1432
        Episode_Reward/action_rate: -0.0911
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 1.94s
                      Time elapsed: 00:51:54
                               ETA: 00:02:41

################################################################################
                     [1m Learning iteration 1427/1500 [0m                     

                       Computation: 49481 steps/s (collection: 1.810s, learning 0.177s)
             Mean action noise std: 4.27
          Mean value_function loss: 76.0884
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 61.5561
                       Mean reward: 726.52
               Mean episode length: 233.18
    Episode_Reward/reaching_object: 1.0784
    Episode_Reward/rotating_object: 146.8885
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 1.99s
                      Time elapsed: 00:51:56
                               ETA: 00:02:39

################################################################################
                     [1m Learning iteration 1428/1500 [0m                     

                       Computation: 49927 steps/s (collection: 1.851s, learning 0.118s)
             Mean action noise std: 4.27
          Mean value_function loss: 50.4809
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 61.5674
                       Mean reward: 749.96
               Mean episode length: 237.48
    Episode_Reward/reaching_object: 1.0869
    Episode_Reward/rotating_object: 149.1475
        Episode_Reward/action_rate: -0.0922
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 1.97s
                      Time elapsed: 00:51:58
                               ETA: 00:02:37

################################################################################
                     [1m Learning iteration 1429/1500 [0m                     

                       Computation: 48679 steps/s (collection: 1.885s, learning 0.135s)
             Mean action noise std: 4.27
          Mean value_function loss: 62.3137
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 61.5806
                       Mean reward: 709.43
               Mean episode length: 231.25
    Episode_Reward/reaching_object: 1.0827
    Episode_Reward/rotating_object: 145.3669
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 2.02s
                      Time elapsed: 00:52:00
                               ETA: 00:02:34

################################################################################
                     [1m Learning iteration 1430/1500 [0m                     

                       Computation: 50649 steps/s (collection: 1.796s, learning 0.145s)
             Mean action noise std: 4.27
          Mean value_function loss: 65.8009
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 61.5962
                       Mean reward: 754.07
               Mean episode length: 241.26
    Episode_Reward/reaching_object: 1.1070
    Episode_Reward/rotating_object: 148.6192
        Episode_Reward/action_rate: -0.0938
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 1.94s
                      Time elapsed: 00:52:02
                               ETA: 00:02:32

################################################################################
                     [1m Learning iteration 1431/1500 [0m                     

                       Computation: 50359 steps/s (collection: 1.852s, learning 0.100s)
             Mean action noise std: 4.28
          Mean value_function loss: 72.2705
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 61.6106
                       Mean reward: 755.34
               Mean episode length: 235.50
    Episode_Reward/reaching_object: 1.0904
    Episode_Reward/rotating_object: 147.0841
        Episode_Reward/action_rate: -0.0929
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 1.95s
                      Time elapsed: 00:52:04
                               ETA: 00:02:30

################################################################################
                     [1m Learning iteration 1432/1500 [0m                     

                       Computation: 50518 steps/s (collection: 1.804s, learning 0.142s)
             Mean action noise std: 4.28
          Mean value_function loss: 76.9860
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 61.6211
                       Mean reward: 749.59
               Mean episode length: 234.48
    Episode_Reward/reaching_object: 1.0835
    Episode_Reward/rotating_object: 148.0427
        Episode_Reward/action_rate: -0.0922
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 1.95s
                      Time elapsed: 00:52:06
                               ETA: 00:02:28

################################################################################
                     [1m Learning iteration 1433/1500 [0m                     

                       Computation: 49611 steps/s (collection: 1.867s, learning 0.114s)
             Mean action noise std: 4.28
          Mean value_function loss: 57.3597
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.6302
                       Mean reward: 731.83
               Mean episode length: 234.70
    Episode_Reward/reaching_object: 1.1038
    Episode_Reward/rotating_object: 147.2925
        Episode_Reward/action_rate: -0.0943
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 1.98s
                      Time elapsed: 00:52:08
                               ETA: 00:02:26

################################################################################
                     [1m Learning iteration 1434/1500 [0m                     

                       Computation: 50006 steps/s (collection: 1.860s, learning 0.106s)
             Mean action noise std: 4.28
          Mean value_function loss: 71.2675
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 61.6379
                       Mean reward: 750.29
               Mean episode length: 238.89
    Episode_Reward/reaching_object: 1.0808
    Episode_Reward/rotating_object: 143.5321
        Episode_Reward/action_rate: -0.0931
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 1.97s
                      Time elapsed: 00:52:10
                               ETA: 00:02:23

################################################################################
                     [1m Learning iteration 1435/1500 [0m                     

                       Computation: 50671 steps/s (collection: 1.840s, learning 0.100s)
             Mean action noise std: 4.28
          Mean value_function loss: 71.3477
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 61.6454
                       Mean reward: 720.90
               Mean episode length: 228.77
    Episode_Reward/reaching_object: 1.0576
    Episode_Reward/rotating_object: 142.4342
        Episode_Reward/action_rate: -0.0906
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 1.94s
                      Time elapsed: 00:52:12
                               ETA: 00:02:21

################################################################################
                     [1m Learning iteration 1436/1500 [0m                     

                       Computation: 51242 steps/s (collection: 1.822s, learning 0.097s)
             Mean action noise std: 4.29
          Mean value_function loss: 66.4623
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 61.6626
                       Mean reward: 740.46
               Mean episode length: 233.62
    Episode_Reward/reaching_object: 1.0713
    Episode_Reward/rotating_object: 145.0687
        Episode_Reward/action_rate: -0.0919
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 1.92s
                      Time elapsed: 00:52:13
                               ETA: 00:02:19

################################################################################
                     [1m Learning iteration 1437/1500 [0m                     

                       Computation: 49893 steps/s (collection: 1.853s, learning 0.118s)
             Mean action noise std: 4.29
          Mean value_function loss: 79.7809
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 61.6773
                       Mean reward: 751.83
               Mean episode length: 237.38
    Episode_Reward/reaching_object: 1.0828
    Episode_Reward/rotating_object: 146.7318
        Episode_Reward/action_rate: -0.0925
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 1.97s
                      Time elapsed: 00:52:15
                               ETA: 00:02:17

################################################################################
                     [1m Learning iteration 1438/1500 [0m                     

                       Computation: 51252 steps/s (collection: 1.801s, learning 0.117s)
             Mean action noise std: 4.29
          Mean value_function loss: 60.5707
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 61.6887
                       Mean reward: 744.35
               Mean episode length: 237.22
    Episode_Reward/reaching_object: 1.0897
    Episode_Reward/rotating_object: 146.5833
        Episode_Reward/action_rate: -0.0936
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 1.92s
                      Time elapsed: 00:52:17
                               ETA: 00:02:15

################################################################################
                     [1m Learning iteration 1439/1500 [0m                     

                       Computation: 51442 steps/s (collection: 1.810s, learning 0.101s)
             Mean action noise std: 4.30
          Mean value_function loss: 65.9698
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 61.7003
                       Mean reward: 717.22
               Mean episode length: 231.23
    Episode_Reward/reaching_object: 1.0680
    Episode_Reward/rotating_object: 144.2663
        Episode_Reward/action_rate: -0.0916
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 1.91s
                      Time elapsed: 00:52:19
                               ETA: 00:02:13

################################################################################
                     [1m Learning iteration 1440/1500 [0m                     

                       Computation: 50454 steps/s (collection: 1.857s, learning 0.092s)
             Mean action noise std: 4.30
          Mean value_function loss: 70.5483
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 61.7114
                       Mean reward: 744.05
               Mean episode length: 231.09
    Episode_Reward/reaching_object: 1.0751
    Episode_Reward/rotating_object: 144.0132
        Episode_Reward/action_rate: -0.0926
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 1.95s
                      Time elapsed: 00:52:21
                               ETA: 00:02:10

################################################################################
                     [1m Learning iteration 1441/1500 [0m                     

                       Computation: 51338 steps/s (collection: 1.802s, learning 0.113s)
             Mean action noise std: 4.30
          Mean value_function loss: 70.7816
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 61.7257
                       Mean reward: 730.74
               Mean episode length: 229.63
    Episode_Reward/reaching_object: 1.0740
    Episode_Reward/rotating_object: 144.1065
        Episode_Reward/action_rate: -0.0930
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 1.91s
                      Time elapsed: 00:52:23
                               ETA: 00:02:08

################################################################################
                     [1m Learning iteration 1442/1500 [0m                     

                       Computation: 48399 steps/s (collection: 1.891s, learning 0.140s)
             Mean action noise std: 4.30
          Mean value_function loss: 57.2308
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 61.7357
                       Mean reward: 735.02
               Mean episode length: 237.75
    Episode_Reward/reaching_object: 1.0920
    Episode_Reward/rotating_object: 145.7630
        Episode_Reward/action_rate: -0.0939
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 2.03s
                      Time elapsed: 00:52:25
                               ETA: 00:02:06

################################################################################
                     [1m Learning iteration 1443/1500 [0m                     

                       Computation: 49858 steps/s (collection: 1.856s, learning 0.116s)
             Mean action noise std: 4.30
          Mean value_function loss: 69.2083
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 61.7436
                       Mean reward: 710.99
               Mean episode length: 230.71
    Episode_Reward/reaching_object: 1.0960
    Episode_Reward/rotating_object: 144.9559
        Episode_Reward/action_rate: -0.0947
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 1.97s
                      Time elapsed: 00:52:27
                               ETA: 00:02:04

################################################################################
                     [1m Learning iteration 1444/1500 [0m                     

                       Computation: 51647 steps/s (collection: 1.761s, learning 0.142s)
             Mean action noise std: 4.31
          Mean value_function loss: 70.7615
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 61.7511
                       Mean reward: 700.78
               Mean episode length: 225.44
    Episode_Reward/reaching_object: 1.0732
    Episode_Reward/rotating_object: 145.3391
        Episode_Reward/action_rate: -0.0928
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 1.90s
                      Time elapsed: 00:52:29
                               ETA: 00:02:02

################################################################################
                     [1m Learning iteration 1445/1500 [0m                     

                       Computation: 50091 steps/s (collection: 1.807s, learning 0.156s)
             Mean action noise std: 4.31
          Mean value_function loss: 64.3407
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 61.7636
                       Mean reward: 743.33
               Mean episode length: 238.44
    Episode_Reward/reaching_object: 1.0700
    Episode_Reward/rotating_object: 143.7987
        Episode_Reward/action_rate: -0.0932
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 1.96s
                      Time elapsed: 00:52:31
                               ETA: 00:01:59

################################################################################
                     [1m Learning iteration 1446/1500 [0m                     

                       Computation: 52177 steps/s (collection: 1.768s, learning 0.116s)
             Mean action noise std: 4.31
          Mean value_function loss: 61.0818
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 61.7756
                       Mean reward: 710.95
               Mean episode length: 225.70
    Episode_Reward/reaching_object: 1.0618
    Episode_Reward/rotating_object: 144.8163
        Episode_Reward/action_rate: -0.0923
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 1.88s
                      Time elapsed: 00:52:33
                               ETA: 00:01:57

################################################################################
                     [1m Learning iteration 1447/1500 [0m                     

                       Computation: 50052 steps/s (collection: 1.801s, learning 0.163s)
             Mean action noise std: 4.31
          Mean value_function loss: 64.8886
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 61.7859
                       Mean reward: 780.75
               Mean episode length: 243.59
    Episode_Reward/reaching_object: 1.0868
    Episode_Reward/rotating_object: 148.7256
        Episode_Reward/action_rate: -0.0945
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 1.96s
                      Time elapsed: 00:52:35
                               ETA: 00:01:55

################################################################################
                     [1m Learning iteration 1448/1500 [0m                     

                       Computation: 50196 steps/s (collection: 1.841s, learning 0.117s)
             Mean action noise std: 4.32
          Mean value_function loss: 51.6021
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 61.7973
                       Mean reward: 733.09
               Mean episode length: 235.46
    Episode_Reward/reaching_object: 1.0921
    Episode_Reward/rotating_object: 150.0336
        Episode_Reward/action_rate: -0.0959
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 1.96s
                      Time elapsed: 00:52:37
                               ETA: 00:01:53

################################################################################
                     [1m Learning iteration 1449/1500 [0m                     

                       Computation: 49716 steps/s (collection: 1.859s, learning 0.118s)
             Mean action noise std: 4.32
          Mean value_function loss: 78.3871
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.8049
                       Mean reward: 768.67
               Mean episode length: 238.58
    Episode_Reward/reaching_object: 1.0786
    Episode_Reward/rotating_object: 148.3233
        Episode_Reward/action_rate: -0.0947
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 1.98s
                      Time elapsed: 00:52:39
                               ETA: 00:01:51

################################################################################
                     [1m Learning iteration 1450/1500 [0m                     

                       Computation: 51240 steps/s (collection: 1.810s, learning 0.109s)
             Mean action noise std: 4.32
          Mean value_function loss: 63.0881
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 61.8167
                       Mean reward: 761.75
               Mean episode length: 242.63
    Episode_Reward/reaching_object: 1.0857
    Episode_Reward/rotating_object: 149.4796
        Episode_Reward/action_rate: -0.0956
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 1.92s
                      Time elapsed: 00:52:41
                               ETA: 00:01:48

################################################################################
                     [1m Learning iteration 1451/1500 [0m                     

                       Computation: 50596 steps/s (collection: 1.854s, learning 0.089s)
             Mean action noise std: 4.32
          Mean value_function loss: 63.8541
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 61.8289
                       Mean reward: 727.24
               Mean episode length: 235.75
    Episode_Reward/reaching_object: 1.0794
    Episode_Reward/rotating_object: 146.7628
        Episode_Reward/action_rate: -0.0956
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 1.94s
                      Time elapsed: 00:52:43
                               ETA: 00:01:46

################################################################################
                     [1m Learning iteration 1452/1500 [0m                     

                       Computation: 51202 steps/s (collection: 1.829s, learning 0.091s)
             Mean action noise std: 4.33
          Mean value_function loss: 56.4130
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 61.8409
                       Mean reward: 726.22
               Mean episode length: 233.61
    Episode_Reward/reaching_object: 1.0848
    Episode_Reward/rotating_object: 148.3697
        Episode_Reward/action_rate: -0.0962
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 1.92s
                      Time elapsed: 00:52:45
                               ETA: 00:01:44

################################################################################
                     [1m Learning iteration 1453/1500 [0m                     

                       Computation: 49940 steps/s (collection: 1.860s, learning 0.109s)
             Mean action noise std: 4.33
          Mean value_function loss: 57.2506
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 61.8478
                       Mean reward: 747.17
               Mean episode length: 236.43
    Episode_Reward/reaching_object: 1.0867
    Episode_Reward/rotating_object: 150.5816
        Episode_Reward/action_rate: -0.0962
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 1.97s
                      Time elapsed: 00:52:46
                               ETA: 00:01:42

################################################################################
                     [1m Learning iteration 1454/1500 [0m                     

                       Computation: 50729 steps/s (collection: 1.847s, learning 0.091s)
             Mean action noise std: 4.33
          Mean value_function loss: 63.6829
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 61.8597
                       Mean reward: 737.02
               Mean episode length: 230.95
    Episode_Reward/reaching_object: 1.0607
    Episode_Reward/rotating_object: 146.5169
        Episode_Reward/action_rate: -0.0943
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 1.94s
                      Time elapsed: 00:52:48
                               ETA: 00:01:40

################################################################################
                     [1m Learning iteration 1455/1500 [0m                     

                       Computation: 46560 steps/s (collection: 1.994s, learning 0.117s)
             Mean action noise std: 4.33
          Mean value_function loss: 67.4260
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 61.8689
                       Mean reward: 764.50
               Mean episode length: 239.10
    Episode_Reward/reaching_object: 1.0830
    Episode_Reward/rotating_object: 148.9700
        Episode_Reward/action_rate: -0.0965
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 2.11s
                      Time elapsed: 00:52:51
                               ETA: 00:01:38

################################################################################
                     [1m Learning iteration 1456/1500 [0m                     

                       Computation: 51198 steps/s (collection: 1.829s, learning 0.091s)
             Mean action noise std: 4.33
          Mean value_function loss: 70.8739
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 61.8727
                       Mean reward: 719.80
               Mean episode length: 230.08
    Episode_Reward/reaching_object: 1.0678
    Episode_Reward/rotating_object: 147.5152
        Episode_Reward/action_rate: -0.0952
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 1.92s
                      Time elapsed: 00:52:52
                               ETA: 00:01:35

################################################################################
                     [1m Learning iteration 1457/1500 [0m                     

                       Computation: 52006 steps/s (collection: 1.800s, learning 0.090s)
             Mean action noise std: 4.34
          Mean value_function loss: 52.7534
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 61.8797
                       Mean reward: 737.54
               Mean episode length: 236.10
    Episode_Reward/reaching_object: 1.0626
    Episode_Reward/rotating_object: 145.9076
        Episode_Reward/action_rate: -0.0956
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 1.89s
                      Time elapsed: 00:52:54
                               ETA: 00:01:33

################################################################################
                     [1m Learning iteration 1458/1500 [0m                     

                       Computation: 51481 steps/s (collection: 1.820s, learning 0.089s)
             Mean action noise std: 4.34
          Mean value_function loss: 52.4424
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 61.8908
                       Mean reward: 769.17
               Mean episode length: 241.99
    Episode_Reward/reaching_object: 1.0969
    Episode_Reward/rotating_object: 152.5550
        Episode_Reward/action_rate: -0.0983
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 1.91s
                      Time elapsed: 00:52:56
                               ETA: 00:01:31

################################################################################
                     [1m Learning iteration 1459/1500 [0m                     

                       Computation: 51200 steps/s (collection: 1.822s, learning 0.098s)
             Mean action noise std: 4.34
          Mean value_function loss: 58.0827
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.9009
                       Mean reward: 799.68
               Mean episode length: 245.61
    Episode_Reward/reaching_object: 1.1039
    Episode_Reward/rotating_object: 153.9209
        Episode_Reward/action_rate: -0.0983
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 1.92s
                      Time elapsed: 00:52:58
                               ETA: 00:01:29

################################################################################
                     [1m Learning iteration 1460/1500 [0m                     

                       Computation: 50616 steps/s (collection: 1.836s, learning 0.107s)
             Mean action noise std: 4.34
          Mean value_function loss: 63.9943
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 61.9127
                       Mean reward: 763.62
               Mean episode length: 237.61
    Episode_Reward/reaching_object: 1.0615
    Episode_Reward/rotating_object: 147.0911
        Episode_Reward/action_rate: -0.0954
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 1.94s
                      Time elapsed: 00:53:00
                               ETA: 00:01:27

################################################################################
                     [1m Learning iteration 1461/1500 [0m                     

                       Computation: 50208 steps/s (collection: 1.823s, learning 0.135s)
             Mean action noise std: 4.34
          Mean value_function loss: 63.0622
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 61.9231
                       Mean reward: 781.35
               Mean episode length: 243.51
    Episode_Reward/reaching_object: 1.0834
    Episode_Reward/rotating_object: 150.7624
        Episode_Reward/action_rate: -0.0972
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 1.96s
                      Time elapsed: 00:53:02
                               ETA: 00:01:24

################################################################################
                     [1m Learning iteration 1462/1500 [0m                     

                       Computation: 49270 steps/s (collection: 1.843s, learning 0.152s)
             Mean action noise std: 4.35
          Mean value_function loss: 64.5391
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 61.9334
                       Mean reward: 729.67
               Mean episode length: 232.11
    Episode_Reward/reaching_object: 1.0545
    Episode_Reward/rotating_object: 143.8608
        Episode_Reward/action_rate: -0.0951
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 2.00s
                      Time elapsed: 00:53:04
                               ETA: 00:01:22

################################################################################
                     [1m Learning iteration 1463/1500 [0m                     

                       Computation: 51384 steps/s (collection: 1.791s, learning 0.122s)
             Mean action noise std: 4.35
          Mean value_function loss: 63.6667
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 61.9457
                       Mean reward: 763.57
               Mean episode length: 243.74
    Episode_Reward/reaching_object: 1.0884
    Episode_Reward/rotating_object: 150.2430
        Episode_Reward/action_rate: -0.0980
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 1.91s
                      Time elapsed: 00:53:06
                               ETA: 00:01:20

################################################################################
                     [1m Learning iteration 1464/1500 [0m                     

                       Computation: 49414 steps/s (collection: 1.849s, learning 0.141s)
             Mean action noise std: 4.35
          Mean value_function loss: 59.3046
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 61.9604
                       Mean reward: 736.21
               Mean episode length: 239.30
    Episode_Reward/reaching_object: 1.0703
    Episode_Reward/rotating_object: 143.7045
        Episode_Reward/action_rate: -0.0960
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 1.99s
                      Time elapsed: 00:53:08
                               ETA: 00:01:18

################################################################################
                     [1m Learning iteration 1465/1500 [0m                     

                       Computation: 49105 steps/s (collection: 1.853s, learning 0.149s)
             Mean action noise std: 4.36
          Mean value_function loss: 55.9055
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 61.9736
                       Mean reward: 715.43
               Mean episode length: 234.09
    Episode_Reward/reaching_object: 1.0454
    Episode_Reward/rotating_object: 139.9088
        Episode_Reward/action_rate: -0.0946
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 2.00s
                      Time elapsed: 00:53:10
                               ETA: 00:01:16

################################################################################
                     [1m Learning iteration 1466/1500 [0m                     

                       Computation: 50766 steps/s (collection: 1.813s, learning 0.124s)
             Mean action noise std: 4.36
          Mean value_function loss: 56.7090
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 61.9877
                       Mean reward: 728.88
               Mean episode length: 231.53
    Episode_Reward/reaching_object: 1.0919
    Episode_Reward/rotating_object: 150.3927
        Episode_Reward/action_rate: -0.0976
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 1.94s
                      Time elapsed: 00:53:12
                               ETA: 00:01:13

################################################################################
                     [1m Learning iteration 1467/1500 [0m                     

                       Computation: 49869 steps/s (collection: 1.834s, learning 0.138s)
             Mean action noise std: 4.36
          Mean value_function loss: 61.7002
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 62.0002
                       Mean reward: 709.08
               Mean episode length: 232.23
    Episode_Reward/reaching_object: 1.0770
    Episode_Reward/rotating_object: 147.5121
        Episode_Reward/action_rate: -0.0968
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 1.97s
                      Time elapsed: 00:53:14
                               ETA: 00:01:11

################################################################################
                     [1m Learning iteration 1468/1500 [0m                     

                       Computation: 50189 steps/s (collection: 1.840s, learning 0.118s)
             Mean action noise std: 4.36
          Mean value_function loss: 54.3549
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 62.0129
                       Mean reward: 734.27
               Mean episode length: 235.07
    Episode_Reward/reaching_object: 1.0723
    Episode_Reward/rotating_object: 147.5352
        Episode_Reward/action_rate: -0.0963
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 1.96s
                      Time elapsed: 00:53:16
                               ETA: 00:01:09

################################################################################
                     [1m Learning iteration 1469/1500 [0m                     

                       Computation: 50726 steps/s (collection: 1.845s, learning 0.093s)
             Mean action noise std: 4.37
          Mean value_function loss: 65.1116
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 62.0256
                       Mean reward: 726.92
               Mean episode length: 235.36
    Episode_Reward/reaching_object: 1.0960
    Episode_Reward/rotating_object: 150.5726
        Episode_Reward/action_rate: -0.0981
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 1.94s
                      Time elapsed: 00:53:18
                               ETA: 00:01:07

################################################################################
                     [1m Learning iteration 1470/1500 [0m                     

                       Computation: 48597 steps/s (collection: 1.879s, learning 0.144s)
             Mean action noise std: 4.37
          Mean value_function loss: 55.6892
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 62.0336
                       Mean reward: 696.01
               Mean episode length: 227.53
    Episode_Reward/reaching_object: 1.0775
    Episode_Reward/rotating_object: 146.3638
        Episode_Reward/action_rate: -0.0969
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 2.02s
                      Time elapsed: 00:53:20
                               ETA: 00:01:05

################################################################################
                     [1m Learning iteration 1471/1500 [0m                     

                       Computation: 49904 steps/s (collection: 1.861s, learning 0.109s)
             Mean action noise std: 4.37
          Mean value_function loss: 68.8849
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 62.0403
                       Mean reward: 761.41
               Mean episode length: 241.75
    Episode_Reward/reaching_object: 1.0741
    Episode_Reward/rotating_object: 148.6685
        Episode_Reward/action_rate: -0.0967
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 1.97s
                      Time elapsed: 00:53:22
                               ETA: 00:01:03

################################################################################
                     [1m Learning iteration 1472/1500 [0m                     

                       Computation: 51569 steps/s (collection: 1.802s, learning 0.104s)
             Mean action noise std: 4.37
          Mean value_function loss: 75.5967
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 62.0521
                       Mean reward: 737.81
               Mean episode length: 232.06
    Episode_Reward/reaching_object: 1.0625
    Episode_Reward/rotating_object: 144.9940
        Episode_Reward/action_rate: -0.0957
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 1.91s
                      Time elapsed: 00:53:24
                               ETA: 00:01:00

################################################################################
                     [1m Learning iteration 1473/1500 [0m                     

                       Computation: 51467 steps/s (collection: 1.822s, learning 0.088s)
             Mean action noise std: 4.37
          Mean value_function loss: 51.6871
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 62.0594
                       Mean reward: 715.71
               Mean episode length: 231.29
    Episode_Reward/reaching_object: 1.0765
    Episode_Reward/rotating_object: 146.3685
        Episode_Reward/action_rate: -0.0969
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 1.91s
                      Time elapsed: 00:53:26
                               ETA: 00:00:58

################################################################################
                     [1m Learning iteration 1474/1500 [0m                     

                       Computation: 51822 steps/s (collection: 1.804s, learning 0.093s)
             Mean action noise std: 4.38
          Mean value_function loss: 56.3668
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 62.0654
                       Mean reward: 724.07
               Mean episode length: 236.48
    Episode_Reward/reaching_object: 1.0974
    Episode_Reward/rotating_object: 148.6658
        Episode_Reward/action_rate: -0.0989
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 1.90s
                      Time elapsed: 00:53:27
                               ETA: 00:00:56

################################################################################
                     [1m Learning iteration 1475/1500 [0m                     

                       Computation: 50677 steps/s (collection: 1.844s, learning 0.096s)
             Mean action noise std: 4.38
          Mean value_function loss: 74.1522
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 62.0747
                       Mean reward: 755.61
               Mean episode length: 234.45
    Episode_Reward/reaching_object: 1.0626
    Episode_Reward/rotating_object: 146.2156
        Episode_Reward/action_rate: -0.0959
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 1.94s
                      Time elapsed: 00:53:29
                               ETA: 00:00:54

################################################################################
                     [1m Learning iteration 1476/1500 [0m                     

                       Computation: 52252 steps/s (collection: 1.792s, learning 0.089s)
             Mean action noise std: 4.38
          Mean value_function loss: 56.9557
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 62.0869
                       Mean reward: 764.14
               Mean episode length: 245.15
    Episode_Reward/reaching_object: 1.0772
    Episode_Reward/rotating_object: 146.2569
        Episode_Reward/action_rate: -0.0977
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 1.88s
                      Time elapsed: 00:53:31
                               ETA: 00:00:52

################################################################################
                     [1m Learning iteration 1477/1500 [0m                     

                       Computation: 48449 steps/s (collection: 1.907s, learning 0.122s)
             Mean action noise std: 4.38
          Mean value_function loss: 68.4834
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 62.0922
                       Mean reward: 705.08
               Mean episode length: 224.27
    Episode_Reward/reaching_object: 1.0688
    Episode_Reward/rotating_object: 147.4094
        Episode_Reward/action_rate: -0.0967
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 2.03s
                      Time elapsed: 00:53:33
                               ETA: 00:00:50

################################################################################
                     [1m Learning iteration 1478/1500 [0m                     

                       Computation: 48774 steps/s (collection: 1.922s, learning 0.093s)
             Mean action noise std: 4.39
          Mean value_function loss: 52.9619
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 62.1032
                       Mean reward: 732.66
               Mean episode length: 232.32
    Episode_Reward/reaching_object: 1.0760
    Episode_Reward/rotating_object: 148.9023
        Episode_Reward/action_rate: -0.0979
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 2.02s
                      Time elapsed: 00:53:35
                               ETA: 00:00:47

################################################################################
                     [1m Learning iteration 1479/1500 [0m                     

                       Computation: 50709 steps/s (collection: 1.851s, learning 0.088s)
             Mean action noise std: 4.39
          Mean value_function loss: 61.1505
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 62.1145
                       Mean reward: 768.02
               Mean episode length: 237.94
    Episode_Reward/reaching_object: 1.0922
    Episode_Reward/rotating_object: 153.0967
        Episode_Reward/action_rate: -0.0990
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 1.94s
                      Time elapsed: 00:53:37
                               ETA: 00:00:45

################################################################################
                     [1m Learning iteration 1480/1500 [0m                     

                       Computation: 51170 steps/s (collection: 1.787s, learning 0.134s)
             Mean action noise std: 4.39
          Mean value_function loss: 75.7222
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 62.1252
                       Mean reward: 700.69
               Mean episode length: 230.24
    Episode_Reward/reaching_object: 1.0658
    Episode_Reward/rotating_object: 145.9355
        Episode_Reward/action_rate: -0.0970
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 1.92s
                      Time elapsed: 00:53:39
                               ETA: 00:00:43

################################################################################
                     [1m Learning iteration 1481/1500 [0m                     

                       Computation: 49732 steps/s (collection: 1.845s, learning 0.132s)
             Mean action noise std: 4.39
          Mean value_function loss: 72.8314
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 62.1379
                       Mean reward: 730.09
               Mean episode length: 229.33
    Episode_Reward/reaching_object: 1.0736
    Episode_Reward/rotating_object: 148.4415
        Episode_Reward/action_rate: -0.0976
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 1.98s
                      Time elapsed: 00:53:41
                               ETA: 00:00:41

################################################################################
                     [1m Learning iteration 1482/1500 [0m                     

                       Computation: 50341 steps/s (collection: 1.837s, learning 0.116s)
             Mean action noise std: 4.39
          Mean value_function loss: 62.2721
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 62.1486
                       Mean reward: 724.58
               Mean episode length: 228.03
    Episode_Reward/reaching_object: 1.0793
    Episode_Reward/rotating_object: 148.3586
        Episode_Reward/action_rate: -0.0981
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 1.95s
                      Time elapsed: 00:53:43
                               ETA: 00:00:39

################################################################################
                     [1m Learning iteration 1483/1500 [0m                     

                       Computation: 50522 steps/s (collection: 1.792s, learning 0.154s)
             Mean action noise std: 4.40
          Mean value_function loss: 80.0505
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 62.1573
                       Mean reward: 715.56
               Mean episode length: 225.85
    Episode_Reward/reaching_object: 1.0793
    Episode_Reward/rotating_object: 148.1119
        Episode_Reward/action_rate: -0.0985
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 1.95s
                      Time elapsed: 00:53:45
                               ETA: 00:00:36

################################################################################
                     [1m Learning iteration 1484/1500 [0m                     

                       Computation: 52325 steps/s (collection: 1.784s, learning 0.094s)
             Mean action noise std: 4.40
          Mean value_function loss: 76.6580
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 62.1718
                       Mean reward: 765.42
               Mean episode length: 239.88
    Episode_Reward/reaching_object: 1.0837
    Episode_Reward/rotating_object: 147.5999
        Episode_Reward/action_rate: -0.0982
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 1.88s
                      Time elapsed: 00:53:47
                               ETA: 00:00:34

################################################################################
                     [1m Learning iteration 1485/1500 [0m                     

                       Computation: 50404 steps/s (collection: 1.833s, learning 0.117s)
             Mean action noise std: 4.40
          Mean value_function loss: 80.2169
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 62.1860
                       Mean reward: 701.78
               Mean episode length: 221.61
    Episode_Reward/reaching_object: 1.0482
    Episode_Reward/rotating_object: 142.9495
        Episode_Reward/action_rate: -0.0953
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 1.95s
                      Time elapsed: 00:53:49
                               ETA: 00:00:32

################################################################################
                     [1m Learning iteration 1486/1500 [0m                     

                       Computation: 51674 steps/s (collection: 1.813s, learning 0.090s)
             Mean action noise std: 4.40
          Mean value_function loss: 67.3380
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 62.1932
                       Mean reward: 710.95
               Mean episode length: 229.87
    Episode_Reward/reaching_object: 1.0680
    Episode_Reward/rotating_object: 143.2683
        Episode_Reward/action_rate: -0.0971
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 1.90s
                      Time elapsed: 00:53:51
                               ETA: 00:00:30

################################################################################
                     [1m Learning iteration 1487/1500 [0m                     

                       Computation: 51680 steps/s (collection: 1.802s, learning 0.100s)
             Mean action noise std: 4.40
          Mean value_function loss: 68.5209
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 62.1969
                       Mean reward: 761.00
               Mean episode length: 237.16
    Episode_Reward/reaching_object: 1.0668
    Episode_Reward/rotating_object: 146.4418
        Episode_Reward/action_rate: -0.0972
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 1.90s
                      Time elapsed: 00:53:53
                               ETA: 00:00:28

################################################################################
                     [1m Learning iteration 1488/1500 [0m                     

                       Computation: 51158 steps/s (collection: 1.827s, learning 0.095s)
             Mean action noise std: 4.41
          Mean value_function loss: 59.5071
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 62.2029
                       Mean reward: 731.38
               Mean episode length: 231.17
    Episode_Reward/reaching_object: 1.0770
    Episode_Reward/rotating_object: 147.4546
        Episode_Reward/action_rate: -0.0982
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 1.92s
                      Time elapsed: 00:53:55
                               ETA: 00:00:26

################################################################################
                     [1m Learning iteration 1489/1500 [0m                     

                       Computation: 52237 steps/s (collection: 1.781s, learning 0.101s)
             Mean action noise std: 4.41
          Mean value_function loss: 71.3288
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 62.2157
                       Mean reward: 726.47
               Mean episode length: 230.11
    Episode_Reward/reaching_object: 1.0793
    Episode_Reward/rotating_object: 146.5978
        Episode_Reward/action_rate: -0.0980
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 1.88s
                      Time elapsed: 00:53:57
                               ETA: 00:00:23

################################################################################
                     [1m Learning iteration 1490/1500 [0m                     

                       Computation: 51462 steps/s (collection: 1.810s, learning 0.101s)
             Mean action noise std: 4.41
          Mean value_function loss: 54.3227
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 62.2342
                       Mean reward: 725.93
               Mean episode length: 232.13
    Episode_Reward/reaching_object: 1.0874
    Episode_Reward/rotating_object: 149.2466
        Episode_Reward/action_rate: -0.0993
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 1.91s
                      Time elapsed: 00:53:58
                               ETA: 00:00:21

################################################################################
                     [1m Learning iteration 1491/1500 [0m                     

                       Computation: 51140 steps/s (collection: 1.798s, learning 0.124s)
             Mean action noise std: 4.41
          Mean value_function loss: 71.2348
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 62.2423
                       Mean reward: 781.80
               Mean episode length: 241.14
    Episode_Reward/reaching_object: 1.0528
    Episode_Reward/rotating_object: 144.6940
        Episode_Reward/action_rate: -0.0967
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 1.92s
                      Time elapsed: 00:54:00
                               ETA: 00:00:19

################################################################################
                     [1m Learning iteration 1492/1500 [0m                     

                       Computation: 50299 steps/s (collection: 1.800s, learning 0.154s)
             Mean action noise std: 4.42
          Mean value_function loss: 73.6566
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 62.2479
                       Mean reward: 755.77
               Mean episode length: 236.56
    Episode_Reward/reaching_object: 1.0738
    Episode_Reward/rotating_object: 145.9198
        Episode_Reward/action_rate: -0.0978
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 1.95s
                      Time elapsed: 00:54:02
                               ETA: 00:00:17

################################################################################
                     [1m Learning iteration 1493/1500 [0m                     

                       Computation: 51196 steps/s (collection: 1.831s, learning 0.090s)
             Mean action noise std: 4.42
          Mean value_function loss: 68.8481
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 62.2567
                       Mean reward: 735.20
               Mean episode length: 232.10
    Episode_Reward/reaching_object: 1.0820
    Episode_Reward/rotating_object: 149.1971
        Episode_Reward/action_rate: -0.0991
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 1.92s
                      Time elapsed: 00:54:04
                               ETA: 00:00:15

################################################################################
                     [1m Learning iteration 1494/1500 [0m                     

                       Computation: 51774 steps/s (collection: 1.785s, learning 0.114s)
             Mean action noise std: 4.42
          Mean value_function loss: 54.3054
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 62.2621
                       Mean reward: 728.19
               Mean episode length: 232.85
    Episode_Reward/reaching_object: 1.0747
    Episode_Reward/rotating_object: 145.1693
        Episode_Reward/action_rate: -0.0982
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 1.90s
                      Time elapsed: 00:54:06
                               ETA: 00:00:13

################################################################################
                     [1m Learning iteration 1495/1500 [0m                     

                       Computation: 52731 steps/s (collection: 1.766s, learning 0.099s)
             Mean action noise std: 4.42
          Mean value_function loss: 55.6218
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 62.2729
                       Mean reward: 786.87
               Mean episode length: 242.31
    Episode_Reward/reaching_object: 1.0873
    Episode_Reward/rotating_object: 151.8057
        Episode_Reward/action_rate: -0.0995
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 1.86s
                      Time elapsed: 00:54:08
                               ETA: 00:00:10

################################################################################
                     [1m Learning iteration 1496/1500 [0m                     

                       Computation: 51592 steps/s (collection: 1.811s, learning 0.095s)
             Mean action noise std: 4.42
          Mean value_function loss: 63.2231
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 62.2814
                       Mean reward: 745.06
               Mean episode length: 232.77
    Episode_Reward/reaching_object: 1.0805
    Episode_Reward/rotating_object: 149.8418
        Episode_Reward/action_rate: -0.0993
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 1.91s
                      Time elapsed: 00:54:10
                               ETA: 00:00:08

################################################################################
                     [1m Learning iteration 1497/1500 [0m                     

                       Computation: 52917 steps/s (collection: 1.769s, learning 0.089s)
             Mean action noise std: 4.43
          Mean value_function loss: 69.0777
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 62.2944
                       Mean reward: 778.54
               Mean episode length: 240.42
    Episode_Reward/reaching_object: 1.0921
    Episode_Reward/rotating_object: 150.0670
        Episode_Reward/action_rate: -0.1001
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 1.86s
                      Time elapsed: 00:54:12
                               ETA: 00:00:06

################################################################################
                     [1m Learning iteration 1498/1500 [0m                     

                       Computation: 52837 steps/s (collection: 1.772s, learning 0.088s)
             Mean action noise std: 4.43
          Mean value_function loss: 76.9117
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 62.3073
                       Mean reward: 752.68
               Mean episode length: 238.36
    Episode_Reward/reaching_object: 1.0784
    Episode_Reward/rotating_object: 148.1031
        Episode_Reward/action_rate: -0.0992
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 1.86s
                      Time elapsed: 00:54:14
                               ETA: 00:00:04

################################################################################
                     [1m Learning iteration 1499/1500 [0m                     

                       Computation: 52118 steps/s (collection: 1.791s, learning 0.096s)
             Mean action noise std: 4.43
          Mean value_function loss: 57.5985
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 62.3152
                       Mean reward: 738.35
               Mean episode length: 233.21
    Episode_Reward/reaching_object: 1.0714
    Episode_Reward/rotating_object: 146.3803
        Episode_Reward/action_rate: -0.0992
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 1.89s
                      Time elapsed: 00:54:16
                               ETA: 00:00:02

