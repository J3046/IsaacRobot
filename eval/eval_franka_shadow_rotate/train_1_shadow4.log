################################################################################
                      [1m Learning iteration 0/1500 [0m                       

                       Computation: 22635 steps/s (collection: 4.221s, learning 0.122s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0058
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 36.9340
                       Mean reward: 0.00
               Mean episode length: 21.93
    Episode_Reward/reaching_object: 0.0008
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0003
          Episode_Reward/joint_vel: -0.0004
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 4.34s
                      Time elapsed: 00:00:04
                               ETA: 01:48:34

################################################################################
                      [1m Learning iteration 1/1500 [0m                       

                       Computation: 53733 steps/s (collection: 1.716s, learning 0.113s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0005
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 37.0591
                       Mean reward: 0.00
               Mean episode length: 45.42
    Episode_Reward/reaching_object: 0.0023
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0008
          Episode_Reward/joint_vel: -0.0011
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 1.83s
                      Time elapsed: 00:00:06
                               ETA: 01:17:06

################################################################################
                      [1m Learning iteration 2/1500 [0m                       

                       Computation: 54843 steps/s (collection: 1.673s, learning 0.119s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 37.1349
                       Mean reward: 0.00
               Mean episode length: 69.07
    Episode_Reward/reaching_object: 0.0039
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0013
          Episode_Reward/joint_vel: -0.0018
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 1.79s
                      Time elapsed: 00:00:07
                               ETA: 01:06:17

################################################################################
                      [1m Learning iteration 3/1500 [0m                       

                       Computation: 54918 steps/s (collection: 1.673s, learning 0.117s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0004
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 37.1575
                       Mean reward: 0.01
               Mean episode length: 93.12
    Episode_Reward/reaching_object: 0.0052
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0018
          Episode_Reward/joint_vel: -0.0025
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 1.79s
                      Time elapsed: 00:00:09
                               ETA: 01:00:50

################################################################################
                      [1m Learning iteration 4/1500 [0m                       

                       Computation: 54441 steps/s (collection: 1.689s, learning 0.117s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 37.2013
                       Mean reward: 0.01
               Mean episode length: 117.84
    Episode_Reward/reaching_object: 0.0074
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0023
          Episode_Reward/joint_vel: -0.0032
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 1.81s
                      Time elapsed: 00:00:11
                               ETA: 00:57:38

################################################################################
                      [1m Learning iteration 5/1500 [0m                       

                       Computation: 54641 steps/s (collection: 1.685s, learning 0.115s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 37.2395
                       Mean reward: 0.02
               Mean episode length: 141.19
    Episode_Reward/reaching_object: 0.0090
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0028
          Episode_Reward/joint_vel: -0.0039
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 1.80s
                      Time elapsed: 00:00:13
                               ETA: 00:55:28

################################################################################
                      [1m Learning iteration 6/1500 [0m                       

                       Computation: 55012 steps/s (collection: 1.671s, learning 0.116s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 37.2382
                       Mean reward: 0.02
               Mean episode length: 165.18
    Episode_Reward/reaching_object: 0.0111
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0033
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 1.79s
                      Time elapsed: 00:00:15
                               ETA: 00:53:52

################################################################################
                      [1m Learning iteration 7/1500 [0m                       

                       Computation: 54888 steps/s (collection: 1.677s, learning 0.114s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 37.2339
                       Mean reward: 0.02
               Mean episode length: 189.88
    Episode_Reward/reaching_object: 0.0138
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0039
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 1.79s
                      Time elapsed: 00:00:16
                               ETA: 00:52:40

################################################################################
                      [1m Learning iteration 8/1500 [0m                       

                       Computation: 53988 steps/s (collection: 1.709s, learning 0.112s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 37.2220
                       Mean reward: 0.03
               Mean episode length: 213.51
    Episode_Reward/reaching_object: 0.0156
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 1.82s
                      Time elapsed: 00:00:18
                               ETA: 00:51:49

################################################################################
                      [1m Learning iteration 9/1500 [0m                       

                       Computation: 55763 steps/s (collection: 1.653s, learning 0.110s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 37.2111
                       Mean reward: 0.04
               Mean episode length: 236.90
    Episode_Reward/reaching_object: 0.0188
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 1.76s
                      Time elapsed: 00:00:20
                               ETA: 00:50:59

################################################################################
                      [1m Learning iteration 10/1500 [0m                      

                       Computation: 55996 steps/s (collection: 1.644s, learning 0.111s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 37.2534
                       Mean reward: 0.05
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0226
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 1.76s
                      Time elapsed: 00:00:22
                               ETA: 00:50:17

################################################################################
                      [1m Learning iteration 11/1500 [0m                      

                       Computation: 56234 steps/s (collection: 1.637s, learning 0.111s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 37.2491
                       Mean reward: 0.07
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0248
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 1.75s
                      Time elapsed: 00:00:24
                               ETA: 00:49:41

################################################################################
                      [1m Learning iteration 12/1500 [0m                      

                       Computation: 54530 steps/s (collection: 1.688s, learning 0.115s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 37.3039
                       Mean reward: 0.08
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0291
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 1.80s
                      Time elapsed: 00:00:25
                               ETA: 00:49:16

################################################################################
                      [1m Learning iteration 13/1500 [0m                      

                       Computation: 55902 steps/s (collection: 1.648s, learning 0.111s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 37.3466
                       Mean reward: 0.12
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0341
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 1.76s
                      Time elapsed: 00:00:27
                               ETA: 00:48:50

################################################################################
                      [1m Learning iteration 14/1500 [0m                      

                       Computation: 56032 steps/s (collection: 1.643s, learning 0.111s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 37.4014
                       Mean reward: 0.16
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0434
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 1.75s
                      Time elapsed: 00:00:29
                               ETA: 00:48:26

################################################################################
                      [1m Learning iteration 15/1500 [0m                      

                       Computation: 56131 steps/s (collection: 1.638s, learning 0.113s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0004
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 37.4525
                       Mean reward: 0.27
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0566
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 1.75s
                      Time elapsed: 00:00:31
                               ETA: 00:48:05

################################################################################
                      [1m Learning iteration 16/1500 [0m                      

                       Computation: 55464 steps/s (collection: 1.662s, learning 0.110s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0006
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 37.5159
                       Mean reward: 0.35
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0759
    Episode_Reward/rotating_object: 0.0001
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 1.77s
                      Time elapsed: 00:00:32
                               ETA: 00:47:48

################################################################################
                      [1m Learning iteration 17/1500 [0m                      

                       Computation: 55437 steps/s (collection: 1.661s, learning 0.112s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0009
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 37.5919
                       Mean reward: 0.52
               Mean episode length: 249.80
    Episode_Reward/reaching_object: 0.0993
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 1.77s
                      Time elapsed: 00:00:34
                               ETA: 00:47:33

################################################################################
                      [1m Learning iteration 18/1500 [0m                      

                       Computation: 53395 steps/s (collection: 1.731s, learning 0.110s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0014
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 37.6435
                       Mean reward: 0.52
               Mean episode length: 249.38
    Episode_Reward/reaching_object: 0.1111
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 1.84s
                      Time elapsed: 00:00:36
                               ETA: 00:47:25

################################################################################
                      [1m Learning iteration 19/1500 [0m                      

                       Computation: 50571 steps/s (collection: 1.833s, learning 0.111s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0021
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 37.7119
                       Mean reward: 0.71
               Mean episode length: 249.42
    Episode_Reward/reaching_object: 0.1526
    Episode_Reward/rotating_object: 0.0001
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 1.94s
                      Time elapsed: 00:00:38
                               ETA: 00:47:25

################################################################################
                      [1m Learning iteration 20/1500 [0m                      

                       Computation: 50283 steps/s (collection: 1.828s, learning 0.127s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0026
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 37.7635
                       Mean reward: 0.96
               Mean episode length: 249.58
    Episode_Reward/reaching_object: 0.1863
    Episode_Reward/rotating_object: 0.0003
        Episode_Reward/action_rate: -0.0055
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 1.95s
                      Time elapsed: 00:00:40
                               ETA: 00:47:25

################################################################################
                      [1m Learning iteration 21/1500 [0m                      

                       Computation: 49253 steps/s (collection: 1.882s, learning 0.114s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0054
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 37.8614
                       Mean reward: 1.20
               Mean episode length: 247.00
    Episode_Reward/reaching_object: 0.2301
    Episode_Reward/rotating_object: 0.0025
        Episode_Reward/action_rate: -0.0055
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 2.00s
                      Time elapsed: 00:00:42
                               ETA: 00:47:28

################################################################################
                      [1m Learning iteration 22/1500 [0m                      

                       Computation: 49500 steps/s (collection: 1.873s, learning 0.112s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0133
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 37.9129
                       Mean reward: 1.54
               Mean episode length: 245.86
    Episode_Reward/reaching_object: 0.2913
    Episode_Reward/rotating_object: 0.0054
        Episode_Reward/action_rate: -0.0055
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 1.99s
                      Time elapsed: 00:00:44
                               ETA: 00:47:30

################################################################################
                      [1m Learning iteration 23/1500 [0m                      

                       Computation: 48897 steps/s (collection: 1.900s, learning 0.111s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0127
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 37.9695
                       Mean reward: 1.63
               Mean episode length: 240.84
    Episode_Reward/reaching_object: 0.3185
    Episode_Reward/rotating_object: 0.0043
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 2.01s
                      Time elapsed: 00:00:46
                               ETA: 00:47:33

################################################################################
                      [1m Learning iteration 24/1500 [0m                      

                       Computation: 48546 steps/s (collection: 1.912s, learning 0.113s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0197
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 38.0023
                       Mean reward: 1.85
               Mean episode length: 238.69
    Episode_Reward/reaching_object: 0.3575
    Episode_Reward/rotating_object: 0.0095
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 2.02s
                      Time elapsed: 00:00:48
                               ETA: 00:47:37

################################################################################
                      [1m Learning iteration 25/1500 [0m                      

                       Computation: 48457 steps/s (collection: 1.915s, learning 0.113s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0117
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 38.0674
                       Mean reward: 1.92
               Mean episode length: 232.58
    Episode_Reward/reaching_object: 0.3873
    Episode_Reward/rotating_object: 0.0132
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 9.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.4167
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 2.03s
                      Time elapsed: 00:00:50
                               ETA: 00:47:40

################################################################################
                      [1m Learning iteration 26/1500 [0m                      

                       Computation: 47352 steps/s (collection: 1.963s, learning 0.113s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0113
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 38.1245
                       Mean reward: 2.02
               Mean episode length: 230.72
    Episode_Reward/reaching_object: 0.4131
    Episode_Reward/rotating_object: 0.0152
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 7.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 2.08s
                      Time elapsed: 00:00:52
                               ETA: 00:47:46

################################################################################
                      [1m Learning iteration 27/1500 [0m                      

                       Computation: 47318 steps/s (collection: 1.961s, learning 0.116s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0146
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 38.1750
                       Mean reward: 2.40
               Mean episode length: 225.59
    Episode_Reward/reaching_object: 0.4354
    Episode_Reward/rotating_object: 0.0202
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 7.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 2.08s
                      Time elapsed: 00:00:54
                               ETA: 00:47:51

################################################################################
                      [1m Learning iteration 28/1500 [0m                      

                       Computation: 46686 steps/s (collection: 1.977s, learning 0.128s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0180
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 38.2595
                       Mean reward: 2.52
               Mean episode length: 215.92
    Episode_Reward/reaching_object: 0.4606
    Episode_Reward/rotating_object: 0.0274
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 4.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 2.11s
                      Time elapsed: 00:00:56
                               ETA: 00:47:57

################################################################################
                      [1m Learning iteration 29/1500 [0m                      

                       Computation: 46322 steps/s (collection: 1.994s, learning 0.128s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0752
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 38.3577
                       Mean reward: 2.28
               Mean episode length: 211.57
    Episode_Reward/reaching_object: 0.4743
    Episode_Reward/rotating_object: 0.0275
        Episode_Reward/action_rate: -0.0050
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 4.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 2.12s
                      Time elapsed: 00:00:58
                               ETA: 00:48:03

################################################################################
                      [1m Learning iteration 30/1500 [0m                      

                       Computation: 42795 steps/s (collection: 2.172s, learning 0.125s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.2453
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 38.4474
                       Mean reward: 2.44
               Mean episode length: 206.27
    Episode_Reward/reaching_object: 0.5124
    Episode_Reward/rotating_object: 0.0559
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 3.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 2.30s
                      Time elapsed: 00:01:01
                               ETA: 00:48:17

################################################################################
                      [1m Learning iteration 31/1500 [0m                      

                       Computation: 45454 steps/s (collection: 2.047s, learning 0.115s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.1852
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 38.5055
                       Mean reward: 2.85
               Mean episode length: 209.22
    Episode_Reward/reaching_object: 0.5298
    Episode_Reward/rotating_object: 0.0480
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 3.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 2.16s
                      Time elapsed: 00:01:03
                               ETA: 00:48:24

################################################################################
                      [1m Learning iteration 32/1500 [0m                      

                       Computation: 45121 steps/s (collection: 2.066s, learning 0.112s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.2342
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 38.6802
                       Mean reward: 2.91
               Mean episode length: 200.67
    Episode_Reward/reaching_object: 0.5187
    Episode_Reward/rotating_object: 0.0847
        Episode_Reward/action_rate: -0.0047
          Episode_Reward/joint_vel: -0.0073
      Episode_Termination/time_out: 3.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 2.18s
                      Time elapsed: 00:01:05
                               ETA: 00:48:31

################################################################################
                      [1m Learning iteration 33/1500 [0m                      

                       Computation: 44814 steps/s (collection: 2.081s, learning 0.113s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.3379
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 38.8251
                       Mean reward: 3.32
               Mean episode length: 205.31
    Episode_Reward/reaching_object: 0.5698
    Episode_Reward/rotating_object: 0.1994
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 4.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 2.19s
                      Time elapsed: 00:01:07
                               ETA: 00:48:38

################################################################################
                      [1m Learning iteration 34/1500 [0m                      

                       Computation: 46193 steps/s (collection: 2.018s, learning 0.110s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.3011
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 38.9057
                       Mean reward: 4.74
               Mean episode length: 202.20
    Episode_Reward/reaching_object: 0.6007
    Episode_Reward/rotating_object: 0.2124
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 5.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.5417
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 2.13s
                      Time elapsed: 00:01:09
                               ETA: 00:48:42

################################################################################
                      [1m Learning iteration 35/1500 [0m                      

                       Computation: 45904 steps/s (collection: 2.031s, learning 0.110s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.4245
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 39.0642
                       Mean reward: 5.10
               Mean episode length: 204.08
    Episode_Reward/reaching_object: 0.6279
    Episode_Reward/rotating_object: 0.3123
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 6.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 2.14s
                      Time elapsed: 00:01:11
                               ETA: 00:48:46

################################################################################
                      [1m Learning iteration 36/1500 [0m                      

                       Computation: 45500 steps/s (collection: 2.050s, learning 0.111s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.5330
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 39.1915
                       Mean reward: 3.97
               Mean episode length: 212.24
    Episode_Reward/reaching_object: 0.6937
    Episode_Reward/rotating_object: 0.1178
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 7.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.2500
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 2.16s
                      Time elapsed: 00:01:14
                               ETA: 00:48:50

################################################################################
                      [1m Learning iteration 37/1500 [0m                      

                       Computation: 45256 steps/s (collection: 2.059s, learning 0.113s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.5380
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 39.3877
                       Mean reward: 4.87
               Mean episode length: 212.48
    Episode_Reward/reaching_object: 0.7497
    Episode_Reward/rotating_object: 0.2386
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 10.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 2.17s
                      Time elapsed: 00:01:16
                               ETA: 00:48:55

################################################################################
                      [1m Learning iteration 38/1500 [0m                      

                       Computation: 45561 steps/s (collection: 2.047s, learning 0.110s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.7024
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 39.5242
                       Mean reward: 6.51
               Mean episode length: 224.17
    Episode_Reward/reaching_object: 0.7749
    Episode_Reward/rotating_object: 0.3343
        Episode_Reward/action_rate: -0.0055
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 10.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 2.16s
                      Time elapsed: 00:01:18
                               ETA: 00:48:58

################################################################################
                      [1m Learning iteration 39/1500 [0m                      

                       Computation: 45452 steps/s (collection: 2.052s, learning 0.110s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.7011
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 39.6288
                       Mean reward: 6.35
               Mean episode length: 222.65
    Episode_Reward/reaching_object: 0.8116
    Episode_Reward/rotating_object: 0.4724
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 11.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 2.16s
                      Time elapsed: 00:01:20
                               ETA: 00:49:02

################################################################################
                      [1m Learning iteration 40/1500 [0m                      

                       Computation: 44755 steps/s (collection: 2.083s, learning 0.113s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.8007
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 39.7994
                       Mean reward: 5.13
               Mean episode length: 227.39
    Episode_Reward/reaching_object: 0.8486
    Episode_Reward/rotating_object: 0.4960
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 2.20s
                      Time elapsed: 00:01:22
                               ETA: 00:49:06

################################################################################
                      [1m Learning iteration 41/1500 [0m                      

                       Computation: 44066 steps/s (collection: 2.118s, learning 0.113s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.5065
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 39.9074
                       Mean reward: 7.55
               Mean episode length: 226.96
    Episode_Reward/reaching_object: 0.8644
    Episode_Reward/rotating_object: 0.7179
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 2.23s
                      Time elapsed: 00:01:24
                               ETA: 00:49:12

################################################################################
                      [1m Learning iteration 42/1500 [0m                      

                       Computation: 44783 steps/s (collection: 2.084s, learning 0.112s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.7217
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 40.0463
                       Mean reward: 8.03
               Mean episode length: 235.62
    Episode_Reward/reaching_object: 0.9097
    Episode_Reward/rotating_object: 0.6735
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 2.20s
                      Time elapsed: 00:01:27
                               ETA: 00:49:16

################################################################################
                      [1m Learning iteration 43/1500 [0m                      

                       Computation: 44356 steps/s (collection: 2.106s, learning 0.110s)
             Mean action noise std: 1.14
          Mean value_function loss: 0.6539
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 40.1778
                       Mean reward: 8.60
               Mean episode length: 239.25
    Episode_Reward/reaching_object: 0.9554
    Episode_Reward/rotating_object: 0.7787
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 2.22s
                      Time elapsed: 00:01:29
                               ETA: 00:49:20

################################################################################
                      [1m Learning iteration 44/1500 [0m                      

                       Computation: 44518 steps/s (collection: 2.096s, learning 0.112s)
             Mean action noise std: 1.14
          Mean value_function loss: 0.8334
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 40.3088
                       Mean reward: 9.49
               Mean episode length: 236.69
    Episode_Reward/reaching_object: 0.9553
    Episode_Reward/rotating_object: 0.6865
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 2.21s
                      Time elapsed: 00:01:31
                               ETA: 00:49:23

################################################################################
                      [1m Learning iteration 45/1500 [0m                      

                       Computation: 44437 steps/s (collection: 2.101s, learning 0.111s)
             Mean action noise std: 1.15
          Mean value_function loss: 1.1037
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 40.4771
                       Mean reward: 7.82
               Mean episode length: 240.48
    Episode_Reward/reaching_object: 0.9486
    Episode_Reward/rotating_object: 0.5702
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 2.21s
                      Time elapsed: 00:01:33
                               ETA: 00:49:27

################################################################################
                      [1m Learning iteration 46/1500 [0m                      

                       Computation: 44472 steps/s (collection: 2.098s, learning 0.113s)
             Mean action noise std: 1.16
          Mean value_function loss: 1.0635
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 40.5793
                       Mean reward: 6.99
               Mean episode length: 242.65
    Episode_Reward/reaching_object: 0.9237
    Episode_Reward/rotating_object: 0.5188
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 2.21s
                      Time elapsed: 00:01:36
                               ETA: 00:49:30

################################################################################
                      [1m Learning iteration 47/1500 [0m                      

                       Computation: 44649 steps/s (collection: 2.091s, learning 0.111s)
             Mean action noise std: 1.16
          Mean value_function loss: 0.9368
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 40.7551
                       Mean reward: 7.98
               Mean episode length: 241.10
    Episode_Reward/reaching_object: 0.9770
    Episode_Reward/rotating_object: 0.7021
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 2.20s
                      Time elapsed: 00:01:38
                               ETA: 00:49:33

################################################################################
                      [1m Learning iteration 48/1500 [0m                      

                       Computation: 44476 steps/s (collection: 2.089s, learning 0.121s)
             Mean action noise std: 1.17
          Mean value_function loss: 0.9716
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 40.8560
                       Mean reward: 10.92
               Mean episode length: 247.67
    Episode_Reward/reaching_object: 0.9736
    Episode_Reward/rotating_object: 1.0048
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 2.21s
                      Time elapsed: 00:01:40
                               ETA: 00:49:36

################################################################################
                      [1m Learning iteration 49/1500 [0m                      

                       Computation: 44925 steps/s (collection: 2.075s, learning 0.113s)
             Mean action noise std: 1.17
          Mean value_function loss: 0.8758
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 40.9858
                       Mean reward: 11.31
               Mean episode length: 244.94
    Episode_Reward/reaching_object: 0.9741
    Episode_Reward/rotating_object: 0.9640
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 2.19s
                      Time elapsed: 00:01:42
                               ETA: 00:49:38

################################################################################
                      [1m Learning iteration 50/1500 [0m                      

                       Computation: 45029 steps/s (collection: 2.070s, learning 0.113s)
             Mean action noise std: 1.18
          Mean value_function loss: 1.3241
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 41.1090
                       Mean reward: 11.88
               Mean episode length: 249.43
    Episode_Reward/reaching_object: 0.9886
    Episode_Reward/rotating_object: 1.1022
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 2.18s
                      Time elapsed: 00:01:44
                               ETA: 00:49:39

################################################################################
                      [1m Learning iteration 51/1500 [0m                      

                       Computation: 45229 steps/s (collection: 2.060s, learning 0.113s)
             Mean action noise std: 1.18
          Mean value_function loss: 1.2966
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.2135
                       Mean reward: 11.00
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.0302
    Episode_Reward/rotating_object: 1.2230
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 2.17s
                      Time elapsed: 00:01:46
                               ETA: 00:49:41

################################################################################
                      [1m Learning iteration 52/1500 [0m                      

                       Computation: 43624 steps/s (collection: 2.137s, learning 0.116s)
             Mean action noise std: 1.19
          Mean value_function loss: 1.4941
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 41.3373
                       Mean reward: 10.34
               Mean episode length: 248.54
    Episode_Reward/reaching_object: 1.0241
    Episode_Reward/rotating_object: 0.9516
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 2.25s
                      Time elapsed: 00:01:49
                               ETA: 00:49:44

################################################################################
                      [1m Learning iteration 53/1500 [0m                      

                       Computation: 43910 steps/s (collection: 2.128s, learning 0.111s)
             Mean action noise std: 1.20
          Mean value_function loss: 1.7221
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 41.4706
                       Mean reward: 11.61
               Mean episode length: 245.14
    Episode_Reward/reaching_object: 0.9681
    Episode_Reward/rotating_object: 1.0595
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 2.24s
                      Time elapsed: 00:01:51
                               ETA: 00:49:47

################################################################################
                      [1m Learning iteration 54/1500 [0m                      

                       Computation: 45043 steps/s (collection: 2.069s, learning 0.113s)
             Mean action noise std: 1.20
          Mean value_function loss: 1.3275
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 41.5694
                       Mean reward: 10.63
               Mean episode length: 246.22
    Episode_Reward/reaching_object: 0.9889
    Episode_Reward/rotating_object: 1.3382
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 2.18s
                      Time elapsed: 00:01:53
                               ETA: 00:49:48

################################################################################
                      [1m Learning iteration 55/1500 [0m                      

                       Computation: 45133 steps/s (collection: 2.060s, learning 0.118s)
             Mean action noise std: 1.21
          Mean value_function loss: 1.3417
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 41.7156
                       Mean reward: 11.96
               Mean episode length: 246.67
    Episode_Reward/reaching_object: 1.0332
    Episode_Reward/rotating_object: 1.3772
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 2.18s
                      Time elapsed: 00:01:55
                               ETA: 00:49:49

################################################################################
                      [1m Learning iteration 56/1500 [0m                      

                       Computation: 46102 steps/s (collection: 2.019s, learning 0.113s)
             Mean action noise std: 1.21
          Mean value_function loss: 1.4510
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 41.8227
                       Mean reward: 9.73
               Mean episode length: 248.51
    Episode_Reward/reaching_object: 1.0133
    Episode_Reward/rotating_object: 1.0917
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 2.13s
                      Time elapsed: 00:01:57
                               ETA: 00:49:48

################################################################################
                      [1m Learning iteration 57/1500 [0m                      

                       Computation: 46511 steps/s (collection: 2.003s, learning 0.111s)
             Mean action noise std: 1.22
          Mean value_function loss: 1.4648
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 41.9412
                       Mean reward: 11.83
               Mean episode length: 248.34
    Episode_Reward/reaching_object: 1.0463
    Episode_Reward/rotating_object: 1.2541
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 2.11s
                      Time elapsed: 00:02:00
                               ETA: 00:49:47

################################################################################
                      [1m Learning iteration 58/1500 [0m                      

                       Computation: 46464 steps/s (collection: 2.004s, learning 0.111s)
             Mean action noise std: 1.22
          Mean value_function loss: 1.2299
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 41.9932
                       Mean reward: 8.94
               Mean episode length: 247.08
    Episode_Reward/reaching_object: 1.0313
    Episode_Reward/rotating_object: 1.2458
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 2.12s
                      Time elapsed: 00:02:02
                               ETA: 00:49:46

################################################################################
                      [1m Learning iteration 59/1500 [0m                      

                       Computation: 46728 steps/s (collection: 1.989s, learning 0.115s)
             Mean action noise std: 1.22
          Mean value_function loss: 1.6744
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 42.0885
                       Mean reward: 7.66
               Mean episode length: 248.32
    Episode_Reward/reaching_object: 1.0425
    Episode_Reward/rotating_object: 0.7578
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 2.10s
                      Time elapsed: 00:02:04
                               ETA: 00:49:45

################################################################################
                      [1m Learning iteration 60/1500 [0m                      

                       Computation: 46667 steps/s (collection: 1.996s, learning 0.111s)
             Mean action noise std: 1.23
          Mean value_function loss: 1.9687
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.2125
                       Mean reward: 11.69
               Mean episode length: 249.91
    Episode_Reward/reaching_object: 1.0403
    Episode_Reward/rotating_object: 1.6420
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 2.11s
                      Time elapsed: 00:02:06
                               ETA: 00:49:44

################################################################################
                      [1m Learning iteration 61/1500 [0m                      

                       Computation: 46884 steps/s (collection: 1.985s, learning 0.112s)
             Mean action noise std: 1.23
          Mean value_function loss: 2.1278
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.2715
                       Mean reward: 11.18
               Mean episode length: 249.32
    Episode_Reward/reaching_object: 1.0637
    Episode_Reward/rotating_object: 1.3859
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 2.10s
                      Time elapsed: 00:02:08
                               ETA: 00:49:42

################################################################################
                      [1m Learning iteration 62/1500 [0m                      

                       Computation: 46818 steps/s (collection: 1.988s, learning 0.112s)
             Mean action noise std: 1.24
          Mean value_function loss: 1.9753
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.3667
                       Mean reward: 10.87
               Mean episode length: 249.09
    Episode_Reward/reaching_object: 1.0917
    Episode_Reward/rotating_object: 1.2881
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 2.10s
                      Time elapsed: 00:02:10
                               ETA: 00:49:41

################################################################################
                      [1m Learning iteration 63/1500 [0m                      

                       Computation: 45844 steps/s (collection: 2.023s, learning 0.121s)
             Mean action noise std: 1.24
          Mean value_function loss: 2.2868
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.4722
                       Mean reward: 13.72
               Mean episode length: 249.81
    Episode_Reward/reaching_object: 1.0534
    Episode_Reward/rotating_object: 1.2815
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 2.14s
                      Time elapsed: 00:02:12
                               ETA: 00:49:40

################################################################################
                      [1m Learning iteration 64/1500 [0m                      

                       Computation: 45829 steps/s (collection: 2.022s, learning 0.123s)
             Mean action noise std: 1.25
          Mean value_function loss: 1.8908
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.5707
                       Mean reward: 18.42
               Mean episode length: 249.81
    Episode_Reward/reaching_object: 1.0415
    Episode_Reward/rotating_object: 1.9568
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 2.14s
                      Time elapsed: 00:02:14
                               ETA: 00:49:40

################################################################################
                      [1m Learning iteration 65/1500 [0m                      

                       Computation: 45945 steps/s (collection: 2.029s, learning 0.111s)
             Mean action noise std: 1.25
          Mean value_function loss: 2.0189
               Mean surrogate loss: 0.0033
                 Mean entropy loss: 42.6049
                       Mean reward: 13.64
               Mean episode length: 247.14
    Episode_Reward/reaching_object: 1.0189
    Episode_Reward/rotating_object: 1.5877
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 2.14s
                      Time elapsed: 00:02:17
                               ETA: 00:49:39

################################################################################
                      [1m Learning iteration 66/1500 [0m                      

                       Computation: 45947 steps/s (collection: 2.029s, learning 0.111s)
             Mean action noise std: 1.25
          Mean value_function loss: 1.9789
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 42.6133
                       Mean reward: 12.38
               Mean episode length: 248.26
    Episode_Reward/reaching_object: 1.0274
    Episode_Reward/rotating_object: 1.4356
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 2.14s
                      Time elapsed: 00:02:19
                               ETA: 00:49:38

################################################################################
                      [1m Learning iteration 67/1500 [0m                      

                       Computation: 46598 steps/s (collection: 1.996s, learning 0.113s)
             Mean action noise std: 1.25
          Mean value_function loss: 1.7917
               Mean surrogate loss: 0.0071
                 Mean entropy loss: 42.6458
                       Mean reward: 16.63
               Mean episode length: 249.23
    Episode_Reward/reaching_object: 1.0514
    Episode_Reward/rotating_object: 1.5337
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 2.11s
                      Time elapsed: 00:02:21
                               ETA: 00:49:37

################################################################################
                      [1m Learning iteration 68/1500 [0m                      

                       Computation: 46483 steps/s (collection: 2.000s, learning 0.115s)
             Mean action noise std: 1.25
          Mean value_function loss: 1.9399
               Mean surrogate loss: 0.0031
                 Mean entropy loss: 42.6542
                       Mean reward: 13.11
               Mean episode length: 249.42
    Episode_Reward/reaching_object: 1.0581
    Episode_Reward/rotating_object: 1.6185
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 2.11s
                      Time elapsed: 00:02:23
                               ETA: 00:49:36

################################################################################
                      [1m Learning iteration 69/1500 [0m                      

                       Computation: 46563 steps/s (collection: 1.990s, learning 0.122s)
             Mean action noise std: 1.25
          Mean value_function loss: 2.0484
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 42.6658
                       Mean reward: 13.66
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.0508
    Episode_Reward/rotating_object: 1.7102
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 2.11s
                      Time elapsed: 00:02:25
                               ETA: 00:49:34

################################################################################
                      [1m Learning iteration 70/1500 [0m                      

                       Computation: 44705 steps/s (collection: 2.076s, learning 0.123s)
             Mean action noise std: 1.25
          Mean value_function loss: 1.8581
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 42.7387
                       Mean reward: 12.79
               Mean episode length: 248.45
    Episode_Reward/reaching_object: 1.0307
    Episode_Reward/rotating_object: 2.1087
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 2.20s
                      Time elapsed: 00:02:27
                               ETA: 00:49:34

################################################################################
                      [1m Learning iteration 71/1500 [0m                      

                       Computation: 45714 steps/s (collection: 2.037s, learning 0.113s)
             Mean action noise std: 1.26
          Mean value_function loss: 1.6935
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 42.8276
                       Mean reward: 10.24
               Mean episode length: 249.40
    Episode_Reward/reaching_object: 1.0540
    Episode_Reward/rotating_object: 1.4813
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 2.15s
                      Time elapsed: 00:02:29
                               ETA: 00:49:34

################################################################################
                      [1m Learning iteration 72/1500 [0m                      

                       Computation: 45883 steps/s (collection: 2.030s, learning 0.113s)
             Mean action noise std: 1.26
          Mean value_function loss: 1.5459
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 42.9111
                       Mean reward: 16.74
               Mean episode length: 247.24
    Episode_Reward/reaching_object: 1.0264
    Episode_Reward/rotating_object: 1.6774
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 2.14s
                      Time elapsed: 00:02:32
                               ETA: 00:49:33

################################################################################
                      [1m Learning iteration 73/1500 [0m                      

                       Computation: 45609 steps/s (collection: 2.044s, learning 0.112s)
             Mean action noise std: 1.27
          Mean value_function loss: 1.8392
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.9843
                       Mean reward: 7.90
               Mean episode length: 249.36
    Episode_Reward/reaching_object: 1.0447
    Episode_Reward/rotating_object: 1.2093
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 2.16s
                      Time elapsed: 00:02:34
                               ETA: 00:49:32

################################################################################
                      [1m Learning iteration 74/1500 [0m                      

                       Computation: 46450 steps/s (collection: 2.005s, learning 0.111s)
             Mean action noise std: 1.27
          Mean value_function loss: 2.7143
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 43.0521
                       Mean reward: 17.49
               Mean episode length: 248.34
    Episode_Reward/reaching_object: 1.0280
    Episode_Reward/rotating_object: 2.0480
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 2.12s
                      Time elapsed: 00:02:36
                               ETA: 00:49:31

################################################################################
                      [1m Learning iteration 75/1500 [0m                      

                       Computation: 45956 steps/s (collection: 2.029s, learning 0.110s)
             Mean action noise std: 1.27
          Mean value_function loss: 2.7091
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 43.1160
                       Mean reward: 17.58
               Mean episode length: 248.58
    Episode_Reward/reaching_object: 1.0198
    Episode_Reward/rotating_object: 1.6053
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 2.14s
                      Time elapsed: 00:02:38
                               ETA: 00:49:30

################################################################################
                      [1m Learning iteration 76/1500 [0m                      

                       Computation: 45883 steps/s (collection: 2.029s, learning 0.113s)
             Mean action noise std: 1.28
          Mean value_function loss: 2.5441
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 43.2198
                       Mean reward: 20.23
               Mean episode length: 249.98
    Episode_Reward/reaching_object: 1.0232
    Episode_Reward/rotating_object: 2.2175
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 2.14s
                      Time elapsed: 00:02:40
                               ETA: 00:49:29

################################################################################
                      [1m Learning iteration 77/1500 [0m                      

                       Computation: 46602 steps/s (collection: 1.998s, learning 0.111s)
             Mean action noise std: 1.28
          Mean value_function loss: 2.8326
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 43.3121
                       Mean reward: 11.85
               Mean episode length: 249.46
    Episode_Reward/reaching_object: 1.0204
    Episode_Reward/rotating_object: 1.5673
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 2.11s
                      Time elapsed: 00:02:42
                               ETA: 00:49:27

################################################################################
                      [1m Learning iteration 78/1500 [0m                      

                       Computation: 46673 steps/s (collection: 1.996s, learning 0.110s)
             Mean action noise std: 1.29
          Mean value_function loss: 2.9287
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 43.4350
                       Mean reward: 13.14
               Mean episode length: 249.49
    Episode_Reward/reaching_object: 1.0341
    Episode_Reward/rotating_object: 2.0164
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 2.11s
                      Time elapsed: 00:02:44
                               ETA: 00:49:25

################################################################################
                      [1m Learning iteration 79/1500 [0m                      

                       Computation: 47367 steps/s (collection: 1.964s, learning 0.111s)
             Mean action noise std: 1.29
          Mean value_function loss: 3.1428
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 43.5254
                       Mean reward: 20.16
               Mean episode length: 249.58
    Episode_Reward/reaching_object: 1.0360
    Episode_Reward/rotating_object: 2.4824
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 2.08s
                      Time elapsed: 00:02:46
                               ETA: 00:49:23

################################################################################
                      [1m Learning iteration 80/1500 [0m                      

                       Computation: 47587 steps/s (collection: 1.954s, learning 0.111s)
             Mean action noise std: 1.30
          Mean value_function loss: 3.0670
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 43.5901
                       Mean reward: 19.52
               Mean episode length: 248.92
    Episode_Reward/reaching_object: 1.0332
    Episode_Reward/rotating_object: 2.4648
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 2.07s
                      Time elapsed: 00:02:48
                               ETA: 00:49:21

################################################################################
                      [1m Learning iteration 81/1500 [0m                      

                       Computation: 47480 steps/s (collection: 1.958s, learning 0.112s)
             Mean action noise std: 1.30
          Mean value_function loss: 3.3733
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 43.6567
                       Mean reward: 14.10
               Mean episode length: 245.49
    Episode_Reward/reaching_object: 1.0051
    Episode_Reward/rotating_object: 1.6888
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 2.07s
                      Time elapsed: 00:02:50
                               ETA: 00:49:18

################################################################################
                      [1m Learning iteration 82/1500 [0m                      

                       Computation: 47381 steps/s (collection: 1.965s, learning 0.110s)
             Mean action noise std: 1.30
          Mean value_function loss: 4.4178
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.7449
                       Mean reward: 19.47
               Mean episode length: 248.95
    Episode_Reward/reaching_object: 1.0128
    Episode_Reward/rotating_object: 2.4523
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 2.07s
                      Time elapsed: 00:02:53
                               ETA: 00:49:16

################################################################################
                      [1m Learning iteration 83/1500 [0m                      

                       Computation: 47225 steps/s (collection: 1.972s, learning 0.110s)
             Mean action noise std: 1.31
          Mean value_function loss: 3.7387
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 43.8450
                       Mean reward: 15.87
               Mean episode length: 248.42
    Episode_Reward/reaching_object: 1.0268
    Episode_Reward/rotating_object: 2.8451
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 2.08s
                      Time elapsed: 00:02:55
                               ETA: 00:49:14

################################################################################
                      [1m Learning iteration 84/1500 [0m                      

                       Computation: 47263 steps/s (collection: 1.970s, learning 0.110s)
             Mean action noise std: 1.32
          Mean value_function loss: 3.8763
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 43.9640
                       Mean reward: 14.69
               Mean episode length: 248.73
    Episode_Reward/reaching_object: 0.9950
    Episode_Reward/rotating_object: 2.5903
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 2.08s
                      Time elapsed: 00:02:57
                               ETA: 00:49:12

################################################################################
                      [1m Learning iteration 85/1500 [0m                      

                       Computation: 47148 steps/s (collection: 1.972s, learning 0.113s)
             Mean action noise std: 1.32
          Mean value_function loss: 4.7689
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 44.0743
                       Mean reward: 16.39
               Mean episode length: 248.04
    Episode_Reward/reaching_object: 0.9976
    Episode_Reward/rotating_object: 2.3869
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 2.09s
                      Time elapsed: 00:02:59
                               ETA: 00:49:10

################################################################################
                      [1m Learning iteration 86/1500 [0m                      

                       Computation: 45340 steps/s (collection: 2.055s, learning 0.113s)
             Mean action noise std: 1.33
          Mean value_function loss: 4.9031
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.1728
                       Mean reward: 16.94
               Mean episode length: 246.03
    Episode_Reward/reaching_object: 1.0107
    Episode_Reward/rotating_object: 3.0891
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 2.17s
                      Time elapsed: 00:03:01
                               ETA: 00:49:09

################################################################################
                      [1m Learning iteration 87/1500 [0m                      

                       Computation: 43979 steps/s (collection: 2.119s, learning 0.116s)
             Mean action noise std: 1.33
          Mean value_function loss: 4.2715
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 44.2914
                       Mean reward: 21.26
               Mean episode length: 246.11
    Episode_Reward/reaching_object: 1.0129
    Episode_Reward/rotating_object: 3.0529
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 2.24s
                      Time elapsed: 00:03:03
                               ETA: 00:49:09

################################################################################
                      [1m Learning iteration 88/1500 [0m                      

                       Computation: 42974 steps/s (collection: 2.176s, learning 0.112s)
             Mean action noise std: 1.34
          Mean value_function loss: 4.6396
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 44.3718
                       Mean reward: 20.53
               Mean episode length: 244.04
    Episode_Reward/reaching_object: 0.9864
    Episode_Reward/rotating_object: 2.8717
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 2.29s
                      Time elapsed: 00:03:05
                               ETA: 00:49:10

################################################################################
                      [1m Learning iteration 89/1500 [0m                      

                       Computation: 43372 steps/s (collection: 2.153s, learning 0.113s)
             Mean action noise std: 1.34
          Mean value_function loss: 4.8313
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 44.4435
                       Mean reward: 20.01
               Mean episode length: 248.32
    Episode_Reward/reaching_object: 1.0141
    Episode_Reward/rotating_object: 2.8571
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 2.27s
                      Time elapsed: 00:03:08
                               ETA: 00:49:11

################################################################################
                      [1m Learning iteration 90/1500 [0m                      

                       Computation: 43284 steps/s (collection: 2.158s, learning 0.113s)
             Mean action noise std: 1.34
          Mean value_function loss: 4.3247
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 44.5154
                       Mean reward: 17.98
               Mean episode length: 241.60
    Episode_Reward/reaching_object: 0.9938
    Episode_Reward/rotating_object: 3.4710
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 2.27s
                      Time elapsed: 00:03:10
                               ETA: 00:49:12

################################################################################
                      [1m Learning iteration 91/1500 [0m                      

                       Computation: 43211 steps/s (collection: 2.162s, learning 0.113s)
             Mean action noise std: 1.35
          Mean value_function loss: 4.7682
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.5996
                       Mean reward: 17.80
               Mean episode length: 247.63
    Episode_Reward/reaching_object: 0.9824
    Episode_Reward/rotating_object: 2.5825
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 2.27s
                      Time elapsed: 00:03:12
                               ETA: 00:49:12

################################################################################
                      [1m Learning iteration 92/1500 [0m                      

                       Computation: 43440 steps/s (collection: 2.153s, learning 0.110s)
             Mean action noise std: 1.35
          Mean value_function loss: 5.3231
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 44.6581
                       Mean reward: 22.56
               Mean episode length: 247.41
    Episode_Reward/reaching_object: 1.0023
    Episode_Reward/rotating_object: 3.1987
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 2.26s
                      Time elapsed: 00:03:15
                               ETA: 00:49:13

################################################################################
                      [1m Learning iteration 93/1500 [0m                      

                       Computation: 45129 steps/s (collection: 2.063s, learning 0.116s)
             Mean action noise std: 1.35
          Mean value_function loss: 5.0363
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 44.7135
                       Mean reward: 20.78
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 0.9612
    Episode_Reward/rotating_object: 2.8786
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 2.18s
                      Time elapsed: 00:03:17
                               ETA: 00:49:12

################################################################################
                      [1m Learning iteration 94/1500 [0m                      

                       Computation: 46122 steps/s (collection: 2.018s, learning 0.114s)
             Mean action noise std: 1.36
          Mean value_function loss: 5.5735
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.7960
                       Mean reward: 21.54
               Mean episode length: 246.60
    Episode_Reward/reaching_object: 0.9809
    Episode_Reward/rotating_object: 3.1818
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 2.13s
                      Time elapsed: 00:03:19
                               ETA: 00:49:10

################################################################################
                      [1m Learning iteration 95/1500 [0m                      

                       Computation: 46170 steps/s (collection: 2.017s, learning 0.112s)
             Mean action noise std: 1.36
          Mean value_function loss: 5.3480
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 44.8872
                       Mean reward: 24.65
               Mean episode length: 246.02
    Episode_Reward/reaching_object: 0.9682
    Episode_Reward/rotating_object: 2.8830
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 2.13s
                      Time elapsed: 00:03:21
                               ETA: 00:49:09

################################################################################
                      [1m Learning iteration 96/1500 [0m                      

                       Computation: 46176 steps/s (collection: 2.014s, learning 0.115s)
             Mean action noise std: 1.37
          Mean value_function loss: 5.3214
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 44.9737
                       Mean reward: 18.30
               Mean episode length: 245.94
    Episode_Reward/reaching_object: 0.9643
    Episode_Reward/rotating_object: 3.3172
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 2.13s
                      Time elapsed: 00:03:23
                               ETA: 00:49:07

################################################################################
                      [1m Learning iteration 97/1500 [0m                      

                       Computation: 46317 steps/s (collection: 2.009s, learning 0.113s)
             Mean action noise std: 1.37
          Mean value_function loss: 6.1490
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 45.0557
                       Mean reward: 27.77
               Mean episode length: 243.36
    Episode_Reward/reaching_object: 0.9707
    Episode_Reward/rotating_object: 3.7329
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 2.12s
                      Time elapsed: 00:03:25
                               ETA: 00:49:05

################################################################################
                      [1m Learning iteration 98/1500 [0m                      

                       Computation: 46699 steps/s (collection: 1.993s, learning 0.112s)
             Mean action noise std: 1.37
          Mean value_function loss: 6.6286
               Mean surrogate loss: 0.0015
                 Mean entropy loss: 45.1231
                       Mean reward: 18.12
               Mean episode length: 245.37
    Episode_Reward/reaching_object: 0.9296
    Episode_Reward/rotating_object: 2.8859
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 2.11s
                      Time elapsed: 00:03:27
                               ETA: 00:49:03

################################################################################
                      [1m Learning iteration 99/1500 [0m                      

                       Computation: 46086 steps/s (collection: 2.019s, learning 0.115s)
             Mean action noise std: 1.38
          Mean value_function loss: 6.8407
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 45.1664
                       Mean reward: 25.36
               Mean episode length: 246.31
    Episode_Reward/reaching_object: 0.9568
    Episode_Reward/rotating_object: 3.6296
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 2.13s
                      Time elapsed: 00:03:29
                               ETA: 00:49:02

################################################################################
                     [1m Learning iteration 100/1500 [0m                      

                       Computation: 46232 steps/s (collection: 2.013s, learning 0.113s)
             Mean action noise std: 1.38
          Mean value_function loss: 5.8520
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 45.2427
                       Mean reward: 17.95
               Mean episode length: 243.80
    Episode_Reward/reaching_object: 0.9291
    Episode_Reward/rotating_object: 3.5299
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 2.13s
                      Time elapsed: 00:03:32
                               ETA: 00:49:00

################################################################################
                     [1m Learning iteration 101/1500 [0m                      

                       Computation: 47065 steps/s (collection: 1.978s, learning 0.111s)
             Mean action noise std: 1.39
          Mean value_function loss: 5.9181
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 45.3106
                       Mean reward: 16.88
               Mean episode length: 239.09
    Episode_Reward/reaching_object: 0.9486
    Episode_Reward/rotating_object: 3.2249
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 2.09s
                      Time elapsed: 00:03:34
                               ETA: 00:48:58

################################################################################
                     [1m Learning iteration 102/1500 [0m                      

                       Computation: 47394 steps/s (collection: 1.964s, learning 0.110s)
             Mean action noise std: 1.39
          Mean value_function loss: 7.3621
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 45.3933
                       Mean reward: 24.66
               Mean episode length: 242.45
    Episode_Reward/reaching_object: 0.9126
    Episode_Reward/rotating_object: 3.4216
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 2.07s
                      Time elapsed: 00:03:36
                               ETA: 00:48:55

################################################################################
                     [1m Learning iteration 103/1500 [0m                      

                       Computation: 47651 steps/s (collection: 1.953s, learning 0.110s)
             Mean action noise std: 1.39
          Mean value_function loss: 7.6655
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 45.4583
                       Mean reward: 14.96
               Mean episode length: 240.99
    Episode_Reward/reaching_object: 0.9463
    Episode_Reward/rotating_object: 4.0492
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 2.06s
                      Time elapsed: 00:03:38
                               ETA: 00:48:53

################################################################################
                     [1m Learning iteration 104/1500 [0m                      

                       Computation: 46806 steps/s (collection: 1.990s, learning 0.110s)
             Mean action noise std: 1.40
          Mean value_function loss: 8.0150
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 45.5256
                       Mean reward: 27.05
               Mean episode length: 243.74
    Episode_Reward/reaching_object: 0.9022
    Episode_Reward/rotating_object: 3.0985
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 2.10s
                      Time elapsed: 00:03:40
                               ETA: 00:48:50

################################################################################
                     [1m Learning iteration 105/1500 [0m                      

                       Computation: 47461 steps/s (collection: 1.961s, learning 0.110s)
             Mean action noise std: 1.40
          Mean value_function loss: 7.2361
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 45.6087
                       Mean reward: 25.15
               Mean episode length: 245.43
    Episode_Reward/reaching_object: 0.8989
    Episode_Reward/rotating_object: 3.9382
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 2.07s
                      Time elapsed: 00:03:42
                               ETA: 00:48:48

################################################################################
                     [1m Learning iteration 106/1500 [0m                      

                       Computation: 47233 steps/s (collection: 1.971s, learning 0.111s)
             Mean action noise std: 1.41
          Mean value_function loss: 7.3428
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 45.7002
                       Mean reward: 19.18
               Mean episode length: 244.15
    Episode_Reward/reaching_object: 0.8867
    Episode_Reward/rotating_object: 3.2330
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 2.08s
                      Time elapsed: 00:03:44
                               ETA: 00:48:46

################################################################################
                     [1m Learning iteration 107/1500 [0m                      

                       Computation: 46980 steps/s (collection: 1.982s, learning 0.111s)
             Mean action noise std: 1.41
          Mean value_function loss: 7.1334
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 45.7703
                       Mean reward: 26.88
               Mean episode length: 241.09
    Episode_Reward/reaching_object: 0.9208
    Episode_Reward/rotating_object: 4.9172
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 2.09s
                      Time elapsed: 00:03:46
                               ETA: 00:48:43

################################################################################
                     [1m Learning iteration 108/1500 [0m                      

                       Computation: 46136 steps/s (collection: 2.020s, learning 0.110s)
             Mean action noise std: 1.41
          Mean value_function loss: 6.7464
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 45.8354
                       Mean reward: 15.02
               Mean episode length: 233.54
    Episode_Reward/reaching_object: 0.9155
    Episode_Reward/rotating_object: 3.6359
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 2.13s
                      Time elapsed: 00:03:48
                               ETA: 00:48:42

################################################################################
                     [1m Learning iteration 109/1500 [0m                      

                       Computation: 44920 steps/s (collection: 2.074s, learning 0.115s)
             Mean action noise std: 1.42
          Mean value_function loss: 6.4034
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 45.8911
                       Mean reward: 19.73
               Mean episode length: 236.37
    Episode_Reward/reaching_object: 0.9057
    Episode_Reward/rotating_object: 3.6470
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 2.19s
                      Time elapsed: 00:03:51
                               ETA: 00:48:41

################################################################################
                     [1m Learning iteration 110/1500 [0m                      

                       Computation: 45801 steps/s (collection: 2.036s, learning 0.110s)
             Mean action noise std: 1.42
          Mean value_function loss: 6.8779
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 45.9609
                       Mean reward: 20.74
               Mean episode length: 235.75
    Episode_Reward/reaching_object: 0.9004
    Episode_Reward/rotating_object: 2.7175
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 2.15s
                      Time elapsed: 00:03:53
                               ETA: 00:48:39

################################################################################
                     [1m Learning iteration 111/1500 [0m                      

                       Computation: 43651 steps/s (collection: 2.127s, learning 0.125s)
             Mean action noise std: 1.42
          Mean value_function loss: 6.7767
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 46.0303
                       Mean reward: 24.64
               Mean episode length: 240.15
    Episode_Reward/reaching_object: 0.9087
    Episode_Reward/rotating_object: 3.9399
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 2.25s
                      Time elapsed: 00:03:55
                               ETA: 00:48:39

################################################################################
                     [1m Learning iteration 112/1500 [0m                      

                       Computation: 45602 steps/s (collection: 2.044s, learning 0.112s)
             Mean action noise std: 1.43
          Mean value_function loss: 6.6489
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 46.1207
                       Mean reward: 23.98
               Mean episode length: 233.87
    Episode_Reward/reaching_object: 0.8749
    Episode_Reward/rotating_object: 3.1752
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 2.16s
                      Time elapsed: 00:03:57
                               ETA: 00:48:38

################################################################################
                     [1m Learning iteration 113/1500 [0m                      

                       Computation: 45165 steps/s (collection: 2.065s, learning 0.111s)
             Mean action noise std: 1.43
          Mean value_function loss: 8.0886
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 46.1969
                       Mean reward: 21.10
               Mean episode length: 240.91
    Episode_Reward/reaching_object: 0.9163
    Episode_Reward/rotating_object: 3.9088
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 2.18s
                      Time elapsed: 00:03:59
                               ETA: 00:48:36

################################################################################
                     [1m Learning iteration 114/1500 [0m                      

                       Computation: 46074 steps/s (collection: 2.021s, learning 0.113s)
             Mean action noise std: 1.44
          Mean value_function loss: 7.2646
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 46.2592
                       Mean reward: 23.68
               Mean episode length: 236.52
    Episode_Reward/reaching_object: 0.9331
    Episode_Reward/rotating_object: 3.7543
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 2.13s
                      Time elapsed: 00:04:01
                               ETA: 00:48:35

################################################################################
                     [1m Learning iteration 115/1500 [0m                      

                       Computation: 45872 steps/s (collection: 2.031s, learning 0.112s)
             Mean action noise std: 1.44
          Mean value_function loss: 8.3962
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 46.3512
                       Mean reward: 25.90
               Mean episode length: 241.21
    Episode_Reward/reaching_object: 0.9518
    Episode_Reward/rotating_object: 4.3349
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 2.14s
                      Time elapsed: 00:04:04
                               ETA: 00:48:33

################################################################################
                     [1m Learning iteration 116/1500 [0m                      

                       Computation: 45422 steps/s (collection: 2.054s, learning 0.111s)
             Mean action noise std: 1.45
          Mean value_function loss: 7.4772
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 46.4443
                       Mean reward: 21.74
               Mean episode length: 240.50
    Episode_Reward/reaching_object: 0.9121
    Episode_Reward/rotating_object: 4.0936
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 2.16s
                      Time elapsed: 00:04:06
                               ETA: 00:48:32

################################################################################
                     [1m Learning iteration 117/1500 [0m                      

                       Computation: 45856 steps/s (collection: 2.033s, learning 0.111s)
             Mean action noise std: 1.45
          Mean value_function loss: 8.6110
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 46.5419
                       Mean reward: 20.29
               Mean episode length: 241.20
    Episode_Reward/reaching_object: 0.9079
    Episode_Reward/rotating_object: 3.5189
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 2.14s
                      Time elapsed: 00:04:08
                               ETA: 00:48:30

################################################################################
                     [1m Learning iteration 118/1500 [0m                      

                       Computation: 46102 steps/s (collection: 2.020s, learning 0.112s)
             Mean action noise std: 1.46
          Mean value_function loss: 9.0448
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 46.6278
                       Mean reward: 17.15
               Mean episode length: 239.42
    Episode_Reward/reaching_object: 0.8938
    Episode_Reward/rotating_object: 3.5520
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 2.13s
                      Time elapsed: 00:04:10
                               ETA: 00:48:28

################################################################################
                     [1m Learning iteration 119/1500 [0m                      

                       Computation: 45473 steps/s (collection: 2.051s, learning 0.111s)
             Mean action noise std: 1.46
          Mean value_function loss: 8.5964
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 46.7185
                       Mean reward: 16.15
               Mean episode length: 231.31
    Episode_Reward/reaching_object: 0.8910
    Episode_Reward/rotating_object: 4.1652
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 2.16s
                      Time elapsed: 00:04:12
                               ETA: 00:48:27

################################################################################
                     [1m Learning iteration 120/1500 [0m                      

                       Computation: 45105 steps/s (collection: 2.065s, learning 0.114s)
             Mean action noise std: 1.47
          Mean value_function loss: 8.7482
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 46.7948
                       Mean reward: 32.15
               Mean episode length: 237.18
    Episode_Reward/reaching_object: 0.8820
    Episode_Reward/rotating_object: 4.0694
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 2.18s
                      Time elapsed: 00:04:14
                               ETA: 00:48:26

################################################################################
                     [1m Learning iteration 121/1500 [0m                      

                       Computation: 45488 steps/s (collection: 2.050s, learning 0.111s)
             Mean action noise std: 1.47
          Mean value_function loss: 9.4216
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 46.8650
                       Mean reward: 25.42
               Mean episode length: 239.96
    Episode_Reward/reaching_object: 0.9045
    Episode_Reward/rotating_object: 4.3328
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 2.16s
                      Time elapsed: 00:04:16
                               ETA: 00:48:24

################################################################################
                     [1m Learning iteration 122/1500 [0m                      

                       Computation: 45614 steps/s (collection: 2.043s, learning 0.112s)
             Mean action noise std: 1.48
          Mean value_function loss: 9.8607
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 46.9495
                       Mean reward: 26.36
               Mean episode length: 238.38
    Episode_Reward/reaching_object: 0.9099
    Episode_Reward/rotating_object: 4.0961
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 2.16s
                      Time elapsed: 00:04:19
                               ETA: 00:48:22

################################################################################
                     [1m Learning iteration 123/1500 [0m                      

                       Computation: 45953 steps/s (collection: 2.029s, learning 0.110s)
             Mean action noise std: 1.48
          Mean value_function loss: 9.4071
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 47.0220
                       Mean reward: 33.61
               Mean episode length: 242.69
    Episode_Reward/reaching_object: 0.9309
    Episode_Reward/rotating_object: 4.9065
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 2.14s
                      Time elapsed: 00:04:21
                               ETA: 00:48:21

################################################################################
                     [1m Learning iteration 124/1500 [0m                      

                       Computation: 47206 steps/s (collection: 1.972s, learning 0.111s)
             Mean action noise std: 1.48
          Mean value_function loss: 10.2376
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 47.0818
                       Mean reward: 17.20
               Mean episode length: 237.34
    Episode_Reward/reaching_object: 0.8898
    Episode_Reward/rotating_object: 3.1185
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 2.08s
                      Time elapsed: 00:04:23
                               ETA: 00:48:18

################################################################################
                     [1m Learning iteration 125/1500 [0m                      

                       Computation: 47467 steps/s (collection: 1.960s, learning 0.111s)
             Mean action noise std: 1.49
          Mean value_function loss: 11.5671
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 47.1437
                       Mean reward: 20.71
               Mean episode length: 237.62
    Episode_Reward/reaching_object: 0.9026
    Episode_Reward/rotating_object: 4.2679
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 2.07s
                      Time elapsed: 00:04:25
                               ETA: 00:48:16

################################################################################
                     [1m Learning iteration 126/1500 [0m                      

                       Computation: 47060 steps/s (collection: 1.979s, learning 0.110s)
             Mean action noise std: 1.49
          Mean value_function loss: 12.3869
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 47.2048
                       Mean reward: 27.04
               Mean episode length: 244.13
    Episode_Reward/reaching_object: 0.9743
    Episode_Reward/rotating_object: 4.5355
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 2.09s
                      Time elapsed: 00:04:27
                               ETA: 00:48:14

################################################################################
                     [1m Learning iteration 127/1500 [0m                      

                       Computation: 47489 steps/s (collection: 1.960s, learning 0.110s)
             Mean action noise std: 1.49
          Mean value_function loss: 11.4456
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 47.2368
                       Mean reward: 25.80
               Mean episode length: 241.29
    Episode_Reward/reaching_object: 0.9076
    Episode_Reward/rotating_object: 3.9587
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 2.07s
                      Time elapsed: 00:04:29
                               ETA: 00:48:11

################################################################################
                     [1m Learning iteration 128/1500 [0m                      

                       Computation: 46964 steps/s (collection: 1.983s, learning 0.110s)
             Mean action noise std: 1.49
          Mean value_function loss: 11.4017
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 47.2762
                       Mean reward: 23.84
               Mean episode length: 237.19
    Episode_Reward/reaching_object: 0.9347
    Episode_Reward/rotating_object: 5.1707
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 2.09s
                      Time elapsed: 00:04:31
                               ETA: 00:48:09

################################################################################
                     [1m Learning iteration 129/1500 [0m                      

                       Computation: 47589 steps/s (collection: 1.955s, learning 0.110s)
             Mean action noise std: 1.50
          Mean value_function loss: 11.5957
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 47.3322
                       Mean reward: 36.19
               Mean episode length: 239.41
    Episode_Reward/reaching_object: 0.9148
    Episode_Reward/rotating_object: 4.8624
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 2.07s
                      Time elapsed: 00:04:33
                               ETA: 00:48:06

################################################################################
                     [1m Learning iteration 130/1500 [0m                      

                       Computation: 47400 steps/s (collection: 1.964s, learning 0.110s)
             Mean action noise std: 1.50
          Mean value_function loss: 9.9554
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 47.4000
                       Mean reward: 24.72
               Mean episode length: 228.81
    Episode_Reward/reaching_object: 0.8960
    Episode_Reward/rotating_object: 4.0679
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 2.07s
                      Time elapsed: 00:04:35
                               ETA: 00:48:04

################################################################################
                     [1m Learning iteration 131/1500 [0m                      

                       Computation: 46460 steps/s (collection: 2.002s, learning 0.113s)
             Mean action noise std: 1.51
          Mean value_function loss: 9.5964
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 47.4832
                       Mean reward: 36.90
               Mean episode length: 238.27
    Episode_Reward/reaching_object: 0.9323
    Episode_Reward/rotating_object: 5.7114
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 2.12s
                      Time elapsed: 00:04:37
                               ETA: 00:48:02

################################################################################
                     [1m Learning iteration 132/1500 [0m                      

                       Computation: 46309 steps/s (collection: 2.010s, learning 0.113s)
             Mean action noise std: 1.51
          Mean value_function loss: 11.1148
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 47.5376
                       Mean reward: 21.74
               Mean episode length: 237.51
    Episode_Reward/reaching_object: 0.9049
    Episode_Reward/rotating_object: 4.6562
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 2.12s
                      Time elapsed: 00:04:40
                               ETA: 00:48:00

################################################################################
                     [1m Learning iteration 133/1500 [0m                      

                       Computation: 46543 steps/s (collection: 1.999s, learning 0.113s)
             Mean action noise std: 1.51
          Mean value_function loss: 12.9547
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 47.5882
                       Mean reward: 27.37
               Mean episode length: 239.88
    Episode_Reward/reaching_object: 0.8887
    Episode_Reward/rotating_object: 4.4872
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 2.11s
                      Time elapsed: 00:04:42
                               ETA: 00:47:58

################################################################################
                     [1m Learning iteration 134/1500 [0m                      

                       Computation: 46324 steps/s (collection: 2.011s, learning 0.111s)
             Mean action noise std: 1.52
          Mean value_function loss: 12.0145
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 47.6575
                       Mean reward: 24.63
               Mean episode length: 237.88
    Episode_Reward/reaching_object: 0.9051
    Episode_Reward/rotating_object: 5.2026
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 2.12s
                      Time elapsed: 00:04:44
                               ETA: 00:47:56

################################################################################
                     [1m Learning iteration 135/1500 [0m                      

                       Computation: 46297 steps/s (collection: 2.010s, learning 0.113s)
             Mean action noise std: 1.52
          Mean value_function loss: 11.8658
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 47.7312
                       Mean reward: 25.17
               Mean episode length: 241.61
    Episode_Reward/reaching_object: 0.8791
    Episode_Reward/rotating_object: 4.3073
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 2.12s
                      Time elapsed: 00:04:46
                               ETA: 00:47:54

################################################################################
                     [1m Learning iteration 136/1500 [0m                      

                       Computation: 46968 steps/s (collection: 1.983s, learning 0.110s)
             Mean action noise std: 1.52
          Mean value_function loss: 13.6799
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 47.7861
                       Mean reward: 25.44
               Mean episode length: 240.50
    Episode_Reward/reaching_object: 0.8741
    Episode_Reward/rotating_object: 4.4858
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 2.09s
                      Time elapsed: 00:04:48
                               ETA: 00:47:52

################################################################################
                     [1m Learning iteration 137/1500 [0m                      

                       Computation: 46782 steps/s (collection: 1.989s, learning 0.113s)
             Mean action noise std: 1.53
          Mean value_function loss: 12.5922
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 47.8465
                       Mean reward: 37.73
               Mean episode length: 240.65
    Episode_Reward/reaching_object: 0.8888
    Episode_Reward/rotating_object: 5.0952
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 2.10s
                      Time elapsed: 00:04:50
                               ETA: 00:47:50

################################################################################
                     [1m Learning iteration 138/1500 [0m                      

                       Computation: 46365 steps/s (collection: 2.007s, learning 0.113s)
             Mean action noise std: 1.53
          Mean value_function loss: 11.2781
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 47.9042
                       Mean reward: 31.46
               Mean episode length: 240.46
    Episode_Reward/reaching_object: 0.9250
    Episode_Reward/rotating_object: 5.1685
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 2.12s
                      Time elapsed: 00:04:52
                               ETA: 00:47:48

################################################################################
                     [1m Learning iteration 139/1500 [0m                      

                       Computation: 46575 steps/s (collection: 1.997s, learning 0.113s)
             Mean action noise std: 1.54
          Mean value_function loss: 11.0895
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 47.9738
                       Mean reward: 24.09
               Mean episode length: 239.55
    Episode_Reward/reaching_object: 0.9209
    Episode_Reward/rotating_object: 4.6089
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 2.11s
                      Time elapsed: 00:04:54
                               ETA: 00:47:46

################################################################################
                     [1m Learning iteration 140/1500 [0m                      

                       Computation: 46084 steps/s (collection: 2.020s, learning 0.113s)
             Mean action noise std: 1.54
          Mean value_function loss: 12.5425
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 48.0348
                       Mean reward: 25.58
               Mean episode length: 239.19
    Episode_Reward/reaching_object: 0.9005
    Episode_Reward/rotating_object: 5.5268
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 2.13s
                      Time elapsed: 00:04:56
                               ETA: 00:47:44

################################################################################
                     [1m Learning iteration 141/1500 [0m                      

                       Computation: 46818 steps/s (collection: 1.988s, learning 0.111s)
             Mean action noise std: 1.54
          Mean value_function loss: 10.3163
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 48.1026
                       Mean reward: 29.38
               Mean episode length: 246.75
    Episode_Reward/reaching_object: 0.9352
    Episode_Reward/rotating_object: 5.4815
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 2.10s
                      Time elapsed: 00:04:59
                               ETA: 00:47:42

################################################################################
                     [1m Learning iteration 142/1500 [0m                      

                       Computation: 46198 steps/s (collection: 2.016s, learning 0.112s)
             Mean action noise std: 1.55
          Mean value_function loss: 10.4304
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 48.1630
                       Mean reward: 26.71
               Mean episode length: 236.67
    Episode_Reward/reaching_object: 0.9166
    Episode_Reward/rotating_object: 4.8205
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 2.13s
                      Time elapsed: 00:05:01
                               ETA: 00:47:40

################################################################################
                     [1m Learning iteration 143/1500 [0m                      

                       Computation: 43583 steps/s (collection: 2.143s, learning 0.112s)
             Mean action noise std: 1.55
          Mean value_function loss: 11.6063
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 48.2088
                       Mean reward: 32.40
               Mean episode length: 244.16
    Episode_Reward/reaching_object: 0.8988
    Episode_Reward/rotating_object: 4.3031
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 2.26s
                      Time elapsed: 00:05:03
                               ETA: 00:47:39

################################################################################
                     [1m Learning iteration 144/1500 [0m                      

                       Computation: 44814 steps/s (collection: 2.083s, learning 0.110s)
             Mean action noise std: 1.55
          Mean value_function loss: 13.3420
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 48.2633
                       Mean reward: 29.41
               Mean episode length: 232.58
    Episode_Reward/reaching_object: 0.8981
    Episode_Reward/rotating_object: 5.5066
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 2.19s
                      Time elapsed: 00:05:05
                               ETA: 00:47:38

################################################################################
                     [1m Learning iteration 145/1500 [0m                      

                       Computation: 46708 steps/s (collection: 1.991s, learning 0.114s)
             Mean action noise std: 1.55
          Mean value_function loss: 11.5656
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 48.3050
                       Mean reward: 27.52
               Mean episode length: 236.21
    Episode_Reward/reaching_object: 0.8786
    Episode_Reward/rotating_object: 4.3104
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 2.10s
                      Time elapsed: 00:05:07
                               ETA: 00:47:36

################################################################################
                     [1m Learning iteration 146/1500 [0m                      

                       Computation: 47526 steps/s (collection: 1.958s, learning 0.110s)
             Mean action noise std: 1.56
          Mean value_function loss: 10.5699
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 48.3540
                       Mean reward: 27.83
               Mean episode length: 243.91
    Episode_Reward/reaching_object: 0.8844
    Episode_Reward/rotating_object: 5.3996
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 2.07s
                      Time elapsed: 00:05:09
                               ETA: 00:47:33

################################################################################
                     [1m Learning iteration 147/1500 [0m                      

                       Computation: 48169 steps/s (collection: 1.930s, learning 0.110s)
             Mean action noise std: 1.56
          Mean value_function loss: 10.5667
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 48.4058
                       Mean reward: 27.71
               Mean episode length: 241.23
    Episode_Reward/reaching_object: 0.8871
    Episode_Reward/rotating_object: 4.5866
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 2.04s
                      Time elapsed: 00:05:11
                               ETA: 00:47:30

################################################################################
                     [1m Learning iteration 148/1500 [0m                      

                       Computation: 48178 steps/s (collection: 1.929s, learning 0.112s)
             Mean action noise std: 1.57
          Mean value_function loss: 12.9340
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 48.4810
                       Mean reward: 32.20
               Mean episode length: 243.52
    Episode_Reward/reaching_object: 0.9233
    Episode_Reward/rotating_object: 5.2581
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 2.04s
                      Time elapsed: 00:05:13
                               ETA: 00:47:28

################################################################################
                     [1m Learning iteration 149/1500 [0m                      

                       Computation: 48051 steps/s (collection: 1.936s, learning 0.110s)
             Mean action noise std: 1.57
          Mean value_function loss: 10.7268
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 48.5438
                       Mean reward: 27.52
               Mean episode length: 239.27
    Episode_Reward/reaching_object: 0.8895
    Episode_Reward/rotating_object: 4.7142
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 2.05s
                      Time elapsed: 00:05:15
                               ETA: 00:47:25

################################################################################
                     [1m Learning iteration 150/1500 [0m                      

                       Computation: 48082 steps/s (collection: 1.933s, learning 0.112s)
             Mean action noise std: 1.57
          Mean value_function loss: 12.5371
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 48.5959
                       Mean reward: 29.13
               Mean episode length: 237.16
    Episode_Reward/reaching_object: 0.9103
    Episode_Reward/rotating_object: 6.2320
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 2.04s
                      Time elapsed: 00:05:17
                               ETA: 00:47:22

################################################################################
                     [1m Learning iteration 151/1500 [0m                      

                       Computation: 48117 steps/s (collection: 1.932s, learning 0.111s)
             Mean action noise std: 1.58
          Mean value_function loss: 12.7095
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 48.6656
                       Mean reward: 26.43
               Mean episode length: 244.86
    Episode_Reward/reaching_object: 0.9027
    Episode_Reward/rotating_object: 5.1323
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 2.04s
                      Time elapsed: 00:05:20
                               ETA: 00:47:20

################################################################################
                     [1m Learning iteration 152/1500 [0m                      

                       Computation: 47747 steps/s (collection: 1.948s, learning 0.110s)
             Mean action noise std: 1.58
          Mean value_function loss: 14.0364
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 48.7184
                       Mean reward: 43.10
               Mean episode length: 241.47
    Episode_Reward/reaching_object: 0.9114
    Episode_Reward/rotating_object: 6.9342
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 2.06s
                      Time elapsed: 00:05:22
                               ETA: 00:47:17

################################################################################
                     [1m Learning iteration 153/1500 [0m                      

                       Computation: 47494 steps/s (collection: 1.959s, learning 0.111s)
             Mean action noise std: 1.58
          Mean value_function loss: 13.1442
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 48.7648
                       Mean reward: 35.05
               Mean episode length: 241.76
    Episode_Reward/reaching_object: 0.8857
    Episode_Reward/rotating_object: 5.7218
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 2.07s
                      Time elapsed: 00:05:24
                               ETA: 00:47:15

################################################################################
                     [1m Learning iteration 154/1500 [0m                      

                       Computation: 46856 steps/s (collection: 1.988s, learning 0.110s)
             Mean action noise std: 1.59
          Mean value_function loss: 16.6440
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 48.8191
                       Mean reward: 33.48
               Mean episode length: 240.14
    Episode_Reward/reaching_object: 0.8928
    Episode_Reward/rotating_object: 4.3567
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 2.10s
                      Time elapsed: 00:05:26
                               ETA: 00:47:13

################################################################################
                     [1m Learning iteration 155/1500 [0m                      

                       Computation: 46953 steps/s (collection: 1.982s, learning 0.112s)
             Mean action noise std: 1.59
          Mean value_function loss: 17.4111
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 48.8793
                       Mean reward: 29.46
               Mean episode length: 236.67
    Episode_Reward/reaching_object: 0.9206
    Episode_Reward/rotating_object: 4.3004
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 2.09s
                      Time elapsed: 00:05:28
                               ETA: 00:47:10

################################################################################
                     [1m Learning iteration 156/1500 [0m                      

                       Computation: 45791 steps/s (collection: 2.036s, learning 0.111s)
             Mean action noise std: 1.59
          Mean value_function loss: 17.0503
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 48.9402
                       Mean reward: 36.24
               Mean episode length: 237.27
    Episode_Reward/reaching_object: 0.9125
    Episode_Reward/rotating_object: 6.0466
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 2.15s
                      Time elapsed: 00:05:30
                               ETA: 00:47:09

################################################################################
                     [1m Learning iteration 157/1500 [0m                      

                       Computation: 46292 steps/s (collection: 2.011s, learning 0.113s)
             Mean action noise std: 1.60
          Mean value_function loss: 17.2797
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 48.9835
                       Mean reward: 29.56
               Mean episode length: 235.51
    Episode_Reward/reaching_object: 0.9074
    Episode_Reward/rotating_object: 4.9379
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 2.12s
                      Time elapsed: 00:05:32
                               ETA: 00:47:07

################################################################################
                     [1m Learning iteration 158/1500 [0m                      

                       Computation: 47120 steps/s (collection: 1.976s, learning 0.110s)
             Mean action noise std: 1.60
          Mean value_function loss: 15.9804
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 49.0312
                       Mean reward: 20.81
               Mean episode length: 234.84
    Episode_Reward/reaching_object: 0.8777
    Episode_Reward/rotating_object: 4.1026
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 2.09s
                      Time elapsed: 00:05:34
                               ETA: 00:47:04

################################################################################
                     [1m Learning iteration 159/1500 [0m                      

                       Computation: 46167 steps/s (collection: 2.015s, learning 0.114s)
             Mean action noise std: 1.60
          Mean value_function loss: 15.3735
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 49.0588
                       Mean reward: 32.06
               Mean episode length: 233.06
    Episode_Reward/reaching_object: 0.9345
    Episode_Reward/rotating_object: 6.4051
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 2.13s
                      Time elapsed: 00:05:36
                               ETA: 00:47:03

################################################################################
                     [1m Learning iteration 160/1500 [0m                      

                       Computation: 46983 steps/s (collection: 1.982s, learning 0.111s)
             Mean action noise std: 1.60
          Mean value_function loss: 18.5113
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 49.1004
                       Mean reward: 32.35
               Mean episode length: 233.63
    Episode_Reward/reaching_object: 0.9133
    Episode_Reward/rotating_object: 6.1248
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 2.09s
                      Time elapsed: 00:05:38
                               ETA: 00:47:00

################################################################################
                     [1m Learning iteration 161/1500 [0m                      

                       Computation: 46467 steps/s (collection: 2.003s, learning 0.113s)
             Mean action noise std: 1.61
          Mean value_function loss: 16.4062
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 49.1477
                       Mean reward: 22.66
               Mean episode length: 228.07
    Episode_Reward/reaching_object: 0.9117
    Episode_Reward/rotating_object: 4.9073
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 2.12s
                      Time elapsed: 00:05:41
                               ETA: 00:46:58

################################################################################
                     [1m Learning iteration 162/1500 [0m                      

                       Computation: 46974 steps/s (collection: 1.982s, learning 0.111s)
             Mean action noise std: 1.61
          Mean value_function loss: 20.0393
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 49.2203
                       Mean reward: 38.20
               Mean episode length: 240.75
    Episode_Reward/reaching_object: 0.9124
    Episode_Reward/rotating_object: 6.0562
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 2.09s
                      Time elapsed: 00:05:43
                               ETA: 00:46:56

################################################################################
                     [1m Learning iteration 163/1500 [0m                      

                       Computation: 46603 steps/s (collection: 1.998s, learning 0.111s)
             Mean action noise std: 1.62
          Mean value_function loss: 18.8772
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 49.2796
                       Mean reward: 30.24
               Mean episode length: 229.54
    Episode_Reward/reaching_object: 0.9084
    Episode_Reward/rotating_object: 7.1722
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 2.11s
                      Time elapsed: 00:05:45
                               ETA: 00:46:54

################################################################################
                     [1m Learning iteration 164/1500 [0m                      

                       Computation: 43880 steps/s (collection: 2.126s, learning 0.115s)
             Mean action noise std: 1.62
          Mean value_function loss: 17.6969
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 49.3389
                       Mean reward: 34.46
               Mean episode length: 241.55
    Episode_Reward/reaching_object: 0.9164
    Episode_Reward/rotating_object: 6.4304
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 2.24s
                      Time elapsed: 00:05:47
                               ETA: 00:46:53

################################################################################
                     [1m Learning iteration 165/1500 [0m                      

                       Computation: 43733 steps/s (collection: 2.136s, learning 0.112s)
             Mean action noise std: 1.62
          Mean value_function loss: 19.8850
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 49.3857
                       Mean reward: 24.60
               Mean episode length: 239.08
    Episode_Reward/reaching_object: 0.8978
    Episode_Reward/rotating_object: 7.1327
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 2.25s
                      Time elapsed: 00:05:49
                               ETA: 00:46:52

################################################################################
                     [1m Learning iteration 166/1500 [0m                      

                       Computation: 43573 steps/s (collection: 2.145s, learning 0.111s)
             Mean action noise std: 1.62
          Mean value_function loss: 21.3448
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 49.4375
                       Mean reward: 40.73
               Mean episode length: 239.41
    Episode_Reward/reaching_object: 0.9103
    Episode_Reward/rotating_object: 6.7287
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 2.26s
                      Time elapsed: 00:05:51
                               ETA: 00:46:51

################################################################################
                     [1m Learning iteration 167/1500 [0m                      

                       Computation: 43792 steps/s (collection: 2.132s, learning 0.112s)
             Mean action noise std: 1.63
          Mean value_function loss: 18.1577
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 49.4744
                       Mean reward: 26.92
               Mean episode length: 241.52
    Episode_Reward/reaching_object: 0.9135
    Episode_Reward/rotating_object: 5.3556
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 2.24s
                      Time elapsed: 00:05:54
                               ETA: 00:46:50

################################################################################
                     [1m Learning iteration 168/1500 [0m                      

                       Computation: 46378 steps/s (collection: 2.007s, learning 0.112s)
             Mean action noise std: 1.63
          Mean value_function loss: 19.8938
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 49.5267
                       Mean reward: 26.25
               Mean episode length: 242.39
    Episode_Reward/reaching_object: 0.8617
    Episode_Reward/rotating_object: 4.9511
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 2.12s
                      Time elapsed: 00:05:56
                               ETA: 00:46:48

################################################################################
                     [1m Learning iteration 169/1500 [0m                      

                       Computation: 46949 steps/s (collection: 1.983s, learning 0.111s)
             Mean action noise std: 1.63
          Mean value_function loss: 24.2480
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 49.5807
                       Mean reward: 42.03
               Mean episode length: 243.52
    Episode_Reward/reaching_object: 0.9190
    Episode_Reward/rotating_object: 7.5535
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 2.09s
                      Time elapsed: 00:05:58
                               ETA: 00:46:46

################################################################################
                     [1m Learning iteration 170/1500 [0m                      

                       Computation: 48216 steps/s (collection: 1.929s, learning 0.110s)
             Mean action noise std: 1.64
          Mean value_function loss: 16.7131
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 49.6370
                       Mean reward: 44.80
               Mean episode length: 241.66
    Episode_Reward/reaching_object: 0.8954
    Episode_Reward/rotating_object: 7.1008
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 2.04s
                      Time elapsed: 00:06:00
                               ETA: 00:46:43

################################################################################
                     [1m Learning iteration 171/1500 [0m                      

                       Computation: 47792 steps/s (collection: 1.943s, learning 0.114s)
             Mean action noise std: 1.64
          Mean value_function loss: 17.2659
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 49.7020
                       Mean reward: 41.43
               Mean episode length: 228.35
    Episode_Reward/reaching_object: 0.8869
    Episode_Reward/rotating_object: 7.3360
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 2.06s
                      Time elapsed: 00:06:02
                               ETA: 00:46:41

################################################################################
                     [1m Learning iteration 172/1500 [0m                      

                       Computation: 47764 steps/s (collection: 1.947s, learning 0.111s)
             Mean action noise std: 1.65
          Mean value_function loss: 21.4524
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 49.7750
                       Mean reward: 40.19
               Mean episode length: 234.59
    Episode_Reward/reaching_object: 0.8765
    Episode_Reward/rotating_object: 7.6674
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 2.06s
                      Time elapsed: 00:06:04
                               ETA: 00:46:38

################################################################################
                     [1m Learning iteration 173/1500 [0m                      

                       Computation: 47504 steps/s (collection: 1.959s, learning 0.110s)
             Mean action noise std: 1.65
          Mean value_function loss: 21.6374
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 49.8408
                       Mean reward: 41.40
               Mean episode length: 237.05
    Episode_Reward/reaching_object: 0.8980
    Episode_Reward/rotating_object: 8.2462
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 2.07s
                      Time elapsed: 00:06:06
                               ETA: 00:46:36

################################################################################
                     [1m Learning iteration 174/1500 [0m                      

                       Computation: 47947 steps/s (collection: 1.940s, learning 0.110s)
             Mean action noise std: 1.66
          Mean value_function loss: 21.2434
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 49.9064
                       Mean reward: 37.86
               Mean episode length: 239.25
    Episode_Reward/reaching_object: 0.8909
    Episode_Reward/rotating_object: 7.9300
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 2.05s
                      Time elapsed: 00:06:08
                               ETA: 00:46:33

################################################################################
                     [1m Learning iteration 175/1500 [0m                      

                       Computation: 47788 steps/s (collection: 1.947s, learning 0.110s)
             Mean action noise std: 1.66
          Mean value_function loss: 21.9589
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 49.9583
                       Mean reward: 36.69
               Mean episode length: 237.39
    Episode_Reward/reaching_object: 0.8707
    Episode_Reward/rotating_object: 7.2056
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 2.06s
                      Time elapsed: 00:06:10
                               ETA: 00:46:31

################################################################################
                     [1m Learning iteration 176/1500 [0m                      

                       Computation: 47745 steps/s (collection: 1.949s, learning 0.110s)
             Mean action noise std: 1.66
          Mean value_function loss: 18.7652
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 50.0092
                       Mean reward: 46.53
               Mean episode length: 244.27
    Episode_Reward/reaching_object: 0.8889
    Episode_Reward/rotating_object: 8.7722
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 2.06s
                      Time elapsed: 00:06:12
                               ETA: 00:46:28

################################################################################
                     [1m Learning iteration 177/1500 [0m                      

                       Computation: 47394 steps/s (collection: 1.959s, learning 0.115s)
             Mean action noise std: 1.67
          Mean value_function loss: 20.5541
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 50.0678
                       Mean reward: 33.10
               Mean episode length: 237.08
    Episode_Reward/reaching_object: 0.8605
    Episode_Reward/rotating_object: 5.8164
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 2.07s
                      Time elapsed: 00:06:14
                               ETA: 00:46:26

################################################################################
                     [1m Learning iteration 178/1500 [0m                      

                       Computation: 47283 steps/s (collection: 1.967s, learning 0.112s)
             Mean action noise std: 1.67
          Mean value_function loss: 20.0565
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 50.1265
                       Mean reward: 41.75
               Mean episode length: 235.39
    Episode_Reward/reaching_object: 0.8965
    Episode_Reward/rotating_object: 8.8789
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 2.08s
                      Time elapsed: 00:06:16
                               ETA: 00:46:24

################################################################################
                     [1m Learning iteration 179/1500 [0m                      

                       Computation: 47099 steps/s (collection: 1.974s, learning 0.113s)
             Mean action noise std: 1.67
          Mean value_function loss: 18.5452
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 50.1861
                       Mean reward: 54.54
               Mean episode length: 236.68
    Episode_Reward/reaching_object: 0.9123
    Episode_Reward/rotating_object: 7.7533
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 2.09s
                      Time elapsed: 00:06:19
                               ETA: 00:46:21

################################################################################
                     [1m Learning iteration 180/1500 [0m                      

                       Computation: 46710 steps/s (collection: 1.989s, learning 0.115s)
             Mean action noise std: 1.68
          Mean value_function loss: 21.6923
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 50.2553
                       Mean reward: 56.31
               Mean episode length: 242.63
    Episode_Reward/reaching_object: 0.9225
    Episode_Reward/rotating_object: 8.2254
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 2.10s
                      Time elapsed: 00:06:21
                               ETA: 00:46:19

################################################################################
                     [1m Learning iteration 181/1500 [0m                      

                       Computation: 46554 steps/s (collection: 2.001s, learning 0.110s)
             Mean action noise std: 1.68
          Mean value_function loss: 19.3842
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 50.3118
                       Mean reward: 58.48
               Mean episode length: 241.18
    Episode_Reward/reaching_object: 0.9094
    Episode_Reward/rotating_object: 8.5950
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 2.11s
                      Time elapsed: 00:06:23
                               ETA: 00:46:17

################################################################################
                     [1m Learning iteration 182/1500 [0m                      

                       Computation: 46776 steps/s (collection: 1.989s, learning 0.113s)
             Mean action noise std: 1.69
          Mean value_function loss: 20.3057
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 50.3644
                       Mean reward: 34.92
               Mean episode length: 243.88
    Episode_Reward/reaching_object: 0.8875
    Episode_Reward/rotating_object: 7.1154
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 2.10s
                      Time elapsed: 00:06:25
                               ETA: 00:46:15

################################################################################
                     [1m Learning iteration 183/1500 [0m                      

                       Computation: 45917 steps/s (collection: 2.013s, learning 0.128s)
             Mean action noise std: 1.69
          Mean value_function loss: 21.8410
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 50.4253
                       Mean reward: 36.80
               Mean episode length: 238.00
    Episode_Reward/reaching_object: 0.8940
    Episode_Reward/rotating_object: 7.8931
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 2.14s
                      Time elapsed: 00:06:27
                               ETA: 00:46:13

################################################################################
                     [1m Learning iteration 184/1500 [0m                      

                       Computation: 45981 steps/s (collection: 2.024s, learning 0.113s)
             Mean action noise std: 1.69
          Mean value_function loss: 20.8719
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 50.4865
                       Mean reward: 49.19
               Mean episode length: 243.48
    Episode_Reward/reaching_object: 0.8714
    Episode_Reward/rotating_object: 7.8910
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 2.14s
                      Time elapsed: 00:06:29
                               ETA: 00:46:11

################################################################################
                     [1m Learning iteration 185/1500 [0m                      

                       Computation: 44955 steps/s (collection: 2.072s, learning 0.114s)
             Mean action noise std: 1.70
          Mean value_function loss: 23.3803
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 50.5373
                       Mean reward: 43.46
               Mean episode length: 237.33
    Episode_Reward/reaching_object: 0.8846
    Episode_Reward/rotating_object: 7.8235
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 2.19s
                      Time elapsed: 00:06:31
                               ETA: 00:46:10

################################################################################
                     [1m Learning iteration 186/1500 [0m                      

                       Computation: 44012 steps/s (collection: 2.123s, learning 0.110s)
             Mean action noise std: 1.70
          Mean value_function loss: 19.3660
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 50.5839
                       Mean reward: 53.05
               Mean episode length: 246.48
    Episode_Reward/reaching_object: 0.8850
    Episode_Reward/rotating_object: 8.9528
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 2.23s
                      Time elapsed: 00:06:34
                               ETA: 00:46:09

################################################################################
                     [1m Learning iteration 187/1500 [0m                      

                       Computation: 44681 steps/s (collection: 2.085s, learning 0.115s)
             Mean action noise std: 1.70
          Mean value_function loss: 22.8349
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 50.6099
                       Mean reward: 36.94
               Mean episode length: 238.72
    Episode_Reward/reaching_object: 0.9090
    Episode_Reward/rotating_object: 7.8779
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 2.20s
                      Time elapsed: 00:06:36
                               ETA: 00:46:07

################################################################################
                     [1m Learning iteration 188/1500 [0m                      

                       Computation: 46594 steps/s (collection: 1.997s, learning 0.113s)
             Mean action noise std: 1.70
          Mean value_function loss: 24.4824
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 50.6469
                       Mean reward: 52.98
               Mean episode length: 236.63
    Episode_Reward/reaching_object: 0.8881
    Episode_Reward/rotating_object: 8.1474
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 2.11s
                      Time elapsed: 00:06:38
                               ETA: 00:46:05

################################################################################
                     [1m Learning iteration 189/1500 [0m                      

                       Computation: 46580 steps/s (collection: 2.000s, learning 0.111s)
             Mean action noise std: 1.71
          Mean value_function loss: 26.0760
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 50.6900
                       Mean reward: 31.28
               Mean episode length: 232.92
    Episode_Reward/reaching_object: 0.8889
    Episode_Reward/rotating_object: 7.6014
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 2.11s
                      Time elapsed: 00:06:40
                               ETA: 00:46:03

################################################################################
                     [1m Learning iteration 190/1500 [0m                      

                       Computation: 45463 steps/s (collection: 2.049s, learning 0.113s)
             Mean action noise std: 1.71
          Mean value_function loss: 26.0145
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 50.7558
                       Mean reward: 52.57
               Mean episode length: 242.72
    Episode_Reward/reaching_object: 0.9325
    Episode_Reward/rotating_object: 8.7671
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 2.16s
                      Time elapsed: 00:06:42
                               ETA: 00:46:01

################################################################################
                     [1m Learning iteration 191/1500 [0m                      

                       Computation: 46620 steps/s (collection: 1.996s, learning 0.113s)
             Mean action noise std: 1.71
          Mean value_function loss: 25.8273
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 50.8100
                       Mean reward: 48.52
               Mean episode length: 239.38
    Episode_Reward/reaching_object: 0.9314
    Episode_Reward/rotating_object: 10.1791
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 2.11s
                      Time elapsed: 00:06:44
                               ETA: 00:45:59

################################################################################
                     [1m Learning iteration 192/1500 [0m                      

                       Computation: 46165 steps/s (collection: 2.019s, learning 0.111s)
             Mean action noise std: 1.72
          Mean value_function loss: 24.6620
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 50.8533
                       Mean reward: 53.56
               Mean episode length: 233.97
    Episode_Reward/reaching_object: 0.9371
    Episode_Reward/rotating_object: 9.8785
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 2.13s
                      Time elapsed: 00:06:46
                               ETA: 00:45:57

################################################################################
                     [1m Learning iteration 193/1500 [0m                      

                       Computation: 47416 steps/s (collection: 1.962s, learning 0.112s)
             Mean action noise std: 1.72
          Mean value_function loss: 28.1127
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 50.9027
                       Mean reward: 37.19
               Mean episode length: 241.42
    Episode_Reward/reaching_object: 0.9329
    Episode_Reward/rotating_object: 8.0227
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 2.07s
                      Time elapsed: 00:06:48
                               ETA: 00:45:55

################################################################################
                     [1m Learning iteration 194/1500 [0m                      

                       Computation: 47173 steps/s (collection: 1.973s, learning 0.111s)
             Mean action noise std: 1.73
          Mean value_function loss: 26.0998
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 50.9601
                       Mean reward: 58.73
               Mean episode length: 245.57
    Episode_Reward/reaching_object: 0.9270
    Episode_Reward/rotating_object: 8.1754
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 2.08s
                      Time elapsed: 00:06:51
                               ETA: 00:45:53

################################################################################
                     [1m Learning iteration 195/1500 [0m                      

                       Computation: 47310 steps/s (collection: 1.967s, learning 0.111s)
             Mean action noise std: 1.73
          Mean value_function loss: 24.5123
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 51.0148
                       Mean reward: 48.13
               Mean episode length: 236.88
    Episode_Reward/reaching_object: 0.9264
    Episode_Reward/rotating_object: 8.9427
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 2.08s
                      Time elapsed: 00:06:53
                               ETA: 00:45:50

################################################################################
                     [1m Learning iteration 196/1500 [0m                      

                       Computation: 47178 steps/s (collection: 1.970s, learning 0.114s)
             Mean action noise std: 1.73
          Mean value_function loss: 24.7748
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 51.0630
                       Mean reward: 51.77
               Mean episode length: 244.98
    Episode_Reward/reaching_object: 0.9189
    Episode_Reward/rotating_object: 9.0936
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 2.08s
                      Time elapsed: 00:06:55
                               ETA: 00:45:48

################################################################################
                     [1m Learning iteration 197/1500 [0m                      

                       Computation: 46856 steps/s (collection: 1.988s, learning 0.110s)
             Mean action noise std: 1.74
          Mean value_function loss: 21.6238
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 51.1230
                       Mean reward: 42.64
               Mean episode length: 235.71
    Episode_Reward/reaching_object: 0.9129
    Episode_Reward/rotating_object: 7.5579
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 2.10s
                      Time elapsed: 00:06:57
                               ETA: 00:45:46

################################################################################
                     [1m Learning iteration 198/1500 [0m                      

                       Computation: 47117 steps/s (collection: 1.976s, learning 0.111s)
             Mean action noise std: 1.74
          Mean value_function loss: 24.7452
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 51.1708
                       Mean reward: 61.89
               Mean episode length: 234.96
    Episode_Reward/reaching_object: 0.9218
    Episode_Reward/rotating_object: 10.6539
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 2.09s
                      Time elapsed: 00:06:59
                               ETA: 00:45:44

################################################################################
                     [1m Learning iteration 199/1500 [0m                      

                       Computation: 47427 steps/s (collection: 1.960s, learning 0.113s)
             Mean action noise std: 1.74
          Mean value_function loss: 22.4780
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 51.2084
                       Mean reward: 53.22
               Mean episode length: 232.63
    Episode_Reward/reaching_object: 0.9072
    Episode_Reward/rotating_object: 8.8899
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 2.07s
                      Time elapsed: 00:07:01
                               ETA: 00:45:41

################################################################################
                     [1m Learning iteration 200/1500 [0m                      

                       Computation: 46584 steps/s (collection: 1.995s, learning 0.115s)
             Mean action noise std: 1.74
          Mean value_function loss: 22.6105
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 51.2535
                       Mean reward: 57.88
               Mean episode length: 236.37
    Episode_Reward/reaching_object: 0.9112
    Episode_Reward/rotating_object: 8.7331
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 2.11s
                      Time elapsed: 00:07:03
                               ETA: 00:45:39

################################################################################
                     [1m Learning iteration 201/1500 [0m                      

                       Computation: 46400 steps/s (collection: 2.006s, learning 0.113s)
             Mean action noise std: 1.75
          Mean value_function loss: 22.9832
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 51.2914
                       Mean reward: 56.13
               Mean episode length: 237.73
    Episode_Reward/reaching_object: 0.8866
    Episode_Reward/rotating_object: 8.7210
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 2.12s
                      Time elapsed: 00:07:05
                               ETA: 00:45:37

################################################################################
                     [1m Learning iteration 202/1500 [0m                      

                       Computation: 46346 steps/s (collection: 2.008s, learning 0.113s)
             Mean action noise std: 1.75
          Mean value_function loss: 22.4419
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 51.3422
                       Mean reward: 69.46
               Mean episode length: 240.21
    Episode_Reward/reaching_object: 0.9254
    Episode_Reward/rotating_object: 10.8404
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 2.12s
                      Time elapsed: 00:07:07
                               ETA: 00:45:35

################################################################################
                     [1m Learning iteration 203/1500 [0m                      

                       Computation: 44959 steps/s (collection: 2.070s, learning 0.117s)
             Mean action noise std: 1.75
          Mean value_function loss: 25.2166
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 51.3869
                       Mean reward: 41.91
               Mean episode length: 240.82
    Episode_Reward/reaching_object: 0.9400
    Episode_Reward/rotating_object: 9.5994
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 2.19s
                      Time elapsed: 00:07:10
                               ETA: 00:45:33

################################################################################
                     [1m Learning iteration 204/1500 [0m                      

                       Computation: 45880 steps/s (collection: 2.030s, learning 0.112s)
             Mean action noise std: 1.76
          Mean value_function loss: 24.8672
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 51.4300
                       Mean reward: 47.38
               Mean episode length: 242.71
    Episode_Reward/reaching_object: 0.9425
    Episode_Reward/rotating_object: 8.5291
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 2.14s
                      Time elapsed: 00:07:12
                               ETA: 00:45:32

################################################################################
                     [1m Learning iteration 205/1500 [0m                      

                       Computation: 46719 steps/s (collection: 1.994s, learning 0.110s)
             Mean action noise std: 1.76
          Mean value_function loss: 24.3291
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 51.4802
                       Mean reward: 57.74
               Mean episode length: 240.28
    Episode_Reward/reaching_object: 0.9388
    Episode_Reward/rotating_object: 10.1201
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 2.10s
                      Time elapsed: 00:07:14
                               ETA: 00:45:29

################################################################################
                     [1m Learning iteration 206/1500 [0m                      

                       Computation: 46057 steps/s (collection: 2.021s, learning 0.113s)
             Mean action noise std: 1.76
          Mean value_function loss: 22.7505
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 51.5249
                       Mean reward: 44.33
               Mean episode length: 237.61
    Episode_Reward/reaching_object: 0.8996
    Episode_Reward/rotating_object: 8.8714
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 2.13s
                      Time elapsed: 00:07:16
                               ETA: 00:45:28

################################################################################
                     [1m Learning iteration 207/1500 [0m                      

                       Computation: 45456 steps/s (collection: 2.050s, learning 0.113s)
             Mean action noise std: 1.77
          Mean value_function loss: 27.4645
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 51.5802
                       Mean reward: 61.32
               Mean episode length: 236.50
    Episode_Reward/reaching_object: 0.9151
    Episode_Reward/rotating_object: 9.5115
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 2.16s
                      Time elapsed: 00:07:18
                               ETA: 00:45:26

################################################################################
                     [1m Learning iteration 208/1500 [0m                      

                       Computation: 46121 steps/s (collection: 2.021s, learning 0.110s)
             Mean action noise std: 1.77
          Mean value_function loss: 25.4555
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 51.6307
                       Mean reward: 46.09
               Mean episode length: 234.76
    Episode_Reward/reaching_object: 0.9324
    Episode_Reward/rotating_object: 8.2409
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 2.13s
                      Time elapsed: 00:07:20
                               ETA: 00:45:24

################################################################################
                     [1m Learning iteration 209/1500 [0m                      

                       Computation: 46070 steps/s (collection: 2.022s, learning 0.112s)
             Mean action noise std: 1.77
          Mean value_function loss: 32.2320
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 51.6832
                       Mean reward: 67.44
               Mean episode length: 242.87
    Episode_Reward/reaching_object: 0.9599
    Episode_Reward/rotating_object: 11.2874
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 2.13s
                      Time elapsed: 00:07:22
                               ETA: 00:45:22

################################################################################
                     [1m Learning iteration 210/1500 [0m                      

                       Computation: 45854 steps/s (collection: 2.030s, learning 0.114s)
             Mean action noise std: 1.78
          Mean value_function loss: 30.4361
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 51.7423
                       Mean reward: 68.65
               Mean episode length: 238.85
    Episode_Reward/reaching_object: 0.9351
    Episode_Reward/rotating_object: 10.9092
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 2.14s
                      Time elapsed: 00:07:24
                               ETA: 00:45:20

################################################################################
                     [1m Learning iteration 211/1500 [0m                      

                       Computation: 45923 steps/s (collection: 2.027s, learning 0.114s)
             Mean action noise std: 1.78
          Mean value_function loss: 28.8378
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 51.7956
                       Mean reward: 57.06
               Mean episode length: 238.75
    Episode_Reward/reaching_object: 0.9532
    Episode_Reward/rotating_object: 11.4960
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 2.14s
                      Time elapsed: 00:07:27
                               ETA: 00:45:18

################################################################################
                     [1m Learning iteration 212/1500 [0m                      

                       Computation: 45936 steps/s (collection: 2.027s, learning 0.113s)
             Mean action noise std: 1.78
          Mean value_function loss: 30.1471
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 51.8333
                       Mean reward: 65.79
               Mean episode length: 235.21
    Episode_Reward/reaching_object: 0.9612
    Episode_Reward/rotating_object: 11.1854
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 2.14s
                      Time elapsed: 00:07:29
                               ETA: 00:45:16

################################################################################
                     [1m Learning iteration 213/1500 [0m                      

                       Computation: 45661 steps/s (collection: 2.039s, learning 0.113s)
             Mean action noise std: 1.79
          Mean value_function loss: 33.9010
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 51.8644
                       Mean reward: 46.77
               Mean episode length: 236.21
    Episode_Reward/reaching_object: 0.9486
    Episode_Reward/rotating_object: 9.0803
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 2.15s
                      Time elapsed: 00:07:31
                               ETA: 00:45:14

################################################################################
                     [1m Learning iteration 214/1500 [0m                      

                       Computation: 46314 steps/s (collection: 2.012s, learning 0.110s)
             Mean action noise std: 1.79
          Mean value_function loss: 34.2478
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 51.9138
                       Mean reward: 52.52
               Mean episode length: 231.57
    Episode_Reward/reaching_object: 0.9561
    Episode_Reward/rotating_object: 11.3915
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 2.12s
                      Time elapsed: 00:07:33
                               ETA: 00:45:12

################################################################################
                     [1m Learning iteration 215/1500 [0m                      

                       Computation: 46855 steps/s (collection: 1.984s, learning 0.114s)
             Mean action noise std: 1.79
          Mean value_function loss: 30.9847
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 51.9600
                       Mean reward: 56.71
               Mean episode length: 239.91
    Episode_Reward/reaching_object: 0.9763
    Episode_Reward/rotating_object: 10.3298
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 2.10s
                      Time elapsed: 00:07:35
                               ETA: 00:45:10

################################################################################
                     [1m Learning iteration 216/1500 [0m                      

                       Computation: 47601 steps/s (collection: 1.955s, learning 0.110s)
             Mean action noise std: 1.80
          Mean value_function loss: 31.0400
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 52.0085
                       Mean reward: 63.91
               Mean episode length: 238.62
    Episode_Reward/reaching_object: 0.9900
    Episode_Reward/rotating_object: 12.5663
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 2.07s
                      Time elapsed: 00:07:37
                               ETA: 00:45:08

################################################################################
                     [1m Learning iteration 217/1500 [0m                      

                       Computation: 47112 steps/s (collection: 1.976s, learning 0.110s)
             Mean action noise std: 1.80
          Mean value_function loss: 32.7478
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 52.0615
                       Mean reward: 88.19
               Mean episode length: 240.15
    Episode_Reward/reaching_object: 0.9990
    Episode_Reward/rotating_object: 14.0141
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 2.09s
                      Time elapsed: 00:07:39
                               ETA: 00:45:05

################################################################################
                     [1m Learning iteration 218/1500 [0m                      

                       Computation: 47156 steps/s (collection: 1.974s, learning 0.111s)
             Mean action noise std: 1.80
          Mean value_function loss: 26.8539
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 52.0996
                       Mean reward: 60.67
               Mean episode length: 224.13
    Episode_Reward/reaching_object: 0.9524
    Episode_Reward/rotating_object: 11.6547
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 2.08s
                      Time elapsed: 00:07:41
                               ETA: 00:45:03

################################################################################
                     [1m Learning iteration 219/1500 [0m                      

                       Computation: 47334 steps/s (collection: 1.966s, learning 0.111s)
             Mean action noise std: 1.80
          Mean value_function loss: 29.5640
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 52.1361
                       Mean reward: 61.60
               Mean episode length: 236.82
    Episode_Reward/reaching_object: 0.9666
    Episode_Reward/rotating_object: 12.4020
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 2.08s
                      Time elapsed: 00:07:43
                               ETA: 00:45:01

################################################################################
                     [1m Learning iteration 220/1500 [0m                      

                       Computation: 47109 steps/s (collection: 1.976s, learning 0.110s)
             Mean action noise std: 1.81
          Mean value_function loss: 31.4119
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 52.1753
                       Mean reward: 75.43
               Mean episode length: 233.99
    Episode_Reward/reaching_object: 0.9771
    Episode_Reward/rotating_object: 12.4958
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 2.09s
                      Time elapsed: 00:07:46
                               ETA: 00:44:59

################################################################################
                     [1m Learning iteration 221/1500 [0m                      

                       Computation: 47536 steps/s (collection: 1.957s, learning 0.111s)
             Mean action noise std: 1.81
          Mean value_function loss: 34.3867
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 52.2172
                       Mean reward: 62.74
               Mean episode length: 237.92
    Episode_Reward/reaching_object: 0.9792
    Episode_Reward/rotating_object: 12.5918
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 2.07s
                      Time elapsed: 00:07:48
                               ETA: 00:44:56

################################################################################
                     [1m Learning iteration 222/1500 [0m                      

                       Computation: 46830 steps/s (collection: 1.985s, learning 0.114s)
             Mean action noise std: 1.81
          Mean value_function loss: 36.0578
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 52.2581
                       Mean reward: 64.88
               Mean episode length: 239.34
    Episode_Reward/reaching_object: 0.9853
    Episode_Reward/rotating_object: 13.6476
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 2.10s
                      Time elapsed: 00:07:50
                               ETA: 00:44:54

################################################################################
                     [1m Learning iteration 223/1500 [0m                      

                       Computation: 46130 steps/s (collection: 2.019s, learning 0.112s)
             Mean action noise std: 1.82
          Mean value_function loss: 37.7598
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 52.2978
                       Mean reward: 66.59
               Mean episode length: 233.94
    Episode_Reward/reaching_object: 1.0160
    Episode_Reward/rotating_object: 13.6139
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 2.13s
                      Time elapsed: 00:07:52
                               ETA: 00:44:52

################################################################################
                     [1m Learning iteration 224/1500 [0m                      

                       Computation: 46401 steps/s (collection: 2.008s, learning 0.110s)
             Mean action noise std: 1.82
          Mean value_function loss: 42.1499
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 52.3385
                       Mean reward: 74.04
               Mean episode length: 225.56
    Episode_Reward/reaching_object: 0.9712
    Episode_Reward/rotating_object: 13.2333
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 2.12s
                      Time elapsed: 00:07:54
                               ETA: 00:44:50

################################################################################
                     [1m Learning iteration 225/1500 [0m                      

                       Computation: 46367 steps/s (collection: 2.009s, learning 0.111s)
             Mean action noise std: 1.82
          Mean value_function loss: 38.5378
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 52.3811
                       Mean reward: 68.91
               Mean episode length: 239.87
    Episode_Reward/reaching_object: 1.0182
    Episode_Reward/rotating_object: 12.9224
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 2.12s
                      Time elapsed: 00:07:56
                               ETA: 00:44:48

################################################################################
                     [1m Learning iteration 226/1500 [0m                      

                       Computation: 46403 steps/s (collection: 2.003s, learning 0.116s)
             Mean action noise std: 1.82
          Mean value_function loss: 37.5615
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 52.4151
                       Mean reward: 72.70
               Mean episode length: 229.55
    Episode_Reward/reaching_object: 1.0029
    Episode_Reward/rotating_object: 13.6437
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 2.12s
                      Time elapsed: 00:07:58
                               ETA: 00:44:46

################################################################################
                     [1m Learning iteration 227/1500 [0m                      

                       Computation: 46263 steps/s (collection: 2.013s, learning 0.112s)
             Mean action noise std: 1.83
          Mean value_function loss: 36.4240
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 52.4423
                       Mean reward: 69.17
               Mean episode length: 232.01
    Episode_Reward/reaching_object: 1.0332
    Episode_Reward/rotating_object: 14.0414
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 2.12s
                      Time elapsed: 00:08:00
                               ETA: 00:44:44

################################################################################
                     [1m Learning iteration 228/1500 [0m                      

                       Computation: 43463 steps/s (collection: 2.151s, learning 0.111s)
             Mean action noise std: 1.83
          Mean value_function loss: 34.0584
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 52.4841
                       Mean reward: 70.61
               Mean episode length: 232.56
    Episode_Reward/reaching_object: 1.0417
    Episode_Reward/rotating_object: 14.3278
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 2.26s
                      Time elapsed: 00:08:03
                               ETA: 00:44:43

################################################################################
                     [1m Learning iteration 229/1500 [0m                      

                       Computation: 43572 steps/s (collection: 2.143s, learning 0.114s)
             Mean action noise std: 1.83
          Mean value_function loss: 40.0435
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 52.5374
                       Mean reward: 79.80
               Mean episode length: 235.16
    Episode_Reward/reaching_object: 1.0237
    Episode_Reward/rotating_object: 14.1830
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 2.26s
                      Time elapsed: 00:08:05
                               ETA: 00:44:41

################################################################################
                     [1m Learning iteration 230/1500 [0m                      

                       Computation: 45172 steps/s (collection: 2.048s, learning 0.129s)
             Mean action noise std: 1.84
          Mean value_function loss: 37.0750
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 52.5762
                       Mean reward: 99.64
               Mean episode length: 235.82
    Episode_Reward/reaching_object: 1.0099
    Episode_Reward/rotating_object: 15.3397
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 2.18s
                      Time elapsed: 00:08:07
                               ETA: 00:44:40

################################################################################
                     [1m Learning iteration 231/1500 [0m                      

                       Computation: 45156 steps/s (collection: 2.065s, learning 0.112s)
             Mean action noise std: 1.84
          Mean value_function loss: 43.4933
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 52.6124
                       Mean reward: 80.27
               Mean episode length: 231.38
    Episode_Reward/reaching_object: 1.0345
    Episode_Reward/rotating_object: 14.4098
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 2.18s
                      Time elapsed: 00:08:09
                               ETA: 00:44:38

################################################################################
                     [1m Learning iteration 232/1500 [0m                      

                       Computation: 45069 steps/s (collection: 2.071s, learning 0.110s)
             Mean action noise std: 1.84
          Mean value_function loss: 41.5339
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 52.6619
                       Mean reward: 85.36
               Mean episode length: 232.79
    Episode_Reward/reaching_object: 1.0372
    Episode_Reward/rotating_object: 15.5057
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 2.18s
                      Time elapsed: 00:08:11
                               ETA: 00:44:36

################################################################################
                     [1m Learning iteration 233/1500 [0m                      

                       Computation: 45970 steps/s (collection: 2.026s, learning 0.113s)
             Mean action noise std: 1.84
          Mean value_function loss: 42.1099
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 52.7013
                       Mean reward: 85.57
               Mean episode length: 234.75
    Episode_Reward/reaching_object: 1.0261
    Episode_Reward/rotating_object: 14.9726
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 2.14s
                      Time elapsed: 00:08:13
                               ETA: 00:44:34

################################################################################
                     [1m Learning iteration 234/1500 [0m                      

                       Computation: 45538 steps/s (collection: 2.045s, learning 0.114s)
             Mean action noise std: 1.85
          Mean value_function loss: 47.6655
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 52.7352
                       Mean reward: 91.85
               Mean episode length: 240.92
    Episode_Reward/reaching_object: 1.0728
    Episode_Reward/rotating_object: 15.9021
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 2.16s
                      Time elapsed: 00:08:16
                               ETA: 00:44:32

################################################################################
                     [1m Learning iteration 235/1500 [0m                      

                       Computation: 44913 steps/s (collection: 2.070s, learning 0.119s)
             Mean action noise std: 1.85
          Mean value_function loss: 45.5218
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 52.7726
                       Mean reward: 104.89
               Mean episode length: 238.79
    Episode_Reward/reaching_object: 1.0813
    Episode_Reward/rotating_object: 17.1904
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 2.19s
                      Time elapsed: 00:08:18
                               ETA: 00:44:31

################################################################################
                     [1m Learning iteration 236/1500 [0m                      

                       Computation: 46146 steps/s (collection: 2.020s, learning 0.111s)
             Mean action noise std: 1.85
          Mean value_function loss: 42.7918
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 52.8129
                       Mean reward: 108.16
               Mean episode length: 236.22
    Episode_Reward/reaching_object: 1.0958
    Episode_Reward/rotating_object: 17.4684
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 2.13s
                      Time elapsed: 00:08:20
                               ETA: 00:44:29

################################################################################
                     [1m Learning iteration 237/1500 [0m                      

                       Computation: 45719 steps/s (collection: 2.040s, learning 0.110s)
             Mean action noise std: 1.86
          Mean value_function loss: 36.9650
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 52.8487
                       Mean reward: 85.49
               Mean episode length: 234.22
    Episode_Reward/reaching_object: 1.0991
    Episode_Reward/rotating_object: 17.7631
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 2.15s
                      Time elapsed: 00:08:22
                               ETA: 00:44:27

################################################################################
                     [1m Learning iteration 238/1500 [0m                      

                       Computation: 46889 steps/s (collection: 1.986s, learning 0.110s)
             Mean action noise std: 1.86
          Mean value_function loss: 39.9154
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 52.8807
                       Mean reward: 98.42
               Mean episode length: 235.21
    Episode_Reward/reaching_object: 1.0900
    Episode_Reward/rotating_object: 19.2448
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 2.10s
                      Time elapsed: 00:08:24
                               ETA: 00:44:25

################################################################################
                     [1m Learning iteration 239/1500 [0m                      

                       Computation: 46358 steps/s (collection: 2.011s, learning 0.110s)
             Mean action noise std: 1.86
          Mean value_function loss: 42.8096
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 52.9166
                       Mean reward: 102.64
               Mean episode length: 228.47
    Episode_Reward/reaching_object: 1.0952
    Episode_Reward/rotating_object: 17.5680
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 2.12s
                      Time elapsed: 00:08:26
                               ETA: 00:44:23

################################################################################
                     [1m Learning iteration 240/1500 [0m                      

                       Computation: 46677 steps/s (collection: 1.996s, learning 0.110s)
             Mean action noise std: 1.86
          Mean value_function loss: 47.3053
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 52.9627
                       Mean reward: 95.36
               Mean episode length: 237.55
    Episode_Reward/reaching_object: 1.0794
    Episode_Reward/rotating_object: 18.3918
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 2.11s
                      Time elapsed: 00:08:28
                               ETA: 00:44:20

################################################################################
                     [1m Learning iteration 241/1500 [0m                      

                       Computation: 46365 steps/s (collection: 2.010s, learning 0.110s)
             Mean action noise std: 1.87
          Mean value_function loss: 42.8991
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 53.0073
                       Mean reward: 101.20
               Mean episode length: 229.54
    Episode_Reward/reaching_object: 1.0703
    Episode_Reward/rotating_object: 16.6125
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 2.12s
                      Time elapsed: 00:08:31
                               ETA: 00:44:18

################################################################################
                     [1m Learning iteration 242/1500 [0m                      

                       Computation: 46918 steps/s (collection: 1.985s, learning 0.110s)
             Mean action noise std: 1.87
          Mean value_function loss: 41.6528
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 53.0468
                       Mean reward: 104.21
               Mean episode length: 238.80
    Episode_Reward/reaching_object: 1.0623
    Episode_Reward/rotating_object: 17.6760
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 2.10s
                      Time elapsed: 00:08:33
                               ETA: 00:44:16

################################################################################
                     [1m Learning iteration 243/1500 [0m                      

                       Computation: 46814 steps/s (collection: 1.989s, learning 0.110s)
             Mean action noise std: 1.87
          Mean value_function loss: 44.2864
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 53.0825
                       Mean reward: 109.18
               Mean episode length: 222.40
    Episode_Reward/reaching_object: 1.0773
    Episode_Reward/rotating_object: 19.0992
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 2.10s
                      Time elapsed: 00:08:35
                               ETA: 00:44:14

################################################################################
                     [1m Learning iteration 244/1500 [0m                      

                       Computation: 46349 steps/s (collection: 2.011s, learning 0.110s)
             Mean action noise std: 1.87
          Mean value_function loss: 50.2952
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 53.1124
                       Mean reward: 83.78
               Mean episode length: 221.34
    Episode_Reward/reaching_object: 1.0772
    Episode_Reward/rotating_object: 19.1865
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 2.12s
                      Time elapsed: 00:08:37
                               ETA: 00:44:12

################################################################################
                     [1m Learning iteration 245/1500 [0m                      

                       Computation: 44676 steps/s (collection: 2.088s, learning 0.113s)
             Mean action noise std: 1.88
          Mean value_function loss: 49.9929
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 53.1399
                       Mean reward: 95.74
               Mean episode length: 231.71
    Episode_Reward/reaching_object: 1.0613
    Episode_Reward/rotating_object: 18.0815
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 2.20s
                      Time elapsed: 00:08:39
                               ETA: 00:44:10

################################################################################
                     [1m Learning iteration 246/1500 [0m                      

                       Computation: 45608 steps/s (collection: 2.042s, learning 0.113s)
             Mean action noise std: 1.88
          Mean value_function loss: 46.7292
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 53.1693
                       Mean reward: 105.29
               Mean episode length: 234.02
    Episode_Reward/reaching_object: 1.1188
    Episode_Reward/rotating_object: 19.7251
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 2.16s
                      Time elapsed: 00:08:41
                               ETA: 00:44:08

################################################################################
                     [1m Learning iteration 247/1500 [0m                      

                       Computation: 45782 steps/s (collection: 2.037s, learning 0.110s)
             Mean action noise std: 1.88
          Mean value_function loss: 51.5205
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 53.2027
                       Mean reward: 112.11
               Mean episode length: 225.32
    Episode_Reward/reaching_object: 1.0817
    Episode_Reward/rotating_object: 19.0002
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 2.15s
                      Time elapsed: 00:08:43
                               ETA: 00:44:06

################################################################################
                     [1m Learning iteration 248/1500 [0m                      

                       Computation: 45534 steps/s (collection: 2.047s, learning 0.112s)
             Mean action noise std: 1.88
          Mean value_function loss: 50.8949
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 53.2446
                       Mean reward: 104.69
               Mean episode length: 227.91
    Episode_Reward/reaching_object: 1.1000
    Episode_Reward/rotating_object: 20.4782
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 2.16s
                      Time elapsed: 00:08:46
                               ETA: 00:44:05

################################################################################
                     [1m Learning iteration 249/1500 [0m                      

                       Computation: 45679 steps/s (collection: 2.042s, learning 0.110s)
             Mean action noise std: 1.89
          Mean value_function loss: 48.4558
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 53.2760
                       Mean reward: 101.45
               Mean episode length: 222.41
    Episode_Reward/reaching_object: 1.0640
    Episode_Reward/rotating_object: 18.4276
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 2.15s
                      Time elapsed: 00:08:48
                               ETA: 00:44:03

################################################################################
                     [1m Learning iteration 250/1500 [0m                      

                       Computation: 45198 steps/s (collection: 2.063s, learning 0.112s)
             Mean action noise std: 1.89
          Mean value_function loss: 47.1381
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.3015
                       Mean reward: 112.11
               Mean episode length: 220.09
    Episode_Reward/reaching_object: 1.0655
    Episode_Reward/rotating_object: 20.6920
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 2.17s
                      Time elapsed: 00:08:50
                               ETA: 00:44:01

################################################################################
                     [1m Learning iteration 251/1500 [0m                      

                       Computation: 43623 steps/s (collection: 2.141s, learning 0.113s)
             Mean action noise std: 1.89
          Mean value_function loss: 47.6177
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.3236
                       Mean reward: 107.63
               Mean episode length: 229.08
    Episode_Reward/reaching_object: 1.0911
    Episode_Reward/rotating_object: 21.4274
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 2.25s
                      Time elapsed: 00:08:52
                               ETA: 00:43:59

################################################################################
                     [1m Learning iteration 252/1500 [0m                      

                       Computation: 45594 steps/s (collection: 2.043s, learning 0.113s)
             Mean action noise std: 1.89
          Mean value_function loss: 45.0183
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 53.3471
                       Mean reward: 106.77
               Mean episode length: 224.95
    Episode_Reward/reaching_object: 1.1011
    Episode_Reward/rotating_object: 22.6962
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 2.16s
                      Time elapsed: 00:08:54
                               ETA: 00:43:57

################################################################################
                     [1m Learning iteration 253/1500 [0m                      

                       Computation: 45390 steps/s (collection: 2.053s, learning 0.112s)
             Mean action noise std: 1.90
          Mean value_function loss: 47.6923
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 53.3808
                       Mean reward: 93.80
               Mean episode length: 230.09
    Episode_Reward/reaching_object: 1.0743
    Episode_Reward/rotating_object: 20.0354
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 2.17s
                      Time elapsed: 00:08:56
                               ETA: 00:43:56

################################################################################
                     [1m Learning iteration 254/1500 [0m                      

                       Computation: 45595 steps/s (collection: 2.045s, learning 0.111s)
             Mean action noise std: 1.90
          Mean value_function loss: 49.2296
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 53.4062
                       Mean reward: 107.97
               Mean episode length: 236.65
    Episode_Reward/reaching_object: 1.1236
    Episode_Reward/rotating_object: 20.3567
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 2.16s
                      Time elapsed: 00:08:59
                               ETA: 00:43:54

################################################################################
                     [1m Learning iteration 255/1500 [0m                      

                       Computation: 45542 steps/s (collection: 2.046s, learning 0.113s)
             Mean action noise std: 1.90
          Mean value_function loss: 51.7693
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 53.4243
                       Mean reward: 133.85
               Mean episode length: 229.23
    Episode_Reward/reaching_object: 1.0954
    Episode_Reward/rotating_object: 25.1638
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 2.16s
                      Time elapsed: 00:09:01
                               ETA: 00:43:52

################################################################################
                     [1m Learning iteration 256/1500 [0m                      

                       Computation: 45107 steps/s (collection: 2.068s, learning 0.111s)
             Mean action noise std: 1.90
          Mean value_function loss: 49.9904
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 53.4430
                       Mean reward: 109.94
               Mean episode length: 226.35
    Episode_Reward/reaching_object: 1.0991
    Episode_Reward/rotating_object: 21.4733
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 2.18s
                      Time elapsed: 00:09:03
                               ETA: 00:43:50

################################################################################
                     [1m Learning iteration 257/1500 [0m                      

                       Computation: 45178 steps/s (collection: 2.065s, learning 0.111s)
             Mean action noise std: 1.90
          Mean value_function loss: 50.0054
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 53.4639
                       Mean reward: 102.12
               Mean episode length: 221.42
    Episode_Reward/reaching_object: 1.1058
    Episode_Reward/rotating_object: 20.1318
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 2.18s
                      Time elapsed: 00:09:05
                               ETA: 00:43:48

################################################################################
                     [1m Learning iteration 258/1500 [0m                      

                       Computation: 45553 steps/s (collection: 2.041s, learning 0.117s)
             Mean action noise std: 1.90
          Mean value_function loss: 46.6754
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 53.4898
                       Mean reward: 115.24
               Mean episode length: 236.09
    Episode_Reward/reaching_object: 1.0982
    Episode_Reward/rotating_object: 23.7471
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 2.16s
                      Time elapsed: 00:09:07
                               ETA: 00:43:46

################################################################################
                     [1m Learning iteration 259/1500 [0m                      

                       Computation: 45157 steps/s (collection: 2.066s, learning 0.111s)
             Mean action noise std: 1.91
          Mean value_function loss: 48.3751
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 53.5180
                       Mean reward: 158.27
               Mean episode length: 230.67
    Episode_Reward/reaching_object: 1.0747
    Episode_Reward/rotating_object: 24.2463
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 2.18s
                      Time elapsed: 00:09:09
                               ETA: 00:43:44

################################################################################
                     [1m Learning iteration 260/1500 [0m                      

                       Computation: 45826 steps/s (collection: 2.034s, learning 0.111s)
             Mean action noise std: 1.91
          Mean value_function loss: 52.3046
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 53.5543
                       Mean reward: 123.90
               Mean episode length: 226.15
    Episode_Reward/reaching_object: 1.1069
    Episode_Reward/rotating_object: 21.9584
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 2.15s
                      Time elapsed: 00:09:12
                               ETA: 00:43:42

################################################################################
                     [1m Learning iteration 261/1500 [0m                      

                       Computation: 46315 steps/s (collection: 2.010s, learning 0.112s)
             Mean action noise std: 1.91
          Mean value_function loss: 51.4639
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 53.5879
                       Mean reward: 119.51
               Mean episode length: 223.94
    Episode_Reward/reaching_object: 1.0943
    Episode_Reward/rotating_object: 23.1236
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 2.12s
                      Time elapsed: 00:09:14
                               ETA: 00:43:40

################################################################################
                     [1m Learning iteration 262/1500 [0m                      

                       Computation: 46231 steps/s (collection: 2.015s, learning 0.111s)
             Mean action noise std: 1.91
          Mean value_function loss: 51.2965
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 53.6182
                       Mean reward: 115.80
               Mean episode length: 225.79
    Episode_Reward/reaching_object: 1.1018
    Episode_Reward/rotating_object: 23.6513
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 2.13s
                      Time elapsed: 00:09:16
                               ETA: 00:43:38

################################################################################
                     [1m Learning iteration 263/1500 [0m                      

                       Computation: 46479 steps/s (collection: 2.004s, learning 0.111s)
             Mean action noise std: 1.92
          Mean value_function loss: 51.3199
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 53.6541
                       Mean reward: 121.03
               Mean episode length: 229.18
    Episode_Reward/reaching_object: 1.1096
    Episode_Reward/rotating_object: 23.2381
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 2.11s
                      Time elapsed: 00:09:18
                               ETA: 00:43:36

################################################################################
                     [1m Learning iteration 264/1500 [0m                      

                       Computation: 45456 steps/s (collection: 2.048s, learning 0.115s)
             Mean action noise std: 1.92
          Mean value_function loss: 45.3999
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 53.6853
                       Mean reward: 115.60
               Mean episode length: 212.04
    Episode_Reward/reaching_object: 1.0886
    Episode_Reward/rotating_object: 22.3403
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 2.16s
                      Time elapsed: 00:09:20
                               ETA: 00:43:34

################################################################################
                     [1m Learning iteration 265/1500 [0m                      

                       Computation: 45335 steps/s (collection: 2.057s, learning 0.111s)
             Mean action noise std: 1.92
          Mean value_function loss: 44.7942
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 53.7165
                       Mean reward: 130.70
               Mean episode length: 224.74
    Episode_Reward/reaching_object: 1.1035
    Episode_Reward/rotating_object: 24.4305
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 2.17s
                      Time elapsed: 00:09:22
                               ETA: 00:43:32

################################################################################
                     [1m Learning iteration 266/1500 [0m                      

                       Computation: 46668 steps/s (collection: 1.995s, learning 0.111s)
             Mean action noise std: 1.92
          Mean value_function loss: 48.8056
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 53.7502
                       Mean reward: 157.25
               Mean episode length: 234.48
    Episode_Reward/reaching_object: 1.1048
    Episode_Reward/rotating_object: 25.8916
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 2.11s
                      Time elapsed: 00:09:24
                               ETA: 00:43:30

################################################################################
                     [1m Learning iteration 267/1500 [0m                      

                       Computation: 45294 steps/s (collection: 2.054s, learning 0.116s)
             Mean action noise std: 1.93
          Mean value_function loss: 52.6232
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 53.7826
                       Mean reward: 156.26
               Mean episode length: 224.24
    Episode_Reward/reaching_object: 1.1138
    Episode_Reward/rotating_object: 25.1250
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 2.17s
                      Time elapsed: 00:09:27
                               ETA: 00:43:28

################################################################################
                     [1m Learning iteration 268/1500 [0m                      

                       Computation: 45028 steps/s (collection: 2.058s, learning 0.125s)
             Mean action noise std: 1.93
          Mean value_function loss: 49.7175
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 53.8175
                       Mean reward: 116.70
               Mean episode length: 224.29
    Episode_Reward/reaching_object: 1.1255
    Episode_Reward/rotating_object: 26.4466
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 2.18s
                      Time elapsed: 00:09:29
                               ETA: 00:43:27

################################################################################
                     [1m Learning iteration 269/1500 [0m                      

                       Computation: 45366 steps/s (collection: 2.056s, learning 0.111s)
             Mean action noise std: 1.93
          Mean value_function loss: 48.8683
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 53.8474
                       Mean reward: 107.83
               Mean episode length: 226.40
    Episode_Reward/reaching_object: 1.1044
    Episode_Reward/rotating_object: 23.7687
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 2.17s
                      Time elapsed: 00:09:31
                               ETA: 00:43:25

################################################################################
                     [1m Learning iteration 270/1500 [0m                      

                       Computation: 45414 steps/s (collection: 2.053s, learning 0.111s)
             Mean action noise std: 1.93
          Mean value_function loss: 46.2546
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 53.8708
                       Mean reward: 127.50
               Mean episode length: 221.49
    Episode_Reward/reaching_object: 1.1289
    Episode_Reward/rotating_object: 25.5115
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 2.16s
                      Time elapsed: 00:09:33
                               ETA: 00:43:23

################################################################################
                     [1m Learning iteration 271/1500 [0m                      

                       Computation: 44421 steps/s (collection: 2.098s, learning 0.115s)
             Mean action noise std: 1.93
          Mean value_function loss: 48.9603
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 53.8984
                       Mean reward: 150.22
               Mean episode length: 228.13
    Episode_Reward/reaching_object: 1.1226
    Episode_Reward/rotating_object: 29.1741
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 2.21s
                      Time elapsed: 00:09:35
                               ETA: 00:43:21

################################################################################
                     [1m Learning iteration 272/1500 [0m                      

                       Computation: 42120 steps/s (collection: 2.205s, learning 0.129s)
             Mean action noise std: 1.94
          Mean value_function loss: 45.2543
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 53.9305
                       Mean reward: 129.80
               Mean episode length: 223.41
    Episode_Reward/reaching_object: 1.1172
    Episode_Reward/rotating_object: 24.9235
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 2.33s
                      Time elapsed: 00:09:38
                               ETA: 00:43:20

################################################################################
                     [1m Learning iteration 273/1500 [0m                      

                       Computation: 45299 steps/s (collection: 2.044s, learning 0.126s)
             Mean action noise std: 1.94
          Mean value_function loss: 48.5523
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 53.9569
                       Mean reward: 140.90
               Mean episode length: 231.21
    Episode_Reward/reaching_object: 1.1422
    Episode_Reward/rotating_object: 24.2385
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 2.17s
                      Time elapsed: 00:09:40
                               ETA: 00:43:18

################################################################################
                     [1m Learning iteration 274/1500 [0m                      

                       Computation: 45486 steps/s (collection: 2.035s, learning 0.126s)
             Mean action noise std: 1.94
          Mean value_function loss: 42.9510
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 53.9777
                       Mean reward: 155.29
               Mean episode length: 227.21
    Episode_Reward/reaching_object: 1.1109
    Episode_Reward/rotating_object: 26.5952
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 2.16s
                      Time elapsed: 00:09:42
                               ETA: 00:43:16

################################################################################
                     [1m Learning iteration 275/1500 [0m                      

                       Computation: 45676 steps/s (collection: 2.035s, learning 0.117s)
             Mean action noise std: 1.94
          Mean value_function loss: 42.6253
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 54.0045
                       Mean reward: 140.15
               Mean episode length: 226.07
    Episode_Reward/reaching_object: 1.0975
    Episode_Reward/rotating_object: 27.0719
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 2.15s
                      Time elapsed: 00:09:44
                               ETA: 00:43:14

################################################################################
                     [1m Learning iteration 276/1500 [0m                      

                       Computation: 45981 steps/s (collection: 2.023s, learning 0.115s)
             Mean action noise std: 1.94
          Mean value_function loss: 41.5665
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 54.0266
                       Mean reward: 170.33
               Mean episode length: 220.37
    Episode_Reward/reaching_object: 1.0900
    Episode_Reward/rotating_object: 26.8315
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 2.14s
                      Time elapsed: 00:09:46
                               ETA: 00:43:12

################################################################################
                     [1m Learning iteration 277/1500 [0m                      

                       Computation: 45288 steps/s (collection: 2.056s, learning 0.115s)
             Mean action noise std: 1.95
          Mean value_function loss: 48.0675
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 54.0501
                       Mean reward: 151.58
               Mean episode length: 231.82
    Episode_Reward/reaching_object: 1.1222
    Episode_Reward/rotating_object: 28.9955
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 2.17s
                      Time elapsed: 00:09:48
                               ETA: 00:43:10

################################################################################
                     [1m Learning iteration 278/1500 [0m                      

                       Computation: 44941 steps/s (collection: 2.071s, learning 0.116s)
             Mean action noise std: 1.95
          Mean value_function loss: 48.1927
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 54.0757
                       Mean reward: 137.74
               Mean episode length: 222.29
    Episode_Reward/reaching_object: 1.0902
    Episode_Reward/rotating_object: 26.4131
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 2.19s
                      Time elapsed: 00:09:51
                               ETA: 00:43:09

################################################################################
                     [1m Learning iteration 279/1500 [0m                      

                       Computation: 43165 steps/s (collection: 2.167s, learning 0.111s)
             Mean action noise std: 1.95
          Mean value_function loss: 45.7184
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 54.1002
                       Mean reward: 144.67
               Mean episode length: 221.28
    Episode_Reward/reaching_object: 1.1269
    Episode_Reward/rotating_object: 28.9099
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 2.28s
                      Time elapsed: 00:09:53
                               ETA: 00:43:07

################################################################################
                     [1m Learning iteration 280/1500 [0m                      

                       Computation: 45210 steps/s (collection: 2.063s, learning 0.111s)
             Mean action noise std: 1.95
          Mean value_function loss: 48.5663
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 54.1265
                       Mean reward: 178.81
               Mean episode length: 223.95
    Episode_Reward/reaching_object: 1.1117
    Episode_Reward/rotating_object: 27.6038
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 2.17s
                      Time elapsed: 00:09:55
                               ETA: 00:43:05

################################################################################
                     [1m Learning iteration 281/1500 [0m                      

                       Computation: 45120 steps/s (collection: 2.066s, learning 0.113s)
             Mean action noise std: 1.95
          Mean value_function loss: 42.2702
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 54.1534
                       Mean reward: 159.19
               Mean episode length: 230.54
    Episode_Reward/reaching_object: 1.1462
    Episode_Reward/rotating_object: 26.3597
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 2.18s
                      Time elapsed: 00:09:57
                               ETA: 00:43:03

################################################################################
                     [1m Learning iteration 282/1500 [0m                      

                       Computation: 45270 steps/s (collection: 2.061s, learning 0.110s)
             Mean action noise std: 1.96
          Mean value_function loss: 50.7376
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 54.1755
                       Mean reward: 150.68
               Mean episode length: 231.68
    Episode_Reward/reaching_object: 1.1275
    Episode_Reward/rotating_object: 27.7443
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 2.17s
                      Time elapsed: 00:09:59
                               ETA: 00:43:01

################################################################################
                     [1m Learning iteration 283/1500 [0m                      

                       Computation: 46744 steps/s (collection: 1.993s, learning 0.110s)
             Mean action noise std: 1.96
          Mean value_function loss: 46.2632
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 54.2029
                       Mean reward: 163.69
               Mean episode length: 223.56
    Episode_Reward/reaching_object: 1.1353
    Episode_Reward/rotating_object: 29.0407
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 2.10s
                      Time elapsed: 00:10:02
                               ETA: 00:42:59

################################################################################
                     [1m Learning iteration 284/1500 [0m                      

                       Computation: 46757 steps/s (collection: 1.992s, learning 0.110s)
             Mean action noise std: 1.96
          Mean value_function loss: 46.7573
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 54.2228
                       Mean reward: 174.45
               Mean episode length: 232.61
    Episode_Reward/reaching_object: 1.1575
    Episode_Reward/rotating_object: 29.3412
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 2.10s
                      Time elapsed: 00:10:04
                               ETA: 00:42:57

################################################################################
                     [1m Learning iteration 285/1500 [0m                      

                       Computation: 46932 steps/s (collection: 1.985s, learning 0.110s)
             Mean action noise std: 1.96
          Mean value_function loss: 46.3235
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 54.2463
                       Mean reward: 174.56
               Mean episode length: 234.34
    Episode_Reward/reaching_object: 1.1423
    Episode_Reward/rotating_object: 28.2264
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 2.09s
                      Time elapsed: 00:10:06
                               ETA: 00:42:55

################################################################################
                     [1m Learning iteration 286/1500 [0m                      

                       Computation: 46811 steps/s (collection: 1.990s, learning 0.110s)
             Mean action noise std: 1.96
          Mean value_function loss: 47.3812
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 54.2699
                       Mean reward: 166.98
               Mean episode length: 220.28
    Episode_Reward/reaching_object: 1.1201
    Episode_Reward/rotating_object: 30.0972
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 2.10s
                      Time elapsed: 00:10:08
                               ETA: 00:42:53

################################################################################
                     [1m Learning iteration 287/1500 [0m                      

                       Computation: 47000 steps/s (collection: 1.981s, learning 0.110s)
             Mean action noise std: 1.96
          Mean value_function loss: 42.2831
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 54.2969
                       Mean reward: 157.74
               Mean episode length: 233.59
    Episode_Reward/reaching_object: 1.1582
    Episode_Reward/rotating_object: 32.9183
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 2.09s
                      Time elapsed: 00:10:10
                               ETA: 00:42:50

################################################################################
                     [1m Learning iteration 288/1500 [0m                      

                       Computation: 46621 steps/s (collection: 1.998s, learning 0.110s)
             Mean action noise std: 1.97
          Mean value_function loss: 39.9311
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 54.3210
                       Mean reward: 162.00
               Mean episode length: 232.78
    Episode_Reward/reaching_object: 1.1550
    Episode_Reward/rotating_object: 30.0294
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 2.11s
                      Time elapsed: 00:10:12
                               ETA: 00:42:48

################################################################################
                     [1m Learning iteration 289/1500 [0m                      

                       Computation: 46137 steps/s (collection: 2.017s, learning 0.114s)
             Mean action noise std: 1.97
          Mean value_function loss: 41.5581
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 54.3422
                       Mean reward: 136.99
               Mean episode length: 222.08
    Episode_Reward/reaching_object: 1.1206
    Episode_Reward/rotating_object: 27.7979
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 2.13s
                      Time elapsed: 00:10:14
                               ETA: 00:42:46

################################################################################
                     [1m Learning iteration 290/1500 [0m                      

                       Computation: 46052 steps/s (collection: 2.022s, learning 0.113s)
             Mean action noise std: 1.97
          Mean value_function loss: 44.6954
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 54.3678
                       Mean reward: 127.66
               Mean episode length: 223.68
    Episode_Reward/reaching_object: 1.1491
    Episode_Reward/rotating_object: 29.0025
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 2.13s
                      Time elapsed: 00:10:16
                               ETA: 00:42:44

################################################################################
                     [1m Learning iteration 291/1500 [0m                      

                       Computation: 45918 steps/s (collection: 2.030s, learning 0.111s)
             Mean action noise std: 1.97
          Mean value_function loss: 43.1057
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 54.3876
                       Mean reward: 163.60
               Mean episode length: 223.22
    Episode_Reward/reaching_object: 1.1443
    Episode_Reward/rotating_object: 32.0894
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 2.14s
                      Time elapsed: 00:10:18
                               ETA: 00:42:42

################################################################################
                     [1m Learning iteration 292/1500 [0m                      

                       Computation: 45191 steps/s (collection: 2.064s, learning 0.111s)
             Mean action noise std: 1.97
          Mean value_function loss: 50.0450
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 54.4029
                       Mean reward: 185.29
               Mean episode length: 231.27
    Episode_Reward/reaching_object: 1.1683
    Episode_Reward/rotating_object: 31.2941
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 2.18s
                      Time elapsed: 00:10:21
                               ETA: 00:42:40

################################################################################
                     [1m Learning iteration 293/1500 [0m                      

                       Computation: 43022 steps/s (collection: 2.173s, learning 0.112s)
             Mean action noise std: 1.97
          Mean value_function loss: 52.4436
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 54.4254
                       Mean reward: 148.43
               Mean episode length: 215.86
    Episode_Reward/reaching_object: 1.0942
    Episode_Reward/rotating_object: 27.8411
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 2.28s
                      Time elapsed: 00:10:23
                               ETA: 00:42:39

################################################################################
                     [1m Learning iteration 294/1500 [0m                      

                       Computation: 42626 steps/s (collection: 2.196s, learning 0.110s)
             Mean action noise std: 1.98
          Mean value_function loss: 44.6044
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 54.4545
                       Mean reward: 157.40
               Mean episode length: 218.90
    Episode_Reward/reaching_object: 1.1458
    Episode_Reward/rotating_object: 33.0491
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 2.31s
                      Time elapsed: 00:10:25
                               ETA: 00:42:37

################################################################################
                     [1m Learning iteration 295/1500 [0m                      

                       Computation: 45837 steps/s (collection: 2.032s, learning 0.113s)
             Mean action noise std: 1.98
          Mean value_function loss: 47.6228
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 54.4874
                       Mean reward: 140.00
               Mean episode length: 230.01
    Episode_Reward/reaching_object: 1.1498
    Episode_Reward/rotating_object: 31.1292
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 2.14s
                      Time elapsed: 00:10:27
                               ETA: 00:42:35

################################################################################
                     [1m Learning iteration 296/1500 [0m                      

                       Computation: 45801 steps/s (collection: 2.033s, learning 0.113s)
             Mean action noise std: 1.98
          Mean value_function loss: 57.1837
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 54.5187
                       Mean reward: 168.09
               Mean episode length: 221.57
    Episode_Reward/reaching_object: 1.1440
    Episode_Reward/rotating_object: 32.2533
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 2.15s
                      Time elapsed: 00:10:29
                               ETA: 00:42:33

################################################################################
                     [1m Learning iteration 297/1500 [0m                      

                       Computation: 46164 steps/s (collection: 2.019s, learning 0.110s)
             Mean action noise std: 1.98
          Mean value_function loss: 53.0101
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 54.5452
                       Mean reward: 141.75
               Mean episode length: 214.62
    Episode_Reward/reaching_object: 1.1562
    Episode_Reward/rotating_object: 28.1280
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 2.13s
                      Time elapsed: 00:10:32
                               ETA: 00:42:31

################################################################################
                     [1m Learning iteration 298/1500 [0m                      

                       Computation: 45470 steps/s (collection: 2.048s, learning 0.114s)
             Mean action noise std: 1.99
          Mean value_function loss: 50.9584
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 54.5697
                       Mean reward: 157.12
               Mean episode length: 234.74
    Episode_Reward/reaching_object: 1.1648
    Episode_Reward/rotating_object: 32.7601
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 2.16s
                      Time elapsed: 00:10:34
                               ETA: 00:42:29

################################################################################
                     [1m Learning iteration 299/1500 [0m                      

                       Computation: 45704 steps/s (collection: 2.040s, learning 0.111s)
             Mean action noise std: 1.99
          Mean value_function loss: 56.0983
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 54.5978
                       Mean reward: 158.20
               Mean episode length: 224.27
    Episode_Reward/reaching_object: 1.1679
    Episode_Reward/rotating_object: 31.9157
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 2.15s
                      Time elapsed: 00:10:36
                               ETA: 00:42:27

################################################################################
                     [1m Learning iteration 300/1500 [0m                      

                       Computation: 45155 steps/s (collection: 2.067s, learning 0.110s)
             Mean action noise std: 1.99
          Mean value_function loss: 53.5704
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 54.6197
                       Mean reward: 188.86
               Mean episode length: 234.52
    Episode_Reward/reaching_object: 1.1882
    Episode_Reward/rotating_object: 32.6230
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 2.18s
                      Time elapsed: 00:10:38
                               ETA: 00:42:25

################################################################################
                     [1m Learning iteration 301/1500 [0m                      

                       Computation: 45676 steps/s (collection: 2.040s, learning 0.112s)
             Mean action noise std: 1.99
          Mean value_function loss: 47.3502
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 54.6441
                       Mean reward: 147.82
               Mean episode length: 226.57
    Episode_Reward/reaching_object: 1.1346
    Episode_Reward/rotating_object: 31.1566
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 2.15s
                      Time elapsed: 00:10:40
                               ETA: 00:42:23

################################################################################
                     [1m Learning iteration 302/1500 [0m                      

                       Computation: 45854 steps/s (collection: 2.034s, learning 0.110s)
             Mean action noise std: 1.99
          Mean value_function loss: 45.7906
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 54.6659
                       Mean reward: 160.04
               Mean episode length: 228.91
    Episode_Reward/reaching_object: 1.1454
    Episode_Reward/rotating_object: 31.3960
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 2.14s
                      Time elapsed: 00:10:42
                               ETA: 00:42:21

################################################################################
                     [1m Learning iteration 303/1500 [0m                      

                       Computation: 45545 steps/s (collection: 2.046s, learning 0.112s)
             Mean action noise std: 1.99
          Mean value_function loss: 49.6847
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 54.6862
                       Mean reward: 181.26
               Mean episode length: 230.15
    Episode_Reward/reaching_object: 1.1485
    Episode_Reward/rotating_object: 32.9395
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 2.16s
                      Time elapsed: 00:10:45
                               ETA: 00:42:19

################################################################################
                     [1m Learning iteration 304/1500 [0m                      

                       Computation: 45648 steps/s (collection: 2.043s, learning 0.111s)
             Mean action noise std: 2.00
          Mean value_function loss: 47.0402
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 54.7116
                       Mean reward: 166.85
               Mean episode length: 226.22
    Episode_Reward/reaching_object: 1.1636
    Episode_Reward/rotating_object: 32.9309
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 2.15s
                      Time elapsed: 00:10:47
                               ETA: 00:42:17

################################################################################
                     [1m Learning iteration 305/1500 [0m                      

                       Computation: 46095 steps/s (collection: 2.021s, learning 0.111s)
             Mean action noise std: 2.00
          Mean value_function loss: 53.0215
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 54.7353
                       Mean reward: 180.41
               Mean episode length: 224.70
    Episode_Reward/reaching_object: 1.1733
    Episode_Reward/rotating_object: 32.2700
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 2.13s
                      Time elapsed: 00:10:49
                               ETA: 00:42:15

################################################################################
                     [1m Learning iteration 306/1500 [0m                      

                       Computation: 46070 steps/s (collection: 2.023s, learning 0.111s)
             Mean action noise std: 2.00
          Mean value_function loss: 55.9909
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 54.7561
                       Mean reward: 168.72
               Mean episode length: 234.29
    Episode_Reward/reaching_object: 1.1772
    Episode_Reward/rotating_object: 34.2926
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 2.13s
                      Time elapsed: 00:10:51
                               ETA: 00:42:13

################################################################################
                     [1m Learning iteration 307/1500 [0m                      

                       Computation: 46484 steps/s (collection: 2.004s, learning 0.111s)
             Mean action noise std: 2.00
          Mean value_function loss: 54.1720
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 54.7723
                       Mean reward: 147.87
               Mean episode length: 217.35
    Episode_Reward/reaching_object: 1.1631
    Episode_Reward/rotating_object: 30.8825
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 2.11s
                      Time elapsed: 00:10:53
                               ETA: 00:42:11

################################################################################
                     [1m Learning iteration 308/1500 [0m                      

                       Computation: 46458 steps/s (collection: 2.005s, learning 0.111s)
             Mean action noise std: 2.00
          Mean value_function loss: 51.3190
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 54.7940
                       Mean reward: 191.48
               Mean episode length: 224.39
    Episode_Reward/reaching_object: 1.1672
    Episode_Reward/rotating_object: 35.7483
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 2.12s
                      Time elapsed: 00:10:55
                               ETA: 00:42:09

################################################################################
                     [1m Learning iteration 309/1500 [0m                      

                       Computation: 45935 steps/s (collection: 2.025s, learning 0.116s)
             Mean action noise std: 2.01
          Mean value_function loss: 54.8408
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 54.8216
                       Mean reward: 153.36
               Mean episode length: 229.12
    Episode_Reward/reaching_object: 1.1654
    Episode_Reward/rotating_object: 32.5668
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 2.14s
                      Time elapsed: 00:10:57
                               ETA: 00:42:07

################################################################################
                     [1m Learning iteration 310/1500 [0m                      

                       Computation: 46111 steps/s (collection: 2.014s, learning 0.118s)
             Mean action noise std: 2.01
          Mean value_function loss: 47.9586
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 54.8434
                       Mean reward: 176.01
               Mean episode length: 230.12
    Episode_Reward/reaching_object: 1.1594
    Episode_Reward/rotating_object: 32.1428
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 2.13s
                      Time elapsed: 00:10:59
                               ETA: 00:42:05

################################################################################
                     [1m Learning iteration 311/1500 [0m                      

                       Computation: 46365 steps/s (collection: 2.009s, learning 0.111s)
             Mean action noise std: 2.01
          Mean value_function loss: 53.1258
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 54.8670
                       Mean reward: 187.44
               Mean episode length: 228.45
    Episode_Reward/reaching_object: 1.1776
    Episode_Reward/rotating_object: 33.7399
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 2.12s
                      Time elapsed: 00:11:02
                               ETA: 00:42:03

################################################################################
                     [1m Learning iteration 312/1500 [0m                      

                       Computation: 45836 steps/s (collection: 2.032s, learning 0.113s)
             Mean action noise std: 2.01
          Mean value_function loss: 44.6967
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 54.8894
                       Mean reward: 188.21
               Mean episode length: 236.56
    Episode_Reward/reaching_object: 1.1970
    Episode_Reward/rotating_object: 34.0511
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 2.14s
                      Time elapsed: 00:11:04
                               ETA: 00:42:01

################################################################################
                     [1m Learning iteration 313/1500 [0m                      

                       Computation: 45712 steps/s (collection: 2.036s, learning 0.115s)
             Mean action noise std: 2.01
          Mean value_function loss: 48.3621
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 54.9121
                       Mean reward: 160.62
               Mean episode length: 225.49
    Episode_Reward/reaching_object: 1.1784
    Episode_Reward/rotating_object: 32.9992
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 2.15s
                      Time elapsed: 00:11:06
                               ETA: 00:41:59

################################################################################
                     [1m Learning iteration 314/1500 [0m                      

                       Computation: 45763 steps/s (collection: 2.032s, learning 0.116s)
             Mean action noise std: 2.01
          Mean value_function loss: 51.1896
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 54.9338
                       Mean reward: 187.23
               Mean episode length: 231.06
    Episode_Reward/reaching_object: 1.2023
    Episode_Reward/rotating_object: 32.6111
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 2.15s
                      Time elapsed: 00:11:08
                               ETA: 00:41:57

################################################################################
                     [1m Learning iteration 315/1500 [0m                      

                       Computation: 45638 steps/s (collection: 2.040s, learning 0.114s)
             Mean action noise std: 2.02
          Mean value_function loss: 46.3761
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.9527
                       Mean reward: 181.33
               Mean episode length: 222.34
    Episode_Reward/reaching_object: 1.1706
    Episode_Reward/rotating_object: 35.1819
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 2.15s
                      Time elapsed: 00:11:10
                               ETA: 00:41:55

################################################################################
                     [1m Learning iteration 316/1500 [0m                      

                       Computation: 45335 steps/s (collection: 2.055s, learning 0.114s)
             Mean action noise std: 2.02
          Mean value_function loss: 44.0724
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 54.9739
                       Mean reward: 176.83
               Mean episode length: 223.16
    Episode_Reward/reaching_object: 1.1799
    Episode_Reward/rotating_object: 32.4386
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 2.17s
                      Time elapsed: 00:11:12
                               ETA: 00:41:53

################################################################################
                     [1m Learning iteration 317/1500 [0m                      

                       Computation: 45500 steps/s (collection: 2.048s, learning 0.112s)
             Mean action noise std: 2.02
          Mean value_function loss: 53.0499
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 54.9978
                       Mean reward: 193.96
               Mean episode length: 235.22
    Episode_Reward/reaching_object: 1.1787
    Episode_Reward/rotating_object: 36.8615
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 2.16s
                      Time elapsed: 00:11:15
                               ETA: 00:41:51

################################################################################
                     [1m Learning iteration 318/1500 [0m                      

                       Computation: 45010 steps/s (collection: 2.060s, learning 0.124s)
             Mean action noise std: 2.02
          Mean value_function loss: 49.6768
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 55.0230
                       Mean reward: 173.74
               Mean episode length: 226.78
    Episode_Reward/reaching_object: 1.1854
    Episode_Reward/rotating_object: 36.3065
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 2.18s
                      Time elapsed: 00:11:17
                               ETA: 00:41:49

################################################################################
                     [1m Learning iteration 319/1500 [0m                      

                       Computation: 45444 steps/s (collection: 2.039s, learning 0.124s)
             Mean action noise std: 2.02
          Mean value_function loss: 55.5286
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 55.0531
                       Mean reward: 179.92
               Mean episode length: 225.86
    Episode_Reward/reaching_object: 1.1206
    Episode_Reward/rotating_object: 32.4826
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 2.16s
                      Time elapsed: 00:11:19
                               ETA: 00:41:47

################################################################################
                     [1m Learning iteration 320/1500 [0m                      

                       Computation: 45294 steps/s (collection: 2.055s, learning 0.116s)
             Mean action noise std: 2.03
          Mean value_function loss: 50.3992
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 55.0823
                       Mean reward: 207.51
               Mean episode length: 233.51
    Episode_Reward/reaching_object: 1.1574
    Episode_Reward/rotating_object: 33.1387
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 2.17s
                      Time elapsed: 00:11:21
                               ETA: 00:41:45

################################################################################
                     [1m Learning iteration 321/1500 [0m                      

                       Computation: 44697 steps/s (collection: 2.086s, learning 0.114s)
             Mean action noise std: 2.03
          Mean value_function loss: 47.1241
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 55.1194
                       Mean reward: 166.92
               Mean episode length: 228.35
    Episode_Reward/reaching_object: 1.1680
    Episode_Reward/rotating_object: 35.2441
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 2.20s
                      Time elapsed: 00:11:23
                               ETA: 00:41:43

################################################################################
                     [1m Learning iteration 322/1500 [0m                      

                       Computation: 45552 steps/s (collection: 2.047s, learning 0.111s)
             Mean action noise std: 2.03
          Mean value_function loss: 46.6535
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 55.1452
                       Mean reward: 175.48
               Mean episode length: 226.64
    Episode_Reward/reaching_object: 1.1718
    Episode_Reward/rotating_object: 33.1424
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 2.16s
                      Time elapsed: 00:11:25
                               ETA: 00:41:41

################################################################################
                     [1m Learning iteration 323/1500 [0m                      

                       Computation: 46148 steps/s (collection: 2.017s, learning 0.113s)
             Mean action noise std: 2.03
          Mean value_function loss: 58.0559
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 55.1673
                       Mean reward: 202.15
               Mean episode length: 232.86
    Episode_Reward/reaching_object: 1.1869
    Episode_Reward/rotating_object: 34.7135
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 2.13s
                      Time elapsed: 00:11:28
                               ETA: 00:41:39

################################################################################
                     [1m Learning iteration 324/1500 [0m                      

                       Computation: 45830 steps/s (collection: 2.033s, learning 0.112s)
             Mean action noise std: 2.03
          Mean value_function loss: 48.6429
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 55.1910
                       Mean reward: 183.19
               Mean episode length: 233.16
    Episode_Reward/reaching_object: 1.2048
    Episode_Reward/rotating_object: 35.9730
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 2.14s
                      Time elapsed: 00:11:30
                               ETA: 00:41:37

################################################################################
                     [1m Learning iteration 325/1500 [0m                      

                       Computation: 46181 steps/s (collection: 2.017s, learning 0.112s)
             Mean action noise std: 2.04
          Mean value_function loss: 52.2311
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 55.2104
                       Mean reward: 164.47
               Mean episode length: 216.80
    Episode_Reward/reaching_object: 1.1607
    Episode_Reward/rotating_object: 32.7176
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 2.13s
                      Time elapsed: 00:11:32
                               ETA: 00:41:35

################################################################################
                     [1m Learning iteration 326/1500 [0m                      

                       Computation: 45182 steps/s (collection: 2.061s, learning 0.114s)
             Mean action noise std: 2.04
          Mean value_function loss: 45.8060
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 55.2341
                       Mean reward: 207.41
               Mean episode length: 233.66
    Episode_Reward/reaching_object: 1.2161
    Episode_Reward/rotating_object: 37.0449
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 2.18s
                      Time elapsed: 00:11:34
                               ETA: 00:41:33

################################################################################
                     [1m Learning iteration 327/1500 [0m                      

                       Computation: 45820 steps/s (collection: 2.031s, learning 0.114s)
             Mean action noise std: 2.04
          Mean value_function loss: 47.8722
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 55.2645
                       Mean reward: 176.54
               Mean episode length: 230.32
    Episode_Reward/reaching_object: 1.1978
    Episode_Reward/rotating_object: 35.7946
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 2.15s
                      Time elapsed: 00:11:36
                               ETA: 00:41:31

################################################################################
                     [1m Learning iteration 328/1500 [0m                      

                       Computation: 45702 steps/s (collection: 2.036s, learning 0.115s)
             Mean action noise std: 2.04
          Mean value_function loss: 47.9364
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 55.2983
                       Mean reward: 182.51
               Mean episode length: 227.62
    Episode_Reward/reaching_object: 1.2038
    Episode_Reward/rotating_object: 36.0362
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 2.15s
                      Time elapsed: 00:11:38
                               ETA: 00:41:29

################################################################################
                     [1m Learning iteration 329/1500 [0m                      

                       Computation: 46879 steps/s (collection: 1.987s, learning 0.110s)
             Mean action noise std: 2.05
          Mean value_function loss: 59.8624
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 55.3268
                       Mean reward: 134.13
               Mean episode length: 223.48
    Episode_Reward/reaching_object: 1.2216
    Episode_Reward/rotating_object: 33.5842
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 2.10s
                      Time elapsed: 00:11:40
                               ETA: 00:41:27

################################################################################
                     [1m Learning iteration 330/1500 [0m                      

                       Computation: 46975 steps/s (collection: 1.982s, learning 0.111s)
             Mean action noise std: 2.05
          Mean value_function loss: 56.1468
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 55.3458
                       Mean reward: 180.37
               Mean episode length: 226.69
    Episode_Reward/reaching_object: 1.1785
    Episode_Reward/rotating_object: 33.4200
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 2.09s
                      Time elapsed: 00:11:42
                               ETA: 00:41:24

################################################################################
                     [1m Learning iteration 331/1500 [0m                      

                       Computation: 46742 steps/s (collection: 1.993s, learning 0.110s)
             Mean action noise std: 2.05
          Mean value_function loss: 57.8926
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 55.3663
                       Mean reward: 171.48
               Mean episode length: 218.95
    Episode_Reward/reaching_object: 1.1591
    Episode_Reward/rotating_object: 34.9868
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 2.10s
                      Time elapsed: 00:11:45
                               ETA: 00:41:22

################################################################################
                     [1m Learning iteration 332/1500 [0m                      

                       Computation: 46841 steps/s (collection: 1.989s, learning 0.110s)
             Mean action noise std: 2.05
          Mean value_function loss: 49.6953
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 55.3944
                       Mean reward: 204.78
               Mean episode length: 237.88
    Episode_Reward/reaching_object: 1.2146
    Episode_Reward/rotating_object: 35.9253
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 2.10s
                      Time elapsed: 00:11:47
                               ETA: 00:41:20

################################################################################
                     [1m Learning iteration 333/1500 [0m                      

                       Computation: 46657 steps/s (collection: 1.997s, learning 0.110s)
             Mean action noise std: 2.05
          Mean value_function loss: 52.7189
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 55.4143
                       Mean reward: 178.26
               Mean episode length: 212.85
    Episode_Reward/reaching_object: 1.1900
    Episode_Reward/rotating_object: 36.3854
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 2.11s
                      Time elapsed: 00:11:49
                               ETA: 00:41:18

################################################################################
                     [1m Learning iteration 334/1500 [0m                      

                       Computation: 46292 steps/s (collection: 2.009s, learning 0.115s)
             Mean action noise std: 2.05
          Mean value_function loss: 57.7279
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 55.4328
                       Mean reward: 170.78
               Mean episode length: 222.65
    Episode_Reward/reaching_object: 1.1821
    Episode_Reward/rotating_object: 35.6497
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 2.12s
                      Time elapsed: 00:11:51
                               ETA: 00:41:16

################################################################################
                     [1m Learning iteration 335/1500 [0m                      

                       Computation: 46085 steps/s (collection: 2.022s, learning 0.111s)
             Mean action noise std: 2.06
          Mean value_function loss: 58.7737
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 55.4562
                       Mean reward: 152.98
               Mean episode length: 224.25
    Episode_Reward/reaching_object: 1.1810
    Episode_Reward/rotating_object: 34.6644
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 2.13s
                      Time elapsed: 00:11:53
                               ETA: 00:41:13

################################################################################
                     [1m Learning iteration 336/1500 [0m                      

                       Computation: 45607 steps/s (collection: 2.044s, learning 0.111s)
             Mean action noise std: 2.06
          Mean value_function loss: 53.5842
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 55.4754
                       Mean reward: 187.98
               Mean episode length: 233.18
    Episode_Reward/reaching_object: 1.1950
    Episode_Reward/rotating_object: 36.3329
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 2.16s
                      Time elapsed: 00:11:55
                               ETA: 00:41:11

################################################################################
                     [1m Learning iteration 337/1500 [0m                      

                       Computation: 46233 steps/s (collection: 2.013s, learning 0.113s)
             Mean action noise std: 2.06
          Mean value_function loss: 55.3940
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 55.4938
                       Mean reward: 184.03
               Mean episode length: 225.54
    Episode_Reward/reaching_object: 1.1946
    Episode_Reward/rotating_object: 37.5948
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 2.13s
                      Time elapsed: 00:11:57
                               ETA: 00:41:09

################################################################################
                     [1m Learning iteration 338/1500 [0m                      

                       Computation: 45751 steps/s (collection: 2.037s, learning 0.112s)
             Mean action noise std: 2.06
          Mean value_function loss: 62.9912
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 55.5125
                       Mean reward: 196.77
               Mean episode length: 221.40
    Episode_Reward/reaching_object: 1.1560
    Episode_Reward/rotating_object: 37.4484
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 2.15s
                      Time elapsed: 00:11:59
                               ETA: 00:41:07

################################################################################
                     [1m Learning iteration 339/1500 [0m                      

                       Computation: 46050 steps/s (collection: 2.021s, learning 0.113s)
             Mean action noise std: 2.06
          Mean value_function loss: 53.0176
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 55.5347
                       Mean reward: 168.94
               Mean episode length: 213.28
    Episode_Reward/reaching_object: 1.1753
    Episode_Reward/rotating_object: 37.1424
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 2.13s
                      Time elapsed: 00:12:02
                               ETA: 00:41:05

################################################################################
                     [1m Learning iteration 340/1500 [0m                      

                       Computation: 46085 steps/s (collection: 2.020s, learning 0.113s)
             Mean action noise std: 2.06
          Mean value_function loss: 46.6223
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 55.5646
                       Mean reward: 204.46
               Mean episode length: 232.63
    Episode_Reward/reaching_object: 1.1933
    Episode_Reward/rotating_object: 36.9364
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 2.13s
                      Time elapsed: 00:12:04
                               ETA: 00:41:03

################################################################################
                     [1m Learning iteration 341/1500 [0m                      

                       Computation: 46452 steps/s (collection: 2.001s, learning 0.115s)
             Mean action noise std: 2.07
          Mean value_function loss: 51.0454
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 55.5882
                       Mean reward: 185.02
               Mean episode length: 216.15
    Episode_Reward/reaching_object: 1.1547
    Episode_Reward/rotating_object: 35.2964
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 2.12s
                      Time elapsed: 00:12:06
                               ETA: 00:41:01

################################################################################
                     [1m Learning iteration 342/1500 [0m                      

                       Computation: 46139 steps/s (collection: 2.017s, learning 0.114s)
             Mean action noise std: 2.07
          Mean value_function loss: 48.3029
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 55.6092
                       Mean reward: 214.43
               Mean episode length: 231.52
    Episode_Reward/reaching_object: 1.1685
    Episode_Reward/rotating_object: 36.6551
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 2.13s
                      Time elapsed: 00:12:08
                               ETA: 00:40:59

################################################################################
                     [1m Learning iteration 343/1500 [0m                      

                       Computation: 45996 steps/s (collection: 2.023s, learning 0.115s)
             Mean action noise std: 2.07
          Mean value_function loss: 54.1682
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 55.6285
                       Mean reward: 198.60
               Mean episode length: 223.24
    Episode_Reward/reaching_object: 1.1978
    Episode_Reward/rotating_object: 38.7040
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 2.14s
                      Time elapsed: 00:12:10
                               ETA: 00:40:57

################################################################################
                     [1m Learning iteration 344/1500 [0m                      

                       Computation: 46378 steps/s (collection: 2.008s, learning 0.112s)
             Mean action noise std: 2.07
          Mean value_function loss: 64.3711
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 55.6455
                       Mean reward: 194.93
               Mean episode length: 227.60
    Episode_Reward/reaching_object: 1.2140
    Episode_Reward/rotating_object: 39.6680
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 2.12s
                      Time elapsed: 00:12:12
                               ETA: 00:40:55

################################################################################
                     [1m Learning iteration 345/1500 [0m                      

                       Computation: 44681 steps/s (collection: 2.088s, learning 0.112s)
             Mean action noise std: 2.07
          Mean value_function loss: 60.3316
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 55.6667
                       Mean reward: 214.43
               Mean episode length: 231.50
    Episode_Reward/reaching_object: 1.1828
    Episode_Reward/rotating_object: 37.3645
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 2.20s
                      Time elapsed: 00:12:14
                               ETA: 00:40:53

################################################################################
                     [1m Learning iteration 346/1500 [0m                      

                       Computation: 46054 steps/s (collection: 2.020s, learning 0.114s)
             Mean action noise std: 2.08
          Mean value_function loss: 65.0184
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 55.6953
                       Mean reward: 205.87
               Mean episode length: 233.29
    Episode_Reward/reaching_object: 1.2138
    Episode_Reward/rotating_object: 41.7276
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 2.13s
                      Time elapsed: 00:12:17
                               ETA: 00:40:51

################################################################################
                     [1m Learning iteration 347/1500 [0m                      

                       Computation: 45599 steps/s (collection: 2.044s, learning 0.112s)
             Mean action noise std: 2.08
          Mean value_function loss: 58.8350
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 55.7228
                       Mean reward: 215.32
               Mean episode length: 229.02
    Episode_Reward/reaching_object: 1.2139
    Episode_Reward/rotating_object: 36.9560
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 2.16s
                      Time elapsed: 00:12:19
                               ETA: 00:40:49

################################################################################
                     [1m Learning iteration 348/1500 [0m                      

                       Computation: 46501 steps/s (collection: 2.001s, learning 0.113s)
             Mean action noise std: 2.08
          Mean value_function loss: 62.4737
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 55.7438
                       Mean reward: 214.49
               Mean episode length: 235.97
    Episode_Reward/reaching_object: 1.1872
    Episode_Reward/rotating_object: 40.8465
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 2.11s
                      Time elapsed: 00:12:21
                               ETA: 00:40:47

################################################################################
                     [1m Learning iteration 349/1500 [0m                      

                       Computation: 46584 steps/s (collection: 1.998s, learning 0.112s)
             Mean action noise std: 2.08
          Mean value_function loss: 59.3014
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 55.7669
                       Mean reward: 212.87
               Mean episode length: 229.64
    Episode_Reward/reaching_object: 1.2059
    Episode_Reward/rotating_object: 38.8564
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 2.11s
                      Time elapsed: 00:12:23
                               ETA: 00:40:44

################################################################################
                     [1m Learning iteration 350/1500 [0m                      

                       Computation: 45943 steps/s (collection: 2.029s, learning 0.110s)
             Mean action noise std: 2.08
          Mean value_function loss: 65.0817
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 55.7920
                       Mean reward: 215.15
               Mean episode length: 232.24
    Episode_Reward/reaching_object: 1.1997
    Episode_Reward/rotating_object: 39.7734
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 2.14s
                      Time elapsed: 00:12:25
                               ETA: 00:40:42

################################################################################
                     [1m Learning iteration 351/1500 [0m                      

                       Computation: 47084 steps/s (collection: 1.977s, learning 0.110s)
             Mean action noise std: 2.09
          Mean value_function loss: 59.0997
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 55.8161
                       Mean reward: 201.70
               Mean episode length: 233.29
    Episode_Reward/reaching_object: 1.2099
    Episode_Reward/rotating_object: 38.1967
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 2.09s
                      Time elapsed: 00:12:27
                               ETA: 00:40:40

################################################################################
                     [1m Learning iteration 352/1500 [0m                      

                       Computation: 47299 steps/s (collection: 1.968s, learning 0.110s)
             Mean action noise std: 2.09
          Mean value_function loss: 57.3186
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 55.8364
                       Mean reward: 235.07
               Mean episode length: 230.68
    Episode_Reward/reaching_object: 1.1995
    Episode_Reward/rotating_object: 41.2873
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 2.08s
                      Time elapsed: 00:12:29
                               ETA: 00:40:38

################################################################################
                     [1m Learning iteration 353/1500 [0m                      

                       Computation: 47728 steps/s (collection: 1.950s, learning 0.110s)
             Mean action noise std: 2.09
          Mean value_function loss: 56.6356
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 55.8572
                       Mean reward: 255.30
               Mean episode length: 227.44
    Episode_Reward/reaching_object: 1.1785
    Episode_Reward/rotating_object: 42.7598
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 2.06s
                      Time elapsed: 00:12:31
                               ETA: 00:40:35

################################################################################
                     [1m Learning iteration 354/1500 [0m                      

                       Computation: 47101 steps/s (collection: 1.977s, learning 0.110s)
             Mean action noise std: 2.09
          Mean value_function loss: 58.6196
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 55.8762
                       Mean reward: 196.12
               Mean episode length: 213.56
    Episode_Reward/reaching_object: 1.1669
    Episode_Reward/rotating_object: 42.1140
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 2.09s
                      Time elapsed: 00:12:33
                               ETA: 00:40:33

################################################################################
                     [1m Learning iteration 355/1500 [0m                      

                       Computation: 47078 steps/s (collection: 1.977s, learning 0.111s)
             Mean action noise std: 2.09
          Mean value_function loss: 58.7904
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 55.8985
                       Mean reward: 244.77
               Mean episode length: 229.38
    Episode_Reward/reaching_object: 1.2192
    Episode_Reward/rotating_object: 41.6548
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 2.09s
                      Time elapsed: 00:12:35
                               ETA: 00:40:31

################################################################################
                     [1m Learning iteration 356/1500 [0m                      

                       Computation: 46569 steps/s (collection: 2.000s, learning 0.111s)
             Mean action noise std: 2.09
          Mean value_function loss: 57.0014
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 55.9213
                       Mean reward: 214.07
               Mean episode length: 231.88
    Episode_Reward/reaching_object: 1.1899
    Episode_Reward/rotating_object: 37.9080
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 2.11s
                      Time elapsed: 00:12:38
                               ETA: 00:40:29

################################################################################
                     [1m Learning iteration 357/1500 [0m                      

                       Computation: 43673 steps/s (collection: 2.141s, learning 0.110s)
             Mean action noise std: 2.10
          Mean value_function loss: 53.4877
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 55.9456
                       Mean reward: 209.24
               Mean episode length: 221.47
    Episode_Reward/reaching_object: 1.2050
    Episode_Reward/rotating_object: 44.1952
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 2.25s
                      Time elapsed: 00:12:40
                               ETA: 00:40:27

################################################################################
                     [1m Learning iteration 358/1500 [0m                      

                       Computation: 43530 steps/s (collection: 2.145s, learning 0.114s)
             Mean action noise std: 2.10
          Mean value_function loss: 50.3713
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 55.9709
                       Mean reward: 223.47
               Mean episode length: 226.45
    Episode_Reward/reaching_object: 1.1948
    Episode_Reward/rotating_object: 41.3203
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 2.26s
                      Time elapsed: 00:12:42
                               ETA: 00:40:25

################################################################################
                     [1m Learning iteration 359/1500 [0m                      

                       Computation: 46231 steps/s (collection: 2.014s, learning 0.112s)
             Mean action noise std: 2.10
          Mean value_function loss: 56.3922
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 56.0013
                       Mean reward: 235.68
               Mean episode length: 228.93
    Episode_Reward/reaching_object: 1.1866
    Episode_Reward/rotating_object: 42.0534
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 2.13s
                      Time elapsed: 00:12:44
                               ETA: 00:40:23

################################################################################
                     [1m Learning iteration 360/1500 [0m                      

                       Computation: 46195 steps/s (collection: 2.015s, learning 0.113s)
             Mean action noise std: 2.10
          Mean value_function loss: 66.4738
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 56.0370
                       Mean reward: 195.23
               Mean episode length: 220.84
    Episode_Reward/reaching_object: 1.1967
    Episode_Reward/rotating_object: 40.8817
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 2.13s
                      Time elapsed: 00:12:46
                               ETA: 00:40:21

################################################################################
                     [1m Learning iteration 361/1500 [0m                      

                       Computation: 46256 steps/s (collection: 2.011s, learning 0.114s)
             Mean action noise std: 2.11
          Mean value_function loss: 63.4051
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 56.0614
                       Mean reward: 232.80
               Mean episode length: 225.40
    Episode_Reward/reaching_object: 1.2185
    Episode_Reward/rotating_object: 41.5118
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 2.13s
                      Time elapsed: 00:12:48
                               ETA: 00:40:19

################################################################################
                     [1m Learning iteration 362/1500 [0m                      

                       Computation: 46044 steps/s (collection: 2.007s, learning 0.128s)
             Mean action noise std: 2.11
          Mean value_function loss: 58.7598
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 56.0839
                       Mean reward: 246.48
               Mean episode length: 225.46
    Episode_Reward/reaching_object: 1.1595
    Episode_Reward/rotating_object: 42.0515
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 2.13s
                      Time elapsed: 00:12:51
                               ETA: 00:40:17

################################################################################
                     [1m Learning iteration 363/1500 [0m                      

                       Computation: 46536 steps/s (collection: 1.995s, learning 0.117s)
             Mean action noise std: 2.11
          Mean value_function loss: 59.2235
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 56.1170
                       Mean reward: 194.57
               Mean episode length: 229.34
    Episode_Reward/reaching_object: 1.2147
    Episode_Reward/rotating_object: 40.1497
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 2.11s
                      Time elapsed: 00:12:53
                               ETA: 00:40:15

################################################################################
                     [1m Learning iteration 364/1500 [0m                      

                       Computation: 46425 steps/s (collection: 2.004s, learning 0.113s)
             Mean action noise std: 2.11
          Mean value_function loss: 58.6179
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 56.1460
                       Mean reward: 224.99
               Mean episode length: 229.74
    Episode_Reward/reaching_object: 1.1636
    Episode_Reward/rotating_object: 40.2166
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 2.12s
                      Time elapsed: 00:12:55
                               ETA: 00:40:13

################################################################################
                     [1m Learning iteration 365/1500 [0m                      

                       Computation: 46611 steps/s (collection: 1.999s, learning 0.110s)
             Mean action noise std: 2.11
          Mean value_function loss: 63.7640
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 56.1702
                       Mean reward: 227.54
               Mean episode length: 230.63
    Episode_Reward/reaching_object: 1.1833
    Episode_Reward/rotating_object: 42.1426
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 2.11s
                      Time elapsed: 00:12:57
                               ETA: 00:40:10

################################################################################
                     [1m Learning iteration 366/1500 [0m                      

                       Computation: 46602 steps/s (collection: 1.997s, learning 0.112s)
             Mean action noise std: 2.12
          Mean value_function loss: 52.4484
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 56.1901
                       Mean reward: 209.95
               Mean episode length: 220.87
    Episode_Reward/reaching_object: 1.1778
    Episode_Reward/rotating_object: 41.8012
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 2.11s
                      Time elapsed: 00:12:59
                               ETA: 00:40:08

################################################################################
                     [1m Learning iteration 367/1500 [0m                      

                       Computation: 46183 steps/s (collection: 2.017s, learning 0.112s)
             Mean action noise std: 2.12
          Mean value_function loss: 56.9265
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 56.2164
                       Mean reward: 209.16
               Mean episode length: 227.63
    Episode_Reward/reaching_object: 1.1925
    Episode_Reward/rotating_object: 40.2273
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 2.13s
                      Time elapsed: 00:13:01
                               ETA: 00:40:06

################################################################################
                     [1m Learning iteration 368/1500 [0m                      

                       Computation: 46622 steps/s (collection: 1.998s, learning 0.110s)
             Mean action noise std: 2.12
          Mean value_function loss: 53.7619
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 56.2365
                       Mean reward: 210.63
               Mean episode length: 229.42
    Episode_Reward/reaching_object: 1.2252
    Episode_Reward/rotating_object: 42.3711
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 2.11s
                      Time elapsed: 00:13:03
                               ETA: 00:40:04

################################################################################
                     [1m Learning iteration 369/1500 [0m                      

                       Computation: 46179 steps/s (collection: 2.015s, learning 0.114s)
             Mean action noise std: 2.12
          Mean value_function loss: 53.3626
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 56.2586
                       Mean reward: 217.96
               Mean episode length: 226.92
    Episode_Reward/reaching_object: 1.2092
    Episode_Reward/rotating_object: 41.8493
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 2.13s
                      Time elapsed: 00:13:05
                               ETA: 00:40:02

################################################################################
                     [1m Learning iteration 370/1500 [0m                      

                       Computation: 44029 steps/s (collection: 2.119s, learning 0.113s)
             Mean action noise std: 2.12
          Mean value_function loss: 58.0047
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 56.2812
                       Mean reward: 241.75
               Mean episode length: 232.31
    Episode_Reward/reaching_object: 1.2101
    Episode_Reward/rotating_object: 41.9012
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 2.23s
                      Time elapsed: 00:13:08
                               ETA: 00:40:00

################################################################################
                     [1m Learning iteration 371/1500 [0m                      

                       Computation: 46756 steps/s (collection: 1.992s, learning 0.110s)
             Mean action noise std: 2.12
          Mean value_function loss: 58.1961
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 56.2991
                       Mean reward: 223.47
               Mean episode length: 233.92
    Episode_Reward/reaching_object: 1.2297
    Episode_Reward/rotating_object: 44.4395
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 2.10s
                      Time elapsed: 00:13:10
                               ETA: 00:39:58

################################################################################
                     [1m Learning iteration 372/1500 [0m                      

                       Computation: 47186 steps/s (collection: 1.971s, learning 0.112s)
             Mean action noise std: 2.13
          Mean value_function loss: 63.3798
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 56.3192
                       Mean reward: 247.17
               Mean episode length: 240.27
    Episode_Reward/reaching_object: 1.2209
    Episode_Reward/rotating_object: 47.1923
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 2.08s
                      Time elapsed: 00:13:12
                               ETA: 00:39:56

################################################################################
                     [1m Learning iteration 373/1500 [0m                      

                       Computation: 45999 steps/s (collection: 2.027s, learning 0.110s)
             Mean action noise std: 2.13
          Mean value_function loss: 56.4926
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 56.3442
                       Mean reward: 211.25
               Mean episode length: 234.96
    Episode_Reward/reaching_object: 1.2401
    Episode_Reward/rotating_object: 45.5540
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 2.14s
                      Time elapsed: 00:13:14
                               ETA: 00:39:54

################################################################################
                     [1m Learning iteration 374/1500 [0m                      

                       Computation: 46362 steps/s (collection: 2.010s, learning 0.110s)
             Mean action noise std: 2.13
          Mean value_function loss: 61.0191
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 56.3723
                       Mean reward: 236.31
               Mean episode length: 228.32
    Episode_Reward/reaching_object: 1.2498
    Episode_Reward/rotating_object: 46.6117
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 2.12s
                      Time elapsed: 00:13:16
                               ETA: 00:39:51

################################################################################
                     [1m Learning iteration 375/1500 [0m                      

                       Computation: 47161 steps/s (collection: 1.974s, learning 0.110s)
             Mean action noise std: 2.13
          Mean value_function loss: 69.7334
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 56.3907
                       Mean reward: 208.47
               Mean episode length: 229.75
    Episode_Reward/reaching_object: 1.2136
    Episode_Reward/rotating_object: 42.2305
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 2.08s
                      Time elapsed: 00:13:18
                               ETA: 00:39:49

################################################################################
                     [1m Learning iteration 376/1500 [0m                      

                       Computation: 47831 steps/s (collection: 1.945s, learning 0.110s)
             Mean action noise std: 2.13
          Mean value_function loss: 57.4407
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 56.4101
                       Mean reward: 208.57
               Mean episode length: 216.51
    Episode_Reward/reaching_object: 1.1945
    Episode_Reward/rotating_object: 41.7023
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 2.06s
                      Time elapsed: 00:13:20
                               ETA: 00:39:47

################################################################################
                     [1m Learning iteration 377/1500 [0m                      

                       Computation: 48234 steps/s (collection: 1.928s, learning 0.110s)
             Mean action noise std: 2.14
          Mean value_function loss: 66.8187
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 56.4311
                       Mean reward: 245.36
               Mean episode length: 235.27
    Episode_Reward/reaching_object: 1.2545
    Episode_Reward/rotating_object: 44.2571
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 2.04s
                      Time elapsed: 00:13:22
                               ETA: 00:39:44

################################################################################
                     [1m Learning iteration 378/1500 [0m                      

                       Computation: 47904 steps/s (collection: 1.942s, learning 0.110s)
             Mean action noise std: 2.14
          Mean value_function loss: 57.7366
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 56.4544
                       Mean reward: 226.04
               Mean episode length: 223.52
    Episode_Reward/reaching_object: 1.2393
    Episode_Reward/rotating_object: 42.8639
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 2.05s
                      Time elapsed: 00:13:24
                               ETA: 00:39:42

################################################################################
                     [1m Learning iteration 379/1500 [0m                      

                       Computation: 47513 steps/s (collection: 1.959s, learning 0.110s)
             Mean action noise std: 2.14
          Mean value_function loss: 55.8056
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 56.4826
                       Mean reward: 243.27
               Mean episode length: 234.16
    Episode_Reward/reaching_object: 1.2365
    Episode_Reward/rotating_object: 46.1489
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 2.07s
                      Time elapsed: 00:13:26
                               ETA: 00:39:40

################################################################################
                     [1m Learning iteration 380/1500 [0m                      

                       Computation: 47067 steps/s (collection: 1.976s, learning 0.113s)
             Mean action noise std: 2.14
          Mean value_function loss: 59.4963
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 56.5094
                       Mean reward: 184.89
               Mean episode length: 213.35
    Episode_Reward/reaching_object: 1.1946
    Episode_Reward/rotating_object: 42.8254
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 2.09s
                      Time elapsed: 00:13:28
                               ETA: 00:39:38

################################################################################
                     [1m Learning iteration 381/1500 [0m                      

                       Computation: 46701 steps/s (collection: 1.994s, learning 0.111s)
             Mean action noise std: 2.14
          Mean value_function loss: 63.0408
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 56.5304
                       Mean reward: 193.79
               Mean episode length: 219.76
    Episode_Reward/reaching_object: 1.2385
    Episode_Reward/rotating_object: 42.8650
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 2.10s
                      Time elapsed: 00:13:31
                               ETA: 00:39:35

################################################################################
                     [1m Learning iteration 382/1500 [0m                      

                       Computation: 46486 steps/s (collection: 1.998s, learning 0.116s)
             Mean action noise std: 2.15
          Mean value_function loss: 58.8714
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 56.5472
                       Mean reward: 258.02
               Mean episode length: 224.61
    Episode_Reward/reaching_object: 1.2215
    Episode_Reward/rotating_object: 47.6812
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 2.11s
                      Time elapsed: 00:13:33
                               ETA: 00:39:33

################################################################################
                     [1m Learning iteration 383/1500 [0m                      

                       Computation: 46516 steps/s (collection: 2.001s, learning 0.112s)
             Mean action noise std: 2.15
          Mean value_function loss: 66.1062
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 56.5629
                       Mean reward: 241.64
               Mean episode length: 232.46
    Episode_Reward/reaching_object: 1.2516
    Episode_Reward/rotating_object: 46.2874
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 2.11s
                      Time elapsed: 00:13:35
                               ETA: 00:39:31

################################################################################
                     [1m Learning iteration 384/1500 [0m                      

                       Computation: 44155 steps/s (collection: 2.114s, learning 0.112s)
             Mean action noise std: 2.15
          Mean value_function loss: 70.3039
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 56.5794
                       Mean reward: 232.89
               Mean episode length: 236.55
    Episode_Reward/reaching_object: 1.2417
    Episode_Reward/rotating_object: 46.7314
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 2.23s
                      Time elapsed: 00:13:37
                               ETA: 00:39:29

################################################################################
                     [1m Learning iteration 385/1500 [0m                      

                       Computation: 46024 steps/s (collection: 2.025s, learning 0.111s)
             Mean action noise std: 2.15
          Mean value_function loss: 67.4636
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 56.5972
                       Mean reward: 253.69
               Mean episode length: 230.76
    Episode_Reward/reaching_object: 1.2794
    Episode_Reward/rotating_object: 49.4815
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 2.14s
                      Time elapsed: 00:13:39
                               ETA: 00:39:27

################################################################################
                     [1m Learning iteration 386/1500 [0m                      

                       Computation: 46996 steps/s (collection: 1.978s, learning 0.114s)
             Mean action noise std: 2.15
          Mean value_function loss: 66.3775
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 56.6191
                       Mean reward: 234.00
               Mean episode length: 228.61
    Episode_Reward/reaching_object: 1.2563
    Episode_Reward/rotating_object: 46.4151
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 2.09s
                      Time elapsed: 00:13:41
                               ETA: 00:39:25

################################################################################
                     [1m Learning iteration 387/1500 [0m                      

                       Computation: 46825 steps/s (collection: 1.987s, learning 0.113s)
             Mean action noise std: 2.15
          Mean value_function loss: 67.6637
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 56.6404
                       Mean reward: 236.24
               Mean episode length: 228.01
    Episode_Reward/reaching_object: 1.2589
    Episode_Reward/rotating_object: 49.6851
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 2.10s
                      Time elapsed: 00:13:43
                               ETA: 00:39:23

################################################################################
                     [1m Learning iteration 388/1500 [0m                      

                       Computation: 46208 steps/s (collection: 2.016s, learning 0.112s)
             Mean action noise std: 2.15
          Mean value_function loss: 64.1172
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 56.6569
                       Mean reward: 229.47
               Mean episode length: 227.18
    Episode_Reward/reaching_object: 1.2594
    Episode_Reward/rotating_object: 43.8770
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 2.13s
                      Time elapsed: 00:13:46
                               ETA: 00:39:21

################################################################################
                     [1m Learning iteration 389/1500 [0m                      

                       Computation: 46855 steps/s (collection: 1.985s, learning 0.113s)
             Mean action noise std: 2.16
          Mean value_function loss: 64.4421
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 56.6734
                       Mean reward: 231.96
               Mean episode length: 227.58
    Episode_Reward/reaching_object: 1.2528
    Episode_Reward/rotating_object: 45.4341
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 2.10s
                      Time elapsed: 00:13:48
                               ETA: 00:39:19

################################################################################
                     [1m Learning iteration 390/1500 [0m                      

                       Computation: 46981 steps/s (collection: 1.980s, learning 0.113s)
             Mean action noise std: 2.16
          Mean value_function loss: 66.1594
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 56.7004
                       Mean reward: 230.52
               Mean episode length: 229.56
    Episode_Reward/reaching_object: 1.2260
    Episode_Reward/rotating_object: 45.2538
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 2.09s
                      Time elapsed: 00:13:50
                               ETA: 00:39:16

################################################################################
                     [1m Learning iteration 391/1500 [0m                      

                       Computation: 47086 steps/s (collection: 1.973s, learning 0.115s)
             Mean action noise std: 2.16
          Mean value_function loss: 65.0058
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 56.7266
                       Mean reward: 226.22
               Mean episode length: 231.91
    Episode_Reward/reaching_object: 1.2643
    Episode_Reward/rotating_object: 45.4732
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 2.09s
                      Time elapsed: 00:13:52
                               ETA: 00:39:14

################################################################################
                     [1m Learning iteration 392/1500 [0m                      

                       Computation: 47118 steps/s (collection: 1.973s, learning 0.113s)
             Mean action noise std: 2.16
          Mean value_function loss: 70.0060
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 56.7442
                       Mean reward: 268.97
               Mean episode length: 225.81
    Episode_Reward/reaching_object: 1.2562
    Episode_Reward/rotating_object: 49.4424
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 2.09s
                      Time elapsed: 00:13:54
                               ETA: 00:39:12

################################################################################
                     [1m Learning iteration 393/1500 [0m                      

                       Computation: 47331 steps/s (collection: 1.964s, learning 0.113s)
             Mean action noise std: 2.16
          Mean value_function loss: 67.3801
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 56.7604
                       Mean reward: 240.15
               Mean episode length: 233.92
    Episode_Reward/reaching_object: 1.2405
    Episode_Reward/rotating_object: 45.9086
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 2.08s
                      Time elapsed: 00:13:56
                               ETA: 00:39:10

################################################################################
                     [1m Learning iteration 394/1500 [0m                      

                       Computation: 47313 steps/s (collection: 1.964s, learning 0.114s)
             Mean action noise std: 2.17
          Mean value_function loss: 67.9294
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 56.7837
                       Mean reward: 204.84
               Mean episode length: 213.25
    Episode_Reward/reaching_object: 1.2907
    Episode_Reward/rotating_object: 49.8543
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 2.08s
                      Time elapsed: 00:13:58
                               ETA: 00:39:07

################################################################################
                     [1m Learning iteration 395/1500 [0m                      

                       Computation: 46952 steps/s (collection: 1.975s, learning 0.119s)
             Mean action noise std: 2.17
          Mean value_function loss: 70.3124
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 56.8006
                       Mean reward: 252.38
               Mean episode length: 216.51
    Episode_Reward/reaching_object: 1.2162
    Episode_Reward/rotating_object: 49.2060
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 2.09s
                      Time elapsed: 00:14:00
                               ETA: 00:39:05

################################################################################
                     [1m Learning iteration 396/1500 [0m                      

                       Computation: 47141 steps/s (collection: 1.962s, learning 0.123s)
             Mean action noise std: 2.17
          Mean value_function loss: 69.5796
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 56.8164
                       Mean reward: 251.45
               Mean episode length: 224.98
    Episode_Reward/reaching_object: 1.2310
    Episode_Reward/rotating_object: 45.4303
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 2.09s
                      Time elapsed: 00:14:02
                               ETA: 00:39:03

################################################################################
                     [1m Learning iteration 397/1500 [0m                      

                       Computation: 47931 steps/s (collection: 1.928s, learning 0.123s)
             Mean action noise std: 2.17
          Mean value_function loss: 73.5375
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 56.8434
                       Mean reward: 269.37
               Mean episode length: 225.67
    Episode_Reward/reaching_object: 1.2711
    Episode_Reward/rotating_object: 51.5158
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 2.05s
                      Time elapsed: 00:14:04
                               ETA: 00:39:01

################################################################################
                     [1m Learning iteration 398/1500 [0m                      

                       Computation: 47544 steps/s (collection: 1.945s, learning 0.123s)
             Mean action noise std: 2.17
          Mean value_function loss: 74.0222
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 56.8690
                       Mean reward: 218.50
               Mean episode length: 223.42
    Episode_Reward/reaching_object: 1.2911
    Episode_Reward/rotating_object: 48.2040
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 2.07s
                      Time elapsed: 00:14:06
                               ETA: 00:38:58

################################################################################
                     [1m Learning iteration 399/1500 [0m                      

                       Computation: 47937 steps/s (collection: 1.940s, learning 0.111s)
             Mean action noise std: 2.18
          Mean value_function loss: 75.3202
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 56.8959
                       Mean reward: 279.27
               Mean episode length: 226.95
    Episode_Reward/reaching_object: 1.2906
    Episode_Reward/rotating_object: 50.2159
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 2.05s
                      Time elapsed: 00:14:08
                               ETA: 00:38:56

################################################################################
                     [1m Learning iteration 400/1500 [0m                      

                       Computation: 48021 steps/s (collection: 1.936s, learning 0.111s)
             Mean action noise std: 2.18
          Mean value_function loss: 74.7457
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 56.9214
                       Mean reward: 250.11
               Mean episode length: 223.85
    Episode_Reward/reaching_object: 1.2431
    Episode_Reward/rotating_object: 48.0241
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 2.05s
                      Time elapsed: 00:14:10
                               ETA: 00:38:54

################################################################################
                     [1m Learning iteration 401/1500 [0m                      

                       Computation: 47977 steps/s (collection: 1.937s, learning 0.112s)
             Mean action noise std: 2.18
          Mean value_function loss: 71.1334
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 56.9507
                       Mean reward: 249.77
               Mean episode length: 228.79
    Episode_Reward/reaching_object: 1.2493
    Episode_Reward/rotating_object: 48.4747
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 2.05s
                      Time elapsed: 00:14:12
                               ETA: 00:38:51

################################################################################
                     [1m Learning iteration 402/1500 [0m                      

                       Computation: 47856 steps/s (collection: 1.943s, learning 0.112s)
             Mean action noise std: 2.18
          Mean value_function loss: 70.8856
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 56.9767
                       Mean reward: 211.56
               Mean episode length: 216.99
    Episode_Reward/reaching_object: 1.2884
    Episode_Reward/rotating_object: 46.2513
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 2.05s
                      Time elapsed: 00:14:15
                               ETA: 00:38:49

################################################################################
                     [1m Learning iteration 403/1500 [0m                      

                       Computation: 48175 steps/s (collection: 1.928s, learning 0.113s)
             Mean action noise std: 2.18
          Mean value_function loss: 71.0329
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 56.9953
                       Mean reward: 258.27
               Mean episode length: 224.73
    Episode_Reward/reaching_object: 1.3102
    Episode_Reward/rotating_object: 48.2734
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 2.04s
                      Time elapsed: 00:14:17
                               ETA: 00:38:47

################################################################################
                     [1m Learning iteration 404/1500 [0m                      

                       Computation: 47563 steps/s (collection: 1.956s, learning 0.110s)
             Mean action noise std: 2.18
          Mean value_function loss: 71.9197
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 57.0122
                       Mean reward: 278.54
               Mean episode length: 234.76
    Episode_Reward/reaching_object: 1.3278
    Episode_Reward/rotating_object: 49.2073
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 2.07s
                      Time elapsed: 00:14:19
                               ETA: 00:38:44

################################################################################
                     [1m Learning iteration 405/1500 [0m                      

                       Computation: 47556 steps/s (collection: 1.954s, learning 0.113s)
             Mean action noise std: 2.19
          Mean value_function loss: 60.9372
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 57.0267
                       Mean reward: 253.94
               Mean episode length: 227.80
    Episode_Reward/reaching_object: 1.2702
    Episode_Reward/rotating_object: 49.6372
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 2.07s
                      Time elapsed: 00:14:21
                               ETA: 00:38:42

################################################################################
                     [1m Learning iteration 406/1500 [0m                      

                       Computation: 46630 steps/s (collection: 1.994s, learning 0.114s)
             Mean action noise std: 2.19
          Mean value_function loss: 63.1099
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 57.0524
                       Mean reward: 282.23
               Mean episode length: 238.78
    Episode_Reward/reaching_object: 1.3079
    Episode_Reward/rotating_object: 49.2921
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 2.11s
                      Time elapsed: 00:14:23
                               ETA: 00:38:40

################################################################################
                     [1m Learning iteration 407/1500 [0m                      

                       Computation: 44353 steps/s (collection: 2.104s, learning 0.112s)
             Mean action noise std: 2.19
          Mean value_function loss: 72.2488
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.0714
                       Mean reward: 255.00
               Mean episode length: 228.80
    Episode_Reward/reaching_object: 1.2769
    Episode_Reward/rotating_object: 50.5990
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 2.22s
                      Time elapsed: 00:14:25
                               ETA: 00:38:38

################################################################################
                     [1m Learning iteration 408/1500 [0m                      

                       Computation: 44534 steps/s (collection: 2.094s, learning 0.113s)
             Mean action noise std: 2.19
          Mean value_function loss: 78.4900
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 57.0821
                       Mean reward: 248.87
               Mean episode length: 231.38
    Episode_Reward/reaching_object: 1.2974
    Episode_Reward/rotating_object: 52.0934
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 2.21s
                      Time elapsed: 00:14:27
                               ETA: 00:38:36

################################################################################
                     [1m Learning iteration 409/1500 [0m                      

                       Computation: 44719 steps/s (collection: 2.067s, learning 0.131s)
             Mean action noise std: 2.19
          Mean value_function loss: 74.7839
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 57.0992
                       Mean reward: 264.51
               Mean episode length: 235.34
    Episode_Reward/reaching_object: 1.3065
    Episode_Reward/rotating_object: 50.9948
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 2.20s
                      Time elapsed: 00:14:29
                               ETA: 00:38:34

################################################################################
                     [1m Learning iteration 410/1500 [0m                      

                       Computation: 44949 steps/s (collection: 2.074s, learning 0.113s)
             Mean action noise std: 2.19
          Mean value_function loss: 64.7906
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 57.1182
                       Mean reward: 271.05
               Mean episode length: 231.28
    Episode_Reward/reaching_object: 1.2670
    Episode_Reward/rotating_object: 52.2219
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 2.19s
                      Time elapsed: 00:14:32
                               ETA: 00:38:32

################################################################################
                     [1m Learning iteration 411/1500 [0m                      

                       Computation: 42031 steps/s (collection: 2.210s, learning 0.129s)
             Mean action noise std: 2.20
          Mean value_function loss: 65.4497
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 57.1374
                       Mean reward: 274.52
               Mean episode length: 231.90
    Episode_Reward/reaching_object: 1.2919
    Episode_Reward/rotating_object: 53.6874
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 2.34s
                      Time elapsed: 00:14:34
                               ETA: 00:38:31

################################################################################
                     [1m Learning iteration 412/1500 [0m                      

                       Computation: 43323 steps/s (collection: 2.152s, learning 0.117s)
             Mean action noise std: 2.20
          Mean value_function loss: 58.9879
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 57.1612
                       Mean reward: 291.80
               Mean episode length: 238.72
    Episode_Reward/reaching_object: 1.2803
    Episode_Reward/rotating_object: 52.2330
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 2.27s
                      Time elapsed: 00:14:36
                               ETA: 00:38:29

################################################################################
                     [1m Learning iteration 413/1500 [0m                      

                       Computation: 45657 steps/s (collection: 2.042s, learning 0.111s)
             Mean action noise std: 2.20
          Mean value_function loss: 69.7578
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 57.1832
                       Mean reward: 267.03
               Mean episode length: 226.03
    Episode_Reward/reaching_object: 1.2430
    Episode_Reward/rotating_object: 49.8094
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 2.15s
                      Time elapsed: 00:14:38
                               ETA: 00:38:27

################################################################################
                     [1m Learning iteration 414/1500 [0m                      

                       Computation: 47479 steps/s (collection: 1.958s, learning 0.113s)
             Mean action noise std: 2.20
          Mean value_function loss: 71.5850
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 57.2079
                       Mean reward: 303.17
               Mean episode length: 235.51
    Episode_Reward/reaching_object: 1.2800
    Episode_Reward/rotating_object: 52.0449
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 2.07s
                      Time elapsed: 00:14:40
                               ETA: 00:38:25

################################################################################
                     [1m Learning iteration 415/1500 [0m                      

                       Computation: 46988 steps/s (collection: 1.982s, learning 0.110s)
             Mean action noise std: 2.20
          Mean value_function loss: 79.5440
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 57.2240
                       Mean reward: 250.47
               Mean episode length: 238.63
    Episode_Reward/reaching_object: 1.2532
    Episode_Reward/rotating_object: 48.8476
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 2.09s
                      Time elapsed: 00:14:43
                               ETA: 00:38:23

################################################################################
                     [1m Learning iteration 416/1500 [0m                      

                       Computation: 44973 steps/s (collection: 2.074s, learning 0.111s)
             Mean action noise std: 2.20
          Mean value_function loss: 78.6741
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 57.2334
                       Mean reward: 234.00
               Mean episode length: 232.01
    Episode_Reward/reaching_object: 1.2453
    Episode_Reward/rotating_object: 49.5252
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 2.19s
                      Time elapsed: 00:14:45
                               ETA: 00:38:21

################################################################################
                     [1m Learning iteration 417/1500 [0m                      

                       Computation: 45891 steps/s (collection: 2.016s, learning 0.127s)
             Mean action noise std: 2.20
          Mean value_function loss: 80.3400
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 57.2439
                       Mean reward: 242.33
               Mean episode length: 224.23
    Episode_Reward/reaching_object: 1.2903
    Episode_Reward/rotating_object: 52.7787
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 2.14s
                      Time elapsed: 00:14:47
                               ETA: 00:38:19

################################################################################
                     [1m Learning iteration 418/1500 [0m                      

                       Computation: 43606 steps/s (collection: 2.142s, learning 0.113s)
             Mean action noise std: 2.21
          Mean value_function loss: 78.6148
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 57.2627
                       Mean reward: 235.69
               Mean episode length: 223.49
    Episode_Reward/reaching_object: 1.3072
    Episode_Reward/rotating_object: 51.8437
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 2.25s
                      Time elapsed: 00:14:49
                               ETA: 00:38:17

################################################################################
                     [1m Learning iteration 419/1500 [0m                      

                       Computation: 48227 steps/s (collection: 1.928s, learning 0.110s)
             Mean action noise std: 2.21
          Mean value_function loss: 71.0742
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.2766
                       Mean reward: 294.42
               Mean episode length: 233.10
    Episode_Reward/reaching_object: 1.2807
    Episode_Reward/rotating_object: 52.9507
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 2.04s
                      Time elapsed: 00:14:51
                               ETA: 00:38:14

################################################################################
                     [1m Learning iteration 420/1500 [0m                      

                       Computation: 48434 steps/s (collection: 1.919s, learning 0.111s)
             Mean action noise std: 2.21
          Mean value_function loss: 71.7449
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 57.2923
                       Mean reward: 307.57
               Mean episode length: 231.02
    Episode_Reward/reaching_object: 1.2915
    Episode_Reward/rotating_object: 59.1888
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 2.03s
                      Time elapsed: 00:14:53
                               ETA: 00:38:12

################################################################################
                     [1m Learning iteration 421/1500 [0m                      

                       Computation: 48314 steps/s (collection: 1.924s, learning 0.110s)
             Mean action noise std: 2.21
          Mean value_function loss: 73.9093
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 57.3197
                       Mean reward: 267.53
               Mean episode length: 223.60
    Episode_Reward/reaching_object: 1.3144
    Episode_Reward/rotating_object: 55.1957
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 2.03s
                      Time elapsed: 00:14:55
                               ETA: 00:38:10

################################################################################
                     [1m Learning iteration 422/1500 [0m                      

                       Computation: 48179 steps/s (collection: 1.930s, learning 0.110s)
             Mean action noise std: 2.21
          Mean value_function loss: 72.6203
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 57.3430
                       Mean reward: 267.78
               Mean episode length: 239.37
    Episode_Reward/reaching_object: 1.3257
    Episode_Reward/rotating_object: 52.5494
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 2.04s
                      Time elapsed: 00:14:57
                               ETA: 00:38:07

################################################################################
                     [1m Learning iteration 423/1500 [0m                      

                       Computation: 48217 steps/s (collection: 1.928s, learning 0.111s)
             Mean action noise std: 2.21
          Mean value_function loss: 67.9536
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 57.3580
                       Mean reward: 295.34
               Mean episode length: 238.87
    Episode_Reward/reaching_object: 1.3233
    Episode_Reward/rotating_object: 56.9033
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 2.04s
                      Time elapsed: 00:14:59
                               ETA: 00:38:05

################################################################################
                     [1m Learning iteration 424/1500 [0m                      

                       Computation: 48742 steps/s (collection: 1.907s, learning 0.110s)
             Mean action noise std: 2.22
          Mean value_function loss: 66.8892
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 57.3773
                       Mean reward: 256.03
               Mean episode length: 233.10
    Episode_Reward/reaching_object: 1.2721
    Episode_Reward/rotating_object: 51.5816
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 2.02s
                      Time elapsed: 00:15:01
                               ETA: 00:38:03

################################################################################
                     [1m Learning iteration 425/1500 [0m                      

                       Computation: 48200 steps/s (collection: 1.929s, learning 0.110s)
             Mean action noise std: 2.22
          Mean value_function loss: 79.1644
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 57.3975
                       Mean reward: 219.90
               Mean episode length: 224.00
    Episode_Reward/reaching_object: 1.2960
    Episode_Reward/rotating_object: 54.1138
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 2.04s
                      Time elapsed: 00:15:03
                               ETA: 00:38:00

################################################################################
                     [1m Learning iteration 426/1500 [0m                      

                       Computation: 48130 steps/s (collection: 1.932s, learning 0.110s)
             Mean action noise std: 2.22
          Mean value_function loss: 78.5855
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 57.4141
                       Mean reward: 274.24
               Mean episode length: 236.46
    Episode_Reward/reaching_object: 1.2412
    Episode_Reward/rotating_object: 51.0268
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 2.04s
                      Time elapsed: 00:15:05
                               ETA: 00:37:58

################################################################################
                     [1m Learning iteration 427/1500 [0m                      

                       Computation: 46891 steps/s (collection: 1.986s, learning 0.110s)
             Mean action noise std: 2.22
          Mean value_function loss: 83.5420
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 57.4302
                       Mean reward: 245.29
               Mean episode length: 224.40
    Episode_Reward/reaching_object: 1.2593
    Episode_Reward/rotating_object: 49.7145
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 2.10s
                      Time elapsed: 00:15:07
                               ETA: 00:37:56

################################################################################
                     [1m Learning iteration 428/1500 [0m                      

                       Computation: 46674 steps/s (collection: 1.986s, learning 0.120s)
             Mean action noise std: 2.22
          Mean value_function loss: 72.9072
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 57.4437
                       Mean reward: 275.26
               Mean episode length: 238.23
    Episode_Reward/reaching_object: 1.2625
    Episode_Reward/rotating_object: 50.0616
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 2.11s
                      Time elapsed: 00:15:10
                               ETA: 00:37:54

################################################################################
                     [1m Learning iteration 429/1500 [0m                      

                       Computation: 46454 steps/s (collection: 1.990s, learning 0.126s)
             Mean action noise std: 2.22
          Mean value_function loss: 78.6490
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 57.4634
                       Mean reward: 245.19
               Mean episode length: 227.25
    Episode_Reward/reaching_object: 1.2500
    Episode_Reward/rotating_object: 51.8215
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 2.12s
                      Time elapsed: 00:15:12
                               ETA: 00:37:52

################################################################################
                     [1m Learning iteration 430/1500 [0m                      

                       Computation: 45782 steps/s (collection: 2.030s, learning 0.118s)
             Mean action noise std: 2.23
          Mean value_function loss: 74.1731
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 57.4867
                       Mean reward: 277.08
               Mean episode length: 237.41
    Episode_Reward/reaching_object: 1.3191
    Episode_Reward/rotating_object: 53.3124
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 2.15s
                      Time elapsed: 00:15:14
                               ETA: 00:37:50

################################################################################
                     [1m Learning iteration 431/1500 [0m                      

                       Computation: 47267 steps/s (collection: 1.966s, learning 0.114s)
             Mean action noise std: 2.23
          Mean value_function loss: 71.4090
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 57.5070
                       Mean reward: 259.91
               Mean episode length: 241.94
    Episode_Reward/reaching_object: 1.2960
    Episode_Reward/rotating_object: 53.5664
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 2.08s
                      Time elapsed: 00:15:16
                               ETA: 00:37:47

################################################################################
                     [1m Learning iteration 432/1500 [0m                      

                       Computation: 45734 steps/s (collection: 2.039s, learning 0.111s)
             Mean action noise std: 2.23
          Mean value_function loss: 74.1439
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 57.5348
                       Mean reward: 292.61
               Mean episode length: 240.68
    Episode_Reward/reaching_object: 1.3157
    Episode_Reward/rotating_object: 55.3041
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 2.15s
                      Time elapsed: 00:15:18
                               ETA: 00:37:45

################################################################################
                     [1m Learning iteration 433/1500 [0m                      

                       Computation: 46867 steps/s (collection: 1.985s, learning 0.113s)
             Mean action noise std: 2.23
          Mean value_function loss: 73.8602
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 57.5645
                       Mean reward: 283.08
               Mean episode length: 232.18
    Episode_Reward/reaching_object: 1.2879
    Episode_Reward/rotating_object: 53.6479
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 2.10s
                      Time elapsed: 00:15:20
                               ETA: 00:37:43

################################################################################
                     [1m Learning iteration 434/1500 [0m                      

                       Computation: 47534 steps/s (collection: 1.953s, learning 0.115s)
             Mean action noise std: 2.24
          Mean value_function loss: 77.0494
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 57.5872
                       Mean reward: 289.01
               Mean episode length: 231.02
    Episode_Reward/reaching_object: 1.2778
    Episode_Reward/rotating_object: 53.8977
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 2.07s
                      Time elapsed: 00:15:22
                               ETA: 00:37:41

################################################################################
                     [1m Learning iteration 435/1500 [0m                      

                       Computation: 47543 steps/s (collection: 1.955s, learning 0.113s)
             Mean action noise std: 2.24
          Mean value_function loss: 67.5753
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 57.6060
                       Mean reward: 292.12
               Mean episode length: 232.60
    Episode_Reward/reaching_object: 1.3015
    Episode_Reward/rotating_object: 55.2257
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 2.07s
                      Time elapsed: 00:15:24
                               ETA: 00:37:39

################################################################################
                     [1m Learning iteration 436/1500 [0m                      

                       Computation: 47165 steps/s (collection: 1.953s, learning 0.131s)
             Mean action noise std: 2.24
          Mean value_function loss: 69.6907
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 57.6182
                       Mean reward: 303.47
               Mean episode length: 229.21
    Episode_Reward/reaching_object: 1.2852
    Episode_Reward/rotating_object: 55.4028
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 2.08s
                      Time elapsed: 00:15:26
                               ETA: 00:37:36

################################################################################
                     [1m Learning iteration 437/1500 [0m                      

                       Computation: 47031 steps/s (collection: 1.979s, learning 0.112s)
             Mean action noise std: 2.24
          Mean value_function loss: 76.6546
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 57.6360
                       Mean reward: 274.99
               Mean episode length: 233.18
    Episode_Reward/reaching_object: 1.3039
    Episode_Reward/rotating_object: 58.7802
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 2.09s
                      Time elapsed: 00:15:29
                               ETA: 00:37:34

################################################################################
                     [1m Learning iteration 438/1500 [0m                      

                       Computation: 47005 steps/s (collection: 1.974s, learning 0.117s)
             Mean action noise std: 2.24
          Mean value_function loss: 80.5496
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 57.6584
                       Mean reward: 260.19
               Mean episode length: 226.16
    Episode_Reward/reaching_object: 1.2774
    Episode_Reward/rotating_object: 54.6701
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 2.09s
                      Time elapsed: 00:15:31
                               ETA: 00:37:32

################################################################################
                     [1m Learning iteration 439/1500 [0m                      

                       Computation: 45830 steps/s (collection: 2.032s, learning 0.113s)
             Mean action noise std: 2.24
          Mean value_function loss: 83.5697
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 57.6818
                       Mean reward: 294.87
               Mean episode length: 234.60
    Episode_Reward/reaching_object: 1.2793
    Episode_Reward/rotating_object: 56.3067
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 2.14s
                      Time elapsed: 00:15:33
                               ETA: 00:37:30

################################################################################
                     [1m Learning iteration 440/1500 [0m                      

                       Computation: 45031 steps/s (collection: 2.072s, learning 0.111s)
             Mean action noise std: 2.24
          Mean value_function loss: 81.4868
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 57.7002
                       Mean reward: 271.86
               Mean episode length: 234.80
    Episode_Reward/reaching_object: 1.2857
    Episode_Reward/rotating_object: 55.4506
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 2.18s
                      Time elapsed: 00:15:35
                               ETA: 00:37:28

################################################################################
                     [1m Learning iteration 441/1500 [0m                      

                       Computation: 44923 steps/s (collection: 2.073s, learning 0.116s)
             Mean action noise std: 2.25
          Mean value_function loss: 73.0192
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 57.7182
                       Mean reward: 268.91
               Mean episode length: 231.34
    Episode_Reward/reaching_object: 1.2671
    Episode_Reward/rotating_object: 52.9957
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 2.19s
                      Time elapsed: 00:15:37
                               ETA: 00:37:26

################################################################################
                     [1m Learning iteration 442/1500 [0m                      

                       Computation: 47549 steps/s (collection: 1.957s, learning 0.111s)
             Mean action noise std: 2.25
          Mean value_function loss: 78.2573
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 57.7340
                       Mean reward: 290.92
               Mean episode length: 236.59
    Episode_Reward/reaching_object: 1.2958
    Episode_Reward/rotating_object: 57.2940
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 2.07s
                      Time elapsed: 00:15:39
                               ETA: 00:37:24

################################################################################
                     [1m Learning iteration 443/1500 [0m                      

                       Computation: 48376 steps/s (collection: 1.922s, learning 0.110s)
             Mean action noise std: 2.25
          Mean value_function loss: 75.2842
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 57.7521
                       Mean reward: 304.65
               Mean episode length: 236.04
    Episode_Reward/reaching_object: 1.3083
    Episode_Reward/rotating_object: 57.6786
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 2.03s
                      Time elapsed: 00:15:41
                               ETA: 00:37:21

################################################################################
                     [1m Learning iteration 444/1500 [0m                      

                       Computation: 48440 steps/s (collection: 1.918s, learning 0.111s)
             Mean action noise std: 2.25
          Mean value_function loss: 60.0337
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 57.7694
                       Mean reward: 272.52
               Mean episode length: 235.52
    Episode_Reward/reaching_object: 1.2639
    Episode_Reward/rotating_object: 52.2165
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 2.03s
                      Time elapsed: 00:15:43
                               ETA: 00:37:19

################################################################################
                     [1m Learning iteration 445/1500 [0m                      

                       Computation: 47310 steps/s (collection: 1.963s, learning 0.115s)
             Mean action noise std: 2.25
          Mean value_function loss: 69.1715
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 57.7881
                       Mean reward: 285.89
               Mean episode length: 241.52
    Episode_Reward/reaching_object: 1.3046
    Episode_Reward/rotating_object: 57.9504
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 2.08s
                      Time elapsed: 00:15:45
                               ETA: 00:37:17

################################################################################
                     [1m Learning iteration 446/1500 [0m                      

                       Computation: 46690 steps/s (collection: 1.990s, learning 0.115s)
             Mean action noise std: 2.25
          Mean value_function loss: 71.2031
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 57.8052
                       Mean reward: 278.02
               Mean episode length: 238.21
    Episode_Reward/reaching_object: 1.2931
    Episode_Reward/rotating_object: 57.7367
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 2.11s
                      Time elapsed: 00:15:47
                               ETA: 00:37:15

################################################################################
                     [1m Learning iteration 447/1500 [0m                      

                       Computation: 47377 steps/s (collection: 1.960s, learning 0.115s)
             Mean action noise std: 2.26
          Mean value_function loss: 70.6306
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 57.8276
                       Mean reward: 281.45
               Mean episode length: 233.06
    Episode_Reward/reaching_object: 1.2964
    Episode_Reward/rotating_object: 57.8549
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 2.07s
                      Time elapsed: 00:15:49
                               ETA: 00:37:12

################################################################################
                     [1m Learning iteration 448/1500 [0m                      

                       Computation: 47738 steps/s (collection: 1.949s, learning 0.110s)
             Mean action noise std: 2.26
          Mean value_function loss: 73.7743
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 57.8526
                       Mean reward: 278.01
               Mean episode length: 231.12
    Episode_Reward/reaching_object: 1.2873
    Episode_Reward/rotating_object: 56.8743
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 2.06s
                      Time elapsed: 00:15:52
                               ETA: 00:37:10

################################################################################
                     [1m Learning iteration 449/1500 [0m                      

                       Computation: 47843 steps/s (collection: 1.944s, learning 0.111s)
             Mean action noise std: 2.26
          Mean value_function loss: 79.0565
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 57.8748
                       Mean reward: 325.94
               Mean episode length: 239.22
    Episode_Reward/reaching_object: 1.2940
    Episode_Reward/rotating_object: 58.1414
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 2.05s
                      Time elapsed: 00:15:54
                               ETA: 00:37:08

################################################################################
                     [1m Learning iteration 450/1500 [0m                      

                       Computation: 46200 steps/s (collection: 2.016s, learning 0.112s)
             Mean action noise std: 2.26
          Mean value_function loss: 76.5242
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 57.8948
                       Mean reward: 295.72
               Mean episode length: 227.92
    Episode_Reward/reaching_object: 1.2857
    Episode_Reward/rotating_object: 56.8154
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 2.13s
                      Time elapsed: 00:15:56
                               ETA: 00:37:06

################################################################################
                     [1m Learning iteration 451/1500 [0m                      

                       Computation: 47321 steps/s (collection: 1.965s, learning 0.112s)
             Mean action noise std: 2.26
          Mean value_function loss: 71.0824
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 57.9163
                       Mean reward: 315.21
               Mean episode length: 236.87
    Episode_Reward/reaching_object: 1.2775
    Episode_Reward/rotating_object: 59.9170
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 2.08s
                      Time elapsed: 00:15:58
                               ETA: 00:37:04

################################################################################
                     [1m Learning iteration 452/1500 [0m                      

                       Computation: 47444 steps/s (collection: 1.962s, learning 0.110s)
             Mean action noise std: 2.27
          Mean value_function loss: 77.8151
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 57.9360
                       Mean reward: 307.95
               Mean episode length: 237.21
    Episode_Reward/reaching_object: 1.2688
    Episode_Reward/rotating_object: 58.0870
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 2.07s
                      Time elapsed: 00:16:00
                               ETA: 00:37:01

################################################################################
                     [1m Learning iteration 453/1500 [0m                      

                       Computation: 47203 steps/s (collection: 1.969s, learning 0.113s)
             Mean action noise std: 2.27
          Mean value_function loss: 85.6237
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 57.9496
                       Mean reward: 337.65
               Mean episode length: 230.06
    Episode_Reward/reaching_object: 1.2637
    Episode_Reward/rotating_object: 58.0909
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 2.08s
                      Time elapsed: 00:16:02
                               ETA: 00:36:59

################################################################################
                     [1m Learning iteration 454/1500 [0m                      

                       Computation: 46666 steps/s (collection: 1.994s, learning 0.113s)
             Mean action noise std: 2.27
          Mean value_function loss: 79.3432
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 57.9739
                       Mean reward: 287.97
               Mean episode length: 228.76
    Episode_Reward/reaching_object: 1.2510
    Episode_Reward/rotating_object: 53.5731
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 2.11s
                      Time elapsed: 00:16:04
                               ETA: 00:36:57

################################################################################
                     [1m Learning iteration 455/1500 [0m                      

                       Computation: 47215 steps/s (collection: 1.971s, learning 0.111s)
             Mean action noise std: 2.27
          Mean value_function loss: 69.9024
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 57.9933
                       Mean reward: 270.76
               Mean episode length: 234.67
    Episode_Reward/reaching_object: 1.2772
    Episode_Reward/rotating_object: 57.3318
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 2.08s
                      Time elapsed: 00:16:06
                               ETA: 00:36:55

################################################################################
                     [1m Learning iteration 456/1500 [0m                      

                       Computation: 47564 steps/s (collection: 1.955s, learning 0.112s)
             Mean action noise std: 2.27
          Mean value_function loss: 67.8431
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 58.0100
                       Mean reward: 303.82
               Mean episode length: 234.87
    Episode_Reward/reaching_object: 1.2826
    Episode_Reward/rotating_object: 57.6359
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 2.07s
                      Time elapsed: 00:16:08
                               ETA: 00:36:53

################################################################################
                     [1m Learning iteration 457/1500 [0m                      

                       Computation: 47396 steps/s (collection: 1.963s, learning 0.111s)
             Mean action noise std: 2.27
          Mean value_function loss: 74.3371
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 58.0260
                       Mean reward: 271.46
               Mean episode length: 228.77
    Episode_Reward/reaching_object: 1.3079
    Episode_Reward/rotating_object: 60.4080
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 2.07s
                      Time elapsed: 00:16:10
                               ETA: 00:36:50

################################################################################
                     [1m Learning iteration 458/1500 [0m                      

                       Computation: 48111 steps/s (collection: 1.933s, learning 0.111s)
             Mean action noise std: 2.28
          Mean value_function loss: 73.7626
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 58.0515
                       Mean reward: 321.76
               Mean episode length: 239.78
    Episode_Reward/reaching_object: 1.2845
    Episode_Reward/rotating_object: 55.9111
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 2.04s
                      Time elapsed: 00:16:12
                               ETA: 00:36:48

################################################################################
                     [1m Learning iteration 459/1500 [0m                      

                       Computation: 47611 steps/s (collection: 1.954s, learning 0.110s)
             Mean action noise std: 2.28
          Mean value_function loss: 73.4615
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 58.0739
                       Mean reward: 266.64
               Mean episode length: 231.57
    Episode_Reward/reaching_object: 1.2681
    Episode_Reward/rotating_object: 55.8747
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 2.06s
                      Time elapsed: 00:16:14
                               ETA: 00:36:46

################################################################################
                     [1m Learning iteration 460/1500 [0m                      

                       Computation: 47827 steps/s (collection: 1.944s, learning 0.111s)
             Mean action noise std: 2.28
          Mean value_function loss: 81.4267
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 58.0884
                       Mean reward: 282.13
               Mean episode length: 231.40
    Episode_Reward/reaching_object: 1.2954
    Episode_Reward/rotating_object: 58.3603
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 2.06s
                      Time elapsed: 00:16:16
                               ETA: 00:36:43

################################################################################
                     [1m Learning iteration 461/1500 [0m                      

                       Computation: 47070 steps/s (collection: 1.975s, learning 0.113s)
             Mean action noise std: 2.28
          Mean value_function loss: 81.4895
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 58.1107
                       Mean reward: 274.56
               Mean episode length: 236.31
    Episode_Reward/reaching_object: 1.3303
    Episode_Reward/rotating_object: 60.4819
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 2.09s
                      Time elapsed: 00:16:19
                               ETA: 00:36:41

################################################################################
                     [1m Learning iteration 462/1500 [0m                      

                       Computation: 45380 steps/s (collection: 2.053s, learning 0.114s)
             Mean action noise std: 2.28
          Mean value_function loss: 68.9043
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 58.1307
                       Mean reward: 252.88
               Mean episode length: 226.23
    Episode_Reward/reaching_object: 1.3061
    Episode_Reward/rotating_object: 60.0072
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 2.17s
                      Time elapsed: 00:16:21
                               ETA: 00:36:39

################################################################################
                     [1m Learning iteration 463/1500 [0m                      

                       Computation: 44627 steps/s (collection: 2.090s, learning 0.112s)
             Mean action noise std: 2.29
          Mean value_function loss: 80.9686
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 58.1464
                       Mean reward: 314.46
               Mean episode length: 228.87
    Episode_Reward/reaching_object: 1.3106
    Episode_Reward/rotating_object: 63.5798
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 2.20s
                      Time elapsed: 00:16:23
                               ETA: 00:36:37

################################################################################
                     [1m Learning iteration 464/1500 [0m                      

                       Computation: 46751 steps/s (collection: 1.981s, learning 0.122s)
             Mean action noise std: 2.29
          Mean value_function loss: 69.5507
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 58.1692
                       Mean reward: 325.77
               Mean episode length: 239.69
    Episode_Reward/reaching_object: 1.3165
    Episode_Reward/rotating_object: 64.0853
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 2.10s
                      Time elapsed: 00:16:25
                               ETA: 00:36:35

################################################################################
                     [1m Learning iteration 465/1500 [0m                      

                       Computation: 48063 steps/s (collection: 1.934s, learning 0.111s)
             Mean action noise std: 2.29
          Mean value_function loss: 74.5601
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 58.1940
                       Mean reward: 279.80
               Mean episode length: 234.55
    Episode_Reward/reaching_object: 1.2602
    Episode_Reward/rotating_object: 55.1630
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 2.05s
                      Time elapsed: 00:16:27
                               ETA: 00:36:33

################################################################################
                     [1m Learning iteration 466/1500 [0m                      

                       Computation: 48315 steps/s (collection: 1.924s, learning 0.111s)
             Mean action noise std: 2.29
          Mean value_function loss: 80.5876
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 58.2071
                       Mean reward: 319.39
               Mean episode length: 237.77
    Episode_Reward/reaching_object: 1.3099
    Episode_Reward/rotating_object: 62.0835
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 2.03s
                      Time elapsed: 00:16:29
                               ETA: 00:36:31

################################################################################
                     [1m Learning iteration 467/1500 [0m                      

                       Computation: 48779 steps/s (collection: 1.904s, learning 0.111s)
             Mean action noise std: 2.29
          Mean value_function loss: 71.7862
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 58.2212
                       Mean reward: 296.26
               Mean episode length: 234.12
    Episode_Reward/reaching_object: 1.2786
    Episode_Reward/rotating_object: 60.7593
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 2.02s
                      Time elapsed: 00:16:31
                               ETA: 00:36:28

################################################################################
                     [1m Learning iteration 468/1500 [0m                      

                       Computation: 48413 steps/s (collection: 1.920s, learning 0.111s)
             Mean action noise std: 2.29
          Mean value_function loss: 72.0395
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 58.2398
                       Mean reward: 294.31
               Mean episode length: 237.84
    Episode_Reward/reaching_object: 1.3033
    Episode_Reward/rotating_object: 60.0808
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 2.03s
                      Time elapsed: 00:16:33
                               ETA: 00:36:26

################################################################################
                     [1m Learning iteration 469/1500 [0m                      

                       Computation: 48539 steps/s (collection: 1.911s, learning 0.114s)
             Mean action noise std: 2.30
          Mean value_function loss: 77.4931
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 58.2590
                       Mean reward: 295.25
               Mean episode length: 234.69
    Episode_Reward/reaching_object: 1.2995
    Episode_Reward/rotating_object: 60.8031
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 2.03s
                      Time elapsed: 00:16:35
                               ETA: 00:36:24

################################################################################
                     [1m Learning iteration 470/1500 [0m                      

                       Computation: 48655 steps/s (collection: 1.910s, learning 0.111s)
             Mean action noise std: 2.30
          Mean value_function loss: 73.5561
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 58.2741
                       Mean reward: 290.77
               Mean episode length: 224.59
    Episode_Reward/reaching_object: 1.2611
    Episode_Reward/rotating_object: 59.3907
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 2.02s
                      Time elapsed: 00:16:37
                               ETA: 00:36:21

################################################################################
                     [1m Learning iteration 471/1500 [0m                      

                       Computation: 48269 steps/s (collection: 1.926s, learning 0.111s)
             Mean action noise std: 2.30
          Mean value_function loss: 77.0968
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 58.2877
                       Mean reward: 312.53
               Mean episode length: 232.61
    Episode_Reward/reaching_object: 1.2574
    Episode_Reward/rotating_object: 57.8374
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 2.04s
                      Time elapsed: 00:16:39
                               ETA: 00:36:19

################################################################################
                     [1m Learning iteration 472/1500 [0m                      

                       Computation: 48642 steps/s (collection: 1.910s, learning 0.111s)
             Mean action noise std: 2.30
          Mean value_function loss: 69.3215
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 58.3070
                       Mean reward: 292.39
               Mean episode length: 225.71
    Episode_Reward/reaching_object: 1.2830
    Episode_Reward/rotating_object: 60.2331
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 2.02s
                      Time elapsed: 00:16:41
                               ETA: 00:36:17

################################################################################
                     [1m Learning iteration 473/1500 [0m                      

                       Computation: 47443 steps/s (collection: 1.960s, learning 0.112s)
             Mean action noise std: 2.30
          Mean value_function loss: 75.6901
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 58.3315
                       Mean reward: 316.05
               Mean episode length: 234.26
    Episode_Reward/reaching_object: 1.3237
    Episode_Reward/rotating_object: 64.8578
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 2.07s
                      Time elapsed: 00:16:43
                               ETA: 00:36:14

################################################################################
                     [1m Learning iteration 474/1500 [0m                      

                       Computation: 48187 steps/s (collection: 1.927s, learning 0.113s)
             Mean action noise std: 2.30
          Mean value_function loss: 68.6727
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 58.3491
                       Mean reward: 282.58
               Mean episode length: 232.77
    Episode_Reward/reaching_object: 1.3169
    Episode_Reward/rotating_object: 59.5492
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 2.04s
                      Time elapsed: 00:16:45
                               ETA: 00:36:12

################################################################################
                     [1m Learning iteration 475/1500 [0m                      

                       Computation: 44440 steps/s (collection: 2.085s, learning 0.127s)
             Mean action noise std: 2.31
          Mean value_function loss: 68.8730
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 58.3665
                       Mean reward: 266.83
               Mean episode length: 217.18
    Episode_Reward/reaching_object: 1.2421
    Episode_Reward/rotating_object: 57.5871
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 2.21s
                      Time elapsed: 00:16:48
                               ETA: 00:36:10

################################################################################
                     [1m Learning iteration 476/1500 [0m                      

                       Computation: 44005 steps/s (collection: 2.094s, learning 0.140s)
             Mean action noise std: 2.31
          Mean value_function loss: 73.0999
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 58.3878
                       Mean reward: 301.76
               Mean episode length: 238.35
    Episode_Reward/reaching_object: 1.3184
    Episode_Reward/rotating_object: 58.9513
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 2.23s
                      Time elapsed: 00:16:50
                               ETA: 00:36:08

################################################################################
                     [1m Learning iteration 477/1500 [0m                      

                       Computation: 44068 steps/s (collection: 2.106s, learning 0.125s)
             Mean action noise std: 2.31
          Mean value_function loss: 84.5030
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 58.4049
                       Mean reward: 268.54
               Mean episode length: 231.40
    Episode_Reward/reaching_object: 1.2916
    Episode_Reward/rotating_object: 58.6071
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 2.23s
                      Time elapsed: 00:16:52
                               ETA: 00:36:07

################################################################################
                     [1m Learning iteration 478/1500 [0m                      

                       Computation: 44076 steps/s (collection: 2.100s, learning 0.130s)
             Mean action noise std: 2.31
          Mean value_function loss: 81.9693
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 58.4261
                       Mean reward: 315.93
               Mean episode length: 226.54
    Episode_Reward/reaching_object: 1.3052
    Episode_Reward/rotating_object: 60.7739
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 2.23s
                      Time elapsed: 00:16:54
                               ETA: 00:36:05

################################################################################
                     [1m Learning iteration 479/1500 [0m                      

                       Computation: 43819 steps/s (collection: 2.115s, learning 0.128s)
             Mean action noise std: 2.31
          Mean value_function loss: 81.2619
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 58.4443
                       Mean reward: 273.65
               Mean episode length: 229.30
    Episode_Reward/reaching_object: 1.2665
    Episode_Reward/rotating_object: 59.2170
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 2.24s
                      Time elapsed: 00:16:57
                               ETA: 00:36:03

################################################################################
                     [1m Learning iteration 480/1500 [0m                      

                       Computation: 43973 steps/s (collection: 2.108s, learning 0.127s)
             Mean action noise std: 2.31
          Mean value_function loss: 73.4260
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 58.4600
                       Mean reward: 290.13
               Mean episode length: 214.52
    Episode_Reward/reaching_object: 1.2945
    Episode_Reward/rotating_object: 61.2167
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 2.24s
                      Time elapsed: 00:16:59
                               ETA: 00:36:01

################################################################################
                     [1m Learning iteration 481/1500 [0m                      

                       Computation: 43821 steps/s (collection: 2.115s, learning 0.128s)
             Mean action noise std: 2.32
          Mean value_function loss: 80.5770
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 58.4756
                       Mean reward: 353.83
               Mean episode length: 236.56
    Episode_Reward/reaching_object: 1.2729
    Episode_Reward/rotating_object: 59.5654
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 2.24s
                      Time elapsed: 00:17:01
                               ETA: 00:35:59

################################################################################
                     [1m Learning iteration 482/1500 [0m                      

                       Computation: 44148 steps/s (collection: 2.097s, learning 0.129s)
             Mean action noise std: 2.32
          Mean value_function loss: 73.7912
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 58.4999
                       Mean reward: 322.58
               Mean episode length: 227.14
    Episode_Reward/reaching_object: 1.3219
    Episode_Reward/rotating_object: 65.3160
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 2.23s
                      Time elapsed: 00:17:03
                               ETA: 00:35:57

################################################################################
                     [1m Learning iteration 483/1500 [0m                      

                       Computation: 43811 steps/s (collection: 2.117s, learning 0.127s)
             Mean action noise std: 2.32
          Mean value_function loss: 80.0226
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 58.5233
                       Mean reward: 314.46
               Mean episode length: 228.95
    Episode_Reward/reaching_object: 1.2910
    Episode_Reward/rotating_object: 60.2805
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 2.24s
                      Time elapsed: 00:17:05
                               ETA: 00:35:55

################################################################################
                     [1m Learning iteration 484/1500 [0m                      

                       Computation: 43898 steps/s (collection: 2.107s, learning 0.132s)
             Mean action noise std: 2.32
          Mean value_function loss: 79.7947
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 58.5390
                       Mean reward: 338.31
               Mean episode length: 240.04
    Episode_Reward/reaching_object: 1.3251
    Episode_Reward/rotating_object: 61.1725
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 2.24s
                      Time elapsed: 00:17:08
                               ETA: 00:35:53

################################################################################
                     [1m Learning iteration 485/1500 [0m                      

                       Computation: 47887 steps/s (collection: 1.923s, learning 0.129s)
             Mean action noise std: 2.32
          Mean value_function loss: 80.5472
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 58.5585
                       Mean reward: 319.27
               Mean episode length: 230.84
    Episode_Reward/reaching_object: 1.2922
    Episode_Reward/rotating_object: 62.6347
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 2.05s
                      Time elapsed: 00:17:10
                               ETA: 00:35:51

################################################################################
                     [1m Learning iteration 486/1500 [0m                      

                       Computation: 48284 steps/s (collection: 1.921s, learning 0.114s)
             Mean action noise std: 2.32
          Mean value_function loss: 71.0878
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 58.5759
                       Mean reward: 291.22
               Mean episode length: 233.68
    Episode_Reward/reaching_object: 1.3001
    Episode_Reward/rotating_object: 61.8075
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 2.04s
                      Time elapsed: 00:17:12
                               ETA: 00:35:49

################################################################################
                     [1m Learning iteration 487/1500 [0m                      

                       Computation: 46582 steps/s (collection: 1.997s, learning 0.113s)
             Mean action noise std: 2.33
          Mean value_function loss: 78.4223
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 58.5918
                       Mean reward: 345.16
               Mean episode length: 230.35
    Episode_Reward/reaching_object: 1.3197
    Episode_Reward/rotating_object: 63.6848
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 2.11s
                      Time elapsed: 00:17:14
                               ETA: 00:35:47

################################################################################
                     [1m Learning iteration 488/1500 [0m                      

                       Computation: 46959 steps/s (collection: 1.983s, learning 0.110s)
             Mean action noise std: 2.33
          Mean value_function loss: 76.3341
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 58.6162
                       Mean reward: 318.21
               Mean episode length: 228.59
    Episode_Reward/reaching_object: 1.3017
    Episode_Reward/rotating_object: 60.9000
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 2.09s
                      Time elapsed: 00:17:16
                               ETA: 00:35:45

################################################################################
                     [1m Learning iteration 489/1500 [0m                      

                       Computation: 48953 steps/s (collection: 1.898s, learning 0.110s)
             Mean action noise std: 2.33
          Mean value_function loss: 65.6753
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 58.6470
                       Mean reward: 334.69
               Mean episode length: 240.33
    Episode_Reward/reaching_object: 1.2987
    Episode_Reward/rotating_object: 63.0344
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 2.01s
                      Time elapsed: 00:17:18
                               ETA: 00:35:42

################################################################################
                     [1m Learning iteration 490/1500 [0m                      

                       Computation: 49277 steps/s (collection: 1.885s, learning 0.110s)
             Mean action noise std: 2.33
          Mean value_function loss: 76.7564
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 58.6710
                       Mean reward: 285.34
               Mean episode length: 226.82
    Episode_Reward/reaching_object: 1.2822
    Episode_Reward/rotating_object: 63.5057
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 1.99s
                      Time elapsed: 00:17:20
                               ETA: 00:35:40

################################################################################
                     [1m Learning iteration 491/1500 [0m                      

                       Computation: 49405 steps/s (collection: 1.878s, learning 0.111s)
             Mean action noise std: 2.34
          Mean value_function loss: 72.5606
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 58.6894
                       Mean reward: 339.25
               Mean episode length: 234.31
    Episode_Reward/reaching_object: 1.2889
    Episode_Reward/rotating_object: 62.1028
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 1.99s
                      Time elapsed: 00:17:22
                               ETA: 00:35:37

################################################################################
                     [1m Learning iteration 492/1500 [0m                      

                       Computation: 48974 steps/s (collection: 1.897s, learning 0.110s)
             Mean action noise std: 2.34
          Mean value_function loss: 84.6632
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 58.7171
                       Mean reward: 285.34
               Mean episode length: 232.70
    Episode_Reward/reaching_object: 1.2782
    Episode_Reward/rotating_object: 58.3878
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 2.01s
                      Time elapsed: 00:17:24
                               ETA: 00:35:35

################################################################################
                     [1m Learning iteration 493/1500 [0m                      

                       Computation: 49817 steps/s (collection: 1.864s, learning 0.110s)
             Mean action noise std: 2.34
          Mean value_function loss: 77.9174
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 58.7365
                       Mean reward: 322.98
               Mean episode length: 232.63
    Episode_Reward/reaching_object: 1.2922
    Episode_Reward/rotating_object: 63.7076
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 1.97s
                      Time elapsed: 00:17:26
                               ETA: 00:35:33

################################################################################
                     [1m Learning iteration 494/1500 [0m                      

                       Computation: 48889 steps/s (collection: 1.900s, learning 0.111s)
             Mean action noise std: 2.34
          Mean value_function loss: 72.8176
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 58.7556
                       Mean reward: 312.44
               Mean episode length: 227.58
    Episode_Reward/reaching_object: 1.3004
    Episode_Reward/rotating_object: 66.1156
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 2.01s
                      Time elapsed: 00:17:28
                               ETA: 00:35:30

################################################################################
                     [1m Learning iteration 495/1500 [0m                      

                       Computation: 49049 steps/s (collection: 1.894s, learning 0.110s)
             Mean action noise std: 2.34
          Mean value_function loss: 65.5086
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 58.7744
                       Mean reward: 334.09
               Mean episode length: 240.20
    Episode_Reward/reaching_object: 1.2998
    Episode_Reward/rotating_object: 64.2483
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 2.00s
                      Time elapsed: 00:17:30
                               ETA: 00:35:28

################################################################################
                     [1m Learning iteration 496/1500 [0m                      

                       Computation: 48193 steps/s (collection: 1.930s, learning 0.110s)
             Mean action noise std: 2.35
          Mean value_function loss: 79.9111
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 58.7963
                       Mean reward: 315.37
               Mean episode length: 238.13
    Episode_Reward/reaching_object: 1.2989
    Episode_Reward/rotating_object: 63.0266
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 2.04s
                      Time elapsed: 00:17:32
                               ETA: 00:35:26

################################################################################
                     [1m Learning iteration 497/1500 [0m                      

                       Computation: 48439 steps/s (collection: 1.914s, learning 0.116s)
             Mean action noise std: 2.35
          Mean value_function loss: 78.0262
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 58.8137
                       Mean reward: 325.12
               Mean episode length: 233.82
    Episode_Reward/reaching_object: 1.3074
    Episode_Reward/rotating_object: 64.2979
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 2.03s
                      Time elapsed: 00:17:34
                               ETA: 00:35:23

################################################################################
                     [1m Learning iteration 498/1500 [0m                      

                       Computation: 47692 steps/s (collection: 1.948s, learning 0.113s)
             Mean action noise std: 2.35
          Mean value_function loss: 79.0644
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 58.8266
                       Mean reward: 310.39
               Mean episode length: 234.87
    Episode_Reward/reaching_object: 1.2786
    Episode_Reward/rotating_object: 58.8997
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 2.06s
                      Time elapsed: 00:17:36
                               ETA: 00:35:21

################################################################################
                     [1m Learning iteration 499/1500 [0m                      

                       Computation: 46868 steps/s (collection: 1.987s, learning 0.111s)
             Mean action noise std: 2.35
          Mean value_function loss: 78.9396
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 58.8481
                       Mean reward: 347.70
               Mean episode length: 239.16
    Episode_Reward/reaching_object: 1.3012
    Episode_Reward/rotating_object: 65.5348
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 2.10s
                      Time elapsed: 00:17:38
                               ETA: 00:35:19

################################################################################
                     [1m Learning iteration 500/1500 [0m                      

                       Computation: 45212 steps/s (collection: 2.057s, learning 0.118s)
             Mean action noise std: 2.35
          Mean value_function loss: 75.2304
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 58.8677
                       Mean reward: 315.80
               Mean episode length: 233.19
    Episode_Reward/reaching_object: 1.3042
    Episode_Reward/rotating_object: 62.3666
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 2.17s
                      Time elapsed: 00:17:40
                               ETA: 00:35:17

################################################################################
                     [1m Learning iteration 501/1500 [0m                      

                       Computation: 45741 steps/s (collection: 2.035s, learning 0.114s)
             Mean action noise std: 2.35
          Mean value_function loss: 72.3210
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 58.8861
                       Mean reward: 315.53
               Mean episode length: 242.98
    Episode_Reward/reaching_object: 1.3296
    Episode_Reward/rotating_object: 64.3273
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 2.15s
                      Time elapsed: 00:17:43
                               ETA: 00:35:15

################################################################################
                     [1m Learning iteration 502/1500 [0m                      

                       Computation: 45754 steps/s (collection: 2.039s, learning 0.110s)
             Mean action noise std: 2.36
          Mean value_function loss: 80.3110
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 58.9070
                       Mean reward: 342.51
               Mean episode length: 234.61
    Episode_Reward/reaching_object: 1.3246
    Episode_Reward/rotating_object: 67.1636
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 2.15s
                      Time elapsed: 00:17:45
                               ETA: 00:35:13

################################################################################
                     [1m Learning iteration 503/1500 [0m                      

                       Computation: 45755 steps/s (collection: 2.034s, learning 0.114s)
             Mean action noise std: 2.36
          Mean value_function loss: 72.8498
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 58.9314
                       Mean reward: 360.62
               Mean episode length: 238.88
    Episode_Reward/reaching_object: 1.3266
    Episode_Reward/rotating_object: 62.2578
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 2.15s
                      Time elapsed: 00:17:47
                               ETA: 00:35:11

################################################################################
                     [1m Learning iteration 504/1500 [0m                      

                       Computation: 45663 steps/s (collection: 2.030s, learning 0.123s)
             Mean action noise std: 2.36
          Mean value_function loss: 77.8477
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 58.9481
                       Mean reward: 332.99
               Mean episode length: 242.07
    Episode_Reward/reaching_object: 1.3133
    Episode_Reward/rotating_object: 64.0955
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 2.15s
                      Time elapsed: 00:17:49
                               ETA: 00:35:09

################################################################################
                     [1m Learning iteration 505/1500 [0m                      

                       Computation: 45840 steps/s (collection: 2.034s, learning 0.110s)
             Mean action noise std: 2.36
          Mean value_function loss: 77.9326
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 58.9679
                       Mean reward: 333.91
               Mean episode length: 238.20
    Episode_Reward/reaching_object: 1.3373
    Episode_Reward/rotating_object: 66.3495
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 2.14s
                      Time elapsed: 00:17:51
                               ETA: 00:35:07

################################################################################
                     [1m Learning iteration 506/1500 [0m                      

                       Computation: 45182 steps/s (collection: 2.063s, learning 0.113s)
             Mean action noise std: 2.36
          Mean value_function loss: 70.5910
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 58.9900
                       Mean reward: 321.96
               Mean episode length: 237.88
    Episode_Reward/reaching_object: 1.3399
    Episode_Reward/rotating_object: 64.6370
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 2.18s
                      Time elapsed: 00:17:53
                               ETA: 00:35:05

################################################################################
                     [1m Learning iteration 507/1500 [0m                      

                       Computation: 47508 steps/s (collection: 1.956s, learning 0.113s)
             Mean action noise std: 2.37
          Mean value_function loss: 71.1307
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 59.0157
                       Mean reward: 345.51
               Mean episode length: 241.94
    Episode_Reward/reaching_object: 1.3474
    Episode_Reward/rotating_object: 66.6800
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 2.07s
                      Time elapsed: 00:17:55
                               ETA: 00:35:03

################################################################################
                     [1m Learning iteration 508/1500 [0m                      

                       Computation: 45513 steps/s (collection: 2.044s, learning 0.115s)
             Mean action noise std: 2.37
          Mean value_function loss: 78.2407
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 59.0377
                       Mean reward: 313.72
               Mean episode length: 236.58
    Episode_Reward/reaching_object: 1.3251
    Episode_Reward/rotating_object: 63.3722
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 2.16s
                      Time elapsed: 00:17:58
                               ETA: 00:35:01

################################################################################
                     [1m Learning iteration 509/1500 [0m                      

                       Computation: 45886 steps/s (collection: 2.029s, learning 0.114s)
             Mean action noise std: 2.37
          Mean value_function loss: 75.8401
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 59.0647
                       Mean reward: 290.23
               Mean episode length: 243.40
    Episode_Reward/reaching_object: 1.3253
    Episode_Reward/rotating_object: 63.8307
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 2.14s
                      Time elapsed: 00:18:00
                               ETA: 00:34:58

################################################################################
                     [1m Learning iteration 510/1500 [0m                      

                       Computation: 46363 steps/s (collection: 2.008s, learning 0.112s)
             Mean action noise std: 2.37
          Mean value_function loss: 79.1325
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 59.1020
                       Mean reward: 362.50
               Mean episode length: 238.61
    Episode_Reward/reaching_object: 1.3238
    Episode_Reward/rotating_object: 64.5891
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 2.12s
                      Time elapsed: 00:18:02
                               ETA: 00:34:56

################################################################################
                     [1m Learning iteration 511/1500 [0m                      

                       Computation: 46287 steps/s (collection: 2.014s, learning 0.110s)
             Mean action noise std: 2.38
          Mean value_function loss: 70.8838
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 59.1266
                       Mean reward: 326.01
               Mean episode length: 239.71
    Episode_Reward/reaching_object: 1.3528
    Episode_Reward/rotating_object: 68.7757
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 2.12s
                      Time elapsed: 00:18:04
                               ETA: 00:34:54

################################################################################
                     [1m Learning iteration 512/1500 [0m                      

                       Computation: 47823 steps/s (collection: 1.946s, learning 0.110s)
             Mean action noise std: 2.38
          Mean value_function loss: 80.9212
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 59.1548
                       Mean reward: 304.84
               Mean episode length: 233.16
    Episode_Reward/reaching_object: 1.3204
    Episode_Reward/rotating_object: 64.1048
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 2.06s
                      Time elapsed: 00:18:06
                               ETA: 00:34:52

################################################################################
                     [1m Learning iteration 513/1500 [0m                      

                       Computation: 48988 steps/s (collection: 1.896s, learning 0.111s)
             Mean action noise std: 2.38
          Mean value_function loss: 77.9944
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 59.1827
                       Mean reward: 320.82
               Mean episode length: 238.33
    Episode_Reward/reaching_object: 1.3122
    Episode_Reward/rotating_object: 62.5983
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 2.01s
                      Time elapsed: 00:18:08
                               ETA: 00:34:50

################################################################################
                     [1m Learning iteration 514/1500 [0m                      

                       Computation: 49323 steps/s (collection: 1.883s, learning 0.110s)
             Mean action noise std: 2.38
          Mean value_function loss: 69.3077
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 59.2065
                       Mean reward: 334.42
               Mean episode length: 231.89
    Episode_Reward/reaching_object: 1.3429
    Episode_Reward/rotating_object: 64.4688
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 1.99s
                      Time elapsed: 00:18:10
                               ETA: 00:34:47

################################################################################
                     [1m Learning iteration 515/1500 [0m                      

                       Computation: 48901 steps/s (collection: 1.900s, learning 0.110s)
             Mean action noise std: 2.39
          Mean value_function loss: 80.3880
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 59.2246
                       Mean reward: 325.57
               Mean episode length: 230.93
    Episode_Reward/reaching_object: 1.3119
    Episode_Reward/rotating_object: 64.9677
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 2.01s
                      Time elapsed: 00:18:12
                               ETA: 00:34:45

################################################################################
                     [1m Learning iteration 516/1500 [0m                      

                       Computation: 48990 steps/s (collection: 1.875s, learning 0.132s)
             Mean action noise std: 2.39
          Mean value_function loss: 77.6433
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 59.2528
                       Mean reward: 307.62
               Mean episode length: 231.36
    Episode_Reward/reaching_object: 1.3261
    Episode_Reward/rotating_object: 69.0891
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 2.01s
                      Time elapsed: 00:18:14
                               ETA: 00:34:43

################################################################################
                     [1m Learning iteration 517/1500 [0m                      

                       Computation: 49272 steps/s (collection: 1.885s, learning 0.110s)
             Mean action noise std: 2.39
          Mean value_function loss: 71.6912
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 59.2789
                       Mean reward: 347.50
               Mean episode length: 237.82
    Episode_Reward/reaching_object: 1.3670
    Episode_Reward/rotating_object: 71.8376
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 2.00s
                      Time elapsed: 00:18:16
                               ETA: 00:34:40

################################################################################
                     [1m Learning iteration 518/1500 [0m                      

                       Computation: 49209 steps/s (collection: 1.887s, learning 0.110s)
             Mean action noise std: 2.39
          Mean value_function loss: 83.9241
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 59.2968
                       Mean reward: 332.65
               Mean episode length: 233.35
    Episode_Reward/reaching_object: 1.3335
    Episode_Reward/rotating_object: 63.0569
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 2.00s
                      Time elapsed: 00:18:18
                               ETA: 00:34:38

################################################################################
                     [1m Learning iteration 519/1500 [0m                      

                       Computation: 46930 steps/s (collection: 1.985s, learning 0.110s)
             Mean action noise std: 2.40
          Mean value_function loss: 69.2268
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 59.3154
                       Mean reward: 341.34
               Mean episode length: 233.68
    Episode_Reward/reaching_object: 1.3370
    Episode_Reward/rotating_object: 68.3690
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 2.09s
                      Time elapsed: 00:18:20
                               ETA: 00:34:36

################################################################################
                     [1m Learning iteration 520/1500 [0m                      

                       Computation: 46936 steps/s (collection: 1.981s, learning 0.113s)
             Mean action noise std: 2.40
          Mean value_function loss: 73.3076
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 59.3358
                       Mean reward: 341.85
               Mean episode length: 234.26
    Episode_Reward/reaching_object: 1.3429
    Episode_Reward/rotating_object: 67.0328
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 2.09s
                      Time elapsed: 00:18:22
                               ETA: 00:34:34

################################################################################
                     [1m Learning iteration 521/1500 [0m                      

                       Computation: 47572 steps/s (collection: 1.956s, learning 0.110s)
             Mean action noise std: 2.40
          Mean value_function loss: 70.6328
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 59.3579
                       Mean reward: 330.56
               Mean episode length: 234.54
    Episode_Reward/reaching_object: 1.3505
    Episode_Reward/rotating_object: 68.5705
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 2.07s
                      Time elapsed: 00:18:24
                               ETA: 00:34:31

################################################################################
                     [1m Learning iteration 522/1500 [0m                      

                       Computation: 46404 steps/s (collection: 2.006s, learning 0.113s)
             Mean action noise std: 2.40
          Mean value_function loss: 74.2604
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 59.3860
                       Mean reward: 337.22
               Mean episode length: 234.10
    Episode_Reward/reaching_object: 1.3098
    Episode_Reward/rotating_object: 66.7256
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 2.12s
                      Time elapsed: 00:18:26
                               ETA: 00:34:29

################################################################################
                     [1m Learning iteration 523/1500 [0m                      

                       Computation: 46852 steps/s (collection: 1.985s, learning 0.114s)
             Mean action noise std: 2.41
          Mean value_function loss: 78.7945
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 59.4169
                       Mean reward: 369.44
               Mean episode length: 241.33
    Episode_Reward/reaching_object: 1.2973
    Episode_Reward/rotating_object: 62.8260
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 2.10s
                      Time elapsed: 00:18:28
                               ETA: 00:34:27

################################################################################
                     [1m Learning iteration 524/1500 [0m                      

                       Computation: 48187 steps/s (collection: 1.928s, learning 0.112s)
             Mean action noise std: 2.41
          Mean value_function loss: 77.0415
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 59.4384
                       Mean reward: 378.26
               Mean episode length: 238.45
    Episode_Reward/reaching_object: 1.3240
    Episode_Reward/rotating_object: 68.8477
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 2.04s
                      Time elapsed: 00:18:30
                               ETA: 00:34:25

################################################################################
                     [1m Learning iteration 525/1500 [0m                      

                       Computation: 49021 steps/s (collection: 1.893s, learning 0.112s)
             Mean action noise std: 2.41
          Mean value_function loss: 85.1357
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 59.4551
                       Mean reward: 377.52
               Mean episode length: 237.87
    Episode_Reward/reaching_object: 1.3329
    Episode_Reward/rotating_object: 67.6849
        Episode_Reward/action_rate: -0.0355
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 2.01s
                      Time elapsed: 00:18:33
                               ETA: 00:34:23

################################################################################
                     [1m Learning iteration 526/1500 [0m                      

                       Computation: 48666 steps/s (collection: 1.910s, learning 0.110s)
             Mean action noise std: 2.41
          Mean value_function loss: 75.6679
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 59.4830
                       Mean reward: 347.04
               Mean episode length: 236.22
    Episode_Reward/reaching_object: 1.3050
    Episode_Reward/rotating_object: 66.0560
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 2.02s
                      Time elapsed: 00:18:35
                               ETA: 00:34:20

################################################################################
                     [1m Learning iteration 527/1500 [0m                      

                       Computation: 48468 steps/s (collection: 1.915s, learning 0.113s)
             Mean action noise std: 2.41
          Mean value_function loss: 86.3514
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 59.5142
                       Mean reward: 341.01
               Mean episode length: 229.81
    Episode_Reward/reaching_object: 1.3465
    Episode_Reward/rotating_object: 69.6027
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 2.03s
                      Time elapsed: 00:18:37
                               ETA: 00:34:18

################################################################################
                     [1m Learning iteration 528/1500 [0m                      

                       Computation: 48582 steps/s (collection: 1.909s, learning 0.115s)
             Mean action noise std: 2.42
          Mean value_function loss: 81.1887
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 59.5367
                       Mean reward: 353.03
               Mean episode length: 230.56
    Episode_Reward/reaching_object: 1.3350
    Episode_Reward/rotating_object: 70.9662
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 2.02s
                      Time elapsed: 00:18:39
                               ETA: 00:34:16

################################################################################
                     [1m Learning iteration 529/1500 [0m                      

                       Computation: 48950 steps/s (collection: 1.898s, learning 0.110s)
             Mean action noise std: 2.42
          Mean value_function loss: 66.4393
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 59.5607
                       Mean reward: 337.64
               Mean episode length: 231.52
    Episode_Reward/reaching_object: 1.3191
    Episode_Reward/rotating_object: 66.7258
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 2.01s
                      Time elapsed: 00:18:41
                               ETA: 00:34:13

################################################################################
                     [1m Learning iteration 530/1500 [0m                      

                       Computation: 48323 steps/s (collection: 1.917s, learning 0.117s)
             Mean action noise std: 2.42
          Mean value_function loss: 79.5354
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 59.5853
                       Mean reward: 344.95
               Mean episode length: 236.97
    Episode_Reward/reaching_object: 1.3217
    Episode_Reward/rotating_object: 65.0580
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 2.03s
                      Time elapsed: 00:18:43
                               ETA: 00:34:11

################################################################################
                     [1m Learning iteration 531/1500 [0m                      

                       Computation: 48788 steps/s (collection: 1.904s, learning 0.111s)
             Mean action noise std: 2.42
          Mean value_function loss: 83.9538
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 59.6054
                       Mean reward: 301.12
               Mean episode length: 227.30
    Episode_Reward/reaching_object: 1.3112
    Episode_Reward/rotating_object: 62.7272
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 2.01s
                      Time elapsed: 00:18:45
                               ETA: 00:34:09

################################################################################
                     [1m Learning iteration 532/1500 [0m                      

                       Computation: 47720 steps/s (collection: 1.950s, learning 0.110s)
             Mean action noise std: 2.43
          Mean value_function loss: 72.5016
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 59.6266
                       Mean reward: 332.33
               Mean episode length: 237.97
    Episode_Reward/reaching_object: 1.3532
    Episode_Reward/rotating_object: 70.6923
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 2.06s
                      Time elapsed: 00:18:47
                               ETA: 00:34:07

################################################################################
                     [1m Learning iteration 533/1500 [0m                      

                       Computation: 48521 steps/s (collection: 1.915s, learning 0.111s)
             Mean action noise std: 2.43
          Mean value_function loss: 73.3305
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 59.6473
                       Mean reward: 300.89
               Mean episode length: 227.29
    Episode_Reward/reaching_object: 1.3128
    Episode_Reward/rotating_object: 67.1484
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 2.03s
                      Time elapsed: 00:18:49
                               ETA: 00:34:04

################################################################################
                     [1m Learning iteration 534/1500 [0m                      

                       Computation: 48703 steps/s (collection: 1.908s, learning 0.110s)
             Mean action noise std: 2.43
          Mean value_function loss: 78.9922
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 59.6650
                       Mean reward: 311.83
               Mean episode length: 219.25
    Episode_Reward/reaching_object: 1.2932
    Episode_Reward/rotating_object: 66.2276
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 2.02s
                      Time elapsed: 00:18:51
                               ETA: 00:34:02

################################################################################
                     [1m Learning iteration 535/1500 [0m                      

                       Computation: 48972 steps/s (collection: 1.897s, learning 0.111s)
             Mean action noise std: 2.43
          Mean value_function loss: 81.6980
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 59.6875
                       Mean reward: 329.62
               Mean episode length: 232.35
    Episode_Reward/reaching_object: 1.2987
    Episode_Reward/rotating_object: 66.2696
        Episode_Reward/action_rate: -0.0355
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 2.01s
                      Time elapsed: 00:18:53
                               ETA: 00:34:00

################################################################################
                     [1m Learning iteration 536/1500 [0m                      

                       Computation: 49702 steps/s (collection: 1.867s, learning 0.110s)
             Mean action noise std: 2.43
          Mean value_function loss: 78.3094
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 59.7169
                       Mean reward: 319.18
               Mean episode length: 230.54
    Episode_Reward/reaching_object: 1.2798
    Episode_Reward/rotating_object: 64.3249
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 1.98s
                      Time elapsed: 00:18:55
                               ETA: 00:33:57

################################################################################
                     [1m Learning iteration 537/1500 [0m                      

                       Computation: 49146 steps/s (collection: 1.890s, learning 0.110s)
             Mean action noise std: 2.44
          Mean value_function loss: 65.4580
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 59.7421
                       Mean reward: 356.94
               Mean episode length: 241.56
    Episode_Reward/reaching_object: 1.3307
    Episode_Reward/rotating_object: 67.9793
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 2.00s
                      Time elapsed: 00:18:57
                               ETA: 00:33:55

################################################################################
                     [1m Learning iteration 538/1500 [0m                      

                       Computation: 49852 steps/s (collection: 1.862s, learning 0.110s)
             Mean action noise std: 2.44
          Mean value_function loss: 66.6297
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 59.7596
                       Mean reward: 306.89
               Mean episode length: 231.55
    Episode_Reward/reaching_object: 1.3082
    Episode_Reward/rotating_object: 69.2037
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 1.97s
                      Time elapsed: 00:18:59
                               ETA: 00:33:53

################################################################################
                     [1m Learning iteration 539/1500 [0m                      

                       Computation: 49243 steps/s (collection: 1.886s, learning 0.110s)
             Mean action noise std: 2.44
          Mean value_function loss: 72.3384
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 59.7817
                       Mean reward: 341.82
               Mean episode length: 235.61
    Episode_Reward/reaching_object: 1.3257
    Episode_Reward/rotating_object: 68.0258
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 2.00s
                      Time elapsed: 00:19:01
                               ETA: 00:33:50

################################################################################
                     [1m Learning iteration 540/1500 [0m                      

                       Computation: 49565 steps/s (collection: 1.873s, learning 0.110s)
             Mean action noise std: 2.44
          Mean value_function loss: 74.7546
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 59.8047
                       Mean reward: 318.85
               Mean episode length: 240.68
    Episode_Reward/reaching_object: 1.3015
    Episode_Reward/rotating_object: 64.1008
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 1.98s
                      Time elapsed: 00:19:03
                               ETA: 00:33:48

################################################################################
                     [1m Learning iteration 541/1500 [0m                      

                       Computation: 49178 steps/s (collection: 1.889s, learning 0.110s)
             Mean action noise std: 2.45
          Mean value_function loss: 72.9064
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 59.8251
                       Mean reward: 333.39
               Mean episode length: 228.33
    Episode_Reward/reaching_object: 1.2987
    Episode_Reward/rotating_object: 64.7547
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 2.00s
                      Time elapsed: 00:19:05
                               ETA: 00:33:46

################################################################################
                     [1m Learning iteration 542/1500 [0m                      

                       Computation: 49509 steps/s (collection: 1.873s, learning 0.113s)
             Mean action noise std: 2.45
          Mean value_function loss: 70.9730
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 59.8479
                       Mean reward: 335.82
               Mean episode length: 237.33
    Episode_Reward/reaching_object: 1.3336
    Episode_Reward/rotating_object: 66.9415
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 1.99s
                      Time elapsed: 00:19:07
                               ETA: 00:33:43

################################################################################
                     [1m Learning iteration 543/1500 [0m                      

                       Computation: 48436 steps/s (collection: 1.915s, learning 0.114s)
             Mean action noise std: 2.45
          Mean value_function loss: 73.8253
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 59.8738
                       Mean reward: 358.35
               Mean episode length: 237.75
    Episode_Reward/reaching_object: 1.3003
    Episode_Reward/rotating_object: 68.6103
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 2.03s
                      Time elapsed: 00:19:09
                               ETA: 00:33:41

################################################################################
                     [1m Learning iteration 544/1500 [0m                      

                       Computation: 47886 steps/s (collection: 1.936s, learning 0.117s)
             Mean action noise std: 2.45
          Mean value_function loss: 64.3056
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 59.8974
                       Mean reward: 368.42
               Mean episode length: 246.91
    Episode_Reward/reaching_object: 1.3456
    Episode_Reward/rotating_object: 70.0769
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 2.05s
                      Time elapsed: 00:19:11
                               ETA: 00:33:39

################################################################################
                     [1m Learning iteration 545/1500 [0m                      

                       Computation: 48668 steps/s (collection: 1.909s, learning 0.111s)
             Mean action noise std: 2.45
          Mean value_function loss: 68.2518
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 59.9165
                       Mean reward: 338.29
               Mean episode length: 231.84
    Episode_Reward/reaching_object: 1.3231
    Episode_Reward/rotating_object: 67.2722
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 2.02s
                      Time elapsed: 00:19:13
                               ETA: 00:33:37

################################################################################
                     [1m Learning iteration 546/1500 [0m                      

                       Computation: 48023 steps/s (collection: 1.932s, learning 0.115s)
             Mean action noise std: 2.46
          Mean value_function loss: 67.9265
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 59.9412
                       Mean reward: 342.22
               Mean episode length: 241.27
    Episode_Reward/reaching_object: 1.3250
    Episode_Reward/rotating_object: 70.9221
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 2.05s
                      Time elapsed: 00:19:15
                               ETA: 00:33:34

################################################################################
                     [1m Learning iteration 547/1500 [0m                      

                       Computation: 47835 steps/s (collection: 1.939s, learning 0.116s)
             Mean action noise std: 2.46
          Mean value_function loss: 63.6647
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 59.9649
                       Mean reward: 302.77
               Mean episode length: 232.27
    Episode_Reward/reaching_object: 1.2968
    Episode_Reward/rotating_object: 65.1153
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 2.06s
                      Time elapsed: 00:19:17
                               ETA: 00:33:32

################################################################################
                     [1m Learning iteration 548/1500 [0m                      

                       Computation: 47575 steps/s (collection: 1.955s, learning 0.111s)
             Mean action noise std: 2.46
          Mean value_function loss: 69.4605
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 60.0032
                       Mean reward: 340.15
               Mean episode length: 235.63
    Episode_Reward/reaching_object: 1.3317
    Episode_Reward/rotating_object: 68.6258
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 2.07s
                      Time elapsed: 00:19:19
                               ETA: 00:33:30

################################################################################
                     [1m Learning iteration 549/1500 [0m                      

                       Computation: 48617 steps/s (collection: 1.909s, learning 0.113s)
             Mean action noise std: 2.47
          Mean value_function loss: 73.9291
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.0295
                       Mean reward: 368.03
               Mean episode length: 233.28
    Episode_Reward/reaching_object: 1.2972
    Episode_Reward/rotating_object: 66.0357
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 2.02s
                      Time elapsed: 00:19:21
                               ETA: 00:33:28

################################################################################
                     [1m Learning iteration 550/1500 [0m                      

                       Computation: 47534 steps/s (collection: 1.953s, learning 0.115s)
             Mean action noise std: 2.47
          Mean value_function loss: 69.0266
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 60.0517
                       Mean reward: 365.64
               Mean episode length: 240.02
    Episode_Reward/reaching_object: 1.3398
    Episode_Reward/rotating_object: 68.5036
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 2.07s
                      Time elapsed: 00:19:23
                               ETA: 00:33:26

################################################################################
                     [1m Learning iteration 551/1500 [0m                      

                       Computation: 48550 steps/s (collection: 1.914s, learning 0.111s)
             Mean action noise std: 2.47
          Mean value_function loss: 72.3414
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 60.0747
                       Mean reward: 328.64
               Mean episode length: 228.66
    Episode_Reward/reaching_object: 1.2970
    Episode_Reward/rotating_object: 68.1113
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 2.02s
                      Time elapsed: 00:19:25
                               ETA: 00:33:23

################################################################################
                     [1m Learning iteration 552/1500 [0m                      

                       Computation: 47398 steps/s (collection: 1.956s, learning 0.118s)
             Mean action noise std: 2.47
          Mean value_function loss: 80.2859
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 60.1000
                       Mean reward: 383.64
               Mean episode length: 240.83
    Episode_Reward/reaching_object: 1.3660
    Episode_Reward/rotating_object: 69.7699
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 2.07s
                      Time elapsed: 00:19:27
                               ETA: 00:33:21

################################################################################
                     [1m Learning iteration 553/1500 [0m                      

                       Computation: 45116 steps/s (collection: 2.048s, learning 0.131s)
             Mean action noise std: 2.48
          Mean value_function loss: 77.9802
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 60.1304
                       Mean reward: 347.88
               Mean episode length: 234.55
    Episode_Reward/reaching_object: 1.2996
    Episode_Reward/rotating_object: 67.0980
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 2.18s
                      Time elapsed: 00:19:29
                               ETA: 00:33:19

################################################################################
                     [1m Learning iteration 554/1500 [0m                      

                       Computation: 48515 steps/s (collection: 1.913s, learning 0.113s)
             Mean action noise std: 2.48
          Mean value_function loss: 73.9697
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 60.1559
                       Mean reward: 353.46
               Mean episode length: 236.10
    Episode_Reward/reaching_object: 1.3358
    Episode_Reward/rotating_object: 71.5559
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 2.03s
                      Time elapsed: 00:19:31
                               ETA: 00:33:17

################################################################################
                     [1m Learning iteration 555/1500 [0m                      

                       Computation: 48376 steps/s (collection: 1.921s, learning 0.111s)
             Mean action noise std: 2.48
          Mean value_function loss: 84.3132
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 60.1744
                       Mean reward: 359.33
               Mean episode length: 241.89
    Episode_Reward/reaching_object: 1.3304
    Episode_Reward/rotating_object: 69.6161
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 2.03s
                      Time elapsed: 00:19:33
                               ETA: 00:33:15

################################################################################
                     [1m Learning iteration 556/1500 [0m                      

                       Computation: 48477 steps/s (collection: 1.917s, learning 0.111s)
             Mean action noise std: 2.48
          Mean value_function loss: 64.9133
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 60.2040
                       Mean reward: 373.71
               Mean episode length: 238.66
    Episode_Reward/reaching_object: 1.3307
    Episode_Reward/rotating_object: 70.9437
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 2.03s
                      Time elapsed: 00:19:35
                               ETA: 00:33:12

################################################################################
                     [1m Learning iteration 557/1500 [0m                      

                       Computation: 47425 steps/s (collection: 1.942s, learning 0.131s)
             Mean action noise std: 2.49
          Mean value_function loss: 63.2904
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 60.2372
                       Mean reward: 330.12
               Mean episode length: 233.34
    Episode_Reward/reaching_object: 1.3348
    Episode_Reward/rotating_object: 69.4404
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 2.07s
                      Time elapsed: 00:19:37
                               ETA: 00:33:10

################################################################################
                     [1m Learning iteration 558/1500 [0m                      

                       Computation: 49318 steps/s (collection: 1.883s, learning 0.111s)
             Mean action noise std: 2.49
          Mean value_function loss: 67.8331
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 60.2741
                       Mean reward: 368.58
               Mean episode length: 228.77
    Episode_Reward/reaching_object: 1.3185
    Episode_Reward/rotating_object: 71.8550
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 1.99s
                      Time elapsed: 00:19:39
                               ETA: 00:33:08

################################################################################
                     [1m Learning iteration 559/1500 [0m                      

                       Computation: 49338 steps/s (collection: 1.881s, learning 0.111s)
             Mean action noise std: 2.49
          Mean value_function loss: 68.8192
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 60.3113
                       Mean reward: 325.10
               Mean episode length: 240.32
    Episode_Reward/reaching_object: 1.3301
    Episode_Reward/rotating_object: 67.2541
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 1.99s
                      Time elapsed: 00:19:41
                               ETA: 00:33:06

################################################################################
                     [1m Learning iteration 560/1500 [0m                      

                       Computation: 49905 steps/s (collection: 1.859s, learning 0.111s)
             Mean action noise std: 2.50
          Mean value_function loss: 65.9350
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 60.3539
                       Mean reward: 386.52
               Mean episode length: 242.47
    Episode_Reward/reaching_object: 1.3137
    Episode_Reward/rotating_object: 69.4273
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 1.97s
                      Time elapsed: 00:19:43
                               ETA: 00:33:03

################################################################################
                     [1m Learning iteration 561/1500 [0m                      

                       Computation: 49214 steps/s (collection: 1.887s, learning 0.111s)
             Mean action noise std: 2.50
          Mean value_function loss: 72.4575
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 60.3884
                       Mean reward: 317.30
               Mean episode length: 223.81
    Episode_Reward/reaching_object: 1.2982
    Episode_Reward/rotating_object: 68.9424
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 2.00s
                      Time elapsed: 00:19:45
                               ETA: 00:33:01

################################################################################
                     [1m Learning iteration 562/1500 [0m                      

                       Computation: 49370 steps/s (collection: 1.880s, learning 0.111s)
             Mean action noise std: 2.50
          Mean value_function loss: 72.3578
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 60.4181
                       Mean reward: 401.73
               Mean episode length: 241.84
    Episode_Reward/reaching_object: 1.3489
    Episode_Reward/rotating_object: 73.0389
        Episode_Reward/action_rate: -0.0384
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 1.99s
                      Time elapsed: 00:19:47
                               ETA: 00:32:59

################################################################################
                     [1m Learning iteration 563/1500 [0m                      

                       Computation: 48951 steps/s (collection: 1.898s, learning 0.111s)
             Mean action noise std: 2.51
          Mean value_function loss: 75.9772
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 60.4522
                       Mean reward: 359.99
               Mean episode length: 234.63
    Episode_Reward/reaching_object: 1.2885
    Episode_Reward/rotating_object: 66.8787
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 2.01s
                      Time elapsed: 00:19:49
                               ETA: 00:32:56

################################################################################
                     [1m Learning iteration 564/1500 [0m                      

                       Computation: 49041 steps/s (collection: 1.894s, learning 0.111s)
             Mean action noise std: 2.51
          Mean value_function loss: 75.3490
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 60.4821
                       Mean reward: 351.89
               Mean episode length: 235.80
    Episode_Reward/reaching_object: 1.3277
    Episode_Reward/rotating_object: 70.5213
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 2.00s
                      Time elapsed: 00:19:51
                               ETA: 00:32:54

################################################################################
                     [1m Learning iteration 565/1500 [0m                      

                       Computation: 48828 steps/s (collection: 1.902s, learning 0.111s)
             Mean action noise std: 2.51
          Mean value_function loss: 73.5042
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 60.5035
                       Mean reward: 319.27
               Mean episode length: 235.10
    Episode_Reward/reaching_object: 1.3214
    Episode_Reward/rotating_object: 69.0728
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 2.01s
                      Time elapsed: 00:19:53
                               ETA: 00:32:52

################################################################################
                     [1m Learning iteration 566/1500 [0m                      

                       Computation: 48798 steps/s (collection: 1.897s, learning 0.117s)
             Mean action noise std: 2.51
          Mean value_function loss: 79.5394
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 60.5260
                       Mean reward: 382.49
               Mean episode length: 241.72
    Episode_Reward/reaching_object: 1.3399
    Episode_Reward/rotating_object: 69.3611
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 2.01s
                      Time elapsed: 00:19:55
                               ETA: 00:32:50

################################################################################
                     [1m Learning iteration 567/1500 [0m                      

                       Computation: 47712 steps/s (collection: 1.950s, learning 0.110s)
             Mean action noise std: 2.52
          Mean value_function loss: 74.4463
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 60.5444
                       Mean reward: 369.66
               Mean episode length: 234.05
    Episode_Reward/reaching_object: 1.3230
    Episode_Reward/rotating_object: 69.2836
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 2.06s
                      Time elapsed: 00:19:58
                               ETA: 00:32:47

################################################################################
                     [1m Learning iteration 568/1500 [0m                      

                       Computation: 47914 steps/s (collection: 1.938s, learning 0.114s)
             Mean action noise std: 2.52
          Mean value_function loss: 78.6302
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 60.5648
                       Mean reward: 358.22
               Mean episode length: 231.49
    Episode_Reward/reaching_object: 1.3391
    Episode_Reward/rotating_object: 70.3108
        Episode_Reward/action_rate: -0.0384
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 2.05s
                      Time elapsed: 00:20:00
                               ETA: 00:32:45

################################################################################
                     [1m Learning iteration 569/1500 [0m                      

                       Computation: 48244 steps/s (collection: 1.924s, learning 0.113s)
             Mean action noise std: 2.52
          Mean value_function loss: 77.9057
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 60.5872
                       Mean reward: 323.96
               Mean episode length: 238.73
    Episode_Reward/reaching_object: 1.3289
    Episode_Reward/rotating_object: 68.7834
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 2.04s
                      Time elapsed: 00:20:02
                               ETA: 00:32:43

################################################################################
                     [1m Learning iteration 570/1500 [0m                      

                       Computation: 48288 steps/s (collection: 1.925s, learning 0.111s)
             Mean action noise std: 2.52
          Mean value_function loss: 83.4719
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 60.6094
                       Mean reward: 356.96
               Mean episode length: 224.61
    Episode_Reward/reaching_object: 1.3641
    Episode_Reward/rotating_object: 72.7090
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 2.04s
                      Time elapsed: 00:20:04
                               ETA: 00:32:41

################################################################################
                     [1m Learning iteration 571/1500 [0m                      

                       Computation: 48423 steps/s (collection: 1.920s, learning 0.110s)
             Mean action noise std: 2.52
          Mean value_function loss: 85.0225
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 60.6270
                       Mean reward: 351.35
               Mean episode length: 233.74
    Episode_Reward/reaching_object: 1.3562
    Episode_Reward/rotating_object: 70.1209
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 2.03s
                      Time elapsed: 00:20:06
                               ETA: 00:32:38

################################################################################
                     [1m Learning iteration 572/1500 [0m                      

                       Computation: 48026 steps/s (collection: 1.937s, learning 0.110s)
             Mean action noise std: 2.53
          Mean value_function loss: 86.9463
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 60.6468
                       Mean reward: 359.93
               Mean episode length: 233.81
    Episode_Reward/reaching_object: 1.3651
    Episode_Reward/rotating_object: 68.6685
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 2.05s
                      Time elapsed: 00:20:08
                               ETA: 00:32:36

################################################################################
                     [1m Learning iteration 573/1500 [0m                      

                       Computation: 48577 steps/s (collection: 1.912s, learning 0.112s)
             Mean action noise std: 2.53
          Mean value_function loss: 86.8155
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 60.6597
                       Mean reward: 370.99
               Mean episode length: 237.92
    Episode_Reward/reaching_object: 1.3817
    Episode_Reward/rotating_object: 71.1783
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 2.02s
                      Time elapsed: 00:20:10
                               ETA: 00:32:34

################################################################################
                     [1m Learning iteration 574/1500 [0m                      

                       Computation: 48057 steps/s (collection: 1.936s, learning 0.110s)
             Mean action noise std: 2.53
          Mean value_function loss: 87.6192
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 60.6782
                       Mean reward: 376.49
               Mean episode length: 232.69
    Episode_Reward/reaching_object: 1.3616
    Episode_Reward/rotating_object: 70.4749
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 2.05s
                      Time elapsed: 00:20:12
                               ETA: 00:32:32

################################################################################
                     [1m Learning iteration 575/1500 [0m                      

                       Computation: 48471 steps/s (collection: 1.918s, learning 0.111s)
             Mean action noise std: 2.53
          Mean value_function loss: 84.1417
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 60.7002
                       Mean reward: 379.17
               Mean episode length: 237.36
    Episode_Reward/reaching_object: 1.3820
    Episode_Reward/rotating_object: 73.8769
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 2.03s
                      Time elapsed: 00:20:14
                               ETA: 00:32:30

################################################################################
                     [1m Learning iteration 576/1500 [0m                      

                       Computation: 48222 steps/s (collection: 1.926s, learning 0.112s)
             Mean action noise std: 2.54
          Mean value_function loss: 85.2790
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 60.7254
                       Mean reward: 360.74
               Mean episode length: 237.62
    Episode_Reward/reaching_object: 1.3727
    Episode_Reward/rotating_object: 69.2411
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 2.04s
                      Time elapsed: 00:20:16
                               ETA: 00:32:27

################################################################################
                     [1m Learning iteration 577/1500 [0m                      

                       Computation: 48014 steps/s (collection: 1.935s, learning 0.113s)
             Mean action noise std: 2.54
          Mean value_function loss: 92.9641
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 60.7633
                       Mean reward: 324.09
               Mean episode length: 229.44
    Episode_Reward/reaching_object: 1.3478
    Episode_Reward/rotating_object: 66.9927
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 2.05s
                      Time elapsed: 00:20:18
                               ETA: 00:32:25

################################################################################
                     [1m Learning iteration 578/1500 [0m                      

                       Computation: 47881 steps/s (collection: 1.941s, learning 0.113s)
             Mean action noise std: 2.54
          Mean value_function loss: 84.4905
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 60.7884
                       Mean reward: 366.97
               Mean episode length: 232.58
    Episode_Reward/reaching_object: 1.3683
    Episode_Reward/rotating_object: 71.9458
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 2.05s
                      Time elapsed: 00:20:20
                               ETA: 00:32:23

################################################################################
                     [1m Learning iteration 579/1500 [0m                      

                       Computation: 46718 steps/s (collection: 1.994s, learning 0.110s)
             Mean action noise std: 2.54
          Mean value_function loss: 79.2351
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 60.8089
                       Mean reward: 340.27
               Mean episode length: 222.89
    Episode_Reward/reaching_object: 1.3655
    Episode_Reward/rotating_object: 70.8805
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 2.10s
                      Time elapsed: 00:20:22
                               ETA: 00:32:21

################################################################################
                     [1m Learning iteration 580/1500 [0m                      

                       Computation: 48879 steps/s (collection: 1.898s, learning 0.113s)
             Mean action noise std: 2.55
          Mean value_function loss: 74.7795
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 60.8313
                       Mean reward: 331.83
               Mean episode length: 235.31
    Episode_Reward/reaching_object: 1.3561
    Episode_Reward/rotating_object: 66.7182
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 2.01s
                      Time elapsed: 00:20:24
                               ETA: 00:32:19

################################################################################
                     [1m Learning iteration 581/1500 [0m                      

                       Computation: 48254 steps/s (collection: 1.927s, learning 0.110s)
             Mean action noise std: 2.55
          Mean value_function loss: 86.6795
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 60.8619
                       Mean reward: 347.55
               Mean episode length: 234.27
    Episode_Reward/reaching_object: 1.3453
    Episode_Reward/rotating_object: 68.0564
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 2.04s
                      Time elapsed: 00:20:26
                               ETA: 00:32:16

################################################################################
                     [1m Learning iteration 582/1500 [0m                      

                       Computation: 49053 steps/s (collection: 1.894s, learning 0.110s)
             Mean action noise std: 2.55
          Mean value_function loss: 82.4863
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 60.8926
                       Mean reward: 348.22
               Mean episode length: 230.62
    Episode_Reward/reaching_object: 1.3893
    Episode_Reward/rotating_object: 70.2986
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 2.00s
                      Time elapsed: 00:20:28
                               ETA: 00:32:14

################################################################################
                     [1m Learning iteration 583/1500 [0m                      

                       Computation: 49189 steps/s (collection: 1.888s, learning 0.110s)
             Mean action noise std: 2.55
          Mean value_function loss: 71.7913
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 60.9132
                       Mean reward: 351.66
               Mean episode length: 238.01
    Episode_Reward/reaching_object: 1.3710
    Episode_Reward/rotating_object: 70.9805
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 2.00s
                      Time elapsed: 00:20:30
                               ETA: 00:32:12

################################################################################
                     [1m Learning iteration 584/1500 [0m                      

                       Computation: 48924 steps/s (collection: 1.892s, learning 0.117s)
             Mean action noise std: 2.56
          Mean value_function loss: 70.2492
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 60.9407
                       Mean reward: 357.19
               Mean episode length: 231.70
    Episode_Reward/reaching_object: 1.3719
    Episode_Reward/rotating_object: 68.1240
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 2.01s
                      Time elapsed: 00:20:32
                               ETA: 00:32:10

################################################################################
                     [1m Learning iteration 585/1500 [0m                      

                       Computation: 49216 steps/s (collection: 1.888s, learning 0.110s)
             Mean action noise std: 2.56
          Mean value_function loss: 70.9491
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 60.9685
                       Mean reward: 372.60
               Mean episode length: 239.98
    Episode_Reward/reaching_object: 1.3684
    Episode_Reward/rotating_object: 69.4683
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 2.00s
                      Time elapsed: 00:20:34
                               ETA: 00:32:07

################################################################################
                     [1m Learning iteration 586/1500 [0m                      

                       Computation: 49351 steps/s (collection: 1.882s, learning 0.110s)
             Mean action noise std: 2.56
          Mean value_function loss: 73.1086
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 60.9955
                       Mean reward: 334.79
               Mean episode length: 230.46
    Episode_Reward/reaching_object: 1.3517
    Episode_Reward/rotating_object: 71.1887
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 1.99s
                      Time elapsed: 00:20:36
                               ETA: 00:32:05

################################################################################
                     [1m Learning iteration 587/1500 [0m                      

                       Computation: 49302 steps/s (collection: 1.883s, learning 0.111s)
             Mean action noise std: 2.57
          Mean value_function loss: 74.4752
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 61.0269
                       Mean reward: 341.80
               Mean episode length: 227.42
    Episode_Reward/reaching_object: 1.3432
    Episode_Reward/rotating_object: 70.6869
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 1.99s
                      Time elapsed: 00:20:38
                               ETA: 00:32:03

################################################################################
                     [1m Learning iteration 588/1500 [0m                      

                       Computation: 49629 steps/s (collection: 1.870s, learning 0.110s)
             Mean action noise std: 2.57
          Mean value_function loss: 78.1646
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 61.0512
                       Mean reward: 395.43
               Mean episode length: 232.10
    Episode_Reward/reaching_object: 1.3218
    Episode_Reward/rotating_object: 69.5448
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 1.98s
                      Time elapsed: 00:20:40
                               ETA: 00:32:00

################################################################################
                     [1m Learning iteration 589/1500 [0m                      

                       Computation: 48946 steps/s (collection: 1.896s, learning 0.112s)
             Mean action noise std: 2.57
          Mean value_function loss: 73.4631
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 61.0862
                       Mean reward: 366.96
               Mean episode length: 234.55
    Episode_Reward/reaching_object: 1.3769
    Episode_Reward/rotating_object: 74.4466
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 2.01s
                      Time elapsed: 00:20:42
                               ETA: 00:31:58

################################################################################
                     [1m Learning iteration 590/1500 [0m                      

                       Computation: 48945 steps/s (collection: 1.895s, learning 0.113s)
             Mean action noise std: 2.58
          Mean value_function loss: 68.0759
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 61.1287
                       Mean reward: 365.75
               Mean episode length: 232.43
    Episode_Reward/reaching_object: 1.3648
    Episode_Reward/rotating_object: 71.6051
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 2.01s
                      Time elapsed: 00:20:44
                               ETA: 00:31:56

################################################################################
                     [1m Learning iteration 591/1500 [0m                      

                       Computation: 48360 steps/s (collection: 1.922s, learning 0.111s)
             Mean action noise std: 2.58
          Mean value_function loss: 72.6979
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 61.1707
                       Mean reward: 358.33
               Mean episode length: 228.70
    Episode_Reward/reaching_object: 1.3484
    Episode_Reward/rotating_object: 69.0099
        Episode_Reward/action_rate: -0.0401
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 2.03s
                      Time elapsed: 00:20:46
                               ETA: 00:31:54

################################################################################
                     [1m Learning iteration 592/1500 [0m                      

                       Computation: 47892 steps/s (collection: 1.939s, learning 0.113s)
             Mean action noise std: 2.58
          Mean value_function loss: 78.0434
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 61.2033
                       Mean reward: 358.41
               Mean episode length: 227.65
    Episode_Reward/reaching_object: 1.3256
    Episode_Reward/rotating_object: 68.6936
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 2.05s
                      Time elapsed: 00:20:48
                               ETA: 00:31:51

################################################################################
                     [1m Learning iteration 593/1500 [0m                      

                       Computation: 47809 steps/s (collection: 1.942s, learning 0.114s)
             Mean action noise std: 2.59
          Mean value_function loss: 69.8098
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 61.2284
                       Mean reward: 320.48
               Mean episode length: 233.76
    Episode_Reward/reaching_object: 1.3316
    Episode_Reward/rotating_object: 69.2069
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 2.06s
                      Time elapsed: 00:20:50
                               ETA: 00:31:49

################################################################################
                     [1m Learning iteration 594/1500 [0m                      

                       Computation: 47447 steps/s (collection: 1.957s, learning 0.114s)
             Mean action noise std: 2.59
          Mean value_function loss: 81.2996
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 61.2581
                       Mean reward: 372.61
               Mean episode length: 232.90
    Episode_Reward/reaching_object: 1.3439
    Episode_Reward/rotating_object: 70.2654
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 2.07s
                      Time elapsed: 00:20:52
                               ETA: 00:31:47

################################################################################
                     [1m Learning iteration 595/1500 [0m                      

                       Computation: 48623 steps/s (collection: 1.908s, learning 0.113s)
             Mean action noise std: 2.59
          Mean value_function loss: 81.5785
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 61.2848
                       Mean reward: 342.45
               Mean episode length: 230.86
    Episode_Reward/reaching_object: 1.3199
    Episode_Reward/rotating_object: 70.5670
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 2.02s
                      Time elapsed: 00:20:54
                               ETA: 00:31:45

################################################################################
                     [1m Learning iteration 596/1500 [0m                      

                       Computation: 47972 steps/s (collection: 1.939s, learning 0.111s)
             Mean action noise std: 2.60
          Mean value_function loss: 84.8557
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 61.3042
                       Mean reward: 297.29
               Mean episode length: 229.33
    Episode_Reward/reaching_object: 1.3280
    Episode_Reward/rotating_object: 67.2806
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 2.05s
                      Time elapsed: 00:20:56
                               ETA: 00:31:43

################################################################################
                     [1m Learning iteration 597/1500 [0m                      

                       Computation: 48754 steps/s (collection: 1.904s, learning 0.112s)
             Mean action noise std: 2.60
          Mean value_function loss: 79.8719
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 61.3295
                       Mean reward: 361.43
               Mean episode length: 231.62
    Episode_Reward/reaching_object: 1.3570
    Episode_Reward/rotating_object: 69.3054
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 2.02s
                      Time elapsed: 00:20:58
                               ETA: 00:31:40

################################################################################
                     [1m Learning iteration 598/1500 [0m                      

                       Computation: 48352 steps/s (collection: 1.920s, learning 0.113s)
             Mean action noise std: 2.60
          Mean value_function loss: 84.4727
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 61.3556
                       Mean reward: 339.71
               Mean episode length: 226.57
    Episode_Reward/reaching_object: 1.3502
    Episode_Reward/rotating_object: 70.5353
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 2.03s
                      Time elapsed: 00:21:00
                               ETA: 00:31:38

################################################################################
                     [1m Learning iteration 599/1500 [0m                      

                       Computation: 48627 steps/s (collection: 1.909s, learning 0.113s)
             Mean action noise std: 2.60
          Mean value_function loss: 80.4474
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 61.3856
                       Mean reward: 377.20
               Mean episode length: 239.89
    Episode_Reward/reaching_object: 1.3734
    Episode_Reward/rotating_object: 71.6460
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 2.02s
                      Time elapsed: 00:21:02
                               ETA: 00:31:36

################################################################################
                     [1m Learning iteration 600/1500 [0m                      

                       Computation: 48507 steps/s (collection: 1.913s, learning 0.114s)
             Mean action noise std: 2.61
          Mean value_function loss: 81.2975
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 61.4105
                       Mean reward: 414.61
               Mean episode length: 239.40
    Episode_Reward/reaching_object: 1.3792
    Episode_Reward/rotating_object: 69.2580
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 2.03s
                      Time elapsed: 00:21:04
                               ETA: 00:31:34

################################################################################
                     [1m Learning iteration 601/1500 [0m                      

                       Computation: 48383 steps/s (collection: 1.919s, learning 0.113s)
             Mean action noise std: 2.61
          Mean value_function loss: 77.0480
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 61.4301
                       Mean reward: 348.60
               Mean episode length: 234.44
    Episode_Reward/reaching_object: 1.3843
    Episode_Reward/rotating_object: 70.6220
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 2.03s
                      Time elapsed: 00:21:06
                               ETA: 00:31:32

################################################################################
                     [1m Learning iteration 602/1500 [0m                      

                       Computation: 48957 steps/s (collection: 1.897s, learning 0.111s)
             Mean action noise std: 2.61
          Mean value_function loss: 78.0450
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 61.4495
                       Mean reward: 360.21
               Mean episode length: 230.42
    Episode_Reward/reaching_object: 1.3724
    Episode_Reward/rotating_object: 71.0432
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 2.01s
                      Time elapsed: 00:21:09
                               ETA: 00:31:29

################################################################################
                     [1m Learning iteration 603/1500 [0m                      

                       Computation: 47104 steps/s (collection: 1.971s, learning 0.116s)
             Mean action noise std: 2.61
          Mean value_function loss: 77.5841
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 61.4701
                       Mean reward: 362.05
               Mean episode length: 230.49
    Episode_Reward/reaching_object: 1.3567
    Episode_Reward/rotating_object: 70.0567
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 2.09s
                      Time elapsed: 00:21:11
                               ETA: 00:31:27

################################################################################
                     [1m Learning iteration 604/1500 [0m                      

                       Computation: 46554 steps/s (collection: 2.001s, learning 0.110s)
             Mean action noise std: 2.62
          Mean value_function loss: 80.4724
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 61.4897
                       Mean reward: 379.93
               Mean episode length: 238.76
    Episode_Reward/reaching_object: 1.4017
    Episode_Reward/rotating_object: 73.9427
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 2.11s
                      Time elapsed: 00:21:13
                               ETA: 00:31:25

################################################################################
                     [1m Learning iteration 605/1500 [0m                      

                       Computation: 46196 steps/s (collection: 2.015s, learning 0.113s)
             Mean action noise std: 2.62
          Mean value_function loss: 74.3014
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 61.5216
                       Mean reward: 362.72
               Mean episode length: 238.62
    Episode_Reward/reaching_object: 1.3873
    Episode_Reward/rotating_object: 74.8474
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 2.13s
                      Time elapsed: 00:21:15
                               ETA: 00:31:23

################################################################################
                     [1m Learning iteration 606/1500 [0m                      

                       Computation: 47551 steps/s (collection: 1.957s, learning 0.111s)
             Mean action noise std: 2.62
          Mean value_function loss: 74.9146
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 61.5564
                       Mean reward: 382.58
               Mean episode length: 239.22
    Episode_Reward/reaching_object: 1.3504
    Episode_Reward/rotating_object: 70.2808
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 2.07s
                      Time elapsed: 00:21:17
                               ETA: 00:31:21

################################################################################
                     [1m Learning iteration 607/1500 [0m                      

                       Computation: 48981 steps/s (collection: 1.896s, learning 0.111s)
             Mean action noise std: 2.63
          Mean value_function loss: 69.2464
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 61.5926
                       Mean reward: 385.73
               Mean episode length: 236.72
    Episode_Reward/reaching_object: 1.3741
    Episode_Reward/rotating_object: 71.9745
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 2.01s
                      Time elapsed: 00:21:19
                               ETA: 00:31:19

################################################################################
                     [1m Learning iteration 608/1500 [0m                      

                       Computation: 49480 steps/s (collection: 1.876s, learning 0.111s)
             Mean action noise std: 2.63
          Mean value_function loss: 72.7868
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 61.6240
                       Mean reward: 408.50
               Mean episode length: 245.48
    Episode_Reward/reaching_object: 1.3538
    Episode_Reward/rotating_object: 72.7736
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 1.99s
                      Time elapsed: 00:21:21
                               ETA: 00:31:16

################################################################################
                     [1m Learning iteration 609/1500 [0m                      

                       Computation: 49083 steps/s (collection: 1.889s, learning 0.114s)
             Mean action noise std: 2.63
          Mean value_function loss: 77.5620
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 61.6497
                       Mean reward: 377.24
               Mean episode length: 232.41
    Episode_Reward/reaching_object: 1.3638
    Episode_Reward/rotating_object: 74.3620
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 2.00s
                      Time elapsed: 00:21:23
                               ETA: 00:31:14

################################################################################
                     [1m Learning iteration 610/1500 [0m                      

                       Computation: 49549 steps/s (collection: 1.873s, learning 0.111s)
             Mean action noise std: 2.63
          Mean value_function loss: 72.5703
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 61.6747
                       Mean reward: 379.09
               Mean episode length: 238.67
    Episode_Reward/reaching_object: 1.3481
    Episode_Reward/rotating_object: 71.8226
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 1.98s
                      Time elapsed: 00:21:25
                               ETA: 00:31:12

################################################################################
                     [1m Learning iteration 611/1500 [0m                      

                       Computation: 49457 steps/s (collection: 1.877s, learning 0.110s)
             Mean action noise std: 2.64
          Mean value_function loss: 72.6219
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 61.7026
                       Mean reward: 369.75
               Mean episode length: 231.59
    Episode_Reward/reaching_object: 1.3569
    Episode_Reward/rotating_object: 76.1663
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 1.99s
                      Time elapsed: 00:21:27
                               ETA: 00:31:10

################################################################################
                     [1m Learning iteration 612/1500 [0m                      

                       Computation: 49057 steps/s (collection: 1.891s, learning 0.113s)
             Mean action noise std: 2.64
          Mean value_function loss: 66.7068
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 61.7319
                       Mean reward: 381.52
               Mean episode length: 242.18
    Episode_Reward/reaching_object: 1.3575
    Episode_Reward/rotating_object: 75.0881
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 2.00s
                      Time elapsed: 00:21:29
                               ETA: 00:31:07

################################################################################
                     [1m Learning iteration 613/1500 [0m                      

                       Computation: 49444 steps/s (collection: 1.876s, learning 0.112s)
             Mean action noise std: 2.64
          Mean value_function loss: 66.4646
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 61.7629
                       Mean reward: 398.75
               Mean episode length: 241.02
    Episode_Reward/reaching_object: 1.3413
    Episode_Reward/rotating_object: 75.6883
        Episode_Reward/action_rate: -0.0423
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 1.99s
                      Time elapsed: 00:21:31
                               ETA: 00:31:05

################################################################################
                     [1m Learning iteration 614/1500 [0m                      

                       Computation: 48192 steps/s (collection: 1.926s, learning 0.113s)
             Mean action noise std: 2.65
          Mean value_function loss: 72.0656
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 61.7997
                       Mean reward: 344.37
               Mean episode length: 224.29
    Episode_Reward/reaching_object: 1.3366
    Episode_Reward/rotating_object: 71.9713
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 2.04s
                      Time elapsed: 00:21:33
                               ETA: 00:31:03

################################################################################
                     [1m Learning iteration 615/1500 [0m                      

                       Computation: 48745 steps/s (collection: 1.907s, learning 0.110s)
             Mean action noise std: 2.65
          Mean value_function loss: 66.1202
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 61.8320
                       Mean reward: 389.15
               Mean episode length: 241.88
    Episode_Reward/reaching_object: 1.3703
    Episode_Reward/rotating_object: 74.6106
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 2.02s
                      Time elapsed: 00:21:35
                               ETA: 00:31:01

################################################################################
                     [1m Learning iteration 616/1500 [0m                      

                       Computation: 48480 steps/s (collection: 1.915s, learning 0.113s)
             Mean action noise std: 2.66
          Mean value_function loss: 75.5379
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 61.8663
                       Mean reward: 349.81
               Mean episode length: 236.99
    Episode_Reward/reaching_object: 1.3371
    Episode_Reward/rotating_object: 71.9209
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 2.03s
                      Time elapsed: 00:21:37
                               ETA: 00:30:58

################################################################################
                     [1m Learning iteration 617/1500 [0m                      

                       Computation: 48403 steps/s (collection: 1.921s, learning 0.110s)
             Mean action noise std: 2.66
          Mean value_function loss: 79.8429
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 61.8929
                       Mean reward: 351.75
               Mean episode length: 229.70
    Episode_Reward/reaching_object: 1.3510
    Episode_Reward/rotating_object: 72.4784
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 2.03s
                      Time elapsed: 00:21:39
                               ETA: 00:30:56

################################################################################
                     [1m Learning iteration 618/1500 [0m                      

                       Computation: 47994 steps/s (collection: 1.936s, learning 0.113s)
             Mean action noise std: 2.66
          Mean value_function loss: 84.5822
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 61.9114
                       Mean reward: 356.97
               Mean episode length: 232.75
    Episode_Reward/reaching_object: 1.3388
    Episode_Reward/rotating_object: 72.1988
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 2.05s
                      Time elapsed: 00:21:41
                               ETA: 00:30:54

################################################################################
                     [1m Learning iteration 619/1500 [0m                      

                       Computation: 48045 steps/s (collection: 1.935s, learning 0.111s)
             Mean action noise std: 2.66
          Mean value_function loss: 81.2957
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 61.9361
                       Mean reward: 408.57
               Mean episode length: 226.74
    Episode_Reward/reaching_object: 1.3691
    Episode_Reward/rotating_object: 76.0955
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 2.05s
                      Time elapsed: 00:21:43
                               ETA: 00:30:52

################################################################################
                     [1m Learning iteration 620/1500 [0m                      

                       Computation: 48035 steps/s (collection: 1.933s, learning 0.113s)
             Mean action noise std: 2.66
          Mean value_function loss: 79.5855
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 61.9578
                       Mean reward: 356.70
               Mean episode length: 232.08
    Episode_Reward/reaching_object: 1.3316
    Episode_Reward/rotating_object: 70.1246
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 2.05s
                      Time elapsed: 00:21:45
                               ETA: 00:30:50

################################################################################
                     [1m Learning iteration 621/1500 [0m                      

                       Computation: 48405 steps/s (collection: 1.919s, learning 0.111s)
             Mean action noise std: 2.67
          Mean value_function loss: 85.5359
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 61.9743
                       Mean reward: 349.48
               Mean episode length: 237.41
    Episode_Reward/reaching_object: 1.3917
    Episode_Reward/rotating_object: 76.3862
        Episode_Reward/action_rate: -0.0433
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 2.03s
                      Time elapsed: 00:21:47
                               ETA: 00:30:47

################################################################################
                     [1m Learning iteration 622/1500 [0m                      

                       Computation: 47857 steps/s (collection: 1.934s, learning 0.120s)
             Mean action noise std: 2.67
          Mean value_function loss: 83.3321
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 62.0019
                       Mean reward: 311.68
               Mean episode length: 233.64
    Episode_Reward/reaching_object: 1.3996
    Episode_Reward/rotating_object: 72.4768
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 2.05s
                      Time elapsed: 00:21:49
                               ETA: 00:30:45

################################################################################
                     [1m Learning iteration 623/1500 [0m                      

                       Computation: 47720 steps/s (collection: 1.947s, learning 0.113s)
             Mean action noise std: 2.67
          Mean value_function loss: 74.1596
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 62.0263
                       Mean reward: 397.17
               Mean episode length: 237.66
    Episode_Reward/reaching_object: 1.3814
    Episode_Reward/rotating_object: 76.6953
        Episode_Reward/action_rate: -0.0436
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 2.06s
                      Time elapsed: 00:21:51
                               ETA: 00:30:43

################################################################################
                     [1m Learning iteration 624/1500 [0m                      

                       Computation: 47288 steps/s (collection: 1.966s, learning 0.112s)
             Mean action noise std: 2.68
          Mean value_function loss: 77.5419
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 62.0546
                       Mean reward: 354.65
               Mean episode length: 240.18
    Episode_Reward/reaching_object: 1.4132
    Episode_Reward/rotating_object: 74.2369
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 2.08s
                      Time elapsed: 00:21:53
                               ETA: 00:30:41

################################################################################
                     [1m Learning iteration 625/1500 [0m                      

                       Computation: 46299 steps/s (collection: 2.011s, learning 0.113s)
             Mean action noise std: 2.68
          Mean value_function loss: 74.2670
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 62.0892
                       Mean reward: 344.81
               Mean episode length: 230.82
    Episode_Reward/reaching_object: 1.3758
    Episode_Reward/rotating_object: 73.6766
        Episode_Reward/action_rate: -0.0433
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 2.12s
                      Time elapsed: 00:21:55
                               ETA: 00:30:39

################################################################################
                     [1m Learning iteration 626/1500 [0m                      

                       Computation: 47638 steps/s (collection: 1.953s, learning 0.111s)
             Mean action noise std: 2.68
          Mean value_function loss: 73.5133
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 62.1221
                       Mean reward: 338.83
               Mean episode length: 237.63
    Episode_Reward/reaching_object: 1.3671
    Episode_Reward/rotating_object: 70.9937
        Episode_Reward/action_rate: -0.0436
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 2.06s
                      Time elapsed: 00:21:58
                               ETA: 00:30:37

################################################################################
                     [1m Learning iteration 627/1500 [0m                      

                       Computation: 48292 steps/s (collection: 1.921s, learning 0.114s)
             Mean action noise std: 2.69
          Mean value_function loss: 70.9220
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 62.1633
                       Mean reward: 349.18
               Mean episode length: 236.01
    Episode_Reward/reaching_object: 1.3762
    Episode_Reward/rotating_object: 71.8925
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 2.04s
                      Time elapsed: 00:22:00
                               ETA: 00:30:35

################################################################################
                     [1m Learning iteration 628/1500 [0m                      

                       Computation: 48541 steps/s (collection: 1.911s, learning 0.114s)
             Mean action noise std: 2.69
          Mean value_function loss: 78.6594
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 62.1967
                       Mean reward: 392.37
               Mean episode length: 230.34
    Episode_Reward/reaching_object: 1.3814
    Episode_Reward/rotating_object: 74.7935
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 2.03s
                      Time elapsed: 00:22:02
                               ETA: 00:30:32

################################################################################
                     [1m Learning iteration 629/1500 [0m                      

                       Computation: 48207 steps/s (collection: 1.925s, learning 0.114s)
             Mean action noise std: 2.69
          Mean value_function loss: 86.6346
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 62.2207
                       Mean reward: 405.01
               Mean episode length: 230.25
    Episode_Reward/reaching_object: 1.3807
    Episode_Reward/rotating_object: 74.0676
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 2.04s
                      Time elapsed: 00:22:04
                               ETA: 00:30:30

################################################################################
                     [1m Learning iteration 630/1500 [0m                      

                       Computation: 48810 steps/s (collection: 1.903s, learning 0.111s)
             Mean action noise std: 2.70
          Mean value_function loss: 78.1616
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 62.2473
                       Mean reward: 334.97
               Mean episode length: 235.28
    Episode_Reward/reaching_object: 1.3801
    Episode_Reward/rotating_object: 71.9679
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 2.01s
                      Time elapsed: 00:22:06
                               ETA: 00:30:28

################################################################################
                     [1m Learning iteration 631/1500 [0m                      

                       Computation: 49176 steps/s (collection: 1.888s, learning 0.111s)
             Mean action noise std: 2.70
          Mean value_function loss: 87.5482
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 62.2764
                       Mean reward: 360.84
               Mean episode length: 235.22
    Episode_Reward/reaching_object: 1.3618
    Episode_Reward/rotating_object: 73.2308
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 2.00s
                      Time elapsed: 00:22:08
                               ETA: 00:30:26

################################################################################
                     [1m Learning iteration 632/1500 [0m                      

                       Computation: 49121 steps/s (collection: 1.890s, learning 0.111s)
             Mean action noise std: 2.70
          Mean value_function loss: 81.8744
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 62.3056
                       Mean reward: 347.69
               Mean episode length: 228.47
    Episode_Reward/reaching_object: 1.3582
    Episode_Reward/rotating_object: 71.6505
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 2.00s
                      Time elapsed: 00:22:10
                               ETA: 00:30:23

################################################################################
                     [1m Learning iteration 633/1500 [0m                      

                       Computation: 49658 steps/s (collection: 1.869s, learning 0.111s)
             Mean action noise std: 2.71
          Mean value_function loss: 84.0442
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 62.3392
                       Mean reward: 385.40
               Mean episode length: 242.11
    Episode_Reward/reaching_object: 1.3636
    Episode_Reward/rotating_object: 73.3552
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 1.98s
                      Time elapsed: 00:22:12
                               ETA: 00:30:21

################################################################################
                     [1m Learning iteration 634/1500 [0m                      

                       Computation: 49433 steps/s (collection: 1.878s, learning 0.111s)
             Mean action noise std: 2.71
          Mean value_function loss: 76.8339
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 62.3671
                       Mean reward: 381.38
               Mean episode length: 232.04
    Episode_Reward/reaching_object: 1.3647
    Episode_Reward/rotating_object: 76.7353
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 1.99s
                      Time elapsed: 00:22:14
                               ETA: 00:30:19

################################################################################
                     [1m Learning iteration 635/1500 [0m                      

                       Computation: 48967 steps/s (collection: 1.895s, learning 0.112s)
             Mean action noise std: 2.71
          Mean value_function loss: 82.5677
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 62.3930
                       Mean reward: 434.36
               Mean episode length: 241.84
    Episode_Reward/reaching_object: 1.3868
    Episode_Reward/rotating_object: 78.3111
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 2.01s
                      Time elapsed: 00:22:16
                               ETA: 00:30:17

################################################################################
                     [1m Learning iteration 636/1500 [0m                      

                       Computation: 48992 steps/s (collection: 1.896s, learning 0.111s)
             Mean action noise std: 2.72
          Mean value_function loss: 71.3544
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 62.4226
                       Mean reward: 392.29
               Mean episode length: 238.81
    Episode_Reward/reaching_object: 1.3826
    Episode_Reward/rotating_object: 75.6649
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 2.01s
                      Time elapsed: 00:22:18
                               ETA: 00:30:14

################################################################################
                     [1m Learning iteration 637/1500 [0m                      

                       Computation: 49586 steps/s (collection: 1.872s, learning 0.111s)
             Mean action noise std: 2.72
          Mean value_function loss: 67.3543
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 62.4420
                       Mean reward: 388.58
               Mean episode length: 241.05
    Episode_Reward/reaching_object: 1.3669
    Episode_Reward/rotating_object: 74.4833
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 1.98s
                      Time elapsed: 00:22:20
                               ETA: 00:30:12

################################################################################
                     [1m Learning iteration 638/1500 [0m                      

                       Computation: 47857 steps/s (collection: 1.931s, learning 0.123s)
             Mean action noise std: 2.72
          Mean value_function loss: 70.0037
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 62.4708
                       Mean reward: 395.92
               Mean episode length: 230.51
    Episode_Reward/reaching_object: 1.3835
    Episode_Reward/rotating_object: 77.8308
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 2.05s
                      Time elapsed: 00:22:22
                               ETA: 00:30:10

################################################################################
                     [1m Learning iteration 639/1500 [0m                      

                       Computation: 48548 steps/s (collection: 1.911s, learning 0.114s)
             Mean action noise std: 2.73
          Mean value_function loss: 74.3921
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 62.5007
                       Mean reward: 355.21
               Mean episode length: 231.59
    Episode_Reward/reaching_object: 1.3523
    Episode_Reward/rotating_object: 76.0693
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 2.02s
                      Time elapsed: 00:22:24
                               ETA: 00:30:08

################################################################################
                     [1m Learning iteration 640/1500 [0m                      

                       Computation: 48412 steps/s (collection: 1.918s, learning 0.113s)
             Mean action noise std: 2.73
          Mean value_function loss: 74.4195
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 62.5369
                       Mean reward: 376.15
               Mean episode length: 238.86
    Episode_Reward/reaching_object: 1.3955
    Episode_Reward/rotating_object: 75.8597
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 2.03s
                      Time elapsed: 00:22:26
                               ETA: 00:30:06

################################################################################
                     [1m Learning iteration 641/1500 [0m                      

                       Computation: 48045 steps/s (collection: 1.935s, learning 0.111s)
             Mean action noise std: 2.73
          Mean value_function loss: 74.2812
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 62.5756
                       Mean reward: 399.57
               Mean episode length: 230.77
    Episode_Reward/reaching_object: 1.3569
    Episode_Reward/rotating_object: 76.1520
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 2.05s
                      Time elapsed: 00:22:28
                               ETA: 00:30:03

################################################################################
                     [1m Learning iteration 642/1500 [0m                      

                       Computation: 48295 steps/s (collection: 1.921s, learning 0.114s)
             Mean action noise std: 2.74
          Mean value_function loss: 69.6245
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 62.6060
                       Mean reward: 391.59
               Mean episode length: 236.62
    Episode_Reward/reaching_object: 1.3836
    Episode_Reward/rotating_object: 78.1514
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 2.04s
                      Time elapsed: 00:22:30
                               ETA: 00:30:01

################################################################################
                     [1m Learning iteration 643/1500 [0m                      

                       Computation: 48304 steps/s (collection: 1.924s, learning 0.111s)
             Mean action noise std: 2.74
          Mean value_function loss: 72.8564
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 62.6189
                       Mean reward: 368.78
               Mean episode length: 240.49
    Episode_Reward/reaching_object: 1.3762
    Episode_Reward/rotating_object: 72.9284
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 2.04s
                      Time elapsed: 00:22:32
                               ETA: 00:29:59

################################################################################
                     [1m Learning iteration 644/1500 [0m                      

                       Computation: 48616 steps/s (collection: 1.908s, learning 0.114s)
             Mean action noise std: 2.74
          Mean value_function loss: 68.5400
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 62.6443
                       Mean reward: 388.49
               Mean episode length: 238.83
    Episode_Reward/reaching_object: 1.3986
    Episode_Reward/rotating_object: 80.1015
        Episode_Reward/action_rate: -0.0464
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 2.02s
                      Time elapsed: 00:22:34
                               ETA: 00:29:57

################################################################################
                     [1m Learning iteration 645/1500 [0m                      

                       Computation: 48056 steps/s (collection: 1.933s, learning 0.113s)
             Mean action noise std: 2.75
          Mean value_function loss: 77.5786
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 62.6828
                       Mean reward: 346.22
               Mean episode length: 234.36
    Episode_Reward/reaching_object: 1.3845
    Episode_Reward/rotating_object: 79.7964
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 2.05s
                      Time elapsed: 00:22:36
                               ETA: 00:29:55

################################################################################
                     [1m Learning iteration 646/1500 [0m                      

                       Computation: 49054 steps/s (collection: 1.891s, learning 0.113s)
             Mean action noise std: 2.75
          Mean value_function loss: 75.1776
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 62.7128
                       Mean reward: 409.81
               Mean episode length: 243.70
    Episode_Reward/reaching_object: 1.3859
    Episode_Reward/rotating_object: 76.7266
        Episode_Reward/action_rate: -0.0468
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 2.00s
                      Time elapsed: 00:22:38
                               ETA: 00:29:53

################################################################################
                     [1m Learning iteration 647/1500 [0m                      

                       Computation: 48347 steps/s (collection: 1.921s, learning 0.113s)
             Mean action noise std: 2.75
          Mean value_function loss: 88.5990
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 62.7386
                       Mean reward: 399.67
               Mean episode length: 236.96
    Episode_Reward/reaching_object: 1.3719
    Episode_Reward/rotating_object: 74.3713
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 2.03s
                      Time elapsed: 00:22:40
                               ETA: 00:29:50

################################################################################
                     [1m Learning iteration 648/1500 [0m                      

                       Computation: 48726 steps/s (collection: 1.905s, learning 0.113s)
             Mean action noise std: 2.75
          Mean value_function loss: 78.9277
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 62.7517
                       Mean reward: 404.00
               Mean episode length: 228.93
    Episode_Reward/reaching_object: 1.3930
    Episode_Reward/rotating_object: 79.8896
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 2.02s
                      Time elapsed: 00:22:42
                               ETA: 00:29:48

################################################################################
                     [1m Learning iteration 649/1500 [0m                      

                       Computation: 47980 steps/s (collection: 1.936s, learning 0.113s)
             Mean action noise std: 2.76
          Mean value_function loss: 72.5261
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 62.7751
                       Mean reward: 360.62
               Mean episode length: 236.93
    Episode_Reward/reaching_object: 1.4125
    Episode_Reward/rotating_object: 76.4422
        Episode_Reward/action_rate: -0.0472
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 2.05s
                      Time elapsed: 00:22:44
                               ETA: 00:29:46

################################################################################
                     [1m Learning iteration 650/1500 [0m                      

                       Computation: 48400 steps/s (collection: 1.920s, learning 0.111s)
             Mean action noise std: 2.76
          Mean value_function loss: 80.7672
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 62.8083
                       Mean reward: 378.76
               Mean episode length: 235.75
    Episode_Reward/reaching_object: 1.3867
    Episode_Reward/rotating_object: 76.3736
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 2.03s
                      Time elapsed: 00:22:46
                               ETA: 00:29:44

################################################################################
                     [1m Learning iteration 651/1500 [0m                      

                       Computation: 47014 steps/s (collection: 1.979s, learning 0.112s)
             Mean action noise std: 2.76
          Mean value_function loss: 84.6183
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 62.8299
                       Mean reward: 412.39
               Mean episode length: 234.66
    Episode_Reward/reaching_object: 1.3814
    Episode_Reward/rotating_object: 78.4898
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 2.09s
                      Time elapsed: 00:22:48
                               ETA: 00:29:42

################################################################################
                     [1m Learning iteration 652/1500 [0m                      

                       Computation: 48152 steps/s (collection: 1.928s, learning 0.114s)
             Mean action noise std: 2.76
          Mean value_function loss: 84.0077
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 62.8495
                       Mean reward: 387.23
               Mean episode length: 238.39
    Episode_Reward/reaching_object: 1.3648
    Episode_Reward/rotating_object: 73.6103
        Episode_Reward/action_rate: -0.0464
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 2.04s
                      Time elapsed: 00:22:50
                               ETA: 00:29:39

################################################################################
                     [1m Learning iteration 653/1500 [0m                      

                       Computation: 48770 steps/s (collection: 1.905s, learning 0.111s)
             Mean action noise std: 2.77
          Mean value_function loss: 76.9727
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 62.8775
                       Mean reward: 381.36
               Mean episode length: 235.09
    Episode_Reward/reaching_object: 1.3950
    Episode_Reward/rotating_object: 77.0450
        Episode_Reward/action_rate: -0.0471
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 2.02s
                      Time elapsed: 00:22:52
                               ETA: 00:29:37

################################################################################
                     [1m Learning iteration 654/1500 [0m                      

                       Computation: 48732 steps/s (collection: 1.906s, learning 0.111s)
             Mean action noise std: 2.77
          Mean value_function loss: 72.9314
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 62.9065
                       Mean reward: 433.25
               Mean episode length: 237.13
    Episode_Reward/reaching_object: 1.3995
    Episode_Reward/rotating_object: 79.3979
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 2.02s
                      Time elapsed: 00:22:54
                               ETA: 00:29:35

################################################################################
                     [1m Learning iteration 655/1500 [0m                      

                       Computation: 49497 steps/s (collection: 1.872s, learning 0.114s)
             Mean action noise std: 2.77
          Mean value_function loss: 64.7126
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 62.9307
                       Mean reward: 408.76
               Mean episode length: 237.08
    Episode_Reward/reaching_object: 1.3897
    Episode_Reward/rotating_object: 80.7359
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 1.99s
                      Time elapsed: 00:22:56
                               ETA: 00:29:33

################################################################################
                     [1m Learning iteration 656/1500 [0m                      

                       Computation: 49375 steps/s (collection: 1.881s, learning 0.110s)
             Mean action noise std: 2.78
          Mean value_function loss: 71.5869
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 62.9532
                       Mean reward: 402.93
               Mean episode length: 243.82
    Episode_Reward/reaching_object: 1.4059
    Episode_Reward/rotating_object: 79.2797
        Episode_Reward/action_rate: -0.0486
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 1.99s
                      Time elapsed: 00:22:58
                               ETA: 00:29:31

################################################################################
                     [1m Learning iteration 657/1500 [0m                      

                       Computation: 49806 steps/s (collection: 1.863s, learning 0.110s)
             Mean action noise std: 2.78
          Mean value_function loss: 75.0573
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 62.9767
                       Mean reward: 407.43
               Mean episode length: 239.61
    Episode_Reward/reaching_object: 1.3708
    Episode_Reward/rotating_object: 77.0834
        Episode_Reward/action_rate: -0.0472
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 1.97s
                      Time elapsed: 00:23:00
                               ETA: 00:29:28

################################################################################
                     [1m Learning iteration 658/1500 [0m                      

                       Computation: 49477 steps/s (collection: 1.876s, learning 0.110s)
             Mean action noise std: 2.78
          Mean value_function loss: 73.6130
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 63.0079
                       Mean reward: 389.00
               Mean episode length: 243.68
    Episode_Reward/reaching_object: 1.3709
    Episode_Reward/rotating_object: 77.4636
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 1.99s
                      Time elapsed: 00:23:02
                               ETA: 00:29:26

################################################################################
                     [1m Learning iteration 659/1500 [0m                      

                       Computation: 49866 steps/s (collection: 1.861s, learning 0.110s)
             Mean action noise std: 2.79
          Mean value_function loss: 75.1176
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 63.0424
                       Mean reward: 448.95
               Mean episode length: 244.00
    Episode_Reward/reaching_object: 1.3638
    Episode_Reward/rotating_object: 76.3868
        Episode_Reward/action_rate: -0.0470
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 1.97s
                      Time elapsed: 00:23:04
                               ETA: 00:29:24

################################################################################
                     [1m Learning iteration 660/1500 [0m                      

                       Computation: 49200 steps/s (collection: 1.888s, learning 0.110s)
             Mean action noise std: 2.79
          Mean value_function loss: 76.5204
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 63.0664
                       Mean reward: 452.58
               Mean episode length: 241.78
    Episode_Reward/reaching_object: 1.3891
    Episode_Reward/rotating_object: 81.6869
        Episode_Reward/action_rate: -0.0480
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 2.00s
                      Time elapsed: 00:23:06
                               ETA: 00:29:22

################################################################################
                     [1m Learning iteration 661/1500 [0m                      

                       Computation: 49152 steps/s (collection: 1.889s, learning 0.111s)
             Mean action noise std: 2.79
          Mean value_function loss: 72.3855
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 63.0836
                       Mean reward: 403.75
               Mean episode length: 241.57
    Episode_Reward/reaching_object: 1.3683
    Episode_Reward/rotating_object: 75.7131
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 2.00s
                      Time elapsed: 00:23:08
                               ETA: 00:29:19

################################################################################
                     [1m Learning iteration 662/1500 [0m                      

                       Computation: 48668 steps/s (collection: 1.907s, learning 0.113s)
             Mean action noise std: 2.79
          Mean value_function loss: 82.0416
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 63.1107
                       Mean reward: 444.23
               Mean episode length: 241.84
    Episode_Reward/reaching_object: 1.4014
    Episode_Reward/rotating_object: 85.0785
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 2.02s
                      Time elapsed: 00:23:10
                               ETA: 00:29:17

################################################################################
                     [1m Learning iteration 663/1500 [0m                      

                       Computation: 48016 steps/s (collection: 1.935s, learning 0.112s)
             Mean action noise std: 2.80
          Mean value_function loss: 70.0199
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 63.1381
                       Mean reward: 395.88
               Mean episode length: 243.52
    Episode_Reward/reaching_object: 1.3751
    Episode_Reward/rotating_object: 76.7968
        Episode_Reward/action_rate: -0.0486
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 2.05s
                      Time elapsed: 00:23:12
                               ETA: 00:29:15

################################################################################
                     [1m Learning iteration 664/1500 [0m                      

                       Computation: 48392 steps/s (collection: 1.921s, learning 0.110s)
             Mean action noise std: 2.80
          Mean value_function loss: 80.6031
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 63.1688
                       Mean reward: 421.74
               Mean episode length: 237.09
    Episode_Reward/reaching_object: 1.3684
    Episode_Reward/rotating_object: 79.0073
        Episode_Reward/action_rate: -0.0480
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 2.03s
                      Time elapsed: 00:23:14
                               ETA: 00:29:13

################################################################################
                     [1m Learning iteration 665/1500 [0m                      

                       Computation: 48404 steps/s (collection: 1.918s, learning 0.113s)
             Mean action noise std: 2.80
          Mean value_function loss: 71.9440
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 63.1960
                       Mean reward: 370.66
               Mean episode length: 236.62
    Episode_Reward/reaching_object: 1.3487
    Episode_Reward/rotating_object: 77.9884
        Episode_Reward/action_rate: -0.0480
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 2.03s
                      Time elapsed: 00:23:16
                               ETA: 00:29:11

################################################################################
                     [1m Learning iteration 666/1500 [0m                      

                       Computation: 48689 steps/s (collection: 1.905s, learning 0.114s)
             Mean action noise std: 2.81
          Mean value_function loss: 78.8269
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 63.2337
                       Mean reward: 390.58
               Mean episode length: 230.86
    Episode_Reward/reaching_object: 1.3449
    Episode_Reward/rotating_object: 78.2633
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 2.02s
                      Time elapsed: 00:23:18
                               ETA: 00:29:08

################################################################################
                     [1m Learning iteration 667/1500 [0m                      

                       Computation: 48594 steps/s (collection: 1.908s, learning 0.115s)
             Mean action noise std: 2.81
          Mean value_function loss: 71.6234
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 63.2690
                       Mean reward: 398.77
               Mean episode length: 242.57
    Episode_Reward/reaching_object: 1.3782
    Episode_Reward/rotating_object: 79.6378
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 2.02s
                      Time elapsed: 00:23:20
                               ETA: 00:29:06

################################################################################
                     [1m Learning iteration 668/1500 [0m                      

                       Computation: 48788 steps/s (collection: 1.904s, learning 0.110s)
             Mean action noise std: 2.81
          Mean value_function loss: 67.1272
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 63.2866
                       Mean reward: 360.98
               Mean episode length: 235.93
    Episode_Reward/reaching_object: 1.4062
    Episode_Reward/rotating_object: 78.8987
        Episode_Reward/action_rate: -0.0495
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 2.01s
                      Time elapsed: 00:23:22
                               ETA: 00:29:04

################################################################################
                     [1m Learning iteration 669/1500 [0m                      

                       Computation: 48715 steps/s (collection: 1.907s, learning 0.111s)
             Mean action noise std: 2.82
          Mean value_function loss: 64.5177
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 63.3176
                       Mean reward: 417.12
               Mean episode length: 244.04
    Episode_Reward/reaching_object: 1.4064
    Episode_Reward/rotating_object: 85.0198
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 2.02s
                      Time elapsed: 00:23:24
                               ETA: 00:29:02

################################################################################
                     [1m Learning iteration 670/1500 [0m                      

                       Computation: 48792 steps/s (collection: 1.905s, learning 0.110s)
             Mean action noise std: 2.82
          Mean value_function loss: 75.7825
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 63.3490
                       Mean reward: 407.54
               Mean episode length: 239.08
    Episode_Reward/reaching_object: 1.3491
    Episode_Reward/rotating_object: 77.4569
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 2.01s
                      Time elapsed: 00:23:26
                               ETA: 00:29:00

################################################################################
                     [1m Learning iteration 671/1500 [0m                      

                       Computation: 48586 steps/s (collection: 1.913s, learning 0.110s)
             Mean action noise std: 2.82
          Mean value_function loss: 74.2904
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 63.3784
                       Mean reward: 399.36
               Mean episode length: 233.01
    Episode_Reward/reaching_object: 1.3406
    Episode_Reward/rotating_object: 76.2339
        Episode_Reward/action_rate: -0.0482
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 2.02s
                      Time elapsed: 00:23:28
                               ETA: 00:28:57

################################################################################
                     [1m Learning iteration 672/1500 [0m                      

                       Computation: 48845 steps/s (collection: 1.900s, learning 0.113s)
             Mean action noise std: 2.83
          Mean value_function loss: 78.0123
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 63.4109
                       Mean reward: 444.26
               Mean episode length: 237.47
    Episode_Reward/reaching_object: 1.3793
    Episode_Reward/rotating_object: 81.7364
        Episode_Reward/action_rate: -0.0490
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 2.01s
                      Time elapsed: 00:23:30
                               ETA: 00:28:55

################################################################################
                     [1m Learning iteration 673/1500 [0m                      

                       Computation: 48567 steps/s (collection: 1.911s, learning 0.113s)
             Mean action noise std: 2.83
          Mean value_function loss: 76.7886
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 63.4353
                       Mean reward: 401.02
               Mean episode length: 234.02
    Episode_Reward/reaching_object: 1.3577
    Episode_Reward/rotating_object: 77.6808
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 2.02s
                      Time elapsed: 00:23:32
                               ETA: 00:28:53

################################################################################
                     [1m Learning iteration 674/1500 [0m                      

                       Computation: 49045 steps/s (collection: 1.894s, learning 0.110s)
             Mean action noise std: 2.83
          Mean value_function loss: 74.1567
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 63.4614
                       Mean reward: 411.13
               Mean episode length: 237.81
    Episode_Reward/reaching_object: 1.3852
    Episode_Reward/rotating_object: 83.5180
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 2.00s
                      Time elapsed: 00:23:34
                               ETA: 00:28:51

################################################################################
                     [1m Learning iteration 675/1500 [0m                      

                       Computation: 48128 steps/s (collection: 1.932s, learning 0.110s)
             Mean action noise std: 2.84
          Mean value_function loss: 73.0317
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 63.4761
                       Mean reward: 392.36
               Mean episode length: 232.01
    Episode_Reward/reaching_object: 1.3491
    Episode_Reward/rotating_object: 78.9541
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 2.04s
                      Time elapsed: 00:23:36
                               ETA: 00:28:49

################################################################################
                     [1m Learning iteration 676/1500 [0m                      

                       Computation: 48488 steps/s (collection: 1.912s, learning 0.116s)
             Mean action noise std: 2.84
          Mean value_function loss: 71.8441
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 63.5073
                       Mean reward: 414.97
               Mean episode length: 240.41
    Episode_Reward/reaching_object: 1.3462
    Episode_Reward/rotating_object: 77.9046
        Episode_Reward/action_rate: -0.0493
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 2.03s
                      Time elapsed: 00:23:38
                               ETA: 00:28:47

################################################################################
                     [1m Learning iteration 677/1500 [0m                      

                       Computation: 48309 steps/s (collection: 1.924s, learning 0.111s)
             Mean action noise std: 2.84
          Mean value_function loss: 68.6738
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 63.5384
                       Mean reward: 422.58
               Mean episode length: 234.70
    Episode_Reward/reaching_object: 1.3813
    Episode_Reward/rotating_object: 80.8237
        Episode_Reward/action_rate: -0.0501
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 2.03s
                      Time elapsed: 00:23:40
                               ETA: 00:28:44

################################################################################
                     [1m Learning iteration 678/1500 [0m                      

                       Computation: 48219 steps/s (collection: 1.928s, learning 0.111s)
             Mean action noise std: 2.84
          Mean value_function loss: 75.1431
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 63.5633
                       Mean reward: 423.01
               Mean episode length: 245.23
    Episode_Reward/reaching_object: 1.3584
    Episode_Reward/rotating_object: 78.9813
        Episode_Reward/action_rate: -0.0497
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 2.04s
                      Time elapsed: 00:23:43
                               ETA: 00:28:42

################################################################################
                     [1m Learning iteration 679/1500 [0m                      

                       Computation: 49333 steps/s (collection: 1.882s, learning 0.111s)
             Mean action noise std: 2.85
          Mean value_function loss: 63.1192
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 63.5820
                       Mean reward: 434.21
               Mean episode length: 243.29
    Episode_Reward/reaching_object: 1.3745
    Episode_Reward/rotating_object: 80.4663
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 1.99s
                      Time elapsed: 00:23:45
                               ETA: 00:28:40

################################################################################
                     [1m Learning iteration 680/1500 [0m                      

                       Computation: 49367 steps/s (collection: 1.881s, learning 0.111s)
             Mean action noise std: 2.85
          Mean value_function loss: 71.5992
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 63.6126
                       Mean reward: 402.53
               Mean episode length: 239.11
    Episode_Reward/reaching_object: 1.3569
    Episode_Reward/rotating_object: 78.9186
        Episode_Reward/action_rate: -0.0501
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 1.99s
                      Time elapsed: 00:23:47
                               ETA: 00:28:38

################################################################################
                     [1m Learning iteration 681/1500 [0m                      

                       Computation: 49660 steps/s (collection: 1.869s, learning 0.111s)
             Mean action noise std: 2.86
          Mean value_function loss: 71.5821
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 63.6550
                       Mean reward: 408.86
               Mean episode length: 237.85
    Episode_Reward/reaching_object: 1.3562
    Episode_Reward/rotating_object: 79.8458
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 1.98s
                      Time elapsed: 00:23:48
                               ETA: 00:28:36

################################################################################
                     [1m Learning iteration 682/1500 [0m                      

                       Computation: 48704 steps/s (collection: 1.907s, learning 0.112s)
             Mean action noise std: 2.86
          Mean value_function loss: 70.2870
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 63.6894
                       Mean reward: 410.49
               Mean episode length: 239.19
    Episode_Reward/reaching_object: 1.3741
    Episode_Reward/rotating_object: 81.1661
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 2.02s
                      Time elapsed: 00:23:51
                               ETA: 00:28:33

################################################################################
                     [1m Learning iteration 683/1500 [0m                      

                       Computation: 49649 steps/s (collection: 1.870s, learning 0.110s)
             Mean action noise std: 2.86
          Mean value_function loss: 78.2366
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 63.7141
                       Mean reward: 333.64
               Mean episode length: 223.37
    Episode_Reward/reaching_object: 1.3152
    Episode_Reward/rotating_object: 75.1376
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 1.98s
                      Time elapsed: 00:23:52
                               ETA: 00:28:31

################################################################################
                     [1m Learning iteration 684/1500 [0m                      

                       Computation: 48962 steps/s (collection: 1.895s, learning 0.113s)
             Mean action noise std: 2.87
          Mean value_function loss: 75.5735
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 63.7438
                       Mean reward: 397.89
               Mean episode length: 233.89
    Episode_Reward/reaching_object: 1.3655
    Episode_Reward/rotating_object: 76.8512
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 2.01s
                      Time elapsed: 00:23:55
                               ETA: 00:28:29

################################################################################
                     [1m Learning iteration 685/1500 [0m                      

                       Computation: 49443 steps/s (collection: 1.878s, learning 0.111s)
             Mean action noise std: 2.87
          Mean value_function loss: 72.0665
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 63.7779
                       Mean reward: 413.71
               Mean episode length: 235.51
    Episode_Reward/reaching_object: 1.3337
    Episode_Reward/rotating_object: 77.6044
        Episode_Reward/action_rate: -0.0495
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 1.99s
                      Time elapsed: 00:23:56
                               ETA: 00:28:27

################################################################################
                     [1m Learning iteration 686/1500 [0m                      

                       Computation: 48234 steps/s (collection: 1.925s, learning 0.113s)
             Mean action noise std: 2.87
          Mean value_function loss: 81.3165
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 63.8075
                       Mean reward: 409.16
               Mean episode length: 233.18
    Episode_Reward/reaching_object: 1.3588
    Episode_Reward/rotating_object: 78.4011
        Episode_Reward/action_rate: -0.0504
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 2.04s
                      Time elapsed: 00:23:59
                               ETA: 00:28:25

################################################################################
                     [1m Learning iteration 687/1500 [0m                      

                       Computation: 48172 steps/s (collection: 1.930s, learning 0.111s)
             Mean action noise std: 2.88
          Mean value_function loss: 83.0880
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 63.8338
                       Mean reward: 426.07
               Mean episode length: 237.97
    Episode_Reward/reaching_object: 1.3581
    Episode_Reward/rotating_object: 78.6948
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 2.04s
                      Time elapsed: 00:24:01
                               ETA: 00:28:22

################################################################################
                     [1m Learning iteration 688/1500 [0m                      

                       Computation: 47352 steps/s (collection: 1.965s, learning 0.111s)
             Mean action noise std: 2.88
          Mean value_function loss: 78.3907
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 63.8456
                       Mean reward: 396.09
               Mean episode length: 236.28
    Episode_Reward/reaching_object: 1.3657
    Episode_Reward/rotating_object: 78.8910
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 2.08s
                      Time elapsed: 00:24:03
                               ETA: 00:28:20

################################################################################
                     [1m Learning iteration 689/1500 [0m                      

                       Computation: 47721 steps/s (collection: 1.947s, learning 0.112s)
             Mean action noise std: 2.88
          Mean value_function loss: 73.3370
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 63.8713
                       Mean reward: 447.10
               Mean episode length: 242.89
    Episode_Reward/reaching_object: 1.3852
    Episode_Reward/rotating_object: 81.8433
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 2.06s
                      Time elapsed: 00:24:05
                               ETA: 00:28:18

################################################################################
                     [1m Learning iteration 690/1500 [0m                      

                       Computation: 48218 steps/s (collection: 1.929s, learning 0.110s)
             Mean action noise std: 2.88
          Mean value_function loss: 69.3661
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 63.8955
                       Mean reward: 394.59
               Mean episode length: 240.34
    Episode_Reward/reaching_object: 1.3919
    Episode_Reward/rotating_object: 80.2197
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 2.04s
                      Time elapsed: 00:24:07
                               ETA: 00:28:16

################################################################################
                     [1m Learning iteration 691/1500 [0m                      

                       Computation: 48357 steps/s (collection: 1.921s, learning 0.112s)
             Mean action noise std: 2.89
          Mean value_function loss: 79.0731
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 63.9199
                       Mean reward: 401.41
               Mean episode length: 239.68
    Episode_Reward/reaching_object: 1.3571
    Episode_Reward/rotating_object: 80.2681
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 2.03s
                      Time elapsed: 00:24:09
                               ETA: 00:28:14

################################################################################
                     [1m Learning iteration 692/1500 [0m                      

                       Computation: 48712 steps/s (collection: 1.906s, learning 0.112s)
             Mean action noise std: 2.89
          Mean value_function loss: 67.5244
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 63.9503
                       Mean reward: 402.92
               Mean episode length: 234.41
    Episode_Reward/reaching_object: 1.3640
    Episode_Reward/rotating_object: 79.3029
        Episode_Reward/action_rate: -0.0514
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 2.02s
                      Time elapsed: 00:24:11
                               ETA: 00:28:12

################################################################################
                     [1m Learning iteration 693/1500 [0m                      

                       Computation: 48117 steps/s (collection: 1.928s, learning 0.115s)
             Mean action noise std: 2.89
          Mean value_function loss: 79.4598
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 63.9762
                       Mean reward: 432.87
               Mean episode length: 242.40
    Episode_Reward/reaching_object: 1.3939
    Episode_Reward/rotating_object: 83.6160
        Episode_Reward/action_rate: -0.0517
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 2.04s
                      Time elapsed: 00:24:13
                               ETA: 00:28:09

################################################################################
                     [1m Learning iteration 694/1500 [0m                      

                       Computation: 48803 steps/s (collection: 1.902s, learning 0.112s)
             Mean action noise std: 2.90
          Mean value_function loss: 77.6530
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 64.0029
                       Mean reward: 394.11
               Mean episode length: 236.66
    Episode_Reward/reaching_object: 1.3786
    Episode_Reward/rotating_object: 83.8573
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 2.01s
                      Time elapsed: 00:24:15
                               ETA: 00:28:07

################################################################################
                     [1m Learning iteration 695/1500 [0m                      

                       Computation: 48188 steps/s (collection: 1.928s, learning 0.112s)
             Mean action noise std: 2.90
          Mean value_function loss: 75.0095
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 64.0291
                       Mean reward: 432.27
               Mean episode length: 239.43
    Episode_Reward/reaching_object: 1.3576
    Episode_Reward/rotating_object: 81.4159
        Episode_Reward/action_rate: -0.0517
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 2.04s
                      Time elapsed: 00:24:17
                               ETA: 00:28:05

################################################################################
                     [1m Learning iteration 696/1500 [0m                      

                       Computation: 48968 steps/s (collection: 1.898s, learning 0.110s)
             Mean action noise std: 2.90
          Mean value_function loss: 67.4495
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 64.0529
                       Mean reward: 436.69
               Mean episode length: 244.13
    Episode_Reward/reaching_object: 1.3728
    Episode_Reward/rotating_object: 80.0987
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 2.01s
                      Time elapsed: 00:24:19
                               ETA: 00:28:03

################################################################################
                     [1m Learning iteration 697/1500 [0m                      

                       Computation: 48193 steps/s (collection: 1.927s, learning 0.113s)
             Mean action noise std: 2.90
          Mean value_function loss: 72.9404
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 64.0733
                       Mean reward: 426.09
               Mean episode length: 242.30
    Episode_Reward/reaching_object: 1.3724
    Episode_Reward/rotating_object: 81.2590
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 2.04s
                      Time elapsed: 00:24:21
                               ETA: 00:28:01

################################################################################
                     [1m Learning iteration 698/1500 [0m                      

                       Computation: 48475 steps/s (collection: 1.915s, learning 0.113s)
             Mean action noise std: 2.91
          Mean value_function loss: 84.0596
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 64.0943
                       Mean reward: 380.81
               Mean episode length: 239.38
    Episode_Reward/reaching_object: 1.3653
    Episode_Reward/rotating_object: 80.9564
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 2.03s
                      Time elapsed: 00:24:23
                               ETA: 00:27:59

################################################################################
                     [1m Learning iteration 699/1500 [0m                      

                       Computation: 47962 steps/s (collection: 1.937s, learning 0.113s)
             Mean action noise std: 2.91
          Mean value_function loss: 79.2895
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 64.1191
                       Mean reward: 407.10
               Mean episode length: 241.19
    Episode_Reward/reaching_object: 1.3543
    Episode_Reward/rotating_object: 82.3939
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 2.05s
                      Time elapsed: 00:24:25
                               ETA: 00:27:56

################################################################################
                     [1m Learning iteration 700/1500 [0m                      

                       Computation: 47932 steps/s (collection: 1.925s, learning 0.126s)
             Mean action noise std: 2.91
          Mean value_function loss: 74.6816
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 64.1482
                       Mean reward: 370.15
               Mean episode length: 223.39
    Episode_Reward/reaching_object: 1.2976
    Episode_Reward/rotating_object: 73.8334
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 2.05s
                      Time elapsed: 00:24:27
                               ETA: 00:27:54

################################################################################
                     [1m Learning iteration 701/1500 [0m                      

                       Computation: 48477 steps/s (collection: 1.902s, learning 0.126s)
             Mean action noise std: 2.92
          Mean value_function loss: 65.0466
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 64.1684
                       Mean reward: 401.24
               Mean episode length: 228.20
    Episode_Reward/reaching_object: 1.3814
    Episode_Reward/rotating_object: 84.5064
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 2.03s
                      Time elapsed: 00:24:29
                               ETA: 00:27:52

################################################################################
                     [1m Learning iteration 702/1500 [0m                      

                       Computation: 48823 steps/s (collection: 1.891s, learning 0.122s)
             Mean action noise std: 2.92
          Mean value_function loss: 61.1628
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 64.1820
                       Mean reward: 402.87
               Mean episode length: 233.36
    Episode_Reward/reaching_object: 1.3350
    Episode_Reward/rotating_object: 80.3531
        Episode_Reward/action_rate: -0.0529
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 2.01s
                      Time elapsed: 00:24:31
                               ETA: 00:27:50

################################################################################
                     [1m Learning iteration 703/1500 [0m                      

                       Computation: 49754 steps/s (collection: 1.854s, learning 0.122s)
             Mean action noise std: 2.92
          Mean value_function loss: 73.2243
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 64.2038
                       Mean reward: 404.73
               Mean episode length: 240.31
    Episode_Reward/reaching_object: 1.3879
    Episode_Reward/rotating_object: 83.8231
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 1.98s
                      Time elapsed: 00:24:33
                               ETA: 00:27:48

################################################################################
                     [1m Learning iteration 704/1500 [0m                      

                       Computation: 48654 steps/s (collection: 1.898s, learning 0.123s)
             Mean action noise std: 2.92
          Mean value_function loss: 73.1642
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 64.2296
                       Mean reward: 447.74
               Mean episode length: 240.26
    Episode_Reward/reaching_object: 1.3744
    Episode_Reward/rotating_object: 82.4365
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 2.02s
                      Time elapsed: 00:24:35
                               ETA: 00:27:46

################################################################################
                     [1m Learning iteration 705/1500 [0m                      

                       Computation: 48951 steps/s (collection: 1.886s, learning 0.123s)
             Mean action noise std: 2.93
          Mean value_function loss: 69.6551
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 64.2589
                       Mean reward: 422.71
               Mean episode length: 240.50
    Episode_Reward/reaching_object: 1.3874
    Episode_Reward/rotating_object: 82.2385
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 2.01s
                      Time elapsed: 00:24:37
                               ETA: 00:27:43

################################################################################
                     [1m Learning iteration 706/1500 [0m                      

                       Computation: 48646 steps/s (collection: 1.898s, learning 0.122s)
             Mean action noise std: 2.93
          Mean value_function loss: 74.9504
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 64.2920
                       Mean reward: 420.84
               Mean episode length: 240.49
    Episode_Reward/reaching_object: 1.3658
    Episode_Reward/rotating_object: 82.1597
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 2.02s
                      Time elapsed: 00:24:39
                               ETA: 00:27:41

################################################################################
                     [1m Learning iteration 707/1500 [0m                      

                       Computation: 48926 steps/s (collection: 1.887s, learning 0.123s)
             Mean action noise std: 2.94
          Mean value_function loss: 75.8415
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 64.3242
                       Mean reward: 385.63
               Mean episode length: 237.95
    Episode_Reward/reaching_object: 1.3565
    Episode_Reward/rotating_object: 79.4932
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 2.01s
                      Time elapsed: 00:24:41
                               ETA: 00:27:39

################################################################################
                     [1m Learning iteration 708/1500 [0m                      

                       Computation: 47890 steps/s (collection: 1.931s, learning 0.122s)
             Mean action noise std: 2.94
          Mean value_function loss: 82.1500
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 64.3556
                       Mean reward: 423.74
               Mean episode length: 237.69
    Episode_Reward/reaching_object: 1.3574
    Episode_Reward/rotating_object: 83.7750
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 2.05s
                      Time elapsed: 00:24:43
                               ETA: 00:27:37

################################################################################
                     [1m Learning iteration 709/1500 [0m                      

                       Computation: 47680 steps/s (collection: 1.939s, learning 0.123s)
             Mean action noise std: 2.94
          Mean value_function loss: 76.8393
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 64.3710
                       Mean reward: 397.27
               Mean episode length: 237.85
    Episode_Reward/reaching_object: 1.3523
    Episode_Reward/rotating_object: 79.3977
        Episode_Reward/action_rate: -0.0536
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 2.06s
                      Time elapsed: 00:24:45
                               ETA: 00:27:35

################################################################################
                     [1m Learning iteration 710/1500 [0m                      

                       Computation: 47521 steps/s (collection: 1.956s, learning 0.113s)
             Mean action noise std: 2.94
          Mean value_function loss: 79.4943
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 64.3944
                       Mean reward: 409.46
               Mean episode length: 236.56
    Episode_Reward/reaching_object: 1.3533
    Episode_Reward/rotating_object: 81.7781
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 2.07s
                      Time elapsed: 00:24:47
                               ETA: 00:27:33

################################################################################
                     [1m Learning iteration 711/1500 [0m                      

                       Computation: 48323 steps/s (collection: 1.921s, learning 0.113s)
             Mean action noise std: 2.95
          Mean value_function loss: 76.9639
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 64.4248
                       Mean reward: 418.14
               Mean episode length: 235.15
    Episode_Reward/reaching_object: 1.3746
    Episode_Reward/rotating_object: 79.4570
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 2.03s
                      Time elapsed: 00:24:49
                               ETA: 00:27:30

################################################################################
                     [1m Learning iteration 712/1500 [0m                      

                       Computation: 48379 steps/s (collection: 1.920s, learning 0.112s)
             Mean action noise std: 2.95
          Mean value_function loss: 70.1775
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 64.4577
                       Mean reward: 447.52
               Mean episode length: 242.56
    Episode_Reward/reaching_object: 1.3772
    Episode_Reward/rotating_object: 84.8248
        Episode_Reward/action_rate: -0.0538
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 2.03s
                      Time elapsed: 00:24:51
                               ETA: 00:27:28

################################################################################
                     [1m Learning iteration 713/1500 [0m                      

                       Computation: 47547 steps/s (collection: 1.957s, learning 0.110s)
             Mean action noise std: 2.95
          Mean value_function loss: 77.8578
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 64.4883
                       Mean reward: 440.03
               Mean episode length: 239.07
    Episode_Reward/reaching_object: 1.3543
    Episode_Reward/rotating_object: 83.5816
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 2.07s
                      Time elapsed: 00:24:53
                               ETA: 00:27:26

################################################################################
                     [1m Learning iteration 714/1500 [0m                      

                       Computation: 48320 steps/s (collection: 1.915s, learning 0.120s)
             Mean action noise std: 2.96
          Mean value_function loss: 73.3316
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 64.5116
                       Mean reward: 395.02
               Mean episode length: 237.56
    Episode_Reward/reaching_object: 1.3742
    Episode_Reward/rotating_object: 82.3252
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 2.03s
                      Time elapsed: 00:24:55
                               ETA: 00:27:24

################################################################################
                     [1m Learning iteration 715/1500 [0m                      

                       Computation: 47789 steps/s (collection: 1.943s, learning 0.114s)
             Mean action noise std: 2.96
          Mean value_function loss: 80.9451
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 64.5348
                       Mean reward: 390.49
               Mean episode length: 242.53
    Episode_Reward/reaching_object: 1.3677
    Episode_Reward/rotating_object: 79.5064
        Episode_Reward/action_rate: -0.0544
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 2.06s
                      Time elapsed: 00:24:58
                               ETA: 00:27:22

################################################################################
                     [1m Learning iteration 716/1500 [0m                      

                       Computation: 47251 steps/s (collection: 1.969s, learning 0.111s)
             Mean action noise std: 2.96
          Mean value_function loss: 86.7852
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 64.5515
                       Mean reward: 404.25
               Mean episode length: 236.33
    Episode_Reward/reaching_object: 1.3599
    Episode_Reward/rotating_object: 82.9083
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 2.08s
                      Time elapsed: 00:25:00
                               ETA: 00:27:20

################################################################################
                     [1m Learning iteration 717/1500 [0m                      

                       Computation: 47640 steps/s (collection: 1.951s, learning 0.113s)
             Mean action noise std: 2.97
          Mean value_function loss: 82.3726
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 64.5811
                       Mean reward: 443.85
               Mean episode length: 245.84
    Episode_Reward/reaching_object: 1.3570
    Episode_Reward/rotating_object: 83.3881
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 2.06s
                      Time elapsed: 00:25:02
                               ETA: 00:27:18

################################################################################
                     [1m Learning iteration 718/1500 [0m                      

                       Computation: 48334 steps/s (collection: 1.923s, learning 0.111s)
             Mean action noise std: 2.97
          Mean value_function loss: 82.1924
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 64.6135
                       Mean reward: 461.91
               Mean episode length: 234.35
    Episode_Reward/reaching_object: 1.3674
    Episode_Reward/rotating_object: 86.3918
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 2.03s
                      Time elapsed: 00:25:04
                               ETA: 00:27:16

################################################################################
                     [1m Learning iteration 719/1500 [0m                      

                       Computation: 48193 steps/s (collection: 1.926s, learning 0.114s)
             Mean action noise std: 2.97
          Mean value_function loss: 81.1169
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 64.6394
                       Mean reward: 410.68
               Mean episode length: 240.47
    Episode_Reward/reaching_object: 1.3473
    Episode_Reward/rotating_object: 79.2115
        Episode_Reward/action_rate: -0.0538
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 2.04s
                      Time elapsed: 00:25:06
                               ETA: 00:27:13

################################################################################
                     [1m Learning iteration 720/1500 [0m                      

                       Computation: 48366 steps/s (collection: 1.922s, learning 0.111s)
             Mean action noise std: 2.98
          Mean value_function loss: 88.6171
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 64.6679
                       Mean reward: 423.72
               Mean episode length: 234.16
    Episode_Reward/reaching_object: 1.3645
    Episode_Reward/rotating_object: 80.4801
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 2.03s
                      Time elapsed: 00:25:08
                               ETA: 00:27:11

################################################################################
                     [1m Learning iteration 721/1500 [0m                      

                       Computation: 47720 steps/s (collection: 1.950s, learning 0.110s)
             Mean action noise std: 2.98
          Mean value_function loss: 78.3930
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 64.6866
                       Mean reward: 432.22
               Mean episode length: 235.46
    Episode_Reward/reaching_object: 1.3681
    Episode_Reward/rotating_object: 79.1313
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 2.06s
                      Time elapsed: 00:25:10
                               ETA: 00:27:09

################################################################################
                     [1m Learning iteration 722/1500 [0m                      

                       Computation: 48541 steps/s (collection: 1.915s, learning 0.111s)
             Mean action noise std: 2.98
          Mean value_function loss: 70.6217
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 64.7117
                       Mean reward: 417.63
               Mean episode length: 227.72
    Episode_Reward/reaching_object: 1.3750
    Episode_Reward/rotating_object: 78.4499
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 2.03s
                      Time elapsed: 00:25:12
                               ETA: 00:27:07

################################################################################
                     [1m Learning iteration 723/1500 [0m                      

                       Computation: 47606 steps/s (collection: 1.954s, learning 0.111s)
             Mean action noise std: 2.99
          Mean value_function loss: 78.2093
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 64.7457
                       Mean reward: 416.81
               Mean episode length: 236.43
    Episode_Reward/reaching_object: 1.3808
    Episode_Reward/rotating_object: 85.2617
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 2.06s
                      Time elapsed: 00:25:14
                               ETA: 00:27:05

################################################################################
                     [1m Learning iteration 724/1500 [0m                      

                       Computation: 48408 steps/s (collection: 1.918s, learning 0.113s)
             Mean action noise std: 2.99
          Mean value_function loss: 73.7785
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 64.7755
                       Mean reward: 420.01
               Mean episode length: 239.64
    Episode_Reward/reaching_object: 1.3856
    Episode_Reward/rotating_object: 80.8048
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 2.03s
                      Time elapsed: 00:25:16
                               ETA: 00:27:03

################################################################################
                     [1m Learning iteration 725/1500 [0m                      

                       Computation: 48237 steps/s (collection: 1.926s, learning 0.112s)
             Mean action noise std: 2.99
          Mean value_function loss: 70.5483
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 64.7959
                       Mean reward: 384.53
               Mean episode length: 232.99
    Episode_Reward/reaching_object: 1.3680
    Episode_Reward/rotating_object: 79.3538
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 2.04s
                      Time elapsed: 00:25:18
                               ETA: 00:27:01

################################################################################
                     [1m Learning iteration 726/1500 [0m                      

                       Computation: 48139 steps/s (collection: 1.925s, learning 0.117s)
             Mean action noise std: 2.99
          Mean value_function loss: 77.7422
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 64.8120
                       Mean reward: 422.14
               Mean episode length: 240.59
    Episode_Reward/reaching_object: 1.3768
    Episode_Reward/rotating_object: 80.0512
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 2.04s
                      Time elapsed: 00:25:20
                               ETA: 00:26:58

################################################################################
                     [1m Learning iteration 727/1500 [0m                      

                       Computation: 49277 steps/s (collection: 1.885s, learning 0.110s)
             Mean action noise std: 2.99
          Mean value_function loss: 74.7600
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 64.8221
                       Mean reward: 421.34
               Mean episode length: 234.46
    Episode_Reward/reaching_object: 1.3643
    Episode_Reward/rotating_object: 82.4233
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 1.99s
                      Time elapsed: 00:25:22
                               ETA: 00:26:56

################################################################################
                     [1m Learning iteration 728/1500 [0m                      

                       Computation: 48587 steps/s (collection: 1.905s, learning 0.118s)
             Mean action noise std: 3.00
          Mean value_function loss: 78.4651
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 64.8323
                       Mean reward: 426.44
               Mean episode length: 235.68
    Episode_Reward/reaching_object: 1.3628
    Episode_Reward/rotating_object: 81.6616
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 2.02s
                      Time elapsed: 00:25:24
                               ETA: 00:26:54

################################################################################
                     [1m Learning iteration 729/1500 [0m                      

                       Computation: 49186 steps/s (collection: 1.888s, learning 0.110s)
             Mean action noise std: 3.00
          Mean value_function loss: 74.0283
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 64.8507
                       Mean reward: 427.41
               Mean episode length: 246.88
    Episode_Reward/reaching_object: 1.3541
    Episode_Reward/rotating_object: 81.1684
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 2.00s
                      Time elapsed: 00:25:26
                               ETA: 00:26:52

################################################################################
                     [1m Learning iteration 730/1500 [0m                      

                       Computation: 49069 steps/s (collection: 1.893s, learning 0.110s)
             Mean action noise std: 3.00
          Mean value_function loss: 70.4419
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 64.8789
                       Mean reward: 445.50
               Mean episode length: 241.35
    Episode_Reward/reaching_object: 1.3605
    Episode_Reward/rotating_object: 85.5192
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 2.00s
                      Time elapsed: 00:25:28
                               ETA: 00:26:50

################################################################################
                     [1m Learning iteration 731/1500 [0m                      

                       Computation: 49519 steps/s (collection: 1.875s, learning 0.110s)
             Mean action noise std: 3.01
          Mean value_function loss: 70.6884
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 64.9215
                       Mean reward: 401.82
               Mean episode length: 234.75
    Episode_Reward/reaching_object: 1.3476
    Episode_Reward/rotating_object: 80.4706
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 1.99s
                      Time elapsed: 00:25:30
                               ETA: 00:26:47

################################################################################
                     [1m Learning iteration 732/1500 [0m                      

                       Computation: 49237 steps/s (collection: 1.886s, learning 0.110s)
             Mean action noise std: 3.01
          Mean value_function loss: 74.1862
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 64.9545
                       Mean reward: 396.26
               Mean episode length: 233.02
    Episode_Reward/reaching_object: 1.3388
    Episode_Reward/rotating_object: 80.0371
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 2.00s
                      Time elapsed: 00:25:32
                               ETA: 00:26:45

################################################################################
                     [1m Learning iteration 733/1500 [0m                      

                       Computation: 48934 steps/s (collection: 1.896s, learning 0.112s)
             Mean action noise std: 3.02
          Mean value_function loss: 70.7921
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 64.9835
                       Mean reward: 437.06
               Mean episode length: 239.87
    Episode_Reward/reaching_object: 1.3970
    Episode_Reward/rotating_object: 86.2017
        Episode_Reward/action_rate: -0.0566
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 2.01s
                      Time elapsed: 00:25:34
                               ETA: 00:26:43

################################################################################
                     [1m Learning iteration 734/1500 [0m                      

                       Computation: 48226 steps/s (collection: 1.921s, learning 0.118s)
             Mean action noise std: 3.02
          Mean value_function loss: 73.9160
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 65.0110
                       Mean reward: 393.52
               Mean episode length: 229.33
    Episode_Reward/reaching_object: 1.3567
    Episode_Reward/rotating_object: 84.5422
        Episode_Reward/action_rate: -0.0550
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 2.04s
                      Time elapsed: 00:25:36
                               ETA: 00:26:41

################################################################################
                     [1m Learning iteration 735/1500 [0m                      

                       Computation: 47190 steps/s (collection: 1.970s, learning 0.113s)
             Mean action noise std: 3.02
          Mean value_function loss: 73.9474
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 65.0368
                       Mean reward: 419.44
               Mean episode length: 239.67
    Episode_Reward/reaching_object: 1.3430
    Episode_Reward/rotating_object: 80.8932
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 2.08s
                      Time elapsed: 00:25:38
                               ETA: 00:26:39

################################################################################
                     [1m Learning iteration 736/1500 [0m                      

                       Computation: 47668 steps/s (collection: 1.946s, learning 0.117s)
             Mean action noise std: 3.03
          Mean value_function loss: 73.9688
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 65.0684
                       Mean reward: 401.53
               Mean episode length: 233.32
    Episode_Reward/reaching_object: 1.3455
    Episode_Reward/rotating_object: 79.1848
        Episode_Reward/action_rate: -0.0561
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 2.06s
                      Time elapsed: 00:25:40
                               ETA: 00:26:37

################################################################################
                     [1m Learning iteration 737/1500 [0m                      

                       Computation: 47804 steps/s (collection: 1.943s, learning 0.114s)
             Mean action noise std: 3.03
          Mean value_function loss: 77.2754
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 65.1010
                       Mean reward: 436.16
               Mean episode length: 233.01
    Episode_Reward/reaching_object: 1.3481
    Episode_Reward/rotating_object: 82.5009
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 2.06s
                      Time elapsed: 00:25:42
                               ETA: 00:26:35

################################################################################
                     [1m Learning iteration 738/1500 [0m                      

                       Computation: 47986 steps/s (collection: 1.938s, learning 0.111s)
             Mean action noise std: 3.04
          Mean value_function loss: 75.1757
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 65.1374
                       Mean reward: 414.45
               Mean episode length: 236.55
    Episode_Reward/reaching_object: 1.3576
    Episode_Reward/rotating_object: 81.1228
        Episode_Reward/action_rate: -0.0564
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 18.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 2.05s
                      Time elapsed: 00:25:44
                               ETA: 00:26:32

################################################################################
                     [1m Learning iteration 739/1500 [0m                      

                       Computation: 46151 steps/s (collection: 2.015s, learning 0.115s)
             Mean action noise std: 3.04
          Mean value_function loss: 82.0271
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 65.1852
                       Mean reward: 425.98
               Mean episode length: 235.28
    Episode_Reward/reaching_object: 1.3375
    Episode_Reward/rotating_object: 81.5679
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 2.13s
                      Time elapsed: 00:25:46
                               ETA: 00:26:30

################################################################################
                     [1m Learning iteration 740/1500 [0m                      

                       Computation: 47937 steps/s (collection: 1.940s, learning 0.111s)
             Mean action noise std: 3.04
          Mean value_function loss: 83.0089
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 65.2202
                       Mean reward: 446.37
               Mean episode length: 238.34
    Episode_Reward/reaching_object: 1.3402
    Episode_Reward/rotating_object: 81.8126
        Episode_Reward/action_rate: -0.0560
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 2.05s
                      Time elapsed: 00:25:49
                               ETA: 00:26:28

################################################################################
                     [1m Learning iteration 741/1500 [0m                      

                       Computation: 47768 steps/s (collection: 1.945s, learning 0.113s)
             Mean action noise std: 3.05
          Mean value_function loss: 82.3808
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 65.2417
                       Mean reward: 437.63
               Mean episode length: 235.08
    Episode_Reward/reaching_object: 1.3125
    Episode_Reward/rotating_object: 76.5896
        Episode_Reward/action_rate: -0.0556
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 2.06s
                      Time elapsed: 00:25:51
                               ETA: 00:26:26

################################################################################
                     [1m Learning iteration 742/1500 [0m                      

                       Computation: 47872 steps/s (collection: 1.943s, learning 0.110s)
             Mean action noise std: 3.05
          Mean value_function loss: 82.0692
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 65.2670
                       Mean reward: 402.90
               Mean episode length: 229.70
    Episode_Reward/reaching_object: 1.3257
    Episode_Reward/rotating_object: 81.2652
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 2.05s
                      Time elapsed: 00:25:53
                               ETA: 00:26:24

################################################################################
                     [1m Learning iteration 743/1500 [0m                      

                       Computation: 45509 steps/s (collection: 2.046s, learning 0.115s)
             Mean action noise std: 3.05
          Mean value_function loss: 73.1230
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 65.2837
                       Mean reward: 422.42
               Mean episode length: 233.81
    Episode_Reward/reaching_object: 1.3493
    Episode_Reward/rotating_object: 83.3031
        Episode_Reward/action_rate: -0.0563
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 2.16s
                      Time elapsed: 00:25:55
                               ETA: 00:26:22

################################################################################
                     [1m Learning iteration 744/1500 [0m                      

                       Computation: 45499 steps/s (collection: 2.050s, learning 0.111s)
             Mean action noise std: 3.05
          Mean value_function loss: 73.2121
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 65.3053
                       Mean reward: 418.29
               Mean episode length: 235.61
    Episode_Reward/reaching_object: 1.3252
    Episode_Reward/rotating_object: 78.5726
        Episode_Reward/action_rate: -0.0563
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 2.16s
                      Time elapsed: 00:25:57
                               ETA: 00:26:20

################################################################################
                     [1m Learning iteration 745/1500 [0m                      

                       Computation: 45530 steps/s (collection: 2.046s, learning 0.113s)
             Mean action noise std: 3.06
          Mean value_function loss: 70.3139
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 65.3306
                       Mean reward: 460.39
               Mean episode length: 239.72
    Episode_Reward/reaching_object: 1.3802
    Episode_Reward/rotating_object: 84.5049
        Episode_Reward/action_rate: -0.0576
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 2.16s
                      Time elapsed: 00:25:59
                               ETA: 00:26:18

################################################################################
                     [1m Learning iteration 746/1500 [0m                      

                       Computation: 45559 steps/s (collection: 2.047s, learning 0.111s)
             Mean action noise std: 3.06
          Mean value_function loss: 73.7829
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 65.3550
                       Mean reward: 427.67
               Mean episode length: 240.85
    Episode_Reward/reaching_object: 1.3606
    Episode_Reward/rotating_object: 81.8239
        Episode_Reward/action_rate: -0.0574
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 2.16s
                      Time elapsed: 00:26:01
                               ETA: 00:26:16

################################################################################
                     [1m Learning iteration 747/1500 [0m                      

                       Computation: 46983 steps/s (collection: 1.967s, learning 0.126s)
             Mean action noise std: 3.07
          Mean value_function loss: 71.1299
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 65.3873
                       Mean reward: 409.88
               Mean episode length: 238.08
    Episode_Reward/reaching_object: 1.3409
    Episode_Reward/rotating_object: 78.9641
        Episode_Reward/action_rate: -0.0565
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 2.09s
                      Time elapsed: 00:26:03
                               ETA: 00:26:14

################################################################################
                     [1m Learning iteration 748/1500 [0m                      

                       Computation: 47598 steps/s (collection: 1.950s, learning 0.116s)
             Mean action noise std: 3.07
          Mean value_function loss: 78.3224
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 65.4186
                       Mean reward: 398.96
               Mean episode length: 238.65
    Episode_Reward/reaching_object: 1.3421
    Episode_Reward/rotating_object: 82.6322
        Episode_Reward/action_rate: -0.0567
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 2.07s
                      Time elapsed: 00:26:05
                               ETA: 00:26:12

################################################################################
                     [1m Learning iteration 749/1500 [0m                      

                       Computation: 47862 steps/s (collection: 1.943s, learning 0.111s)
             Mean action noise std: 3.07
          Mean value_function loss: 69.9529
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 65.4547
                       Mean reward: 400.43
               Mean episode length: 229.01
    Episode_Reward/reaching_object: 1.3645
    Episode_Reward/rotating_object: 84.4682
        Episode_Reward/action_rate: -0.0574
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 2.05s
                      Time elapsed: 00:26:08
                               ETA: 00:26:10

################################################################################
                     [1m Learning iteration 750/1500 [0m                      

                       Computation: 48584 steps/s (collection: 1.912s, learning 0.112s)
             Mean action noise std: 3.08
          Mean value_function loss: 78.2836
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 65.4838
                       Mean reward: 368.04
               Mean episode length: 228.04
    Episode_Reward/reaching_object: 1.3400
    Episode_Reward/rotating_object: 80.6327
        Episode_Reward/action_rate: -0.0579
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 2.02s
                      Time elapsed: 00:26:10
                               ETA: 00:26:07

################################################################################
                     [1m Learning iteration 751/1500 [0m                      

                       Computation: 48100 steps/s (collection: 1.933s, learning 0.110s)
             Mean action noise std: 3.08
          Mean value_function loss: 78.8050
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 65.5106
                       Mean reward: 404.79
               Mean episode length: 230.93
    Episode_Reward/reaching_object: 1.3449
    Episode_Reward/rotating_object: 83.4915
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 2.04s
                      Time elapsed: 00:26:12
                               ETA: 00:26:05

################################################################################
                     [1m Learning iteration 752/1500 [0m                      

                       Computation: 49004 steps/s (collection: 1.895s, learning 0.111s)
             Mean action noise std: 3.08
          Mean value_function loss: 67.0848
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 65.5441
                       Mean reward: 424.64
               Mean episode length: 237.79
    Episode_Reward/reaching_object: 1.3721
    Episode_Reward/rotating_object: 87.6389
        Episode_Reward/action_rate: -0.0580
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 2.01s
                      Time elapsed: 00:26:14
                               ETA: 00:26:03

################################################################################
                     [1m Learning iteration 753/1500 [0m                      

                       Computation: 48953 steps/s (collection: 1.898s, learning 0.111s)
             Mean action noise std: 3.09
          Mean value_function loss: 67.9812
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 65.5720
                       Mean reward: 417.88
               Mean episode length: 231.50
    Episode_Reward/reaching_object: 1.3579
    Episode_Reward/rotating_object: 82.6396
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 2.01s
                      Time elapsed: 00:26:16
                               ETA: 00:26:01

################################################################################
                     [1m Learning iteration 754/1500 [0m                      

                       Computation: 49096 steps/s (collection: 1.892s, learning 0.111s)
             Mean action noise std: 3.09
          Mean value_function loss: 74.0647
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 65.6035
                       Mean reward: 404.57
               Mean episode length: 232.66
    Episode_Reward/reaching_object: 1.3464
    Episode_Reward/rotating_object: 81.2041
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 2.00s
                      Time elapsed: 00:26:18
                               ETA: 00:25:59

################################################################################
                     [1m Learning iteration 755/1500 [0m                      

                       Computation: 48522 steps/s (collection: 1.915s, learning 0.111s)
             Mean action noise std: 3.09
          Mean value_function loss: 76.5973
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 65.6287
                       Mean reward: 446.41
               Mean episode length: 241.04
    Episode_Reward/reaching_object: 1.3644
    Episode_Reward/rotating_object: 80.8611
        Episode_Reward/action_rate: -0.0588
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 2.03s
                      Time elapsed: 00:26:20
                               ETA: 00:25:57

################################################################################
                     [1m Learning iteration 756/1500 [0m                      

                       Computation: 48966 steps/s (collection: 1.896s, learning 0.111s)
             Mean action noise std: 3.10
          Mean value_function loss: 75.9665
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 65.6590
                       Mean reward: 451.23
               Mean episode length: 240.16
    Episode_Reward/reaching_object: 1.3590
    Episode_Reward/rotating_object: 81.7141
        Episode_Reward/action_rate: -0.0580
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 2.01s
                      Time elapsed: 00:26:22
                               ETA: 00:25:54

################################################################################
                     [1m Learning iteration 757/1500 [0m                      

                       Computation: 47951 steps/s (collection: 1.939s, learning 0.111s)
             Mean action noise std: 3.10
          Mean value_function loss: 77.1772
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 65.6852
                       Mean reward: 370.82
               Mean episode length: 229.50
    Episode_Reward/reaching_object: 1.3447
    Episode_Reward/rotating_object: 81.5945
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 2.05s
                      Time elapsed: 00:26:24
                               ETA: 00:25:52

################################################################################
                     [1m Learning iteration 758/1500 [0m                      

                       Computation: 47600 steps/s (collection: 1.951s, learning 0.114s)
             Mean action noise std: 3.10
          Mean value_function loss: 77.3231
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 65.7091
                       Mean reward: 361.35
               Mean episode length: 217.08
    Episode_Reward/reaching_object: 1.2902
    Episode_Reward/rotating_object: 77.1213
        Episode_Reward/action_rate: -0.0566
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 2.07s
                      Time elapsed: 00:26:26
                               ETA: 00:25:50

################################################################################
                     [1m Learning iteration 759/1500 [0m                      

                       Computation: 47381 steps/s (collection: 1.961s, learning 0.114s)
             Mean action noise std: 3.11
          Mean value_function loss: 78.8662
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 65.7383
                       Mean reward: 368.36
               Mean episode length: 225.06
    Episode_Reward/reaching_object: 1.3555
    Episode_Reward/rotating_object: 83.5382
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 2.07s
                      Time elapsed: 00:26:28
                               ETA: 00:25:48

################################################################################
                     [1m Learning iteration 760/1500 [0m                      

                       Computation: 47041 steps/s (collection: 1.976s, learning 0.113s)
             Mean action noise std: 3.11
          Mean value_function loss: 79.8317
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 65.7709
                       Mean reward: 421.44
               Mean episode length: 231.87
    Episode_Reward/reaching_object: 1.3272
    Episode_Reward/rotating_object: 80.6677
        Episode_Reward/action_rate: -0.0573
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 2.09s
                      Time elapsed: 00:26:30
                               ETA: 00:25:46

################################################################################
                     [1m Learning iteration 761/1500 [0m                      

                       Computation: 47806 steps/s (collection: 1.944s, learning 0.113s)
             Mean action noise std: 3.11
          Mean value_function loss: 80.1903
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 65.7927
                       Mean reward: 451.54
               Mean episode length: 237.97
    Episode_Reward/reaching_object: 1.3179
    Episode_Reward/rotating_object: 80.2520
        Episode_Reward/action_rate: -0.0571
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 2.06s
                      Time elapsed: 00:26:32
                               ETA: 00:25:44

################################################################################
                     [1m Learning iteration 762/1500 [0m                      

                       Computation: 45781 steps/s (collection: 2.000s, learning 0.147s)
             Mean action noise std: 3.12
          Mean value_function loss: 70.7234
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 65.8062
                       Mean reward: 407.58
               Mean episode length: 237.64
    Episode_Reward/reaching_object: 1.3365
    Episode_Reward/rotating_object: 80.7234
        Episode_Reward/action_rate: -0.0585
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 2.15s
                      Time elapsed: 00:26:34
                               ETA: 00:25:42

################################################################################
                     [1m Learning iteration 763/1500 [0m                      

                       Computation: 45626 steps/s (collection: 2.040s, learning 0.115s)
             Mean action noise std: 3.12
          Mean value_function loss: 67.0604
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 65.8254
                       Mean reward: 390.21
               Mean episode length: 228.92
    Episode_Reward/reaching_object: 1.3281
    Episode_Reward/rotating_object: 78.8451
        Episode_Reward/action_rate: -0.0581
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 2.15s
                      Time elapsed: 00:26:36
                               ETA: 00:25:40

################################################################################
                     [1m Learning iteration 764/1500 [0m                      

                       Computation: 47884 steps/s (collection: 1.943s, learning 0.110s)
             Mean action noise std: 3.12
          Mean value_function loss: 69.2125
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 65.8509
                       Mean reward: 423.90
               Mean episode length: 238.36
    Episode_Reward/reaching_object: 1.3570
    Episode_Reward/rotating_object: 81.9126
        Episode_Reward/action_rate: -0.0589
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 2.05s
                      Time elapsed: 00:26:38
                               ETA: 00:25:38

################################################################################
                     [1m Learning iteration 765/1500 [0m                      

                       Computation: 47959 steps/s (collection: 1.938s, learning 0.112s)
             Mean action noise std: 3.13
          Mean value_function loss: 76.6380
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 65.8765
                       Mean reward: 450.56
               Mean episode length: 238.38
    Episode_Reward/reaching_object: 1.3538
    Episode_Reward/rotating_object: 85.9664
        Episode_Reward/action_rate: -0.0587
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 2.05s
                      Time elapsed: 00:26:40
                               ETA: 00:25:36

################################################################################
                     [1m Learning iteration 766/1500 [0m                      

                       Computation: 48134 steps/s (collection: 1.930s, learning 0.112s)
             Mean action noise std: 3.13
          Mean value_function loss: 75.4461
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 65.9013
                       Mean reward: 413.91
               Mean episode length: 236.06
    Episode_Reward/reaching_object: 1.3602
    Episode_Reward/rotating_object: 83.8553
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 2.04s
                      Time elapsed: 00:26:42
                               ETA: 00:25:33

################################################################################
                     [1m Learning iteration 767/1500 [0m                      

                       Computation: 47944 steps/s (collection: 1.939s, learning 0.111s)
             Mean action noise std: 3.13
          Mean value_function loss: 74.7600
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 65.9242
                       Mean reward: 419.28
               Mean episode length: 235.08
    Episode_Reward/reaching_object: 1.3675
    Episode_Reward/rotating_object: 84.9691
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 2.05s
                      Time elapsed: 00:26:44
                               ETA: 00:25:31

################################################################################
                     [1m Learning iteration 768/1500 [0m                      

                       Computation: 47807 steps/s (collection: 1.943s, learning 0.113s)
             Mean action noise std: 3.14
          Mean value_function loss: 71.8343
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 65.9455
                       Mean reward: 424.84
               Mean episode length: 238.05
    Episode_Reward/reaching_object: 1.3601
    Episode_Reward/rotating_object: 85.0792
        Episode_Reward/action_rate: -0.0593
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 2.06s
                      Time elapsed: 00:26:47
                               ETA: 00:25:29

################################################################################
                     [1m Learning iteration 769/1500 [0m                      

                       Computation: 47244 steps/s (collection: 1.968s, learning 0.112s)
             Mean action noise std: 3.14
          Mean value_function loss: 73.5303
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 65.9730
                       Mean reward: 444.03
               Mean episode length: 228.84
    Episode_Reward/reaching_object: 1.3595
    Episode_Reward/rotating_object: 84.3743
        Episode_Reward/action_rate: -0.0596
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 18.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 2.08s
                      Time elapsed: 00:26:49
                               ETA: 00:25:27

################################################################################
                     [1m Learning iteration 770/1500 [0m                      

                       Computation: 47988 steps/s (collection: 1.935s, learning 0.113s)
             Mean action noise std: 3.14
          Mean value_function loss: 80.2230
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 66.0046
                       Mean reward: 439.41
               Mean episode length: 243.54
    Episode_Reward/reaching_object: 1.3795
    Episode_Reward/rotating_object: 82.8306
        Episode_Reward/action_rate: -0.0608
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 2.05s
                      Time elapsed: 00:26:51
                               ETA: 00:25:25

################################################################################
                     [1m Learning iteration 771/1500 [0m                      

                       Computation: 47530 steps/s (collection: 1.954s, learning 0.114s)
             Mean action noise std: 3.15
          Mean value_function loss: 86.8404
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 66.0350
                       Mean reward: 443.76
               Mean episode length: 238.21
    Episode_Reward/reaching_object: 1.3663
    Episode_Reward/rotating_object: 84.4311
        Episode_Reward/action_rate: -0.0601
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 2.07s
                      Time elapsed: 00:26:53
                               ETA: 00:25:23

################################################################################
                     [1m Learning iteration 772/1500 [0m                      

                       Computation: 47944 steps/s (collection: 1.935s, learning 0.115s)
             Mean action noise std: 3.15
          Mean value_function loss: 74.9974
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 66.0682
                       Mean reward: 411.77
               Mean episode length: 234.97
    Episode_Reward/reaching_object: 1.3534
    Episode_Reward/rotating_object: 81.0134
        Episode_Reward/action_rate: -0.0588
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 2.05s
                      Time elapsed: 00:26:55
                               ETA: 00:25:21

################################################################################
                     [1m Learning iteration 773/1500 [0m                      

                       Computation: 48317 steps/s (collection: 1.924s, learning 0.111s)
             Mean action noise std: 3.15
          Mean value_function loss: 78.9173
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 66.0937
                       Mean reward: 417.28
               Mean episode length: 230.27
    Episode_Reward/reaching_object: 1.3317
    Episode_Reward/rotating_object: 80.2216
        Episode_Reward/action_rate: -0.0589
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 2.03s
                      Time elapsed: 00:26:57
                               ETA: 00:25:19

################################################################################
                     [1m Learning iteration 774/1500 [0m                      

                       Computation: 48701 steps/s (collection: 1.908s, learning 0.111s)
             Mean action noise std: 3.16
          Mean value_function loss: 74.1156
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 66.1188
                       Mean reward: 426.27
               Mean episode length: 237.52
    Episode_Reward/reaching_object: 1.3425
    Episode_Reward/rotating_object: 80.9949
        Episode_Reward/action_rate: -0.0595
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 2.02s
                      Time elapsed: 00:26:59
                               ETA: 00:25:16

################################################################################
                     [1m Learning iteration 775/1500 [0m                      

                       Computation: 47958 steps/s (collection: 1.939s, learning 0.111s)
             Mean action noise std: 3.16
          Mean value_function loss: 76.6262
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 66.1473
                       Mean reward: 409.48
               Mean episode length: 240.20
    Episode_Reward/reaching_object: 1.3813
    Episode_Reward/rotating_object: 81.7375
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 2.05s
                      Time elapsed: 00:27:01
                               ETA: 00:25:14

################################################################################
                     [1m Learning iteration 776/1500 [0m                      

                       Computation: 48906 steps/s (collection: 1.899s, learning 0.111s)
             Mean action noise std: 3.16
          Mean value_function loss: 88.8385
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 66.1719
                       Mean reward: 397.27
               Mean episode length: 235.02
    Episode_Reward/reaching_object: 1.3654
    Episode_Reward/rotating_object: 86.2428
        Episode_Reward/action_rate: -0.0599
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 2.01s
                      Time elapsed: 00:27:03
                               ETA: 00:25:12

################################################################################
                     [1m Learning iteration 777/1500 [0m                      

                       Computation: 48402 steps/s (collection: 1.917s, learning 0.114s)
             Mean action noise std: 3.17
          Mean value_function loss: 79.6677
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 66.1976
                       Mean reward: 461.71
               Mean episode length: 236.34
    Episode_Reward/reaching_object: 1.3698
    Episode_Reward/rotating_object: 84.1883
        Episode_Reward/action_rate: -0.0603
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 2.03s
                      Time elapsed: 00:27:05
                               ETA: 00:25:10

################################################################################
                     [1m Learning iteration 778/1500 [0m                      

                       Computation: 48737 steps/s (collection: 1.906s, learning 0.111s)
             Mean action noise std: 3.17
          Mean value_function loss: 71.6659
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 66.2312
                       Mean reward: 389.33
               Mean episode length: 232.87
    Episode_Reward/reaching_object: 1.3548
    Episode_Reward/rotating_object: 81.1064
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 2.02s
                      Time elapsed: 00:27:07
                               ETA: 00:25:08

################################################################################
                     [1m Learning iteration 779/1500 [0m                      

                       Computation: 49329 steps/s (collection: 1.882s, learning 0.111s)
             Mean action noise std: 3.18
          Mean value_function loss: 62.9505
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 66.2720
                       Mean reward: 432.35
               Mean episode length: 238.13
    Episode_Reward/reaching_object: 1.3482
    Episode_Reward/rotating_object: 82.3598
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 1.99s
                      Time elapsed: 00:27:09
                               ETA: 00:25:06

################################################################################
                     [1m Learning iteration 780/1500 [0m                      

                       Computation: 47665 steps/s (collection: 1.950s, learning 0.112s)
             Mean action noise std: 3.18
          Mean value_function loss: 70.6420
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 66.3090
                       Mean reward: 453.38
               Mean episode length: 239.40
    Episode_Reward/reaching_object: 1.3710
    Episode_Reward/rotating_object: 87.9075
        Episode_Reward/action_rate: -0.0612
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 2.06s
                      Time elapsed: 00:27:11
                               ETA: 00:25:04

################################################################################
                     [1m Learning iteration 781/1500 [0m                      

                       Computation: 47743 steps/s (collection: 1.946s, learning 0.113s)
             Mean action noise std: 3.18
          Mean value_function loss: 77.3993
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 66.3276
                       Mean reward: 444.66
               Mean episode length: 234.08
    Episode_Reward/reaching_object: 1.3447
    Episode_Reward/rotating_object: 86.3216
        Episode_Reward/action_rate: -0.0605
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 2.06s
                      Time elapsed: 00:27:13
                               ETA: 00:25:01

################################################################################
                     [1m Learning iteration 782/1500 [0m                      

                       Computation: 47517 steps/s (collection: 1.958s, learning 0.111s)
             Mean action noise std: 3.19
          Mean value_function loss: 70.1302
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 66.3458
                       Mean reward: 476.62
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 1.3409
    Episode_Reward/rotating_object: 85.3589
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 2.07s
                      Time elapsed: 00:27:15
                               ETA: 00:24:59

################################################################################
                     [1m Learning iteration 783/1500 [0m                      

                       Computation: 48094 steps/s (collection: 1.932s, learning 0.112s)
             Mean action noise std: 3.19
          Mean value_function loss: 72.9027
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 66.3668
                       Mean reward: 464.45
               Mean episode length: 239.52
    Episode_Reward/reaching_object: 1.3450
    Episode_Reward/rotating_object: 85.4411
        Episode_Reward/action_rate: -0.0615
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 2.04s
                      Time elapsed: 00:27:17
                               ETA: 00:24:57

################################################################################
                     [1m Learning iteration 784/1500 [0m                      

                       Computation: 48373 steps/s (collection: 1.921s, learning 0.111s)
             Mean action noise std: 3.19
          Mean value_function loss: 73.0083
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 66.3907
                       Mean reward: 389.29
               Mean episode length: 228.48
    Episode_Reward/reaching_object: 1.3385
    Episode_Reward/rotating_object: 82.8299
        Episode_Reward/action_rate: -0.0615
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 2.03s
                      Time elapsed: 00:27:19
                               ETA: 00:24:55

################################################################################
                     [1m Learning iteration 785/1500 [0m                      

                       Computation: 48188 steps/s (collection: 1.929s, learning 0.111s)
             Mean action noise std: 3.20
          Mean value_function loss: 73.7775
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 66.4133
                       Mean reward: 498.42
               Mean episode length: 245.19
    Episode_Reward/reaching_object: 1.3884
    Episode_Reward/rotating_object: 87.4462
        Episode_Reward/action_rate: -0.0631
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 2.04s
                      Time elapsed: 00:27:21
                               ETA: 00:24:53

################################################################################
                     [1m Learning iteration 786/1500 [0m                      

                       Computation: 48359 steps/s (collection: 1.920s, learning 0.113s)
             Mean action noise std: 3.20
          Mean value_function loss: 70.2909
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 66.4437
                       Mean reward: 388.13
               Mean episode length: 238.90
    Episode_Reward/reaching_object: 1.3291
    Episode_Reward/rotating_object: 81.8226
        Episode_Reward/action_rate: -0.0618
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 2.03s
                      Time elapsed: 00:27:23
                               ETA: 00:24:51

################################################################################
                     [1m Learning iteration 787/1500 [0m                      

                       Computation: 47742 steps/s (collection: 1.945s, learning 0.114s)
             Mean action noise std: 3.20
          Mean value_function loss: 80.7675
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 66.4675
                       Mean reward: 453.09
               Mean episode length: 237.15
    Episode_Reward/reaching_object: 1.3198
    Episode_Reward/rotating_object: 81.7901
        Episode_Reward/action_rate: -0.0612
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 2.06s
                      Time elapsed: 00:27:25
                               ETA: 00:24:49

################################################################################
                     [1m Learning iteration 788/1500 [0m                      

                       Computation: 45988 steps/s (collection: 2.023s, learning 0.115s)
             Mean action noise std: 3.21
          Mean value_function loss: 83.1278
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 66.4961
                       Mean reward: 404.62
               Mean episode length: 232.10
    Episode_Reward/reaching_object: 1.3531
    Episode_Reward/rotating_object: 82.4359
        Episode_Reward/action_rate: -0.0627
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 2.14s
                      Time elapsed: 00:27:27
                               ETA: 00:24:47

################################################################################
                     [1m Learning iteration 789/1500 [0m                      

                       Computation: 45825 steps/s (collection: 2.034s, learning 0.111s)
             Mean action noise std: 3.21
          Mean value_function loss: 83.2872
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 66.5227
                       Mean reward: 426.35
               Mean episode length: 240.07
    Episode_Reward/reaching_object: 1.3406
    Episode_Reward/rotating_object: 83.3616
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 2.15s
                      Time elapsed: 00:27:30
                               ETA: 00:24:45

################################################################################
                     [1m Learning iteration 790/1500 [0m                      

                       Computation: 47242 steps/s (collection: 1.968s, learning 0.113s)
             Mean action noise std: 3.22
          Mean value_function loss: 77.2961
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 66.5633
                       Mean reward: 422.72
               Mean episode length: 227.87
    Episode_Reward/reaching_object: 1.3832
    Episode_Reward/rotating_object: 87.2563
        Episode_Reward/action_rate: -0.0632
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 18.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 2.08s
                      Time elapsed: 00:27:32
                               ETA: 00:24:42

################################################################################
                     [1m Learning iteration 791/1500 [0m                      

                       Computation: 47242 steps/s (collection: 1.967s, learning 0.114s)
             Mean action noise std: 3.22
          Mean value_function loss: 87.0480
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 66.5968
                       Mean reward: 416.26
               Mean episode length: 241.40
    Episode_Reward/reaching_object: 1.3383
    Episode_Reward/rotating_object: 82.9716
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 2.08s
                      Time elapsed: 00:27:34
                               ETA: 00:24:40

################################################################################
                     [1m Learning iteration 792/1500 [0m                      

                       Computation: 47200 steps/s (collection: 1.970s, learning 0.113s)
             Mean action noise std: 3.22
          Mean value_function loss: 84.0163
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 66.6104
                       Mean reward: 354.27
               Mean episode length: 225.23
    Episode_Reward/reaching_object: 1.3437
    Episode_Reward/rotating_object: 82.7950
        Episode_Reward/action_rate: -0.0621
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 2.08s
                      Time elapsed: 00:27:36
                               ETA: 00:24:38

################################################################################
                     [1m Learning iteration 793/1500 [0m                      

                       Computation: 47954 steps/s (collection: 1.936s, learning 0.114s)
             Mean action noise std: 3.22
          Mean value_function loss: 86.4209
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 66.6221
                       Mean reward: 407.61
               Mean episode length: 233.74
    Episode_Reward/reaching_object: 1.3397
    Episode_Reward/rotating_object: 84.5653
        Episode_Reward/action_rate: -0.0621
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 2.05s
                      Time elapsed: 00:27:38
                               ETA: 00:24:36

################################################################################
                     [1m Learning iteration 794/1500 [0m                      

                       Computation: 47936 steps/s (collection: 1.938s, learning 0.112s)
             Mean action noise std: 3.23
          Mean value_function loss: 83.3360
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 66.6379
                       Mean reward: 425.71
               Mean episode length: 231.76
    Episode_Reward/reaching_object: 1.3588
    Episode_Reward/rotating_object: 87.5141
        Episode_Reward/action_rate: -0.0623
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 2.05s
                      Time elapsed: 00:27:40
                               ETA: 00:24:34

################################################################################
                     [1m Learning iteration 795/1500 [0m                      

                       Computation: 47054 steps/s (collection: 1.976s, learning 0.113s)
             Mean action noise std: 3.23
          Mean value_function loss: 77.5113
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 66.6655
                       Mean reward: 417.66
               Mean episode length: 237.81
    Episode_Reward/reaching_object: 1.3688
    Episode_Reward/rotating_object: 83.1139
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 2.09s
                      Time elapsed: 00:27:42
                               ETA: 00:24:32

################################################################################
                     [1m Learning iteration 796/1500 [0m                      

                       Computation: 48144 steps/s (collection: 1.931s, learning 0.111s)
             Mean action noise std: 3.23
          Mean value_function loss: 79.4019
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 66.6927
                       Mean reward: 442.58
               Mean episode length: 239.58
    Episode_Reward/reaching_object: 1.3462
    Episode_Reward/rotating_object: 80.5585
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 2.04s
                      Time elapsed: 00:27:44
                               ETA: 00:24:30

################################################################################
                     [1m Learning iteration 797/1500 [0m                      

                       Computation: 48631 steps/s (collection: 1.910s, learning 0.111s)
             Mean action noise std: 3.24
          Mean value_function loss: 70.9991
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 66.7172
                       Mean reward: 459.84
               Mean episode length: 235.26
    Episode_Reward/reaching_object: 1.3557
    Episode_Reward/rotating_object: 85.9540
        Episode_Reward/action_rate: -0.0626
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 2.02s
                      Time elapsed: 00:27:46
                               ETA: 00:24:28

################################################################################
                     [1m Learning iteration 798/1500 [0m                      

                       Computation: 48703 steps/s (collection: 1.907s, learning 0.112s)
             Mean action noise std: 3.24
          Mean value_function loss: 83.1528
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 66.7412
                       Mean reward: 377.59
               Mean episode length: 227.75
    Episode_Reward/reaching_object: 1.3221
    Episode_Reward/rotating_object: 80.3237
        Episode_Reward/action_rate: -0.0624
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 2.02s
                      Time elapsed: 00:27:48
                               ETA: 00:24:26

################################################################################
                     [1m Learning iteration 799/1500 [0m                      

                       Computation: 48957 steps/s (collection: 1.897s, learning 0.111s)
             Mean action noise std: 3.24
          Mean value_function loss: 69.7903
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 66.7528
                       Mean reward: 446.06
               Mean episode length: 231.40
    Episode_Reward/reaching_object: 1.3567
    Episode_Reward/rotating_object: 86.6414
        Episode_Reward/action_rate: -0.0632
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 2.01s
                      Time elapsed: 00:27:50
                               ETA: 00:24:23

################################################################################
                     [1m Learning iteration 800/1500 [0m                      

                       Computation: 48924 steps/s (collection: 1.898s, learning 0.111s)
             Mean action noise std: 3.24
          Mean value_function loss: 64.6692
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 66.7744
                       Mean reward: 399.39
               Mean episode length: 227.81
    Episode_Reward/reaching_object: 1.3397
    Episode_Reward/rotating_object: 80.9743
        Episode_Reward/action_rate: -0.0637
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 2.01s
                      Time elapsed: 00:27:52
                               ETA: 00:24:21

################################################################################
                     [1m Learning iteration 801/1500 [0m                      

                       Computation: 48432 steps/s (collection: 1.918s, learning 0.111s)
             Mean action noise std: 3.25
          Mean value_function loss: 81.9465
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 66.8076
                       Mean reward: 452.32
               Mean episode length: 231.81
    Episode_Reward/reaching_object: 1.3296
    Episode_Reward/rotating_object: 83.8503
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 2.03s
                      Time elapsed: 00:27:54
                               ETA: 00:24:19

################################################################################
                     [1m Learning iteration 802/1500 [0m                      

                       Computation: 48509 steps/s (collection: 1.914s, learning 0.112s)
             Mean action noise std: 3.25
          Mean value_function loss: 89.0663
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 66.8363
                       Mean reward: 468.97
               Mean episode length: 235.25
    Episode_Reward/reaching_object: 1.3464
    Episode_Reward/rotating_object: 87.1735
        Episode_Reward/action_rate: -0.0633
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 2.03s
                      Time elapsed: 00:27:56
                               ETA: 00:24:17

################################################################################
                     [1m Learning iteration 803/1500 [0m                      

                       Computation: 48664 steps/s (collection: 1.909s, learning 0.111s)
             Mean action noise std: 3.26
          Mean value_function loss: 78.3944
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 66.8618
                       Mean reward: 442.87
               Mean episode length: 233.90
    Episode_Reward/reaching_object: 1.3586
    Episode_Reward/rotating_object: 87.1302
        Episode_Reward/action_rate: -0.0639
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 2.02s
                      Time elapsed: 00:27:58
                               ETA: 00:24:15

################################################################################
                     [1m Learning iteration 804/1500 [0m                      

                       Computation: 47889 steps/s (collection: 1.941s, learning 0.111s)
             Mean action noise std: 3.26
          Mean value_function loss: 77.4389
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 66.8915
                       Mean reward: 447.12
               Mean episode length: 239.57
    Episode_Reward/reaching_object: 1.3360
    Episode_Reward/rotating_object: 84.5308
        Episode_Reward/action_rate: -0.0641
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 2.05s
                      Time elapsed: 00:28:00
                               ETA: 00:24:13

################################################################################
                     [1m Learning iteration 805/1500 [0m                      

                       Computation: 46876 steps/s (collection: 1.982s, learning 0.115s)
             Mean action noise std: 3.26
          Mean value_function loss: 78.8013
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 66.9190
                       Mean reward: 433.85
               Mean episode length: 236.22
    Episode_Reward/reaching_object: 1.3329
    Episode_Reward/rotating_object: 82.9073
        Episode_Reward/action_rate: -0.0644
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 2.10s
                      Time elapsed: 00:28:02
                               ETA: 00:24:11

################################################################################
                     [1m Learning iteration 806/1500 [0m                      

                       Computation: 46905 steps/s (collection: 1.985s, learning 0.111s)
             Mean action noise std: 3.27
          Mean value_function loss: 73.3553
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 66.9463
                       Mean reward: 443.81
               Mean episode length: 237.25
    Episode_Reward/reaching_object: 1.3297
    Episode_Reward/rotating_object: 84.7252
        Episode_Reward/action_rate: -0.0647
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 2.10s
                      Time elapsed: 00:28:04
                               ETA: 00:24:09

################################################################################
                     [1m Learning iteration 807/1500 [0m                      

                       Computation: 47359 steps/s (collection: 1.963s, learning 0.113s)
             Mean action noise std: 3.27
          Mean value_function loss: 66.5307
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 66.9689
                       Mean reward: 440.98
               Mean episode length: 229.20
    Episode_Reward/reaching_object: 1.3514
    Episode_Reward/rotating_object: 89.3674
        Episode_Reward/action_rate: -0.0643
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 2.08s
                      Time elapsed: 00:28:07
                               ETA: 00:24:06

################################################################################
                     [1m Learning iteration 808/1500 [0m                      

                       Computation: 47883 steps/s (collection: 1.942s, learning 0.111s)
             Mean action noise std: 3.27
          Mean value_function loss: 70.4171
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 66.9846
                       Mean reward: 456.41
               Mean episode length: 242.80
    Episode_Reward/reaching_object: 1.3618
    Episode_Reward/rotating_object: 86.3447
        Episode_Reward/action_rate: -0.0655
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 2.05s
                      Time elapsed: 00:28:09
                               ETA: 00:24:04

################################################################################
                     [1m Learning iteration 809/1500 [0m                      

                       Computation: 47820 steps/s (collection: 1.945s, learning 0.111s)
             Mean action noise std: 3.28
          Mean value_function loss: 71.9998
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 67.0146
                       Mean reward: 425.08
               Mean episode length: 231.44
    Episode_Reward/reaching_object: 1.3496
    Episode_Reward/rotating_object: 85.1010
        Episode_Reward/action_rate: -0.0649
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 2.06s
                      Time elapsed: 00:28:11
                               ETA: 00:24:02

################################################################################
                     [1m Learning iteration 810/1500 [0m                      

                       Computation: 47354 steps/s (collection: 1.963s, learning 0.113s)
             Mean action noise std: 3.28
          Mean value_function loss: 76.3277
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 67.0438
                       Mean reward: 384.39
               Mean episode length: 237.64
    Episode_Reward/reaching_object: 1.3608
    Episode_Reward/rotating_object: 84.0722
        Episode_Reward/action_rate: -0.0658
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 2.08s
                      Time elapsed: 00:28:13
                               ETA: 00:24:00

################################################################################
                     [1m Learning iteration 811/1500 [0m                      

                       Computation: 46971 steps/s (collection: 1.982s, learning 0.111s)
             Mean action noise std: 3.28
          Mean value_function loss: 82.9067
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 67.0668
                       Mean reward: 406.72
               Mean episode length: 233.05
    Episode_Reward/reaching_object: 1.3357
    Episode_Reward/rotating_object: 82.1978
        Episode_Reward/action_rate: -0.0655
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 2.09s
                      Time elapsed: 00:28:15
                               ETA: 00:23:58

################################################################################
                     [1m Learning iteration 812/1500 [0m                      

                       Computation: 47283 steps/s (collection: 1.968s, learning 0.111s)
             Mean action noise std: 3.29
          Mean value_function loss: 87.5435
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 67.0896
                       Mean reward: 361.08
               Mean episode length: 232.40
    Episode_Reward/reaching_object: 1.3402
    Episode_Reward/rotating_object: 83.2608
        Episode_Reward/action_rate: -0.0661
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 2.08s
                      Time elapsed: 00:28:17
                               ETA: 00:23:56

################################################################################
                     [1m Learning iteration 813/1500 [0m                      

                       Computation: 47333 steps/s (collection: 1.962s, learning 0.115s)
             Mean action noise std: 3.29
          Mean value_function loss: 84.4451
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 67.1202
                       Mean reward: 412.67
               Mean episode length: 239.69
    Episode_Reward/reaching_object: 1.3449
    Episode_Reward/rotating_object: 84.6462
        Episode_Reward/action_rate: -0.0658
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 2.08s
                      Time elapsed: 00:28:19
                               ETA: 00:23:54

################################################################################
                     [1m Learning iteration 814/1500 [0m                      

                       Computation: 47564 steps/s (collection: 1.954s, learning 0.112s)
             Mean action noise std: 3.29
          Mean value_function loss: 89.7168
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 67.1543
                       Mean reward: 414.79
               Mean episode length: 229.28
    Episode_Reward/reaching_object: 1.3080
    Episode_Reward/rotating_object: 81.6447
        Episode_Reward/action_rate: -0.0642
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 2.07s
                      Time elapsed: 00:28:21
                               ETA: 00:23:52

################################################################################
                     [1m Learning iteration 815/1500 [0m                      

                       Computation: 47751 steps/s (collection: 1.948s, learning 0.111s)
             Mean action noise std: 3.30
          Mean value_function loss: 79.9031
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 67.1833
                       Mean reward: 445.78
               Mean episode length: 232.91
    Episode_Reward/reaching_object: 1.3368
    Episode_Reward/rotating_object: 84.0296
        Episode_Reward/action_rate: -0.0653
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 2.06s
                      Time elapsed: 00:28:23
                               ETA: 00:23:50

################################################################################
                     [1m Learning iteration 816/1500 [0m                      

                       Computation: 47744 steps/s (collection: 1.947s, learning 0.112s)
             Mean action noise std: 3.30
          Mean value_function loss: 81.3062
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 67.2154
                       Mean reward: 408.76
               Mean episode length: 233.68
    Episode_Reward/reaching_object: 1.2954
    Episode_Reward/rotating_object: 74.4868
        Episode_Reward/action_rate: -0.0649
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 2.06s
                      Time elapsed: 00:28:25
                               ETA: 00:23:47

################################################################################
                     [1m Learning iteration 817/1500 [0m                      

                       Computation: 48001 steps/s (collection: 1.935s, learning 0.113s)
             Mean action noise std: 3.30
          Mean value_function loss: 69.0168
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 67.2396
                       Mean reward: 425.77
               Mean episode length: 241.02
    Episode_Reward/reaching_object: 1.3525
    Episode_Reward/rotating_object: 84.0766
        Episode_Reward/action_rate: -0.0663
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 2.05s
                      Time elapsed: 00:28:27
                               ETA: 00:23:45

################################################################################
                     [1m Learning iteration 818/1500 [0m                      

                       Computation: 48038 steps/s (collection: 1.934s, learning 0.113s)
             Mean action noise std: 3.31
          Mean value_function loss: 79.0612
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 67.2544
                       Mean reward: 409.56
               Mean episode length: 220.23
    Episode_Reward/reaching_object: 1.3300
    Episode_Reward/rotating_object: 82.7443
        Episode_Reward/action_rate: -0.0656
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 2.05s
                      Time elapsed: 00:28:29
                               ETA: 00:23:43

################################################################################
                     [1m Learning iteration 819/1500 [0m                      

                       Computation: 47327 steps/s (collection: 1.967s, learning 0.111s)
             Mean action noise std: 3.31
          Mean value_function loss: 81.4780
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 67.2755
                       Mean reward: 421.92
               Mean episode length: 225.67
    Episode_Reward/reaching_object: 1.3524
    Episode_Reward/rotating_object: 85.6583
        Episode_Reward/action_rate: -0.0664
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 2.08s
                      Time elapsed: 00:28:31
                               ETA: 00:23:41

################################################################################
                     [1m Learning iteration 820/1500 [0m                      

                       Computation: 47683 steps/s (collection: 1.951s, learning 0.111s)
             Mean action noise std: 3.31
          Mean value_function loss: 73.6485
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 67.3028
                       Mean reward: 461.01
               Mean episode length: 231.17
    Episode_Reward/reaching_object: 1.3463
    Episode_Reward/rotating_object: 85.3936
        Episode_Reward/action_rate: -0.0665
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 2.06s
                      Time elapsed: 00:28:33
                               ETA: 00:23:39

################################################################################
                     [1m Learning iteration 821/1500 [0m                      

                       Computation: 48760 steps/s (collection: 1.905s, learning 0.111s)
             Mean action noise std: 3.32
          Mean value_function loss: 71.0508
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 67.3249
                       Mean reward: 458.97
               Mean episode length: 242.34
    Episode_Reward/reaching_object: 1.3685
    Episode_Reward/rotating_object: 86.5351
        Episode_Reward/action_rate: -0.0674
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 2.02s
                      Time elapsed: 00:28:35
                               ETA: 00:23:37

################################################################################
                     [1m Learning iteration 822/1500 [0m                      

                       Computation: 48843 steps/s (collection: 1.902s, learning 0.110s)
             Mean action noise std: 3.32
          Mean value_function loss: 78.7838
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 67.3464
                       Mean reward: 404.76
               Mean episode length: 222.20
    Episode_Reward/reaching_object: 1.3187
    Episode_Reward/rotating_object: 83.4228
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 2.01s
                      Time elapsed: 00:28:37
                               ETA: 00:23:35

################################################################################
                     [1m Learning iteration 823/1500 [0m                      

                       Computation: 48351 steps/s (collection: 1.923s, learning 0.111s)
             Mean action noise std: 3.32
          Mean value_function loss: 80.4440
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 67.3688
                       Mean reward: 431.56
               Mean episode length: 237.42
    Episode_Reward/reaching_object: 1.3286
    Episode_Reward/rotating_object: 83.5566
        Episode_Reward/action_rate: -0.0664
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 2.03s
                      Time elapsed: 00:28:39
                               ETA: 00:23:33

################################################################################
                     [1m Learning iteration 824/1500 [0m                      

                       Computation: 48269 steps/s (collection: 1.926s, learning 0.111s)
             Mean action noise std: 3.33
          Mean value_function loss: 80.8574
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 67.3993
                       Mean reward: 386.18
               Mean episode length: 237.05
    Episode_Reward/reaching_object: 1.3284
    Episode_Reward/rotating_object: 81.5631
        Episode_Reward/action_rate: -0.0665
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 2.04s
                      Time elapsed: 00:28:41
                               ETA: 00:23:30

################################################################################
                     [1m Learning iteration 825/1500 [0m                      

                       Computation: 48267 steps/s (collection: 1.926s, learning 0.110s)
             Mean action noise std: 3.33
          Mean value_function loss: 73.6792
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 67.4242
                       Mean reward: 401.34
               Mean episode length: 228.05
    Episode_Reward/reaching_object: 1.3160
    Episode_Reward/rotating_object: 81.5840
        Episode_Reward/action_rate: -0.0670
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 2.04s
                      Time elapsed: 00:28:44
                               ETA: 00:23:28

################################################################################
                     [1m Learning iteration 826/1500 [0m                      

                       Computation: 48318 steps/s (collection: 1.922s, learning 0.113s)
             Mean action noise std: 3.34
          Mean value_function loss: 81.4912
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 67.4531
                       Mean reward: 433.85
               Mean episode length: 232.81
    Episode_Reward/reaching_object: 1.3493
    Episode_Reward/rotating_object: 82.9630
        Episode_Reward/action_rate: -0.0672
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 2.03s
                      Time elapsed: 00:28:46
                               ETA: 00:23:26

################################################################################
                     [1m Learning iteration 827/1500 [0m                      

                       Computation: 48537 steps/s (collection: 1.911s, learning 0.114s)
             Mean action noise std: 3.34
          Mean value_function loss: 71.4740
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 67.4778
                       Mean reward: 423.19
               Mean episode length: 227.87
    Episode_Reward/reaching_object: 1.3094
    Episode_Reward/rotating_object: 80.6596
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 2.03s
                      Time elapsed: 00:28:48
                               ETA: 00:23:24

################################################################################
                     [1m Learning iteration 828/1500 [0m                      

                       Computation: 46385 steps/s (collection: 2.005s, learning 0.114s)
             Mean action noise std: 3.34
          Mean value_function loss: 82.5447
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 67.5080
                       Mean reward: 389.60
               Mean episode length: 224.18
    Episode_Reward/reaching_object: 1.3133
    Episode_Reward/rotating_object: 82.1586
        Episode_Reward/action_rate: -0.0668
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 2.12s
                      Time elapsed: 00:28:50
                               ETA: 00:23:22

################################################################################
                     [1m Learning iteration 829/1500 [0m                      

                       Computation: 45337 steps/s (collection: 2.056s, learning 0.112s)
             Mean action noise std: 3.35
          Mean value_function loss: 77.8277
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 67.5332
                       Mean reward: 459.11
               Mean episode length: 231.65
    Episode_Reward/reaching_object: 1.3489
    Episode_Reward/rotating_object: 86.0076
        Episode_Reward/action_rate: -0.0673
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 2.17s
                      Time elapsed: 00:28:52
                               ETA: 00:23:20

################################################################################
                     [1m Learning iteration 830/1500 [0m                      

                       Computation: 46075 steps/s (collection: 2.021s, learning 0.112s)
             Mean action noise std: 3.35
          Mean value_function loss: 82.1947
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 67.5535
                       Mean reward: 417.64
               Mean episode length: 230.47
    Episode_Reward/reaching_object: 1.3556
    Episode_Reward/rotating_object: 84.6384
        Episode_Reward/action_rate: -0.0685
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 2.13s
                      Time elapsed: 00:28:54
                               ETA: 00:23:18

################################################################################
                     [1m Learning iteration 831/1500 [0m                      

                       Computation: 46958 steps/s (collection: 1.978s, learning 0.116s)
             Mean action noise std: 3.35
          Mean value_function loss: 73.7040
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 67.5796
                       Mean reward: 427.10
               Mean episode length: 237.98
    Episode_Reward/reaching_object: 1.3271
    Episode_Reward/rotating_object: 80.8691
        Episode_Reward/action_rate: -0.0677
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 2.09s
                      Time elapsed: 00:28:56
                               ETA: 00:23:16

################################################################################
                     [1m Learning iteration 832/1500 [0m                      

                       Computation: 47428 steps/s (collection: 1.960s, learning 0.113s)
             Mean action noise std: 3.36
          Mean value_function loss: 79.9274
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 67.5991
                       Mean reward: 438.75
               Mean episode length: 230.41
    Episode_Reward/reaching_object: 1.3480
    Episode_Reward/rotating_object: 85.0410
        Episode_Reward/action_rate: -0.0687
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 2.07s
                      Time elapsed: 00:28:58
                               ETA: 00:23:14

################################################################################
                     [1m Learning iteration 833/1500 [0m                      

                       Computation: 47560 steps/s (collection: 1.954s, learning 0.113s)
             Mean action noise std: 3.36
          Mean value_function loss: 75.0167
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 67.6242
                       Mean reward: 442.30
               Mean episode length: 243.01
    Episode_Reward/reaching_object: 1.3449
    Episode_Reward/rotating_object: 86.2908
        Episode_Reward/action_rate: -0.0685
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 2.07s
                      Time elapsed: 00:29:00
                               ETA: 00:23:12

################################################################################
                     [1m Learning iteration 834/1500 [0m                      

                       Computation: 47838 steps/s (collection: 1.941s, learning 0.114s)
             Mean action noise std: 3.36
          Mean value_function loss: 77.1588
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 67.6502
                       Mean reward: 373.75
               Mean episode length: 226.42
    Episode_Reward/reaching_object: 1.3260
    Episode_Reward/rotating_object: 84.1566
        Episode_Reward/action_rate: -0.0680
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 2.05s
                      Time elapsed: 00:29:02
                               ETA: 00:23:10

################################################################################
                     [1m Learning iteration 835/1500 [0m                      

                       Computation: 47576 steps/s (collection: 1.952s, learning 0.114s)
             Mean action noise std: 3.37
          Mean value_function loss: 78.2663
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 67.6712
                       Mean reward: 378.59
               Mean episode length: 220.15
    Episode_Reward/reaching_object: 1.3099
    Episode_Reward/rotating_object: 83.4285
        Episode_Reward/action_rate: -0.0670
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 2.07s
                      Time elapsed: 00:29:04
                               ETA: 00:23:07

################################################################################
                     [1m Learning iteration 836/1500 [0m                      

                       Computation: 46700 steps/s (collection: 1.990s, learning 0.114s)
             Mean action noise std: 3.37
          Mean value_function loss: 73.8611
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 67.6962
                       Mean reward: 417.67
               Mean episode length: 229.58
    Episode_Reward/reaching_object: 1.3374
    Episode_Reward/rotating_object: 84.5997
        Episode_Reward/action_rate: -0.0689
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 2.10s
                      Time elapsed: 00:29:06
                               ETA: 00:23:05

################################################################################
                     [1m Learning iteration 837/1500 [0m                      

                       Computation: 47502 steps/s (collection: 1.957s, learning 0.113s)
             Mean action noise std: 3.37
          Mean value_function loss: 75.8682
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 67.7224
                       Mean reward: 441.95
               Mean episode length: 232.55
    Episode_Reward/reaching_object: 1.2997
    Episode_Reward/rotating_object: 84.0270
        Episode_Reward/action_rate: -0.0674
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 2.07s
                      Time elapsed: 00:29:09
                               ETA: 00:23:03

################################################################################
                     [1m Learning iteration 838/1500 [0m                      

                       Computation: 47507 steps/s (collection: 1.958s, learning 0.112s)
             Mean action noise std: 3.37
          Mean value_function loss: 80.2110
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 67.7412
                       Mean reward: 399.27
               Mean episode length: 231.22
    Episode_Reward/reaching_object: 1.3161
    Episode_Reward/rotating_object: 83.9947
        Episode_Reward/action_rate: -0.0683
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 2.07s
                      Time elapsed: 00:29:11
                               ETA: 00:23:01

################################################################################
                     [1m Learning iteration 839/1500 [0m                      

                       Computation: 47575 steps/s (collection: 1.949s, learning 0.117s)
             Mean action noise std: 3.38
          Mean value_function loss: 72.8224
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 67.7625
                       Mean reward: 443.98
               Mean episode length: 235.34
    Episode_Reward/reaching_object: 1.3636
    Episode_Reward/rotating_object: 88.6631
        Episode_Reward/action_rate: -0.0703
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 2.07s
                      Time elapsed: 00:29:13
                               ETA: 00:22:59

################################################################################
                     [1m Learning iteration 840/1500 [0m                      

                       Computation: 47243 steps/s (collection: 1.967s, learning 0.113s)
             Mean action noise std: 3.38
          Mean value_function loss: 79.4283
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 67.7869
                       Mean reward: 359.77
               Mean episode length: 220.53
    Episode_Reward/reaching_object: 1.2952
    Episode_Reward/rotating_object: 79.4449
        Episode_Reward/action_rate: -0.0678
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 2.08s
                      Time elapsed: 00:29:15
                               ETA: 00:22:57

################################################################################
                     [1m Learning iteration 841/1500 [0m                      

                       Computation: 46916 steps/s (collection: 1.984s, learning 0.111s)
             Mean action noise std: 3.39
          Mean value_function loss: 67.4243
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 67.8167
                       Mean reward: 453.52
               Mean episode length: 235.71
    Episode_Reward/reaching_object: 1.3442
    Episode_Reward/rotating_object: 86.3320
        Episode_Reward/action_rate: -0.0693
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 2.10s
                      Time elapsed: 00:29:17
                               ETA: 00:22:55

################################################################################
                     [1m Learning iteration 842/1500 [0m                      

                       Computation: 47201 steps/s (collection: 1.970s, learning 0.112s)
             Mean action noise std: 3.39
          Mean value_function loss: 72.8902
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 67.8335
                       Mean reward: 452.09
               Mean episode length: 225.33
    Episode_Reward/reaching_object: 1.3002
    Episode_Reward/rotating_object: 84.6799
        Episode_Reward/action_rate: -0.0676
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 2.08s
                      Time elapsed: 00:29:19
                               ETA: 00:22:53

################################################################################
                     [1m Learning iteration 843/1500 [0m                      

                       Computation: 47759 steps/s (collection: 1.948s, learning 0.111s)
             Mean action noise std: 3.39
          Mean value_function loss: 70.6884
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 67.8545
                       Mean reward: 419.68
               Mean episode length: 231.42
    Episode_Reward/reaching_object: 1.3379
    Episode_Reward/rotating_object: 85.1671
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 2.06s
                      Time elapsed: 00:29:21
                               ETA: 00:22:51

################################################################################
                     [1m Learning iteration 844/1500 [0m                      

                       Computation: 48613 steps/s (collection: 1.909s, learning 0.113s)
             Mean action noise std: 3.39
          Mean value_function loss: 67.4877
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 67.8723
                       Mean reward: 450.73
               Mean episode length: 227.10
    Episode_Reward/reaching_object: 1.3346
    Episode_Reward/rotating_object: 89.3486
        Episode_Reward/action_rate: -0.0696
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 2.02s
                      Time elapsed: 00:29:23
                               ETA: 00:22:49

################################################################################
                     [1m Learning iteration 845/1500 [0m                      

                       Computation: 47926 steps/s (collection: 1.941s, learning 0.110s)
             Mean action noise std: 3.40
          Mean value_function loss: 79.0183
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 67.8867
                       Mean reward: 463.44
               Mean episode length: 232.72
    Episode_Reward/reaching_object: 1.2959
    Episode_Reward/rotating_object: 83.2486
        Episode_Reward/action_rate: -0.0686
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 2.05s
                      Time elapsed: 00:29:25
                               ETA: 00:22:46

################################################################################
                     [1m Learning iteration 846/1500 [0m                      

                       Computation: 48121 steps/s (collection: 1.932s, learning 0.110s)
             Mean action noise std: 3.40
          Mean value_function loss: 79.1127
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 67.9165
                       Mean reward: 417.82
               Mean episode length: 239.16
    Episode_Reward/reaching_object: 1.3050
    Episode_Reward/rotating_object: 81.7843
        Episode_Reward/action_rate: -0.0692
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 2.04s
                      Time elapsed: 00:29:27
                               ETA: 00:22:44

################################################################################
                     [1m Learning iteration 847/1500 [0m                      

                       Computation: 48463 steps/s (collection: 1.918s, learning 0.111s)
             Mean action noise std: 3.41
          Mean value_function loss: 74.5069
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 67.9570
                       Mean reward: 441.21
               Mean episode length: 244.94
    Episode_Reward/reaching_object: 1.3236
    Episode_Reward/rotating_object: 86.2057
        Episode_Reward/action_rate: -0.0697
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 2.03s
                      Time elapsed: 00:29:29
                               ETA: 00:22:42

################################################################################
                     [1m Learning iteration 848/1500 [0m                      

                       Computation: 48226 steps/s (collection: 1.928s, learning 0.110s)
             Mean action noise std: 3.41
          Mean value_function loss: 72.6220
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 67.9787
                       Mean reward: 413.82
               Mean episode length: 239.94
    Episode_Reward/reaching_object: 1.3237
    Episode_Reward/rotating_object: 78.2720
        Episode_Reward/action_rate: -0.0708
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 2.04s
                      Time elapsed: 00:29:31
                               ETA: 00:22:40

################################################################################
                     [1m Learning iteration 849/1500 [0m                      

                       Computation: 48655 steps/s (collection: 1.910s, learning 0.110s)
             Mean action noise std: 3.41
          Mean value_function loss: 76.5972
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 68.0030
                       Mean reward: 460.58
               Mean episode length: 236.07
    Episode_Reward/reaching_object: 1.3608
    Episode_Reward/rotating_object: 89.8107
        Episode_Reward/action_rate: -0.0712
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 2.02s
                      Time elapsed: 00:29:33
                               ETA: 00:22:38

################################################################################
                     [1m Learning iteration 850/1500 [0m                      

                       Computation: 47358 steps/s (collection: 1.965s, learning 0.111s)
             Mean action noise std: 3.42
          Mean value_function loss: 79.8236
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 68.0348
                       Mean reward: 396.98
               Mean episode length: 227.46
    Episode_Reward/reaching_object: 1.3518
    Episode_Reward/rotating_object: 85.5075
        Episode_Reward/action_rate: -0.0708
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 2.08s
                      Time elapsed: 00:29:35
                               ETA: 00:22:36

################################################################################
                     [1m Learning iteration 851/1500 [0m                      

                       Computation: 45557 steps/s (collection: 2.043s, learning 0.114s)
             Mean action noise std: 3.42
          Mean value_function loss: 72.7102
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 68.0640
                       Mean reward: 414.01
               Mean episode length: 229.36
    Episode_Reward/reaching_object: 1.3344
    Episode_Reward/rotating_object: 83.6281
        Episode_Reward/action_rate: -0.0704
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 2.16s
                      Time elapsed: 00:29:37
                               ETA: 00:22:34

################################################################################
                     [1m Learning iteration 852/1500 [0m                      

                       Computation: 45638 steps/s (collection: 2.043s, learning 0.111s)
             Mean action noise std: 3.42
          Mean value_function loss: 64.7560
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 68.0813
                       Mean reward: 429.99
               Mean episode length: 228.38
    Episode_Reward/reaching_object: 1.3214
    Episode_Reward/rotating_object: 84.8499
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 2.15s
                      Time elapsed: 00:29:40
                               ETA: 00:22:32

################################################################################
                     [1m Learning iteration 853/1500 [0m                      

                       Computation: 47718 steps/s (collection: 1.944s, learning 0.116s)
             Mean action noise std: 3.43
          Mean value_function loss: 85.9668
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 68.1025
                       Mean reward: 396.32
               Mean episode length: 229.52
    Episode_Reward/reaching_object: 1.3230
    Episode_Reward/rotating_object: 83.6390
        Episode_Reward/action_rate: -0.0704
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 2.06s
                      Time elapsed: 00:29:42
                               ETA: 00:22:30

################################################################################
                     [1m Learning iteration 854/1500 [0m                      

                       Computation: 46471 steps/s (collection: 1.999s, learning 0.116s)
             Mean action noise std: 3.43
          Mean value_function loss: 76.9439
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 68.1275
                       Mean reward: 409.36
               Mean episode length: 235.95
    Episode_Reward/reaching_object: 1.3385
    Episode_Reward/rotating_object: 84.3902
        Episode_Reward/action_rate: -0.0710
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 2.12s
                      Time elapsed: 00:29:44
                               ETA: 00:22:28

################################################################################
                     [1m Learning iteration 855/1500 [0m                      

                       Computation: 46730 steps/s (collection: 1.976s, learning 0.128s)
             Mean action noise std: 3.43
          Mean value_function loss: 73.0867
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 68.1493
                       Mean reward: 386.81
               Mean episode length: 228.71
    Episode_Reward/reaching_object: 1.3413
    Episode_Reward/rotating_object: 84.6908
        Episode_Reward/action_rate: -0.0714
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 2.10s
                      Time elapsed: 00:29:46
                               ETA: 00:22:26

################################################################################
                     [1m Learning iteration 856/1500 [0m                      

                       Computation: 46689 steps/s (collection: 1.978s, learning 0.127s)
             Mean action noise std: 3.44
          Mean value_function loss: 91.6338
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 68.1703
                       Mean reward: 417.23
               Mean episode length: 228.90
    Episode_Reward/reaching_object: 1.3502
    Episode_Reward/rotating_object: 84.0708
        Episode_Reward/action_rate: -0.0717
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 2.11s
                      Time elapsed: 00:29:48
                               ETA: 00:22:23

################################################################################
                     [1m Learning iteration 857/1500 [0m                      

                       Computation: 47065 steps/s (collection: 1.963s, learning 0.126s)
             Mean action noise std: 3.44
          Mean value_function loss: 74.7691
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 68.1942
                       Mean reward: 409.19
               Mean episode length: 241.45
    Episode_Reward/reaching_object: 1.3489
    Episode_Reward/rotating_object: 83.0818
        Episode_Reward/action_rate: -0.0723
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 2.09s
                      Time elapsed: 00:29:50
                               ETA: 00:22:21

################################################################################
                     [1m Learning iteration 858/1500 [0m                      

                       Computation: 47194 steps/s (collection: 1.967s, learning 0.115s)
             Mean action noise std: 3.44
          Mean value_function loss: 74.8937
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 68.2165
                       Mean reward: 460.83
               Mean episode length: 228.73
    Episode_Reward/reaching_object: 1.3262
    Episode_Reward/rotating_object: 84.1938
        Episode_Reward/action_rate: -0.0713
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 2.08s
                      Time elapsed: 00:29:52
                               ETA: 00:22:19

################################################################################
                     [1m Learning iteration 859/1500 [0m                      

                       Computation: 47218 steps/s (collection: 1.966s, learning 0.116s)
             Mean action noise std: 3.45
          Mean value_function loss: 78.3149
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 68.2427
                       Mean reward: 405.52
               Mean episode length: 227.67
    Episode_Reward/reaching_object: 1.2974
    Episode_Reward/rotating_object: 80.9123
        Episode_Reward/action_rate: -0.0697
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 2.08s
                      Time elapsed: 00:29:54
                               ETA: 00:22:17

################################################################################
                     [1m Learning iteration 860/1500 [0m                      

                       Computation: 47524 steps/s (collection: 1.959s, learning 0.110s)
             Mean action noise std: 3.45
          Mean value_function loss: 79.0915
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 68.2732
                       Mean reward: 424.89
               Mean episode length: 234.82
    Episode_Reward/reaching_object: 1.3647
    Episode_Reward/rotating_object: 88.5135
        Episode_Reward/action_rate: -0.0726
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 2.07s
                      Time elapsed: 00:29:56
                               ETA: 00:22:15

################################################################################
                     [1m Learning iteration 861/1500 [0m                      

                       Computation: 47593 steps/s (collection: 1.954s, learning 0.112s)
             Mean action noise std: 3.45
          Mean value_function loss: 80.7662
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 68.3022
                       Mean reward: 424.30
               Mean episode length: 225.11
    Episode_Reward/reaching_object: 1.3330
    Episode_Reward/rotating_object: 83.0317
        Episode_Reward/action_rate: -0.0714
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 2.07s
                      Time elapsed: 00:29:58
                               ETA: 00:22:13

################################################################################
                     [1m Learning iteration 862/1500 [0m                      

                       Computation: 46514 steps/s (collection: 1.990s, learning 0.123s)
             Mean action noise std: 3.46
          Mean value_function loss: 81.4444
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 68.3254
                       Mean reward: 433.81
               Mean episode length: 222.29
    Episode_Reward/reaching_object: 1.3040
    Episode_Reward/rotating_object: 82.9048
        Episode_Reward/action_rate: -0.0705
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 2.11s
                      Time elapsed: 00:30:00
                               ETA: 00:22:11

################################################################################
                     [1m Learning iteration 863/1500 [0m                      

                       Computation: 47503 steps/s (collection: 1.959s, learning 0.110s)
             Mean action noise std: 3.46
          Mean value_function loss: 75.3694
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 68.3419
                       Mean reward: 430.28
               Mean episode length: 243.51
    Episode_Reward/reaching_object: 1.3403
    Episode_Reward/rotating_object: 81.3954
        Episode_Reward/action_rate: -0.0732
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 2.07s
                      Time elapsed: 00:30:03
                               ETA: 00:22:09

################################################################################
                     [1m Learning iteration 864/1500 [0m                      

                       Computation: 47680 steps/s (collection: 1.951s, learning 0.111s)
             Mean action noise std: 3.46
          Mean value_function loss: 81.3174
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 68.3643
                       Mean reward: 402.18
               Mean episode length: 231.38
    Episode_Reward/reaching_object: 1.3423
    Episode_Reward/rotating_object: 84.2502
        Episode_Reward/action_rate: -0.0726
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 2.06s
                      Time elapsed: 00:30:05
                               ETA: 00:22:07

################################################################################
                     [1m Learning iteration 865/1500 [0m                      

                       Computation: 47232 steps/s (collection: 1.966s, learning 0.116s)
             Mean action noise std: 3.47
          Mean value_function loss: 69.4762
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 68.3860
                       Mean reward: 489.81
               Mean episode length: 239.47
    Episode_Reward/reaching_object: 1.3560
    Episode_Reward/rotating_object: 88.6101
        Episode_Reward/action_rate: -0.0736
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 2.08s
                      Time elapsed: 00:30:07
                               ETA: 00:22:05

################################################################################
                     [1m Learning iteration 866/1500 [0m                      

                       Computation: 46633 steps/s (collection: 1.995s, learning 0.113s)
             Mean action noise std: 3.47
          Mean value_function loss: 75.9352
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 68.4113
                       Mean reward: 431.79
               Mean episode length: 226.39
    Episode_Reward/reaching_object: 1.3498
    Episode_Reward/rotating_object: 88.1920
        Episode_Reward/action_rate: -0.0731
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 2.11s
                      Time elapsed: 00:30:09
                               ETA: 00:22:03

################################################################################
                     [1m Learning iteration 867/1500 [0m                      

                       Computation: 48424 steps/s (collection: 1.919s, learning 0.111s)
             Mean action noise std: 3.47
          Mean value_function loss: 76.7461
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 68.4355
                       Mean reward: 407.78
               Mean episode length: 237.90
    Episode_Reward/reaching_object: 1.3381
    Episode_Reward/rotating_object: 84.2491
        Episode_Reward/action_rate: -0.0732
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 2.03s
                      Time elapsed: 00:30:11
                               ETA: 00:22:00

################################################################################
                     [1m Learning iteration 868/1500 [0m                      

                       Computation: 48433 steps/s (collection: 1.917s, learning 0.112s)
             Mean action noise std: 3.48
          Mean value_function loss: 81.1316
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 68.4531
                       Mean reward: 497.28
               Mean episode length: 231.79
    Episode_Reward/reaching_object: 1.3362
    Episode_Reward/rotating_object: 89.9131
        Episode_Reward/action_rate: -0.0728
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 2.03s
                      Time elapsed: 00:30:13
                               ETA: 00:21:58

################################################################################
                     [1m Learning iteration 869/1500 [0m                      

                       Computation: 48670 steps/s (collection: 1.909s, learning 0.111s)
             Mean action noise std: 3.48
          Mean value_function loss: 74.5019
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 68.4739
                       Mean reward: 449.13
               Mean episode length: 238.02
    Episode_Reward/reaching_object: 1.3211
    Episode_Reward/rotating_object: 84.8398
        Episode_Reward/action_rate: -0.0729
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 2.02s
                      Time elapsed: 00:30:15
                               ETA: 00:21:56

################################################################################
                     [1m Learning iteration 870/1500 [0m                      

                       Computation: 48775 steps/s (collection: 1.905s, learning 0.111s)
             Mean action noise std: 3.48
          Mean value_function loss: 70.5809
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 68.4927
                       Mean reward: 407.93
               Mean episode length: 243.09
    Episode_Reward/reaching_object: 1.3355
    Episode_Reward/rotating_object: 86.1965
        Episode_Reward/action_rate: -0.0737
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 2.02s
                      Time elapsed: 00:30:17
                               ETA: 00:21:54

################################################################################
                     [1m Learning iteration 871/1500 [0m                      

                       Computation: 48270 steps/s (collection: 1.925s, learning 0.111s)
             Mean action noise std: 3.48
          Mean value_function loss: 74.3306
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 68.5047
                       Mean reward: 445.95
               Mean episode length: 233.35
    Episode_Reward/reaching_object: 1.3362
    Episode_Reward/rotating_object: 89.0152
        Episode_Reward/action_rate: -0.0742
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 2.04s
                      Time elapsed: 00:30:19
                               ETA: 00:21:52

################################################################################
                     [1m Learning iteration 872/1500 [0m                      

                       Computation: 48215 steps/s (collection: 1.928s, learning 0.111s)
             Mean action noise std: 3.49
          Mean value_function loss: 75.5830
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 68.5304
                       Mean reward: 444.47
               Mean episode length: 236.91
    Episode_Reward/reaching_object: 1.3411
    Episode_Reward/rotating_object: 87.9533
        Episode_Reward/action_rate: -0.0738
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 2.04s
                      Time elapsed: 00:30:21
                               ETA: 00:21:50

################################################################################
                     [1m Learning iteration 873/1500 [0m                      

                       Computation: 48333 steps/s (collection: 1.923s, learning 0.111s)
             Mean action noise std: 3.49
          Mean value_function loss: 77.7768
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 68.5614
                       Mean reward: 455.18
               Mean episode length: 227.88
    Episode_Reward/reaching_object: 1.3213
    Episode_Reward/rotating_object: 86.5845
        Episode_Reward/action_rate: -0.0734
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 2.03s
                      Time elapsed: 00:30:23
                               ETA: 00:21:48

################################################################################
                     [1m Learning iteration 874/1500 [0m                      

                       Computation: 47412 steps/s (collection: 1.963s, learning 0.111s)
             Mean action noise std: 3.50
          Mean value_function loss: 83.8191
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 68.5842
                       Mean reward: 433.42
               Mean episode length: 232.37
    Episode_Reward/reaching_object: 1.3110
    Episode_Reward/rotating_object: 84.7514
        Episode_Reward/action_rate: -0.0730
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 2.07s
                      Time elapsed: 00:30:25
                               ETA: 00:21:46

################################################################################
                     [1m Learning iteration 875/1500 [0m                      

                       Computation: 46149 steps/s (collection: 2.020s, learning 0.111s)
             Mean action noise std: 3.50
          Mean value_function loss: 79.9933
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 68.6072
                       Mean reward: 462.78
               Mean episode length: 236.14
    Episode_Reward/reaching_object: 1.3109
    Episode_Reward/rotating_object: 86.6912
        Episode_Reward/action_rate: -0.0731
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 2.13s
                      Time elapsed: 00:30:27
                               ETA: 00:21:43

################################################################################
                     [1m Learning iteration 876/1500 [0m                      

                       Computation: 46934 steps/s (collection: 1.984s, learning 0.110s)
             Mean action noise std: 3.50
          Mean value_function loss: 81.6202
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 68.6325
                       Mean reward: 446.28
               Mean episode length: 239.12
    Episode_Reward/reaching_object: 1.3560
    Episode_Reward/rotating_object: 88.6126
        Episode_Reward/action_rate: -0.0751
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 2.09s
                      Time elapsed: 00:30:29
                               ETA: 00:21:41

################################################################################
                     [1m Learning iteration 877/1500 [0m                      

                       Computation: 47138 steps/s (collection: 1.973s, learning 0.112s)
             Mean action noise std: 3.50
          Mean value_function loss: 77.9977
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 68.6501
                       Mean reward: 462.42
               Mean episode length: 230.27
    Episode_Reward/reaching_object: 1.3281
    Episode_Reward/rotating_object: 87.5518
        Episode_Reward/action_rate: -0.0746
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 2.09s
                      Time elapsed: 00:30:31
                               ETA: 00:21:39

################################################################################
                     [1m Learning iteration 878/1500 [0m                      

                       Computation: 47144 steps/s (collection: 1.969s, learning 0.117s)
             Mean action noise std: 3.51
          Mean value_function loss: 79.7700
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 68.6643
                       Mean reward: 462.80
               Mean episode length: 238.22
    Episode_Reward/reaching_object: 1.3504
    Episode_Reward/rotating_object: 89.5617
        Episode_Reward/action_rate: -0.0751
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 2.09s
                      Time elapsed: 00:30:33
                               ETA: 00:21:37

################################################################################
                     [1m Learning iteration 879/1500 [0m                      

                       Computation: 47277 steps/s (collection: 1.969s, learning 0.111s)
             Mean action noise std: 3.51
          Mean value_function loss: 71.4910
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 68.6809
                       Mean reward: 431.70
               Mean episode length: 233.26
    Episode_Reward/reaching_object: 1.3441
    Episode_Reward/rotating_object: 88.0695
        Episode_Reward/action_rate: -0.0752
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 2.08s
                      Time elapsed: 00:30:36
                               ETA: 00:21:35

################################################################################
                     [1m Learning iteration 880/1500 [0m                      

                       Computation: 45586 steps/s (collection: 2.046s, learning 0.111s)
             Mean action noise std: 3.51
          Mean value_function loss: 83.0640
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 68.7087
                       Mean reward: 432.67
               Mean episode length: 230.22
    Episode_Reward/reaching_object: 1.3163
    Episode_Reward/rotating_object: 85.8058
        Episode_Reward/action_rate: -0.0741
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 2.16s
                      Time elapsed: 00:30:38
                               ETA: 00:21:33

################################################################################
                     [1m Learning iteration 881/1500 [0m                      

                       Computation: 47020 steps/s (collection: 1.981s, learning 0.110s)
             Mean action noise std: 3.52
          Mean value_function loss: 82.4277
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 68.7300
                       Mean reward: 426.77
               Mean episode length: 235.63
    Episode_Reward/reaching_object: 1.3443
    Episode_Reward/rotating_object: 88.0865
        Episode_Reward/action_rate: -0.0753
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 2.09s
                      Time elapsed: 00:30:40
                               ETA: 00:21:31

################################################################################
                     [1m Learning iteration 882/1500 [0m                      

                       Computation: 46902 steps/s (collection: 1.978s, learning 0.118s)
             Mean action noise std: 3.52
          Mean value_function loss: 75.4355
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 68.7491
                       Mean reward: 451.25
               Mean episode length: 237.49
    Episode_Reward/reaching_object: 1.3646
    Episode_Reward/rotating_object: 87.7699
        Episode_Reward/action_rate: -0.0759
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 2.10s
                      Time elapsed: 00:30:42
                               ETA: 00:21:29

################################################################################
                     [1m Learning iteration 883/1500 [0m                      

                       Computation: 47029 steps/s (collection: 1.971s, learning 0.120s)
             Mean action noise std: 3.52
          Mean value_function loss: 78.0265
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 68.7701
                       Mean reward: 426.49
               Mean episode length: 221.74
    Episode_Reward/reaching_object: 1.3126
    Episode_Reward/rotating_object: 83.7844
        Episode_Reward/action_rate: -0.0736
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 2.09s
                      Time elapsed: 00:30:44
                               ETA: 00:21:27

################################################################################
                     [1m Learning iteration 884/1500 [0m                      

                       Computation: 46999 steps/s (collection: 1.975s, learning 0.117s)
             Mean action noise std: 3.53
          Mean value_function loss: 77.5286
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 68.7931
                       Mean reward: 514.15
               Mean episode length: 233.51
    Episode_Reward/reaching_object: 1.3656
    Episode_Reward/rotating_object: 89.9105
        Episode_Reward/action_rate: -0.0765
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 2.09s
                      Time elapsed: 00:30:46
                               ETA: 00:21:25

################################################################################
                     [1m Learning iteration 885/1500 [0m                      

                       Computation: 46614 steps/s (collection: 1.992s, learning 0.117s)
             Mean action noise std: 3.53
          Mean value_function loss: 81.4984
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 68.8168
                       Mean reward: 444.44
               Mean episode length: 233.90
    Episode_Reward/reaching_object: 1.3226
    Episode_Reward/rotating_object: 86.5733
        Episode_Reward/action_rate: -0.0751
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 2.11s
                      Time elapsed: 00:30:48
                               ETA: 00:21:23

################################################################################
                     [1m Learning iteration 886/1500 [0m                      

                       Computation: 46357 steps/s (collection: 2.006s, learning 0.115s)
             Mean action noise std: 3.53
          Mean value_function loss: 78.1280
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 68.8431
                       Mean reward: 404.32
               Mean episode length: 225.98
    Episode_Reward/reaching_object: 1.3142
    Episode_Reward/rotating_object: 85.9095
        Episode_Reward/action_rate: -0.0742
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 2.12s
                      Time elapsed: 00:30:50
                               ETA: 00:21:21

################################################################################
                     [1m Learning iteration 887/1500 [0m                      

                       Computation: 46223 steps/s (collection: 2.012s, learning 0.114s)
             Mean action noise std: 3.54
          Mean value_function loss: 80.6290
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 68.8657
                       Mean reward: 433.01
               Mean episode length: 237.84
    Episode_Reward/reaching_object: 1.3625
    Episode_Reward/rotating_object: 88.8668
        Episode_Reward/action_rate: -0.0773
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 2.13s
                      Time elapsed: 00:30:52
                               ETA: 00:21:19

################################################################################
                     [1m Learning iteration 888/1500 [0m                      

                       Computation: 46779 steps/s (collection: 1.982s, learning 0.119s)
             Mean action noise std: 3.54
          Mean value_function loss: 87.2587
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 68.8843
                       Mean reward: 434.55
               Mean episode length: 228.14
    Episode_Reward/reaching_object: 1.3298
    Episode_Reward/rotating_object: 89.6608
        Episode_Reward/action_rate: -0.0755
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 2.10s
                      Time elapsed: 00:30:55
                               ETA: 00:21:17

################################################################################
                     [1m Learning iteration 889/1500 [0m                      

                       Computation: 47330 steps/s (collection: 1.966s, learning 0.111s)
             Mean action noise std: 3.54
          Mean value_function loss: 82.0296
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 68.9033
                       Mean reward: 448.21
               Mean episode length: 241.91
    Episode_Reward/reaching_object: 1.3165
    Episode_Reward/rotating_object: 84.5462
        Episode_Reward/action_rate: -0.0758
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 2.08s
                      Time elapsed: 00:30:57
                               ETA: 00:21:14

################################################################################
                     [1m Learning iteration 890/1500 [0m                      

                       Computation: 46911 steps/s (collection: 1.985s, learning 0.110s)
             Mean action noise std: 3.55
          Mean value_function loss: 93.9354
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 68.9271
                       Mean reward: 477.82
               Mean episode length: 244.93
    Episode_Reward/reaching_object: 1.3317
    Episode_Reward/rotating_object: 84.2987
        Episode_Reward/action_rate: -0.0761
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 2.10s
                      Time elapsed: 00:30:59
                               ETA: 00:21:12

################################################################################
                     [1m Learning iteration 891/1500 [0m                      

                       Computation: 48236 steps/s (collection: 1.928s, learning 0.110s)
             Mean action noise std: 3.55
          Mean value_function loss: 83.5978
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 68.9545
                       Mean reward: 435.53
               Mean episode length: 230.59
    Episode_Reward/reaching_object: 1.3307
    Episode_Reward/rotating_object: 87.4202
        Episode_Reward/action_rate: -0.0758
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 2.04s
                      Time elapsed: 00:31:01
                               ETA: 00:21:10

################################################################################
                     [1m Learning iteration 892/1500 [0m                      

                       Computation: 48298 steps/s (collection: 1.925s, learning 0.110s)
             Mean action noise std: 3.55
          Mean value_function loss: 75.8345
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 68.9776
                       Mean reward: 471.45
               Mean episode length: 239.29
    Episode_Reward/reaching_object: 1.3087
    Episode_Reward/rotating_object: 83.6490
        Episode_Reward/action_rate: -0.0756
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 2.04s
                      Time elapsed: 00:31:03
                               ETA: 00:21:08

################################################################################
                     [1m Learning iteration 893/1500 [0m                      

                       Computation: 48462 steps/s (collection: 1.918s, learning 0.111s)
             Mean action noise std: 3.55
          Mean value_function loss: 79.1848
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 68.9908
                       Mean reward: 458.09
               Mean episode length: 231.37
    Episode_Reward/reaching_object: 1.3447
    Episode_Reward/rotating_object: 87.1704
        Episode_Reward/action_rate: -0.0769
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 2.03s
                      Time elapsed: 00:31:05
                               ETA: 00:21:06

################################################################################
                     [1m Learning iteration 894/1500 [0m                      

                       Computation: 48700 steps/s (collection: 1.908s, learning 0.110s)
             Mean action noise std: 3.56
          Mean value_function loss: 73.8417
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 69.0137
                       Mean reward: 439.18
               Mean episode length: 239.41
    Episode_Reward/reaching_object: 1.3389
    Episode_Reward/rotating_object: 87.3693
        Episode_Reward/action_rate: -0.0778
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 2.02s
                      Time elapsed: 00:31:07
                               ETA: 00:21:04

################################################################################
                     [1m Learning iteration 895/1500 [0m                      

                       Computation: 48380 steps/s (collection: 1.922s, learning 0.110s)
             Mean action noise std: 3.56
          Mean value_function loss: 81.6825
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 69.0465
                       Mean reward: 420.41
               Mean episode length: 226.66
    Episode_Reward/reaching_object: 1.3281
    Episode_Reward/rotating_object: 86.6011
        Episode_Reward/action_rate: -0.0765
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 2.03s
                      Time elapsed: 00:31:09
                               ETA: 00:21:02

################################################################################
                     [1m Learning iteration 896/1500 [0m                      

                       Computation: 48365 steps/s (collection: 1.922s, learning 0.110s)
             Mean action noise std: 3.57
          Mean value_function loss: 85.3717
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 69.0806
                       Mean reward: 469.30
               Mean episode length: 233.18
    Episode_Reward/reaching_object: 1.3264
    Episode_Reward/rotating_object: 89.4795
        Episode_Reward/action_rate: -0.0765
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 2.03s
                      Time elapsed: 00:31:11
                               ETA: 00:21:00

################################################################################
                     [1m Learning iteration 897/1500 [0m                      

                       Computation: 47994 steps/s (collection: 1.938s, learning 0.111s)
             Mean action noise std: 3.57
          Mean value_function loss: 82.5457
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 69.1077
                       Mean reward: 440.38
               Mean episode length: 238.27
    Episode_Reward/reaching_object: 1.3184
    Episode_Reward/rotating_object: 88.0750
        Episode_Reward/action_rate: -0.0777
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 2.05s
                      Time elapsed: 00:31:13
                               ETA: 00:20:57

################################################################################
                     [1m Learning iteration 898/1500 [0m                      

                       Computation: 46672 steps/s (collection: 1.994s, learning 0.113s)
             Mean action noise std: 3.57
          Mean value_function loss: 79.4142
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 69.1267
                       Mean reward: 504.78
               Mean episode length: 241.43
    Episode_Reward/reaching_object: 1.3549
    Episode_Reward/rotating_object: 89.7851
        Episode_Reward/action_rate: -0.0798
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 2.11s
                      Time elapsed: 00:31:15
                               ETA: 00:20:55

################################################################################
                     [1m Learning iteration 899/1500 [0m                      

                       Computation: 47932 steps/s (collection: 1.938s, learning 0.113s)
             Mean action noise std: 3.58
          Mean value_function loss: 80.1934
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 69.1484
                       Mean reward: 471.07
               Mean episode length: 234.48
    Episode_Reward/reaching_object: 1.3182
    Episode_Reward/rotating_object: 88.4957
        Episode_Reward/action_rate: -0.0774
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 2.05s
                      Time elapsed: 00:31:17
                               ETA: 00:20:53

################################################################################
                     [1m Learning iteration 900/1500 [0m                      

                       Computation: 47592 steps/s (collection: 1.952s, learning 0.113s)
             Mean action noise std: 3.58
          Mean value_function loss: 86.6779
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 69.1744
                       Mean reward: 423.32
               Mean episode length: 227.77
    Episode_Reward/reaching_object: 1.3084
    Episode_Reward/rotating_object: 83.7599
        Episode_Reward/action_rate: -0.0778
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 2.07s
                      Time elapsed: 00:31:19
                               ETA: 00:20:51

################################################################################
                     [1m Learning iteration 901/1500 [0m                      

                       Computation: 47458 steps/s (collection: 1.959s, learning 0.113s)
             Mean action noise std: 3.58
          Mean value_function loss: 79.1290
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 69.1968
                       Mean reward: 381.26
               Mean episode length: 226.92
    Episode_Reward/reaching_object: 1.2884
    Episode_Reward/rotating_object: 81.4137
        Episode_Reward/action_rate: -0.0767
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 2.07s
                      Time elapsed: 00:31:21
                               ETA: 00:20:49

################################################################################
                     [1m Learning iteration 902/1500 [0m                      

                       Computation: 47312 steps/s (collection: 1.964s, learning 0.114s)
             Mean action noise std: 3.59
          Mean value_function loss: 87.7251
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 69.2123
                       Mean reward: 422.82
               Mean episode length: 230.86
    Episode_Reward/reaching_object: 1.2886
    Episode_Reward/rotating_object: 84.0424
        Episode_Reward/action_rate: -0.0765
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 2.08s
                      Time elapsed: 00:31:23
                               ETA: 00:20:47

################################################################################
                     [1m Learning iteration 903/1500 [0m                      

                       Computation: 47640 steps/s (collection: 1.949s, learning 0.114s)
             Mean action noise std: 3.59
          Mean value_function loss: 81.2417
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 69.2268
                       Mean reward: 462.76
               Mean episode length: 233.74
    Episode_Reward/reaching_object: 1.3238
    Episode_Reward/rotating_object: 87.6408
        Episode_Reward/action_rate: -0.0777
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 2.06s
                      Time elapsed: 00:31:25
                               ETA: 00:20:45

################################################################################
                     [1m Learning iteration 904/1500 [0m                      

                       Computation: 47856 steps/s (collection: 1.941s, learning 0.113s)
             Mean action noise std: 3.59
          Mean value_function loss: 72.3839
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 69.2454
                       Mean reward: 442.06
               Mean episode length: 233.24
    Episode_Reward/reaching_object: 1.3030
    Episode_Reward/rotating_object: 85.8209
        Episode_Reward/action_rate: -0.0776
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 2.05s
                      Time elapsed: 00:31:27
                               ETA: 00:20:43

################################################################################
                     [1m Learning iteration 905/1500 [0m                      

                       Computation: 47463 steps/s (collection: 1.956s, learning 0.115s)
             Mean action noise std: 3.59
          Mean value_function loss: 76.1743
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 69.2622
                       Mean reward: 440.59
               Mean episode length: 231.17
    Episode_Reward/reaching_object: 1.3191
    Episode_Reward/rotating_object: 84.7759
        Episode_Reward/action_rate: -0.0787
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 2.07s
                      Time elapsed: 00:31:29
                               ETA: 00:20:41

################################################################################
                     [1m Learning iteration 906/1500 [0m                      

                       Computation: 47562 steps/s (collection: 1.954s, learning 0.113s)
             Mean action noise std: 3.60
          Mean value_function loss: 75.8977
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 69.2811
                       Mean reward: 434.33
               Mean episode length: 238.30
    Episode_Reward/reaching_object: 1.3677
    Episode_Reward/rotating_object: 89.4086
        Episode_Reward/action_rate: -0.0812
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 2.07s
                      Time elapsed: 00:31:32
                               ETA: 00:20:39

################################################################################
                     [1m Learning iteration 907/1500 [0m                      

                       Computation: 47808 steps/s (collection: 1.940s, learning 0.117s)
             Mean action noise std: 3.60
          Mean value_function loss: 80.8243
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 69.2962
                       Mean reward: 411.64
               Mean episode length: 226.22
    Episode_Reward/reaching_object: 1.3216
    Episode_Reward/rotating_object: 89.9978
        Episode_Reward/action_rate: -0.0784
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 2.06s
                      Time elapsed: 00:31:34
                               ETA: 00:20:36

################################################################################
                     [1m Learning iteration 908/1500 [0m                      

                       Computation: 47580 steps/s (collection: 1.944s, learning 0.122s)
             Mean action noise std: 3.60
          Mean value_function loss: 78.8049
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 69.3181
                       Mean reward: 430.30
               Mean episode length: 229.88
    Episode_Reward/reaching_object: 1.3112
    Episode_Reward/rotating_object: 87.1272
        Episode_Reward/action_rate: -0.0789
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 2.07s
                      Time elapsed: 00:31:36
                               ETA: 00:20:34

################################################################################
                     [1m Learning iteration 909/1500 [0m                      

                       Computation: 47175 steps/s (collection: 1.970s, learning 0.113s)
             Mean action noise std: 3.61
          Mean value_function loss: 69.0029
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 69.3367
                       Mean reward: 455.28
               Mean episode length: 237.74
    Episode_Reward/reaching_object: 1.3131
    Episode_Reward/rotating_object: 85.0416
        Episode_Reward/action_rate: -0.0797
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 2.08s
                      Time elapsed: 00:31:38
                               ETA: 00:20:32

################################################################################
                     [1m Learning iteration 910/1500 [0m                      

                       Computation: 47344 steps/s (collection: 1.966s, learning 0.111s)
             Mean action noise std: 3.61
          Mean value_function loss: 80.6014
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 69.3589
                       Mean reward: 435.79
               Mean episode length: 234.03
    Episode_Reward/reaching_object: 1.3176
    Episode_Reward/rotating_object: 87.9744
        Episode_Reward/action_rate: -0.0791
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 2.08s
                      Time elapsed: 00:31:40
                               ETA: 00:20:30

################################################################################
                     [1m Learning iteration 911/1500 [0m                      

                       Computation: 47303 steps/s (collection: 1.966s, learning 0.112s)
             Mean action noise std: 3.61
          Mean value_function loss: 74.8830
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 69.3742
                       Mean reward: 464.65
               Mean episode length: 234.02
    Episode_Reward/reaching_object: 1.3098
    Episode_Reward/rotating_object: 86.4284
        Episode_Reward/action_rate: -0.0795
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 2.08s
                      Time elapsed: 00:31:42
                               ETA: 00:20:28

################################################################################
                     [1m Learning iteration 912/1500 [0m                      

                       Computation: 47507 steps/s (collection: 1.958s, learning 0.111s)
             Mean action noise std: 3.61
          Mean value_function loss: 76.3979
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 69.3986
                       Mean reward: 477.79
               Mean episode length: 238.38
    Episode_Reward/reaching_object: 1.3567
    Episode_Reward/rotating_object: 92.3838
        Episode_Reward/action_rate: -0.0816
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 2.07s
                      Time elapsed: 00:31:44
                               ETA: 00:20:26

################################################################################
                     [1m Learning iteration 913/1500 [0m                      

                       Computation: 47549 steps/s (collection: 1.955s, learning 0.112s)
             Mean action noise std: 3.62
          Mean value_function loss: 79.2306
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 69.4163
                       Mean reward: 466.08
               Mean episode length: 229.38
    Episode_Reward/reaching_object: 1.3352
    Episode_Reward/rotating_object: 91.3541
        Episode_Reward/action_rate: -0.0793
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 2.07s
                      Time elapsed: 00:31:46
                               ETA: 00:20:24

################################################################################
                     [1m Learning iteration 914/1500 [0m                      

                       Computation: 48586 steps/s (collection: 1.913s, learning 0.110s)
             Mean action noise std: 3.62
          Mean value_function loss: 80.7478
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 69.4395
                       Mean reward: 418.55
               Mean episode length: 223.42
    Episode_Reward/reaching_object: 1.3016
    Episode_Reward/rotating_object: 84.5603
        Episode_Reward/action_rate: -0.0796
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 2.02s
                      Time elapsed: 00:31:48
                               ETA: 00:20:22

################################################################################
                     [1m Learning iteration 915/1500 [0m                      

                       Computation: 48739 steps/s (collection: 1.906s, learning 0.110s)
             Mean action noise std: 3.63
          Mean value_function loss: 84.7765
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 69.4638
                       Mean reward: 448.79
               Mean episode length: 228.17
    Episode_Reward/reaching_object: 1.3071
    Episode_Reward/rotating_object: 87.8548
        Episode_Reward/action_rate: -0.0790
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 2.02s
                      Time elapsed: 00:31:50
                               ETA: 00:20:20

################################################################################
                     [1m Learning iteration 916/1500 [0m                      

                       Computation: 48287 steps/s (collection: 1.926s, learning 0.110s)
             Mean action noise std: 3.63
          Mean value_function loss: 86.2392
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 69.4865
                       Mean reward: 444.06
               Mean episode length: 228.55
    Episode_Reward/reaching_object: 1.3210
    Episode_Reward/rotating_object: 89.2942
        Episode_Reward/action_rate: -0.0796
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 2.04s
                      Time elapsed: 00:31:52
                               ETA: 00:20:18

################################################################################
                     [1m Learning iteration 917/1500 [0m                      

                       Computation: 48534 steps/s (collection: 1.915s, learning 0.110s)
             Mean action noise std: 3.63
          Mean value_function loss: 88.5735
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 69.5194
                       Mean reward: 438.82
               Mean episode length: 228.78
    Episode_Reward/reaching_object: 1.3407
    Episode_Reward/rotating_object: 89.8850
        Episode_Reward/action_rate: -0.0813
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 2.03s
                      Time elapsed: 00:31:54
                               ETA: 00:20:15

################################################################################
                     [1m Learning iteration 918/1500 [0m                      

                       Computation: 48812 steps/s (collection: 1.904s, learning 0.110s)
             Mean action noise std: 3.64
          Mean value_function loss: 83.2406
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 69.5437
                       Mean reward: 417.37
               Mean episode length: 226.77
    Episode_Reward/reaching_object: 1.3253
    Episode_Reward/rotating_object: 90.3287
        Episode_Reward/action_rate: -0.0801
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 2.01s
                      Time elapsed: 00:31:56
                               ETA: 00:20:13

################################################################################
                     [1m Learning iteration 919/1500 [0m                      

                       Computation: 48686 steps/s (collection: 1.905s, learning 0.114s)
             Mean action noise std: 3.64
          Mean value_function loss: 81.7923
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 69.5562
                       Mean reward: 452.57
               Mean episode length: 228.28
    Episode_Reward/reaching_object: 1.3433
    Episode_Reward/rotating_object: 87.8129
        Episode_Reward/action_rate: -0.0815
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 2.02s
                      Time elapsed: 00:31:58
                               ETA: 00:20:11

################################################################################
                     [1m Learning iteration 920/1500 [0m                      

                       Computation: 48647 steps/s (collection: 1.907s, learning 0.114s)
             Mean action noise std: 3.64
          Mean value_function loss: 87.8197
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 69.5721
                       Mean reward: 439.61
               Mean episode length: 238.83
    Episode_Reward/reaching_object: 1.2983
    Episode_Reward/rotating_object: 83.6146
        Episode_Reward/action_rate: -0.0802
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 2.02s
                      Time elapsed: 00:32:00
                               ETA: 00:20:09

################################################################################
                     [1m Learning iteration 921/1500 [0m                      

                       Computation: 48027 steps/s (collection: 1.937s, learning 0.110s)
             Mean action noise std: 3.64
          Mean value_function loss: 78.2960
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 69.5888
                       Mean reward: 450.66
               Mean episode length: 233.65
    Episode_Reward/reaching_object: 1.3554
    Episode_Reward/rotating_object: 91.7652
        Episode_Reward/action_rate: -0.0818
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 2.05s
                      Time elapsed: 00:32:02
                               ETA: 00:20:07

################################################################################
                     [1m Learning iteration 922/1500 [0m                      

                       Computation: 47206 steps/s (collection: 1.969s, learning 0.114s)
             Mean action noise std: 3.65
          Mean value_function loss: 79.9576
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 69.6086
                       Mean reward: 451.14
               Mean episode length: 225.75
    Episode_Reward/reaching_object: 1.3315
    Episode_Reward/rotating_object: 88.9581
        Episode_Reward/action_rate: -0.0807
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 2.08s
                      Time elapsed: 00:32:04
                               ETA: 00:20:05

################################################################################
                     [1m Learning iteration 923/1500 [0m                      

                       Computation: 47522 steps/s (collection: 1.957s, learning 0.112s)
             Mean action noise std: 3.65
          Mean value_function loss: 75.3848
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 69.6298
                       Mean reward: 410.77
               Mean episode length: 229.91
    Episode_Reward/reaching_object: 1.3179
    Episode_Reward/rotating_object: 89.6254
        Episode_Reward/action_rate: -0.0805
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 2.07s
                      Time elapsed: 00:32:06
                               ETA: 00:20:03

################################################################################
                     [1m Learning iteration 924/1500 [0m                      

                       Computation: 47618 steps/s (collection: 1.950s, learning 0.115s)
             Mean action noise std: 3.65
          Mean value_function loss: 77.9108
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 69.6548
                       Mean reward: 446.14
               Mean episode length: 235.59
    Episode_Reward/reaching_object: 1.3281
    Episode_Reward/rotating_object: 88.7244
        Episode_Reward/action_rate: -0.0816
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 2.06s
                      Time elapsed: 00:32:08
                               ETA: 00:20:01

################################################################################
                     [1m Learning iteration 925/1500 [0m                      

                       Computation: 47769 steps/s (collection: 1.944s, learning 0.114s)
             Mean action noise std: 3.66
          Mean value_function loss: 83.7961
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 69.6836
                       Mean reward: 411.65
               Mean episode length: 225.71
    Episode_Reward/reaching_object: 1.2913
    Episode_Reward/rotating_object: 86.4467
        Episode_Reward/action_rate: -0.0799
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 2.06s
                      Time elapsed: 00:32:11
                               ETA: 00:19:59

################################################################################
                     [1m Learning iteration 926/1500 [0m                      

                       Computation: 47272 steps/s (collection: 1.968s, learning 0.112s)
             Mean action noise std: 3.66
          Mean value_function loss: 85.6255
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 69.7069
                       Mean reward: 443.90
               Mean episode length: 230.34
    Episode_Reward/reaching_object: 1.2836
    Episode_Reward/rotating_object: 82.5753
        Episode_Reward/action_rate: -0.0804
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 2.08s
                      Time elapsed: 00:32:13
                               ETA: 00:19:56

################################################################################
                     [1m Learning iteration 927/1500 [0m                      

                       Computation: 46578 steps/s (collection: 1.997s, learning 0.113s)
             Mean action noise std: 3.66
          Mean value_function loss: 97.1743
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 69.7300
                       Mean reward: 440.33
               Mean episode length: 227.88
    Episode_Reward/reaching_object: 1.2837
    Episode_Reward/rotating_object: 85.6417
        Episode_Reward/action_rate: -0.0799
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 2.11s
                      Time elapsed: 00:32:15
                               ETA: 00:19:54

################################################################################
                     [1m Learning iteration 928/1500 [0m                      

                       Computation: 46393 steps/s (collection: 2.005s, learning 0.114s)
             Mean action noise std: 3.67
          Mean value_function loss: 80.3623
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 69.7484
                       Mean reward: 445.60
               Mean episode length: 227.66
    Episode_Reward/reaching_object: 1.2877
    Episode_Reward/rotating_object: 84.2523
        Episode_Reward/action_rate: -0.0806
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 2.12s
                      Time elapsed: 00:32:17
                               ETA: 00:19:52

################################################################################
                     [1m Learning iteration 929/1500 [0m                      

                       Computation: 47234 steps/s (collection: 1.968s, learning 0.114s)
             Mean action noise std: 3.67
          Mean value_function loss: 83.9409
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 69.7664
                       Mean reward: 443.40
               Mean episode length: 229.97
    Episode_Reward/reaching_object: 1.3193
    Episode_Reward/rotating_object: 88.8807
        Episode_Reward/action_rate: -0.0818
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 2.08s
                      Time elapsed: 00:32:19
                               ETA: 00:19:50

################################################################################
                     [1m Learning iteration 930/1500 [0m                      

                       Computation: 47567 steps/s (collection: 1.956s, learning 0.110s)
             Mean action noise std: 3.67
          Mean value_function loss: 83.0894
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 69.7862
                       Mean reward: 452.36
               Mean episode length: 232.62
    Episode_Reward/reaching_object: 1.3061
    Episode_Reward/rotating_object: 86.7954
        Episode_Reward/action_rate: -0.0816
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 2.07s
                      Time elapsed: 00:32:21
                               ETA: 00:19:48

################################################################################
                     [1m Learning iteration 931/1500 [0m                      

                       Computation: 47257 steps/s (collection: 1.969s, learning 0.111s)
             Mean action noise std: 3.68
          Mean value_function loss: 79.6087
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 69.8036
                       Mean reward: 423.29
               Mean episode length: 237.12
    Episode_Reward/reaching_object: 1.3154
    Episode_Reward/rotating_object: 85.0942
        Episode_Reward/action_rate: -0.0823
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 2.08s
                      Time elapsed: 00:32:23
                               ETA: 00:19:46

################################################################################
                     [1m Learning iteration 932/1500 [0m                      

                       Computation: 47502 steps/s (collection: 1.956s, learning 0.114s)
             Mean action noise std: 3.68
          Mean value_function loss: 78.0753
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 69.8221
                       Mean reward: 469.72
               Mean episode length: 243.97
    Episode_Reward/reaching_object: 1.3317
    Episode_Reward/rotating_object: 87.9647
        Episode_Reward/action_rate: -0.0830
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 2.07s
                      Time elapsed: 00:32:25
                               ETA: 00:19:44

################################################################################
                     [1m Learning iteration 933/1500 [0m                      

                       Computation: 47452 steps/s (collection: 1.960s, learning 0.111s)
             Mean action noise std: 3.68
          Mean value_function loss: 85.0233
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 69.8464
                       Mean reward: 457.09
               Mean episode length: 241.59
    Episode_Reward/reaching_object: 1.3643
    Episode_Reward/rotating_object: 88.9804
        Episode_Reward/action_rate: -0.0853
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 2.07s
                      Time elapsed: 00:32:27
                               ETA: 00:19:42

################################################################################
                     [1m Learning iteration 934/1500 [0m                      

                       Computation: 47658 steps/s (collection: 1.952s, learning 0.111s)
             Mean action noise std: 3.68
          Mean value_function loss: 88.2113
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 69.8638
                       Mean reward: 427.98
               Mean episode length: 230.81
    Episode_Reward/reaching_object: 1.2892
    Episode_Reward/rotating_object: 82.0592
        Episode_Reward/action_rate: -0.0812
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 2.06s
                      Time elapsed: 00:32:29
                               ETA: 00:19:40

################################################################################
                     [1m Learning iteration 935/1500 [0m                      

                       Computation: 47059 steps/s (collection: 1.976s, learning 0.113s)
             Mean action noise std: 3.69
          Mean value_function loss: 79.5745
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 69.8797
                       Mean reward: 447.03
               Mean episode length: 235.85
    Episode_Reward/reaching_object: 1.3244
    Episode_Reward/rotating_object: 84.0346
        Episode_Reward/action_rate: -0.0824
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 2.09s
                      Time elapsed: 00:32:31
                               ETA: 00:19:38

################################################################################
                     [1m Learning iteration 936/1500 [0m                      

                       Computation: 47772 steps/s (collection: 1.944s, learning 0.113s)
             Mean action noise std: 3.69
          Mean value_function loss: 87.7833
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 69.8996
                       Mean reward: 475.36
               Mean episode length: 229.20
    Episode_Reward/reaching_object: 1.3649
    Episode_Reward/rotating_object: 90.2344
        Episode_Reward/action_rate: -0.0850
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 2.06s
                      Time elapsed: 00:32:33
                               ETA: 00:19:36

################################################################################
                     [1m Learning iteration 937/1500 [0m                      

                       Computation: 48055 steps/s (collection: 1.933s, learning 0.113s)
             Mean action noise std: 3.69
          Mean value_function loss: 86.0667
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 69.9192
                       Mean reward: 472.39
               Mean episode length: 229.29
    Episode_Reward/reaching_object: 1.3145
    Episode_Reward/rotating_object: 86.1017
        Episode_Reward/action_rate: -0.0820
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 2.05s
                      Time elapsed: 00:32:35
                               ETA: 00:19:33

################################################################################
                     [1m Learning iteration 938/1500 [0m                      

                       Computation: 48459 steps/s (collection: 1.918s, learning 0.111s)
             Mean action noise std: 3.70
          Mean value_function loss: 79.3446
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 69.9467
                       Mean reward: 443.52
               Mean episode length: 233.07
    Episode_Reward/reaching_object: 1.3333
    Episode_Reward/rotating_object: 88.8194
        Episode_Reward/action_rate: -0.0832
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 2.03s
                      Time elapsed: 00:32:37
                               ETA: 00:19:31

################################################################################
                     [1m Learning iteration 939/1500 [0m                      

                       Computation: 48149 steps/s (collection: 1.932s, learning 0.110s)
             Mean action noise std: 3.70
          Mean value_function loss: 86.0084
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 69.9699
                       Mean reward: 473.89
               Mean episode length: 232.37
    Episode_Reward/reaching_object: 1.3541
    Episode_Reward/rotating_object: 90.4115
        Episode_Reward/action_rate: -0.0845
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 2.04s
                      Time elapsed: 00:32:40
                               ETA: 00:19:29

################################################################################
                     [1m Learning iteration 940/1500 [0m                      

                       Computation: 48626 steps/s (collection: 1.911s, learning 0.110s)
             Mean action noise std: 3.70
          Mean value_function loss: 77.3404
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 69.9890
                       Mean reward: 399.76
               Mean episode length: 230.74
    Episode_Reward/reaching_object: 1.3257
    Episode_Reward/rotating_object: 86.8912
        Episode_Reward/action_rate: -0.0830
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 2.02s
                      Time elapsed: 00:32:42
                               ETA: 00:19:27

################################################################################
                     [1m Learning iteration 941/1500 [0m                      

                       Computation: 48866 steps/s (collection: 1.901s, learning 0.110s)
             Mean action noise std: 3.71
          Mean value_function loss: 70.5150
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 70.0144
                       Mean reward: 439.39
               Mean episode length: 235.24
    Episode_Reward/reaching_object: 1.3393
    Episode_Reward/rotating_object: 91.1006
        Episode_Reward/action_rate: -0.0842
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 2.01s
                      Time elapsed: 00:32:44
                               ETA: 00:19:25

################################################################################
                     [1m Learning iteration 942/1500 [0m                      

                       Computation: 48803 steps/s (collection: 1.895s, learning 0.119s)
             Mean action noise std: 3.71
          Mean value_function loss: 75.8796
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 70.0323
                       Mean reward: 409.29
               Mean episode length: 230.36
    Episode_Reward/reaching_object: 1.3112
    Episode_Reward/rotating_object: 84.8069
        Episode_Reward/action_rate: -0.0833
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 2.01s
                      Time elapsed: 00:32:46
                               ETA: 00:19:23

################################################################################
                     [1m Learning iteration 943/1500 [0m                      

                       Computation: 48614 steps/s (collection: 1.907s, learning 0.115s)
             Mean action noise std: 3.71
          Mean value_function loss: 76.4299
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 70.0493
                       Mean reward: 419.68
               Mean episode length: 223.30
    Episode_Reward/reaching_object: 1.3313
    Episode_Reward/rotating_object: 89.2065
        Episode_Reward/action_rate: -0.0839
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 2.02s
                      Time elapsed: 00:32:48
                               ETA: 00:19:21

################################################################################
                     [1m Learning iteration 944/1500 [0m                      

                       Computation: 48432 steps/s (collection: 1.920s, learning 0.110s)
             Mean action noise std: 3.72
          Mean value_function loss: 82.4757
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 70.0740
                       Mean reward: 479.30
               Mean episode length: 235.84
    Episode_Reward/reaching_object: 1.3114
    Episode_Reward/rotating_object: 88.5575
        Episode_Reward/action_rate: -0.0832
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 2.03s
                      Time elapsed: 00:32:50
                               ETA: 00:19:19

################################################################################
                     [1m Learning iteration 945/1500 [0m                      

                       Computation: 48125 steps/s (collection: 1.929s, learning 0.114s)
             Mean action noise std: 3.72
          Mean value_function loss: 84.9228
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 70.1014
                       Mean reward: 394.60
               Mean episode length: 229.04
    Episode_Reward/reaching_object: 1.3016
    Episode_Reward/rotating_object: 86.1161
        Episode_Reward/action_rate: -0.0833
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 2.04s
                      Time elapsed: 00:32:52
                               ETA: 00:19:17

################################################################################
                     [1m Learning iteration 946/1500 [0m                      

                       Computation: 47266 steps/s (collection: 1.965s, learning 0.115s)
             Mean action noise std: 3.72
          Mean value_function loss: 78.3549
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 70.1274
                       Mean reward: 448.52
               Mean episode length: 224.11
    Episode_Reward/reaching_object: 1.3192
    Episode_Reward/rotating_object: 88.4627
        Episode_Reward/action_rate: -0.0837
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 2.08s
                      Time elapsed: 00:32:54
                               ETA: 00:19:14

################################################################################
                     [1m Learning iteration 947/1500 [0m                      

                       Computation: 48181 steps/s (collection: 1.929s, learning 0.111s)
             Mean action noise std: 3.73
          Mean value_function loss: 80.0282
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 70.1486
                       Mean reward: 429.88
               Mean episode length: 226.05
    Episode_Reward/reaching_object: 1.3381
    Episode_Reward/rotating_object: 89.5605
        Episode_Reward/action_rate: -0.0858
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 2.04s
                      Time elapsed: 00:32:56
                               ETA: 00:19:12

################################################################################
                     [1m Learning iteration 948/1500 [0m                      

                       Computation: 47867 steps/s (collection: 1.940s, learning 0.114s)
             Mean action noise std: 3.73
          Mean value_function loss: 84.0631
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 70.1704
                       Mean reward: 459.46
               Mean episode length: 232.64
    Episode_Reward/reaching_object: 1.2950
    Episode_Reward/rotating_object: 86.2158
        Episode_Reward/action_rate: -0.0833
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 2.05s
                      Time elapsed: 00:32:58
                               ETA: 00:19:10

################################################################################
                     [1m Learning iteration 949/1500 [0m                      

                       Computation: 47664 steps/s (collection: 1.949s, learning 0.114s)
             Mean action noise std: 3.74
          Mean value_function loss: 83.5683
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 70.1914
                       Mean reward: 454.33
               Mean episode length: 235.04
    Episode_Reward/reaching_object: 1.3031
    Episode_Reward/rotating_object: 87.4971
        Episode_Reward/action_rate: -0.0837
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 2.06s
                      Time elapsed: 00:33:00
                               ETA: 00:19:08

################################################################################
                     [1m Learning iteration 950/1500 [0m                      

                       Computation: 46353 steps/s (collection: 2.009s, learning 0.111s)
             Mean action noise std: 3.74
          Mean value_function loss: 86.8189
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 70.2124
                       Mean reward: 430.55
               Mean episode length: 229.79
    Episode_Reward/reaching_object: 1.2921
    Episode_Reward/rotating_object: 86.2197
        Episode_Reward/action_rate: -0.0831
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 2.12s
                      Time elapsed: 00:33:02
                               ETA: 00:19:06

################################################################################
                     [1m Learning iteration 951/1500 [0m                      

                       Computation: 47272 steps/s (collection: 1.969s, learning 0.110s)
             Mean action noise std: 3.74
          Mean value_function loss: 81.2308
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 70.2295
                       Mean reward: 454.68
               Mean episode length: 233.04
    Episode_Reward/reaching_object: 1.2929
    Episode_Reward/rotating_object: 85.1589
        Episode_Reward/action_rate: -0.0836
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 2.08s
                      Time elapsed: 00:33:04
                               ETA: 00:19:04

################################################################################
                     [1m Learning iteration 952/1500 [0m                      

                       Computation: 47760 steps/s (collection: 1.948s, learning 0.110s)
             Mean action noise std: 3.75
          Mean value_function loss: 78.5148
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 70.2537
                       Mean reward: 387.39
               Mean episode length: 228.33
    Episode_Reward/reaching_object: 1.2864
    Episode_Reward/rotating_object: 83.2425
        Episode_Reward/action_rate: -0.0840
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 2.06s
                      Time elapsed: 00:33:06
                               ETA: 00:19:02

################################################################################
                     [1m Learning iteration 953/1500 [0m                      

                       Computation: 48000 steps/s (collection: 1.938s, learning 0.110s)
             Mean action noise std: 3.75
          Mean value_function loss: 78.3327
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 70.2744
                       Mean reward: 401.42
               Mean episode length: 231.97
    Episode_Reward/reaching_object: 1.3343
    Episode_Reward/rotating_object: 88.1608
        Episode_Reward/action_rate: -0.0862
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 2.05s
                      Time elapsed: 00:33:08
                               ETA: 00:19:00

################################################################################
                     [1m Learning iteration 954/1500 [0m                      

                       Computation: 46230 steps/s (collection: 2.017s, learning 0.110s)
             Mean action noise std: 3.75
          Mean value_function loss: 85.6947
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 70.2899
                       Mean reward: 445.12
               Mean episode length: 227.09
    Episode_Reward/reaching_object: 1.2895
    Episode_Reward/rotating_object: 89.0485
        Episode_Reward/action_rate: -0.0837
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 2.13s
                      Time elapsed: 00:33:10
                               ETA: 00:18:58

################################################################################
                     [1m Learning iteration 955/1500 [0m                      

                       Computation: 47595 steps/s (collection: 1.951s, learning 0.114s)
             Mean action noise std: 3.75
          Mean value_function loss: 81.7812
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 70.3037
                       Mean reward: 481.71
               Mean episode length: 230.97
    Episode_Reward/reaching_object: 1.3280
    Episode_Reward/rotating_object: 89.6284
        Episode_Reward/action_rate: -0.0855
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 2.07s
                      Time elapsed: 00:33:12
                               ETA: 00:18:56

################################################################################
                     [1m Learning iteration 956/1500 [0m                      

                       Computation: 46649 steps/s (collection: 1.962s, learning 0.146s)
             Mean action noise std: 3.76
          Mean value_function loss: 89.1360
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 70.3212
                       Mean reward: 405.60
               Mean episode length: 216.93
    Episode_Reward/reaching_object: 1.2934
    Episode_Reward/rotating_object: 85.0797
        Episode_Reward/action_rate: -0.0838
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 2.11s
                      Time elapsed: 00:33:14
                               ETA: 00:18:54

################################################################################
                     [1m Learning iteration 957/1500 [0m                      

                       Computation: 47766 steps/s (collection: 1.947s, learning 0.111s)
             Mean action noise std: 3.76
          Mean value_function loss: 83.1336
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 70.3417
                       Mean reward: 480.99
               Mean episode length: 234.34
    Episode_Reward/reaching_object: 1.3156
    Episode_Reward/rotating_object: 88.1086
        Episode_Reward/action_rate: -0.0853
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 2.06s
                      Time elapsed: 00:33:17
                               ETA: 00:18:51

################################################################################
                     [1m Learning iteration 958/1500 [0m                      

                       Computation: 47477 steps/s (collection: 1.946s, learning 0.125s)
             Mean action noise std: 3.76
          Mean value_function loss: 76.8330
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 70.3661
                       Mean reward: 412.20
               Mean episode length: 228.66
    Episode_Reward/reaching_object: 1.3320
    Episode_Reward/rotating_object: 88.0253
        Episode_Reward/action_rate: -0.0863
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 2.07s
                      Time elapsed: 00:33:19
                               ETA: 00:18:49

################################################################################
                     [1m Learning iteration 959/1500 [0m                      

                       Computation: 47716 steps/s (collection: 1.947s, learning 0.113s)
             Mean action noise std: 3.77
          Mean value_function loss: 81.4318
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 70.3908
                       Mean reward: 479.40
               Mean episode length: 232.02
    Episode_Reward/reaching_object: 1.3205
    Episode_Reward/rotating_object: 85.5640
        Episode_Reward/action_rate: -0.0859
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 2.06s
                      Time elapsed: 00:33:21
                               ETA: 00:18:47

################################################################################
                     [1m Learning iteration 960/1500 [0m                      

                       Computation: 48107 steps/s (collection: 1.933s, learning 0.111s)
             Mean action noise std: 3.77
          Mean value_function loss: 88.8480
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 70.4173
                       Mean reward: 440.19
               Mean episode length: 225.83
    Episode_Reward/reaching_object: 1.3059
    Episode_Reward/rotating_object: 87.7522
        Episode_Reward/action_rate: -0.0845
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 2.04s
                      Time elapsed: 00:33:23
                               ETA: 00:18:45

################################################################################
                     [1m Learning iteration 961/1500 [0m                      

                       Computation: 48424 steps/s (collection: 1.916s, learning 0.114s)
             Mean action noise std: 3.77
          Mean value_function loss: 78.9875
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 70.4365
                       Mean reward: 456.98
               Mean episode length: 233.38
    Episode_Reward/reaching_object: 1.3251
    Episode_Reward/rotating_object: 87.4232
        Episode_Reward/action_rate: -0.0868
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 2.03s
                      Time elapsed: 00:33:25
                               ETA: 00:18:43

################################################################################
                     [1m Learning iteration 962/1500 [0m                      

                       Computation: 48493 steps/s (collection: 1.916s, learning 0.111s)
             Mean action noise std: 3.78
          Mean value_function loss: 82.6228
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 70.4579
                       Mean reward: 463.69
               Mean episode length: 231.23
    Episode_Reward/reaching_object: 1.3197
    Episode_Reward/rotating_object: 85.9478
        Episode_Reward/action_rate: -0.0865
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 2.03s
                      Time elapsed: 00:33:27
                               ETA: 00:18:41

################################################################################
                     [1m Learning iteration 963/1500 [0m                      

                       Computation: 48476 steps/s (collection: 1.916s, learning 0.112s)
             Mean action noise std: 3.78
          Mean value_function loss: 81.6205
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 70.4889
                       Mean reward: 431.54
               Mean episode length: 237.00
    Episode_Reward/reaching_object: 1.2769
    Episode_Reward/rotating_object: 81.2712
        Episode_Reward/action_rate: -0.0849
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 2.03s
                      Time elapsed: 00:33:29
                               ETA: 00:18:39

################################################################################
                     [1m Learning iteration 964/1500 [0m                      

                       Computation: 48958 steps/s (collection: 1.898s, learning 0.110s)
             Mean action noise std: 3.79
          Mean value_function loss: 81.0592
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 70.5209
                       Mean reward: 452.02
               Mean episode length: 235.73
    Episode_Reward/reaching_object: 1.3429
    Episode_Reward/rotating_object: 90.6205
        Episode_Reward/action_rate: -0.0876
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 2.01s
                      Time elapsed: 00:33:31
                               ETA: 00:18:37

################################################################################
                     [1m Learning iteration 965/1500 [0m                      

                       Computation: 49132 steps/s (collection: 1.891s, learning 0.110s)
             Mean action noise std: 3.79
          Mean value_function loss: 73.0421
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 70.5359
                       Mean reward: 451.26
               Mean episode length: 230.57
    Episode_Reward/reaching_object: 1.3217
    Episode_Reward/rotating_object: 90.0393
        Episode_Reward/action_rate: -0.0863
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 2.00s
                      Time elapsed: 00:33:33
                               ETA: 00:18:35

################################################################################
                     [1m Learning iteration 966/1500 [0m                      

                       Computation: 48934 steps/s (collection: 1.899s, learning 0.110s)
             Mean action noise std: 3.79
          Mean value_function loss: 78.8666
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 70.5512
                       Mean reward: 459.93
               Mean episode length: 235.99
    Episode_Reward/reaching_object: 1.3495
    Episode_Reward/rotating_object: 91.3478
        Episode_Reward/action_rate: -0.0882
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 2.01s
                      Time elapsed: 00:33:35
                               ETA: 00:18:32

################################################################################
                     [1m Learning iteration 967/1500 [0m                      

                       Computation: 49091 steps/s (collection: 1.892s, learning 0.110s)
             Mean action noise std: 3.79
          Mean value_function loss: 77.6799
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 70.5707
                       Mean reward: 455.11
               Mean episode length: 232.80
    Episode_Reward/reaching_object: 1.3664
    Episode_Reward/rotating_object: 91.0463
        Episode_Reward/action_rate: -0.0890
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 2.00s
                      Time elapsed: 00:33:37
                               ETA: 00:18:30

################################################################################
                     [1m Learning iteration 968/1500 [0m                      

                       Computation: 47604 steps/s (collection: 1.955s, learning 0.110s)
             Mean action noise std: 3.80
          Mean value_function loss: 76.5814
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 70.5962
                       Mean reward: 431.47
               Mean episode length: 235.33
    Episode_Reward/reaching_object: 1.3183
    Episode_Reward/rotating_object: 84.8887
        Episode_Reward/action_rate: -0.0871
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 2.07s
                      Time elapsed: 00:33:39
                               ETA: 00:18:28

################################################################################
                     [1m Learning iteration 969/1500 [0m                      

                       Computation: 47763 steps/s (collection: 1.948s, learning 0.110s)
             Mean action noise std: 3.80
          Mean value_function loss: 83.4573
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 70.6208
                       Mean reward: 437.30
               Mean episode length: 234.81
    Episode_Reward/reaching_object: 1.3396
    Episode_Reward/rotating_object: 88.2334
        Episode_Reward/action_rate: -0.0880
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 2.06s
                      Time elapsed: 00:33:41
                               ETA: 00:18:26

################################################################################
                     [1m Learning iteration 970/1500 [0m                      

                       Computation: 47953 steps/s (collection: 1.933s, learning 0.117s)
             Mean action noise std: 3.81
          Mean value_function loss: 80.6463
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 70.6470
                       Mean reward: 466.73
               Mean episode length: 241.66
    Episode_Reward/reaching_object: 1.3422
    Episode_Reward/rotating_object: 89.3616
        Episode_Reward/action_rate: -0.0879
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 2.05s
                      Time elapsed: 00:33:43
                               ETA: 00:18:24

################################################################################
                     [1m Learning iteration 971/1500 [0m                      

                       Computation: 47660 steps/s (collection: 1.951s, learning 0.111s)
             Mean action noise std: 3.81
          Mean value_function loss: 90.6002
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 70.6723
                       Mean reward: 440.99
               Mean episode length: 229.79
    Episode_Reward/reaching_object: 1.3153
    Episode_Reward/rotating_object: 89.6987
        Episode_Reward/action_rate: -0.0860
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 2.06s
                      Time elapsed: 00:33:45
                               ETA: 00:18:22

################################################################################
                     [1m Learning iteration 972/1500 [0m                      

                       Computation: 47843 steps/s (collection: 1.941s, learning 0.114s)
             Mean action noise std: 3.81
          Mean value_function loss: 80.2578
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 70.6926
                       Mean reward: 464.28
               Mean episode length: 229.52
    Episode_Reward/reaching_object: 1.3254
    Episode_Reward/rotating_object: 89.5485
        Episode_Reward/action_rate: -0.0863
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 2.05s
                      Time elapsed: 00:33:47
                               ETA: 00:18:20

################################################################################
                     [1m Learning iteration 973/1500 [0m                      

                       Computation: 47992 steps/s (collection: 1.935s, learning 0.113s)
             Mean action noise std: 3.82
          Mean value_function loss: 70.3892
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 70.7135
                       Mean reward: 421.69
               Mean episode length: 232.84
    Episode_Reward/reaching_object: 1.3167
    Episode_Reward/rotating_object: 87.9413
        Episode_Reward/action_rate: -0.0867
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 2.05s
                      Time elapsed: 00:33:49
                               ETA: 00:18:18

################################################################################
                     [1m Learning iteration 974/1500 [0m                      

                       Computation: 48110 steps/s (collection: 1.928s, learning 0.115s)
             Mean action noise std: 3.82
          Mean value_function loss: 80.5303
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 70.7367
                       Mean reward: 467.68
               Mean episode length: 237.16
    Episode_Reward/reaching_object: 1.3194
    Episode_Reward/rotating_object: 88.0152
        Episode_Reward/action_rate: -0.0875
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 2.04s
                      Time elapsed: 00:33:51
                               ETA: 00:18:16

################################################################################
                     [1m Learning iteration 975/1500 [0m                      

                       Computation: 47754 steps/s (collection: 1.945s, learning 0.114s)
             Mean action noise std: 3.82
          Mean value_function loss: 66.8133
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 70.7619
                       Mean reward: 431.03
               Mean episode length: 220.08
    Episode_Reward/reaching_object: 1.2872
    Episode_Reward/rotating_object: 86.0163
        Episode_Reward/action_rate: -0.0856
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 2.06s
                      Time elapsed: 00:33:53
                               ETA: 00:18:13

################################################################################
                     [1m Learning iteration 976/1500 [0m                      

                       Computation: 47299 steps/s (collection: 1.967s, learning 0.111s)
             Mean action noise std: 3.83
          Mean value_function loss: 74.5075
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 70.7911
                       Mean reward: 460.44
               Mean episode length: 234.62
    Episode_Reward/reaching_object: 1.2987
    Episode_Reward/rotating_object: 88.7528
        Episode_Reward/action_rate: -0.0872
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 2.08s
                      Time elapsed: 00:33:55
                               ETA: 00:18:11

################################################################################
                     [1m Learning iteration 977/1500 [0m                      

                       Computation: 46869 steps/s (collection: 1.984s, learning 0.113s)
             Mean action noise std: 3.83
          Mean value_function loss: 74.2521
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 70.8219
                       Mean reward: 435.10
               Mean episode length: 236.76
    Episode_Reward/reaching_object: 1.3136
    Episode_Reward/rotating_object: 89.2866
        Episode_Reward/action_rate: -0.0884
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 2.10s
                      Time elapsed: 00:33:57
                               ETA: 00:18:09

################################################################################
                     [1m Learning iteration 978/1500 [0m                      

                       Computation: 46878 steps/s (collection: 1.984s, learning 0.112s)
             Mean action noise std: 3.84
          Mean value_function loss: 75.8912
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 70.8530
                       Mean reward: 468.34
               Mean episode length: 236.81
    Episode_Reward/reaching_object: 1.3029
    Episode_Reward/rotating_object: 88.9333
        Episode_Reward/action_rate: -0.0875
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 2.10s
                      Time elapsed: 00:34:00
                               ETA: 00:18:07

################################################################################
                     [1m Learning iteration 979/1500 [0m                      

                       Computation: 47877 steps/s (collection: 1.938s, learning 0.115s)
             Mean action noise std: 3.84
          Mean value_function loss: 83.8078
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 70.8785
                       Mean reward: 427.19
               Mean episode length: 230.32
    Episode_Reward/reaching_object: 1.2976
    Episode_Reward/rotating_object: 86.8310
        Episode_Reward/action_rate: -0.0881
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 2.05s
                      Time elapsed: 00:34:02
                               ETA: 00:18:05

################################################################################
                     [1m Learning iteration 980/1500 [0m                      

                       Computation: 47470 steps/s (collection: 1.956s, learning 0.114s)
             Mean action noise std: 3.84
          Mean value_function loss: 81.7332
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 70.9014
                       Mean reward: 448.45
               Mean episode length: 234.56
    Episode_Reward/reaching_object: 1.3270
    Episode_Reward/rotating_object: 89.4263
        Episode_Reward/action_rate: -0.0897
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 18.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 2.07s
                      Time elapsed: 00:34:04
                               ETA: 00:18:03

################################################################################
                     [1m Learning iteration 981/1500 [0m                      

                       Computation: 47762 steps/s (collection: 1.945s, learning 0.113s)
             Mean action noise std: 3.85
          Mean value_function loss: 90.2838
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 70.9333
                       Mean reward: 461.80
               Mean episode length: 227.65
    Episode_Reward/reaching_object: 1.2920
    Episode_Reward/rotating_object: 91.1008
        Episode_Reward/action_rate: -0.0879
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 2.06s
                      Time elapsed: 00:34:06
                               ETA: 00:18:01

################################################################################
                     [1m Learning iteration 982/1500 [0m                      

                       Computation: 47836 steps/s (collection: 1.942s, learning 0.113s)
             Mean action noise std: 3.85
          Mean value_function loss: 79.3814
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 70.9654
                       Mean reward: 438.92
               Mean episode length: 221.47
    Episode_Reward/reaching_object: 1.2980
    Episode_Reward/rotating_object: 86.9760
        Episode_Reward/action_rate: -0.0879
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 2.05s
                      Time elapsed: 00:34:08
                               ETA: 00:17:59

################################################################################
                     [1m Learning iteration 983/1500 [0m                      

                       Computation: 47641 steps/s (collection: 1.941s, learning 0.123s)
             Mean action noise std: 3.86
          Mean value_function loss: 71.9487
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 70.9770
                       Mean reward: 504.97
               Mean episode length: 235.82
    Episode_Reward/reaching_object: 1.3250
    Episode_Reward/rotating_object: 90.7059
        Episode_Reward/action_rate: -0.0902
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 2.06s
                      Time elapsed: 00:34:10
                               ETA: 00:17:57

################################################################################
                     [1m Learning iteration 984/1500 [0m                      

                       Computation: 47654 steps/s (collection: 1.952s, learning 0.111s)
             Mean action noise std: 3.86
          Mean value_function loss: 78.8112
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 70.9947
                       Mean reward: 454.44
               Mean episode length: 233.25
    Episode_Reward/reaching_object: 1.3299
    Episode_Reward/rotating_object: 88.3893
        Episode_Reward/action_rate: -0.0898
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 2.06s
                      Time elapsed: 00:34:12
                               ETA: 00:17:55

################################################################################
                     [1m Learning iteration 985/1500 [0m                      

                       Computation: 48890 steps/s (collection: 1.900s, learning 0.111s)
             Mean action noise std: 3.86
          Mean value_function loss: 76.8292
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 71.0122
                       Mean reward: 466.67
               Mean episode length: 243.24
    Episode_Reward/reaching_object: 1.3488
    Episode_Reward/rotating_object: 88.6807
        Episode_Reward/action_rate: -0.0911
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 2.01s
                      Time elapsed: 00:34:14
                               ETA: 00:17:53

################################################################################
                     [1m Learning iteration 986/1500 [0m                      

                       Computation: 48967 steps/s (collection: 1.897s, learning 0.111s)
             Mean action noise std: 3.87
          Mean value_function loss: 76.8096
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 71.0344
                       Mean reward: 455.94
               Mean episode length: 233.66
    Episode_Reward/reaching_object: 1.3361
    Episode_Reward/rotating_object: 93.2427
        Episode_Reward/action_rate: -0.0902
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 2.01s
                      Time elapsed: 00:34:16
                               ETA: 00:17:50

################################################################################
                     [1m Learning iteration 987/1500 [0m                      

                       Computation: 48598 steps/s (collection: 1.902s, learning 0.121s)
             Mean action noise std: 3.87
          Mean value_function loss: 76.4914
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 71.0569
                       Mean reward: 473.32
               Mean episode length: 238.27
    Episode_Reward/reaching_object: 1.3535
    Episode_Reward/rotating_object: 92.7899
        Episode_Reward/action_rate: -0.0908
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 2.02s
                      Time elapsed: 00:34:18
                               ETA: 00:17:48

################################################################################
                     [1m Learning iteration 988/1500 [0m                      

                       Computation: 47837 steps/s (collection: 1.944s, learning 0.111s)
             Mean action noise std: 3.87
          Mean value_function loss: 74.0269
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 71.0792
                       Mean reward: 471.39
               Mean episode length: 232.89
    Episode_Reward/reaching_object: 1.3330
    Episode_Reward/rotating_object: 92.6086
        Episode_Reward/action_rate: -0.0908
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 2.05s
                      Time elapsed: 00:34:20
                               ETA: 00:17:46

################################################################################
                     [1m Learning iteration 989/1500 [0m                      

                       Computation: 48976 steps/s (collection: 1.897s, learning 0.110s)
             Mean action noise std: 3.88
          Mean value_function loss: 76.5094
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 71.1065
                       Mean reward: 490.41
               Mean episode length: 238.73
    Episode_Reward/reaching_object: 1.3367
    Episode_Reward/rotating_object: 92.3022
        Episode_Reward/action_rate: -0.0913
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 2.01s
                      Time elapsed: 00:34:22
                               ETA: 00:17:44

################################################################################
                     [1m Learning iteration 990/1500 [0m                      

                       Computation: 48704 steps/s (collection: 1.908s, learning 0.110s)
             Mean action noise std: 3.88
          Mean value_function loss: 79.6439
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 71.1368
                       Mean reward: 451.33
               Mean episode length: 228.99
    Episode_Reward/reaching_object: 1.3155
    Episode_Reward/rotating_object: 89.7882
        Episode_Reward/action_rate: -0.0906
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 2.02s
                      Time elapsed: 00:34:24
                               ETA: 00:17:42

################################################################################
                     [1m Learning iteration 991/1500 [0m                      

                       Computation: 48627 steps/s (collection: 1.908s, learning 0.114s)
             Mean action noise std: 3.89
          Mean value_function loss: 80.5656
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 71.1707
                       Mean reward: 421.72
               Mean episode length: 221.81
    Episode_Reward/reaching_object: 1.2905
    Episode_Reward/rotating_object: 85.1222
        Episode_Reward/action_rate: -0.0902
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 2.02s
                      Time elapsed: 00:34:26
                               ETA: 00:17:40

################################################################################
                     [1m Learning iteration 992/1500 [0m                      

                       Computation: 48114 steps/s (collection: 1.932s, learning 0.111s)
             Mean action noise std: 3.89
          Mean value_function loss: 78.2418
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 71.1963
                       Mean reward: 461.16
               Mean episode length: 231.32
    Episode_Reward/reaching_object: 1.3076
    Episode_Reward/rotating_object: 90.5914
        Episode_Reward/action_rate: -0.0901
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 2.04s
                      Time elapsed: 00:34:28
                               ETA: 00:17:38

################################################################################
                     [1m Learning iteration 993/1500 [0m                      

                       Computation: 47564 steps/s (collection: 1.954s, learning 0.113s)
             Mean action noise std: 3.89
          Mean value_function loss: 74.6051
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 71.2140
                       Mean reward: 458.97
               Mean episode length: 229.51
    Episode_Reward/reaching_object: 1.3181
    Episode_Reward/rotating_object: 90.0493
        Episode_Reward/action_rate: -0.0910
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 2.07s
                      Time elapsed: 00:34:30
                               ETA: 00:17:36

################################################################################
                     [1m Learning iteration 994/1500 [0m                      

                       Computation: 47813 steps/s (collection: 1.943s, learning 0.113s)
             Mean action noise std: 3.90
          Mean value_function loss: 79.0998
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 71.2346
                       Mean reward: 416.73
               Mean episode length: 233.75
    Episode_Reward/reaching_object: 1.2957
    Episode_Reward/rotating_object: 84.8168
        Episode_Reward/action_rate: -0.0916
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 2.06s
                      Time elapsed: 00:34:32
                               ETA: 00:17:34

################################################################################
                     [1m Learning iteration 995/1500 [0m                      

                       Computation: 47660 steps/s (collection: 1.946s, learning 0.116s)
             Mean action noise std: 3.90
          Mean value_function loss: 82.1618
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 71.2594
                       Mean reward: 457.77
               Mean episode length: 231.59
    Episode_Reward/reaching_object: 1.3239
    Episode_Reward/rotating_object: 92.8116
        Episode_Reward/action_rate: -0.0920
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 2.06s
                      Time elapsed: 00:34:34
                               ETA: 00:17:31

################################################################################
                     [1m Learning iteration 996/1500 [0m                      

                       Computation: 47004 steps/s (collection: 1.979s, learning 0.113s)
             Mean action noise std: 3.90
          Mean value_function loss: 72.8845
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 71.2842
                       Mean reward: 465.91
               Mean episode length: 232.54
    Episode_Reward/reaching_object: 1.3183
    Episode_Reward/rotating_object: 91.9894
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 2.09s
                      Time elapsed: 00:34:36
                               ETA: 00:17:29

################################################################################
                     [1m Learning iteration 997/1500 [0m                      

                       Computation: 46893 steps/s (collection: 1.982s, learning 0.114s)
             Mean action noise std: 3.91
          Mean value_function loss: 76.7982
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 71.3131
                       Mean reward: 394.92
               Mean episode length: 223.30
    Episode_Reward/reaching_object: 1.3230
    Episode_Reward/rotating_object: 90.8397
        Episode_Reward/action_rate: -0.0925
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 2.10s
                      Time elapsed: 00:34:38
                               ETA: 00:17:27

################################################################################
                     [1m Learning iteration 998/1500 [0m                      

                       Computation: 46490 steps/s (collection: 2.002s, learning 0.113s)
             Mean action noise std: 3.91
          Mean value_function loss: 76.5425
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 71.3397
                       Mean reward: 467.89
               Mean episode length: 233.38
    Episode_Reward/reaching_object: 1.3025
    Episode_Reward/rotating_object: 86.8651
        Episode_Reward/action_rate: -0.0920
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 2.11s
                      Time elapsed: 00:34:41
                               ETA: 00:17:25

################################################################################
                     [1m Learning iteration 999/1500 [0m                      

                       Computation: 47133 steps/s (collection: 1.972s, learning 0.114s)
             Mean action noise std: 3.91
          Mean value_function loss: 72.3833
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 71.3613
                       Mean reward: 424.02
               Mean episode length: 228.51
    Episode_Reward/reaching_object: 1.3404
    Episode_Reward/rotating_object: 91.1393
        Episode_Reward/action_rate: -0.0942
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 2.09s
                      Time elapsed: 00:34:43
                               ETA: 00:17:23

################################################################################
                     [1m Learning iteration 1000/1500 [0m                     

                       Computation: 47654 steps/s (collection: 1.951s, learning 0.112s)
             Mean action noise std: 3.92
          Mean value_function loss: 81.2212
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 71.3744
                       Mean reward: 433.92
               Mean episode length: 230.83
    Episode_Reward/reaching_object: 1.3336
    Episode_Reward/rotating_object: 93.1140
        Episode_Reward/action_rate: -0.0926
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 2.06s
                      Time elapsed: 00:34:45
                               ETA: 00:17:21

################################################################################
                     [1m Learning iteration 1001/1500 [0m                     

                       Computation: 47209 steps/s (collection: 1.967s, learning 0.115s)
             Mean action noise std: 3.92
          Mean value_function loss: 77.6717
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 71.3956
                       Mean reward: 462.64
               Mean episode length: 235.84
    Episode_Reward/reaching_object: 1.3168
    Episode_Reward/rotating_object: 89.8755
        Episode_Reward/action_rate: -0.0922
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 2.08s
                      Time elapsed: 00:34:47
                               ETA: 00:17:19

################################################################################
                     [1m Learning iteration 1002/1500 [0m                     

                       Computation: 47096 steps/s (collection: 1.973s, learning 0.114s)
             Mean action noise std: 3.92
          Mean value_function loss: 87.4179
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 71.4171
                       Mean reward: 455.78
               Mean episode length: 233.81
    Episode_Reward/reaching_object: 1.3110
    Episode_Reward/rotating_object: 87.8772
        Episode_Reward/action_rate: -0.0924
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 2.09s
                      Time elapsed: 00:34:49
                               ETA: 00:17:17

################################################################################
                     [1m Learning iteration 1003/1500 [0m                     

                       Computation: 47181 steps/s (collection: 1.970s, learning 0.113s)
             Mean action noise std: 3.93
          Mean value_function loss: 76.4184
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 71.4329
                       Mean reward: 515.34
               Mean episode length: 241.34
    Episode_Reward/reaching_object: 1.3420
    Episode_Reward/rotating_object: 91.9533
        Episode_Reward/action_rate: -0.0931
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 2.08s
                      Time elapsed: 00:34:51
                               ETA: 00:17:15

################################################################################
                     [1m Learning iteration 1004/1500 [0m                     

                       Computation: 47880 steps/s (collection: 1.941s, learning 0.112s)
             Mean action noise std: 3.93
          Mean value_function loss: 81.4404
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 71.4543
                       Mean reward: 414.00
               Mean episode length: 231.15
    Episode_Reward/reaching_object: 1.2991
    Episode_Reward/rotating_object: 85.5975
        Episode_Reward/action_rate: -0.0922
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 2.05s
                      Time elapsed: 00:34:53
                               ETA: 00:17:13

################################################################################
                     [1m Learning iteration 1005/1500 [0m                     

                       Computation: 48001 steps/s (collection: 1.937s, learning 0.111s)
             Mean action noise std: 3.93
          Mean value_function loss: 84.3515
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 71.4721
                       Mean reward: 424.99
               Mean episode length: 235.29
    Episode_Reward/reaching_object: 1.3261
    Episode_Reward/rotating_object: 88.9888
        Episode_Reward/action_rate: -0.0927
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 2.05s
                      Time elapsed: 00:34:55
                               ETA: 00:17:11

################################################################################
                     [1m Learning iteration 1006/1500 [0m                     

                       Computation: 47854 steps/s (collection: 1.941s, learning 0.113s)
             Mean action noise std: 3.94
          Mean value_function loss: 74.7724
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 71.4913
                       Mean reward: 431.05
               Mean episode length: 230.17
    Episode_Reward/reaching_object: 1.3096
    Episode_Reward/rotating_object: 86.7997
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 2.05s
                      Time elapsed: 00:34:57
                               ETA: 00:17:09

################################################################################
                     [1m Learning iteration 1007/1500 [0m                     

                       Computation: 47757 steps/s (collection: 1.948s, learning 0.111s)
             Mean action noise std: 3.94
          Mean value_function loss: 82.0182
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 71.5034
                       Mean reward: 404.84
               Mean episode length: 222.98
    Episode_Reward/reaching_object: 1.2739
    Episode_Reward/rotating_object: 83.4108
        Episode_Reward/action_rate: -0.0897
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 2.06s
                      Time elapsed: 00:34:59
                               ETA: 00:17:06

################################################################################
                     [1m Learning iteration 1008/1500 [0m                     

                       Computation: 48465 steps/s (collection: 1.917s, learning 0.112s)
             Mean action noise std: 3.94
          Mean value_function loss: 83.2058
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 71.5272
                       Mean reward: 502.37
               Mean episode length: 232.22
    Episode_Reward/reaching_object: 1.3184
    Episode_Reward/rotating_object: 88.4049
        Episode_Reward/action_rate: -0.0918
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 2.03s
                      Time elapsed: 00:35:01
                               ETA: 00:17:04

################################################################################
                     [1m Learning iteration 1009/1500 [0m                     

                       Computation: 49217 steps/s (collection: 1.887s, learning 0.111s)
             Mean action noise std: 3.95
          Mean value_function loss: 74.6975
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 71.5518
                       Mean reward: 476.53
               Mean episode length: 240.60
    Episode_Reward/reaching_object: 1.3439
    Episode_Reward/rotating_object: 92.7058
        Episode_Reward/action_rate: -0.0938
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 2.00s
                      Time elapsed: 00:35:03
                               ETA: 00:17:02

################################################################################
                     [1m Learning iteration 1010/1500 [0m                     

                       Computation: 48724 steps/s (collection: 1.907s, learning 0.110s)
             Mean action noise std: 3.95
          Mean value_function loss: 73.3708
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 71.5781
                       Mean reward: 420.97
               Mean episode length: 241.53
    Episode_Reward/reaching_object: 1.3333
    Episode_Reward/rotating_object: 88.2181
        Episode_Reward/action_rate: -0.0946
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 2.02s
                      Time elapsed: 00:35:05
                               ETA: 00:17:00

################################################################################
                     [1m Learning iteration 1011/1500 [0m                     

                       Computation: 49297 steps/s (collection: 1.884s, learning 0.110s)
             Mean action noise std: 3.95
          Mean value_function loss: 78.3499
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 71.6032
                       Mean reward: 483.24
               Mean episode length: 243.89
    Episode_Reward/reaching_object: 1.3073
    Episode_Reward/rotating_object: 87.7761
        Episode_Reward/action_rate: -0.0937
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 1.99s
                      Time elapsed: 00:35:07
                               ETA: 00:16:58

################################################################################
                     [1m Learning iteration 1012/1500 [0m                     

                       Computation: 48796 steps/s (collection: 1.904s, learning 0.110s)
             Mean action noise std: 3.96
          Mean value_function loss: 82.9217
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 71.6250
                       Mean reward: 431.23
               Mean episode length: 226.18
    Episode_Reward/reaching_object: 1.3553
    Episode_Reward/rotating_object: 93.8218
        Episode_Reward/action_rate: -0.0953
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 2.01s
                      Time elapsed: 00:35:09
                               ETA: 00:16:56

################################################################################
                     [1m Learning iteration 1013/1500 [0m                     

                       Computation: 48757 steps/s (collection: 1.905s, learning 0.111s)
             Mean action noise std: 3.96
          Mean value_function loss: 89.8358
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 71.6439
                       Mean reward: 419.14
               Mean episode length: 219.11
    Episode_Reward/reaching_object: 1.2779
    Episode_Reward/rotating_object: 85.9102
        Episode_Reward/action_rate: -0.0907
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 2.02s
                      Time elapsed: 00:35:11
                               ETA: 00:16:54

################################################################################
                     [1m Learning iteration 1014/1500 [0m                     

                       Computation: 48147 steps/s (collection: 1.927s, learning 0.115s)
             Mean action noise std: 3.97
          Mean value_function loss: 82.2027
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 71.6667
                       Mean reward: 451.35
               Mean episode length: 233.40
    Episode_Reward/reaching_object: 1.3215
    Episode_Reward/rotating_object: 91.0902
        Episode_Reward/action_rate: -0.0935
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 2.04s
                      Time elapsed: 00:35:13
                               ETA: 00:16:52

################################################################################
                     [1m Learning iteration 1015/1500 [0m                     

                       Computation: 48483 steps/s (collection: 1.914s, learning 0.113s)
             Mean action noise std: 3.97
          Mean value_function loss: 76.5096
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 71.6911
                       Mean reward: 488.33
               Mean episode length: 230.44
    Episode_Reward/reaching_object: 1.3375
    Episode_Reward/rotating_object: 95.2571
        Episode_Reward/action_rate: -0.0947
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 2.03s
                      Time elapsed: 00:35:15
                               ETA: 00:16:50

################################################################################
                     [1m Learning iteration 1016/1500 [0m                     

                       Computation: 47889 steps/s (collection: 1.940s, learning 0.113s)
             Mean action noise std: 3.97
          Mean value_function loss: 77.6407
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 71.7104
                       Mean reward: 444.11
               Mean episode length: 230.61
    Episode_Reward/reaching_object: 1.2919
    Episode_Reward/rotating_object: 85.7625
        Episode_Reward/action_rate: -0.0921
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 2.05s
                      Time elapsed: 00:35:17
                               ETA: 00:16:47

################################################################################
                     [1m Learning iteration 1017/1500 [0m                     

                       Computation: 47933 steps/s (collection: 1.937s, learning 0.114s)
             Mean action noise std: 3.98
          Mean value_function loss: 72.7488
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 71.7324
                       Mean reward: 459.27
               Mean episode length: 234.59
    Episode_Reward/reaching_object: 1.3089
    Episode_Reward/rotating_object: 90.0538
        Episode_Reward/action_rate: -0.0938
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 2.05s
                      Time elapsed: 00:35:19
                               ETA: 00:16:45

################################################################################
                     [1m Learning iteration 1018/1500 [0m                     

                       Computation: 47778 steps/s (collection: 1.947s, learning 0.110s)
             Mean action noise std: 3.98
          Mean value_function loss: 65.4890
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 71.7625
                       Mean reward: 467.26
               Mean episode length: 236.00
    Episode_Reward/reaching_object: 1.3213
    Episode_Reward/rotating_object: 90.2927
        Episode_Reward/action_rate: -0.0967
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 2.06s
                      Time elapsed: 00:35:21
                               ETA: 00:16:43

################################################################################
                     [1m Learning iteration 1019/1500 [0m                     

                       Computation: 48176 steps/s (collection: 1.929s, learning 0.112s)
             Mean action noise std: 3.98
          Mean value_function loss: 84.4238
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 71.7877
                       Mean reward: 459.93
               Mean episode length: 226.92
    Episode_Reward/reaching_object: 1.3279
    Episode_Reward/rotating_object: 91.7332
        Episode_Reward/action_rate: -0.0957
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 2.04s
                      Time elapsed: 00:35:24
                               ETA: 00:16:41

################################################################################
                     [1m Learning iteration 1020/1500 [0m                     

                       Computation: 48285 steps/s (collection: 1.923s, learning 0.113s)
             Mean action noise std: 3.99
          Mean value_function loss: 78.5274
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 71.8115
                       Mean reward: 437.07
               Mean episode length: 238.49
    Episode_Reward/reaching_object: 1.3205
    Episode_Reward/rotating_object: 88.9536
        Episode_Reward/action_rate: -0.0946
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 2.04s
                      Time elapsed: 00:35:26
                               ETA: 00:16:39

################################################################################
                     [1m Learning iteration 1021/1500 [0m                     

                       Computation: 47965 steps/s (collection: 1.939s, learning 0.111s)
             Mean action noise std: 3.99
          Mean value_function loss: 91.6590
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 71.8386
                       Mean reward: 468.80
               Mean episode length: 228.12
    Episode_Reward/reaching_object: 1.3142
    Episode_Reward/rotating_object: 92.8735
        Episode_Reward/action_rate: -0.0940
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 2.05s
                      Time elapsed: 00:35:28
                               ETA: 00:16:37

################################################################################
                     [1m Learning iteration 1022/1500 [0m                     

                       Computation: 47177 steps/s (collection: 1.971s, learning 0.113s)
             Mean action noise std: 4.00
          Mean value_function loss: 76.1168
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 71.8593
                       Mean reward: 446.85
               Mean episode length: 234.31
    Episode_Reward/reaching_object: 1.3252
    Episode_Reward/rotating_object: 90.8226
        Episode_Reward/action_rate: -0.0956
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 2.08s
                      Time elapsed: 00:35:30
                               ETA: 00:16:35

################################################################################
                     [1m Learning iteration 1023/1500 [0m                     

                       Computation: 48052 steps/s (collection: 1.933s, learning 0.113s)
             Mean action noise std: 4.00
          Mean value_function loss: 79.6356
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 71.8775
                       Mean reward: 476.89
               Mean episode length: 226.07
    Episode_Reward/reaching_object: 1.2974
    Episode_Reward/rotating_object: 88.6347
        Episode_Reward/action_rate: -0.0936
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 2.05s
                      Time elapsed: 00:35:32
                               ETA: 00:16:33

################################################################################
                     [1m Learning iteration 1024/1500 [0m                     

                       Computation: 47950 steps/s (collection: 1.939s, learning 0.111s)
             Mean action noise std: 4.00
          Mean value_function loss: 86.0172
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 71.8997
                       Mean reward: 452.18
               Mean episode length: 227.70
    Episode_Reward/reaching_object: 1.2974
    Episode_Reward/rotating_object: 88.8506
        Episode_Reward/action_rate: -0.0940
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 2.05s
                      Time elapsed: 00:35:34
                               ETA: 00:16:31

################################################################################
                     [1m Learning iteration 1025/1500 [0m                     

                       Computation: 47238 steps/s (collection: 1.970s, learning 0.111s)
             Mean action noise std: 4.01
          Mean value_function loss: 84.4122
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 71.9199
                       Mean reward: 478.67
               Mean episode length: 239.34
    Episode_Reward/reaching_object: 1.3110
    Episode_Reward/rotating_object: 90.6990
        Episode_Reward/action_rate: -0.0945
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 2.08s
                      Time elapsed: 00:35:36
                               ETA: 00:16:29

################################################################################
                     [1m Learning iteration 1026/1500 [0m                     

                       Computation: 47472 steps/s (collection: 1.960s, learning 0.110s)
             Mean action noise std: 4.01
          Mean value_function loss: 82.0427
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 71.9434
                       Mean reward: 496.27
               Mean episode length: 239.67
    Episode_Reward/reaching_object: 1.3250
    Episode_Reward/rotating_object: 92.0303
        Episode_Reward/action_rate: -0.0954
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 2.07s
                      Time elapsed: 00:35:38
                               ETA: 00:16:26

################################################################################
                     [1m Learning iteration 1027/1500 [0m                     

                       Computation: 46672 steps/s (collection: 1.993s, learning 0.113s)
             Mean action noise std: 4.02
          Mean value_function loss: 80.8062
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 71.9751
                       Mean reward: 472.76
               Mean episode length: 224.92
    Episode_Reward/reaching_object: 1.3262
    Episode_Reward/rotating_object: 88.9621
        Episode_Reward/action_rate: -0.0953
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 2.11s
                      Time elapsed: 00:35:40
                               ETA: 00:16:24

################################################################################
                     [1m Learning iteration 1028/1500 [0m                     

                       Computation: 47613 steps/s (collection: 1.949s, learning 0.116s)
             Mean action noise std: 4.02
          Mean value_function loss: 80.0521
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 72.0045
                       Mean reward: 439.80
               Mean episode length: 220.90
    Episode_Reward/reaching_object: 1.3113
    Episode_Reward/rotating_object: 88.2339
        Episode_Reward/action_rate: -0.0944
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 2.06s
                      Time elapsed: 00:35:42
                               ETA: 00:16:22

################################################################################
                     [1m Learning iteration 1029/1500 [0m                     

                       Computation: 48005 steps/s (collection: 1.936s, learning 0.112s)
             Mean action noise std: 4.02
          Mean value_function loss: 82.4803
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 72.0265
                       Mean reward: 485.91
               Mean episode length: 233.76
    Episode_Reward/reaching_object: 1.3574
    Episode_Reward/rotating_object: 94.1788
        Episode_Reward/action_rate: -0.0971
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 2.05s
                      Time elapsed: 00:35:44
                               ETA: 00:16:20

################################################################################
                     [1m Learning iteration 1030/1500 [0m                     

                       Computation: 48677 steps/s (collection: 1.909s, learning 0.111s)
             Mean action noise std: 4.03
          Mean value_function loss: 88.4793
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 72.0475
                       Mean reward: 501.38
               Mean episode length: 238.81
    Episode_Reward/reaching_object: 1.3665
    Episode_Reward/rotating_object: 94.4922
        Episode_Reward/action_rate: -0.0978
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 2.02s
                      Time elapsed: 00:35:46
                               ETA: 00:16:18

################################################################################
                     [1m Learning iteration 1031/1500 [0m                     

                       Computation: 48137 steps/s (collection: 1.932s, learning 0.111s)
             Mean action noise std: 4.03
          Mean value_function loss: 87.4623
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 72.0664
                       Mean reward: 463.55
               Mean episode length: 233.24
    Episode_Reward/reaching_object: 1.3265
    Episode_Reward/rotating_object: 92.1701
        Episode_Reward/action_rate: -0.0957
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 2.04s
                      Time elapsed: 00:35:48
                               ETA: 00:16:16

################################################################################
                     [1m Learning iteration 1032/1500 [0m                     

                       Computation: 48751 steps/s (collection: 1.906s, learning 0.110s)
             Mean action noise std: 4.03
          Mean value_function loss: 77.0918
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 72.0793
                       Mean reward: 457.81
               Mean episode length: 235.24
    Episode_Reward/reaching_object: 1.3215
    Episode_Reward/rotating_object: 90.7966
        Episode_Reward/action_rate: -0.0966
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 2.02s
                      Time elapsed: 00:35:50
                               ETA: 00:16:14

################################################################################
                     [1m Learning iteration 1033/1500 [0m                     

                       Computation: 48925 steps/s (collection: 1.899s, learning 0.111s)
             Mean action noise std: 4.03
          Mean value_function loss: 77.1954
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 72.0923
                       Mean reward: 471.08
               Mean episode length: 225.59
    Episode_Reward/reaching_object: 1.3256
    Episode_Reward/rotating_object: 94.5067
        Episode_Reward/action_rate: -0.0967
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 2.01s
                      Time elapsed: 00:35:52
                               ETA: 00:16:12

################################################################################
                     [1m Learning iteration 1034/1500 [0m                     

                       Computation: 48892 steps/s (collection: 1.900s, learning 0.111s)
             Mean action noise std: 4.04
          Mean value_function loss: 87.5288
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 72.1107
                       Mean reward: 413.67
               Mean episode length: 222.04
    Episode_Reward/reaching_object: 1.2921
    Episode_Reward/rotating_object: 88.2386
        Episode_Reward/action_rate: -0.0959
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 2.01s
                      Time elapsed: 00:35:54
                               ETA: 00:16:10

################################################################################
                     [1m Learning iteration 1035/1500 [0m                     

                       Computation: 48152 steps/s (collection: 1.927s, learning 0.114s)
             Mean action noise std: 4.04
          Mean value_function loss: 80.3780
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 72.1377
                       Mean reward: 417.44
               Mean episode length: 228.29
    Episode_Reward/reaching_object: 1.3174
    Episode_Reward/rotating_object: 90.2188
        Episode_Reward/action_rate: -0.0960
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 2.04s
                      Time elapsed: 00:35:56
                               ETA: 00:16:08

################################################################################
                     [1m Learning iteration 1036/1500 [0m                     

                       Computation: 48787 steps/s (collection: 1.905s, learning 0.110s)
             Mean action noise std: 4.04
          Mean value_function loss: 89.0239
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 72.1574
                       Mean reward: 437.92
               Mean episode length: 228.49
    Episode_Reward/reaching_object: 1.3338
    Episode_Reward/rotating_object: 92.0255
        Episode_Reward/action_rate: -0.0981
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 2.01s
                      Time elapsed: 00:35:58
                               ETA: 00:16:05

################################################################################
                     [1m Learning iteration 1037/1500 [0m                     

                       Computation: 48561 steps/s (collection: 1.910s, learning 0.114s)
             Mean action noise std: 4.05
          Mean value_function loss: 77.5174
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 72.1739
                       Mean reward: 437.85
               Mean episode length: 223.82
    Episode_Reward/reaching_object: 1.2994
    Episode_Reward/rotating_object: 91.0140
        Episode_Reward/action_rate: -0.0959
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 2.02s
                      Time elapsed: 00:36:00
                               ETA: 00:16:03

################################################################################
                     [1m Learning iteration 1038/1500 [0m                     

                       Computation: 48768 steps/s (collection: 1.905s, learning 0.110s)
             Mean action noise std: 4.05
          Mean value_function loss: 80.6738
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 72.1978
                       Mean reward: 430.61
               Mean episode length: 225.83
    Episode_Reward/reaching_object: 1.3286
    Episode_Reward/rotating_object: 92.3040
        Episode_Reward/action_rate: -0.0975
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 2.02s
                      Time elapsed: 00:36:02
                               ETA: 00:16:01

################################################################################
                     [1m Learning iteration 1039/1500 [0m                     

                       Computation: 48114 steps/s (collection: 1.921s, learning 0.122s)
             Mean action noise std: 4.06
          Mean value_function loss: 88.1104
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 72.2202
                       Mean reward: 452.12
               Mean episode length: 227.36
    Episode_Reward/reaching_object: 1.3255
    Episode_Reward/rotating_object: 90.3734
        Episode_Reward/action_rate: -0.0979
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 2.04s
                      Time elapsed: 00:36:04
                               ETA: 00:15:59

################################################################################
                     [1m Learning iteration 1040/1500 [0m                     

                       Computation: 47787 steps/s (collection: 1.929s, learning 0.128s)
             Mean action noise std: 4.06
          Mean value_function loss: 83.7922
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 72.2410
                       Mean reward: 447.76
               Mean episode length: 236.32
    Episode_Reward/reaching_object: 1.3101
    Episode_Reward/rotating_object: 91.2085
        Episode_Reward/action_rate: -0.0967
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 2.06s
                      Time elapsed: 00:36:06
                               ETA: 00:15:57

################################################################################
                     [1m Learning iteration 1041/1500 [0m                     

                       Computation: 48004 steps/s (collection: 1.925s, learning 0.123s)
             Mean action noise std: 4.06
          Mean value_function loss: 80.9399
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 72.2605
                       Mean reward: 426.31
               Mean episode length: 226.43
    Episode_Reward/reaching_object: 1.3119
    Episode_Reward/rotating_object: 89.0119
        Episode_Reward/action_rate: -0.0979
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 2.05s
                      Time elapsed: 00:36:09
                               ETA: 00:15:55

################################################################################
                     [1m Learning iteration 1042/1500 [0m                     

                       Computation: 47779 steps/s (collection: 1.927s, learning 0.130s)
             Mean action noise std: 4.07
          Mean value_function loss: 75.3044
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 72.2887
                       Mean reward: 461.51
               Mean episode length: 231.94
    Episode_Reward/reaching_object: 1.3501
    Episode_Reward/rotating_object: 95.2907
        Episode_Reward/action_rate: -0.0996
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 2.06s
                      Time elapsed: 00:36:11
                               ETA: 00:15:53

################################################################################
                     [1m Learning iteration 1043/1500 [0m                     

                       Computation: 48218 steps/s (collection: 1.921s, learning 0.118s)
             Mean action noise std: 4.07
          Mean value_function loss: 74.6836
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 72.3103
                       Mean reward: 466.46
               Mean episode length: 226.73
    Episode_Reward/reaching_object: 1.3377
    Episode_Reward/rotating_object: 93.7943
        Episode_Reward/action_rate: -0.0996
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 2.04s
                      Time elapsed: 00:36:13
                               ETA: 00:15:51

################################################################################
                     [1m Learning iteration 1044/1500 [0m                     

                       Computation: 48449 steps/s (collection: 1.916s, learning 0.113s)
             Mean action noise std: 4.07
          Mean value_function loss: 79.1110
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 72.3329
                       Mean reward: 543.37
               Mean episode length: 240.98
    Episode_Reward/reaching_object: 1.3262
    Episode_Reward/rotating_object: 93.1669
        Episode_Reward/action_rate: -0.0987
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 2.03s
                      Time elapsed: 00:36:15
                               ETA: 00:15:49

################################################################################
                     [1m Learning iteration 1045/1500 [0m                     

                       Computation: 47947 steps/s (collection: 1.938s, learning 0.112s)
             Mean action noise std: 4.08
          Mean value_function loss: 81.7771
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 72.3541
                       Mean reward: 499.29
               Mean episode length: 237.15
    Episode_Reward/reaching_object: 1.3303
    Episode_Reward/rotating_object: 92.0827
        Episode_Reward/action_rate: -0.0997
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 2.05s
                      Time elapsed: 00:36:17
                               ETA: 00:15:47

################################################################################
                     [1m Learning iteration 1046/1500 [0m                     

                       Computation: 44065 steps/s (collection: 2.106s, learning 0.125s)
             Mean action noise std: 4.08
          Mean value_function loss: 79.6015
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 72.3727
                       Mean reward: 464.85
               Mean episode length: 227.56
    Episode_Reward/reaching_object: 1.2905
    Episode_Reward/rotating_object: 89.8470
        Episode_Reward/action_rate: -0.0978
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 2.23s
                      Time elapsed: 00:36:19
                               ETA: 00:15:45

################################################################################
                     [1m Learning iteration 1047/1500 [0m                     

                       Computation: 44055 steps/s (collection: 2.105s, learning 0.126s)
             Mean action noise std: 4.09
          Mean value_function loss: 76.0636
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 72.3936
                       Mean reward: 459.07
               Mean episode length: 234.56
    Episode_Reward/reaching_object: 1.3265
    Episode_Reward/rotating_object: 89.6116
        Episode_Reward/action_rate: -0.1006
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 2.23s
                      Time elapsed: 00:36:21
                               ETA: 00:15:43

################################################################################
                     [1m Learning iteration 1048/1500 [0m                     

                       Computation: 45215 steps/s (collection: 2.063s, learning 0.111s)
             Mean action noise std: 4.09
          Mean value_function loss: 74.3941
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 72.4188
                       Mean reward: 484.17
               Mean episode length: 230.25
    Episode_Reward/reaching_object: 1.3175
    Episode_Reward/rotating_object: 93.0895
        Episode_Reward/action_rate: -0.0993
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 2.17s
                      Time elapsed: 00:36:23
                               ETA: 00:15:40

################################################################################
                     [1m Learning iteration 1049/1500 [0m                     

                       Computation: 48560 steps/s (collection: 1.914s, learning 0.111s)
             Mean action noise std: 4.09
          Mean value_function loss: 83.6979
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 72.4455
                       Mean reward: 481.72
               Mean episode length: 232.14
    Episode_Reward/reaching_object: 1.3209
    Episode_Reward/rotating_object: 92.5897
        Episode_Reward/action_rate: -0.0998
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 2.02s
                      Time elapsed: 00:36:25
                               ETA: 00:15:38

################################################################################
                     [1m Learning iteration 1050/1500 [0m                     

                       Computation: 47639 steps/s (collection: 1.939s, learning 0.125s)
             Mean action noise std: 4.10
          Mean value_function loss: 81.1022
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 72.4702
                       Mean reward: 488.83
               Mean episode length: 231.87
    Episode_Reward/reaching_object: 1.3357
    Episode_Reward/rotating_object: 94.3838
        Episode_Reward/action_rate: -0.1000
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 2.06s
                      Time elapsed: 00:36:27
                               ETA: 00:15:36

################################################################################
                     [1m Learning iteration 1051/1500 [0m                     

                       Computation: 48028 steps/s (collection: 1.936s, learning 0.111s)
             Mean action noise std: 4.10
          Mean value_function loss: 76.2659
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 72.4775
                       Mean reward: 447.89
               Mean episode length: 228.81
    Episode_Reward/reaching_object: 1.2993
    Episode_Reward/rotating_object: 90.9210
        Episode_Reward/action_rate: -0.0977
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 2.05s
                      Time elapsed: 00:36:29
                               ETA: 00:15:34

################################################################################
                     [1m Learning iteration 1052/1500 [0m                     

                       Computation: 47303 steps/s (collection: 1.967s, learning 0.111s)
             Mean action noise std: 4.10
          Mean value_function loss: 77.9149
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 72.4903
                       Mean reward: 453.48
               Mean episode length: 240.25
    Episode_Reward/reaching_object: 1.3381
    Episode_Reward/rotating_object: 91.3496
        Episode_Reward/action_rate: -0.1008
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 2.08s
                      Time elapsed: 00:36:32
                               ETA: 00:15:32

################################################################################
                     [1m Learning iteration 1053/1500 [0m                     

                       Computation: 47412 steps/s (collection: 1.960s, learning 0.113s)
             Mean action noise std: 4.10
          Mean value_function loss: 85.7474
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 72.5048
                       Mean reward: 441.83
               Mean episode length: 227.36
    Episode_Reward/reaching_object: 1.3160
    Episode_Reward/rotating_object: 89.6140
        Episode_Reward/action_rate: -0.0984
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 2.07s
                      Time elapsed: 00:36:34
                               ETA: 00:15:30

################################################################################
                     [1m Learning iteration 1054/1500 [0m                     

                       Computation: 47774 steps/s (collection: 1.946s, learning 0.112s)
             Mean action noise std: 4.11
          Mean value_function loss: 78.7346
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 72.5182
                       Mean reward: 487.45
               Mean episode length: 229.67
    Episode_Reward/reaching_object: 1.3163
    Episode_Reward/rotating_object: 91.4040
        Episode_Reward/action_rate: -0.0996
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 2.06s
                      Time elapsed: 00:36:36
                               ETA: 00:15:28

################################################################################
                     [1m Learning iteration 1055/1500 [0m                     

                       Computation: 48104 steps/s (collection: 1.933s, learning 0.110s)
             Mean action noise std: 4.11
          Mean value_function loss: 78.3814
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 72.5312
                       Mean reward: 479.97
               Mean episode length: 230.25
    Episode_Reward/reaching_object: 1.3121
    Episode_Reward/rotating_object: 91.9511
        Episode_Reward/action_rate: -0.0986
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 2.04s
                      Time elapsed: 00:36:38
                               ETA: 00:15:26

################################################################################
                     [1m Learning iteration 1056/1500 [0m                     

                       Computation: 49033 steps/s (collection: 1.894s, learning 0.111s)
             Mean action noise std: 4.11
          Mean value_function loss: 82.2281
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 72.5466
                       Mean reward: 490.92
               Mean episode length: 229.54
    Episode_Reward/reaching_object: 1.3376
    Episode_Reward/rotating_object: 90.9234
        Episode_Reward/action_rate: -0.1004
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 2.00s
                      Time elapsed: 00:36:40
                               ETA: 00:15:24

################################################################################
                     [1m Learning iteration 1057/1500 [0m                     

                       Computation: 48712 steps/s (collection: 1.907s, learning 0.111s)
             Mean action noise std: 4.12
          Mean value_function loss: 86.9242
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 72.5658
                       Mean reward: 442.40
               Mean episode length: 221.02
    Episode_Reward/reaching_object: 1.3049
    Episode_Reward/rotating_object: 87.4447
        Episode_Reward/action_rate: -0.0987
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 2.02s
                      Time elapsed: 00:36:42
                               ETA: 00:15:22

################################################################################
                     [1m Learning iteration 1058/1500 [0m                     

                       Computation: 48679 steps/s (collection: 1.908s, learning 0.111s)
             Mean action noise std: 4.12
          Mean value_function loss: 80.3143
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 72.5901
                       Mean reward: 439.61
               Mean episode length: 231.85
    Episode_Reward/reaching_object: 1.3125
    Episode_Reward/rotating_object: 89.8003
        Episode_Reward/action_rate: -0.0990
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 2.02s
                      Time elapsed: 00:36:44
                               ETA: 00:15:20

################################################################################
                     [1m Learning iteration 1059/1500 [0m                     

                       Computation: 48451 steps/s (collection: 1.913s, learning 0.116s)
             Mean action noise std: 4.13
          Mean value_function loss: 71.1365
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 72.6210
                       Mean reward: 433.13
               Mean episode length: 230.67
    Episode_Reward/reaching_object: 1.3111
    Episode_Reward/rotating_object: 88.6092
        Episode_Reward/action_rate: -0.0994
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 2.03s
                      Time elapsed: 00:36:46
                               ETA: 00:15:17

################################################################################
                     [1m Learning iteration 1060/1500 [0m                     

                       Computation: 47960 steps/s (collection: 1.939s, learning 0.111s)
             Mean action noise std: 4.13
          Mean value_function loss: 82.0449
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 72.6515
                       Mean reward: 486.85
               Mean episode length: 234.37
    Episode_Reward/reaching_object: 1.3480
    Episode_Reward/rotating_object: 95.3031
        Episode_Reward/action_rate: -0.1019
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 2.05s
                      Time elapsed: 00:36:48
                               ETA: 00:15:15

################################################################################
                     [1m Learning iteration 1061/1500 [0m                     

                       Computation: 49004 steps/s (collection: 1.895s, learning 0.111s)
             Mean action noise std: 4.13
          Mean value_function loss: 75.0926
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 72.6703
                       Mean reward: 500.45
               Mean episode length: 235.03
    Episode_Reward/reaching_object: 1.3294
    Episode_Reward/rotating_object: 95.9229
        Episode_Reward/action_rate: -0.1000
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 2.01s
                      Time elapsed: 00:36:50
                               ETA: 00:15:13

################################################################################
                     [1m Learning iteration 1062/1500 [0m                     

                       Computation: 48336 steps/s (collection: 1.921s, learning 0.113s)
             Mean action noise std: 4.13
          Mean value_function loss: 73.8564
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 72.6786
                       Mean reward: 482.91
               Mean episode length: 237.48
    Episode_Reward/reaching_object: 1.3550
    Episode_Reward/rotating_object: 97.1211
        Episode_Reward/action_rate: -0.1024
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 2.03s
                      Time elapsed: 00:36:52
                               ETA: 00:15:11

################################################################################
                     [1m Learning iteration 1063/1500 [0m                     

                       Computation: 47406 steps/s (collection: 1.960s, learning 0.114s)
             Mean action noise std: 4.14
          Mean value_function loss: 82.3797
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 72.6947
                       Mean reward: 460.59
               Mean episode length: 225.60
    Episode_Reward/reaching_object: 1.3484
    Episode_Reward/rotating_object: 94.2375
        Episode_Reward/action_rate: -0.1014
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 2.07s
                      Time elapsed: 00:36:54
                               ETA: 00:15:09

################################################################################
                     [1m Learning iteration 1064/1500 [0m                     

                       Computation: 47920 steps/s (collection: 1.941s, learning 0.111s)
             Mean action noise std: 4.14
          Mean value_function loss: 89.5607
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 72.7233
                       Mean reward: 453.62
               Mean episode length: 235.67
    Episode_Reward/reaching_object: 1.3345
    Episode_Reward/rotating_object: 92.0411
        Episode_Reward/action_rate: -0.1003
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 2.05s
                      Time elapsed: 00:36:56
                               ETA: 00:15:07

################################################################################
                     [1m Learning iteration 1065/1500 [0m                     

                       Computation: 48219 steps/s (collection: 1.928s, learning 0.111s)
             Mean action noise std: 4.15
          Mean value_function loss: 82.7160
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 72.7502
                       Mean reward: 529.90
               Mean episode length: 241.60
    Episode_Reward/reaching_object: 1.3790
    Episode_Reward/rotating_object: 98.3101
        Episode_Reward/action_rate: -0.1032
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 2.04s
                      Time elapsed: 00:36:58
                               ETA: 00:15:05

################################################################################
                     [1m Learning iteration 1066/1500 [0m                     

                       Computation: 47744 steps/s (collection: 1.943s, learning 0.116s)
             Mean action noise std: 4.15
          Mean value_function loss: 78.8767
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 72.7646
                       Mean reward: 443.07
               Mean episode length: 223.75
    Episode_Reward/reaching_object: 1.3503
    Episode_Reward/rotating_object: 91.2733
        Episode_Reward/action_rate: -0.1021
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 2.06s
                      Time elapsed: 00:37:00
                               ETA: 00:15:03

################################################################################
                     [1m Learning iteration 1067/1500 [0m                     

                       Computation: 48217 steps/s (collection: 1.925s, learning 0.113s)
             Mean action noise std: 4.15
          Mean value_function loss: 83.2869
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 72.7832
                       Mean reward: 467.28
               Mean episode length: 239.33
    Episode_Reward/reaching_object: 1.3865
    Episode_Reward/rotating_object: 94.0823
        Episode_Reward/action_rate: -0.1043
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 2.04s
                      Time elapsed: 00:37:02
                               ETA: 00:15:01

################################################################################
                     [1m Learning iteration 1068/1500 [0m                     

                       Computation: 47610 steps/s (collection: 1.927s, learning 0.137s)
             Mean action noise std: 4.16
          Mean value_function loss: 84.2154
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 72.8059
                       Mean reward: 466.22
               Mean episode length: 231.72
    Episode_Reward/reaching_object: 1.3618
    Episode_Reward/rotating_object: 93.7875
        Episode_Reward/action_rate: -0.1024
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 2.06s
                      Time elapsed: 00:37:04
                               ETA: 00:14:59

################################################################################
                     [1m Learning iteration 1069/1500 [0m                     

                       Computation: 47695 steps/s (collection: 1.945s, learning 0.116s)
             Mean action noise std: 4.16
          Mean value_function loss: 88.3095
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 72.8202
                       Mean reward: 496.66
               Mean episode length: 231.41
    Episode_Reward/reaching_object: 1.3348
    Episode_Reward/rotating_object: 91.4868
        Episode_Reward/action_rate: -0.1007
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 2.06s
                      Time elapsed: 00:37:06
                               ETA: 00:14:56

################################################################################
                     [1m Learning iteration 1070/1500 [0m                     

                       Computation: 48245 steps/s (collection: 1.922s, learning 0.116s)
             Mean action noise std: 4.16
          Mean value_function loss: 77.1630
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 72.8316
                       Mean reward: 463.13
               Mean episode length: 232.80
    Episode_Reward/reaching_object: 1.3455
    Episode_Reward/rotating_object: 93.2670
        Episode_Reward/action_rate: -0.1017
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 2.04s
                      Time elapsed: 00:37:08
                               ETA: 00:14:54

################################################################################
                     [1m Learning iteration 1071/1500 [0m                     

                       Computation: 48292 steps/s (collection: 1.925s, learning 0.110s)
             Mean action noise std: 4.16
          Mean value_function loss: 68.0320
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 72.8476
                       Mean reward: 485.39
               Mean episode length: 233.94
    Episode_Reward/reaching_object: 1.3652
    Episode_Reward/rotating_object: 95.2565
        Episode_Reward/action_rate: -0.1031
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 2.04s
                      Time elapsed: 00:37:10
                               ETA: 00:14:52

################################################################################
                     [1m Learning iteration 1072/1500 [0m                     

                       Computation: 48691 steps/s (collection: 1.906s, learning 0.112s)
             Mean action noise std: 4.17
          Mean value_function loss: 75.2204
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 72.8699
                       Mean reward: 460.07
               Mean episode length: 229.19
    Episode_Reward/reaching_object: 1.3495
    Episode_Reward/rotating_object: 95.3613
        Episode_Reward/action_rate: -0.1020
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 2.02s
                      Time elapsed: 00:37:12
                               ETA: 00:14:50

################################################################################
                     [1m Learning iteration 1073/1500 [0m                     

                       Computation: 48488 steps/s (collection: 1.915s, learning 0.113s)
             Mean action noise std: 4.17
          Mean value_function loss: 78.0516
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 72.8911
                       Mean reward: 539.98
               Mean episode length: 238.02
    Episode_Reward/reaching_object: 1.3966
    Episode_Reward/rotating_object: 100.3894
        Episode_Reward/action_rate: -0.1054
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 2.03s
                      Time elapsed: 00:37:14
                               ETA: 00:14:48

################################################################################
                     [1m Learning iteration 1074/1500 [0m                     

                       Computation: 47295 steps/s (collection: 1.952s, learning 0.126s)
             Mean action noise std: 4.18
          Mean value_function loss: 70.3752
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 72.9126
                       Mean reward: 473.79
               Mean episode length: 236.23
    Episode_Reward/reaching_object: 1.3837
    Episode_Reward/rotating_object: 99.5023
        Episode_Reward/action_rate: -0.1053
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 2.08s
                      Time elapsed: 00:37:16
                               ETA: 00:14:46

################################################################################
                     [1m Learning iteration 1075/1500 [0m                     

                       Computation: 48384 steps/s (collection: 1.921s, learning 0.110s)
             Mean action noise std: 4.18
          Mean value_function loss: 74.2845
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 72.9366
                       Mean reward: 463.59
               Mean episode length: 237.94
    Episode_Reward/reaching_object: 1.3685
    Episode_Reward/rotating_object: 90.9484
        Episode_Reward/action_rate: -0.1061
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 2.03s
                      Time elapsed: 00:37:18
                               ETA: 00:14:44

################################################################################
                     [1m Learning iteration 1076/1500 [0m                     

                       Computation: 48535 steps/s (collection: 1.911s, learning 0.114s)
             Mean action noise std: 4.18
          Mean value_function loss: 77.0152
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 72.9587
                       Mean reward: 520.12
               Mean episode length: 238.67
    Episode_Reward/reaching_object: 1.3325
    Episode_Reward/rotating_object: 93.7629
        Episode_Reward/action_rate: -0.1032
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 2.03s
                      Time elapsed: 00:37:21
                               ETA: 00:14:42

################################################################################
                     [1m Learning iteration 1077/1500 [0m                     

                       Computation: 47990 steps/s (collection: 1.934s, learning 0.114s)
             Mean action noise std: 4.18
          Mean value_function loss: 76.6069
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 72.9738
                       Mean reward: 491.79
               Mean episode length: 229.48
    Episode_Reward/reaching_object: 1.3196
    Episode_Reward/rotating_object: 90.7745
        Episode_Reward/action_rate: -0.1024
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 2.05s
                      Time elapsed: 00:37:23
                               ETA: 00:14:40

################################################################################
                     [1m Learning iteration 1078/1500 [0m                     

                       Computation: 48311 steps/s (collection: 1.923s, learning 0.112s)
             Mean action noise std: 4.19
          Mean value_function loss: 79.2652
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 72.9819
                       Mean reward: 472.41
               Mean episode length: 230.06
    Episode_Reward/reaching_object: 1.3268
    Episode_Reward/rotating_object: 93.9297
        Episode_Reward/action_rate: -0.1035
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 2.03s
                      Time elapsed: 00:37:25
                               ETA: 00:14:38

################################################################################
                     [1m Learning iteration 1079/1500 [0m                     

                       Computation: 47640 steps/s (collection: 1.953s, learning 0.110s)
             Mean action noise std: 4.19
          Mean value_function loss: 72.9630
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 72.9990
                       Mean reward: 473.22
               Mean episode length: 232.85
    Episode_Reward/reaching_object: 1.3420
    Episode_Reward/rotating_object: 93.2756
        Episode_Reward/action_rate: -0.1043
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 2.06s
                      Time elapsed: 00:37:27
                               ETA: 00:14:35

################################################################################
                     [1m Learning iteration 1080/1500 [0m                     

                       Computation: 49455 steps/s (collection: 1.878s, learning 0.110s)
             Mean action noise std: 4.20
          Mean value_function loss: 74.1799
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 73.0260
                       Mean reward: 464.08
               Mean episode length: 228.87
    Episode_Reward/reaching_object: 1.3312
    Episode_Reward/rotating_object: 91.1367
        Episode_Reward/action_rate: -0.1042
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 1.99s
                      Time elapsed: 00:37:29
                               ETA: 00:14:33

################################################################################
                     [1m Learning iteration 1081/1500 [0m                     

                       Computation: 49514 steps/s (collection: 1.875s, learning 0.110s)
             Mean action noise std: 4.20
          Mean value_function loss: 74.1485
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 73.0433
                       Mean reward: 553.19
               Mean episode length: 245.09
    Episode_Reward/reaching_object: 1.3758
    Episode_Reward/rotating_object: 99.4245
        Episode_Reward/action_rate: -0.1068
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 1.99s
                      Time elapsed: 00:37:31
                               ETA: 00:14:31

################################################################################
                     [1m Learning iteration 1082/1500 [0m                     

                       Computation: 49540 steps/s (collection: 1.874s, learning 0.110s)
             Mean action noise std: 4.20
          Mean value_function loss: 81.8963
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 73.0582
                       Mean reward: 448.37
               Mean episode length: 227.68
    Episode_Reward/reaching_object: 1.3332
    Episode_Reward/rotating_object: 92.4684
        Episode_Reward/action_rate: -0.1046
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 1.98s
                      Time elapsed: 00:37:33
                               ETA: 00:14:29

################################################################################
                     [1m Learning iteration 1083/1500 [0m                     

                       Computation: 49326 steps/s (collection: 1.883s, learning 0.110s)
             Mean action noise std: 4.20
          Mean value_function loss: 76.6855
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 73.0772
                       Mean reward: 480.45
               Mean episode length: 238.92
    Episode_Reward/reaching_object: 1.3465
    Episode_Reward/rotating_object: 94.6236
        Episode_Reward/action_rate: -0.1051
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 1.99s
                      Time elapsed: 00:37:35
                               ETA: 00:14:27

################################################################################
                     [1m Learning iteration 1084/1500 [0m                     

                       Computation: 49421 steps/s (collection: 1.879s, learning 0.110s)
             Mean action noise std: 4.21
          Mean value_function loss: 75.5950
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 73.1020
                       Mean reward: 489.77
               Mean episode length: 233.06
    Episode_Reward/reaching_object: 1.3507
    Episode_Reward/rotating_object: 97.9240
        Episode_Reward/action_rate: -0.1057
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 1.99s
                      Time elapsed: 00:37:37
                               ETA: 00:14:25

################################################################################
                     [1m Learning iteration 1085/1500 [0m                     

                       Computation: 48821 steps/s (collection: 1.903s, learning 0.111s)
             Mean action noise std: 4.21
          Mean value_function loss: 85.2175
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 73.1259
                       Mean reward: 481.04
               Mean episode length: 229.95
    Episode_Reward/reaching_object: 1.3383
    Episode_Reward/rotating_object: 97.8393
        Episode_Reward/action_rate: -0.1049
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 2.01s
                      Time elapsed: 00:37:39
                               ETA: 00:14:23

################################################################################
                     [1m Learning iteration 1086/1500 [0m                     

                       Computation: 48891 steps/s (collection: 1.889s, learning 0.122s)
             Mean action noise std: 4.22
          Mean value_function loss: 74.6533
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 73.1416
                       Mean reward: 463.74
               Mean episode length: 233.95
    Episode_Reward/reaching_object: 1.3210
    Episode_Reward/rotating_object: 92.7109
        Episode_Reward/action_rate: -0.1048
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 2.01s
                      Time elapsed: 00:37:41
                               ETA: 00:14:21

################################################################################
                     [1m Learning iteration 1087/1500 [0m                     

                       Computation: 47348 steps/s (collection: 1.955s, learning 0.121s)
             Mean action noise std: 4.22
          Mean value_function loss: 81.3036
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 73.1563
                       Mean reward: 521.87
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 1.3427
    Episode_Reward/rotating_object: 96.0435
        Episode_Reward/action_rate: -0.1055
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 2.08s
                      Time elapsed: 00:37:43
                               ETA: 00:14:19

################################################################################
                     [1m Learning iteration 1088/1500 [0m                     

                       Computation: 44651 steps/s (collection: 2.061s, learning 0.141s)
             Mean action noise std: 4.22
          Mean value_function loss: 71.5228
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 73.1788
                       Mean reward: 509.83
               Mean episode length: 230.61
    Episode_Reward/reaching_object: 1.3652
    Episode_Reward/rotating_object: 97.3427
        Episode_Reward/action_rate: -0.1064
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 2.20s
                      Time elapsed: 00:37:45
                               ETA: 00:14:17

################################################################################
                     [1m Learning iteration 1089/1500 [0m                     

                       Computation: 44378 steps/s (collection: 2.080s, learning 0.135s)
             Mean action noise std: 4.23
          Mean value_function loss: 74.5216
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 73.2086
                       Mean reward: 501.37
               Mean episode length: 221.46
    Episode_Reward/reaching_object: 1.3355
    Episode_Reward/rotating_object: 96.4856
        Episode_Reward/action_rate: -0.1054
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 2.22s
                      Time elapsed: 00:37:47
                               ETA: 00:14:15

################################################################################
                     [1m Learning iteration 1090/1500 [0m                     

                       Computation: 47972 steps/s (collection: 1.924s, learning 0.125s)
             Mean action noise std: 4.23
          Mean value_function loss: 78.7817
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 73.2326
                       Mean reward: 490.16
               Mean episode length: 234.17
    Episode_Reward/reaching_object: 1.3418
    Episode_Reward/rotating_object: 93.2837
        Episode_Reward/action_rate: -0.1064
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 2.05s
                      Time elapsed: 00:37:49
                               ETA: 00:14:12

################################################################################
                     [1m Learning iteration 1091/1500 [0m                     

                       Computation: 47723 steps/s (collection: 1.937s, learning 0.122s)
             Mean action noise std: 4.23
          Mean value_function loss: 79.7657
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 73.2516
                       Mean reward: 461.92
               Mean episode length: 232.76
    Episode_Reward/reaching_object: 1.3222
    Episode_Reward/rotating_object: 91.8857
        Episode_Reward/action_rate: -0.1057
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 2.06s
                      Time elapsed: 00:37:51
                               ETA: 00:14:10

################################################################################
                     [1m Learning iteration 1092/1500 [0m                     

                       Computation: 47104 steps/s (collection: 1.961s, learning 0.125s)
             Mean action noise std: 4.24
          Mean value_function loss: 81.8361
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 73.2710
                       Mean reward: 474.91
               Mean episode length: 228.28
    Episode_Reward/reaching_object: 1.3458
    Episode_Reward/rotating_object: 98.8078
        Episode_Reward/action_rate: -0.1061
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 2.09s
                      Time elapsed: 00:37:53
                               ETA: 00:14:08

################################################################################
                     [1m Learning iteration 1093/1500 [0m                     

                       Computation: 47948 steps/s (collection: 1.937s, learning 0.113s)
             Mean action noise std: 4.24
          Mean value_function loss: 77.6235
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 73.2951
                       Mean reward: 482.64
               Mean episode length: 233.09
    Episode_Reward/reaching_object: 1.3328
    Episode_Reward/rotating_object: 94.2422
        Episode_Reward/action_rate: -0.1069
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 2.05s
                      Time elapsed: 00:37:55
                               ETA: 00:14:06

################################################################################
                     [1m Learning iteration 1094/1500 [0m                     

                       Computation: 48330 steps/s (collection: 1.923s, learning 0.111s)
             Mean action noise std: 4.25
          Mean value_function loss: 75.8512
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 73.3213
                       Mean reward: 478.11
               Mean episode length: 237.36
    Episode_Reward/reaching_object: 1.3619
    Episode_Reward/rotating_object: 95.0450
        Episode_Reward/action_rate: -0.1074
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 2.03s
                      Time elapsed: 00:37:57
                               ETA: 00:14:04

################################################################################
                     [1m Learning iteration 1095/1500 [0m                     

                       Computation: 48607 steps/s (collection: 1.909s, learning 0.114s)
             Mean action noise std: 4.25
          Mean value_function loss: 85.2480
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 73.3468
                       Mean reward: 486.48
               Mean episode length: 234.35
    Episode_Reward/reaching_object: 1.3394
    Episode_Reward/rotating_object: 94.6552
        Episode_Reward/action_rate: -0.1062
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 2.02s
                      Time elapsed: 00:37:59
                               ETA: 00:14:02

################################################################################
                     [1m Learning iteration 1096/1500 [0m                     

                       Computation: 48186 steps/s (collection: 1.927s, learning 0.113s)
             Mean action noise std: 4.25
          Mean value_function loss: 72.5083
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 73.3741
                       Mean reward: 471.48
               Mean episode length: 233.78
    Episode_Reward/reaching_object: 1.3434
    Episode_Reward/rotating_object: 95.5270
        Episode_Reward/action_rate: -0.1067
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 2.04s
                      Time elapsed: 00:38:01
                               ETA: 00:14:00

################################################################################
                     [1m Learning iteration 1097/1500 [0m                     

                       Computation: 46959 steps/s (collection: 1.975s, learning 0.119s)
             Mean action noise std: 4.26
          Mean value_function loss: 79.0589
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 73.3985
                       Mean reward: 477.35
               Mean episode length: 239.04
    Episode_Reward/reaching_object: 1.3502
    Episode_Reward/rotating_object: 92.9993
        Episode_Reward/action_rate: -0.1083
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 2.09s
                      Time elapsed: 00:38:04
                               ETA: 00:13:58

################################################################################
                     [1m Learning iteration 1098/1500 [0m                     

                       Computation: 48056 steps/s (collection: 1.933s, learning 0.113s)
             Mean action noise std: 4.26
          Mean value_function loss: 73.2877
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 73.4227
                       Mean reward: 481.12
               Mean episode length: 236.23
    Episode_Reward/reaching_object: 1.3225
    Episode_Reward/rotating_object: 92.8279
        Episode_Reward/action_rate: -0.1059
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 2.05s
                      Time elapsed: 00:38:06
                               ETA: 00:13:56

################################################################################
                     [1m Learning iteration 1099/1500 [0m                     

                       Computation: 48251 steps/s (collection: 1.923s, learning 0.114s)
             Mean action noise std: 4.27
          Mean value_function loss: 76.3670
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 73.4434
                       Mean reward: 494.89
               Mean episode length: 236.96
    Episode_Reward/reaching_object: 1.3791
    Episode_Reward/rotating_object: 98.0518
        Episode_Reward/action_rate: -0.1100
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 2.04s
                      Time elapsed: 00:38:08
                               ETA: 00:13:54

################################################################################
                     [1m Learning iteration 1100/1500 [0m                     

                       Computation: 47941 steps/s (collection: 1.940s, learning 0.111s)
             Mean action noise std: 4.27
          Mean value_function loss: 75.3742
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 73.4569
                       Mean reward: 464.44
               Mean episode length: 233.42
    Episode_Reward/reaching_object: 1.3308
    Episode_Reward/rotating_object: 95.6177
        Episode_Reward/action_rate: -0.1069
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 2.05s
                      Time elapsed: 00:38:10
                               ETA: 00:13:52

################################################################################
                     [1m Learning iteration 1101/1500 [0m                     

                       Computation: 48070 steps/s (collection: 1.930s, learning 0.115s)
             Mean action noise std: 4.27
          Mean value_function loss: 73.8945
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 73.4712
                       Mean reward: 486.48
               Mean episode length: 229.22
    Episode_Reward/reaching_object: 1.3402
    Episode_Reward/rotating_object: 92.5727
        Episode_Reward/action_rate: -0.1081
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 2.04s
                      Time elapsed: 00:38:12
                               ETA: 00:13:49

################################################################################
                     [1m Learning iteration 1102/1500 [0m                     

                       Computation: 47539 steps/s (collection: 1.958s, learning 0.110s)
             Mean action noise std: 4.27
          Mean value_function loss: 81.6212
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 73.4931
                       Mean reward: 466.16
               Mean episode length: 229.07
    Episode_Reward/reaching_object: 1.3465
    Episode_Reward/rotating_object: 95.6229
        Episode_Reward/action_rate: -0.1091
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 2.07s
                      Time elapsed: 00:38:14
                               ETA: 00:13:47

################################################################################
                     [1m Learning iteration 1103/1500 [0m                     

                       Computation: 48558 steps/s (collection: 1.914s, learning 0.110s)
             Mean action noise std: 4.28
          Mean value_function loss: 84.3879
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 73.5084
                       Mean reward: 498.74
               Mean episode length: 234.42
    Episode_Reward/reaching_object: 1.3379
    Episode_Reward/rotating_object: 88.7683
        Episode_Reward/action_rate: -0.1081
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 2.02s
                      Time elapsed: 00:38:16
                               ETA: 00:13:45

################################################################################
                     [1m Learning iteration 1104/1500 [0m                     

                       Computation: 48754 steps/s (collection: 1.906s, learning 0.110s)
             Mean action noise std: 4.28
          Mean value_function loss: 73.7462
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 73.5263
                       Mean reward: 488.45
               Mean episode length: 234.78
    Episode_Reward/reaching_object: 1.3646
    Episode_Reward/rotating_object: 98.6115
        Episode_Reward/action_rate: -0.1091
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 2.02s
                      Time elapsed: 00:38:18
                               ETA: 00:13:43

################################################################################
                     [1m Learning iteration 1105/1500 [0m                     

                       Computation: 48152 steps/s (collection: 1.932s, learning 0.110s)
             Mean action noise std: 4.28
          Mean value_function loss: 81.8980
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 73.5452
                       Mean reward: 526.22
               Mean episode length: 243.57
    Episode_Reward/reaching_object: 1.3782
    Episode_Reward/rotating_object: 96.2059
        Episode_Reward/action_rate: -0.1112
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 2.04s
                      Time elapsed: 00:38:20
                               ETA: 00:13:41

################################################################################
                     [1m Learning iteration 1106/1500 [0m                     

                       Computation: 48393 steps/s (collection: 1.921s, learning 0.110s)
             Mean action noise std: 4.28
          Mean value_function loss: 73.0994
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 73.5522
                       Mean reward: 509.48
               Mean episode length: 241.26
    Episode_Reward/reaching_object: 1.3832
    Episode_Reward/rotating_object: 96.9520
        Episode_Reward/action_rate: -0.1112
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 2.03s
                      Time elapsed: 00:38:22
                               ETA: 00:13:39

################################################################################
                     [1m Learning iteration 1107/1500 [0m                     

                       Computation: 48363 steps/s (collection: 1.922s, learning 0.110s)
             Mean action noise std: 4.29
          Mean value_function loss: 79.4360
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 73.5610
                       Mean reward: 502.40
               Mean episode length: 230.34
    Episode_Reward/reaching_object: 1.3261
    Episode_Reward/rotating_object: 94.4839
        Episode_Reward/action_rate: -0.1074
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 2.03s
                      Time elapsed: 00:38:24
                               ETA: 00:13:37

################################################################################
                     [1m Learning iteration 1108/1500 [0m                     

                       Computation: 48633 steps/s (collection: 1.911s, learning 0.110s)
             Mean action noise std: 4.29
          Mean value_function loss: 74.2834
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 73.5892
                       Mean reward: 505.01
               Mean episode length: 234.69
    Episode_Reward/reaching_object: 1.3388
    Episode_Reward/rotating_object: 95.2328
        Episode_Reward/action_rate: -0.1079
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 2.02s
                      Time elapsed: 00:38:26
                               ETA: 00:13:35

################################################################################
                     [1m Learning iteration 1109/1500 [0m                     

                       Computation: 48761 steps/s (collection: 1.906s, learning 0.110s)
             Mean action noise std: 4.30
          Mean value_function loss: 80.2803
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 73.6151
                       Mean reward: 475.57
               Mean episode length: 229.60
    Episode_Reward/reaching_object: 1.3652
    Episode_Reward/rotating_object: 96.3817
        Episode_Reward/action_rate: -0.1102
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 2.02s
                      Time elapsed: 00:38:28
                               ETA: 00:13:33

################################################################################
                     [1m Learning iteration 1110/1500 [0m                     

                       Computation: 48541 steps/s (collection: 1.913s, learning 0.112s)
             Mean action noise std: 4.30
          Mean value_function loss: 82.9017
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 73.6293
                       Mean reward: 462.55
               Mean episode length: 231.02
    Episode_Reward/reaching_object: 1.3554
    Episode_Reward/rotating_object: 94.0046
        Episode_Reward/action_rate: -0.1102
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 2.03s
                      Time elapsed: 00:38:30
                               ETA: 00:13:31

################################################################################
                     [1m Learning iteration 1111/1500 [0m                     

                       Computation: 48405 steps/s (collection: 1.921s, learning 0.110s)
             Mean action noise std: 4.30
          Mean value_function loss: 71.8687
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 73.6458
                       Mean reward: 454.74
               Mean episode length: 231.38
    Episode_Reward/reaching_object: 1.3652
    Episode_Reward/rotating_object: 94.6431
        Episode_Reward/action_rate: -0.1110
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 2.03s
                      Time elapsed: 00:38:32
                               ETA: 00:13:28

################################################################################
                     [1m Learning iteration 1112/1500 [0m                     

                       Computation: 48016 steps/s (collection: 1.933s, learning 0.114s)
             Mean action noise std: 4.31
          Mean value_function loss: 82.1004
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 73.6628
                       Mean reward: 444.62
               Mean episode length: 235.85
    Episode_Reward/reaching_object: 1.3777
    Episode_Reward/rotating_object: 96.7250
        Episode_Reward/action_rate: -0.1108
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 2.05s
                      Time elapsed: 00:38:34
                               ETA: 00:13:26

################################################################################
                     [1m Learning iteration 1113/1500 [0m                     

                       Computation: 46852 steps/s (collection: 1.980s, learning 0.118s)
             Mean action noise std: 4.31
          Mean value_function loss: 77.6849
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 73.6837
                       Mean reward: 459.47
               Mean episode length: 224.65
    Episode_Reward/reaching_object: 1.3588
    Episode_Reward/rotating_object: 93.4649
        Episode_Reward/action_rate: -0.1098
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 2.10s
                      Time elapsed: 00:38:36
                               ETA: 00:13:24

################################################################################
                     [1m Learning iteration 1114/1500 [0m                     

                       Computation: 47664 steps/s (collection: 1.949s, learning 0.113s)
             Mean action noise std: 4.31
          Mean value_function loss: 72.8799
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 73.6991
                       Mean reward: 457.03
               Mean episode length: 227.07
    Episode_Reward/reaching_object: 1.3547
    Episode_Reward/rotating_object: 94.2088
        Episode_Reward/action_rate: -0.1104
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 2.06s
                      Time elapsed: 00:38:38
                               ETA: 00:13:22

################################################################################
                     [1m Learning iteration 1115/1500 [0m                     

                       Computation: 47987 steps/s (collection: 1.935s, learning 0.114s)
             Mean action noise std: 4.31
          Mean value_function loss: 71.8897
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 73.7228
                       Mean reward: 512.16
               Mean episode length: 243.25
    Episode_Reward/reaching_object: 1.3947
    Episode_Reward/rotating_object: 97.7212
        Episode_Reward/action_rate: -0.1129
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 2.05s
                      Time elapsed: 00:38:40
                               ETA: 00:13:20

################################################################################
                     [1m Learning iteration 1116/1500 [0m                     

                       Computation: 48262 steps/s (collection: 1.925s, learning 0.112s)
             Mean action noise std: 4.32
          Mean value_function loss: 66.3629
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 73.7403
                       Mean reward: 460.26
               Mean episode length: 231.43
    Episode_Reward/reaching_object: 1.3625
    Episode_Reward/rotating_object: 96.9560
        Episode_Reward/action_rate: -0.1110
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 2.04s
                      Time elapsed: 00:38:42
                               ETA: 00:13:18

################################################################################
                     [1m Learning iteration 1117/1500 [0m                     

                       Computation: 47601 steps/s (collection: 1.944s, learning 0.121s)
             Mean action noise std: 4.33
          Mean value_function loss: 73.8638
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 73.7731
                       Mean reward: 505.84
               Mean episode length: 231.33
    Episode_Reward/reaching_object: 1.3924
    Episode_Reward/rotating_object: 102.1569
        Episode_Reward/action_rate: -0.1124
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 2.07s
                      Time elapsed: 00:38:44
                               ETA: 00:13:16

################################################################################
                     [1m Learning iteration 1118/1500 [0m                     

                       Computation: 45817 steps/s (collection: 2.025s, learning 0.121s)
             Mean action noise std: 4.33
          Mean value_function loss: 73.3244
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 73.8004
                       Mean reward: 500.92
               Mean episode length: 236.02
    Episode_Reward/reaching_object: 1.3723
    Episode_Reward/rotating_object: 96.9400
        Episode_Reward/action_rate: -0.1118
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 2.15s
                      Time elapsed: 00:38:47
                               ETA: 00:13:14

################################################################################
                     [1m Learning iteration 1119/1500 [0m                     

                       Computation: 47648 steps/s (collection: 1.950s, learning 0.113s)
             Mean action noise std: 4.33
          Mean value_function loss: 81.8092
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 73.8160
                       Mean reward: 514.02
               Mean episode length: 237.77
    Episode_Reward/reaching_object: 1.3608
    Episode_Reward/rotating_object: 97.3704
        Episode_Reward/action_rate: -0.1124
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 2.06s
                      Time elapsed: 00:38:49
                               ETA: 00:13:12

################################################################################
                     [1m Learning iteration 1120/1500 [0m                     

                       Computation: 48023 steps/s (collection: 1.935s, learning 0.112s)
             Mean action noise std: 4.34
          Mean value_function loss: 77.2567
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 73.8371
                       Mean reward: 481.56
               Mean episode length: 229.10
    Episode_Reward/reaching_object: 1.3509
    Episode_Reward/rotating_object: 96.3035
        Episode_Reward/action_rate: -0.1112
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 2.05s
                      Time elapsed: 00:38:51
                               ETA: 00:13:10

################################################################################
                     [1m Learning iteration 1121/1500 [0m                     

                       Computation: 48317 steps/s (collection: 1.921s, learning 0.113s)
             Mean action noise std: 4.34
          Mean value_function loss: 75.3565
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 73.8597
                       Mean reward: 481.72
               Mean episode length: 222.20
    Episode_Reward/reaching_object: 1.3429
    Episode_Reward/rotating_object: 97.2577
        Episode_Reward/action_rate: -0.1102
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 2.03s
                      Time elapsed: 00:38:53
                               ETA: 00:13:08

################################################################################
                     [1m Learning iteration 1122/1500 [0m                     

                       Computation: 48065 steps/s (collection: 1.925s, learning 0.120s)
             Mean action noise std: 4.34
          Mean value_function loss: 68.7990
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 73.8744
                       Mean reward: 480.59
               Mean episode length: 236.04
    Episode_Reward/reaching_object: 1.3989
    Episode_Reward/rotating_object: 99.3433
        Episode_Reward/action_rate: -0.1149
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 2.05s
                      Time elapsed: 00:38:55
                               ETA: 00:13:06

################################################################################
                     [1m Learning iteration 1123/1500 [0m                     

                       Computation: 48186 steps/s (collection: 1.930s, learning 0.110s)
             Mean action noise std: 4.35
          Mean value_function loss: 74.5888
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 73.8943
                       Mean reward: 481.13
               Mean episode length: 235.40
    Episode_Reward/reaching_object: 1.3535
    Episode_Reward/rotating_object: 93.8709
        Episode_Reward/action_rate: -0.1120
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 2.04s
                      Time elapsed: 00:38:57
                               ETA: 00:13:03

################################################################################
                     [1m Learning iteration 1124/1500 [0m                     

                       Computation: 48031 steps/s (collection: 1.935s, learning 0.112s)
             Mean action noise std: 4.35
          Mean value_function loss: 80.6249
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 73.9098
                       Mean reward: 472.51
               Mean episode length: 230.68
    Episode_Reward/reaching_object: 1.3445
    Episode_Reward/rotating_object: 95.1269
        Episode_Reward/action_rate: -0.1114
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 2.05s
                      Time elapsed: 00:38:59
                               ETA: 00:13:01

################################################################################
                     [1m Learning iteration 1125/1500 [0m                     

                       Computation: 48458 steps/s (collection: 1.919s, learning 0.110s)
             Mean action noise std: 4.35
          Mean value_function loss: 71.1313
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 73.9216
                       Mean reward: 460.55
               Mean episode length: 239.69
    Episode_Reward/reaching_object: 1.3683
    Episode_Reward/rotating_object: 97.9991
        Episode_Reward/action_rate: -0.1129
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 2.03s
                      Time elapsed: 00:39:01
                               ETA: 00:12:59

################################################################################
                     [1m Learning iteration 1126/1500 [0m                     

                       Computation: 48129 steps/s (collection: 1.932s, learning 0.110s)
             Mean action noise std: 4.35
          Mean value_function loss: 81.2245
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 73.9395
                       Mean reward: 490.08
               Mean episode length: 228.69
    Episode_Reward/reaching_object: 1.3764
    Episode_Reward/rotating_object: 98.6145
        Episode_Reward/action_rate: -0.1115
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 2.04s
                      Time elapsed: 00:39:03
                               ETA: 00:12:57

################################################################################
                     [1m Learning iteration 1127/1500 [0m                     

                       Computation: 48887 steps/s (collection: 1.886s, learning 0.124s)
             Mean action noise std: 4.36
          Mean value_function loss: 75.9593
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 73.9645
                       Mean reward: 421.07
               Mean episode length: 231.76
    Episode_Reward/reaching_object: 1.3472
    Episode_Reward/rotating_object: 92.8737
        Episode_Reward/action_rate: -0.1114
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 2.01s
                      Time elapsed: 00:39:05
                               ETA: 00:12:55

################################################################################
                     [1m Learning iteration 1128/1500 [0m                     

                       Computation: 48649 steps/s (collection: 1.911s, learning 0.110s)
             Mean action noise std: 4.36
          Mean value_function loss: 76.1377
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 73.9907
                       Mean reward: 466.46
               Mean episode length: 240.72
    Episode_Reward/reaching_object: 1.3484
    Episode_Reward/rotating_object: 92.2303
        Episode_Reward/action_rate: -0.1136
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 2.02s
                      Time elapsed: 00:39:07
                               ETA: 00:12:53

################################################################################
                     [1m Learning iteration 1129/1500 [0m                     

                       Computation: 48816 steps/s (collection: 1.904s, learning 0.110s)
             Mean action noise std: 4.37
          Mean value_function loss: 84.2938
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 74.0084
                       Mean reward: 487.87
               Mean episode length: 233.90
    Episode_Reward/reaching_object: 1.3598
    Episode_Reward/rotating_object: 96.5342
        Episode_Reward/action_rate: -0.1134
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 2.01s
                      Time elapsed: 00:39:09
                               ETA: 00:12:51

################################################################################
                     [1m Learning iteration 1130/1500 [0m                     

                       Computation: 48395 steps/s (collection: 1.921s, learning 0.110s)
             Mean action noise std: 4.37
          Mean value_function loss: 78.3434
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 74.0304
                       Mean reward: 491.18
               Mean episode length: 236.14
    Episode_Reward/reaching_object: 1.3497
    Episode_Reward/rotating_object: 95.2825
        Episode_Reward/action_rate: -0.1145
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 2.03s
                      Time elapsed: 00:39:11
                               ETA: 00:12:49

################################################################################
                     [1m Learning iteration 1131/1500 [0m                     

                       Computation: 49094 steps/s (collection: 1.892s, learning 0.110s)
             Mean action noise std: 4.37
          Mean value_function loss: 83.1697
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 74.0513
                       Mean reward: 455.65
               Mean episode length: 212.87
    Episode_Reward/reaching_object: 1.2916
    Episode_Reward/rotating_object: 92.6037
        Episode_Reward/action_rate: -0.1075
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 2.00s
                      Time elapsed: 00:39:13
                               ETA: 00:12:47

################################################################################
                     [1m Learning iteration 1132/1500 [0m                     

                       Computation: 49218 steps/s (collection: 1.887s, learning 0.110s)
             Mean action noise std: 4.38
          Mean value_function loss: 77.6640
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 74.0691
                       Mean reward: 478.34
               Mean episode length: 234.73
    Episode_Reward/reaching_object: 1.3532
    Episode_Reward/rotating_object: 96.4869
        Episode_Reward/action_rate: -0.1128
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 2.00s
                      Time elapsed: 00:39:15
                               ETA: 00:12:45

################################################################################
                     [1m Learning iteration 1133/1500 [0m                     

                       Computation: 48739 steps/s (collection: 1.904s, learning 0.113s)
             Mean action noise std: 4.38
          Mean value_function loss: 74.1637
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 74.0790
                       Mean reward: 519.34
               Mean episode length: 241.66
    Episode_Reward/reaching_object: 1.3761
    Episode_Reward/rotating_object: 100.2911
        Episode_Reward/action_rate: -0.1154
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 2.02s
                      Time elapsed: 00:39:17
                               ETA: 00:12:42

################################################################################
                     [1m Learning iteration 1134/1500 [0m                     

                       Computation: 48058 steps/s (collection: 1.933s, learning 0.113s)
             Mean action noise std: 4.38
          Mean value_function loss: 86.8158
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 74.0992
                       Mean reward: 506.19
               Mean episode length: 230.63
    Episode_Reward/reaching_object: 1.3663
    Episode_Reward/rotating_object: 98.8217
        Episode_Reward/action_rate: -0.1148
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 2.05s
                      Time elapsed: 00:39:19
                               ETA: 00:12:40

################################################################################
                     [1m Learning iteration 1135/1500 [0m                     

                       Computation: 48557 steps/s (collection: 1.914s, learning 0.110s)
             Mean action noise std: 4.39
          Mean value_function loss: 86.1555
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 74.1190
                       Mean reward: 491.11
               Mean episode length: 228.02
    Episode_Reward/reaching_object: 1.3262
    Episode_Reward/rotating_object: 93.7882
        Episode_Reward/action_rate: -0.1121
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 2.02s
                      Time elapsed: 00:39:21
                               ETA: 00:12:38

################################################################################
                     [1m Learning iteration 1136/1500 [0m                     

                       Computation: 47502 steps/s (collection: 1.956s, learning 0.113s)
             Mean action noise std: 4.39
          Mean value_function loss: 75.6539
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 74.1436
                       Mean reward: 450.38
               Mean episode length: 224.70
    Episode_Reward/reaching_object: 1.3215
    Episode_Reward/rotating_object: 93.5563
        Episode_Reward/action_rate: -0.1120
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 2.07s
                      Time elapsed: 00:39:23
                               ETA: 00:12:36

################################################################################
                     [1m Learning iteration 1137/1500 [0m                     

                       Computation: 47859 steps/s (collection: 1.943s, learning 0.111s)
             Mean action noise std: 4.39
          Mean value_function loss: 79.4467
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 74.1678
                       Mean reward: 485.78
               Mean episode length: 229.29
    Episode_Reward/reaching_object: 1.3694
    Episode_Reward/rotating_object: 98.1362
        Episode_Reward/action_rate: -0.1142
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 2.05s
                      Time elapsed: 00:39:25
                               ETA: 00:12:34

################################################################################
                     [1m Learning iteration 1138/1500 [0m                     

                       Computation: 48062 steps/s (collection: 1.934s, learning 0.111s)
             Mean action noise std: 4.40
          Mean value_function loss: 80.7223
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 74.1846
                       Mean reward: 511.22
               Mean episode length: 232.76
    Episode_Reward/reaching_object: 1.3692
    Episode_Reward/rotating_object: 98.6725
        Episode_Reward/action_rate: -0.1156
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 2.05s
                      Time elapsed: 00:39:27
                               ETA: 00:12:32

################################################################################
                     [1m Learning iteration 1139/1500 [0m                     

                       Computation: 48200 steps/s (collection: 1.926s, learning 0.113s)
             Mean action noise std: 4.40
          Mean value_function loss: 75.0173
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 74.2050
                       Mean reward: 476.15
               Mean episode length: 230.57
    Episode_Reward/reaching_object: 1.3485
    Episode_Reward/rotating_object: 95.2306
        Episode_Reward/action_rate: -0.1145
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 2.04s
                      Time elapsed: 00:39:29
                               ETA: 00:12:30

################################################################################
                     [1m Learning iteration 1140/1500 [0m                     

                       Computation: 48062 steps/s (collection: 1.929s, learning 0.116s)
             Mean action noise std: 4.41
          Mean value_function loss: 78.5373
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 74.2308
                       Mean reward: 502.01
               Mean episode length: 242.45
    Episode_Reward/reaching_object: 1.3548
    Episode_Reward/rotating_object: 93.9432
        Episode_Reward/action_rate: -0.1158
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 2.05s
                      Time elapsed: 00:39:31
                               ETA: 00:12:28

################################################################################
                     [1m Learning iteration 1141/1500 [0m                     

                       Computation: 48554 steps/s (collection: 1.911s, learning 0.114s)
             Mean action noise std: 4.41
          Mean value_function loss: 90.9932
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 74.2458
                       Mean reward: 445.41
               Mean episode length: 223.51
    Episode_Reward/reaching_object: 1.3256
    Episode_Reward/rotating_object: 91.8575
        Episode_Reward/action_rate: -0.1137
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 2.02s
                      Time elapsed: 00:39:33
                               ETA: 00:12:26

################################################################################
                     [1m Learning iteration 1142/1500 [0m                     

                       Computation: 48549 steps/s (collection: 1.915s, learning 0.110s)
             Mean action noise std: 4.41
          Mean value_function loss: 71.4568
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 74.2633
                       Mean reward: 555.26
               Mean episode length: 243.70
    Episode_Reward/reaching_object: 1.3403
    Episode_Reward/rotating_object: 95.6706
        Episode_Reward/action_rate: -0.1153
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 2.02s
                      Time elapsed: 00:39:35
                               ETA: 00:12:24

################################################################################
                     [1m Learning iteration 1143/1500 [0m                     

                       Computation: 48242 steps/s (collection: 1.919s, learning 0.119s)
             Mean action noise std: 4.41
          Mean value_function loss: 76.8675
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 74.2806
                       Mean reward: 485.07
               Mean episode length: 230.75
    Episode_Reward/reaching_object: 1.3630
    Episode_Reward/rotating_object: 97.2025
        Episode_Reward/action_rate: -0.1154
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 2.04s
                      Time elapsed: 00:39:37
                               ETA: 00:12:22

################################################################################
                     [1m Learning iteration 1144/1500 [0m                     

                       Computation: 48256 steps/s (collection: 1.909s, learning 0.128s)
             Mean action noise std: 4.42
          Mean value_function loss: 84.1361
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 74.2987
                       Mean reward: 505.64
               Mean episode length: 234.44
    Episode_Reward/reaching_object: 1.3619
    Episode_Reward/rotating_object: 96.5077
        Episode_Reward/action_rate: -0.1159
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 2.04s
                      Time elapsed: 00:39:39
                               ETA: 00:12:19

################################################################################
                     [1m Learning iteration 1145/1500 [0m                     

                       Computation: 47212 steps/s (collection: 1.957s, learning 0.125s)
             Mean action noise std: 4.42
          Mean value_function loss: 66.7887
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 74.3144
                       Mean reward: 509.41
               Mean episode length: 241.54
    Episode_Reward/reaching_object: 1.3540
    Episode_Reward/rotating_object: 94.7873
        Episode_Reward/action_rate: -0.1165
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 2.08s
                      Time elapsed: 00:39:42
                               ETA: 00:12:17

################################################################################
                     [1m Learning iteration 1146/1500 [0m                     

                       Computation: 47556 steps/s (collection: 1.940s, learning 0.127s)
             Mean action noise std: 4.42
          Mean value_function loss: 72.5264
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 74.3351
                       Mean reward: 476.61
               Mean episode length: 223.56
    Episode_Reward/reaching_object: 1.3521
    Episode_Reward/rotating_object: 95.3646
        Episode_Reward/action_rate: -0.1163
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 2.07s
                      Time elapsed: 00:39:44
                               ETA: 00:12:15

################################################################################
                     [1m Learning iteration 1147/1500 [0m                     

                       Computation: 48234 steps/s (collection: 1.915s, learning 0.123s)
             Mean action noise std: 4.43
          Mean value_function loss: 83.1942
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 74.3582
                       Mean reward: 431.44
               Mean episode length: 225.52
    Episode_Reward/reaching_object: 1.3403
    Episode_Reward/rotating_object: 93.4026
        Episode_Reward/action_rate: -0.1153
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 2.04s
                      Time elapsed: 00:39:46
                               ETA: 00:12:13

################################################################################
                     [1m Learning iteration 1148/1500 [0m                     

                       Computation: 47148 steps/s (collection: 1.960s, learning 0.125s)
             Mean action noise std: 4.43
          Mean value_function loss: 76.3637
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 74.3804
                       Mean reward: 510.21
               Mean episode length: 234.96
    Episode_Reward/reaching_object: 1.3591
    Episode_Reward/rotating_object: 96.5390
        Episode_Reward/action_rate: -0.1170
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 2.08s
                      Time elapsed: 00:39:48
                               ETA: 00:12:11

################################################################################
                     [1m Learning iteration 1149/1500 [0m                     

                       Computation: 45830 steps/s (collection: 2.032s, learning 0.113s)
             Mean action noise std: 4.44
          Mean value_function loss: 83.1215
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 74.4003
                       Mean reward: 534.39
               Mean episode length: 236.87
    Episode_Reward/reaching_object: 1.3468
    Episode_Reward/rotating_object: 95.7923
        Episode_Reward/action_rate: -0.1154
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 2.14s
                      Time elapsed: 00:39:50
                               ETA: 00:12:09

################################################################################
                     [1m Learning iteration 1150/1500 [0m                     

                       Computation: 48350 steps/s (collection: 1.923s, learning 0.110s)
             Mean action noise std: 4.44
          Mean value_function loss: 87.2353
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 74.4209
                       Mean reward: 477.91
               Mean episode length: 230.03
    Episode_Reward/reaching_object: 1.3562
    Episode_Reward/rotating_object: 93.3909
        Episode_Reward/action_rate: -0.1177
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 2.03s
                      Time elapsed: 00:39:52
                               ETA: 00:12:07

################################################################################
                     [1m Learning iteration 1151/1500 [0m                     

                       Computation: 49459 steps/s (collection: 1.877s, learning 0.110s)
             Mean action noise std: 4.44
          Mean value_function loss: 77.6084
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 74.4370
                       Mean reward: 494.88
               Mean episode length: 237.14
    Episode_Reward/reaching_object: 1.3684
    Episode_Reward/rotating_object: 99.2311
        Episode_Reward/action_rate: -0.1180
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 1.99s
                      Time elapsed: 00:39:54
                               ETA: 00:12:05

################################################################################
                     [1m Learning iteration 1152/1500 [0m                     

                       Computation: 49175 steps/s (collection: 1.886s, learning 0.113s)
             Mean action noise std: 4.45
          Mean value_function loss: 63.5616
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 74.4518
                       Mean reward: 480.58
               Mean episode length: 240.27
    Episode_Reward/reaching_object: 1.3492
    Episode_Reward/rotating_object: 94.8611
        Episode_Reward/action_rate: -0.1184
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 2.00s
                      Time elapsed: 00:39:56
                               ETA: 00:12:03

################################################################################
                     [1m Learning iteration 1153/1500 [0m                     

                       Computation: 49210 steps/s (collection: 1.888s, learning 0.110s)
             Mean action noise std: 4.45
          Mean value_function loss: 76.5658
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 74.4716
                       Mean reward: 440.54
               Mean episode length: 240.17
    Episode_Reward/reaching_object: 1.3943
    Episode_Reward/rotating_object: 95.9218
        Episode_Reward/action_rate: -0.1207
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 2.00s
                      Time elapsed: 00:39:58
                               ETA: 00:12:01

################################################################################
                     [1m Learning iteration 1154/1500 [0m                     

                       Computation: 49780 steps/s (collection: 1.865s, learning 0.110s)
             Mean action noise std: 4.45
          Mean value_function loss: 68.1172
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 74.4943
                       Mean reward: 464.48
               Mean episode length: 238.93
    Episode_Reward/reaching_object: 1.3515
    Episode_Reward/rotating_object: 96.0284
        Episode_Reward/action_rate: -0.1181
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 1.97s
                      Time elapsed: 00:40:00
                               ETA: 00:11:59

################################################################################
                     [1m Learning iteration 1155/1500 [0m                     

                       Computation: 49316 steps/s (collection: 1.883s, learning 0.111s)
             Mean action noise std: 4.46
          Mean value_function loss: 81.2674
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 74.5164
                       Mean reward: 490.36
               Mean episode length: 228.70
    Episode_Reward/reaching_object: 1.3368
    Episode_Reward/rotating_object: 95.9311
        Episode_Reward/action_rate: -0.1176
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 1.99s
                      Time elapsed: 00:40:02
                               ETA: 00:11:56

################################################################################
                     [1m Learning iteration 1156/1500 [0m                     

                       Computation: 49142 steps/s (collection: 1.889s, learning 0.111s)
             Mean action noise std: 4.46
          Mean value_function loss: 76.6115
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 74.5297
                       Mean reward: 451.49
               Mean episode length: 232.84
    Episode_Reward/reaching_object: 1.3617
    Episode_Reward/rotating_object: 97.2688
        Episode_Reward/action_rate: -0.1192
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 2.00s
                      Time elapsed: 00:40:04
                               ETA: 00:11:54

################################################################################
                     [1m Learning iteration 1157/1500 [0m                     

                       Computation: 48474 steps/s (collection: 1.918s, learning 0.110s)
             Mean action noise std: 4.47
          Mean value_function loss: 70.0574
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 74.5549
                       Mean reward: 450.27
               Mean episode length: 228.70
    Episode_Reward/reaching_object: 1.3577
    Episode_Reward/rotating_object: 94.7585
        Episode_Reward/action_rate: -0.1199
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 2.03s
                      Time elapsed: 00:40:06
                               ETA: 00:11:52

################################################################################
                     [1m Learning iteration 1158/1500 [0m                     

                       Computation: 47688 steps/s (collection: 1.951s, learning 0.111s)
             Mean action noise std: 4.47
          Mean value_function loss: 73.7285
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 74.5700
                       Mean reward: 456.60
               Mean episode length: 234.51
    Episode_Reward/reaching_object: 1.3604
    Episode_Reward/rotating_object: 92.8659
        Episode_Reward/action_rate: -0.1203
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 2.06s
                      Time elapsed: 00:40:08
                               ETA: 00:11:50

################################################################################
                     [1m Learning iteration 1159/1500 [0m                     

                       Computation: 47659 steps/s (collection: 1.950s, learning 0.113s)
             Mean action noise std: 4.47
          Mean value_function loss: 72.3590
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 74.5788
                       Mean reward: 485.12
               Mean episode length: 229.13
    Episode_Reward/reaching_object: 1.3240
    Episode_Reward/rotating_object: 94.8343
        Episode_Reward/action_rate: -0.1173
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 2.06s
                      Time elapsed: 00:40:10
                               ETA: 00:11:48

################################################################################
                     [1m Learning iteration 1160/1500 [0m                     

                       Computation: 47391 steps/s (collection: 1.960s, learning 0.115s)
             Mean action noise std: 4.47
          Mean value_function loss: 78.6300
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 74.5918
                       Mean reward: 468.11
               Mean episode length: 242.13
    Episode_Reward/reaching_object: 1.3426
    Episode_Reward/rotating_object: 95.7220
        Episode_Reward/action_rate: -0.1197
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 2.07s
                      Time elapsed: 00:40:12
                               ETA: 00:11:46

################################################################################
                     [1m Learning iteration 1161/1500 [0m                     

                       Computation: 47632 steps/s (collection: 1.936s, learning 0.127s)
             Mean action noise std: 4.48
          Mean value_function loss: 82.9098
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 74.6105
                       Mean reward: 472.02
               Mean episode length: 225.37
    Episode_Reward/reaching_object: 1.3301
    Episode_Reward/rotating_object: 97.7605
        Episode_Reward/action_rate: -0.1172
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 2.06s
                      Time elapsed: 00:40:14
                               ETA: 00:11:44

################################################################################
                     [1m Learning iteration 1162/1500 [0m                     

                       Computation: 48309 steps/s (collection: 1.921s, learning 0.114s)
             Mean action noise std: 4.48
          Mean value_function loss: 72.5995
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 74.6335
                       Mean reward: 506.36
               Mean episode length: 234.90
    Episode_Reward/reaching_object: 1.3657
    Episode_Reward/rotating_object: 101.0466
        Episode_Reward/action_rate: -0.1206
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 2.03s
                      Time elapsed: 00:40:16
                               ETA: 00:11:42

################################################################################
                     [1m Learning iteration 1163/1500 [0m                     

                       Computation: 47994 steps/s (collection: 1.936s, learning 0.112s)
             Mean action noise std: 4.48
          Mean value_function loss: 61.0423
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 74.6479
                       Mean reward: 517.98
               Mean episode length: 231.57
    Episode_Reward/reaching_object: 1.3466
    Episode_Reward/rotating_object: 96.1015
        Episode_Reward/action_rate: -0.1204
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 2.05s
                      Time elapsed: 00:40:18
                               ETA: 00:11:40

################################################################################
                     [1m Learning iteration 1164/1500 [0m                     

                       Computation: 47774 steps/s (collection: 1.946s, learning 0.112s)
             Mean action noise std: 4.49
          Mean value_function loss: 72.1238
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 74.6635
                       Mean reward: 539.51
               Mean episode length: 244.69
    Episode_Reward/reaching_object: 1.3922
    Episode_Reward/rotating_object: 99.7562
        Episode_Reward/action_rate: -0.1235
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 2.06s
                      Time elapsed: 00:40:20
                               ETA: 00:11:38

################################################################################
                     [1m Learning iteration 1165/1500 [0m                     

                       Computation: 48257 steps/s (collection: 1.924s, learning 0.113s)
             Mean action noise std: 4.49
          Mean value_function loss: 78.7767
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 74.6862
                       Mean reward: 463.09
               Mean episode length: 225.62
    Episode_Reward/reaching_object: 1.3548
    Episode_Reward/rotating_object: 95.9912
        Episode_Reward/action_rate: -0.1202
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 2.04s
                      Time elapsed: 00:40:22
                               ETA: 00:11:36

################################################################################
                     [1m Learning iteration 1166/1500 [0m                     

                       Computation: 48625 steps/s (collection: 1.908s, learning 0.113s)
             Mean action noise std: 4.49
          Mean value_function loss: 70.8706
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 74.7094
                       Mean reward: 486.82
               Mean episode length: 224.96
    Episode_Reward/reaching_object: 1.3551
    Episode_Reward/rotating_object: 96.7533
        Episode_Reward/action_rate: -0.1206
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 2.02s
                      Time elapsed: 00:40:24
                               ETA: 00:11:33

################################################################################
                     [1m Learning iteration 1167/1500 [0m                     

                       Computation: 48481 steps/s (collection: 1.915s, learning 0.113s)
             Mean action noise std: 4.50
          Mean value_function loss: 80.5057
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 74.7260
                       Mean reward: 501.85
               Mean episode length: 236.19
    Episode_Reward/reaching_object: 1.3649
    Episode_Reward/rotating_object: 100.5812
        Episode_Reward/action_rate: -0.1222
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 2.03s
                      Time elapsed: 00:40:26
                               ETA: 00:11:31

################################################################################
                     [1m Learning iteration 1168/1500 [0m                     

                       Computation: 47554 steps/s (collection: 1.950s, learning 0.117s)
             Mean action noise std: 4.50
          Mean value_function loss: 82.4368
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 74.7446
                       Mean reward: 453.84
               Mean episode length: 231.65
    Episode_Reward/reaching_object: 1.3390
    Episode_Reward/rotating_object: 95.4876
        Episode_Reward/action_rate: -0.1200
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 2.07s
                      Time elapsed: 00:40:28
                               ETA: 00:11:29

################################################################################
                     [1m Learning iteration 1169/1500 [0m                     

                       Computation: 47791 steps/s (collection: 1.943s, learning 0.114s)
             Mean action noise std: 4.50
          Mean value_function loss: 85.7786
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 74.7694
                       Mean reward: 485.05
               Mean episode length: 230.87
    Episode_Reward/reaching_object: 1.3262
    Episode_Reward/rotating_object: 92.2090
        Episode_Reward/action_rate: -0.1186
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 2.06s
                      Time elapsed: 00:40:30
                               ETA: 00:11:27

################################################################################
                     [1m Learning iteration 1170/1500 [0m                     

                       Computation: 47478 steps/s (collection: 1.957s, learning 0.113s)
             Mean action noise std: 4.51
          Mean value_function loss: 76.5464
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 74.7882
                       Mean reward: 489.10
               Mean episode length: 234.24
    Episode_Reward/reaching_object: 1.3441
    Episode_Reward/rotating_object: 93.8398
        Episode_Reward/action_rate: -0.1210
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 2.07s
                      Time elapsed: 00:40:33
                               ETA: 00:11:25

################################################################################
                     [1m Learning iteration 1171/1500 [0m                     

                       Computation: 48102 steps/s (collection: 1.933s, learning 0.111s)
             Mean action noise std: 4.51
          Mean value_function loss: 86.9824
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 74.8059
                       Mean reward: 445.65
               Mean episode length: 226.40
    Episode_Reward/reaching_object: 1.3543
    Episode_Reward/rotating_object: 97.6931
        Episode_Reward/action_rate: -0.1206
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 2.04s
                      Time elapsed: 00:40:35
                               ETA: 00:11:23

################################################################################
                     [1m Learning iteration 1172/1500 [0m                     

                       Computation: 47656 steps/s (collection: 1.950s, learning 0.113s)
             Mean action noise std: 4.51
          Mean value_function loss: 82.9721
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 74.8253
                       Mean reward: 563.17
               Mean episode length: 245.91
    Episode_Reward/reaching_object: 1.3734
    Episode_Reward/rotating_object: 99.9926
        Episode_Reward/action_rate: -0.1215
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 2.06s
                      Time elapsed: 00:40:37
                               ETA: 00:11:21

################################################################################
                     [1m Learning iteration 1173/1500 [0m                     

                       Computation: 47984 steps/s (collection: 1.935s, learning 0.113s)
             Mean action noise std: 4.52
          Mean value_function loss: 76.6279
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 74.8350
                       Mean reward: 477.40
               Mean episode length: 231.72
    Episode_Reward/reaching_object: 1.3494
    Episode_Reward/rotating_object: 94.7760
        Episode_Reward/action_rate: -0.1196
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 2.05s
                      Time elapsed: 00:40:39
                               ETA: 00:11:19

################################################################################
                     [1m Learning iteration 1174/1500 [0m                     

                       Computation: 48520 steps/s (collection: 1.915s, learning 0.111s)
             Mean action noise std: 4.52
          Mean value_function loss: 80.5783
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 74.8419
                       Mean reward: 482.87
               Mean episode length: 231.64
    Episode_Reward/reaching_object: 1.3584
    Episode_Reward/rotating_object: 96.9075
        Episode_Reward/action_rate: -0.1207
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 2.03s
                      Time elapsed: 00:40:41
                               ETA: 00:11:17

################################################################################
                     [1m Learning iteration 1175/1500 [0m                     

                       Computation: 48722 steps/s (collection: 1.906s, learning 0.111s)
             Mean action noise std: 4.52
          Mean value_function loss: 82.5603
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 74.8538
                       Mean reward: 481.13
               Mean episode length: 234.75
    Episode_Reward/reaching_object: 1.3654
    Episode_Reward/rotating_object: 96.9472
        Episode_Reward/action_rate: -0.1213
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 2.02s
                      Time elapsed: 00:40:43
                               ETA: 00:11:15

################################################################################
                     [1m Learning iteration 1176/1500 [0m                     

                       Computation: 48856 steps/s (collection: 1.902s, learning 0.110s)
             Mean action noise std: 4.53
          Mean value_function loss: 67.1369
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 74.8731
                       Mean reward: 480.41
               Mean episode length: 230.12
    Episode_Reward/reaching_object: 1.3588
    Episode_Reward/rotating_object: 96.6016
        Episode_Reward/action_rate: -0.1215
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 2.01s
                      Time elapsed: 00:40:45
                               ETA: 00:11:13

################################################################################
                     [1m Learning iteration 1177/1500 [0m                     

                       Computation: 49043 steps/s (collection: 1.894s, learning 0.111s)
             Mean action noise std: 4.53
          Mean value_function loss: 78.7078
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 74.8898
                       Mean reward: 489.05
               Mean episode length: 234.68
    Episode_Reward/reaching_object: 1.3578
    Episode_Reward/rotating_object: 96.6105
        Episode_Reward/action_rate: -0.1222
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 2.00s
                      Time elapsed: 00:40:47
                               ETA: 00:11:11

################################################################################
                     [1m Learning iteration 1178/1500 [0m                     

                       Computation: 48895 steps/s (collection: 1.899s, learning 0.111s)
             Mean action noise std: 4.53
          Mean value_function loss: 72.4732
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 74.9047
                       Mean reward: 516.70
               Mean episode length: 237.13
    Episode_Reward/reaching_object: 1.3693
    Episode_Reward/rotating_object: 99.3316
        Episode_Reward/action_rate: -0.1227
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 2.01s
                      Time elapsed: 00:40:49
                               ETA: 00:11:08

################################################################################
                     [1m Learning iteration 1179/1500 [0m                     

                       Computation: 48571 steps/s (collection: 1.913s, learning 0.111s)
             Mean action noise std: 4.53
          Mean value_function loss: 77.3095
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 74.9162
                       Mean reward: 446.11
               Mean episode length: 229.10
    Episode_Reward/reaching_object: 1.3568
    Episode_Reward/rotating_object: 98.1111
        Episode_Reward/action_rate: -0.1227
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 2.02s
                      Time elapsed: 00:40:51
                               ETA: 00:11:06

################################################################################
                     [1m Learning iteration 1180/1500 [0m                     

                       Computation: 48813 steps/s (collection: 1.903s, learning 0.111s)
             Mean action noise std: 4.54
          Mean value_function loss: 76.5634
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 74.9323
                       Mean reward: 478.47
               Mean episode length: 225.57
    Episode_Reward/reaching_object: 1.3581
    Episode_Reward/rotating_object: 95.5849
        Episode_Reward/action_rate: -0.1220
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 2.01s
                      Time elapsed: 00:40:53
                               ETA: 00:11:04

################################################################################
                     [1m Learning iteration 1181/1500 [0m                     

                       Computation: 47514 steps/s (collection: 1.956s, learning 0.113s)
             Mean action noise std: 4.54
          Mean value_function loss: 76.5122
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 74.9526
                       Mean reward: 512.93
               Mean episode length: 241.44
    Episode_Reward/reaching_object: 1.3937
    Episode_Reward/rotating_object: 102.4185
        Episode_Reward/action_rate: -0.1256
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 2.07s
                      Time elapsed: 00:40:55
                               ETA: 00:11:02

################################################################################
                     [1m Learning iteration 1182/1500 [0m                     

                       Computation: 47675 steps/s (collection: 1.949s, learning 0.113s)
             Mean action noise std: 4.54
          Mean value_function loss: 81.2641
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 74.9712
                       Mean reward: 522.35
               Mean episode length: 228.94
    Episode_Reward/reaching_object: 1.3514
    Episode_Reward/rotating_object: 100.9358
        Episode_Reward/action_rate: -0.1220
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 2.06s
                      Time elapsed: 00:40:57
                               ETA: 00:11:00

################################################################################
                     [1m Learning iteration 1183/1500 [0m                     

                       Computation: 47806 steps/s (collection: 1.946s, learning 0.111s)
             Mean action noise std: 4.55
          Mean value_function loss: 82.0859
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 74.9901
                       Mean reward: 485.36
               Mean episode length: 231.41
    Episode_Reward/reaching_object: 1.3506
    Episode_Reward/rotating_object: 97.0573
        Episode_Reward/action_rate: -0.1218
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 2.06s
                      Time elapsed: 00:40:59
                               ETA: 00:10:58

################################################################################
                     [1m Learning iteration 1184/1500 [0m                     

                       Computation: 48073 steps/s (collection: 1.932s, learning 0.113s)
             Mean action noise std: 4.55
          Mean value_function loss: 73.7519
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 75.0076
                       Mean reward: 536.26
               Mean episode length: 240.41
    Episode_Reward/reaching_object: 1.3752
    Episode_Reward/rotating_object: 100.4570
        Episode_Reward/action_rate: -0.1248
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 2.04s
                      Time elapsed: 00:41:01
                               ETA: 00:10:56

################################################################################
                     [1m Learning iteration 1185/1500 [0m                     

                       Computation: 47949 steps/s (collection: 1.937s, learning 0.114s)
             Mean action noise std: 4.55
          Mean value_function loss: 71.9983
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 75.0273
                       Mean reward: 512.65
               Mean episode length: 240.57
    Episode_Reward/reaching_object: 1.3724
    Episode_Reward/rotating_object: 97.2389
        Episode_Reward/action_rate: -0.1251
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 2.05s
                      Time elapsed: 00:41:03
                               ETA: 00:10:54

################################################################################
                     [1m Learning iteration 1186/1500 [0m                     

                       Computation: 47974 steps/s (collection: 1.939s, learning 0.111s)
             Mean action noise std: 4.56
          Mean value_function loss: 73.9027
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 75.0480
                       Mean reward: 514.49
               Mean episode length: 236.13
    Episode_Reward/reaching_object: 1.3368
    Episode_Reward/rotating_object: 97.6193
        Episode_Reward/action_rate: -0.1214
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 2.05s
                      Time elapsed: 00:41:05
                               ETA: 00:10:52

################################################################################
                     [1m Learning iteration 1187/1500 [0m                     

                       Computation: 48045 steps/s (collection: 1.935s, learning 0.111s)
             Mean action noise std: 4.56
          Mean value_function loss: 72.7403
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 75.0617
                       Mean reward: 544.23
               Mean episode length: 238.89
    Episode_Reward/reaching_object: 1.3605
    Episode_Reward/rotating_object: 99.6506
        Episode_Reward/action_rate: -0.1247
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 2.05s
                      Time elapsed: 00:41:07
                               ETA: 00:10:50

################################################################################
                     [1m Learning iteration 1188/1500 [0m                     

                       Computation: 47669 steps/s (collection: 1.949s, learning 0.114s)
             Mean action noise std: 4.57
          Mean value_function loss: 70.1754
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 75.0830
                       Mean reward: 500.90
               Mean episode length: 232.35
    Episode_Reward/reaching_object: 1.3844
    Episode_Reward/rotating_object: 101.3239
        Episode_Reward/action_rate: -0.1260
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 2.06s
                      Time elapsed: 00:41:09
                               ETA: 00:10:48

################################################################################
                     [1m Learning iteration 1189/1500 [0m                     

                       Computation: 47601 steps/s (collection: 1.954s, learning 0.111s)
             Mean action noise std: 4.57
          Mean value_function loss: 78.7193
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 75.1001
                       Mean reward: 469.41
               Mean episode length: 232.37
    Episode_Reward/reaching_object: 1.3788
    Episode_Reward/rotating_object: 101.0954
        Episode_Reward/action_rate: -0.1251
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 2.07s
                      Time elapsed: 00:41:11
                               ETA: 00:10:45

################################################################################
                     [1m Learning iteration 1190/1500 [0m                     

                       Computation: 48014 steps/s (collection: 1.934s, learning 0.113s)
             Mean action noise std: 4.57
          Mean value_function loss: 68.0357
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 75.1092
                       Mean reward: 505.11
               Mean episode length: 232.07
    Episode_Reward/reaching_object: 1.3636
    Episode_Reward/rotating_object: 101.6628
        Episode_Reward/action_rate: -0.1244
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 2.05s
                      Time elapsed: 00:41:13
                               ETA: 00:10:43

################################################################################
                     [1m Learning iteration 1191/1500 [0m                     

                       Computation: 48438 steps/s (collection: 1.915s, learning 0.114s)
             Mean action noise std: 4.58
          Mean value_function loss: 73.2805
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 75.1305
                       Mean reward: 490.19
               Mean episode length: 227.21
    Episode_Reward/reaching_object: 1.3361
    Episode_Reward/rotating_object: 96.3370
        Episode_Reward/action_rate: -0.1243
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 2.03s
                      Time elapsed: 00:41:15
                               ETA: 00:10:41

################################################################################
                     [1m Learning iteration 1192/1500 [0m                     

                       Computation: 47779 steps/s (collection: 1.944s, learning 0.113s)
             Mean action noise std: 4.58
          Mean value_function loss: 81.2585
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 75.1495
                       Mean reward: 521.14
               Mean episode length: 236.63
    Episode_Reward/reaching_object: 1.3658
    Episode_Reward/rotating_object: 102.0054
        Episode_Reward/action_rate: -0.1260
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 2.06s
                      Time elapsed: 00:41:17
                               ETA: 00:10:39

################################################################################
                     [1m Learning iteration 1193/1500 [0m                     

                       Computation: 47139 steps/s (collection: 1.972s, learning 0.113s)
             Mean action noise std: 4.58
          Mean value_function loss: 69.4659
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 75.1691
                       Mean reward: 494.79
               Mean episode length: 226.03
    Episode_Reward/reaching_object: 1.3288
    Episode_Reward/rotating_object: 98.2522
        Episode_Reward/action_rate: -0.1229
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 2.09s
                      Time elapsed: 00:41:20
                               ETA: 00:10:37

################################################################################
                     [1m Learning iteration 1194/1500 [0m                     

                       Computation: 47563 steps/s (collection: 1.954s, learning 0.113s)
             Mean action noise std: 4.59
          Mean value_function loss: 80.1016
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 75.1985
                       Mean reward: 463.24
               Mean episode length: 218.59
    Episode_Reward/reaching_object: 1.3113
    Episode_Reward/rotating_object: 96.4783
        Episode_Reward/action_rate: -0.1208
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 2.07s
                      Time elapsed: 00:41:22
                               ETA: 00:10:35

################################################################################
                     [1m Learning iteration 1195/1500 [0m                     

                       Computation: 47835 steps/s (collection: 1.941s, learning 0.114s)
             Mean action noise std: 4.59
          Mean value_function loss: 79.8418
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 75.2172
                       Mean reward: 521.34
               Mean episode length: 238.01
    Episode_Reward/reaching_object: 1.3550
    Episode_Reward/rotating_object: 100.0347
        Episode_Reward/action_rate: -0.1245
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 2.06s
                      Time elapsed: 00:41:24
                               ETA: 00:10:33

################################################################################
                     [1m Learning iteration 1196/1500 [0m                     

                       Computation: 48239 steps/s (collection: 1.925s, learning 0.113s)
             Mean action noise std: 4.59
          Mean value_function loss: 75.4767
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 75.2288
                       Mean reward: 495.89
               Mean episode length: 226.81
    Episode_Reward/reaching_object: 1.3054
    Episode_Reward/rotating_object: 93.7356
        Episode_Reward/action_rate: -0.1226
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 2.04s
                      Time elapsed: 00:41:26
                               ETA: 00:10:31

################################################################################
                     [1m Learning iteration 1197/1500 [0m                     

                       Computation: 48433 steps/s (collection: 1.917s, learning 0.113s)
             Mean action noise std: 4.60
          Mean value_function loss: 69.6361
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 75.2445
                       Mean reward: 563.37
               Mean episode length: 242.14
    Episode_Reward/reaching_object: 1.4011
    Episode_Reward/rotating_object: 101.4054
        Episode_Reward/action_rate: -0.1276
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 2.03s
                      Time elapsed: 00:41:28
                               ETA: 00:10:29

################################################################################
                     [1m Learning iteration 1198/1500 [0m                     

                       Computation: 48907 steps/s (collection: 1.900s, learning 0.110s)
             Mean action noise std: 4.60
          Mean value_function loss: 73.3458
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 75.2585
                       Mean reward: 522.56
               Mean episode length: 231.17
    Episode_Reward/reaching_object: 1.3412
    Episode_Reward/rotating_object: 95.6185
        Episode_Reward/action_rate: -0.1245
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 2.01s
                      Time elapsed: 00:41:30
                               ETA: 00:10:27

################################################################################
                     [1m Learning iteration 1199/1500 [0m                     

                       Computation: 49024 steps/s (collection: 1.895s, learning 0.110s)
             Mean action noise std: 4.60
          Mean value_function loss: 80.7754
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 75.2690
                       Mean reward: 528.58
               Mean episode length: 241.82
    Episode_Reward/reaching_object: 1.3594
    Episode_Reward/rotating_object: 97.4701
        Episode_Reward/action_rate: -0.1252
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 2.01s
                      Time elapsed: 00:41:32
                               ETA: 00:10:25

################################################################################
                     [1m Learning iteration 1200/1500 [0m                     

                       Computation: 49366 steps/s (collection: 1.882s, learning 0.110s)
             Mean action noise std: 4.60
          Mean value_function loss: 76.8460
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 75.2828
                       Mean reward: 492.81
               Mean episode length: 228.83
    Episode_Reward/reaching_object: 1.3613
    Episode_Reward/rotating_object: 97.2081
        Episode_Reward/action_rate: -0.1254
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 1.99s
                      Time elapsed: 00:41:34
                               ETA: 00:10:23

################################################################################
                     [1m Learning iteration 1201/1500 [0m                     

                       Computation: 49301 steps/s (collection: 1.882s, learning 0.112s)
             Mean action noise std: 4.61
          Mean value_function loss: 80.3792
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 75.2950
                       Mean reward: 485.21
               Mean episode length: 231.41
    Episode_Reward/reaching_object: 1.3215
    Episode_Reward/rotating_object: 95.8452
        Episode_Reward/action_rate: -0.1241
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 1.99s
                      Time elapsed: 00:41:36
                               ETA: 00:10:20

################################################################################
                     [1m Learning iteration 1202/1500 [0m                     

                       Computation: 49122 steps/s (collection: 1.892s, learning 0.109s)
             Mean action noise std: 4.61
          Mean value_function loss: 81.4104
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 75.3109
                       Mean reward: 514.41
               Mean episode length: 232.73
    Episode_Reward/reaching_object: 1.3361
    Episode_Reward/rotating_object: 98.8965
        Episode_Reward/action_rate: -0.1253
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 2.00s
                      Time elapsed: 00:41:38
                               ETA: 00:10:18

################################################################################
                     [1m Learning iteration 1203/1500 [0m                     

                       Computation: 48920 steps/s (collection: 1.900s, learning 0.110s)
             Mean action noise std: 4.61
          Mean value_function loss: 74.8738
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 75.3264
                       Mean reward: 522.56
               Mean episode length: 236.12
    Episode_Reward/reaching_object: 1.3481
    Episode_Reward/rotating_object: 97.9688
        Episode_Reward/action_rate: -0.1250
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 2.01s
                      Time elapsed: 00:41:40
                               ETA: 00:10:16

################################################################################
                     [1m Learning iteration 1204/1500 [0m                     

                       Computation: 48534 steps/s (collection: 1.916s, learning 0.110s)
             Mean action noise std: 4.62
          Mean value_function loss: 70.2816
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 75.3422
                       Mean reward: 547.57
               Mean episode length: 234.76
    Episode_Reward/reaching_object: 1.3927
    Episode_Reward/rotating_object: 104.3941
        Episode_Reward/action_rate: -0.1290
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 2.03s
                      Time elapsed: 00:41:42
                               ETA: 00:10:14

################################################################################
                     [1m Learning iteration 1205/1500 [0m                     

                       Computation: 47751 steps/s (collection: 1.945s, learning 0.114s)
             Mean action noise std: 4.62
          Mean value_function loss: 73.2851
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 75.3595
                       Mean reward: 518.36
               Mean episode length: 233.80
    Episode_Reward/reaching_object: 1.3548
    Episode_Reward/rotating_object: 97.4855
        Episode_Reward/action_rate: -0.1267
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 2.06s
                      Time elapsed: 00:41:44
                               ETA: 00:10:12

################################################################################
                     [1m Learning iteration 1206/1500 [0m                     

                       Computation: 46392 steps/s (collection: 2.005s, learning 0.114s)
             Mean action noise std: 4.62
          Mean value_function loss: 76.5506
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 75.3758
                       Mean reward: 511.98
               Mean episode length: 237.74
    Episode_Reward/reaching_object: 1.3442
    Episode_Reward/rotating_object: 98.6268
        Episode_Reward/action_rate: -0.1255
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 2.12s
                      Time elapsed: 00:41:46
                               ETA: 00:10:10

################################################################################
                     [1m Learning iteration 1207/1500 [0m                     

                       Computation: 48040 steps/s (collection: 1.936s, learning 0.110s)
             Mean action noise std: 4.63
          Mean value_function loss: 78.6196
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 75.3939
                       Mean reward: 558.70
               Mean episode length: 238.78
    Episode_Reward/reaching_object: 1.3934
    Episode_Reward/rotating_object: 102.8482
        Episode_Reward/action_rate: -0.1291
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 2.05s
                      Time elapsed: 00:41:48
                               ETA: 00:10:08

################################################################################
                     [1m Learning iteration 1208/1500 [0m                     

                       Computation: 48192 steps/s (collection: 1.924s, learning 0.115s)
             Mean action noise std: 4.63
          Mean value_function loss: 79.5891
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 75.4106
                       Mean reward: 513.33
               Mean episode length: 238.77
    Episode_Reward/reaching_object: 1.3675
    Episode_Reward/rotating_object: 99.0648
        Episode_Reward/action_rate: -0.1282
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 2.04s
                      Time elapsed: 00:41:50
                               ETA: 00:10:06

################################################################################
                     [1m Learning iteration 1209/1500 [0m                     

                       Computation: 47755 steps/s (collection: 1.945s, learning 0.113s)
             Mean action noise std: 4.63
          Mean value_function loss: 71.1378
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 75.4213
                       Mean reward: 451.87
               Mean episode length: 228.68
    Episode_Reward/reaching_object: 1.3523
    Episode_Reward/rotating_object: 94.9202
        Episode_Reward/action_rate: -0.1282
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 2.06s
                      Time elapsed: 00:41:52
                               ETA: 00:10:04

################################################################################
                     [1m Learning iteration 1210/1500 [0m                     

                       Computation: 47868 steps/s (collection: 1.940s, learning 0.114s)
             Mean action noise std: 4.64
          Mean value_function loss: 73.8150
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 75.4360
                       Mean reward: 483.93
               Mean episode length: 220.39
    Episode_Reward/reaching_object: 1.3809
    Episode_Reward/rotating_object: 100.1872
        Episode_Reward/action_rate: -0.1287
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 2.05s
                      Time elapsed: 00:41:54
                               ETA: 00:10:02

################################################################################
                     [1m Learning iteration 1211/1500 [0m                     

                       Computation: 47590 steps/s (collection: 1.950s, learning 0.116s)
             Mean action noise std: 4.64
          Mean value_function loss: 76.1661
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 75.4557
                       Mean reward: 531.63
               Mean episode length: 235.81
    Episode_Reward/reaching_object: 1.3647
    Episode_Reward/rotating_object: 100.1922
        Episode_Reward/action_rate: -0.1287
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 2.07s
                      Time elapsed: 00:41:56
                               ETA: 00:10:00

################################################################################
                     [1m Learning iteration 1212/1500 [0m                     

                       Computation: 48256 steps/s (collection: 1.923s, learning 0.114s)
             Mean action noise std: 4.64
          Mean value_function loss: 70.6498
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 75.4749
                       Mean reward: 501.26
               Mean episode length: 238.33
    Episode_Reward/reaching_object: 1.3884
    Episode_Reward/rotating_object: 102.4930
        Episode_Reward/action_rate: -0.1305
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 2.04s
                      Time elapsed: 00:41:58
                               ETA: 00:09:58

################################################################################
                     [1m Learning iteration 1213/1500 [0m                     

                       Computation: 48132 steps/s (collection: 1.929s, learning 0.114s)
             Mean action noise std: 4.65
          Mean value_function loss: 71.9283
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 75.4886
                       Mean reward: 491.37
               Mean episode length: 228.87
    Episode_Reward/reaching_object: 1.3510
    Episode_Reward/rotating_object: 98.4963
        Episode_Reward/action_rate: -0.1276
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 2.04s
                      Time elapsed: 00:42:00
                               ETA: 00:09:55

################################################################################
                     [1m Learning iteration 1214/1500 [0m                     

                       Computation: 47944 steps/s (collection: 1.938s, learning 0.113s)
             Mean action noise std: 4.65
          Mean value_function loss: 80.4455
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 75.5091
                       Mean reward: 505.42
               Mean episode length: 235.74
    Episode_Reward/reaching_object: 1.3764
    Episode_Reward/rotating_object: 101.8566
        Episode_Reward/action_rate: -0.1291
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 2.05s
                      Time elapsed: 00:42:02
                               ETA: 00:09:53

################################################################################
                     [1m Learning iteration 1215/1500 [0m                     

                       Computation: 48533 steps/s (collection: 1.912s, learning 0.114s)
             Mean action noise std: 4.65
          Mean value_function loss: 69.2876
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 75.5256
                       Mean reward: 491.93
               Mean episode length: 232.53
    Episode_Reward/reaching_object: 1.3811
    Episode_Reward/rotating_object: 100.1945
        Episode_Reward/action_rate: -0.1307
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 2.03s
                      Time elapsed: 00:42:04
                               ETA: 00:09:51

################################################################################
                     [1m Learning iteration 1216/1500 [0m                     

                       Computation: 48045 steps/s (collection: 1.931s, learning 0.115s)
             Mean action noise std: 4.66
          Mean value_function loss: 73.0763
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 75.5406
                       Mean reward: 518.87
               Mean episode length: 241.22
    Episode_Reward/reaching_object: 1.3912
    Episode_Reward/rotating_object: 104.6701
        Episode_Reward/action_rate: -0.1311
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 2.05s
                      Time elapsed: 00:42:06
                               ETA: 00:09:49

################################################################################
                     [1m Learning iteration 1217/1500 [0m                     

                       Computation: 48244 steps/s (collection: 1.926s, learning 0.112s)
             Mean action noise std: 4.66
          Mean value_function loss: 75.4104
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 75.5634
                       Mean reward: 520.58
               Mean episode length: 242.80
    Episode_Reward/reaching_object: 1.3645
    Episode_Reward/rotating_object: 100.4119
        Episode_Reward/action_rate: -0.1296
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 2.04s
                      Time elapsed: 00:42:08
                               ETA: 00:09:47

################################################################################
                     [1m Learning iteration 1218/1500 [0m                     

                       Computation: 48231 steps/s (collection: 1.924s, learning 0.114s)
             Mean action noise std: 4.66
          Mean value_function loss: 76.4159
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 75.5819
                       Mean reward: 509.61
               Mean episode length: 227.12
    Episode_Reward/reaching_object: 1.3348
    Episode_Reward/rotating_object: 100.9286
        Episode_Reward/action_rate: -0.1269
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 2.04s
                      Time elapsed: 00:42:10
                               ETA: 00:09:45

################################################################################
                     [1m Learning iteration 1219/1500 [0m                     

                       Computation: 48502 steps/s (collection: 1.917s, learning 0.110s)
             Mean action noise std: 4.67
          Mean value_function loss: 75.2005
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 75.5957
                       Mean reward: 485.20
               Mean episode length: 235.60
    Episode_Reward/reaching_object: 1.3322
    Episode_Reward/rotating_object: 95.3338
        Episode_Reward/action_rate: -0.1291
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 2.03s
                      Time elapsed: 00:42:13
                               ETA: 00:09:43

################################################################################
                     [1m Learning iteration 1220/1500 [0m                     

                       Computation: 48413 steps/s (collection: 1.920s, learning 0.111s)
             Mean action noise std: 4.67
          Mean value_function loss: 77.1424
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 75.6097
                       Mean reward: 479.44
               Mean episode length: 226.68
    Episode_Reward/reaching_object: 1.3242
    Episode_Reward/rotating_object: 97.7143
        Episode_Reward/action_rate: -0.1272
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 2.03s
                      Time elapsed: 00:42:15
                               ETA: 00:09:41

################################################################################
                     [1m Learning iteration 1221/1500 [0m                     

                       Computation: 48947 steps/s (collection: 1.898s, learning 0.110s)
             Mean action noise std: 4.67
          Mean value_function loss: 74.0653
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 75.6243
                       Mean reward: 473.06
               Mean episode length: 222.19
    Episode_Reward/reaching_object: 1.3538
    Episode_Reward/rotating_object: 101.0823
        Episode_Reward/action_rate: -0.1305
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 2.01s
                      Time elapsed: 00:42:17
                               ETA: 00:09:39

################################################################################
                     [1m Learning iteration 1222/1500 [0m                     

                       Computation: 49325 steps/s (collection: 1.883s, learning 0.110s)
             Mean action noise std: 4.68
          Mean value_function loss: 74.5085
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 75.6381
                       Mean reward: 545.34
               Mean episode length: 241.26
    Episode_Reward/reaching_object: 1.3406
    Episode_Reward/rotating_object: 100.9762
        Episode_Reward/action_rate: -0.1309
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 1.99s
                      Time elapsed: 00:42:19
                               ETA: 00:09:37

################################################################################
                     [1m Learning iteration 1223/1500 [0m                     

                       Computation: 49836 steps/s (collection: 1.862s, learning 0.111s)
             Mean action noise std: 4.68
          Mean value_function loss: 79.2703
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 75.6585
                       Mean reward: 533.83
               Mean episode length: 243.76
    Episode_Reward/reaching_object: 1.3582
    Episode_Reward/rotating_object: 100.6508
        Episode_Reward/action_rate: -0.1327
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 1.97s
                      Time elapsed: 00:42:21
                               ETA: 00:09:35

################################################################################
                     [1m Learning iteration 1224/1500 [0m                     

                       Computation: 49342 steps/s (collection: 1.882s, learning 0.110s)
             Mean action noise std: 4.68
          Mean value_function loss: 82.5217
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 75.6807
                       Mean reward: 486.30
               Mean episode length: 223.29
    Episode_Reward/reaching_object: 1.3284
    Episode_Reward/rotating_object: 99.9457
        Episode_Reward/action_rate: -0.1296
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 1.99s
                      Time elapsed: 00:42:23
                               ETA: 00:09:32

################################################################################
                     [1m Learning iteration 1225/1500 [0m                     

                       Computation: 49281 steps/s (collection: 1.885s, learning 0.110s)
             Mean action noise std: 4.69
          Mean value_function loss: 80.3823
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 75.6947
                       Mean reward: 495.20
               Mean episode length: 242.71
    Episode_Reward/reaching_object: 1.3450
    Episode_Reward/rotating_object: 100.6540
        Episode_Reward/action_rate: -0.1308
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 1.99s
                      Time elapsed: 00:42:24
                               ETA: 00:09:30

################################################################################
                     [1m Learning iteration 1226/1500 [0m                     

                       Computation: 49541 steps/s (collection: 1.874s, learning 0.110s)
             Mean action noise std: 4.69
          Mean value_function loss: 80.1855
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 75.7074
                       Mean reward: 544.03
               Mean episode length: 233.79
    Episode_Reward/reaching_object: 1.3286
    Episode_Reward/rotating_object: 99.9565
        Episode_Reward/action_rate: -0.1285
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 1.98s
                      Time elapsed: 00:42:26
                               ETA: 00:09:28

################################################################################
                     [1m Learning iteration 1227/1500 [0m                     

                       Computation: 48713 steps/s (collection: 1.908s, learning 0.110s)
             Mean action noise std: 4.69
          Mean value_function loss: 74.8141
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 75.7184
                       Mean reward: 505.12
               Mean episode length: 239.45
    Episode_Reward/reaching_object: 1.3778
    Episode_Reward/rotating_object: 102.0913
        Episode_Reward/action_rate: -0.1339
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 2.02s
                      Time elapsed: 00:42:29
                               ETA: 00:09:26

################################################################################
                     [1m Learning iteration 1228/1500 [0m                     

                       Computation: 48737 steps/s (collection: 1.907s, learning 0.110s)
             Mean action noise std: 4.69
          Mean value_function loss: 80.0505
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 75.7359
                       Mean reward: 503.84
               Mean episode length: 242.31
    Episode_Reward/reaching_object: 1.3845
    Episode_Reward/rotating_object: 105.1351
        Episode_Reward/action_rate: -0.1333
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 2.02s
                      Time elapsed: 00:42:31
                               ETA: 00:09:24

################################################################################
                     [1m Learning iteration 1229/1500 [0m                     

                       Computation: 47943 steps/s (collection: 1.940s, learning 0.110s)
             Mean action noise std: 4.70
          Mean value_function loss: 74.8627
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 75.7515
                       Mean reward: 483.43
               Mean episode length: 228.84
    Episode_Reward/reaching_object: 1.3649
    Episode_Reward/rotating_object: 99.4473
        Episode_Reward/action_rate: -0.1318
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 2.05s
                      Time elapsed: 00:42:33
                               ETA: 00:09:22

################################################################################
                     [1m Learning iteration 1230/1500 [0m                     

                       Computation: 48677 steps/s (collection: 1.903s, learning 0.117s)
             Mean action noise std: 4.70
          Mean value_function loss: 74.0951
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 75.7579
                       Mean reward: 519.42
               Mean episode length: 235.88
    Episode_Reward/reaching_object: 1.3814
    Episode_Reward/rotating_object: 101.8827
        Episode_Reward/action_rate: -0.1318
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 2.02s
                      Time elapsed: 00:42:35
                               ETA: 00:09:20

################################################################################
                     [1m Learning iteration 1231/1500 [0m                     

                       Computation: 48187 steps/s (collection: 1.922s, learning 0.118s)
             Mean action noise std: 4.70
          Mean value_function loss: 69.1098
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 75.7669
                       Mean reward: 538.81
               Mean episode length: 229.40
    Episode_Reward/reaching_object: 1.3629
    Episode_Reward/rotating_object: 101.6394
        Episode_Reward/action_rate: -0.1317
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 18.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 2.04s
                      Time elapsed: 00:42:37
                               ETA: 00:09:18

################################################################################
                     [1m Learning iteration 1232/1500 [0m                     

                       Computation: 48500 steps/s (collection: 1.916s, learning 0.111s)
             Mean action noise std: 4.70
          Mean value_function loss: 91.2748
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 75.7810
                       Mean reward: 470.53
               Mean episode length: 217.05
    Episode_Reward/reaching_object: 1.3359
    Episode_Reward/rotating_object: 99.1084
        Episode_Reward/action_rate: -0.1296
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 2.03s
                      Time elapsed: 00:42:39
                               ETA: 00:09:16

################################################################################
                     [1m Learning iteration 1233/1500 [0m                     

                       Computation: 48262 steps/s (collection: 1.926s, learning 0.111s)
             Mean action noise std: 4.71
          Mean value_function loss: 80.8925
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 75.7981
                       Mean reward: 538.36
               Mean episode length: 236.50
    Episode_Reward/reaching_object: 1.3875
    Episode_Reward/rotating_object: 103.8565
        Episode_Reward/action_rate: -0.1330
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 2.04s
                      Time elapsed: 00:42:41
                               ETA: 00:09:14

################################################################################
                     [1m Learning iteration 1234/1500 [0m                     

                       Computation: 48374 steps/s (collection: 1.918s, learning 0.114s)
             Mean action noise std: 4.71
          Mean value_function loss: 79.5079
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 75.8149
                       Mean reward: 468.57
               Mean episode length: 227.40
    Episode_Reward/reaching_object: 1.3519
    Episode_Reward/rotating_object: 99.6442
        Episode_Reward/action_rate: -0.1301
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 2.03s
                      Time elapsed: 00:42:43
                               ETA: 00:09:12

################################################################################
                     [1m Learning iteration 1235/1500 [0m                     

                       Computation: 48296 steps/s (collection: 1.920s, learning 0.115s)
             Mean action noise std: 4.72
          Mean value_function loss: 83.2607
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 75.8368
                       Mean reward: 510.55
               Mean episode length: 235.14
    Episode_Reward/reaching_object: 1.3479
    Episode_Reward/rotating_object: 97.1663
        Episode_Reward/action_rate: -0.1322
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 2.04s
                      Time elapsed: 00:42:45
                               ETA: 00:09:09

################################################################################
                     [1m Learning iteration 1236/1500 [0m                     

                       Computation: 48461 steps/s (collection: 1.915s, learning 0.113s)
             Mean action noise std: 4.72
          Mean value_function loss: 81.6537
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 75.8585
                       Mean reward: 516.11
               Mean episode length: 238.17
    Episode_Reward/reaching_object: 1.3572
    Episode_Reward/rotating_object: 97.5887
        Episode_Reward/action_rate: -0.1320
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 2.03s
                      Time elapsed: 00:42:47
                               ETA: 00:09:07

################################################################################
                     [1m Learning iteration 1237/1500 [0m                     

                       Computation: 48082 steps/s (collection: 1.932s, learning 0.113s)
             Mean action noise std: 4.72
          Mean value_function loss: 80.4785
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 75.8702
                       Mean reward: 493.73
               Mean episode length: 223.71
    Episode_Reward/reaching_object: 1.3420
    Episode_Reward/rotating_object: 98.1063
        Episode_Reward/action_rate: -0.1310
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 2.04s
                      Time elapsed: 00:42:49
                               ETA: 00:09:05

################################################################################
                     [1m Learning iteration 1238/1500 [0m                     

                       Computation: 48171 steps/s (collection: 1.930s, learning 0.111s)
             Mean action noise std: 4.73
          Mean value_function loss: 78.8381
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 75.8892
                       Mean reward: 544.14
               Mean episode length: 240.79
    Episode_Reward/reaching_object: 1.3976
    Episode_Reward/rotating_object: 104.0621
        Episode_Reward/action_rate: -0.1349
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 2.04s
                      Time elapsed: 00:42:51
                               ETA: 00:09:03

################################################################################
                     [1m Learning iteration 1239/1500 [0m                     

                       Computation: 48362 steps/s (collection: 1.918s, learning 0.115s)
             Mean action noise std: 4.73
          Mean value_function loss: 88.6860
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 75.9088
                       Mean reward: 551.99
               Mean episode length: 235.29
    Episode_Reward/reaching_object: 1.3556
    Episode_Reward/rotating_object: 101.7397
        Episode_Reward/action_rate: -0.1307
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 2.03s
                      Time elapsed: 00:42:53
                               ETA: 00:09:01

################################################################################
                     [1m Learning iteration 1240/1500 [0m                     

                       Computation: 48111 steps/s (collection: 1.928s, learning 0.115s)
             Mean action noise std: 4.73
          Mean value_function loss: 74.2738
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 75.9273
                       Mean reward: 534.33
               Mean episode length: 226.99
    Episode_Reward/reaching_object: 1.3603
    Episode_Reward/rotating_object: 101.7299
        Episode_Reward/action_rate: -0.1318
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 2.04s
                      Time elapsed: 00:42:55
                               ETA: 00:08:59

################################################################################
                     [1m Learning iteration 1241/1500 [0m                     

                       Computation: 48515 steps/s (collection: 1.916s, learning 0.111s)
             Mean action noise std: 4.74
          Mean value_function loss: 76.3633
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 75.9487
                       Mean reward: 564.30
               Mean episode length: 231.64
    Episode_Reward/reaching_object: 1.3396
    Episode_Reward/rotating_object: 98.6195
        Episode_Reward/action_rate: -0.1311
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 2.03s
                      Time elapsed: 00:42:57
                               ETA: 00:08:57

################################################################################
                     [1m Learning iteration 1242/1500 [0m                     

                       Computation: 48367 steps/s (collection: 1.922s, learning 0.111s)
             Mean action noise std: 4.74
          Mean value_function loss: 75.3829
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 75.9700
                       Mean reward: 476.74
               Mean episode length: 237.68
    Episode_Reward/reaching_object: 1.3984
    Episode_Reward/rotating_object: 101.3609
        Episode_Reward/action_rate: -0.1370
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 2.03s
                      Time elapsed: 00:42:59
                               ETA: 00:08:55

################################################################################
                     [1m Learning iteration 1243/1500 [0m                     

                       Computation: 47888 steps/s (collection: 1.938s, learning 0.115s)
             Mean action noise std: 4.74
          Mean value_function loss: 77.4288
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 75.9822
                       Mean reward: 471.07
               Mean episode length: 220.88
    Episode_Reward/reaching_object: 1.3784
    Episode_Reward/rotating_object: 98.4071
        Episode_Reward/action_rate: -0.1349
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 2.05s
                      Time elapsed: 00:43:01
                               ETA: 00:08:53

################################################################################
                     [1m Learning iteration 1244/1500 [0m                     

                       Computation: 48396 steps/s (collection: 1.917s, learning 0.114s)
             Mean action noise std: 4.74
          Mean value_function loss: 77.0749
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 75.9911
                       Mean reward: 523.67
               Mean episode length: 233.32
    Episode_Reward/reaching_object: 1.3645
    Episode_Reward/rotating_object: 99.7343
        Episode_Reward/action_rate: -0.1327
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 2.03s
                      Time elapsed: 00:43:03
                               ETA: 00:08:51

################################################################################
                     [1m Learning iteration 1245/1500 [0m                     

                       Computation: 48958 steps/s (collection: 1.897s, learning 0.111s)
             Mean action noise std: 4.75
          Mean value_function loss: 73.4153
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 76.0005
                       Mean reward: 505.62
               Mean episode length: 236.10
    Episode_Reward/reaching_object: 1.3937
    Episode_Reward/rotating_object: 103.1380
        Episode_Reward/action_rate: -0.1358
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 2.01s
                      Time elapsed: 00:43:05
                               ETA: 00:08:49

################################################################################
                     [1m Learning iteration 1246/1500 [0m                     

                       Computation: 49040 steps/s (collection: 1.894s, learning 0.111s)
             Mean action noise std: 4.75
          Mean value_function loss: 69.3656
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 76.0176
                       Mean reward: 486.48
               Mean episode length: 232.42
    Episode_Reward/reaching_object: 1.3798
    Episode_Reward/rotating_object: 101.4346
        Episode_Reward/action_rate: -0.1356
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 2.00s
                      Time elapsed: 00:43:07
                               ETA: 00:08:47

################################################################################
                     [1m Learning iteration 1247/1500 [0m                     

                       Computation: 48917 steps/s (collection: 1.899s, learning 0.111s)
             Mean action noise std: 4.75
          Mean value_function loss: 72.8072
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 76.0324
                       Mean reward: 507.97
               Mean episode length: 235.52
    Episode_Reward/reaching_object: 1.3805
    Episode_Reward/rotating_object: 102.3783
        Episode_Reward/action_rate: -0.1344
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 2.01s
                      Time elapsed: 00:43:09
                               ETA: 00:08:44

################################################################################
                     [1m Learning iteration 1248/1500 [0m                     

                       Computation: 48806 steps/s (collection: 1.899s, learning 0.115s)
             Mean action noise std: 4.76
          Mean value_function loss: 79.7928
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 76.0488
                       Mean reward: 450.24
               Mean episode length: 235.25
    Episode_Reward/reaching_object: 1.3738
    Episode_Reward/rotating_object: 100.7155
        Episode_Reward/action_rate: -0.1356
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 2.01s
                      Time elapsed: 00:43:11
                               ETA: 00:08:42

################################################################################
                     [1m Learning iteration 1249/1500 [0m                     

                       Computation: 48899 steps/s (collection: 1.894s, learning 0.117s)
             Mean action noise std: 4.76
          Mean value_function loss: 71.6158
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 76.0728
                       Mean reward: 501.82
               Mean episode length: 226.37
    Episode_Reward/reaching_object: 1.3592
    Episode_Reward/rotating_object: 100.9497
        Episode_Reward/action_rate: -0.1337
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 2.01s
                      Time elapsed: 00:43:13
                               ETA: 00:08:40

################################################################################
                     [1m Learning iteration 1250/1500 [0m                     

                       Computation: 49121 steps/s (collection: 1.885s, learning 0.116s)
             Mean action noise std: 4.77
          Mean value_function loss: 77.9306
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 76.0933
                       Mean reward: 543.33
               Mean episode length: 226.73
    Episode_Reward/reaching_object: 1.3882
    Episode_Reward/rotating_object: 107.1160
        Episode_Reward/action_rate: -0.1357
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 2.00s
                      Time elapsed: 00:43:15
                               ETA: 00:08:38

################################################################################
                     [1m Learning iteration 1251/1500 [0m                     

                       Computation: 48703 steps/s (collection: 1.904s, learning 0.115s)
             Mean action noise std: 4.77
          Mean value_function loss: 73.7950
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 76.1178
                       Mean reward: 494.47
               Mean episode length: 229.12
    Episode_Reward/reaching_object: 1.3630
    Episode_Reward/rotating_object: 101.8259
        Episode_Reward/action_rate: -0.1348
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 2.02s
                      Time elapsed: 00:43:17
                               ETA: 00:08:36

################################################################################
                     [1m Learning iteration 1252/1500 [0m                     

                       Computation: 48561 steps/s (collection: 1.912s, learning 0.112s)
             Mean action noise std: 4.77
          Mean value_function loss: 76.8507
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 76.1388
                       Mean reward: 531.88
               Mean episode length: 232.63
    Episode_Reward/reaching_object: 1.3536
    Episode_Reward/rotating_object: 99.6912
        Episode_Reward/action_rate: -0.1334
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 2.02s
                      Time elapsed: 00:43:19
                               ETA: 00:08:34

################################################################################
                     [1m Learning iteration 1253/1500 [0m                     

                       Computation: 47143 steps/s (collection: 1.971s, learning 0.114s)
             Mean action noise std: 4.78
          Mean value_function loss: 87.8320
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 76.1571
                       Mean reward: 472.04
               Mean episode length: 220.32
    Episode_Reward/reaching_object: 1.3490
    Episode_Reward/rotating_object: 100.0071
        Episode_Reward/action_rate: -0.1332
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 2.09s
                      Time elapsed: 00:43:21
                               ETA: 00:08:32

################################################################################
                     [1m Learning iteration 1254/1500 [0m                     

                       Computation: 48067 steps/s (collection: 1.931s, learning 0.114s)
             Mean action noise std: 4.78
          Mean value_function loss: 77.7769
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 76.1809
                       Mean reward: 508.34
               Mean episode length: 234.64
    Episode_Reward/reaching_object: 1.3774
    Episode_Reward/rotating_object: 102.5384
        Episode_Reward/action_rate: -0.1364
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 2.05s
                      Time elapsed: 00:43:23
                               ETA: 00:08:30

################################################################################
                     [1m Learning iteration 1255/1500 [0m                     

                       Computation: 48124 steps/s (collection: 1.930s, learning 0.113s)
             Mean action noise std: 4.78
          Mean value_function loss: 69.3404
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 76.1997
                       Mean reward: 520.87
               Mean episode length: 225.68
    Episode_Reward/reaching_object: 1.3750
    Episode_Reward/rotating_object: 103.8244
        Episode_Reward/action_rate: -0.1359
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 2.04s
                      Time elapsed: 00:43:25
                               ETA: 00:08:28

################################################################################
                     [1m Learning iteration 1256/1500 [0m                     

                       Computation: 48111 steps/s (collection: 1.929s, learning 0.114s)
             Mean action noise std: 4.79
          Mean value_function loss: 75.4564
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 76.2138
                       Mean reward: 530.01
               Mean episode length: 238.59
    Episode_Reward/reaching_object: 1.3919
    Episode_Reward/rotating_object: 103.8052
        Episode_Reward/action_rate: -0.1380
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 2.04s
                      Time elapsed: 00:43:27
                               ETA: 00:08:26

################################################################################
                     [1m Learning iteration 1257/1500 [0m                     

                       Computation: 47940 steps/s (collection: 1.933s, learning 0.117s)
             Mean action noise std: 4.79
          Mean value_function loss: 69.9141
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 76.2357
                       Mean reward: 515.38
               Mean episode length: 235.06
    Episode_Reward/reaching_object: 1.3579
    Episode_Reward/rotating_object: 100.3988
        Episode_Reward/action_rate: -0.1361
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 2.05s
                      Time elapsed: 00:43:29
                               ETA: 00:08:24

################################################################################
                     [1m Learning iteration 1258/1500 [0m                     

                       Computation: 47872 steps/s (collection: 1.941s, learning 0.113s)
             Mean action noise std: 4.80
          Mean value_function loss: 77.0340
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 76.2511
                       Mean reward: 568.16
               Mean episode length: 243.47
    Episode_Reward/reaching_object: 1.3829
    Episode_Reward/rotating_object: 103.4261
        Episode_Reward/action_rate: -0.1380
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 2.05s
                      Time elapsed: 00:43:32
                               ETA: 00:08:22

################################################################################
                     [1m Learning iteration 1259/1500 [0m                     

                       Computation: 48167 steps/s (collection: 1.928s, learning 0.113s)
             Mean action noise std: 4.80
          Mean value_function loss: 80.7748
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 76.2758
                       Mean reward: 502.94
               Mean episode length: 232.77
    Episode_Reward/reaching_object: 1.3526
    Episode_Reward/rotating_object: 100.3609
        Episode_Reward/action_rate: -0.1355
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 2.04s
                      Time elapsed: 00:43:34
                               ETA: 00:08:19

################################################################################
                     [1m Learning iteration 1260/1500 [0m                     

                       Computation: 47982 steps/s (collection: 1.934s, learning 0.115s)
             Mean action noise std: 4.80
          Mean value_function loss: 76.5094
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 76.2961
                       Mean reward: 512.84
               Mean episode length: 226.20
    Episode_Reward/reaching_object: 1.3468
    Episode_Reward/rotating_object: 101.1660
        Episode_Reward/action_rate: -0.1367
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 2.05s
                      Time elapsed: 00:43:36
                               ETA: 00:08:17

################################################################################
                     [1m Learning iteration 1261/1500 [0m                     

                       Computation: 48301 steps/s (collection: 1.922s, learning 0.113s)
             Mean action noise std: 4.81
          Mean value_function loss: 72.8883
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 76.3169
                       Mean reward: 526.89
               Mean episode length: 227.60
    Episode_Reward/reaching_object: 1.3521
    Episode_Reward/rotating_object: 102.6329
        Episode_Reward/action_rate: -0.1355
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 2.04s
                      Time elapsed: 00:43:38
                               ETA: 00:08:15

################################################################################
                     [1m Learning iteration 1262/1500 [0m                     

                       Computation: 47985 steps/s (collection: 1.936s, learning 0.112s)
             Mean action noise std: 4.81
          Mean value_function loss: 72.0655
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 76.3362
                       Mean reward: 514.33
               Mean episode length: 238.29
    Episode_Reward/reaching_object: 1.3940
    Episode_Reward/rotating_object: 101.9491
        Episode_Reward/action_rate: -0.1402
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 2.05s
                      Time elapsed: 00:43:40
                               ETA: 00:08:13

################################################################################
                     [1m Learning iteration 1263/1500 [0m                     

                       Computation: 47921 steps/s (collection: 1.939s, learning 0.112s)
             Mean action noise std: 4.82
          Mean value_function loss: 79.1287
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 76.3486
                       Mean reward: 522.99
               Mean episode length: 239.70
    Episode_Reward/reaching_object: 1.3608
    Episode_Reward/rotating_object: 99.7182
        Episode_Reward/action_rate: -0.1373
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 2.05s
                      Time elapsed: 00:43:42
                               ETA: 00:08:11

################################################################################
                     [1m Learning iteration 1264/1500 [0m                     

                       Computation: 48300 steps/s (collection: 1.925s, learning 0.110s)
             Mean action noise std: 4.82
          Mean value_function loss: 85.6013
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 76.3628
                       Mean reward: 497.25
               Mean episode length: 224.64
    Episode_Reward/reaching_object: 1.3304
    Episode_Reward/rotating_object: 97.1735
        Episode_Reward/action_rate: -0.1345
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 2.04s
                      Time elapsed: 00:43:44
                               ETA: 00:08:09

################################################################################
                     [1m Learning iteration 1265/1500 [0m                     

                       Computation: 47629 steps/s (collection: 1.935s, learning 0.129s)
             Mean action noise std: 4.82
          Mean value_function loss: 77.7995
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 76.3861
                       Mean reward: 515.42
               Mean episode length: 230.63
    Episode_Reward/reaching_object: 1.3796
    Episode_Reward/rotating_object: 104.9781
        Episode_Reward/action_rate: -0.1398
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 2.06s
                      Time elapsed: 00:43:46
                               ETA: 00:08:07

################################################################################
                     [1m Learning iteration 1266/1500 [0m                     

                       Computation: 44515 steps/s (collection: 2.083s, learning 0.126s)
             Mean action noise std: 4.83
          Mean value_function loss: 81.8314
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 76.4055
                       Mean reward: 509.68
               Mean episode length: 226.67
    Episode_Reward/reaching_object: 1.3342
    Episode_Reward/rotating_object: 99.0153
        Episode_Reward/action_rate: -0.1359
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 2.21s
                      Time elapsed: 00:43:48
                               ETA: 00:08:05

################################################################################
                     [1m Learning iteration 1267/1500 [0m                     

                       Computation: 44042 steps/s (collection: 2.107s, learning 0.125s)
             Mean action noise std: 4.83
          Mean value_function loss: 83.9895
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 76.4161
                       Mean reward: 506.88
               Mean episode length: 236.15
    Episode_Reward/reaching_object: 1.3785
    Episode_Reward/rotating_object: 99.3859
        Episode_Reward/action_rate: -0.1397
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 2.23s
                      Time elapsed: 00:43:50
                               ETA: 00:08:03

################################################################################
                     [1m Learning iteration 1268/1500 [0m                     

                       Computation: 44904 steps/s (collection: 2.064s, learning 0.125s)
             Mean action noise std: 4.83
          Mean value_function loss: 77.2611
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 76.4270
                       Mean reward: 501.29
               Mean episode length: 235.35
    Episode_Reward/reaching_object: 1.3603
    Episode_Reward/rotating_object: 100.3011
        Episode_Reward/action_rate: -0.1388
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 2.19s
                      Time elapsed: 00:43:52
                               ETA: 00:08:01

################################################################################
                     [1m Learning iteration 1269/1500 [0m                     

                       Computation: 45289 steps/s (collection: 2.045s, learning 0.125s)
             Mean action noise std: 4.83
          Mean value_function loss: 69.6030
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 76.4434
                       Mean reward: 508.09
               Mean episode length: 234.26
    Episode_Reward/reaching_object: 1.3801
    Episode_Reward/rotating_object: 103.2960
        Episode_Reward/action_rate: -0.1402
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 2.17s
                      Time elapsed: 00:43:55
                               ETA: 00:07:59

################################################################################
                     [1m Learning iteration 1270/1500 [0m                     

                       Computation: 45375 steps/s (collection: 2.041s, learning 0.125s)
             Mean action noise std: 4.84
          Mean value_function loss: 78.0838
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 76.4632
                       Mean reward: 508.38
               Mean episode length: 229.05
    Episode_Reward/reaching_object: 1.3413
    Episode_Reward/rotating_object: 100.0647
        Episode_Reward/action_rate: -0.1369
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 2.17s
                      Time elapsed: 00:43:57
                               ETA: 00:07:57

################################################################################
                     [1m Learning iteration 1271/1500 [0m                     

                       Computation: 43743 steps/s (collection: 2.115s, learning 0.132s)
             Mean action noise std: 4.84
          Mean value_function loss: 78.1670
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 76.4831
                       Mean reward: 483.11
               Mean episode length: 231.73
    Episode_Reward/reaching_object: 1.3998
    Episode_Reward/rotating_object: 103.4942
        Episode_Reward/action_rate: -0.1405
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 2.25s
                      Time elapsed: 00:43:59
                               ETA: 00:07:55

################################################################################
                     [1m Learning iteration 1272/1500 [0m                     

                       Computation: 44992 steps/s (collection: 2.060s, learning 0.125s)
             Mean action noise std: 4.85
          Mean value_function loss: 84.7432
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 76.4993
                       Mean reward: 510.92
               Mean episode length: 229.08
    Episode_Reward/reaching_object: 1.3401
    Episode_Reward/rotating_object: 96.5961
        Episode_Reward/action_rate: -0.1368
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 2.18s
                      Time elapsed: 00:44:01
                               ETA: 00:07:53

################################################################################
                     [1m Learning iteration 1273/1500 [0m                     

                       Computation: 44608 steps/s (collection: 2.076s, learning 0.128s)
             Mean action noise std: 4.85
          Mean value_function loss: 82.1442
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 76.5168
                       Mean reward: 510.88
               Mean episode length: 219.69
    Episode_Reward/reaching_object: 1.3423
    Episode_Reward/rotating_object: 99.7130
        Episode_Reward/action_rate: -0.1379
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 2.20s
                      Time elapsed: 00:44:03
                               ETA: 00:07:51

################################################################################
                     [1m Learning iteration 1274/1500 [0m                     

                       Computation: 43775 steps/s (collection: 2.105s, learning 0.141s)
             Mean action noise std: 4.85
          Mean value_function loss: 78.4717
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 76.5378
                       Mean reward: 452.36
               Mean episode length: 220.10
    Episode_Reward/reaching_object: 1.3585
    Episode_Reward/rotating_object: 98.6735
        Episode_Reward/action_rate: -0.1387
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 2.25s
                      Time elapsed: 00:44:06
                               ETA: 00:07:49

################################################################################
                     [1m Learning iteration 1275/1500 [0m                     

                       Computation: 44445 steps/s (collection: 2.094s, learning 0.118s)
             Mean action noise std: 4.86
          Mean value_function loss: 77.9475
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 76.5513
                       Mean reward: 494.26
               Mean episode length: 232.54
    Episode_Reward/reaching_object: 1.3591
    Episode_Reward/rotating_object: 99.9812
        Episode_Reward/action_rate: -0.1386
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 2.21s
                      Time elapsed: 00:44:08
                               ETA: 00:07:46

################################################################################
                     [1m Learning iteration 1276/1500 [0m                     

                       Computation: 47920 steps/s (collection: 1.938s, learning 0.113s)
             Mean action noise std: 4.86
          Mean value_function loss: 93.5616
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 76.5642
                       Mean reward: 523.18
               Mean episode length: 236.94
    Episode_Reward/reaching_object: 1.3946
    Episode_Reward/rotating_object: 102.5126
        Episode_Reward/action_rate: -0.1418
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 2.05s
                      Time elapsed: 00:44:10
                               ETA: 00:07:44

################################################################################
                     [1m Learning iteration 1277/1500 [0m                     

                       Computation: 45750 steps/s (collection: 2.033s, learning 0.116s)
             Mean action noise std: 4.86
          Mean value_function loss: 89.4832
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 76.5843
                       Mean reward: 483.89
               Mean episode length: 224.89
    Episode_Reward/reaching_object: 1.3200
    Episode_Reward/rotating_object: 97.2090
        Episode_Reward/action_rate: -0.1360
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 2.15s
                      Time elapsed: 00:44:12
                               ETA: 00:07:42

################################################################################
                     [1m Learning iteration 1278/1500 [0m                     

                       Computation: 47176 steps/s (collection: 1.966s, learning 0.117s)
             Mean action noise std: 4.87
          Mean value_function loss: 92.1842
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 76.5986
                       Mean reward: 477.40
               Mean episode length: 216.60
    Episode_Reward/reaching_object: 1.3616
    Episode_Reward/rotating_object: 101.2058
        Episode_Reward/action_rate: -0.1380
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 2.08s
                      Time elapsed: 00:44:14
                               ETA: 00:07:40

################################################################################
                     [1m Learning iteration 1279/1500 [0m                     

                       Computation: 47730 steps/s (collection: 1.947s, learning 0.113s)
             Mean action noise std: 4.87
          Mean value_function loss: 82.5002
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 76.6040
                       Mean reward: 473.06
               Mean episode length: 225.35
    Episode_Reward/reaching_object: 1.3853
    Episode_Reward/rotating_object: 101.5562
        Episode_Reward/action_rate: -0.1400
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 2.06s
                      Time elapsed: 00:44:16
                               ETA: 00:07:38

################################################################################
                     [1m Learning iteration 1280/1500 [0m                     

                       Computation: 47579 steps/s (collection: 1.943s, learning 0.123s)
             Mean action noise std: 4.87
          Mean value_function loss: 76.1568
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 76.6165
                       Mean reward: 512.89
               Mean episode length: 226.40
    Episode_Reward/reaching_object: 1.3577
    Episode_Reward/rotating_object: 98.5338
        Episode_Reward/action_rate: -0.1378
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 2.07s
                      Time elapsed: 00:44:18
                               ETA: 00:07:36

################################################################################
                     [1m Learning iteration 1281/1500 [0m                     

                       Computation: 47676 steps/s (collection: 1.950s, learning 0.112s)
             Mean action noise std: 4.87
          Mean value_function loss: 78.3562
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 76.6323
                       Mean reward: 536.76
               Mean episode length: 231.31
    Episode_Reward/reaching_object: 1.4000
    Episode_Reward/rotating_object: 102.8835
        Episode_Reward/action_rate: -0.1425
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 2.06s
                      Time elapsed: 00:44:20
                               ETA: 00:07:34

################################################################################
                     [1m Learning iteration 1282/1500 [0m                     

                       Computation: 47315 steps/s (collection: 1.966s, learning 0.112s)
             Mean action noise std: 4.88
          Mean value_function loss: 92.2437
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 76.6472
                       Mean reward: 473.76
               Mean episode length: 224.20
    Episode_Reward/reaching_object: 1.3639
    Episode_Reward/rotating_object: 93.4123
        Episode_Reward/action_rate: -0.1399
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 2.08s
                      Time elapsed: 00:44:22
                               ETA: 00:07:32

################################################################################
                     [1m Learning iteration 1283/1500 [0m                     

                       Computation: 47347 steps/s (collection: 1.958s, learning 0.118s)
             Mean action noise std: 4.88
          Mean value_function loss: 82.0919
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 76.6645
                       Mean reward: 554.02
               Mean episode length: 237.28
    Episode_Reward/reaching_object: 1.3985
    Episode_Reward/rotating_object: 102.2925
        Episode_Reward/action_rate: -0.1423
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 2.08s
                      Time elapsed: 00:44:25
                               ETA: 00:07:30

################################################################################
                     [1m Learning iteration 1284/1500 [0m                     

                       Computation: 47699 steps/s (collection: 1.951s, learning 0.110s)
             Mean action noise std: 4.88
          Mean value_function loss: 87.8085
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 76.6822
                       Mean reward: 502.27
               Mean episode length: 225.20
    Episode_Reward/reaching_object: 1.3480
    Episode_Reward/rotating_object: 95.0020
        Episode_Reward/action_rate: -0.1384
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 2.06s
                      Time elapsed: 00:44:27
                               ETA: 00:07:28

################################################################################
                     [1m Learning iteration 1285/1500 [0m                     

                       Computation: 47609 steps/s (collection: 1.955s, learning 0.110s)
             Mean action noise std: 4.89
          Mean value_function loss: 87.3418
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 76.6948
                       Mean reward: 512.67
               Mean episode length: 229.54
    Episode_Reward/reaching_object: 1.3925
    Episode_Reward/rotating_object: 101.4838
        Episode_Reward/action_rate: -0.1416
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 2.06s
                      Time elapsed: 00:44:29
                               ETA: 00:07:26

################################################################################
                     [1m Learning iteration 1286/1500 [0m                     

                       Computation: 47821 steps/s (collection: 1.945s, learning 0.111s)
             Mean action noise std: 4.89
          Mean value_function loss: 77.1376
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 76.7106
                       Mean reward: 500.76
               Mean episode length: 233.97
    Episode_Reward/reaching_object: 1.3766
    Episode_Reward/rotating_object: 97.5834
        Episode_Reward/action_rate: -0.1419
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 2.06s
                      Time elapsed: 00:44:31
                               ETA: 00:07:24

################################################################################
                     [1m Learning iteration 1287/1500 [0m                     

                       Computation: 47689 steps/s (collection: 1.951s, learning 0.110s)
             Mean action noise std: 4.89
          Mean value_function loss: 78.5425
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 76.7291
                       Mean reward: 524.37
               Mean episode length: 230.64
    Episode_Reward/reaching_object: 1.3989
    Episode_Reward/rotating_object: 100.4849
        Episode_Reward/action_rate: -0.1438
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 2.06s
                      Time elapsed: 00:44:33
                               ETA: 00:07:22

################################################################################
                     [1m Learning iteration 1288/1500 [0m                     

                       Computation: 47889 steps/s (collection: 1.939s, learning 0.113s)
             Mean action noise std: 4.90
          Mean value_function loss: 82.4327
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 76.7449
                       Mean reward: 498.98
               Mean episode length: 228.44
    Episode_Reward/reaching_object: 1.3866
    Episode_Reward/rotating_object: 101.8769
        Episode_Reward/action_rate: -0.1433
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 2.05s
                      Time elapsed: 00:44:35
                               ETA: 00:07:20

################################################################################
                     [1m Learning iteration 1289/1500 [0m                     

                       Computation: 47368 steps/s (collection: 1.952s, learning 0.124s)
             Mean action noise std: 4.90
          Mean value_function loss: 87.6038
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 76.7600
                       Mean reward: 558.66
               Mean episode length: 240.66
    Episode_Reward/reaching_object: 1.4172
    Episode_Reward/rotating_object: 106.2162
        Episode_Reward/action_rate: -0.1437
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 2.08s
                      Time elapsed: 00:44:37
                               ETA: 00:07:17

################################################################################
                     [1m Learning iteration 1290/1500 [0m                     

                       Computation: 48020 steps/s (collection: 1.934s, learning 0.113s)
             Mean action noise std: 4.90
          Mean value_function loss: 79.0454
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 76.7713
                       Mean reward: 504.89
               Mean episode length: 230.76
    Episode_Reward/reaching_object: 1.3811
    Episode_Reward/rotating_object: 104.2909
        Episode_Reward/action_rate: -0.1419
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 2.05s
                      Time elapsed: 00:44:39
                               ETA: 00:07:15

################################################################################
                     [1m Learning iteration 1291/1500 [0m                     

                       Computation: 48222 steps/s (collection: 1.928s, learning 0.111s)
             Mean action noise std: 4.91
          Mean value_function loss: 78.7482
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 76.7847
                       Mean reward: 478.61
               Mean episode length: 222.71
    Episode_Reward/reaching_object: 1.3704
    Episode_Reward/rotating_object: 99.9791
        Episode_Reward/action_rate: -0.1431
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 2.04s
                      Time elapsed: 00:44:41
                               ETA: 00:07:13

################################################################################
                     [1m Learning iteration 1292/1500 [0m                     

                       Computation: 48492 steps/s (collection: 1.917s, learning 0.110s)
             Mean action noise std: 4.91
          Mean value_function loss: 87.0145
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 76.8004
                       Mean reward: 510.92
               Mean episode length: 223.90
    Episode_Reward/reaching_object: 1.3910
    Episode_Reward/rotating_object: 105.8725
        Episode_Reward/action_rate: -0.1439
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 2.03s
                      Time elapsed: 00:44:43
                               ETA: 00:07:11

################################################################################
                     [1m Learning iteration 1293/1500 [0m                     

                       Computation: 47772 steps/s (collection: 1.948s, learning 0.110s)
             Mean action noise std: 4.91
          Mean value_function loss: 88.4622
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 76.8191
                       Mean reward: 523.34
               Mean episode length: 233.93
    Episode_Reward/reaching_object: 1.3630
    Episode_Reward/rotating_object: 99.0297
        Episode_Reward/action_rate: -0.1422
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 2.06s
                      Time elapsed: 00:44:45
                               ETA: 00:07:09

################################################################################
                     [1m Learning iteration 1294/1500 [0m                     

                       Computation: 48717 steps/s (collection: 1.908s, learning 0.110s)
             Mean action noise std: 4.92
          Mean value_function loss: 80.1633
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 76.8369
                       Mean reward: 514.39
               Mean episode length: 235.63
    Episode_Reward/reaching_object: 1.3888
    Episode_Reward/rotating_object: 102.0490
        Episode_Reward/action_rate: -0.1458
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 2.02s
                      Time elapsed: 00:44:47
                               ETA: 00:07:07

################################################################################
                     [1m Learning iteration 1295/1500 [0m                     

                       Computation: 48679 steps/s (collection: 1.909s, learning 0.110s)
             Mean action noise std: 4.92
          Mean value_function loss: 73.5217
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 76.8548
                       Mean reward: 506.47
               Mean episode length: 231.68
    Episode_Reward/reaching_object: 1.3819
    Episode_Reward/rotating_object: 106.2437
        Episode_Reward/action_rate: -0.1464
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 2.02s
                      Time elapsed: 00:44:49
                               ETA: 00:07:05

################################################################################
                     [1m Learning iteration 1296/1500 [0m                     

                       Computation: 48215 steps/s (collection: 1.929s, learning 0.110s)
             Mean action noise std: 4.92
          Mean value_function loss: 78.3356
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 76.8694
                       Mean reward: 522.64
               Mean episode length: 237.57
    Episode_Reward/reaching_object: 1.3592
    Episode_Reward/rotating_object: 101.7702
        Episode_Reward/action_rate: -0.1440
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 2.04s
                      Time elapsed: 00:44:51
                               ETA: 00:07:03

################################################################################
                     [1m Learning iteration 1297/1500 [0m                     

                       Computation: 48530 steps/s (collection: 1.915s, learning 0.110s)
             Mean action noise std: 4.92
          Mean value_function loss: 80.6502
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 76.8829
                       Mean reward: 484.43
               Mean episode length: 229.77
    Episode_Reward/reaching_object: 1.3955
    Episode_Reward/rotating_object: 100.5407
        Episode_Reward/action_rate: -0.1462
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 2.03s
                      Time elapsed: 00:44:53
                               ETA: 00:07:01

################################################################################
                     [1m Learning iteration 1298/1500 [0m                     

                       Computation: 48126 steps/s (collection: 1.933s, learning 0.110s)
             Mean action noise std: 4.93
          Mean value_function loss: 81.5066
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 76.8935
                       Mean reward: 513.88
               Mean episode length: 234.71
    Episode_Reward/reaching_object: 1.3344
    Episode_Reward/rotating_object: 98.1738
        Episode_Reward/action_rate: -0.1423
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 2.04s
                      Time elapsed: 00:44:55
                               ETA: 00:06:59

################################################################################
                     [1m Learning iteration 1299/1500 [0m                     

                       Computation: 47451 steps/s (collection: 1.946s, learning 0.125s)
             Mean action noise std: 4.93
          Mean value_function loss: 80.1540
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 76.9072
                       Mean reward: 510.32
               Mean episode length: 236.39
    Episode_Reward/reaching_object: 1.3509
    Episode_Reward/rotating_object: 101.7733
        Episode_Reward/action_rate: -0.1452
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 2.07s
                      Time elapsed: 00:44:57
                               ETA: 00:06:57

################################################################################
                     [1m Learning iteration 1300/1500 [0m                     

                       Computation: 47087 steps/s (collection: 1.963s, learning 0.124s)
             Mean action noise std: 4.93
          Mean value_function loss: 79.3759
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 76.9178
                       Mean reward: 524.59
               Mean episode length: 232.35
    Episode_Reward/reaching_object: 1.3450
    Episode_Reward/rotating_object: 104.4069
        Episode_Reward/action_rate: -0.1432
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 2.09s
                      Time elapsed: 00:44:59
                               ETA: 00:06:55

################################################################################
                     [1m Learning iteration 1301/1500 [0m                     

                       Computation: 47369 steps/s (collection: 1.960s, learning 0.115s)
             Mean action noise std: 4.93
          Mean value_function loss: 86.4860
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 76.9314
                       Mean reward: 490.07
               Mean episode length: 220.03
    Episode_Reward/reaching_object: 1.3655
    Episode_Reward/rotating_object: 104.2987
        Episode_Reward/action_rate: -0.1441
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 2.08s
                      Time elapsed: 00:45:01
                               ETA: 00:06:52

################################################################################
                     [1m Learning iteration 1302/1500 [0m                     

                       Computation: 44487 steps/s (collection: 2.084s, learning 0.126s)
             Mean action noise std: 4.94
          Mean value_function loss: 74.3178
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 76.9486
                       Mean reward: 524.90
               Mean episode length: 233.80
    Episode_Reward/reaching_object: 1.3737
    Episode_Reward/rotating_object: 102.2100
        Episode_Reward/action_rate: -0.1463
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 2.21s
                      Time elapsed: 00:45:04
                               ETA: 00:06:50

################################################################################
                     [1m Learning iteration 1303/1500 [0m                     

                       Computation: 44070 steps/s (collection: 2.111s, learning 0.119s)
             Mean action noise std: 4.94
          Mean value_function loss: 79.8420
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 76.9689
                       Mean reward: 507.74
               Mean episode length: 233.81
    Episode_Reward/reaching_object: 1.3670
    Episode_Reward/rotating_object: 102.0563
        Episode_Reward/action_rate: -0.1457
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 2.23s
                      Time elapsed: 00:45:06
                               ETA: 00:06:48

################################################################################
                     [1m Learning iteration 1304/1500 [0m                     

                       Computation: 46464 steps/s (collection: 2.003s, learning 0.113s)
             Mean action noise std: 4.94
          Mean value_function loss: 81.3308
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 76.9829
                       Mean reward: 549.60
               Mean episode length: 232.62
    Episode_Reward/reaching_object: 1.3325
    Episode_Reward/rotating_object: 105.0640
        Episode_Reward/action_rate: -0.1428
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 2.12s
                      Time elapsed: 00:45:08
                               ETA: 00:06:46

################################################################################
                     [1m Learning iteration 1305/1500 [0m                     

                       Computation: 47398 steps/s (collection: 1.960s, learning 0.114s)
             Mean action noise std: 4.95
          Mean value_function loss: 100.0424
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 76.9962
                       Mean reward: 547.01
               Mean episode length: 231.12
    Episode_Reward/reaching_object: 1.3149
    Episode_Reward/rotating_object: 100.3322
        Episode_Reward/action_rate: -0.1423
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 2.07s
                      Time elapsed: 00:45:10
                               ETA: 00:06:44

################################################################################
                     [1m Learning iteration 1306/1500 [0m                     

                       Computation: 47709 steps/s (collection: 1.950s, learning 0.110s)
             Mean action noise std: 4.95
          Mean value_function loss: 87.8892
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 77.0148
                       Mean reward: 536.67
               Mean episode length: 242.40
    Episode_Reward/reaching_object: 1.3331
    Episode_Reward/rotating_object: 101.5785
        Episode_Reward/action_rate: -0.1437
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 2.06s
                      Time elapsed: 00:45:12
                               ETA: 00:06:42

################################################################################
                     [1m Learning iteration 1307/1500 [0m                     

                       Computation: 47852 steps/s (collection: 1.944s, learning 0.110s)
             Mean action noise std: 4.96
          Mean value_function loss: 86.8716
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 77.0352
                       Mean reward: 510.65
               Mean episode length: 232.43
    Episode_Reward/reaching_object: 1.3360
    Episode_Reward/rotating_object: 101.0595
        Episode_Reward/action_rate: -0.1438
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 2.05s
                      Time elapsed: 00:45:14
                               ETA: 00:06:40

################################################################################
                     [1m Learning iteration 1308/1500 [0m                     

                       Computation: 47783 steps/s (collection: 1.932s, learning 0.125s)
             Mean action noise std: 4.96
          Mean value_function loss: 87.1505
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 77.0559
                       Mean reward: 531.57
               Mean episode length: 230.71
    Episode_Reward/reaching_object: 1.3311
    Episode_Reward/rotating_object: 99.7848
        Episode_Reward/action_rate: -0.1432
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 2.06s
                      Time elapsed: 00:45:16
                               ETA: 00:06:38

################################################################################
                     [1m Learning iteration 1309/1500 [0m                     

                       Computation: 48012 steps/s (collection: 1.937s, learning 0.110s)
             Mean action noise std: 4.96
          Mean value_function loss: 78.5141
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 77.0669
                       Mean reward: 548.04
               Mean episode length: 234.02
    Episode_Reward/reaching_object: 1.3502
    Episode_Reward/rotating_object: 101.8092
        Episode_Reward/action_rate: -0.1460
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 2.05s
                      Time elapsed: 00:45:18
                               ETA: 00:06:36

################################################################################
                     [1m Learning iteration 1310/1500 [0m                     

                       Computation: 47539 steps/s (collection: 1.951s, learning 0.117s)
             Mean action noise std: 4.97
          Mean value_function loss: 80.8760
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 77.0848
                       Mean reward: 506.65
               Mean episode length: 225.70
    Episode_Reward/reaching_object: 1.3134
    Episode_Reward/rotating_object: 101.1161
        Episode_Reward/action_rate: -0.1429
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 2.07s
                      Time elapsed: 00:45:20
                               ETA: 00:06:34

################################################################################
                     [1m Learning iteration 1311/1500 [0m                     

                       Computation: 47818 steps/s (collection: 1.944s, learning 0.111s)
             Mean action noise std: 4.97
          Mean value_function loss: 89.5398
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 77.0963
                       Mean reward: 485.22
               Mean episode length: 224.45
    Episode_Reward/reaching_object: 1.3195
    Episode_Reward/rotating_object: 95.8836
        Episode_Reward/action_rate: -0.1455
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 2.06s
                      Time elapsed: 00:45:22
                               ETA: 00:06:32

################################################################################
                     [1m Learning iteration 1312/1500 [0m                     

                       Computation: 46372 steps/s (collection: 2.007s, learning 0.112s)
             Mean action noise std: 4.97
          Mean value_function loss: 80.7378
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 77.1148
                       Mean reward: 526.74
               Mean episode length: 239.78
    Episode_Reward/reaching_object: 1.3471
    Episode_Reward/rotating_object: 104.1814
        Episode_Reward/action_rate: -0.1451
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 2.12s
                      Time elapsed: 00:45:25
                               ETA: 00:06:30

################################################################################
                     [1m Learning iteration 1313/1500 [0m                     

                       Computation: 47696 steps/s (collection: 1.947s, learning 0.114s)
             Mean action noise std: 4.98
          Mean value_function loss: 73.3300
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 77.1360
                       Mean reward: 484.73
               Mean episode length: 229.53
    Episode_Reward/reaching_object: 1.3536
    Episode_Reward/rotating_object: 98.5244
        Episode_Reward/action_rate: -0.1480
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 2.06s
                      Time elapsed: 00:45:27
                               ETA: 00:06:28

################################################################################
                     [1m Learning iteration 1314/1500 [0m                     

                       Computation: 47503 steps/s (collection: 1.956s, learning 0.113s)
             Mean action noise std: 4.98
          Mean value_function loss: 86.9557
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 77.1500
                       Mean reward: 474.58
               Mean episode length: 231.98
    Episode_Reward/reaching_object: 1.3530
    Episode_Reward/rotating_object: 101.0004
        Episode_Reward/action_rate: -0.1495
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 2.07s
                      Time elapsed: 00:45:29
                               ETA: 00:06:26

################################################################################
                     [1m Learning iteration 1315/1500 [0m                     

                       Computation: 48347 steps/s (collection: 1.918s, learning 0.115s)
             Mean action noise std: 4.98
          Mean value_function loss: 82.6672
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 77.1581
                       Mean reward: 510.68
               Mean episode length: 234.73
    Episode_Reward/reaching_object: 1.3435
    Episode_Reward/rotating_object: 102.3249
        Episode_Reward/action_rate: -0.1480
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 2.03s
                      Time elapsed: 00:45:31
                               ETA: 00:06:23

################################################################################
                     [1m Learning iteration 1316/1500 [0m                     

                       Computation: 44644 steps/s (collection: 2.074s, learning 0.128s)
             Mean action noise std: 4.98
          Mean value_function loss: 81.2624
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 77.1709
                       Mean reward: 501.89
               Mean episode length: 233.33
    Episode_Reward/reaching_object: 1.3484
    Episode_Reward/rotating_object: 101.6334
        Episode_Reward/action_rate: -0.1492
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 2.20s
                      Time elapsed: 00:45:33
                               ETA: 00:06:21

################################################################################
                     [1m Learning iteration 1317/1500 [0m                     

                       Computation: 44834 steps/s (collection: 2.079s, learning 0.114s)
             Mean action noise std: 4.99
          Mean value_function loss: 83.5322
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 77.1813
                       Mean reward: 515.87
               Mean episode length: 230.29
    Episode_Reward/reaching_object: 1.3351
    Episode_Reward/rotating_object: 103.4478
        Episode_Reward/action_rate: -0.1468
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 2.19s
                      Time elapsed: 00:45:35
                               ETA: 00:06:19

################################################################################
                     [1m Learning iteration 1318/1500 [0m                     

                       Computation: 48236 steps/s (collection: 1.928s, learning 0.110s)
             Mean action noise std: 4.99
          Mean value_function loss: 79.0341
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 77.1933
                       Mean reward: 491.91
               Mean episode length: 229.30
    Episode_Reward/reaching_object: 1.3383
    Episode_Reward/rotating_object: 99.0442
        Episode_Reward/action_rate: -0.1490
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 2.04s
                      Time elapsed: 00:45:37
                               ETA: 00:06:17

################################################################################
                     [1m Learning iteration 1319/1500 [0m                     

                       Computation: 48752 steps/s (collection: 1.906s, learning 0.110s)
             Mean action noise std: 4.99
          Mean value_function loss: 81.6192
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 77.2053
                       Mean reward: 532.14
               Mean episode length: 233.25
    Episode_Reward/reaching_object: 1.3783
    Episode_Reward/rotating_object: 106.1238
        Episode_Reward/action_rate: -0.1514
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 2.02s
                      Time elapsed: 00:45:39
                               ETA: 00:06:15

################################################################################
                     [1m Learning iteration 1320/1500 [0m                     

                       Computation: 48495 steps/s (collection: 1.916s, learning 0.111s)
             Mean action noise std: 4.99
          Mean value_function loss: 84.0110
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 77.2171
                       Mean reward: 481.43
               Mean episode length: 236.24
    Episode_Reward/reaching_object: 1.3716
    Episode_Reward/rotating_object: 102.6301
        Episode_Reward/action_rate: -0.1522
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 2.03s
                      Time elapsed: 00:45:41
                               ETA: 00:06:13

################################################################################
                     [1m Learning iteration 1321/1500 [0m                     

                       Computation: 48649 steps/s (collection: 1.910s, learning 0.110s)
             Mean action noise std: 5.00
          Mean value_function loss: 73.2104
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 77.2275
                       Mean reward: 535.62
               Mean episode length: 232.59
    Episode_Reward/reaching_object: 1.3493
    Episode_Reward/rotating_object: 102.2557
        Episode_Reward/action_rate: -0.1499
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 2.02s
                      Time elapsed: 00:45:43
                               ETA: 00:06:11

################################################################################
                     [1m Learning iteration 1322/1500 [0m                     

                       Computation: 48044 steps/s (collection: 1.935s, learning 0.111s)
             Mean action noise std: 5.00
          Mean value_function loss: 82.0556
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 77.2373
                       Mean reward: 477.79
               Mean episode length: 225.65
    Episode_Reward/reaching_object: 1.3265
    Episode_Reward/rotating_object: 103.6084
        Episode_Reward/action_rate: -0.1479
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 2.05s
                      Time elapsed: 00:45:45
                               ETA: 00:06:09

################################################################################
                     [1m Learning iteration 1323/1500 [0m                     

                       Computation: 47983 steps/s (collection: 1.937s, learning 0.112s)
             Mean action noise std: 5.00
          Mean value_function loss: 77.8331
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 77.2456
                       Mean reward: 531.76
               Mean episode length: 230.15
    Episode_Reward/reaching_object: 1.3726
    Episode_Reward/rotating_object: 106.0038
        Episode_Reward/action_rate: -0.1521
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 2.05s
                      Time elapsed: 00:45:47
                               ETA: 00:06:07

################################################################################
                     [1m Learning iteration 1324/1500 [0m                     

                       Computation: 47545 steps/s (collection: 1.955s, learning 0.113s)
             Mean action noise std: 5.01
          Mean value_function loss: 70.4845
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 77.2589
                       Mean reward: 501.37
               Mean episode length: 229.21
    Episode_Reward/reaching_object: 1.3523
    Episode_Reward/rotating_object: 103.0718
        Episode_Reward/action_rate: -0.1505
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 2.07s
                      Time elapsed: 00:45:49
                               ETA: 00:06:05

################################################################################
                     [1m Learning iteration 1325/1500 [0m                     

                       Computation: 47619 steps/s (collection: 1.954s, learning 0.110s)
             Mean action noise std: 5.01
          Mean value_function loss: 80.8105
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 77.2762
                       Mean reward: 517.62
               Mean episode length: 229.72
    Episode_Reward/reaching_object: 1.3193
    Episode_Reward/rotating_object: 101.0820
        Episode_Reward/action_rate: -0.1487
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 2.06s
                      Time elapsed: 00:45:51
                               ETA: 00:06:03

################################################################################
                     [1m Learning iteration 1326/1500 [0m                     

                       Computation: 47597 steps/s (collection: 1.948s, learning 0.117s)
             Mean action noise std: 5.01
          Mean value_function loss: 97.5070
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 77.2918
                       Mean reward: 521.05
               Mean episode length: 231.68
    Episode_Reward/reaching_object: 1.3325
    Episode_Reward/rotating_object: 105.2824
        Episode_Reward/action_rate: -0.1491
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 2.07s
                      Time elapsed: 00:45:53
                               ETA: 00:06:01

################################################################################
                     [1m Learning iteration 1327/1500 [0m                     

                       Computation: 47581 steps/s (collection: 1.952s, learning 0.114s)
             Mean action noise std: 5.02
          Mean value_function loss: 90.5740
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 77.3068
                       Mean reward: 525.40
               Mean episode length: 236.19
    Episode_Reward/reaching_object: 1.3553
    Episode_Reward/rotating_object: 104.8036
        Episode_Reward/action_rate: -0.1528
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 2.07s
                      Time elapsed: 00:45:56
                               ETA: 00:05:59

################################################################################
                     [1m Learning iteration 1328/1500 [0m                     

                       Computation: 47602 steps/s (collection: 1.955s, learning 0.110s)
             Mean action noise std: 5.02
          Mean value_function loss: 90.2890
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 77.3272
                       Mean reward: 534.59
               Mean episode length: 235.59
    Episode_Reward/reaching_object: 1.3355
    Episode_Reward/rotating_object: 105.0320
        Episode_Reward/action_rate: -0.1496
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 2.07s
                      Time elapsed: 00:45:58
                               ETA: 00:05:56

################################################################################
                     [1m Learning iteration 1329/1500 [0m                     

                       Computation: 47242 steps/s (collection: 1.970s, learning 0.111s)
             Mean action noise std: 5.02
          Mean value_function loss: 85.2168
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 77.3387
                       Mean reward: 542.60
               Mean episode length: 233.00
    Episode_Reward/reaching_object: 1.3366
    Episode_Reward/rotating_object: 102.9318
        Episode_Reward/action_rate: -0.1509
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 2.08s
                      Time elapsed: 00:46:00
                               ETA: 00:05:54

################################################################################
                     [1m Learning iteration 1330/1500 [0m                     

                       Computation: 47466 steps/s (collection: 1.958s, learning 0.113s)
             Mean action noise std: 5.02
          Mean value_function loss: 80.9280
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 77.3479
                       Mean reward: 509.39
               Mean episode length: 228.59
    Episode_Reward/reaching_object: 1.3569
    Episode_Reward/rotating_object: 102.9728
        Episode_Reward/action_rate: -0.1531
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 2.07s
                      Time elapsed: 00:46:02
                               ETA: 00:05:52

################################################################################
                     [1m Learning iteration 1331/1500 [0m                     

                       Computation: 46948 steps/s (collection: 1.974s, learning 0.120s)
             Mean action noise std: 5.03
          Mean value_function loss: 84.4553
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 77.3559
                       Mean reward: 483.38
               Mean episode length: 226.67
    Episode_Reward/reaching_object: 1.3423
    Episode_Reward/rotating_object: 99.1716
        Episode_Reward/action_rate: -0.1518
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 2.09s
                      Time elapsed: 00:46:04
                               ETA: 00:05:50

################################################################################
                     [1m Learning iteration 1332/1500 [0m                     

                       Computation: 43827 steps/s (collection: 2.117s, learning 0.126s)
             Mean action noise std: 5.03
          Mean value_function loss: 95.0214
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 77.3676
                       Mean reward: 579.11
               Mean episode length: 242.21
    Episode_Reward/reaching_object: 1.3699
    Episode_Reward/rotating_object: 105.4252
        Episode_Reward/action_rate: -0.1541
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 2.24s
                      Time elapsed: 00:46:06
                               ETA: 00:05:48

################################################################################
                     [1m Learning iteration 1333/1500 [0m                     

                       Computation: 44015 steps/s (collection: 2.106s, learning 0.128s)
             Mean action noise std: 5.03
          Mean value_function loss: 79.0736
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 77.3820
                       Mean reward: 514.57
               Mean episode length: 230.32
    Episode_Reward/reaching_object: 1.3281
    Episode_Reward/rotating_object: 102.4695
        Episode_Reward/action_rate: -0.1490
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 2.23s
                      Time elapsed: 00:46:08
                               ETA: 00:05:46

################################################################################
                     [1m Learning iteration 1334/1500 [0m                     

                       Computation: 44209 steps/s (collection: 2.110s, learning 0.114s)
             Mean action noise std: 5.04
          Mean value_function loss: 94.5764
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 77.3978
                       Mean reward: 521.96
               Mean episode length: 222.86
    Episode_Reward/reaching_object: 1.3434
    Episode_Reward/rotating_object: 104.3282
        Episode_Reward/action_rate: -0.1504
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 2.22s
                      Time elapsed: 00:46:11
                               ETA: 00:05:44

################################################################################
                     [1m Learning iteration 1335/1500 [0m                     

                       Computation: 46840 steps/s (collection: 1.985s, learning 0.114s)
             Mean action noise std: 5.04
          Mean value_function loss: 102.5345
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 77.4072
                       Mean reward: 511.42
               Mean episode length: 236.06
    Episode_Reward/reaching_object: 1.3688
    Episode_Reward/rotating_object: 104.0285
        Episode_Reward/action_rate: -0.1555
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 2.10s
                      Time elapsed: 00:46:13
                               ETA: 00:05:42

################################################################################
                     [1m Learning iteration 1336/1500 [0m                     

                       Computation: 47462 steps/s (collection: 1.958s, learning 0.113s)
             Mean action noise std: 5.04
          Mean value_function loss: 89.3149
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 77.4121
                       Mean reward: 534.98
               Mean episode length: 225.58
    Episode_Reward/reaching_object: 1.3113
    Episode_Reward/rotating_object: 102.6384
        Episode_Reward/action_rate: -0.1490
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 2.07s
                      Time elapsed: 00:46:15
                               ETA: 00:05:40

################################################################################
                     [1m Learning iteration 1337/1500 [0m                     

                       Computation: 46805 steps/s (collection: 1.990s, learning 0.110s)
             Mean action noise std: 5.04
          Mean value_function loss: 92.6166
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 77.4170
                       Mean reward: 532.84
               Mean episode length: 232.07
    Episode_Reward/reaching_object: 1.3578
    Episode_Reward/rotating_object: 106.2834
        Episode_Reward/action_rate: -0.1529
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 2.10s
                      Time elapsed: 00:46:17
                               ETA: 00:05:38

################################################################################
                     [1m Learning iteration 1338/1500 [0m                     

                       Computation: 48377 steps/s (collection: 1.922s, learning 0.110s)
             Mean action noise std: 5.04
          Mean value_function loss: 99.5517
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 77.4287
                       Mean reward: 554.20
               Mean episode length: 231.23
    Episode_Reward/reaching_object: 1.3579
    Episode_Reward/rotating_object: 105.3837
        Episode_Reward/action_rate: -0.1520
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 2.03s
                      Time elapsed: 00:46:19
                               ETA: 00:05:36

################################################################################
                     [1m Learning iteration 1339/1500 [0m                     

                       Computation: 47892 steps/s (collection: 1.942s, learning 0.111s)
             Mean action noise std: 5.05
          Mean value_function loss: 93.8530
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 77.4418
                       Mean reward: 552.52
               Mean episode length: 230.01
    Episode_Reward/reaching_object: 1.3610
    Episode_Reward/rotating_object: 104.8833
        Episode_Reward/action_rate: -0.1529
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 2.05s
                      Time elapsed: 00:46:21
                               ETA: 00:05:34

################################################################################
                     [1m Learning iteration 1340/1500 [0m                     

                       Computation: 48128 steps/s (collection: 1.932s, learning 0.110s)
             Mean action noise std: 5.05
          Mean value_function loss: 98.8723
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 77.4527
                       Mean reward: 526.03
               Mean episode length: 231.87
    Episode_Reward/reaching_object: 1.3496
    Episode_Reward/rotating_object: 104.7628
        Episode_Reward/action_rate: -0.1530
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 2.04s
                      Time elapsed: 00:46:23
                               ETA: 00:05:32

################################################################################
                     [1m Learning iteration 1341/1500 [0m                     

                       Computation: 47836 steps/s (collection: 1.944s, learning 0.111s)
             Mean action noise std: 5.05
          Mean value_function loss: 97.1962
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 77.4618
                       Mean reward: 510.27
               Mean episode length: 225.17
    Episode_Reward/reaching_object: 1.3077
    Episode_Reward/rotating_object: 100.6334
        Episode_Reward/action_rate: -0.1498
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 2.06s
                      Time elapsed: 00:46:25
                               ETA: 00:05:30

################################################################################
                     [1m Learning iteration 1342/1500 [0m                     

                       Computation: 47500 steps/s (collection: 1.959s, learning 0.110s)
             Mean action noise std: 5.05
          Mean value_function loss: 99.1539
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 77.4716
                       Mean reward: 546.46
               Mean episode length: 226.67
    Episode_Reward/reaching_object: 1.3218
    Episode_Reward/rotating_object: 100.8812
        Episode_Reward/action_rate: -0.1492
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 2.07s
                      Time elapsed: 00:46:27
                               ETA: 00:05:27

################################################################################
                     [1m Learning iteration 1343/1500 [0m                     

                       Computation: 48112 steps/s (collection: 1.931s, learning 0.112s)
             Mean action noise std: 5.05
          Mean value_function loss: 94.5552
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 77.4811
                       Mean reward: 553.06
               Mean episode length: 231.23
    Episode_Reward/reaching_object: 1.3313
    Episode_Reward/rotating_object: 106.6504
        Episode_Reward/action_rate: -0.1504
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 2.04s
                      Time elapsed: 00:46:29
                               ETA: 00:05:25

################################################################################
                     [1m Learning iteration 1344/1500 [0m                     

                       Computation: 47741 steps/s (collection: 1.949s, learning 0.110s)
             Mean action noise std: 5.06
          Mean value_function loss: 85.4269
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 77.4951
                       Mean reward: 547.76
               Mean episode length: 233.87
    Episode_Reward/reaching_object: 1.3476
    Episode_Reward/rotating_object: 104.8813
        Episode_Reward/action_rate: -0.1518
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 2.06s
                      Time elapsed: 00:46:31
                               ETA: 00:05:23

################################################################################
                     [1m Learning iteration 1345/1500 [0m                     

                       Computation: 47348 steps/s (collection: 1.966s, learning 0.110s)
             Mean action noise std: 5.06
          Mean value_function loss: 105.7432
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 77.5051
                       Mean reward: 499.76
               Mean episode length: 226.67
    Episode_Reward/reaching_object: 1.3595
    Episode_Reward/rotating_object: 105.0322
        Episode_Reward/action_rate: -0.1538
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 2.08s
                      Time elapsed: 00:46:33
                               ETA: 00:05:21

################################################################################
                     [1m Learning iteration 1346/1500 [0m                     

                       Computation: 46480 steps/s (collection: 2.005s, learning 0.110s)
             Mean action noise std: 5.06
          Mean value_function loss: 89.0419
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 77.5151
                       Mean reward: 569.68
               Mean episode length: 237.83
    Episode_Reward/reaching_object: 1.3943
    Episode_Reward/rotating_object: 108.4494
        Episode_Reward/action_rate: -0.1578
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 2.11s
                      Time elapsed: 00:46:35
                               ETA: 00:05:19

################################################################################
                     [1m Learning iteration 1347/1500 [0m                     

                       Computation: 46841 steps/s (collection: 1.975s, learning 0.124s)
             Mean action noise std: 5.06
          Mean value_function loss: 100.0368
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 77.5279
                       Mean reward: 531.93
               Mean episode length: 227.40
    Episode_Reward/reaching_object: 1.3323
    Episode_Reward/rotating_object: 102.5432
        Episode_Reward/action_rate: -0.1525
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 2.10s
                      Time elapsed: 00:46:37
                               ETA: 00:05:17

################################################################################
                     [1m Learning iteration 1348/1500 [0m                     

                       Computation: 46519 steps/s (collection: 2.000s, learning 0.113s)
             Mean action noise std: 5.07
          Mean value_function loss: 93.5358
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 77.5339
                       Mean reward: 504.48
               Mean episode length: 230.36
    Episode_Reward/reaching_object: 1.3445
    Episode_Reward/rotating_object: 106.7329
        Episode_Reward/action_rate: -0.1544
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 2.11s
                      Time elapsed: 00:46:40
                               ETA: 00:05:15

################################################################################
                     [1m Learning iteration 1349/1500 [0m                     

                       Computation: 47166 steps/s (collection: 1.972s, learning 0.113s)
             Mean action noise std: 5.07
          Mean value_function loss: 97.8439
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 77.5430
                       Mean reward: 555.69
               Mean episode length: 235.18
    Episode_Reward/reaching_object: 1.3407
    Episode_Reward/rotating_object: 105.9914
        Episode_Reward/action_rate: -0.1535
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 2.08s
                      Time elapsed: 00:46:42
                               ETA: 00:05:13

################################################################################
                     [1m Learning iteration 1350/1500 [0m                     

                       Computation: 46854 steps/s (collection: 1.986s, learning 0.112s)
             Mean action noise std: 5.07
          Mean value_function loss: 99.5182
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 77.5517
                       Mean reward: 521.59
               Mean episode length: 219.43
    Episode_Reward/reaching_object: 1.3126
    Episode_Reward/rotating_object: 102.5839
        Episode_Reward/action_rate: -0.1509
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 2.10s
                      Time elapsed: 00:46:44
                               ETA: 00:05:11

################################################################################
                     [1m Learning iteration 1351/1500 [0m                     

                       Computation: 46916 steps/s (collection: 1.972s, learning 0.123s)
             Mean action noise std: 5.07
          Mean value_function loss: 101.7618
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 77.5598
                       Mean reward: 542.61
               Mean episode length: 228.06
    Episode_Reward/reaching_object: 1.3390
    Episode_Reward/rotating_object: 106.3877
        Episode_Reward/action_rate: -0.1524
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 2.10s
                      Time elapsed: 00:46:46
                               ETA: 00:05:09

################################################################################
                     [1m Learning iteration 1352/1500 [0m                     

                       Computation: 47414 steps/s (collection: 1.961s, learning 0.112s)
             Mean action noise std: 5.07
          Mean value_function loss: 95.5023
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 77.5674
                       Mean reward: 527.28
               Mean episode length: 223.74
    Episode_Reward/reaching_object: 1.3200
    Episode_Reward/rotating_object: 102.1236
        Episode_Reward/action_rate: -0.1514
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 2.07s
                      Time elapsed: 00:46:48
                               ETA: 00:05:07

################################################################################
                     [1m Learning iteration 1353/1500 [0m                     

                       Computation: 47204 steps/s (collection: 1.963s, learning 0.119s)
             Mean action noise std: 5.08
          Mean value_function loss: 93.4754
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 77.5763
                       Mean reward: 527.51
               Mean episode length: 225.39
    Episode_Reward/reaching_object: 1.3409
    Episode_Reward/rotating_object: 105.5824
        Episode_Reward/action_rate: -0.1527
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 2.08s
                      Time elapsed: 00:46:50
                               ETA: 00:05:05

################################################################################
                     [1m Learning iteration 1354/1500 [0m                     

                       Computation: 46780 steps/s (collection: 1.990s, learning 0.112s)
             Mean action noise std: 5.08
          Mean value_function loss: 100.0149
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 77.5941
                       Mean reward: 564.58
               Mean episode length: 236.60
    Episode_Reward/reaching_object: 1.3981
    Episode_Reward/rotating_object: 112.6901
        Episode_Reward/action_rate: -0.1578
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 2.10s
                      Time elapsed: 00:46:52
                               ETA: 00:05:03

################################################################################
                     [1m Learning iteration 1355/1500 [0m                     

                       Computation: 46656 steps/s (collection: 1.993s, learning 0.114s)
             Mean action noise std: 5.08
          Mean value_function loss: 107.4177
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 77.6044
                       Mean reward: 545.69
               Mean episode length: 225.14
    Episode_Reward/reaching_object: 1.3341
    Episode_Reward/rotating_object: 104.5371
        Episode_Reward/action_rate: -0.1526
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 2.11s
                      Time elapsed: 00:46:54
                               ETA: 00:05:00

################################################################################
                     [1m Learning iteration 1356/1500 [0m                     

                       Computation: 45539 steps/s (collection: 2.041s, learning 0.117s)
             Mean action noise std: 5.09
          Mean value_function loss: 108.3074
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 77.6121
                       Mean reward: 519.52
               Mean episode length: 218.88
    Episode_Reward/reaching_object: 1.3186
    Episode_Reward/rotating_object: 105.7301
        Episode_Reward/action_rate: -0.1508
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 2.16s
                      Time elapsed: 00:46:56
                               ETA: 00:04:58

################################################################################
                     [1m Learning iteration 1357/1500 [0m                     

                       Computation: 46672 steps/s (collection: 1.996s, learning 0.110s)
             Mean action noise std: 5.09
          Mean value_function loss: 100.5427
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 77.6201
                       Mean reward: 551.47
               Mean episode length: 232.86
    Episode_Reward/reaching_object: 1.3907
    Episode_Reward/rotating_object: 109.8683
        Episode_Reward/action_rate: -0.1575
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 2.11s
                      Time elapsed: 00:46:58
                               ETA: 00:04:56

################################################################################
                     [1m Learning iteration 1358/1500 [0m                     

                       Computation: 46627 steps/s (collection: 1.995s, learning 0.114s)
             Mean action noise std: 5.09
          Mean value_function loss: 78.8239
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 77.6251
                       Mean reward: 552.99
               Mean episode length: 233.21
    Episode_Reward/reaching_object: 1.3772
    Episode_Reward/rotating_object: 109.3752
        Episode_Reward/action_rate: -0.1565
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 2.11s
                      Time elapsed: 00:47:01
                               ETA: 00:04:54

################################################################################
                     [1m Learning iteration 1359/1500 [0m                     

                       Computation: 47106 steps/s (collection: 1.957s, learning 0.130s)
             Mean action noise std: 5.09
          Mean value_function loss: 96.0876
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 77.6388
                       Mean reward: 571.38
               Mean episode length: 231.25
    Episode_Reward/reaching_object: 1.3742
    Episode_Reward/rotating_object: 110.0009
        Episode_Reward/action_rate: -0.1560
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 2.09s
                      Time elapsed: 00:47:03
                               ETA: 00:04:52

################################################################################
                     [1m Learning iteration 1360/1500 [0m                     

                       Computation: 46514 steps/s (collection: 1.991s, learning 0.123s)
             Mean action noise std: 5.09
          Mean value_function loss: 93.5922
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 77.6516
                       Mean reward: 600.10
               Mean episode length: 240.10
    Episode_Reward/reaching_object: 1.3754
    Episode_Reward/rotating_object: 113.3641
        Episode_Reward/action_rate: -0.1572
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 2.11s
                      Time elapsed: 00:47:05
                               ETA: 00:04:50

################################################################################
                     [1m Learning iteration 1361/1500 [0m                     

                       Computation: 48143 steps/s (collection: 1.929s, learning 0.113s)
             Mean action noise std: 5.10
          Mean value_function loss: 89.9828
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 77.6589
                       Mean reward: 543.50
               Mean episode length: 228.69
    Episode_Reward/reaching_object: 1.3821
    Episode_Reward/rotating_object: 111.7695
        Episode_Reward/action_rate: -0.1596
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 2.04s
                      Time elapsed: 00:47:07
                               ETA: 00:04:48

################################################################################
                     [1m Learning iteration 1362/1500 [0m                     

                       Computation: 47868 steps/s (collection: 1.940s, learning 0.113s)
             Mean action noise std: 5.10
          Mean value_function loss: 87.9966
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 77.6745
                       Mean reward: 548.56
               Mean episode length: 226.45
    Episode_Reward/reaching_object: 1.3845
    Episode_Reward/rotating_object: 113.9961
        Episode_Reward/action_rate: -0.1598
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 2.05s
                      Time elapsed: 00:47:09
                               ETA: 00:04:46

################################################################################
                     [1m Learning iteration 1363/1500 [0m                     

                       Computation: 48242 steps/s (collection: 1.927s, learning 0.111s)
             Mean action noise std: 5.10
          Mean value_function loss: 92.4080
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 77.6875
                       Mean reward: 551.46
               Mean episode length: 237.56
    Episode_Reward/reaching_object: 1.3573
    Episode_Reward/rotating_object: 109.5507
        Episode_Reward/action_rate: -0.1570
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 2.04s
                      Time elapsed: 00:47:11
                               ETA: 00:04:44

################################################################################
                     [1m Learning iteration 1364/1500 [0m                     

                       Computation: 47579 steps/s (collection: 1.956s, learning 0.110s)
             Mean action noise std: 5.11
          Mean value_function loss: 99.8944
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 77.7015
                       Mean reward: 551.02
               Mean episode length: 225.97
    Episode_Reward/reaching_object: 1.3470
    Episode_Reward/rotating_object: 108.3437
        Episode_Reward/action_rate: -0.1569
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 2.07s
                      Time elapsed: 00:47:13
                               ETA: 00:04:42

################################################################################
                     [1m Learning iteration 1365/1500 [0m                     

                       Computation: 47796 steps/s (collection: 1.946s, learning 0.111s)
             Mean action noise std: 5.11
          Mean value_function loss: 92.6449
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 77.7180
                       Mean reward: 557.00
               Mean episode length: 224.80
    Episode_Reward/reaching_object: 1.3555
    Episode_Reward/rotating_object: 111.4347
        Episode_Reward/action_rate: -0.1570
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 2.06s
                      Time elapsed: 00:47:15
                               ETA: 00:04:40

################################################################################
                     [1m Learning iteration 1366/1500 [0m                     

                       Computation: 47714 steps/s (collection: 1.950s, learning 0.110s)
             Mean action noise std: 5.11
          Mean value_function loss: 104.9811
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 77.7273
                       Mean reward: 538.73
               Mean episode length: 234.54
    Episode_Reward/reaching_object: 1.3325
    Episode_Reward/rotating_object: 105.3599
        Episode_Reward/action_rate: -0.1556
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 2.06s
                      Time elapsed: 00:47:17
                               ETA: 00:04:38

################################################################################
                     [1m Learning iteration 1367/1500 [0m                     

                       Computation: 46862 steps/s (collection: 1.986s, learning 0.112s)
             Mean action noise std: 5.11
          Mean value_function loss: 99.4605
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 77.7373
                       Mean reward: 588.80
               Mean episode length: 238.38
    Episode_Reward/reaching_object: 1.3837
    Episode_Reward/rotating_object: 112.5316
        Episode_Reward/action_rate: -0.1577
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 2.10s
                      Time elapsed: 00:47:19
                               ETA: 00:04:36

################################################################################
                     [1m Learning iteration 1368/1500 [0m                     

                       Computation: 47371 steps/s (collection: 1.965s, learning 0.111s)
             Mean action noise std: 5.12
          Mean value_function loss: 109.7211
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 77.7576
                       Mean reward: 530.33
               Mean episode length: 236.54
    Episode_Reward/reaching_object: 1.3443
    Episode_Reward/rotating_object: 106.8259
        Episode_Reward/action_rate: -0.1572
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 2.08s
                      Time elapsed: 00:47:21
                               ETA: 00:04:34

################################################################################
                     [1m Learning iteration 1369/1500 [0m                     

                       Computation: 46375 steps/s (collection: 2.009s, learning 0.111s)
             Mean action noise std: 5.12
          Mean value_function loss: 101.3339
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 77.7786
                       Mean reward: 541.14
               Mean episode length: 226.39
    Episode_Reward/reaching_object: 1.3529
    Episode_Reward/rotating_object: 108.2677
        Episode_Reward/action_rate: -0.1562
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 2.12s
                      Time elapsed: 00:47:23
                               ETA: 00:04:31

################################################################################
                     [1m Learning iteration 1370/1500 [0m                     

                       Computation: 47026 steps/s (collection: 1.980s, learning 0.110s)
             Mean action noise std: 5.13
          Mean value_function loss: 100.6689
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 77.7977
                       Mean reward: 546.38
               Mean episode length: 224.77
    Episode_Reward/reaching_object: 1.3498
    Episode_Reward/rotating_object: 108.3726
        Episode_Reward/action_rate: -0.1553
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 2.09s
                      Time elapsed: 00:47:25
                               ETA: 00:04:29

################################################################################
                     [1m Learning iteration 1371/1500 [0m                     

                       Computation: 46570 steps/s (collection: 1.999s, learning 0.112s)
             Mean action noise std: 5.13
          Mean value_function loss: 90.2982
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 77.8159
                       Mean reward: 566.78
               Mean episode length: 235.18
    Episode_Reward/reaching_object: 1.3906
    Episode_Reward/rotating_object: 114.2978
        Episode_Reward/action_rate: -0.1609
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 2.11s
                      Time elapsed: 00:47:28
                               ETA: 00:04:27

################################################################################
                     [1m Learning iteration 1372/1500 [0m                     

                       Computation: 46203 steps/s (collection: 2.016s, learning 0.112s)
             Mean action noise std: 5.13
          Mean value_function loss: 109.7600
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 77.8320
                       Mean reward: 522.01
               Mean episode length: 225.15
    Episode_Reward/reaching_object: 1.3202
    Episode_Reward/rotating_object: 105.1826
        Episode_Reward/action_rate: -0.1527
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 2.13s
                      Time elapsed: 00:47:30
                               ETA: 00:04:25

################################################################################
                     [1m Learning iteration 1373/1500 [0m                     

                       Computation: 46634 steps/s (collection: 1.994s, learning 0.114s)
             Mean action noise std: 5.13
          Mean value_function loss: 103.2324
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 77.8451
                       Mean reward: 543.54
               Mean episode length: 222.47
    Episode_Reward/reaching_object: 1.3321
    Episode_Reward/rotating_object: 107.9497
        Episode_Reward/action_rate: -0.1548
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 2.11s
                      Time elapsed: 00:47:32
                               ETA: 00:04:23

################################################################################
                     [1m Learning iteration 1374/1500 [0m                     

                       Computation: 46779 steps/s (collection: 1.988s, learning 0.113s)
             Mean action noise std: 5.14
          Mean value_function loss: 98.5772
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 77.8599
                       Mean reward: 534.16
               Mean episode length: 230.11
    Episode_Reward/reaching_object: 1.3114
    Episode_Reward/rotating_object: 103.8896
        Episode_Reward/action_rate: -0.1541
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 2.10s
                      Time elapsed: 00:47:34
                               ETA: 00:04:21

################################################################################
                     [1m Learning iteration 1375/1500 [0m                     

                       Computation: 46882 steps/s (collection: 1.987s, learning 0.110s)
             Mean action noise std: 5.14
          Mean value_function loss: 102.9072
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 77.8725
                       Mean reward: 576.14
               Mean episode length: 236.57
    Episode_Reward/reaching_object: 1.3387
    Episode_Reward/rotating_object: 104.3169
        Episode_Reward/action_rate: -0.1559
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 2.10s
                      Time elapsed: 00:47:36
                               ETA: 00:04:19

################################################################################
                     [1m Learning iteration 1376/1500 [0m                     

                       Computation: 46240 steps/s (collection: 2.010s, learning 0.116s)
             Mean action noise std: 5.14
          Mean value_function loss: 101.2653
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 77.8815
                       Mean reward: 518.91
               Mean episode length: 228.00
    Episode_Reward/reaching_object: 1.3389
    Episode_Reward/rotating_object: 104.9877
        Episode_Reward/action_rate: -0.1569
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 2.13s
                      Time elapsed: 00:47:38
                               ETA: 00:04:17

################################################################################
                     [1m Learning iteration 1377/1500 [0m                     

                       Computation: 46603 steps/s (collection: 1.998s, learning 0.111s)
             Mean action noise std: 5.15
          Mean value_function loss: 109.4400
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 77.8920
                       Mean reward: 512.69
               Mean episode length: 217.33
    Episode_Reward/reaching_object: 1.3586
    Episode_Reward/rotating_object: 106.5554
        Episode_Reward/action_rate: -0.1571
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 2.11s
                      Time elapsed: 00:47:40
                               ETA: 00:04:15

################################################################################
                     [1m Learning iteration 1378/1500 [0m                     

                       Computation: 46505 steps/s (collection: 2.004s, learning 0.110s)
             Mean action noise std: 5.15
          Mean value_function loss: 100.4884
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 77.9075
                       Mean reward: 545.91
               Mean episode length: 227.26
    Episode_Reward/reaching_object: 1.3302
    Episode_Reward/rotating_object: 100.6500
        Episode_Reward/action_rate: -0.1544
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 2.11s
                      Time elapsed: 00:47:42
                               ETA: 00:04:13

################################################################################
                     [1m Learning iteration 1379/1500 [0m                     

                       Computation: 46318 steps/s (collection: 2.010s, learning 0.112s)
             Mean action noise std: 5.15
          Mean value_function loss: 107.7197
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 77.9220
                       Mean reward: 559.96
               Mean episode length: 228.54
    Episode_Reward/reaching_object: 1.3464
    Episode_Reward/rotating_object: 106.4245
        Episode_Reward/action_rate: -0.1561
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 2.12s
                      Time elapsed: 00:47:45
                               ETA: 00:04:11

################################################################################
                     [1m Learning iteration 1380/1500 [0m                     

                       Computation: 46469 steps/s (collection: 2.006s, learning 0.110s)
             Mean action noise std: 5.15
          Mean value_function loss: 115.1791
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 77.9341
                       Mean reward: 513.69
               Mean episode length: 217.56
    Episode_Reward/reaching_object: 1.3453
    Episode_Reward/rotating_object: 106.7019
        Episode_Reward/action_rate: -0.1556
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 2.12s
                      Time elapsed: 00:47:47
                               ETA: 00:04:09

################################################################################
                     [1m Learning iteration 1381/1500 [0m                     

                       Computation: 46656 steps/s (collection: 1.996s, learning 0.111s)
             Mean action noise std: 5.16
          Mean value_function loss: 103.9329
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 77.9486
                       Mean reward: 516.56
               Mean episode length: 226.12
    Episode_Reward/reaching_object: 1.3228
    Episode_Reward/rotating_object: 104.5981
        Episode_Reward/action_rate: -0.1545
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 2.11s
                      Time elapsed: 00:47:49
                               ETA: 00:04:07

################################################################################
                     [1m Learning iteration 1382/1500 [0m                     

                       Computation: 46887 steps/s (collection: 1.985s, learning 0.112s)
             Mean action noise std: 5.16
          Mean value_function loss: 108.3596
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 77.9657
                       Mean reward: 585.42
               Mean episode length: 229.08
    Episode_Reward/reaching_object: 1.3552
    Episode_Reward/rotating_object: 108.5884
        Episode_Reward/action_rate: -0.1580
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 2.10s
                      Time elapsed: 00:47:51
                               ETA: 00:04:04

################################################################################
                     [1m Learning iteration 1383/1500 [0m                     

                       Computation: 46763 steps/s (collection: 1.992s, learning 0.110s)
             Mean action noise std: 5.16
          Mean value_function loss: 110.6393
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 77.9737
                       Mean reward: 547.37
               Mean episode length: 231.30
    Episode_Reward/reaching_object: 1.3700
    Episode_Reward/rotating_object: 109.8270
        Episode_Reward/action_rate: -0.1599
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 2.10s
                      Time elapsed: 00:47:53
                               ETA: 00:04:02

################################################################################
                     [1m Learning iteration 1384/1500 [0m                     

                       Computation: 46998 steps/s (collection: 1.981s, learning 0.110s)
             Mean action noise std: 5.17
          Mean value_function loss: 99.7657
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 77.9874
                       Mean reward: 554.84
               Mean episode length: 225.32
    Episode_Reward/reaching_object: 1.3350
    Episode_Reward/rotating_object: 106.1424
        Episode_Reward/action_rate: -0.1568
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 2.09s
                      Time elapsed: 00:47:55
                               ETA: 00:04:00

################################################################################
                     [1m Learning iteration 1385/1500 [0m                     

                       Computation: 47281 steps/s (collection: 1.969s, learning 0.110s)
             Mean action noise std: 5.17
          Mean value_function loss: 104.5274
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 78.0082
                       Mean reward: 548.29
               Mean episode length: 226.45
    Episode_Reward/reaching_object: 1.3653
    Episode_Reward/rotating_object: 109.2421
        Episode_Reward/action_rate: -0.1599
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 2.08s
                      Time elapsed: 00:47:57
                               ETA: 00:03:58

################################################################################
                     [1m Learning iteration 1386/1500 [0m                     

                       Computation: 47543 steps/s (collection: 1.957s, learning 0.110s)
             Mean action noise std: 5.17
          Mean value_function loss: 106.7511
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 78.0252
                       Mean reward: 596.56
               Mean episode length: 232.47
    Episode_Reward/reaching_object: 1.3577
    Episode_Reward/rotating_object: 110.3427
        Episode_Reward/action_rate: -0.1589
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 2.07s
                      Time elapsed: 00:47:59
                               ETA: 00:03:56

################################################################################
                     [1m Learning iteration 1387/1500 [0m                     

                       Computation: 46908 steps/s (collection: 1.972s, learning 0.124s)
             Mean action noise std: 5.18
          Mean value_function loss: 106.1546
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 78.0374
                       Mean reward: 536.81
               Mean episode length: 226.69
    Episode_Reward/reaching_object: 1.3613
    Episode_Reward/rotating_object: 110.7792
        Episode_Reward/action_rate: -0.1589
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 2.10s
                      Time elapsed: 00:48:01
                               ETA: 00:03:54

################################################################################
                     [1m Learning iteration 1388/1500 [0m                     

                       Computation: 47574 steps/s (collection: 1.955s, learning 0.111s)
             Mean action noise std: 5.18
          Mean value_function loss: 100.8585
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 78.0492
                       Mean reward: 562.30
               Mean episode length: 229.46
    Episode_Reward/reaching_object: 1.3169
    Episode_Reward/rotating_object: 105.5724
        Episode_Reward/action_rate: -0.1564
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 2.07s
                      Time elapsed: 00:48:03
                               ETA: 00:03:52

################################################################################
                     [1m Learning iteration 1389/1500 [0m                     

                       Computation: 46893 steps/s (collection: 1.973s, learning 0.123s)
             Mean action noise std: 5.18
          Mean value_function loss: 106.5823
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 78.0618
                       Mean reward: 544.67
               Mean episode length: 227.54
    Episode_Reward/reaching_object: 1.3357
    Episode_Reward/rotating_object: 107.4239
        Episode_Reward/action_rate: -0.1564
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 2.10s
                      Time elapsed: 00:48:05
                               ETA: 00:03:50

################################################################################
                     [1m Learning iteration 1390/1500 [0m                     

                       Computation: 47613 steps/s (collection: 1.954s, learning 0.110s)
             Mean action noise std: 5.18
          Mean value_function loss: 110.3167
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 78.0700
                       Mean reward: 573.12
               Mean episode length: 227.17
    Episode_Reward/reaching_object: 1.3616
    Episode_Reward/rotating_object: 110.2510
        Episode_Reward/action_rate: -0.1581
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 2.06s
                      Time elapsed: 00:48:07
                               ETA: 00:03:48

################################################################################
                     [1m Learning iteration 1391/1500 [0m                     

                       Computation: 47061 steps/s (collection: 1.978s, learning 0.111s)
             Mean action noise std: 5.19
          Mean value_function loss: 114.2327
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 78.0754
                       Mean reward: 545.66
               Mean episode length: 228.09
    Episode_Reward/reaching_object: 1.3581
    Episode_Reward/rotating_object: 111.0089
        Episode_Reward/action_rate: -0.1593
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 2.09s
                      Time elapsed: 00:48:10
                               ETA: 00:03:46

################################################################################
                     [1m Learning iteration 1392/1500 [0m                     

                       Computation: 46310 steps/s (collection: 2.012s, learning 0.111s)
             Mean action noise std: 5.19
          Mean value_function loss: 103.9959
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 78.0877
                       Mean reward: 538.09
               Mean episode length: 223.21
    Episode_Reward/reaching_object: 1.3216
    Episode_Reward/rotating_object: 107.4777
        Episode_Reward/action_rate: -0.1560
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 2.12s
                      Time elapsed: 00:48:12
                               ETA: 00:03:44

################################################################################
                     [1m Learning iteration 1393/1500 [0m                     

                       Computation: 47506 steps/s (collection: 1.956s, learning 0.114s)
             Mean action noise std: 5.19
          Mean value_function loss: 89.6267
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 78.0981
                       Mean reward: 583.70
               Mean episode length: 240.66
    Episode_Reward/reaching_object: 1.3245
    Episode_Reward/rotating_object: 107.9576
        Episode_Reward/action_rate: -0.1573
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 2.07s
                      Time elapsed: 00:48:14
                               ETA: 00:03:42

################################################################################
                     [1m Learning iteration 1394/1500 [0m                     

                       Computation: 46651 steps/s (collection: 1.995s, learning 0.112s)
             Mean action noise std: 5.19
          Mean value_function loss: 93.2956
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 78.1089
                       Mean reward: 593.60
               Mean episode length: 238.17
    Episode_Reward/reaching_object: 1.3801
    Episode_Reward/rotating_object: 113.3021
        Episode_Reward/action_rate: -0.1633
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 2.11s
                      Time elapsed: 00:48:16
                               ETA: 00:03:40

################################################################################
                     [1m Learning iteration 1395/1500 [0m                     

                       Computation: 47182 steps/s (collection: 1.973s, learning 0.111s)
             Mean action noise std: 5.20
          Mean value_function loss: 98.0957
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 78.1216
                       Mean reward: 566.57
               Mean episode length: 230.24
    Episode_Reward/reaching_object: 1.3772
    Episode_Reward/rotating_object: 113.4730
        Episode_Reward/action_rate: -0.1612
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 2.08s
                      Time elapsed: 00:48:18
                               ETA: 00:03:38

################################################################################
                     [1m Learning iteration 1396/1500 [0m                     

                       Computation: 46495 steps/s (collection: 2.001s, learning 0.114s)
             Mean action noise std: 5.20
          Mean value_function loss: 94.9210
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 78.1362
                       Mean reward: 563.48
               Mean episode length: 228.47
    Episode_Reward/reaching_object: 1.3453
    Episode_Reward/rotating_object: 108.7049
        Episode_Reward/action_rate: -0.1576
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 2.11s
                      Time elapsed: 00:48:20
                               ETA: 00:03:35

################################################################################
                     [1m Learning iteration 1397/1500 [0m                     

                       Computation: 46558 steps/s (collection: 2.001s, learning 0.111s)
             Mean action noise std: 5.20
          Mean value_function loss: 113.3186
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 78.1495
                       Mean reward: 578.28
               Mean episode length: 226.20
    Episode_Reward/reaching_object: 1.3579
    Episode_Reward/rotating_object: 112.4843
        Episode_Reward/action_rate: -0.1593
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 2.11s
                      Time elapsed: 00:48:22
                               ETA: 00:03:33

################################################################################
                     [1m Learning iteration 1398/1500 [0m                     

                       Computation: 46532 steps/s (collection: 1.998s, learning 0.115s)
             Mean action noise std: 5.20
          Mean value_function loss: 109.9095
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 78.1588
                       Mean reward: 551.15
               Mean episode length: 227.10
    Episode_Reward/reaching_object: 1.3402
    Episode_Reward/rotating_object: 107.1690
        Episode_Reward/action_rate: -0.1578
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 2.11s
                      Time elapsed: 00:48:24
                               ETA: 00:03:31

################################################################################
                     [1m Learning iteration 1399/1500 [0m                     

                       Computation: 46473 steps/s (collection: 2.003s, learning 0.113s)
             Mean action noise std: 5.21
          Mean value_function loss: 104.4185
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 78.1697
                       Mean reward: 538.75
               Mean episode length: 226.89
    Episode_Reward/reaching_object: 1.3732
    Episode_Reward/rotating_object: 112.4595
        Episode_Reward/action_rate: -0.1604
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 2.12s
                      Time elapsed: 00:48:26
                               ETA: 00:03:29

################################################################################
                     [1m Learning iteration 1400/1500 [0m                     

                       Computation: 47043 steps/s (collection: 1.980s, learning 0.110s)
             Mean action noise std: 5.21
          Mean value_function loss: 109.7804
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 78.1795
                       Mean reward: 573.36
               Mean episode length: 235.08
    Episode_Reward/reaching_object: 1.3738
    Episode_Reward/rotating_object: 111.3661
        Episode_Reward/action_rate: -0.1606
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 2.09s
                      Time elapsed: 00:48:29
                               ETA: 00:03:27

################################################################################
                     [1m Learning iteration 1401/1500 [0m                     

                       Computation: 46564 steps/s (collection: 1.997s, learning 0.114s)
             Mean action noise std: 5.21
          Mean value_function loss: 102.6755
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 78.1892
                       Mean reward: 579.86
               Mean episode length: 219.24
    Episode_Reward/reaching_object: 1.3715
    Episode_Reward/rotating_object: 110.1876
        Episode_Reward/action_rate: -0.1598
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 2.11s
                      Time elapsed: 00:48:31
                               ETA: 00:03:25

################################################################################
                     [1m Learning iteration 1402/1500 [0m                     

                       Computation: 46322 steps/s (collection: 2.008s, learning 0.114s)
             Mean action noise std: 5.21
          Mean value_function loss: 105.5367
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 78.1985
                       Mean reward: 546.45
               Mean episode length: 227.21
    Episode_Reward/reaching_object: 1.4011
    Episode_Reward/rotating_object: 110.7603
        Episode_Reward/action_rate: -0.1640
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 2.12s
                      Time elapsed: 00:48:33
                               ETA: 00:03:23

################################################################################
                     [1m Learning iteration 1403/1500 [0m                     

                       Computation: 46525 steps/s (collection: 2.001s, learning 0.112s)
             Mean action noise std: 5.22
          Mean value_function loss: 104.2723
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 78.2103
                       Mean reward: 536.81
               Mean episode length: 212.14
    Episode_Reward/reaching_object: 1.3761
    Episode_Reward/rotating_object: 111.4827
        Episode_Reward/action_rate: -0.1607
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 2.11s
                      Time elapsed: 00:48:35
                               ETA: 00:03:21

################################################################################
                     [1m Learning iteration 1404/1500 [0m                     

                       Computation: 46532 steps/s (collection: 1.998s, learning 0.114s)
             Mean action noise std: 5.22
          Mean value_function loss: 100.0787
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 78.2218
                       Mean reward: 555.12
               Mean episode length: 228.31
    Episode_Reward/reaching_object: 1.3476
    Episode_Reward/rotating_object: 109.1266
        Episode_Reward/action_rate: -0.1601
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 2.11s
                      Time elapsed: 00:48:37
                               ETA: 00:03:19

################################################################################
                     [1m Learning iteration 1405/1500 [0m                     

                       Computation: 47102 steps/s (collection: 1.976s, learning 0.111s)
             Mean action noise std: 5.22
          Mean value_function loss: 102.3417
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 78.2340
                       Mean reward: 583.44
               Mean episode length: 224.61
    Episode_Reward/reaching_object: 1.3550
    Episode_Reward/rotating_object: 110.3474
        Episode_Reward/action_rate: -0.1591
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 2.09s
                      Time elapsed: 00:48:39
                               ETA: 00:03:17

################################################################################
                     [1m Learning iteration 1406/1500 [0m                     

                       Computation: 46752 steps/s (collection: 1.991s, learning 0.112s)
             Mean action noise std: 5.23
          Mean value_function loss: 101.4407
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 78.2549
                       Mean reward: 528.61
               Mean episode length: 212.70
    Episode_Reward/reaching_object: 1.3629
    Episode_Reward/rotating_object: 112.3475
        Episode_Reward/action_rate: -0.1622
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 2.10s
                      Time elapsed: 00:48:41
                               ETA: 00:03:15

################################################################################
                     [1m Learning iteration 1407/1500 [0m                     

                       Computation: 47640 steps/s (collection: 1.953s, learning 0.110s)
             Mean action noise std: 5.23
          Mean value_function loss: 101.8523
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 78.2747
                       Mean reward: 578.89
               Mean episode length: 223.32
    Episode_Reward/reaching_object: 1.3719
    Episode_Reward/rotating_object: 112.9314
        Episode_Reward/action_rate: -0.1605
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 2.06s
                      Time elapsed: 00:48:43
                               ETA: 00:03:13

################################################################################
                     [1m Learning iteration 1408/1500 [0m                     

                       Computation: 47304 steps/s (collection: 1.968s, learning 0.110s)
             Mean action noise std: 5.23
          Mean value_function loss: 106.5426
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 78.2928
                       Mean reward: 571.32
               Mean episode length: 226.04
    Episode_Reward/reaching_object: 1.4133
    Episode_Reward/rotating_object: 114.3240
        Episode_Reward/action_rate: -0.1652
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 2.08s
                      Time elapsed: 00:48:45
                               ETA: 00:03:11

################################################################################
                     [1m Learning iteration 1409/1500 [0m                     

                       Computation: 47930 steps/s (collection: 1.941s, learning 0.110s)
             Mean action noise std: 5.24
          Mean value_function loss: 106.6367
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 78.3121
                       Mean reward: 533.86
               Mean episode length: 220.96
    Episode_Reward/reaching_object: 1.3516
    Episode_Reward/rotating_object: 107.1643
        Episode_Reward/action_rate: -0.1595
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 2.05s
                      Time elapsed: 00:48:47
                               ETA: 00:03:08

################################################################################
                     [1m Learning iteration 1410/1500 [0m                     

                       Computation: 47261 steps/s (collection: 1.970s, learning 0.110s)
             Mean action noise std: 5.24
          Mean value_function loss: 110.0267
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 78.3313
                       Mean reward: 487.74
               Mean episode length: 211.15
    Episode_Reward/reaching_object: 1.3497
    Episode_Reward/rotating_object: 107.1360
        Episode_Reward/action_rate: -0.1604
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 2.08s
                      Time elapsed: 00:48:49
                               ETA: 00:03:06

################################################################################
                     [1m Learning iteration 1411/1500 [0m                     

                       Computation: 48096 steps/s (collection: 1.934s, learning 0.110s)
             Mean action noise std: 5.25
          Mean value_function loss: 99.8086
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 78.3462
                       Mean reward: 533.85
               Mean episode length: 215.15
    Episode_Reward/reaching_object: 1.3759
    Episode_Reward/rotating_object: 114.3022
        Episode_Reward/action_rate: -0.1624
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 2.04s
                      Time elapsed: 00:48:51
                               ETA: 00:03:04

################################################################################
                     [1m Learning iteration 1412/1500 [0m                     

                       Computation: 47212 steps/s (collection: 1.967s, learning 0.115s)
             Mean action noise std: 5.25
          Mean value_function loss: 108.7989
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 78.3625
                       Mean reward: 560.93
               Mean episode length: 226.20
    Episode_Reward/reaching_object: 1.3603
    Episode_Reward/rotating_object: 112.2523
        Episode_Reward/action_rate: -0.1612
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 2.08s
                      Time elapsed: 00:48:54
                               ETA: 00:03:02

################################################################################
                     [1m Learning iteration 1413/1500 [0m                     

                       Computation: 47860 steps/s (collection: 1.941s, learning 0.113s)
             Mean action noise std: 5.25
          Mean value_function loss: 103.6869
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 78.3665
                       Mean reward: 552.53
               Mean episode length: 228.96
    Episode_Reward/reaching_object: 1.3383
    Episode_Reward/rotating_object: 110.2037
        Episode_Reward/action_rate: -0.1586
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 2.05s
                      Time elapsed: 00:48:56
                               ETA: 00:03:00

################################################################################
                     [1m Learning iteration 1414/1500 [0m                     

                       Computation: 47407 steps/s (collection: 1.960s, learning 0.114s)
             Mean action noise std: 5.25
          Mean value_function loss: 95.4630
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 78.3763
                       Mean reward: 596.26
               Mean episode length: 234.02
    Episode_Reward/reaching_object: 1.3797
    Episode_Reward/rotating_object: 115.8591
        Episode_Reward/action_rate: -0.1645
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 2.07s
                      Time elapsed: 00:48:58
                               ETA: 00:02:58

################################################################################
                     [1m Learning iteration 1415/1500 [0m                     

                       Computation: 46237 steps/s (collection: 2.014s, learning 0.112s)
             Mean action noise std: 5.26
          Mean value_function loss: 101.7880
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 78.3908
                       Mean reward: 548.68
               Mean episode length: 228.29
    Episode_Reward/reaching_object: 1.3472
    Episode_Reward/rotating_object: 107.4384
        Episode_Reward/action_rate: -0.1601
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 2.13s
                      Time elapsed: 00:49:00
                               ETA: 00:02:56

################################################################################
                     [1m Learning iteration 1416/1500 [0m                     

                       Computation: 47307 steps/s (collection: 1.968s, learning 0.110s)
             Mean action noise std: 5.26
          Mean value_function loss: 101.4904
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 78.4058
                       Mean reward: 548.46
               Mean episode length: 226.23
    Episode_Reward/reaching_object: 1.3399
    Episode_Reward/rotating_object: 111.7631
        Episode_Reward/action_rate: -0.1599
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 2.08s
                      Time elapsed: 00:49:02
                               ETA: 00:02:54

################################################################################
                     [1m Learning iteration 1417/1500 [0m                     

                       Computation: 45599 steps/s (collection: 2.038s, learning 0.118s)
             Mean action noise std: 5.26
          Mean value_function loss: 111.6012
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 78.4194
                       Mean reward: 588.70
               Mean episode length: 226.57
    Episode_Reward/reaching_object: 1.3518
    Episode_Reward/rotating_object: 112.1303
        Episode_Reward/action_rate: -0.1610
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 2.16s
                      Time elapsed: 00:49:04
                               ETA: 00:02:52

################################################################################
                     [1m Learning iteration 1418/1500 [0m                     

                       Computation: 46689 steps/s (collection: 1.992s, learning 0.114s)
             Mean action noise std: 5.26
          Mean value_function loss: 114.2961
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 78.4337
                       Mean reward: 524.23
               Mean episode length: 214.65
    Episode_Reward/reaching_object: 1.3242
    Episode_Reward/rotating_object: 107.8788
        Episode_Reward/action_rate: -0.1596
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 2.11s
                      Time elapsed: 00:49:06
                               ETA: 00:02:50

################################################################################
                     [1m Learning iteration 1419/1500 [0m                     

                       Computation: 46106 steps/s (collection: 2.019s, learning 0.113s)
             Mean action noise std: 5.27
          Mean value_function loss: 99.8637
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 78.4495
                       Mean reward: 580.87
               Mean episode length: 228.08
    Episode_Reward/reaching_object: 1.3899
    Episode_Reward/rotating_object: 113.2988
        Episode_Reward/action_rate: -0.1665
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 2.13s
                      Time elapsed: 00:49:08
                               ETA: 00:02:48

################################################################################
                     [1m Learning iteration 1420/1500 [0m                     

                       Computation: 46161 steps/s (collection: 2.010s, learning 0.119s)
             Mean action noise std: 5.27
          Mean value_function loss: 110.1792
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 78.4589
                       Mean reward: 548.46
               Mean episode length: 219.51
    Episode_Reward/reaching_object: 1.3713
    Episode_Reward/rotating_object: 111.1677
        Episode_Reward/action_rate: -0.1641
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 2.13s
                      Time elapsed: 00:49:10
                               ETA: 00:02:46

################################################################################
                     [1m Learning iteration 1421/1500 [0m                     

                       Computation: 46977 steps/s (collection: 1.979s, learning 0.114s)
             Mean action noise std: 5.27
          Mean value_function loss: 108.9395
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 78.4661
                       Mean reward: 542.11
               Mean episode length: 219.51
    Episode_Reward/reaching_object: 1.3477
    Episode_Reward/rotating_object: 108.9103
        Episode_Reward/action_rate: -0.1619
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 2.09s
                      Time elapsed: 00:49:13
                               ETA: 00:02:44

################################################################################
                     [1m Learning iteration 1422/1500 [0m                     

                       Computation: 46830 steps/s (collection: 1.986s, learning 0.113s)
             Mean action noise std: 5.27
          Mean value_function loss: 111.9936
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 78.4735
                       Mean reward: 559.71
               Mean episode length: 220.33
    Episode_Reward/reaching_object: 1.3686
    Episode_Reward/rotating_object: 112.2358
        Episode_Reward/action_rate: -0.1648
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 2.10s
                      Time elapsed: 00:49:15
                               ETA: 00:02:41

################################################################################
                     [1m Learning iteration 1423/1500 [0m                     

                       Computation: 46611 steps/s (collection: 1.990s, learning 0.119s)
             Mean action noise std: 5.27
          Mean value_function loss: 101.8985
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 78.4809
                       Mean reward: 548.06
               Mean episode length: 222.08
    Episode_Reward/reaching_object: 1.3638
    Episode_Reward/rotating_object: 108.9154
        Episode_Reward/action_rate: -0.1628
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 2.11s
                      Time elapsed: 00:49:17
                               ETA: 00:02:39

################################################################################
                     [1m Learning iteration 1424/1500 [0m                     

                       Computation: 46876 steps/s (collection: 1.979s, learning 0.118s)
             Mean action noise std: 5.28
          Mean value_function loss: 113.8679
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 78.4908
                       Mean reward: 558.89
               Mean episode length: 224.81
    Episode_Reward/reaching_object: 1.3793
    Episode_Reward/rotating_object: 113.3486
        Episode_Reward/action_rate: -0.1652
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 2.10s
                      Time elapsed: 00:49:19
                               ETA: 00:02:37

################################################################################
                     [1m Learning iteration 1425/1500 [0m                     

                       Computation: 47590 steps/s (collection: 1.956s, learning 0.110s)
             Mean action noise std: 5.28
          Mean value_function loss: 105.4470
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 78.5058
                       Mean reward: 549.87
               Mean episode length: 223.18
    Episode_Reward/reaching_object: 1.3540
    Episode_Reward/rotating_object: 109.8208
        Episode_Reward/action_rate: -0.1627
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 2.07s
                      Time elapsed: 00:49:21
                               ETA: 00:02:35

################################################################################
                     [1m Learning iteration 1426/1500 [0m                     

                       Computation: 47095 steps/s (collection: 1.975s, learning 0.112s)
             Mean action noise std: 5.29
          Mean value_function loss: 109.5449
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 78.5204
                       Mean reward: 553.93
               Mean episode length: 229.81
    Episode_Reward/reaching_object: 1.3858
    Episode_Reward/rotating_object: 113.2347
        Episode_Reward/action_rate: -0.1662
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 2.09s
                      Time elapsed: 00:49:23
                               ETA: 00:02:33

################################################################################
                     [1m Learning iteration 1427/1500 [0m                     

                       Computation: 47240 steps/s (collection: 1.959s, learning 0.122s)
             Mean action noise std: 5.29
          Mean value_function loss: 91.0734
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 78.5362
                       Mean reward: 552.24
               Mean episode length: 223.30
    Episode_Reward/reaching_object: 1.3758
    Episode_Reward/rotating_object: 111.1589
        Episode_Reward/action_rate: -0.1647
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 2.08s
                      Time elapsed: 00:49:25
                               ETA: 00:02:31

################################################################################
                     [1m Learning iteration 1428/1500 [0m                     

                       Computation: 46907 steps/s (collection: 1.971s, learning 0.125s)
             Mean action noise std: 5.29
          Mean value_function loss: 98.4480
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 78.5504
                       Mean reward: 542.57
               Mean episode length: 217.81
    Episode_Reward/reaching_object: 1.3652
    Episode_Reward/rotating_object: 110.0949
        Episode_Reward/action_rate: -0.1634
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 2.10s
                      Time elapsed: 00:49:27
                               ETA: 00:02:29

################################################################################
                     [1m Learning iteration 1429/1500 [0m                     

                       Computation: 47005 steps/s (collection: 1.967s, learning 0.124s)
             Mean action noise std: 5.29
          Mean value_function loss: 99.9293
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 78.5603
                       Mean reward: 593.39
               Mean episode length: 236.21
    Episode_Reward/reaching_object: 1.3833
    Episode_Reward/rotating_object: 115.5800
        Episode_Reward/action_rate: -0.1664
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 2.09s
                      Time elapsed: 00:49:29
                               ETA: 00:02:27

################################################################################
                     [1m Learning iteration 1430/1500 [0m                     

                       Computation: 47036 steps/s (collection: 1.957s, learning 0.133s)
             Mean action noise std: 5.30
          Mean value_function loss: 107.3400
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 78.5730
                       Mean reward: 553.26
               Mean episode length: 220.46
    Episode_Reward/reaching_object: 1.3402
    Episode_Reward/rotating_object: 111.3832
        Episode_Reward/action_rate: -0.1620
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 2.09s
                      Time elapsed: 00:49:31
                               ETA: 00:02:25

################################################################################
                     [1m Learning iteration 1431/1500 [0m                     

                       Computation: 48095 steps/s (collection: 1.934s, learning 0.110s)
             Mean action noise std: 5.30
          Mean value_function loss: 100.6936
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 78.5919
                       Mean reward: 596.47
               Mean episode length: 227.84
    Episode_Reward/reaching_object: 1.3860
    Episode_Reward/rotating_object: 118.3126
        Episode_Reward/action_rate: -0.1670
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 2.04s
                      Time elapsed: 00:49:33
                               ETA: 00:02:23

################################################################################
                     [1m Learning iteration 1432/1500 [0m                     

                       Computation: 48302 steps/s (collection: 1.925s, learning 0.110s)
             Mean action noise std: 5.30
          Mean value_function loss: 110.3404
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 78.6019
                       Mean reward: 576.11
               Mean episode length: 225.59
    Episode_Reward/reaching_object: 1.3834
    Episode_Reward/rotating_object: 114.1367
        Episode_Reward/action_rate: -0.1672
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 2.04s
                      Time elapsed: 00:49:35
                               ETA: 00:02:21

################################################################################
                     [1m Learning iteration 1433/1500 [0m                     

                       Computation: 47747 steps/s (collection: 1.942s, learning 0.117s)
             Mean action noise std: 5.30
          Mean value_function loss: 115.4092
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 78.6104
                       Mean reward: 582.60
               Mean episode length: 228.95
    Episode_Reward/reaching_object: 1.3452
    Episode_Reward/rotating_object: 111.1862
        Episode_Reward/action_rate: -0.1642
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 2.06s
                      Time elapsed: 00:49:37
                               ETA: 00:02:19

################################################################################
                     [1m Learning iteration 1434/1500 [0m                     

                       Computation: 47847 steps/s (collection: 1.944s, learning 0.110s)
             Mean action noise std: 5.31
          Mean value_function loss: 112.4406
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 78.6210
                       Mean reward: 567.31
               Mean episode length: 224.63
    Episode_Reward/reaching_object: 1.3279
    Episode_Reward/rotating_object: 108.3768
        Episode_Reward/action_rate: -0.1611
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 2.05s
                      Time elapsed: 00:49:40
                               ETA: 00:02:17

################################################################################
                     [1m Learning iteration 1435/1500 [0m                     

                       Computation: 47683 steps/s (collection: 1.952s, learning 0.110s)
             Mean action noise std: 5.31
          Mean value_function loss: 110.7527
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 78.6377
                       Mean reward: 552.31
               Mean episode length: 220.30
    Episode_Reward/reaching_object: 1.3830
    Episode_Reward/rotating_object: 113.2124
        Episode_Reward/action_rate: -0.1656
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 2.06s
                      Time elapsed: 00:49:42
                               ETA: 00:02:14

################################################################################
                     [1m Learning iteration 1436/1500 [0m                     

                       Computation: 48228 steps/s (collection: 1.927s, learning 0.111s)
             Mean action noise std: 5.31
          Mean value_function loss: 102.6160
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 78.6473
                       Mean reward: 541.74
               Mean episode length: 212.17
    Episode_Reward/reaching_object: 1.3706
    Episode_Reward/rotating_object: 110.3497
        Episode_Reward/action_rate: -0.1648
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 2.04s
                      Time elapsed: 00:49:44
                               ETA: 00:02:12

################################################################################
                     [1m Learning iteration 1437/1500 [0m                     

                       Computation: 47849 steps/s (collection: 1.944s, learning 0.110s)
             Mean action noise std: 5.31
          Mean value_function loss: 105.0804
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 78.6561
                       Mean reward: 549.28
               Mean episode length: 217.13
    Episode_Reward/reaching_object: 1.3749
    Episode_Reward/rotating_object: 111.3427
        Episode_Reward/action_rate: -0.1637
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 2.05s
                      Time elapsed: 00:49:46
                               ETA: 00:02:10

################################################################################
                     [1m Learning iteration 1438/1500 [0m                     

                       Computation: 47328 steps/s (collection: 1.964s, learning 0.113s)
             Mean action noise std: 5.32
          Mean value_function loss: 99.5451
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 78.6686
                       Mean reward: 537.97
               Mean episode length: 218.31
    Episode_Reward/reaching_object: 1.4069
    Episode_Reward/rotating_object: 114.7700
        Episode_Reward/action_rate: -0.1681
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 2.08s
                      Time elapsed: 00:49:48
                               ETA: 00:02:08

################################################################################
                     [1m Learning iteration 1439/1500 [0m                     

                       Computation: 47267 steps/s (collection: 1.970s, learning 0.110s)
             Mean action noise std: 5.32
          Mean value_function loss: 91.3712
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 78.6816
                       Mean reward: 594.64
               Mean episode length: 235.89
    Episode_Reward/reaching_object: 1.4091
    Episode_Reward/rotating_object: 114.4684
        Episode_Reward/action_rate: -0.1688
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 2.08s
                      Time elapsed: 00:49:50
                               ETA: 00:02:06

################################################################################
                     [1m Learning iteration 1440/1500 [0m                     

                       Computation: 47344 steps/s (collection: 1.966s, learning 0.110s)
             Mean action noise std: 5.32
          Mean value_function loss: 105.2863
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 78.6964
                       Mean reward: 552.71
               Mean episode length: 223.55
    Episode_Reward/reaching_object: 1.3587
    Episode_Reward/rotating_object: 107.7571
        Episode_Reward/action_rate: -0.1645
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 2.08s
                      Time elapsed: 00:49:52
                               ETA: 00:02:04

################################################################################
                     [1m Learning iteration 1441/1500 [0m                     

                       Computation: 47346 steps/s (collection: 1.966s, learning 0.110s)
             Mean action noise std: 5.33
          Mean value_function loss: 115.9815
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 78.7081
                       Mean reward: 540.34
               Mean episode length: 218.66
    Episode_Reward/reaching_object: 1.3334
    Episode_Reward/rotating_object: 106.7249
        Episode_Reward/action_rate: -0.1620
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 2.08s
                      Time elapsed: 00:49:54
                               ETA: 00:02:02

################################################################################
                     [1m Learning iteration 1442/1500 [0m                     

                       Computation: 45988 steps/s (collection: 2.025s, learning 0.112s)
             Mean action noise std: 5.33
          Mean value_function loss: 106.6201
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 78.7161
                       Mean reward: 603.16
               Mean episode length: 237.06
    Episode_Reward/reaching_object: 1.4075
    Episode_Reward/rotating_object: 115.8668
        Episode_Reward/action_rate: -0.1699
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 2.14s
                      Time elapsed: 00:49:56
                               ETA: 00:02:00

################################################################################
                     [1m Learning iteration 1443/1500 [0m                     

                       Computation: 46854 steps/s (collection: 1.988s, learning 0.110s)
             Mean action noise std: 5.33
          Mean value_function loss: 100.4794
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 78.7244
                       Mean reward: 567.09
               Mean episode length: 221.74
    Episode_Reward/reaching_object: 1.3618
    Episode_Reward/rotating_object: 113.4219
        Episode_Reward/action_rate: -0.1659
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 2.10s
                      Time elapsed: 00:49:58
                               ETA: 00:01:58

################################################################################
                     [1m Learning iteration 1444/1500 [0m                     

                       Computation: 46793 steps/s (collection: 1.991s, learning 0.110s)
             Mean action noise std: 5.33
          Mean value_function loss: 101.0323
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 78.7379
                       Mean reward: 558.69
               Mean episode length: 228.89
    Episode_Reward/reaching_object: 1.3830
    Episode_Reward/rotating_object: 115.2989
        Episode_Reward/action_rate: -0.1675
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 2.10s
                      Time elapsed: 00:50:00
                               ETA: 00:01:56

################################################################################
                     [1m Learning iteration 1445/1500 [0m                     

                       Computation: 47158 steps/s (collection: 1.972s, learning 0.112s)
             Mean action noise std: 5.34
          Mean value_function loss: 111.6123
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 78.7478
                       Mean reward: 571.81
               Mean episode length: 228.21
    Episode_Reward/reaching_object: 1.3624
    Episode_Reward/rotating_object: 111.0245
        Episode_Reward/action_rate: -0.1663
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 2.08s
                      Time elapsed: 00:50:02
                               ETA: 00:01:54

################################################################################
                     [1m Learning iteration 1446/1500 [0m                     

                       Computation: 47300 steps/s (collection: 1.966s, learning 0.113s)
             Mean action noise std: 5.34
          Mean value_function loss: 98.4317
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 78.7575
                       Mean reward: 608.11
               Mean episode length: 230.63
    Episode_Reward/reaching_object: 1.3706
    Episode_Reward/rotating_object: 116.2342
        Episode_Reward/action_rate: -0.1680
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 2.08s
                      Time elapsed: 00:50:04
                               ETA: 00:01:52

################################################################################
                     [1m Learning iteration 1447/1500 [0m                     

                       Computation: 47679 steps/s (collection: 1.952s, learning 0.110s)
             Mean action noise std: 5.34
          Mean value_function loss: 100.4346
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 78.7697
                       Mean reward: 598.11
               Mean episode length: 223.08
    Episode_Reward/reaching_object: 1.3472
    Episode_Reward/rotating_object: 110.6920
        Episode_Reward/action_rate: -0.1647
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 2.06s
                      Time elapsed: 00:50:07
                               ETA: 00:01:50

################################################################################
                     [1m Learning iteration 1448/1500 [0m                     

                       Computation: 47012 steps/s (collection: 1.973s, learning 0.118s)
             Mean action noise std: 5.35
          Mean value_function loss: 102.5576
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 78.7843
                       Mean reward: 603.61
               Mean episode length: 232.40
    Episode_Reward/reaching_object: 1.3924
    Episode_Reward/rotating_object: 118.6843
        Episode_Reward/action_rate: -0.1703
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 2.09s
                      Time elapsed: 00:50:09
                               ETA: 00:01:47

################################################################################
                     [1m Learning iteration 1449/1500 [0m                     

                       Computation: 46081 steps/s (collection: 2.022s, learning 0.111s)
             Mean action noise std: 5.35
          Mean value_function loss: 110.1085
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 78.7996
                       Mean reward: 603.71
               Mean episode length: 230.16
    Episode_Reward/reaching_object: 1.3881
    Episode_Reward/rotating_object: 116.8310
        Episode_Reward/action_rate: -0.1708
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 2.13s
                      Time elapsed: 00:50:11
                               ETA: 00:01:45

################################################################################
                     [1m Learning iteration 1450/1500 [0m                     

                       Computation: 47258 steps/s (collection: 1.968s, learning 0.112s)
             Mean action noise std: 5.35
          Mean value_function loss: 97.6545
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 78.8136
                       Mean reward: 608.42
               Mean episode length: 234.96
    Episode_Reward/reaching_object: 1.3822
    Episode_Reward/rotating_object: 116.2048
        Episode_Reward/action_rate: -0.1688
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 2.08s
                      Time elapsed: 00:50:13
                               ETA: 00:01:43

################################################################################
                     [1m Learning iteration 1451/1500 [0m                     

                       Computation: 46814 steps/s (collection: 1.987s, learning 0.113s)
             Mean action noise std: 5.36
          Mean value_function loss: 118.4905
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 78.8310
                       Mean reward: 598.78
               Mean episode length: 233.33
    Episode_Reward/reaching_object: 1.3902
    Episode_Reward/rotating_object: 114.0404
        Episode_Reward/action_rate: -0.1693
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 2.10s
                      Time elapsed: 00:50:15
                               ETA: 00:01:41

################################################################################
                     [1m Learning iteration 1452/1500 [0m                     

                       Computation: 47156 steps/s (collection: 1.972s, learning 0.113s)
             Mean action noise std: 5.36
          Mean value_function loss: 109.6886
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 78.8434
                       Mean reward: 549.52
               Mean episode length: 224.38
    Episode_Reward/reaching_object: 1.3500
    Episode_Reward/rotating_object: 110.9887
        Episode_Reward/action_rate: -0.1664
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 2.08s
                      Time elapsed: 00:50:17
                               ETA: 00:01:39

################################################################################
                     [1m Learning iteration 1453/1500 [0m                     

                       Computation: 46805 steps/s (collection: 1.990s, learning 0.110s)
             Mean action noise std: 5.36
          Mean value_function loss: 123.0783
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 78.8521
                       Mean reward: 562.69
               Mean episode length: 228.72
    Episode_Reward/reaching_object: 1.3817
    Episode_Reward/rotating_object: 114.0960
        Episode_Reward/action_rate: -0.1683
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 2.10s
                      Time elapsed: 00:50:19
                               ETA: 00:01:37

################################################################################
                     [1m Learning iteration 1454/1500 [0m                     

                       Computation: 48000 steps/s (collection: 1.937s, learning 0.111s)
             Mean action noise std: 5.36
          Mean value_function loss: 123.8320
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 78.8631
                       Mean reward: 549.05
               Mean episode length: 218.86
    Episode_Reward/reaching_object: 1.3776
    Episode_Reward/rotating_object: 114.1269
        Episode_Reward/action_rate: -0.1690
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 2.05s
                      Time elapsed: 00:50:21
                               ETA: 00:01:35

################################################################################
                     [1m Learning iteration 1455/1500 [0m                     

                       Computation: 47193 steps/s (collection: 1.973s, learning 0.110s)
             Mean action noise std: 5.37
          Mean value_function loss: 123.3219
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 78.8724
                       Mean reward: 564.27
               Mean episode length: 227.12
    Episode_Reward/reaching_object: 1.3189
    Episode_Reward/rotating_object: 105.6996
        Episode_Reward/action_rate: -0.1621
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 2.08s
                      Time elapsed: 00:50:23
                               ETA: 00:01:33

################################################################################
                     [1m Learning iteration 1456/1500 [0m                     

                       Computation: 47423 steps/s (collection: 1.962s, learning 0.111s)
             Mean action noise std: 5.37
          Mean value_function loss: 116.7103
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 78.8800
                       Mean reward: 558.23
               Mean episode length: 217.12
    Episode_Reward/reaching_object: 1.3739
    Episode_Reward/rotating_object: 112.3337
        Episode_Reward/action_rate: -0.1673
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 2.07s
                      Time elapsed: 00:50:25
                               ETA: 00:01:31

################################################################################
                     [1m Learning iteration 1457/1500 [0m                     

                       Computation: 47734 steps/s (collection: 1.949s, learning 0.110s)
             Mean action noise std: 5.37
          Mean value_function loss: 109.4203
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 78.8911
                       Mean reward: 570.94
               Mean episode length: 213.45
    Episode_Reward/reaching_object: 1.3240
    Episode_Reward/rotating_object: 110.3074
        Episode_Reward/action_rate: -0.1631
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 2.06s
                      Time elapsed: 00:50:27
                               ETA: 00:01:29

################################################################################
                     [1m Learning iteration 1458/1500 [0m                     

                       Computation: 47514 steps/s (collection: 1.958s, learning 0.111s)
             Mean action noise std: 5.37
          Mean value_function loss: 100.2869
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 78.8960
                       Mean reward: 607.59
               Mean episode length: 236.24
    Episode_Reward/reaching_object: 1.4020
    Episode_Reward/rotating_object: 113.7576
        Episode_Reward/action_rate: -0.1719
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 2.07s
                      Time elapsed: 00:50:29
                               ETA: 00:01:27

################################################################################
                     [1m Learning iteration 1459/1500 [0m                     

                       Computation: 47877 steps/s (collection: 1.943s, learning 0.111s)
             Mean action noise std: 5.37
          Mean value_function loss: 105.5200
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 78.8993
                       Mean reward: 544.50
               Mean episode length: 227.16
    Episode_Reward/reaching_object: 1.3783
    Episode_Reward/rotating_object: 111.6367
        Episode_Reward/action_rate: -0.1700
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 2.05s
                      Time elapsed: 00:50:32
                               ETA: 00:01:25

################################################################################
                     [1m Learning iteration 1460/1500 [0m                     

                       Computation: 47382 steps/s (collection: 1.964s, learning 0.110s)
             Mean action noise std: 5.38
          Mean value_function loss: 101.2314
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 78.9091
                       Mean reward: 568.78
               Mean episode length: 226.38
    Episode_Reward/reaching_object: 1.3982
    Episode_Reward/rotating_object: 113.1954
        Episode_Reward/action_rate: -0.1729
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 2.07s
                      Time elapsed: 00:50:34
                               ETA: 00:01:23

################################################################################
                     [1m Learning iteration 1461/1500 [0m                     

                       Computation: 47154 steps/s (collection: 1.968s, learning 0.117s)
             Mean action noise std: 5.38
          Mean value_function loss: 109.1295
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 78.9253
                       Mean reward: 553.51
               Mean episode length: 224.38
    Episode_Reward/reaching_object: 1.4268
    Episode_Reward/rotating_object: 114.1629
        Episode_Reward/action_rate: -0.1745
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 2.08s
                      Time elapsed: 00:50:36
                               ETA: 00:01:20

################################################################################
                     [1m Learning iteration 1462/1500 [0m                     

                       Computation: 46439 steps/s (collection: 1.988s, learning 0.129s)
             Mean action noise std: 5.38
          Mean value_function loss: 120.4376
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 78.9393
                       Mean reward: 598.41
               Mean episode length: 230.10
    Episode_Reward/reaching_object: 1.3779
    Episode_Reward/rotating_object: 113.0237
        Episode_Reward/action_rate: -0.1699
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 2.12s
                      Time elapsed: 00:50:38
                               ETA: 00:01:18

################################################################################
                     [1m Learning iteration 1463/1500 [0m                     

                       Computation: 46566 steps/s (collection: 1.982s, learning 0.129s)
             Mean action noise std: 5.39
          Mean value_function loss: 110.6834
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 78.9573
                       Mean reward: 591.53
               Mean episode length: 226.11
    Episode_Reward/reaching_object: 1.3722
    Episode_Reward/rotating_object: 112.6037
        Episode_Reward/action_rate: -0.1670
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 2.11s
                      Time elapsed: 00:50:40
                               ETA: 00:01:16

################################################################################
                     [1m Learning iteration 1464/1500 [0m                     

                       Computation: 45746 steps/s (collection: 2.023s, learning 0.126s)
             Mean action noise std: 5.39
          Mean value_function loss: 110.5838
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 78.9744
                       Mean reward: 534.16
               Mean episode length: 218.15
    Episode_Reward/reaching_object: 1.3915
    Episode_Reward/rotating_object: 113.0751
        Episode_Reward/action_rate: -0.1708
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 2.15s
                      Time elapsed: 00:50:42
                               ETA: 00:01:14

################################################################################
                     [1m Learning iteration 1465/1500 [0m                     

                       Computation: 46907 steps/s (collection: 1.982s, learning 0.114s)
             Mean action noise std: 5.39
          Mean value_function loss: 105.2277
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 78.9822
                       Mean reward: 539.57
               Mean episode length: 220.34
    Episode_Reward/reaching_object: 1.4106
    Episode_Reward/rotating_object: 115.9192
        Episode_Reward/action_rate: -0.1726
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 2.10s
                      Time elapsed: 00:50:44
                               ETA: 00:01:12

################################################################################
                     [1m Learning iteration 1466/1500 [0m                     

                       Computation: 47152 steps/s (collection: 1.970s, learning 0.115s)
             Mean action noise std: 5.39
          Mean value_function loss: 112.6960
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 78.9921
                       Mean reward: 577.20
               Mean episode length: 219.06
    Episode_Reward/reaching_object: 1.4231
    Episode_Reward/rotating_object: 119.0627
        Episode_Reward/action_rate: -0.1728
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 2.08s
                      Time elapsed: 00:50:46
                               ETA: 00:01:10

################################################################################
                     [1m Learning iteration 1467/1500 [0m                     

                       Computation: 46899 steps/s (collection: 1.981s, learning 0.115s)
             Mean action noise std: 5.40
          Mean value_function loss: 117.1653
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 79.0039
                       Mean reward: 525.61
               Mean episode length: 213.73
    Episode_Reward/reaching_object: 1.3584
    Episode_Reward/rotating_object: 108.9443
        Episode_Reward/action_rate: -0.1663
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 2.10s
                      Time elapsed: 00:50:48
                               ETA: 00:01:08

################################################################################
                     [1m Learning iteration 1468/1500 [0m                     

                       Computation: 47405 steps/s (collection: 1.960s, learning 0.113s)
             Mean action noise std: 5.40
          Mean value_function loss: 111.5426
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 79.0117
                       Mean reward: 602.19
               Mean episode length: 227.51
    Episode_Reward/reaching_object: 1.3941
    Episode_Reward/rotating_object: 113.6357
        Episode_Reward/action_rate: -0.1699
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 2.07s
                      Time elapsed: 00:50:50
                               ETA: 00:01:06

################################################################################
                     [1m Learning iteration 1469/1500 [0m                     

                       Computation: 47044 steps/s (collection: 1.979s, learning 0.111s)
             Mean action noise std: 5.40
          Mean value_function loss: 98.9809
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 79.0178
                       Mean reward: 581.70
               Mean episode length: 225.54
    Episode_Reward/reaching_object: 1.3942
    Episode_Reward/rotating_object: 112.2963
        Episode_Reward/action_rate: -0.1715
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 2.09s
                      Time elapsed: 00:50:52
                               ETA: 00:01:04

################################################################################
                     [1m Learning iteration 1470/1500 [0m                     

                       Computation: 46839 steps/s (collection: 1.973s, learning 0.126s)
             Mean action noise std: 5.40
          Mean value_function loss: 93.0735
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 79.0320
                       Mean reward: 601.01
               Mean episode length: 227.83
    Episode_Reward/reaching_object: 1.4077
    Episode_Reward/rotating_object: 114.0808
        Episode_Reward/action_rate: -0.1735
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 2.10s
                      Time elapsed: 00:50:55
                               ETA: 00:01:02

################################################################################
                     [1m Learning iteration 1471/1500 [0m                     

                       Computation: 47258 steps/s (collection: 1.968s, learning 0.112s)
             Mean action noise std: 5.41
          Mean value_function loss: 97.6423
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 79.0438
                       Mean reward: 582.55
               Mean episode length: 225.56
    Episode_Reward/reaching_object: 1.4059
    Episode_Reward/rotating_object: 114.4796
        Episode_Reward/action_rate: -0.1731
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 2.08s
                      Time elapsed: 00:50:57
                               ETA: 00:01:00

################################################################################
                     [1m Learning iteration 1472/1500 [0m                     

                       Computation: 46338 steps/s (collection: 1.989s, learning 0.133s)
             Mean action noise std: 5.41
          Mean value_function loss: 100.1924
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 79.0585
                       Mean reward: 579.66
               Mean episode length: 223.47
    Episode_Reward/reaching_object: 1.3634
    Episode_Reward/rotating_object: 112.9670
        Episode_Reward/action_rate: -0.1697
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 2.12s
                      Time elapsed: 00:50:59
                               ETA: 00:00:58

################################################################################
                     [1m Learning iteration 1473/1500 [0m                     

                       Computation: 47364 steps/s (collection: 1.960s, learning 0.116s)
             Mean action noise std: 5.41
          Mean value_function loss: 106.8110
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 79.0745
                       Mean reward: 600.42
               Mean episode length: 232.14
    Episode_Reward/reaching_object: 1.4274
    Episode_Reward/rotating_object: 119.3225
        Episode_Reward/action_rate: -0.1773
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 2.08s
                      Time elapsed: 00:51:01
                               ETA: 00:00:56

################################################################################
                     [1m Learning iteration 1474/1500 [0m                     

                       Computation: 46988 steps/s (collection: 1.979s, learning 0.113s)
             Mean action noise std: 5.42
          Mean value_function loss: 107.2827
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 79.0882
                       Mean reward: 573.16
               Mean episode length: 214.79
    Episode_Reward/reaching_object: 1.3465
    Episode_Reward/rotating_object: 111.6336
        Episode_Reward/action_rate: -0.1674
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 2.09s
                      Time elapsed: 00:51:03
                               ETA: 00:00:53

################################################################################
                     [1m Learning iteration 1475/1500 [0m                     

                       Computation: 47819 steps/s (collection: 1.943s, learning 0.113s)
             Mean action noise std: 5.42
          Mean value_function loss: 97.4706
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 79.1088
                       Mean reward: 603.82
               Mean episode length: 238.90
    Episode_Reward/reaching_object: 1.4208
    Episode_Reward/rotating_object: 116.6089
        Episode_Reward/action_rate: -0.1762
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 2.06s
                      Time elapsed: 00:51:05
                               ETA: 00:00:51

################################################################################
                     [1m Learning iteration 1476/1500 [0m                     

                       Computation: 46494 steps/s (collection: 2.000s, learning 0.115s)
             Mean action noise std: 5.42
          Mean value_function loss: 115.2960
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 79.1230
                       Mean reward: 549.34
               Mean episode length: 211.26
    Episode_Reward/reaching_object: 1.3426
    Episode_Reward/rotating_object: 111.7320
        Episode_Reward/action_rate: -0.1709
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 2.11s
                      Time elapsed: 00:51:07
                               ETA: 00:00:49

################################################################################
                     [1m Learning iteration 1477/1500 [0m                     

                       Computation: 48004 steps/s (collection: 1.936s, learning 0.111s)
             Mean action noise std: 5.43
          Mean value_function loss: 109.4943
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 79.1369
                       Mean reward: 563.10
               Mean episode length: 222.65
    Episode_Reward/reaching_object: 1.3880
    Episode_Reward/rotating_object: 114.6881
        Episode_Reward/action_rate: -0.1744
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 2.05s
                      Time elapsed: 00:51:09
                               ETA: 00:00:47

################################################################################
                     [1m Learning iteration 1478/1500 [0m                     

                       Computation: 47836 steps/s (collection: 1.945s, learning 0.110s)
             Mean action noise std: 5.43
          Mean value_function loss: 103.9449
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 79.1469
                       Mean reward: 617.97
               Mean episode length: 233.11
    Episode_Reward/reaching_object: 1.4333
    Episode_Reward/rotating_object: 118.2630
        Episode_Reward/action_rate: -0.1770
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 2.06s
                      Time elapsed: 00:51:11
                               ETA: 00:00:45

################################################################################
                     [1m Learning iteration 1479/1500 [0m                     

                       Computation: 48022 steps/s (collection: 1.922s, learning 0.125s)
             Mean action noise std: 5.43
          Mean value_function loss: 111.4845
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 79.1550
                       Mean reward: 581.52
               Mean episode length: 229.74
    Episode_Reward/reaching_object: 1.4057
    Episode_Reward/rotating_object: 116.3127
        Episode_Reward/action_rate: -0.1760
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 2.05s
                      Time elapsed: 00:51:13
                               ETA: 00:00:43

################################################################################
                     [1m Learning iteration 1480/1500 [0m                     

                       Computation: 48093 steps/s (collection: 1.934s, learning 0.110s)
             Mean action noise std: 5.44
          Mean value_function loss: 106.8985
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 79.1672
                       Mean reward: 595.42
               Mean episode length: 224.13
    Episode_Reward/reaching_object: 1.3665
    Episode_Reward/rotating_object: 110.4963
        Episode_Reward/action_rate: -0.1713
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 2.04s
                      Time elapsed: 00:51:15
                               ETA: 00:00:41

################################################################################
                     [1m Learning iteration 1481/1500 [0m                     

                       Computation: 47782 steps/s (collection: 1.933s, learning 0.125s)
             Mean action noise std: 5.44
          Mean value_function loss: 101.8363
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 79.1849
                       Mean reward: 573.28
               Mean episode length: 227.18
    Episode_Reward/reaching_object: 1.3625
    Episode_Reward/rotating_object: 114.0722
        Episode_Reward/action_rate: -0.1723
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 2.06s
                      Time elapsed: 00:51:17
                               ETA: 00:00:39

################################################################################
                     [1m Learning iteration 1482/1500 [0m                     

                       Computation: 48393 steps/s (collection: 1.921s, learning 0.110s)
             Mean action noise std: 5.44
          Mean value_function loss: 103.9779
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 79.2001
                       Mean reward: 609.23
               Mean episode length: 226.69
    Episode_Reward/reaching_object: 1.4049
    Episode_Reward/rotating_object: 116.7095
        Episode_Reward/action_rate: -0.1751
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 2.03s
                      Time elapsed: 00:51:19
                               ETA: 00:00:37

################################################################################
                     [1m Learning iteration 1483/1500 [0m                     

                       Computation: 47959 steps/s (collection: 1.938s, learning 0.112s)
             Mean action noise std: 5.45
          Mean value_function loss: 97.0367
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 79.2136
                       Mean reward: 591.37
               Mean episode length: 228.39
    Episode_Reward/reaching_object: 1.3926
    Episode_Reward/rotating_object: 117.0558
        Episode_Reward/action_rate: -0.1756
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 2.05s
                      Time elapsed: 00:51:21
                               ETA: 00:00:35

################################################################################
                     [1m Learning iteration 1484/1500 [0m                     

                       Computation: 47145 steps/s (collection: 1.974s, learning 0.111s)
             Mean action noise std: 5.45
          Mean value_function loss: 112.4187
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 79.2225
                       Mean reward: 593.99
               Mean episode length: 226.25
    Episode_Reward/reaching_object: 1.3934
    Episode_Reward/rotating_object: 116.2099
        Episode_Reward/action_rate: -0.1761
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 2.09s
                      Time elapsed: 00:51:24
                               ETA: 00:00:33

################################################################################
                     [1m Learning iteration 1485/1500 [0m                     

                       Computation: 46748 steps/s (collection: 1.989s, learning 0.113s)
             Mean action noise std: 5.45
          Mean value_function loss: 109.7356
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 79.2336
                       Mean reward: 616.87
               Mean episode length: 228.00
    Episode_Reward/reaching_object: 1.4013
    Episode_Reward/rotating_object: 118.7089
        Episode_Reward/action_rate: -0.1757
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 2.10s
                      Time elapsed: 00:51:26
                               ETA: 00:00:31

################################################################################
                     [1m Learning iteration 1486/1500 [0m                     

                       Computation: 46891 steps/s (collection: 1.986s, learning 0.110s)
             Mean action noise std: 5.45
          Mean value_function loss: 122.0019
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 79.2461
                       Mean reward: 611.57
               Mean episode length: 227.48
    Episode_Reward/reaching_object: 1.3971
    Episode_Reward/rotating_object: 117.0576
        Episode_Reward/action_rate: -0.1741
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 2.10s
                      Time elapsed: 00:51:28
                               ETA: 00:00:29

################################################################################
                     [1m Learning iteration 1487/1500 [0m                     

                       Computation: 46827 steps/s (collection: 1.989s, learning 0.110s)
             Mean action noise std: 5.45
          Mean value_function loss: 118.4424
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 79.2539
                       Mean reward: 551.31
               Mean episode length: 226.53
    Episode_Reward/reaching_object: 1.3896
    Episode_Reward/rotating_object: 113.1986
        Episode_Reward/action_rate: -0.1757
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 2.10s
                      Time elapsed: 00:51:30
                               ETA: 00:00:26

################################################################################
                     [1m Learning iteration 1488/1500 [0m                     

                       Computation: 46625 steps/s (collection: 1.989s, learning 0.119s)
             Mean action noise std: 5.46
          Mean value_function loss: 118.6128
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 79.2617
                       Mean reward: 564.91
               Mean episode length: 219.52
    Episode_Reward/reaching_object: 1.3992
    Episode_Reward/rotating_object: 115.6869
        Episode_Reward/action_rate: -0.1750
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 2.11s
                      Time elapsed: 00:51:32
                               ETA: 00:00:24

################################################################################
                     [1m Learning iteration 1489/1500 [0m                     

                       Computation: 46181 steps/s (collection: 2.014s, learning 0.114s)
             Mean action noise std: 5.46
          Mean value_function loss: 115.2796
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 79.2691
                       Mean reward: 598.74
               Mean episode length: 226.45
    Episode_Reward/reaching_object: 1.4069
    Episode_Reward/rotating_object: 113.3028
        Episode_Reward/action_rate: -0.1751
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 2.13s
                      Time elapsed: 00:51:34
                               ETA: 00:00:22

################################################################################
                     [1m Learning iteration 1490/1500 [0m                     

                       Computation: 47091 steps/s (collection: 1.975s, learning 0.113s)
             Mean action noise std: 5.46
          Mean value_function loss: 104.7180
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 79.2848
                       Mean reward: 580.80
               Mean episode length: 224.01
    Episode_Reward/reaching_object: 1.4324
    Episode_Reward/rotating_object: 115.0440
        Episode_Reward/action_rate: -0.1782
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 2.09s
                      Time elapsed: 00:51:36
                               ETA: 00:00:20

################################################################################
                     [1m Learning iteration 1491/1500 [0m                     

                       Computation: 47273 steps/s (collection: 1.967s, learning 0.113s)
             Mean action noise std: 5.47
          Mean value_function loss: 109.7193
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 79.2991
                       Mean reward: 549.76
               Mean episode length: 221.86
    Episode_Reward/reaching_object: 1.4292
    Episode_Reward/rotating_object: 116.2507
        Episode_Reward/action_rate: -0.1786
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 2.08s
                      Time elapsed: 00:51:38
                               ETA: 00:00:18

################################################################################
                     [1m Learning iteration 1492/1500 [0m                     

                       Computation: 47097 steps/s (collection: 1.973s, learning 0.114s)
             Mean action noise std: 5.47
          Mean value_function loss: 102.8188
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 79.3055
                       Mean reward: 593.68
               Mean episode length: 225.38
    Episode_Reward/reaching_object: 1.4268
    Episode_Reward/rotating_object: 117.0182
        Episode_Reward/action_rate: -0.1777
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 2.09s
                      Time elapsed: 00:51:40
                               ETA: 00:00:16

################################################################################
                     [1m Learning iteration 1493/1500 [0m                     

                       Computation: 47716 steps/s (collection: 1.947s, learning 0.113s)
             Mean action noise std: 5.47
          Mean value_function loss: 111.0203
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 79.3117
                       Mean reward: 584.87
               Mean episode length: 221.99
    Episode_Reward/reaching_object: 1.4112
    Episode_Reward/rotating_object: 116.0088
        Episode_Reward/action_rate: -0.1760
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 2.06s
                      Time elapsed: 00:51:42
                               ETA: 00:00:14

################################################################################
                     [1m Learning iteration 1494/1500 [0m                     

                       Computation: 47265 steps/s (collection: 1.969s, learning 0.111s)
             Mean action noise std: 5.47
          Mean value_function loss: 98.7977
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 79.3181
                       Mean reward: 613.05
               Mean episode length: 235.52
    Episode_Reward/reaching_object: 1.4279
    Episode_Reward/rotating_object: 118.8477
        Episode_Reward/action_rate: -0.1790
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 2.08s
                      Time elapsed: 00:51:44
                               ETA: 00:00:12

################################################################################
                     [1m Learning iteration 1495/1500 [0m                     

                       Computation: 47459 steps/s (collection: 1.944s, learning 0.128s)
             Mean action noise std: 5.47
          Mean value_function loss: 98.0498
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 79.3273
                       Mean reward: 632.45
               Mean episode length: 231.84
    Episode_Reward/reaching_object: 1.4228
    Episode_Reward/rotating_object: 121.1789
        Episode_Reward/action_rate: -0.1783
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 2.07s
                      Time elapsed: 00:51:47
                               ETA: 00:00:10

################################################################################
                     [1m Learning iteration 1496/1500 [0m                     

                       Computation: 46945 steps/s (collection: 1.970s, learning 0.124s)
             Mean action noise std: 5.48
          Mean value_function loss: 107.2571
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 79.3338
                       Mean reward: 562.81
               Mean episode length: 216.72
    Episode_Reward/reaching_object: 1.3898
    Episode_Reward/rotating_object: 115.2074
        Episode_Reward/action_rate: -0.1741
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 2.09s
                      Time elapsed: 00:51:49
                               ETA: 00:00:08

################################################################################
                     [1m Learning iteration 1497/1500 [0m                     

                       Computation: 46452 steps/s (collection: 1.991s, learning 0.125s)
             Mean action noise std: 5.48
          Mean value_function loss: 115.8498
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 79.3412
                       Mean reward: 618.87
               Mean episode length: 230.07
    Episode_Reward/reaching_object: 1.3954
    Episode_Reward/rotating_object: 116.4930
        Episode_Reward/action_rate: -0.1754
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 2.12s
                      Time elapsed: 00:51:51
                               ETA: 00:00:06

################################################################################
                     [1m Learning iteration 1498/1500 [0m                     

                       Computation: 47186 steps/s (collection: 1.961s, learning 0.123s)
             Mean action noise std: 5.48
          Mean value_function loss: 108.7791
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 79.3469
                       Mean reward: 588.58
               Mean episode length: 220.06
    Episode_Reward/reaching_object: 1.4260
    Episode_Reward/rotating_object: 120.0457
        Episode_Reward/action_rate: -0.1787
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 2.08s
                      Time elapsed: 00:51:53
                               ETA: 00:00:04

################################################################################
                     [1m Learning iteration 1499/1500 [0m                     

                       Computation: 46696 steps/s (collection: 1.981s, learning 0.125s)
             Mean action noise std: 5.48
          Mean value_function loss: 106.7406
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 79.3530
                       Mean reward: 598.01
               Mean episode length: 220.26
    Episode_Reward/reaching_object: 1.4149
    Episode_Reward/rotating_object: 118.6497
        Episode_Reward/action_rate: -0.1764
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 2.11s
                      Time elapsed: 00:51:55
                               ETA: 00:00:02

