################################################################################
                      [1m Learning iteration 0/1500 [0m                       

                       Computation: 22975 steps/s (collection: 4.153s, learning 0.126s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0031
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 36.9391
                       Mean reward: 0.00
               Mean episode length: 21.21
    Episode_Reward/reaching_object: 0.0008
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0003
          Episode_Reward/joint_vel: -0.0004
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 4.28s
                      Time elapsed: 00:00:04
                               ETA: 01:46:58

################################################################################
                      [1m Learning iteration 1/1500 [0m                       

                       Computation: 54215 steps/s (collection: 1.701s, learning 0.112s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0003
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 37.0728
                       Mean reward: 0.00
               Mean episode length: 45.83
    Episode_Reward/reaching_object: 0.0021
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0008
          Episode_Reward/joint_vel: -0.0011
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 1.81s
                      Time elapsed: 00:00:06
                               ETA: 01:16:05

################################################################################
                      [1m Learning iteration 2/1500 [0m                       

                       Computation: 54038 steps/s (collection: 1.689s, learning 0.130s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 37.1378
                       Mean reward: 0.00
               Mean episode length: 69.78
    Episode_Reward/reaching_object: 0.0032
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0013
          Episode_Reward/joint_vel: -0.0018
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 1.82s
                      Time elapsed: 00:00:07
                               ETA: 01:05:50

################################################################################
                      [1m Learning iteration 3/1500 [0m                       

                       Computation: 54336 steps/s (collection: 1.695s, learning 0.114s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 37.1838
                       Mean reward: 0.00
               Mean episode length: 93.42
    Episode_Reward/reaching_object: 0.0044
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0018
          Episode_Reward/joint_vel: -0.0025
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 1.81s
                      Time elapsed: 00:00:09
                               ETA: 01:00:37

################################################################################
                      [1m Learning iteration 4/1500 [0m                       

                       Computation: 54544 steps/s (collection: 1.691s, learning 0.111s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 37.1962
                       Mean reward: 0.00
               Mean episode length: 117.74
    Episode_Reward/reaching_object: 0.0056
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0023
          Episode_Reward/joint_vel: -0.0033
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 1.80s
                      Time elapsed: 00:00:11
                               ETA: 00:57:27

################################################################################
                      [1m Learning iteration 5/1500 [0m                       

                       Computation: 55086 steps/s (collection: 1.674s, learning 0.111s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 37.2114
                       Mean reward: 0.00
               Mean episode length: 141.96
    Episode_Reward/reaching_object: 0.0068
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0028
          Episode_Reward/joint_vel: -0.0040
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 1.78s
                      Time elapsed: 00:00:13
                               ETA: 00:55:15

################################################################################
                      [1m Learning iteration 6/1500 [0m                       

                       Computation: 55572 steps/s (collection: 1.659s, learning 0.110s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 37.2072
                       Mean reward: -0.00
               Mean episode length: 165.77
    Episode_Reward/reaching_object: 0.0077
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0033
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 1.77s
                      Time elapsed: 00:00:15
                               ETA: 00:53:37

################################################################################
                      [1m Learning iteration 7/1500 [0m                       

                       Computation: 55344 steps/s (collection: 1.666s, learning 0.110s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 37.1946
                       Mean reward: -0.00
               Mean episode length: 189.36
    Episode_Reward/reaching_object: 0.0089
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0038
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 1.78s
                      Time elapsed: 00:00:16
                               ETA: 00:52:25

################################################################################
                      [1m Learning iteration 8/1500 [0m                       

                       Computation: 55792 steps/s (collection: 1.651s, learning 0.111s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 37.1827
                       Mean reward: -0.00
               Mean episode length: 213.10
    Episode_Reward/reaching_object: 0.0097
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0043
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 1.76s
                      Time elapsed: 00:00:18
                               ETA: 00:51:25

################################################################################
                      [1m Learning iteration 9/1500 [0m                       

                       Computation: 55719 steps/s (collection: 1.654s, learning 0.110s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 37.1435
                       Mean reward: -0.01
               Mean episode length: 237.13
    Episode_Reward/reaching_object: 0.0110
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 1.76s
                      Time elapsed: 00:00:20
                               ETA: 00:50:38

################################################################################
                      [1m Learning iteration 10/1500 [0m                      

                       Computation: 55400 steps/s (collection: 1.664s, learning 0.110s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 37.1150
                       Mean reward: 0.00
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0125
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 1.77s
                      Time elapsed: 00:00:22
                               ETA: 00:50:00

################################################################################
                      [1m Learning iteration 11/1500 [0m                      

                       Computation: 55664 steps/s (collection: 1.656s, learning 0.110s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 37.1217
                       Mean reward: 0.01
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0133
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 1.77s
                      Time elapsed: 00:00:23
                               ETA: 00:49:27

################################################################################
                      [1m Learning iteration 12/1500 [0m                      

                       Computation: 55478 steps/s (collection: 1.662s, learning 0.110s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 37.1168
                       Mean reward: 0.02
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0156
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 1.77s
                      Time elapsed: 00:00:25
                               ETA: 00:49:00

################################################################################
                      [1m Learning iteration 13/1500 [0m                      

                       Computation: 54702 steps/s (collection: 1.683s, learning 0.114s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 37.0858
                       Mean reward: 0.02
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0177
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 1.80s
                      Time elapsed: 00:00:27
                               ETA: 00:48:39

################################################################################
                      [1m Learning iteration 14/1500 [0m                      

                       Computation: 53135 steps/s (collection: 1.733s, learning 0.117s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 37.0852
                       Mean reward: 0.05
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0202
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 1.85s
                      Time elapsed: 00:00:29
                               ETA: 00:48:26

################################################################################
                      [1m Learning iteration 15/1500 [0m                      

                       Computation: 53703 steps/s (collection: 1.717s, learning 0.114s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 37.1093
                       Mean reward: 0.07
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0258
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0073
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 1.83s
                      Time elapsed: 00:00:31
                               ETA: 00:48:12

################################################################################
                      [1m Learning iteration 16/1500 [0m                      

                       Computation: 53801 steps/s (collection: 1.715s, learning 0.112s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 37.1259
                       Mean reward: 0.09
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0304
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 1.83s
                      Time elapsed: 00:00:32
                               ETA: 00:48:00

################################################################################
                      [1m Learning iteration 17/1500 [0m                      

                       Computation: 53650 steps/s (collection: 1.705s, learning 0.127s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 37.1694
                       Mean reward: 0.16
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0405
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 1.83s
                      Time elapsed: 00:00:34
                               ETA: 00:47:49

################################################################################
                      [1m Learning iteration 18/1500 [0m                      

                       Computation: 54462 steps/s (collection: 1.692s, learning 0.113s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0003
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 37.1983
                       Mean reward: 0.20
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0527
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 1.81s
                      Time elapsed: 00:00:36
                               ETA: 00:47:37

################################################################################
                      [1m Learning iteration 19/1500 [0m                      

                       Computation: 54125 steps/s (collection: 1.706s, learning 0.111s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0006
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 37.2535
                       Mean reward: 0.31
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0701
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 1.82s
                      Time elapsed: 00:00:38
                               ETA: 00:47:27

################################################################################
                      [1m Learning iteration 20/1500 [0m                      

                       Computation: 52686 steps/s (collection: 1.751s, learning 0.115s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0010
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 37.2898
                       Mean reward: 0.46
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0903
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 1.87s
                      Time elapsed: 00:00:40
                               ETA: 00:47:21

################################################################################
                      [1m Learning iteration 21/1500 [0m                      

                       Computation: 51562 steps/s (collection: 1.788s, learning 0.118s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0016
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 37.3218
                       Mean reward: 0.58
               Mean episode length: 249.79
    Episode_Reward/reaching_object: 0.1199
    Episode_Reward/rotating_object: 0.0001
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 1.91s
                      Time elapsed: 00:00:42
                               ETA: 00:47:18

################################################################################
                      [1m Learning iteration 22/1500 [0m                      

                       Computation: 49736 steps/s (collection: 1.861s, learning 0.115s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0054
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 37.3533
                       Mean reward: 0.86
               Mean episode length: 249.77
    Episode_Reward/reaching_object: 0.1602
    Episode_Reward/rotating_object: 0.0003
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 1.98s
                      Time elapsed: 00:00:44
                               ETA: 00:47:20

################################################################################
                      [1m Learning iteration 23/1500 [0m                      

                       Computation: 49248 steps/s (collection: 1.884s, learning 0.112s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0073
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 37.4358
                       Mean reward: 1.05
               Mean episode length: 248.01
    Episode_Reward/reaching_object: 0.2028
    Episode_Reward/rotating_object: 0.0011
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0071
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 2.00s
                      Time elapsed: 00:00:46
                               ETA: 00:47:22

################################################################################
                      [1m Learning iteration 24/1500 [0m                      

                       Computation: 48267 steps/s (collection: 1.924s, learning 0.113s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0053
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 37.4636
                       Mean reward: 1.31
               Mean episode length: 242.18
    Episode_Reward/reaching_object: 0.2551
    Episode_Reward/rotating_object: 0.0046
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0071
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 2.04s
                      Time elapsed: 00:00:48
                               ETA: 00:47:27

################################################################################
                      [1m Learning iteration 25/1500 [0m                      

                       Computation: 47997 steps/s (collection: 1.935s, learning 0.113s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0076
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 37.4979
                       Mean reward: 1.55
               Mean episode length: 243.66
    Episode_Reward/reaching_object: 0.2937
    Episode_Reward/rotating_object: 0.0057
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0071
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 2.05s
                      Time elapsed: 00:00:50
                               ETA: 00:47:32

################################################################################
                      [1m Learning iteration 26/1500 [0m                      

                       Computation: 47489 steps/s (collection: 1.955s, learning 0.115s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0090
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 37.5228
                       Mean reward: 1.84
               Mean episode length: 237.13
    Episode_Reward/reaching_object: 0.3452
    Episode_Reward/rotating_object: 0.0184
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0071
      Episode_Termination/time_out: 11.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 2.07s
                      Time elapsed: 00:00:52
                               ETA: 00:47:37

################################################################################
                      [1m Learning iteration 27/1500 [0m                      

                       Computation: 46832 steps/s (collection: 1.987s, learning 0.112s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0168
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 37.5816
                       Mean reward: 1.93
               Mean episode length: 232.70
    Episode_Reward/reaching_object: 0.3774
    Episode_Reward/rotating_object: 0.0120
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 9.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.9167
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 2.10s
                      Time elapsed: 00:00:54
                               ETA: 00:47:44

################################################################################
                      [1m Learning iteration 28/1500 [0m                      

                       Computation: 46459 steps/s (collection: 2.002s, learning 0.114s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0113
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 37.6096
                       Mean reward: 1.97
               Mean episode length: 226.37
    Episode_Reward/reaching_object: 0.3959
    Episode_Reward/rotating_object: 0.0106
        Episode_Reward/action_rate: -0.0050
          Episode_Reward/joint_vel: -0.0071
      Episode_Termination/time_out: 8.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 2.12s
                      Time elapsed: 00:00:56
                               ETA: 00:47:51

################################################################################
                      [1m Learning iteration 29/1500 [0m                      

                       Computation: 46366 steps/s (collection: 2.004s, learning 0.116s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0228
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 37.7142
                       Mean reward: 2.24
               Mean episode length: 222.66
    Episode_Reward/reaching_object: 0.4335
    Episode_Reward/rotating_object: 0.0232
        Episode_Reward/action_rate: -0.0050
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 6.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 2.12s
                      Time elapsed: 00:00:58
                               ETA: 00:47:57

################################################################################
                      [1m Learning iteration 30/1500 [0m                      

                       Computation: 46279 steps/s (collection: 2.009s, learning 0.115s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0326
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 37.8471
                       Mean reward: 2.30
               Mean episode length: 218.19
    Episode_Reward/reaching_object: 0.4593
    Episode_Reward/rotating_object: 0.0161
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0073
      Episode_Termination/time_out: 4.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 2.12s
                      Time elapsed: 00:01:00
                               ETA: 00:48:03

################################################################################
                      [1m Learning iteration 31/1500 [0m                      

                       Computation: 46731 steps/s (collection: 1.988s, learning 0.116s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0200
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 37.9832
                       Mean reward: 2.36
               Mean episode length: 219.76
    Episode_Reward/reaching_object: 0.4763
    Episode_Reward/rotating_object: 0.0567
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 4.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 2.10s
                      Time elapsed: 00:01:02
                               ETA: 00:48:08

################################################################################
                      [1m Learning iteration 32/1500 [0m                      

                       Computation: 46547 steps/s (collection: 1.997s, learning 0.115s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0381
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 38.0779
                       Mean reward: 2.58
               Mean episode length: 216.92
    Episode_Reward/reaching_object: 0.4969
    Episode_Reward/rotating_object: 0.0535
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 4.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 2.11s
                      Time elapsed: 00:01:05
                               ETA: 00:48:12

################################################################################
                      [1m Learning iteration 33/1500 [0m                      

                       Computation: 46283 steps/s (collection: 2.010s, learning 0.114s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0713
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 38.2009
                       Mean reward: 3.56
               Mean episode length: 217.93
    Episode_Reward/reaching_object: 0.5350
    Episode_Reward/rotating_object: 0.0892
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 5.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 2.12s
                      Time elapsed: 00:01:07
                               ETA: 00:48:17

################################################################################
                      [1m Learning iteration 34/1500 [0m                      

                       Computation: 45505 steps/s (collection: 2.049s, learning 0.111s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.1266
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 38.3243
                       Mean reward: 3.04
               Mean episode length: 221.69
    Episode_Reward/reaching_object: 0.5598
    Episode_Reward/rotating_object: 0.0631
        Episode_Reward/action_rate: -0.0050
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 5.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.2500
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 2.16s
                      Time elapsed: 00:01:09
                               ETA: 00:48:23

################################################################################
                      [1m Learning iteration 35/1500 [0m                      

                       Computation: 45354 steps/s (collection: 2.056s, learning 0.112s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.1662
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 38.3829
                       Mean reward: 3.88
               Mean episode length: 217.54
    Episode_Reward/reaching_object: 0.6035
    Episode_Reward/rotating_object: 0.0765
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 8.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 2.17s
                      Time elapsed: 00:01:11
                               ETA: 00:48:28

################################################################################
                      [1m Learning iteration 36/1500 [0m                      

                       Computation: 45115 steps/s (collection: 2.069s, learning 0.110s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.1777
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 38.5808
                       Mean reward: 3.62
               Mean episode length: 220.95
    Episode_Reward/reaching_object: 0.6290
    Episode_Reward/rotating_object: 0.1950
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 9.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.0417
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 2.18s
                      Time elapsed: 00:01:13
                               ETA: 00:48:34

################################################################################
                      [1m Learning iteration 37/1500 [0m                      

                       Computation: 44746 steps/s (collection: 2.083s, learning 0.114s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.1815
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 38.7285
                       Mean reward: 3.52
               Mean episode length: 226.50
    Episode_Reward/reaching_object: 0.6643
    Episode_Reward/rotating_object: 0.1404
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 10.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 2.20s
                      Time elapsed: 00:01:15
                               ETA: 00:48:40

################################################################################
                      [1m Learning iteration 38/1500 [0m                      

                       Computation: 44136 steps/s (collection: 2.116s, learning 0.111s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.3406
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 38.8873
                       Mean reward: 5.81
               Mean episode length: 226.26
    Episode_Reward/reaching_object: 0.7155
    Episode_Reward/rotating_object: 0.2787
        Episode_Reward/action_rate: -0.0055
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 2.23s
                      Time elapsed: 00:01:18
                               ETA: 00:48:46

################################################################################
                      [1m Learning iteration 39/1500 [0m                      

                       Computation: 43722 steps/s (collection: 2.135s, learning 0.113s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.6503
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 38.9713
                       Mean reward: 5.65
               Mean episode length: 236.80
    Episode_Reward/reaching_object: 0.7481
    Episode_Reward/rotating_object: 0.2695
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 2.25s
                      Time elapsed: 00:01:20
                               ETA: 00:48:53

################################################################################
                      [1m Learning iteration 40/1500 [0m                      

                       Computation: 44081 steps/s (collection: 2.120s, learning 0.111s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.6966
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 39.0756
                       Mean reward: 5.83
               Mean episode length: 234.31
    Episode_Reward/reaching_object: 0.7371
    Episode_Reward/rotating_object: 0.3426
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 11.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 2.23s
                      Time elapsed: 00:01:22
                               ETA: 00:48:59

################################################################################
                      [1m Learning iteration 41/1500 [0m                      

                       Computation: 43979 steps/s (collection: 2.122s, learning 0.114s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.5560
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 39.2168
                       Mean reward: 5.74
               Mean episode length: 229.32
    Episode_Reward/reaching_object: 0.8059
    Episode_Reward/rotating_object: 0.3673
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 2.24s
                      Time elapsed: 00:01:24
                               ETA: 00:49:05

################################################################################
                      [1m Learning iteration 42/1500 [0m                      

                       Computation: 41634 steps/s (collection: 2.224s, learning 0.137s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.6499
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 39.2961
                       Mean reward: 6.47
               Mean episode length: 232.01
    Episode_Reward/reaching_object: 0.8364
    Episode_Reward/rotating_object: 0.6750
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 2.36s
                      Time elapsed: 00:01:27
                               ETA: 00:49:15

################################################################################
                      [1m Learning iteration 43/1500 [0m                      

                       Computation: 44310 steps/s (collection: 2.108s, learning 0.111s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.3939
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 39.4643
                       Mean reward: 5.81
               Mean episode length: 229.77
    Episode_Reward/reaching_object: 0.8402
    Episode_Reward/rotating_object: 0.5120
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 2.22s
                      Time elapsed: 00:01:29
                               ETA: 00:49:19

################################################################################
                      [1m Learning iteration 44/1500 [0m                      

                       Computation: 43919 steps/s (collection: 2.128s, learning 0.110s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.5989
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 39.5691
                       Mean reward: 5.89
               Mean episode length: 239.51
    Episode_Reward/reaching_object: 0.8723
    Episode_Reward/rotating_object: 0.3628
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 2.24s
                      Time elapsed: 00:01:31
                               ETA: 00:49:24

################################################################################
                      [1m Learning iteration 45/1500 [0m                      

                       Computation: 44104 steps/s (collection: 2.116s, learning 0.113s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.8544
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 39.6765
                       Mean reward: 7.09
               Mean episode length: 232.38
    Episode_Reward/reaching_object: 0.8874
    Episode_Reward/rotating_object: 0.3984
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 2.23s
                      Time elapsed: 00:01:33
                               ETA: 00:49:28

################################################################################
                      [1m Learning iteration 46/1500 [0m                      

                       Computation: 44053 steps/s (collection: 2.117s, learning 0.114s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.9004
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 39.7214
                       Mean reward: 6.16
               Mean episode length: 236.94
    Episode_Reward/reaching_object: 0.9042
    Episode_Reward/rotating_object: 0.6040
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 2.23s
                      Time elapsed: 00:01:36
                               ETA: 00:49:32

################################################################################
                      [1m Learning iteration 47/1500 [0m                      

                       Computation: 43769 steps/s (collection: 2.130s, learning 0.116s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.9341
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 39.8241
                       Mean reward: 8.03
               Mean episode length: 238.93
    Episode_Reward/reaching_object: 0.8856
    Episode_Reward/rotating_object: 0.9649
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 2.25s
                      Time elapsed: 00:01:38
                               ETA: 00:49:36

################################################################################
                      [1m Learning iteration 48/1500 [0m                      

                       Computation: 44167 steps/s (collection: 2.115s, learning 0.111s)
             Mean action noise std: 1.13
          Mean value_function loss: 1.1642
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.9233
                       Mean reward: 6.36
               Mean episode length: 235.40
    Episode_Reward/reaching_object: 0.8988
    Episode_Reward/rotating_object: 0.6631
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 2.23s
                      Time elapsed: 00:01:40
                               ETA: 00:49:39

################################################################################
                      [1m Learning iteration 49/1500 [0m                      

                       Computation: 43889 steps/s (collection: 2.126s, learning 0.114s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.8369
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 40.0099
                       Mean reward: 7.21
               Mean episode length: 237.35
    Episode_Reward/reaching_object: 0.9003
    Episode_Reward/rotating_object: 0.7336
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 2.24s
                      Time elapsed: 00:01:42
                               ETA: 00:49:42

################################################################################
                      [1m Learning iteration 50/1500 [0m                      

                       Computation: 43574 steps/s (collection: 2.143s, learning 0.113s)
             Mean action noise std: 1.14
          Mean value_function loss: 1.0622
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 40.1172
                       Mean reward: 7.29
               Mean episode length: 242.24
    Episode_Reward/reaching_object: 0.9559
    Episode_Reward/rotating_object: 0.8615
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 2.26s
                      Time elapsed: 00:01:45
                               ETA: 00:49:46

################################################################################
                      [1m Learning iteration 51/1500 [0m                      

                       Computation: 43328 steps/s (collection: 2.144s, learning 0.124s)
             Mean action noise std: 1.14
          Mean value_function loss: 1.0669
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 40.2312
                       Mean reward: 8.43
               Mean episode length: 235.04
    Episode_Reward/reaching_object: 0.9399
    Episode_Reward/rotating_object: 0.8184
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 2.27s
                      Time elapsed: 00:01:47
                               ETA: 00:49:50

################################################################################
                      [1m Learning iteration 52/1500 [0m                      

                       Computation: 43538 steps/s (collection: 2.135s, learning 0.123s)
             Mean action noise std: 1.14
          Mean value_function loss: 1.0461
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 40.3161
                       Mean reward: 9.80
               Mean episode length: 237.02
    Episode_Reward/reaching_object: 0.9357
    Episode_Reward/rotating_object: 0.6783
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 2.26s
                      Time elapsed: 00:01:49
                               ETA: 00:49:53

################################################################################
                      [1m Learning iteration 53/1500 [0m                      

                       Computation: 44498 steps/s (collection: 2.089s, learning 0.120s)
             Mean action noise std: 1.14
          Mean value_function loss: 1.2762
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 40.3450
                       Mean reward: 10.60
               Mean episode length: 237.62
    Episode_Reward/reaching_object: 0.9682
    Episode_Reward/rotating_object: 0.9320
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 2.21s
                      Time elapsed: 00:01:51
                               ETA: 00:49:55

################################################################################
                      [1m Learning iteration 54/1500 [0m                      

                       Computation: 44434 steps/s (collection: 2.100s, learning 0.112s)
             Mean action noise std: 1.15
          Mean value_function loss: 0.8930
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 40.4003
                       Mean reward: 9.83
               Mean episode length: 245.12
    Episode_Reward/reaching_object: 0.9605
    Episode_Reward/rotating_object: 1.1714
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 2.21s
                      Time elapsed: 00:01:53
                               ETA: 00:49:56

################################################################################
                      [1m Learning iteration 55/1500 [0m                      

                       Computation: 44427 steps/s (collection: 2.100s, learning 0.112s)
             Mean action noise std: 1.15
          Mean value_function loss: 1.3487
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 40.4340
                       Mean reward: 7.87
               Mean episode length: 244.55
    Episode_Reward/reaching_object: 0.9593
    Episode_Reward/rotating_object: 0.5583
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 2.21s
                      Time elapsed: 00:01:56
                               ETA: 00:49:58

################################################################################
                      [1m Learning iteration 56/1500 [0m                      

                       Computation: 43467 steps/s (collection: 2.143s, learning 0.119s)
             Mean action noise std: 1.15
          Mean value_function loss: 1.6381
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 40.5332
                       Mean reward: 8.52
               Mean episode length: 237.91
    Episode_Reward/reaching_object: 0.9643
    Episode_Reward/rotating_object: 1.0928
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 2.26s
                      Time elapsed: 00:01:58
                               ETA: 00:50:00

################################################################################
                      [1m Learning iteration 57/1500 [0m                      

                       Computation: 44208 steps/s (collection: 2.110s, learning 0.114s)
             Mean action noise std: 1.16
          Mean value_function loss: 1.6875
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 40.6299
                       Mean reward: 9.30
               Mean episode length: 240.35
    Episode_Reward/reaching_object: 0.9388
    Episode_Reward/rotating_object: 0.8996
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 2.22s
                      Time elapsed: 00:02:00
                               ETA: 00:50:02

################################################################################
                      [1m Learning iteration 58/1500 [0m                      

                       Computation: 44436 steps/s (collection: 2.098s, learning 0.114s)
             Mean action noise std: 1.16
          Mean value_function loss: 1.2614
               Mean surrogate loss: 0.0015
                 Mean entropy loss: 40.7548
                       Mean reward: 10.26
               Mean episode length: 236.59
    Episode_Reward/reaching_object: 0.9237
    Episode_Reward/rotating_object: 1.0495
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 2.21s
                      Time elapsed: 00:02:02
                               ETA: 00:50:03

################################################################################
                      [1m Learning iteration 59/1500 [0m                      

                       Computation: 43758 steps/s (collection: 2.122s, learning 0.124s)
             Mean action noise std: 1.16
          Mean value_function loss: 0.9845
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 40.7831
                       Mean reward: 8.33
               Mean episode length: 235.85
    Episode_Reward/reaching_object: 0.9504
    Episode_Reward/rotating_object: 1.3884
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 2.25s
                      Time elapsed: 00:02:05
                               ETA: 00:50:05

################################################################################
                      [1m Learning iteration 60/1500 [0m                      

                       Computation: 43644 steps/s (collection: 2.141s, learning 0.111s)
             Mean action noise std: 1.17
          Mean value_function loss: 1.4693
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.8731
                       Mean reward: 8.49
               Mean episode length: 232.65
    Episode_Reward/reaching_object: 0.9237
    Episode_Reward/rotating_object: 0.9844
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 2.25s
                      Time elapsed: 00:02:07
                               ETA: 00:50:07

################################################################################
                      [1m Learning iteration 61/1500 [0m                      

                       Computation: 43415 steps/s (collection: 2.151s, learning 0.113s)
             Mean action noise std: 1.17
          Mean value_function loss: 1.5685
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 40.9679
                       Mean reward: 10.97
               Mean episode length: 238.84
    Episode_Reward/reaching_object: 0.9293
    Episode_Reward/rotating_object: 0.9572
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 2.26s
                      Time elapsed: 00:02:09
                               ETA: 00:50:09

################################################################################
                      [1m Learning iteration 62/1500 [0m                      

                       Computation: 41648 steps/s (collection: 2.249s, learning 0.111s)
             Mean action noise std: 1.17
          Mean value_function loss: 1.7288
               Mean surrogate loss: 0.0021
                 Mean entropy loss: 41.0380
                       Mean reward: 9.48
               Mean episode length: 240.89
    Episode_Reward/reaching_object: 0.9584
    Episode_Reward/rotating_object: 1.2818
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 2.36s
                      Time elapsed: 00:02:12
                               ETA: 00:50:13

################################################################################
                      [1m Learning iteration 63/1500 [0m                      

                       Computation: 42582 steps/s (collection: 2.197s, learning 0.111s)
             Mean action noise std: 1.18
          Mean value_function loss: 1.5662
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 41.0538
                       Mean reward: 12.39
               Mean episode length: 239.57
    Episode_Reward/reaching_object: 0.9456
    Episode_Reward/rotating_object: 1.1728
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 2.31s
                      Time elapsed: 00:02:14
                               ETA: 00:50:16

################################################################################
                      [1m Learning iteration 64/1500 [0m                      

                       Computation: 42960 steps/s (collection: 2.174s, learning 0.114s)
             Mean action noise std: 1.18
          Mean value_function loss: 2.2674
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 41.1130
                       Mean reward: 17.26
               Mean episode length: 239.09
    Episode_Reward/reaching_object: 0.9560
    Episode_Reward/rotating_object: 1.3742
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 2.29s
                      Time elapsed: 00:02:16
                               ETA: 00:50:18

################################################################################
                      [1m Learning iteration 65/1500 [0m                      

                       Computation: 43317 steps/s (collection: 2.156s, learning 0.114s)
             Mean action noise std: 1.18
          Mean value_function loss: 2.4133
               Mean surrogate loss: 0.0019
                 Mean entropy loss: 41.1842
                       Mean reward: 13.04
               Mean episode length: 242.11
    Episode_Reward/reaching_object: 0.9642
    Episode_Reward/rotating_object: 1.1604
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 2.27s
                      Time elapsed: 00:02:18
                               ETA: 00:50:19

################################################################################
                      [1m Learning iteration 66/1500 [0m                      

                       Computation: 43704 steps/s (collection: 2.135s, learning 0.114s)
             Mean action noise std: 1.18
          Mean value_function loss: 2.4458
               Mean surrogate loss: 0.0021
                 Mean entropy loss: 41.2050
                       Mean reward: 10.54
               Mean episode length: 243.39
    Episode_Reward/reaching_object: 0.9862
    Episode_Reward/rotating_object: 1.1194
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 2.25s
                      Time elapsed: 00:02:21
                               ETA: 00:50:20

################################################################################
                      [1m Learning iteration 67/1500 [0m                      

                       Computation: 43827 steps/s (collection: 2.131s, learning 0.112s)
             Mean action noise std: 1.18
          Mean value_function loss: 2.5151
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 41.2203
                       Mean reward: 15.50
               Mean episode length: 240.50
    Episode_Reward/reaching_object: 0.9684
    Episode_Reward/rotating_object: 1.5733
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 2.24s
                      Time elapsed: 00:02:23
                               ETA: 00:50:21

################################################################################
                      [1m Learning iteration 68/1500 [0m                      

                       Computation: 43834 steps/s (collection: 2.129s, learning 0.114s)
             Mean action noise std: 1.18
          Mean value_function loss: 2.4269
               Mean surrogate loss: 0.0028
                 Mean entropy loss: 41.2556
                       Mean reward: 10.76
               Mean episode length: 239.61
    Episode_Reward/reaching_object: 0.9498
    Episode_Reward/rotating_object: 1.6660
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 2.24s
                      Time elapsed: 00:02:25
                               ETA: 00:50:22

################################################################################
                      [1m Learning iteration 69/1500 [0m                      

                       Computation: 44005 steps/s (collection: 2.121s, learning 0.113s)
             Mean action noise std: 1.18
          Mean value_function loss: 2.4322
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 41.2702
                       Mean reward: 13.04
               Mean episode length: 247.29
    Episode_Reward/reaching_object: 0.9660
    Episode_Reward/rotating_object: 1.6747
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 2.23s
                      Time elapsed: 00:02:27
                               ETA: 00:50:22

################################################################################
                      [1m Learning iteration 70/1500 [0m                      

                       Computation: 43913 steps/s (collection: 2.127s, learning 0.112s)
             Mean action noise std: 1.19
          Mean value_function loss: 2.2662
               Mean surrogate loss: 0.0054
                 Mean entropy loss: 41.2902
                       Mean reward: 11.53
               Mean episode length: 244.16
    Episode_Reward/reaching_object: 0.9597
    Episode_Reward/rotating_object: 2.1623
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 2.24s
                      Time elapsed: 00:02:30
                               ETA: 00:50:22

################################################################################
                      [1m Learning iteration 71/1500 [0m                      

                       Computation: 43393 steps/s (collection: 2.151s, learning 0.115s)
             Mean action noise std: 1.19
          Mean value_function loss: 1.8908
               Mean surrogate loss: 0.0019
                 Mean entropy loss: 41.2992
                       Mean reward: 16.85
               Mean episode length: 240.70
    Episode_Reward/reaching_object: 0.9343
    Episode_Reward/rotating_object: 1.9239
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 2.27s
                      Time elapsed: 00:02:32
                               ETA: 00:50:23

################################################################################
                      [1m Learning iteration 72/1500 [0m                      

                       Computation: 43679 steps/s (collection: 2.139s, learning 0.111s)
             Mean action noise std: 1.19
          Mean value_function loss: 2.4623
               Mean surrogate loss: 0.0070
                 Mean entropy loss: 41.3131
                       Mean reward: 9.42
               Mean episode length: 237.38
    Episode_Reward/reaching_object: 0.9556
    Episode_Reward/rotating_object: 1.5640
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 2.25s
                      Time elapsed: 00:02:34
                               ETA: 00:50:24

################################################################################
                      [1m Learning iteration 73/1500 [0m                      

                       Computation: 42763 steps/s (collection: 2.185s, learning 0.113s)
             Mean action noise std: 1.19
          Mean value_function loss: 2.4645
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 41.3223
                       Mean reward: 9.53
               Mean episode length: 240.80
    Episode_Reward/reaching_object: 0.9356
    Episode_Reward/rotating_object: 1.5444
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 2.30s
                      Time elapsed: 00:02:36
                               ETA: 00:50:25

################################################################################
                      [1m Learning iteration 74/1500 [0m                      

                       Computation: 44178 steps/s (collection: 2.115s, learning 0.110s)
             Mean action noise std: 1.19
          Mean value_function loss: 2.5032
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 41.3660
                       Mean reward: 11.05
               Mean episode length: 242.60
    Episode_Reward/reaching_object: 0.9084
    Episode_Reward/rotating_object: 1.3047
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 2.23s
                      Time elapsed: 00:02:39
                               ETA: 00:50:25

################################################################################
                      [1m Learning iteration 75/1500 [0m                      

                       Computation: 44662 steps/s (collection: 2.091s, learning 0.110s)
             Mean action noise std: 1.19
          Mean value_function loss: 3.0530
               Mean surrogate loss: 0.0078
                 Mean entropy loss: 41.4057
                       Mean reward: 12.23
               Mean episode length: 238.27
    Episode_Reward/reaching_object: 0.9336
    Episode_Reward/rotating_object: 1.9938
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 2.20s
                      Time elapsed: 00:02:41
                               ETA: 00:50:25

################################################################################
                      [1m Learning iteration 76/1500 [0m                      

                       Computation: 44376 steps/s (collection: 2.105s, learning 0.110s)
             Mean action noise std: 1.19
          Mean value_function loss: 3.5190
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 41.4134
                       Mean reward: 15.69
               Mean episode length: 230.81
    Episode_Reward/reaching_object: 0.8855
    Episode_Reward/rotating_object: 2.0299
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 2.22s
                      Time elapsed: 00:02:43
                               ETA: 00:50:24

################################################################################
                      [1m Learning iteration 77/1500 [0m                      

                       Computation: 44387 steps/s (collection: 2.104s, learning 0.111s)
             Mean action noise std: 1.19
          Mean value_function loss: 3.3196
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 41.4522
                       Mean reward: 17.77
               Mean episode length: 236.15
    Episode_Reward/reaching_object: 0.9093
    Episode_Reward/rotating_object: 2.2791
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 2.21s
                      Time elapsed: 00:02:45
                               ETA: 00:50:24

################################################################################
                      [1m Learning iteration 78/1500 [0m                      

                       Computation: 44474 steps/s (collection: 2.100s, learning 0.110s)
             Mean action noise std: 1.20
          Mean value_function loss: 3.1172
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 41.5438
                       Mean reward: 13.64
               Mean episode length: 241.33
    Episode_Reward/reaching_object: 0.9328
    Episode_Reward/rotating_object: 2.4010
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 2.21s
                      Time elapsed: 00:02:47
                               ETA: 00:50:23

################################################################################
                      [1m Learning iteration 79/1500 [0m                      

                       Computation: 44693 steps/s (collection: 2.087s, learning 0.113s)
             Mean action noise std: 1.20
          Mean value_function loss: 2.9922
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 41.6240
                       Mean reward: 14.15
               Mean episode length: 235.89
    Episode_Reward/reaching_object: 0.9166
    Episode_Reward/rotating_object: 2.4501
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 2.20s
                      Time elapsed: 00:02:50
                               ETA: 00:50:22

################################################################################
                      [1m Learning iteration 80/1500 [0m                      

                       Computation: 43977 steps/s (collection: 2.121s, learning 0.115s)
             Mean action noise std: 1.21
          Mean value_function loss: 3.2336
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 41.6861
                       Mean reward: 12.10
               Mean episode length: 238.63
    Episode_Reward/reaching_object: 0.9229
    Episode_Reward/rotating_object: 2.0282
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 2.24s
                      Time elapsed: 00:02:52
                               ETA: 00:50:22

################################################################################
                      [1m Learning iteration 81/1500 [0m                      

                       Computation: 43202 steps/s (collection: 2.155s, learning 0.120s)
             Mean action noise std: 1.21
          Mean value_function loss: 3.3094
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.7681
                       Mean reward: 17.12
               Mean episode length: 236.34
    Episode_Reward/reaching_object: 0.8992
    Episode_Reward/rotating_object: 2.5719
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 2.28s
                      Time elapsed: 00:02:54
                               ETA: 00:50:22

################################################################################
                      [1m Learning iteration 82/1500 [0m                      

                       Computation: 44329 steps/s (collection: 2.105s, learning 0.113s)
             Mean action noise std: 1.21
          Mean value_function loss: 4.4527
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 41.8388
                       Mean reward: 9.35
               Mean episode length: 238.84
    Episode_Reward/reaching_object: 0.8727
    Episode_Reward/rotating_object: 1.7433
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 2.22s
                      Time elapsed: 00:02:56
                               ETA: 00:50:22

################################################################################
                      [1m Learning iteration 83/1500 [0m                      

                       Computation: 44252 steps/s (collection: 2.109s, learning 0.112s)
             Mean action noise std: 1.21
          Mean value_function loss: 5.4658
               Mean surrogate loss: 0.0017
                 Mean entropy loss: 41.9219
                       Mean reward: 13.14
               Mean episode length: 241.89
    Episode_Reward/reaching_object: 0.9140
    Episode_Reward/rotating_object: 1.8573
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 2.22s
                      Time elapsed: 00:02:59
                               ETA: 00:50:21

################################################################################
                      [1m Learning iteration 84/1500 [0m                      

                       Computation: 44138 steps/s (collection: 2.111s, learning 0.116s)
             Mean action noise std: 1.22
          Mean value_function loss: 4.8798
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 41.9379
                       Mean reward: 15.30
               Mean episode length: 243.56
    Episode_Reward/reaching_object: 0.9004
    Episode_Reward/rotating_object: 2.2169
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 2.23s
                      Time elapsed: 00:03:01
                               ETA: 00:50:21

################################################################################
                      [1m Learning iteration 85/1500 [0m                      

                       Computation: 44525 steps/s (collection: 2.097s, learning 0.111s)
             Mean action noise std: 1.22
          Mean value_function loss: 5.6943
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 41.9812
                       Mean reward: 21.27
               Mean episode length: 244.79
    Episode_Reward/reaching_object: 0.9349
    Episode_Reward/rotating_object: 2.5523
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 2.21s
                      Time elapsed: 00:03:03
                               ETA: 00:50:20

################################################################################
                      [1m Learning iteration 86/1500 [0m                      

                       Computation: 44098 steps/s (collection: 2.114s, learning 0.115s)
             Mean action noise std: 1.22
          Mean value_function loss: 5.4450
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.0569
                       Mean reward: 21.15
               Mean episode length: 242.77
    Episode_Reward/reaching_object: 0.9452
    Episode_Reward/rotating_object: 3.5177
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 2.23s
                      Time elapsed: 00:03:05
                               ETA: 00:50:19

################################################################################
                      [1m Learning iteration 87/1500 [0m                      

                       Computation: 44355 steps/s (collection: 2.106s, learning 0.110s)
             Mean action noise std: 1.22
          Mean value_function loss: 5.9329
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.1194
                       Mean reward: 28.33
               Mean episode length: 245.55
    Episode_Reward/reaching_object: 0.9406
    Episode_Reward/rotating_object: 3.2151
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 2.22s
                      Time elapsed: 00:03:08
                               ETA: 00:50:18

################################################################################
                      [1m Learning iteration 88/1500 [0m                      

                       Computation: 43880 steps/s (collection: 2.128s, learning 0.113s)
             Mean action noise std: 1.23
          Mean value_function loss: 5.6951
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.1842
                       Mean reward: 14.94
               Mean episode length: 246.47
    Episode_Reward/reaching_object: 0.9415
    Episode_Reward/rotating_object: 3.3805
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 2.24s
                      Time elapsed: 00:03:10
                               ETA: 00:50:18

################################################################################
                      [1m Learning iteration 89/1500 [0m                      

                       Computation: 44047 steps/s (collection: 2.115s, learning 0.117s)
             Mean action noise std: 1.23
          Mean value_function loss: 5.7538
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 42.2449
                       Mean reward: 21.29
               Mean episode length: 238.78
    Episode_Reward/reaching_object: 0.9228
    Episode_Reward/rotating_object: 3.5957
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 2.23s
                      Time elapsed: 00:03:12
                               ETA: 00:50:17

################################################################################
                      [1m Learning iteration 90/1500 [0m                      

                       Computation: 44364 steps/s (collection: 2.103s, learning 0.113s)
             Mean action noise std: 1.23
          Mean value_function loss: 5.3600
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 42.3057
                       Mean reward: 24.69
               Mean episode length: 244.16
    Episode_Reward/reaching_object: 0.9442
    Episode_Reward/rotating_object: 3.9842
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 2.22s
                      Time elapsed: 00:03:14
                               ETA: 00:50:16

################################################################################
                      [1m Learning iteration 91/1500 [0m                      

                       Computation: 44196 steps/s (collection: 2.114s, learning 0.111s)
             Mean action noise std: 1.24
          Mean value_function loss: 5.9197
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 42.3717
                       Mean reward: 36.03
               Mean episode length: 244.40
    Episode_Reward/reaching_object: 0.9200
    Episode_Reward/rotating_object: 3.5461
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 2.22s
                      Time elapsed: 00:03:16
                               ETA: 00:50:15

################################################################################
                      [1m Learning iteration 92/1500 [0m                      

                       Computation: 44174 steps/s (collection: 2.111s, learning 0.114s)
             Mean action noise std: 1.24
          Mean value_function loss: 5.6470
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 42.4264
                       Mean reward: 20.79
               Mean episode length: 245.87
    Episode_Reward/reaching_object: 0.9248
    Episode_Reward/rotating_object: 2.5856
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 2.23s
                      Time elapsed: 00:03:19
                               ETA: 00:50:14

################################################################################
                      [1m Learning iteration 93/1500 [0m                      

                       Computation: 44073 steps/s (collection: 2.119s, learning 0.112s)
             Mean action noise std: 1.24
          Mean value_function loss: 5.7982
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 42.4933
                       Mean reward: 13.24
               Mean episode length: 239.21
    Episode_Reward/reaching_object: 0.9201
    Episode_Reward/rotating_object: 2.7990
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 2.23s
                      Time elapsed: 00:03:21
                               ETA: 00:50:14

################################################################################
                      [1m Learning iteration 94/1500 [0m                      

                       Computation: 44333 steps/s (collection: 2.104s, learning 0.114s)
             Mean action noise std: 1.25
          Mean value_function loss: 6.0857
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 42.5596
                       Mean reward: 20.11
               Mean episode length: 245.92
    Episode_Reward/reaching_object: 0.9397
    Episode_Reward/rotating_object: 3.1408
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 2.22s
                      Time elapsed: 00:03:23
                               ETA: 00:50:13

################################################################################
                      [1m Learning iteration 95/1500 [0m                      

                       Computation: 44091 steps/s (collection: 2.119s, learning 0.111s)
             Mean action noise std: 1.25
          Mean value_function loss: 6.1515
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 42.6350
                       Mean reward: 17.00
               Mean episode length: 241.19
    Episode_Reward/reaching_object: 0.9366
    Episode_Reward/rotating_object: 3.2220
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 2.23s
                      Time elapsed: 00:03:25
                               ETA: 00:50:12

################################################################################
                      [1m Learning iteration 96/1500 [0m                      

                       Computation: 44779 steps/s (collection: 2.074s, learning 0.121s)
             Mean action noise std: 1.25
          Mean value_function loss: 7.1976
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 42.6870
                       Mean reward: 19.05
               Mean episode length: 245.14
    Episode_Reward/reaching_object: 0.9204
    Episode_Reward/rotating_object: 3.0541
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 2.20s
                      Time elapsed: 00:03:28
                               ETA: 00:50:10

################################################################################
                      [1m Learning iteration 97/1500 [0m                      

                       Computation: 41144 steps/s (collection: 2.264s, learning 0.125s)
             Mean action noise std: 1.26
          Mean value_function loss: 7.1411
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 42.7487
                       Mean reward: 25.94
               Mean episode length: 244.47
    Episode_Reward/reaching_object: 0.9134
    Episode_Reward/rotating_object: 3.9148
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 2.39s
                      Time elapsed: 00:03:30
                               ETA: 00:50:12

################################################################################
                      [1m Learning iteration 98/1500 [0m                      

                       Computation: 40563 steps/s (collection: 2.269s, learning 0.154s)
             Mean action noise std: 1.26
          Mean value_function loss: 6.6605
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 42.8302
                       Mean reward: 21.35
               Mean episode length: 246.10
    Episode_Reward/reaching_object: 0.9501
    Episode_Reward/rotating_object: 3.7610
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 2.42s
                      Time elapsed: 00:03:32
                               ETA: 00:50:13

################################################################################
                      [1m Learning iteration 99/1500 [0m                      

                       Computation: 41424 steps/s (collection: 2.248s, learning 0.125s)
             Mean action noise std: 1.26
          Mean value_function loss: 6.5175
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 42.8868
                       Mean reward: 25.71
               Mean episode length: 241.50
    Episode_Reward/reaching_object: 0.9296
    Episode_Reward/rotating_object: 3.7872
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 2.37s
                      Time elapsed: 00:03:35
                               ETA: 00:50:14

################################################################################
                     [1m Learning iteration 100/1500 [0m                      

                       Computation: 41446 steps/s (collection: 2.247s, learning 0.125s)
             Mean action noise std: 1.27
          Mean value_function loss: 6.3083
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 42.9636
                       Mean reward: 22.47
               Mean episode length: 243.35
    Episode_Reward/reaching_object: 0.9037
    Episode_Reward/rotating_object: 3.1206
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 2.37s
                      Time elapsed: 00:03:37
                               ETA: 00:50:15

################################################################################
                     [1m Learning iteration 101/1500 [0m                      

                       Computation: 42131 steps/s (collection: 2.208s, learning 0.125s)
             Mean action noise std: 1.27
          Mean value_function loss: 7.4272
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 43.0544
                       Mean reward: 16.83
               Mean episode length: 240.74
    Episode_Reward/reaching_object: 0.9220
    Episode_Reward/rotating_object: 3.2369
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 2.33s
                      Time elapsed: 00:03:39
                               ETA: 00:50:16

################################################################################
                     [1m Learning iteration 102/1500 [0m                      

                       Computation: 41572 steps/s (collection: 2.236s, learning 0.128s)
             Mean action noise std: 1.27
          Mean value_function loss: 9.0333
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 43.1306
                       Mean reward: 15.42
               Mean episode length: 243.61
    Episode_Reward/reaching_object: 0.8993
    Episode_Reward/rotating_object: 2.7472
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 2.36s
                      Time elapsed: 00:03:42
                               ETA: 00:50:16

################################################################################
                     [1m Learning iteration 103/1500 [0m                      

                       Computation: 41748 steps/s (collection: 2.228s, learning 0.127s)
             Mean action noise std: 1.28
          Mean value_function loss: 10.0358
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 43.2049
                       Mean reward: 21.25
               Mean episode length: 249.63
    Episode_Reward/reaching_object: 0.9148
    Episode_Reward/rotating_object: 3.7219
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 2.35s
                      Time elapsed: 00:03:44
                               ETA: 00:50:17

################################################################################
                     [1m Learning iteration 104/1500 [0m                      

                       Computation: 41048 steps/s (collection: 2.267s, learning 0.127s)
             Mean action noise std: 1.28
          Mean value_function loss: 10.3426
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 43.2769
                       Mean reward: 19.30
               Mean episode length: 244.39
    Episode_Reward/reaching_object: 0.9341
    Episode_Reward/rotating_object: 3.5012
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 2.39s
                      Time elapsed: 00:03:47
                               ETA: 00:50:18

################################################################################
                     [1m Learning iteration 105/1500 [0m                      

                       Computation: 40484 steps/s (collection: 2.279s, learning 0.150s)
             Mean action noise std: 1.28
          Mean value_function loss: 8.7339
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 43.3030
                       Mean reward: 19.46
               Mean episode length: 245.55
    Episode_Reward/reaching_object: 0.8906
    Episode_Reward/rotating_object: 3.4413
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 2.43s
                      Time elapsed: 00:03:49
                               ETA: 00:50:19

################################################################################
                     [1m Learning iteration 106/1500 [0m                      

                       Computation: 40926 steps/s (collection: 2.263s, learning 0.139s)
             Mean action noise std: 1.28
          Mean value_function loss: 8.2922
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.3435
                       Mean reward: 25.32
               Mean episode length: 247.17
    Episode_Reward/reaching_object: 0.9017
    Episode_Reward/rotating_object: 3.5744
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 2.40s
                      Time elapsed: 00:03:51
                               ETA: 00:50:20

################################################################################
                     [1m Learning iteration 107/1500 [0m                      

                       Computation: 40200 steps/s (collection: 2.317s, learning 0.128s)
             Mean action noise std: 1.29
          Mean value_function loss: 8.7151
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.3771
                       Mean reward: 19.51
               Mean episode length: 245.22
    Episode_Reward/reaching_object: 0.9056
    Episode_Reward/rotating_object: 4.3192
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 2.45s
                      Time elapsed: 00:03:54
                               ETA: 00:50:21

################################################################################
                     [1m Learning iteration 108/1500 [0m                      

                       Computation: 41542 steps/s (collection: 2.254s, learning 0.112s)
             Mean action noise std: 1.29
          Mean value_function loss: 9.3944
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 43.4502
                       Mean reward: 29.42
               Mean episode length: 245.93
    Episode_Reward/reaching_object: 0.8939
    Episode_Reward/rotating_object: 5.2135
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 2.37s
                      Time elapsed: 00:03:56
                               ETA: 00:50:22

################################################################################
                     [1m Learning iteration 109/1500 [0m                      

                       Computation: 43496 steps/s (collection: 2.145s, learning 0.115s)
             Mean action noise std: 1.29
          Mean value_function loss: 9.8529
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 43.5281
                       Mean reward: 19.15
               Mean episode length: 243.17
    Episode_Reward/reaching_object: 0.8983
    Episode_Reward/rotating_object: 4.5348
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 2.26s
                      Time elapsed: 00:03:58
                               ETA: 00:50:21

################################################################################
                     [1m Learning iteration 110/1500 [0m                      

                       Computation: 44124 steps/s (collection: 2.113s, learning 0.115s)
             Mean action noise std: 1.30
          Mean value_function loss: 9.7960
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 43.5996
                       Mean reward: 28.96
               Mean episode length: 243.32
    Episode_Reward/reaching_object: 0.9055
    Episode_Reward/rotating_object: 4.9757
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 2.23s
                      Time elapsed: 00:04:01
                               ETA: 00:50:19

################################################################################
                     [1m Learning iteration 111/1500 [0m                      

                       Computation: 44720 steps/s (collection: 2.088s, learning 0.111s)
             Mean action noise std: 1.30
          Mean value_function loss: 10.1463
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 43.6886
                       Mean reward: 28.01
               Mean episode length: 243.30
    Episode_Reward/reaching_object: 0.9116
    Episode_Reward/rotating_object: 4.3376
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 18.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 2.20s
                      Time elapsed: 00:04:03
                               ETA: 00:50:17

################################################################################
                     [1m Learning iteration 112/1500 [0m                      

                       Computation: 44719 steps/s (collection: 2.087s, learning 0.111s)
             Mean action noise std: 1.31
          Mean value_function loss: 8.8207
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 43.7700
                       Mean reward: 31.47
               Mean episode length: 240.92
    Episode_Reward/reaching_object: 0.9060
    Episode_Reward/rotating_object: 5.7418
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 2.20s
                      Time elapsed: 00:04:05
                               ETA: 00:50:16

################################################################################
                     [1m Learning iteration 113/1500 [0m                      

                       Computation: 44905 steps/s (collection: 2.078s, learning 0.111s)
             Mean action noise std: 1.31
          Mean value_function loss: 9.0450
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 43.8439
                       Mean reward: 25.96
               Mean episode length: 239.35
    Episode_Reward/reaching_object: 0.8858
    Episode_Reward/rotating_object: 4.3419
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 2.19s
                      Time elapsed: 00:04:07
                               ETA: 00:50:14

################################################################################
                     [1m Learning iteration 114/1500 [0m                      

                       Computation: 44340 steps/s (collection: 2.106s, learning 0.111s)
             Mean action noise std: 1.31
          Mean value_function loss: 9.5975
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 43.9284
                       Mean reward: 24.87
               Mean episode length: 242.99
    Episode_Reward/reaching_object: 0.8867
    Episode_Reward/rotating_object: 4.8090
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 2.22s
                      Time elapsed: 00:04:09
                               ETA: 00:50:12

################################################################################
                     [1m Learning iteration 115/1500 [0m                      

                       Computation: 44695 steps/s (collection: 2.085s, learning 0.114s)
             Mean action noise std: 1.32
          Mean value_function loss: 10.1469
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 43.9780
                       Mean reward: 20.80
               Mean episode length: 241.51
    Episode_Reward/reaching_object: 0.8648
    Episode_Reward/rotating_object: 3.6572
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 2.20s
                      Time elapsed: 00:04:12
                               ETA: 00:50:10

################################################################################
                     [1m Learning iteration 116/1500 [0m                      

                       Computation: 44599 steps/s (collection: 2.093s, learning 0.111s)
             Mean action noise std: 1.32
          Mean value_function loss: 11.0702
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 44.0446
                       Mean reward: 24.03
               Mean episode length: 242.19
    Episode_Reward/reaching_object: 0.8621
    Episode_Reward/rotating_object: 4.2531
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 2.20s
                      Time elapsed: 00:04:14
                               ETA: 00:50:08

################################################################################
                     [1m Learning iteration 117/1500 [0m                      

                       Computation: 45315 steps/s (collection: 2.058s, learning 0.111s)
             Mean action noise std: 1.32
          Mean value_function loss: 11.2387
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.1174
                       Mean reward: 25.88
               Mean episode length: 241.45
    Episode_Reward/reaching_object: 0.9044
    Episode_Reward/rotating_object: 3.8399
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 2.17s
                      Time elapsed: 00:04:16
                               ETA: 00:50:06

################################################################################
                     [1m Learning iteration 118/1500 [0m                      

                       Computation: 45358 steps/s (collection: 2.056s, learning 0.111s)
             Mean action noise std: 1.33
          Mean value_function loss: 11.9074
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 44.1866
                       Mean reward: 26.98
               Mean episode length: 243.54
    Episode_Reward/reaching_object: 0.8941
    Episode_Reward/rotating_object: 4.4925
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 2.17s
                      Time elapsed: 00:04:18
                               ETA: 00:50:04

################################################################################
                     [1m Learning iteration 119/1500 [0m                      

                       Computation: 45303 steps/s (collection: 2.059s, learning 0.111s)
             Mean action noise std: 1.33
          Mean value_function loss: 12.2736
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.2675
                       Mean reward: 29.18
               Mean episode length: 238.64
    Episode_Reward/reaching_object: 0.8933
    Episode_Reward/rotating_object: 4.8948
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 2.17s
                      Time elapsed: 00:04:20
                               ETA: 00:50:02

################################################################################
                     [1m Learning iteration 120/1500 [0m                      

                       Computation: 45615 steps/s (collection: 2.044s, learning 0.111s)
             Mean action noise std: 1.33
          Mean value_function loss: 12.4468
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 44.3393
                       Mean reward: 18.90
               Mean episode length: 241.53
    Episode_Reward/reaching_object: 0.8913
    Episode_Reward/rotating_object: 3.9377
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 2.16s
                      Time elapsed: 00:04:23
                               ETA: 00:49:59

################################################################################
                     [1m Learning iteration 121/1500 [0m                      

                       Computation: 45329 steps/s (collection: 2.058s, learning 0.111s)
             Mean action noise std: 1.34
          Mean value_function loss: 12.8903
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 44.3967
                       Mean reward: 32.34
               Mean episode length: 239.04
    Episode_Reward/reaching_object: 0.8768
    Episode_Reward/rotating_object: 4.5104
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 2.17s
                      Time elapsed: 00:04:25
                               ETA: 00:49:57

################################################################################
                     [1m Learning iteration 122/1500 [0m                      

                       Computation: 45203 steps/s (collection: 2.064s, learning 0.111s)
             Mean action noise std: 1.34
          Mean value_function loss: 12.6409
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.4709
                       Mean reward: 32.18
               Mean episode length: 233.38
    Episode_Reward/reaching_object: 0.8559
    Episode_Reward/rotating_object: 4.9709
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 2.17s
                      Time elapsed: 00:04:27
                               ETA: 00:49:55

################################################################################
                     [1m Learning iteration 123/1500 [0m                      

                       Computation: 45191 steps/s (collection: 2.063s, learning 0.113s)
             Mean action noise std: 1.35
          Mean value_function loss: 13.0885
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.5462
                       Mean reward: 35.21
               Mean episode length: 237.30
    Episode_Reward/reaching_object: 0.8776
    Episode_Reward/rotating_object: 5.4940
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 2.18s
                      Time elapsed: 00:04:29
                               ETA: 00:49:53

################################################################################
                     [1m Learning iteration 124/1500 [0m                      

                       Computation: 44110 steps/s (collection: 2.115s, learning 0.113s)
             Mean action noise std: 1.35
          Mean value_function loss: 13.4409
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 44.6099
                       Mean reward: 32.49
               Mean episode length: 234.87
    Episode_Reward/reaching_object: 0.8880
    Episode_Reward/rotating_object: 5.3158
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 2.23s
                      Time elapsed: 00:04:31
                               ETA: 00:49:51

################################################################################
                     [1m Learning iteration 125/1500 [0m                      

                       Computation: 44690 steps/s (collection: 2.086s, learning 0.113s)
             Mean action noise std: 1.35
          Mean value_function loss: 13.1744
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 44.6639
                       Mean reward: 28.30
               Mean episode length: 241.78
    Episode_Reward/reaching_object: 0.8455
    Episode_Reward/rotating_object: 4.6843
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 2.20s
                      Time elapsed: 00:04:33
                               ETA: 00:49:49

################################################################################
                     [1m Learning iteration 126/1500 [0m                      

                       Computation: 43339 steps/s (collection: 2.155s, learning 0.113s)
             Mean action noise std: 1.36
          Mean value_function loss: 13.5808
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 44.7527
                       Mean reward: 39.44
               Mean episode length: 236.07
    Episode_Reward/reaching_object: 0.8787
    Episode_Reward/rotating_object: 5.5715
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 2.27s
                      Time elapsed: 00:04:36
                               ETA: 00:49:48

################################################################################
                     [1m Learning iteration 127/1500 [0m                      

                       Computation: 44681 steps/s (collection: 2.088s, learning 0.112s)
             Mean action noise std: 1.36
          Mean value_function loss: 13.1329
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 44.8320
                       Mean reward: 31.15
               Mean episode length: 237.53
    Episode_Reward/reaching_object: 0.8744
    Episode_Reward/rotating_object: 5.4735
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 2.20s
                      Time elapsed: 00:04:38
                               ETA: 00:49:46

################################################################################
                     [1m Learning iteration 128/1500 [0m                      

                       Computation: 45272 steps/s (collection: 2.058s, learning 0.113s)
             Mean action noise std: 1.37
          Mean value_function loss: 15.8057
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 44.9148
                       Mean reward: 36.19
               Mean episode length: 238.98
    Episode_Reward/reaching_object: 0.8873
    Episode_Reward/rotating_object: 5.7363
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 2.17s
                      Time elapsed: 00:04:40
                               ETA: 00:49:44

################################################################################
                     [1m Learning iteration 129/1500 [0m                      

                       Computation: 44516 steps/s (collection: 2.097s, learning 0.111s)
             Mean action noise std: 1.37
          Mean value_function loss: 15.0378
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.9736
                       Mean reward: 31.16
               Mean episode length: 240.69
    Episode_Reward/reaching_object: 0.8885
    Episode_Reward/rotating_object: 5.1335
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 2.21s
                      Time elapsed: 00:04:42
                               ETA: 00:49:42

################################################################################
                     [1m Learning iteration 130/1500 [0m                      

                       Computation: 45302 steps/s (collection: 2.056s, learning 0.114s)
             Mean action noise std: 1.37
          Mean value_function loss: 17.7023
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 45.0359
                       Mean reward: 22.75
               Mean episode length: 237.08
    Episode_Reward/reaching_object: 0.8827
    Episode_Reward/rotating_object: 4.8721
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 2.17s
                      Time elapsed: 00:04:44
                               ETA: 00:49:40

################################################################################
                     [1m Learning iteration 131/1500 [0m                      

                       Computation: 45386 steps/s (collection: 2.056s, learning 0.110s)
             Mean action noise std: 1.37
          Mean value_function loss: 18.2900
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 45.0978
                       Mean reward: 34.22
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 0.8784
    Episode_Reward/rotating_object: 6.2242
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 2.17s
                      Time elapsed: 00:04:47
                               ETA: 00:49:38

################################################################################
                     [1m Learning iteration 132/1500 [0m                      

                       Computation: 45736 steps/s (collection: 2.039s, learning 0.111s)
             Mean action noise std: 1.38
          Mean value_function loss: 14.1047
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 45.1510
                       Mean reward: 34.44
               Mean episode length: 244.66
    Episode_Reward/reaching_object: 0.8740
    Episode_Reward/rotating_object: 5.9574
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 2.15s
                      Time elapsed: 00:04:49
                               ETA: 00:49:35

################################################################################
                     [1m Learning iteration 133/1500 [0m                      

                       Computation: 45514 steps/s (collection: 2.046s, learning 0.114s)
             Mean action noise std: 1.38
          Mean value_function loss: 16.0444
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 45.1904
                       Mean reward: 28.22
               Mean episode length: 239.95
    Episode_Reward/reaching_object: 0.8311
    Episode_Reward/rotating_object: 5.7386
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 2.16s
                      Time elapsed: 00:04:51
                               ETA: 00:49:33

################################################################################
                     [1m Learning iteration 134/1500 [0m                      

                       Computation: 44785 steps/s (collection: 2.084s, learning 0.111s)
             Mean action noise std: 1.38
          Mean value_function loss: 16.4228
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 45.2328
                       Mean reward: 51.41
               Mean episode length: 244.00
    Episode_Reward/reaching_object: 0.8660
    Episode_Reward/rotating_object: 7.0789
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 2.19s
                      Time elapsed: 00:04:53
                               ETA: 00:49:31

################################################################################
                     [1m Learning iteration 135/1500 [0m                      

                       Computation: 45006 steps/s (collection: 2.056s, learning 0.129s)
             Mean action noise std: 1.38
          Mean value_function loss: 16.0171
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 45.2737
                       Mean reward: 31.22
               Mean episode length: 243.33
    Episode_Reward/reaching_object: 0.8027
    Episode_Reward/rotating_object: 5.6709
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 2.18s
                      Time elapsed: 00:04:55
                               ETA: 00:49:29

################################################################################
                     [1m Learning iteration 136/1500 [0m                      

                       Computation: 45128 steps/s (collection: 2.068s, learning 0.111s)
             Mean action noise std: 1.39
          Mean value_function loss: 16.6624
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 45.3212
                       Mean reward: 46.79
               Mean episode length: 240.20
    Episode_Reward/reaching_object: 0.8318
    Episode_Reward/rotating_object: 6.8493
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 2.18s
                      Time elapsed: 00:04:58
                               ETA: 00:49:27

################################################################################
                     [1m Learning iteration 137/1500 [0m                      

                       Computation: 44596 steps/s (collection: 2.091s, learning 0.114s)
             Mean action noise std: 1.39
          Mean value_function loss: 16.8587
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 45.3749
                       Mean reward: 28.44
               Mean episode length: 233.56
    Episode_Reward/reaching_object: 0.8082
    Episode_Reward/rotating_object: 5.8543
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 2.20s
                      Time elapsed: 00:05:00
                               ETA: 00:49:25

################################################################################
                     [1m Learning iteration 138/1500 [0m                      

                       Computation: 45097 steps/s (collection: 2.067s, learning 0.113s)
             Mean action noise std: 1.39
          Mean value_function loss: 18.7967
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 45.4539
                       Mean reward: 37.71
               Mean episode length: 238.31
    Episode_Reward/reaching_object: 0.8079
    Episode_Reward/rotating_object: 7.2247
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 2.18s
                      Time elapsed: 00:05:02
                               ETA: 00:49:23

################################################################################
                     [1m Learning iteration 139/1500 [0m                      

                       Computation: 45739 steps/s (collection: 2.038s, learning 0.111s)
             Mean action noise std: 1.40
          Mean value_function loss: 17.5470
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 45.5228
                       Mean reward: 42.78
               Mean episode length: 244.36
    Episode_Reward/reaching_object: 0.8181
    Episode_Reward/rotating_object: 6.7786
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 2.15s
                      Time elapsed: 00:05:04
                               ETA: 00:49:20

################################################################################
                     [1m Learning iteration 140/1500 [0m                      

                       Computation: 45318 steps/s (collection: 2.053s, learning 0.116s)
             Mean action noise std: 1.40
          Mean value_function loss: 19.2593
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 45.5738
                       Mean reward: 34.82
               Mean episode length: 242.03
    Episode_Reward/reaching_object: 0.8117
    Episode_Reward/rotating_object: 6.1586
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 2.17s
                      Time elapsed: 00:05:06
                               ETA: 00:49:18

################################################################################
                     [1m Learning iteration 141/1500 [0m                      

                       Computation: 44922 steps/s (collection: 2.078s, learning 0.110s)
             Mean action noise std: 1.40
          Mean value_function loss: 19.4752
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 45.6127
                       Mean reward: 40.80
               Mean episode length: 242.84
    Episode_Reward/reaching_object: 0.7857
    Episode_Reward/rotating_object: 6.8276
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 2.19s
                      Time elapsed: 00:05:08
                               ETA: 00:49:16

################################################################################
                     [1m Learning iteration 142/1500 [0m                      

                       Computation: 45127 steps/s (collection: 2.067s, learning 0.112s)
             Mean action noise std: 1.40
          Mean value_function loss: 18.3120
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 45.6397
                       Mean reward: 40.99
               Mean episode length: 235.22
    Episode_Reward/reaching_object: 0.8158
    Episode_Reward/rotating_object: 6.3144
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 2.18s
                      Time elapsed: 00:05:11
                               ETA: 00:49:14

################################################################################
                     [1m Learning iteration 143/1500 [0m                      

                       Computation: 44297 steps/s (collection: 2.109s, learning 0.111s)
             Mean action noise std: 1.41
          Mean value_function loss: 19.5586
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 45.7083
                       Mean reward: 40.33
               Mean episode length: 230.97
    Episode_Reward/reaching_object: 0.8271
    Episode_Reward/rotating_object: 6.8403
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 2.22s
                      Time elapsed: 00:05:13
                               ETA: 00:49:12

################################################################################
                     [1m Learning iteration 144/1500 [0m                      

                       Computation: 44487 steps/s (collection: 2.100s, learning 0.110s)
             Mean action noise std: 1.41
          Mean value_function loss: 21.3036
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 45.7862
                       Mean reward: 47.87
               Mean episode length: 237.22
    Episode_Reward/reaching_object: 0.8077
    Episode_Reward/rotating_object: 7.1994
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 2.21s
                      Time elapsed: 00:05:15
                               ETA: 00:49:10

################################################################################
                     [1m Learning iteration 145/1500 [0m                      

                       Computation: 45016 steps/s (collection: 2.073s, learning 0.111s)
             Mean action noise std: 1.42
          Mean value_function loss: 23.3068
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 45.8562
                       Mean reward: 43.23
               Mean episode length: 244.62
    Episode_Reward/reaching_object: 0.8443
    Episode_Reward/rotating_object: 7.2483
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 2.18s
                      Time elapsed: 00:05:17
                               ETA: 00:49:08

################################################################################
                     [1m Learning iteration 146/1500 [0m                      

                       Computation: 44922 steps/s (collection: 2.076s, learning 0.112s)
             Mean action noise std: 1.42
          Mean value_function loss: 22.3742
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 45.9330
                       Mean reward: 53.05
               Mean episode length: 240.30
    Episode_Reward/reaching_object: 0.8086
    Episode_Reward/rotating_object: 7.7251
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 2.19s
                      Time elapsed: 00:05:19
                               ETA: 00:49:06

################################################################################
                     [1m Learning iteration 147/1500 [0m                      

                       Computation: 44600 steps/s (collection: 2.092s, learning 0.112s)
             Mean action noise std: 1.42
          Mean value_function loss: 22.9629
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 46.0048
                       Mean reward: 31.79
               Mean episode length: 231.58
    Episode_Reward/reaching_object: 0.8057
    Episode_Reward/rotating_object: 7.1498
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 2.20s
                      Time elapsed: 00:05:22
                               ETA: 00:49:04

################################################################################
                     [1m Learning iteration 148/1500 [0m                      

                       Computation: 45058 steps/s (collection: 2.070s, learning 0.111s)
             Mean action noise std: 1.43
          Mean value_function loss: 23.2016
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 46.0616
                       Mean reward: 44.74
               Mean episode length: 243.04
    Episode_Reward/reaching_object: 0.8169
    Episode_Reward/rotating_object: 7.7776
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 2.18s
                      Time elapsed: 00:05:24
                               ETA: 00:49:02

################################################################################
                     [1m Learning iteration 149/1500 [0m                      

                       Computation: 44446 steps/s (collection: 2.098s, learning 0.114s)
             Mean action noise std: 1.43
          Mean value_function loss: 23.4999
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 46.1077
                       Mean reward: 48.92
               Mean episode length: 236.49
    Episode_Reward/reaching_object: 0.8349
    Episode_Reward/rotating_object: 8.6484
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 2.21s
                      Time elapsed: 00:05:26
                               ETA: 00:49:00

################################################################################
                     [1m Learning iteration 150/1500 [0m                      

                       Computation: 44410 steps/s (collection: 2.102s, learning 0.112s)
             Mean action noise std: 1.43
          Mean value_function loss: 22.0474
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 46.1502
                       Mean reward: 34.03
               Mean episode length: 225.88
    Episode_Reward/reaching_object: 0.7895
    Episode_Reward/rotating_object: 7.7373
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 2.21s
                      Time elapsed: 00:05:28
                               ETA: 00:48:58

################################################################################
                     [1m Learning iteration 151/1500 [0m                      

                       Computation: 44750 steps/s (collection: 2.086s, learning 0.111s)
             Mean action noise std: 1.44
          Mean value_function loss: 20.8611
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 46.2097
                       Mean reward: 41.39
               Mean episode length: 230.81
    Episode_Reward/reaching_object: 0.7997
    Episode_Reward/rotating_object: 7.7017
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 2.20s
                      Time elapsed: 00:05:30
                               ETA: 00:48:56

################################################################################
                     [1m Learning iteration 152/1500 [0m                      

                       Computation: 44760 steps/s (collection: 2.086s, learning 0.110s)
             Mean action noise std: 1.44
          Mean value_function loss: 21.6089
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 46.2818
                       Mean reward: 44.98
               Mean episode length: 234.26
    Episode_Reward/reaching_object: 0.7968
    Episode_Reward/rotating_object: 7.7199
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 2.20s
                      Time elapsed: 00:05:33
                               ETA: 00:48:54

################################################################################
                     [1m Learning iteration 153/1500 [0m                      

                       Computation: 44770 steps/s (collection: 2.085s, learning 0.110s)
             Mean action noise std: 1.44
          Mean value_function loss: 21.9841
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 46.3344
                       Mean reward: 52.79
               Mean episode length: 237.62
    Episode_Reward/reaching_object: 0.8329
    Episode_Reward/rotating_object: 9.1425
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 2.20s
                      Time elapsed: 00:05:35
                               ETA: 00:48:52

################################################################################
                     [1m Learning iteration 154/1500 [0m                      

                       Computation: 44564 steps/s (collection: 2.093s, learning 0.113s)
             Mean action noise std: 1.44
          Mean value_function loss: 23.6725
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 46.3685
                       Mean reward: 37.77
               Mean episode length: 233.64
    Episode_Reward/reaching_object: 0.8081
    Episode_Reward/rotating_object: 8.7093
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 2.21s
                      Time elapsed: 00:05:37
                               ETA: 00:48:50

################################################################################
                     [1m Learning iteration 155/1500 [0m                      

                       Computation: 44562 steps/s (collection: 2.096s, learning 0.110s)
             Mean action noise std: 1.45
          Mean value_function loss: 22.3862
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 46.4189
                       Mean reward: 49.09
               Mean episode length: 232.55
    Episode_Reward/reaching_object: 0.7925
    Episode_Reward/rotating_object: 8.9816
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 2.21s
                      Time elapsed: 00:05:39
                               ETA: 00:48:48

################################################################################
                     [1m Learning iteration 156/1500 [0m                      

                       Computation: 44575 steps/s (collection: 2.095s, learning 0.111s)
             Mean action noise std: 1.45
          Mean value_function loss: 23.0485
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 46.4813
                       Mean reward: 51.20
               Mean episode length: 234.03
    Episode_Reward/reaching_object: 0.8211
    Episode_Reward/rotating_object: 9.1398
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 2.21s
                      Time elapsed: 00:05:41
                               ETA: 00:48:46

################################################################################
                     [1m Learning iteration 157/1500 [0m                      

                       Computation: 44408 steps/s (collection: 2.099s, learning 0.115s)
             Mean action noise std: 1.45
          Mean value_function loss: 23.2092
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 46.5491
                       Mean reward: 36.78
               Mean episode length: 225.95
    Episode_Reward/reaching_object: 0.7876
    Episode_Reward/rotating_object: 8.6994
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 2.21s
                      Time elapsed: 00:05:44
                               ETA: 00:48:44

################################################################################
                     [1m Learning iteration 158/1500 [0m                      

                       Computation: 43914 steps/s (collection: 2.124s, learning 0.115s)
             Mean action noise std: 1.46
          Mean value_function loss: 21.3610
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 46.6103
                       Mean reward: 48.45
               Mean episode length: 226.27
    Episode_Reward/reaching_object: 0.8031
    Episode_Reward/rotating_object: 8.4813
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 2.24s
                      Time elapsed: 00:05:46
                               ETA: 00:48:43

################################################################################
                     [1m Learning iteration 159/1500 [0m                      

                       Computation: 43288 steps/s (collection: 2.160s, learning 0.111s)
             Mean action noise std: 1.46
          Mean value_function loss: 23.9522
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 46.6669
                       Mean reward: 61.40
               Mean episode length: 238.11
    Episode_Reward/reaching_object: 0.7945
    Episode_Reward/rotating_object: 9.7952
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 2.27s
                      Time elapsed: 00:05:48
                               ETA: 00:48:41

################################################################################
                     [1m Learning iteration 160/1500 [0m                      

                       Computation: 44249 steps/s (collection: 2.110s, learning 0.112s)
             Mean action noise std: 1.46
          Mean value_function loss: 24.0254
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 46.7029
                       Mean reward: 55.68
               Mean episode length: 231.27
    Episode_Reward/reaching_object: 0.8267
    Episode_Reward/rotating_object: 10.4480
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 2.22s
                      Time elapsed: 00:05:50
                               ETA: 00:48:40

################################################################################
                     [1m Learning iteration 161/1500 [0m                      

                       Computation: 44683 steps/s (collection: 2.090s, learning 0.110s)
             Mean action noise std: 1.46
          Mean value_function loss: 23.7105
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 46.7327
                       Mean reward: 37.28
               Mean episode length: 236.50
    Episode_Reward/reaching_object: 0.8367
    Episode_Reward/rotating_object: 8.8249
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 2.20s
                      Time elapsed: 00:05:53
                               ETA: 00:48:38

################################################################################
                     [1m Learning iteration 162/1500 [0m                      

                       Computation: 44562 steps/s (collection: 2.095s, learning 0.111s)
             Mean action noise std: 1.46
          Mean value_function loss: 26.1411
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 46.7447
                       Mean reward: 43.56
               Mean episode length: 224.84
    Episode_Reward/reaching_object: 0.7744
    Episode_Reward/rotating_object: 8.7137
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 2.21s
                      Time elapsed: 00:05:55
                               ETA: 00:48:36

################################################################################
                     [1m Learning iteration 163/1500 [0m                      

                       Computation: 44791 steps/s (collection: 2.084s, learning 0.110s)
             Mean action noise std: 1.47
          Mean value_function loss: 26.3724
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 46.7711
                       Mean reward: 56.21
               Mean episode length: 228.66
    Episode_Reward/reaching_object: 0.8312
    Episode_Reward/rotating_object: 9.8566
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 2.19s
                      Time elapsed: 00:05:57
                               ETA: 00:48:34

################################################################################
                     [1m Learning iteration 164/1500 [0m                      

                       Computation: 45090 steps/s (collection: 2.069s, learning 0.111s)
             Mean action noise std: 1.47
          Mean value_function loss: 27.7206
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 46.8201
                       Mean reward: 46.43
               Mean episode length: 231.82
    Episode_Reward/reaching_object: 0.8270
    Episode_Reward/rotating_object: 9.5592
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 2.18s
                      Time elapsed: 00:05:59
                               ETA: 00:48:31

################################################################################
                     [1m Learning iteration 165/1500 [0m                      

                       Computation: 44666 steps/s (collection: 2.090s, learning 0.111s)
             Mean action noise std: 1.47
          Mean value_function loss: 27.2825
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 46.8472
                       Mean reward: 43.32
               Mean episode length: 224.19
    Episode_Reward/reaching_object: 0.7885
    Episode_Reward/rotating_object: 8.6500
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 11.4583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 2.20s
                      Time elapsed: 00:06:01
                               ETA: 00:48:29

################################################################################
                     [1m Learning iteration 166/1500 [0m                      

                       Computation: 44925 steps/s (collection: 2.078s, learning 0.110s)
             Mean action noise std: 1.47
          Mean value_function loss: 29.4729
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 46.8915
                       Mean reward: 54.33
               Mean episode length: 225.72
    Episode_Reward/reaching_object: 0.8329
    Episode_Reward/rotating_object: 10.5514
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 2.19s
                      Time elapsed: 00:06:04
                               ETA: 00:48:27

################################################################################
                     [1m Learning iteration 167/1500 [0m                      

                       Computation: 44834 steps/s (collection: 2.082s, learning 0.110s)
             Mean action noise std: 1.48
          Mean value_function loss: 24.6201
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 46.9352
                       Mean reward: 56.53
               Mean episode length: 227.31
    Episode_Reward/reaching_object: 0.8650
    Episode_Reward/rotating_object: 11.0618
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 2.19s
                      Time elapsed: 00:06:06
                               ETA: 00:48:25

################################################################################
                     [1m Learning iteration 168/1500 [0m                      

                       Computation: 43936 steps/s (collection: 2.123s, learning 0.114s)
             Mean action noise std: 1.48
          Mean value_function loss: 27.4373
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 46.9677
                       Mean reward: 78.73
               Mean episode length: 233.45
    Episode_Reward/reaching_object: 0.8709
    Episode_Reward/rotating_object: 12.5735
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 2.24s
                      Time elapsed: 00:06:08
                               ETA: 00:48:23

################################################################################
                     [1m Learning iteration 169/1500 [0m                      

                       Computation: 44338 steps/s (collection: 2.107s, learning 0.111s)
             Mean action noise std: 1.48
          Mean value_function loss: 23.0985
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 47.0029
                       Mean reward: 60.71
               Mean episode length: 227.30
    Episode_Reward/reaching_object: 0.8707
    Episode_Reward/rotating_object: 11.4545
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 2.22s
                      Time elapsed: 00:06:10
                               ETA: 00:48:22

################################################################################
                     [1m Learning iteration 170/1500 [0m                      

                       Computation: 44391 steps/s (collection: 2.101s, learning 0.113s)
             Mean action noise std: 1.48
          Mean value_function loss: 27.9598
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 47.0409
                       Mean reward: 71.83
               Mean episode length: 226.24
    Episode_Reward/reaching_object: 0.8545
    Episode_Reward/rotating_object: 13.1431
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 2.21s
                      Time elapsed: 00:06:12
                               ETA: 00:48:20

################################################################################
                     [1m Learning iteration 171/1500 [0m                      

                       Computation: 43670 steps/s (collection: 2.141s, learning 0.111s)
             Mean action noise std: 1.48
          Mean value_function loss: 28.2285
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 47.0832
                       Mean reward: 63.92
               Mean episode length: 232.12
    Episode_Reward/reaching_object: 0.8389
    Episode_Reward/rotating_object: 10.3567
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 2.25s
                      Time elapsed: 00:06:15
                               ETA: 00:48:18

################################################################################
                     [1m Learning iteration 172/1500 [0m                      

                       Computation: 44504 steps/s (collection: 2.095s, learning 0.114s)
             Mean action noise std: 1.49
          Mean value_function loss: 30.2203
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 47.1087
                       Mean reward: 58.21
               Mean episode length: 233.07
    Episode_Reward/reaching_object: 0.8462
    Episode_Reward/rotating_object: 12.8353
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 2.21s
                      Time elapsed: 00:06:17
                               ETA: 00:48:16

################################################################################
                     [1m Learning iteration 173/1500 [0m                      

                       Computation: 44381 steps/s (collection: 2.104s, learning 0.111s)
             Mean action noise std: 1.49
          Mean value_function loss: 26.6265
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 47.1565
                       Mean reward: 46.80
               Mean episode length: 229.10
    Episode_Reward/reaching_object: 0.8404
    Episode_Reward/rotating_object: 10.1223
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 2.21s
                      Time elapsed: 00:06:19
                               ETA: 00:48:14

################################################################################
                     [1m Learning iteration 174/1500 [0m                      

                       Computation: 44263 steps/s (collection: 2.110s, learning 0.111s)
             Mean action noise std: 1.49
          Mean value_function loss: 31.7418
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 47.2112
                       Mean reward: 52.70
               Mean episode length: 235.30
    Episode_Reward/reaching_object: 0.8411
    Episode_Reward/rotating_object: 13.2483
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 2.22s
                      Time elapsed: 00:06:21
                               ETA: 00:48:12

################################################################################
                     [1m Learning iteration 175/1500 [0m                      

                       Computation: 44250 steps/s (collection: 2.109s, learning 0.113s)
             Mean action noise std: 1.50
          Mean value_function loss: 32.7127
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 47.2564
                       Mean reward: 51.75
               Mean episode length: 225.13
    Episode_Reward/reaching_object: 0.7654
    Episode_Reward/rotating_object: 9.5072
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 2.22s
                      Time elapsed: 00:06:23
                               ETA: 00:48:10

################################################################################
                     [1m Learning iteration 176/1500 [0m                      

                       Computation: 44197 steps/s (collection: 2.113s, learning 0.111s)
             Mean action noise std: 1.50
          Mean value_function loss: 34.2615
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 47.3071
                       Mean reward: 77.74
               Mean episode length: 225.65
    Episode_Reward/reaching_object: 0.8248
    Episode_Reward/rotating_object: 12.1939
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 2.22s
                      Time elapsed: 00:06:26
                               ETA: 00:48:09

################################################################################
                     [1m Learning iteration 177/1500 [0m                      

                       Computation: 43339 steps/s (collection: 2.157s, learning 0.111s)
             Mean action noise std: 1.50
          Mean value_function loss: 36.0644
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 47.3537
                       Mean reward: 75.95
               Mean episode length: 231.85
    Episode_Reward/reaching_object: 0.8649
    Episode_Reward/rotating_object: 13.0982
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 2.27s
                      Time elapsed: 00:06:28
                               ETA: 00:48:07

################################################################################
                     [1m Learning iteration 178/1500 [0m                      

                       Computation: 43312 steps/s (collection: 2.158s, learning 0.111s)
             Mean action noise std: 1.50
          Mean value_function loss: 33.3938
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 47.4013
                       Mean reward: 69.25
               Mean episode length: 225.60
    Episode_Reward/reaching_object: 0.8635
    Episode_Reward/rotating_object: 13.1525
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 2.27s
                      Time elapsed: 00:06:30
                               ETA: 00:48:05

################################################################################
                     [1m Learning iteration 179/1500 [0m                      

                       Computation: 42860 steps/s (collection: 2.179s, learning 0.114s)
             Mean action noise std: 1.51
          Mean value_function loss: 33.6213
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 47.4455
                       Mean reward: 62.55
               Mean episode length: 229.13
    Episode_Reward/reaching_object: 0.8611
    Episode_Reward/rotating_object: 12.1668
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 2.29s
                      Time elapsed: 00:06:33
                               ETA: 00:48:04

################################################################################
                     [1m Learning iteration 180/1500 [0m                      

                       Computation: 43221 steps/s (collection: 2.162s, learning 0.112s)
             Mean action noise std: 1.51
          Mean value_function loss: 36.6242
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 47.4853
                       Mean reward: 58.33
               Mean episode length: 228.15
    Episode_Reward/reaching_object: 0.8611
    Episode_Reward/rotating_object: 12.0989
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 2.27s
                      Time elapsed: 00:06:35
                               ETA: 00:48:03

################################################################################
                     [1m Learning iteration 181/1500 [0m                      

                       Computation: 44289 steps/s (collection: 2.100s, learning 0.119s)
             Mean action noise std: 1.51
          Mean value_function loss: 35.7578
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 47.5396
                       Mean reward: 64.24
               Mean episode length: 229.94
    Episode_Reward/reaching_object: 0.8402
    Episode_Reward/rotating_object: 12.0810
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 2.22s
                      Time elapsed: 00:06:37
                               ETA: 00:48:01

################################################################################
                     [1m Learning iteration 182/1500 [0m                      

                       Computation: 44505 steps/s (collection: 2.095s, learning 0.114s)
             Mean action noise std: 1.51
          Mean value_function loss: 36.3677
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 47.5870
                       Mean reward: 79.91
               Mean episode length: 229.28
    Episode_Reward/reaching_object: 0.8652
    Episode_Reward/rotating_object: 12.9835
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 2.21s
                      Time elapsed: 00:06:39
                               ETA: 00:47:59

################################################################################
                     [1m Learning iteration 183/1500 [0m                      

                       Computation: 43747 steps/s (collection: 2.136s, learning 0.111s)
             Mean action noise std: 1.52
          Mean value_function loss: 38.5864
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 47.6231
                       Mean reward: 76.86
               Mean episode length: 227.65
    Episode_Reward/reaching_object: 0.8734
    Episode_Reward/rotating_object: 13.9702
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 2.25s
                      Time elapsed: 00:06:41
                               ETA: 00:47:57

################################################################################
                     [1m Learning iteration 184/1500 [0m                      

                       Computation: 42768 steps/s (collection: 2.188s, learning 0.110s)
             Mean action noise std: 1.52
          Mean value_function loss: 35.7399
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 47.6622
                       Mean reward: 61.12
               Mean episode length: 228.80
    Episode_Reward/reaching_object: 0.8631
    Episode_Reward/rotating_object: 11.9781
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 2.30s
                      Time elapsed: 00:06:44
                               ETA: 00:47:55

################################################################################
                     [1m Learning iteration 185/1500 [0m                      

                       Computation: 44388 steps/s (collection: 2.104s, learning 0.111s)
             Mean action noise std: 1.52
          Mean value_function loss: 33.0475
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 47.7019
                       Mean reward: 75.67
               Mean episode length: 231.86
    Episode_Reward/reaching_object: 0.8609
    Episode_Reward/rotating_object: 13.4897
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 2.21s
                      Time elapsed: 00:06:46
                               ETA: 00:47:54

################################################################################
                     [1m Learning iteration 186/1500 [0m                      

                       Computation: 45191 steps/s (collection: 2.065s, learning 0.110s)
             Mean action noise std: 1.52
          Mean value_function loss: 34.7758
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 47.7311
                       Mean reward: 81.65
               Mean episode length: 234.35
    Episode_Reward/reaching_object: 0.8392
    Episode_Reward/rotating_object: 14.5978
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 2.18s
                      Time elapsed: 00:06:48
                               ETA: 00:47:51

################################################################################
                     [1m Learning iteration 187/1500 [0m                      

                       Computation: 44994 steps/s (collection: 2.074s, learning 0.111s)
             Mean action noise std: 1.53
          Mean value_function loss: 29.9585
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 47.7628
                       Mean reward: 70.94
               Mean episode length: 231.09
    Episode_Reward/reaching_object: 0.8512
    Episode_Reward/rotating_object: 14.1124
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 2.18s
                      Time elapsed: 00:06:50
                               ETA: 00:47:49

################################################################################
                     [1m Learning iteration 188/1500 [0m                      

                       Computation: 45119 steps/s (collection: 2.068s, learning 0.111s)
             Mean action noise std: 1.53
          Mean value_function loss: 38.7850
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 47.8230
                       Mean reward: 90.47
               Mean episode length: 239.11
    Episode_Reward/reaching_object: 0.8567
    Episode_Reward/rotating_object: 15.6548
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 2.18s
                      Time elapsed: 00:06:53
                               ETA: 00:47:47

################################################################################
                     [1m Learning iteration 189/1500 [0m                      

                       Computation: 45256 steps/s (collection: 2.059s, learning 0.113s)
             Mean action noise std: 1.53
          Mean value_function loss: 37.0245
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 47.8631
                       Mean reward: 42.61
               Mean episode length: 228.12
    Episode_Reward/reaching_object: 0.8356
    Episode_Reward/rotating_object: 12.4352
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 2.17s
                      Time elapsed: 00:06:55
                               ETA: 00:47:45

################################################################################
                     [1m Learning iteration 190/1500 [0m                      

                       Computation: 44072 steps/s (collection: 2.117s, learning 0.113s)
             Mean action noise std: 1.53
          Mean value_function loss: 40.9462
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 47.8947
                       Mean reward: 96.66
               Mean episode length: 227.54
    Episode_Reward/reaching_object: 0.8295
    Episode_Reward/rotating_object: 15.4009
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 2.23s
                      Time elapsed: 00:06:57
                               ETA: 00:47:43

################################################################################
                     [1m Learning iteration 191/1500 [0m                      

                       Computation: 44344 steps/s (collection: 2.104s, learning 0.112s)
             Mean action noise std: 1.54
          Mean value_function loss: 41.3803
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 47.9350
                       Mean reward: 90.03
               Mean episode length: 238.53
    Episode_Reward/reaching_object: 0.8659
    Episode_Reward/rotating_object: 18.5797
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 2.22s
                      Time elapsed: 00:06:59
                               ETA: 00:47:41

################################################################################
                     [1m Learning iteration 192/1500 [0m                      

                       Computation: 44076 steps/s (collection: 2.118s, learning 0.112s)
             Mean action noise std: 1.54
          Mean value_function loss: 42.8302
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 47.9735
                       Mean reward: 87.72
               Mean episode length: 229.90
    Episode_Reward/reaching_object: 0.8310
    Episode_Reward/rotating_object: 14.3549
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 2.23s
                      Time elapsed: 00:07:01
                               ETA: 00:47:39

################################################################################
                     [1m Learning iteration 193/1500 [0m                      

                       Computation: 44099 steps/s (collection: 2.115s, learning 0.114s)
             Mean action noise std: 1.54
          Mean value_function loss: 41.0454
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 48.0089
                       Mean reward: 97.27
               Mean episode length: 227.84
    Episode_Reward/reaching_object: 0.8300
    Episode_Reward/rotating_object: 16.1399
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 2.23s
                      Time elapsed: 00:07:04
                               ETA: 00:47:37

################################################################################
                     [1m Learning iteration 194/1500 [0m                      

                       Computation: 43445 steps/s (collection: 2.152s, learning 0.111s)
             Mean action noise std: 1.54
          Mean value_function loss: 45.7286
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 48.0448
                       Mean reward: 68.76
               Mean episode length: 226.23
    Episode_Reward/reaching_object: 0.8181
    Episode_Reward/rotating_object: 13.2294
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 2.26s
                      Time elapsed: 00:07:06
                               ETA: 00:47:35

################################################################################
                     [1m Learning iteration 195/1500 [0m                      

                       Computation: 43565 steps/s (collection: 2.145s, learning 0.111s)
             Mean action noise std: 1.54
          Mean value_function loss: 40.3697
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 48.0773
                       Mean reward: 77.45
               Mean episode length: 230.99
    Episode_Reward/reaching_object: 0.8147
    Episode_Reward/rotating_object: 14.4784
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 2.26s
                      Time elapsed: 00:07:08
                               ETA: 00:47:34

################################################################################
                     [1m Learning iteration 196/1500 [0m                      

                       Computation: 44149 steps/s (collection: 2.114s, learning 0.113s)
             Mean action noise std: 1.55
          Mean value_function loss: 41.9189
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 48.1087
                       Mean reward: 85.88
               Mean episode length: 222.45
    Episode_Reward/reaching_object: 0.8212
    Episode_Reward/rotating_object: 16.0874
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 2.23s
                      Time elapsed: 00:07:10
                               ETA: 00:47:32

################################################################################
                     [1m Learning iteration 197/1500 [0m                      

                       Computation: 41879 steps/s (collection: 2.222s, learning 0.126s)
             Mean action noise std: 1.55
          Mean value_function loss: 45.3431
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 48.1361
                       Mean reward: 87.33
               Mean episode length: 213.17
    Episode_Reward/reaching_object: 0.8173
    Episode_Reward/rotating_object: 15.6770
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 2.35s
                      Time elapsed: 00:07:13
                               ETA: 00:47:30

################################################################################
                     [1m Learning iteration 198/1500 [0m                      

                       Computation: 40746 steps/s (collection: 2.282s, learning 0.130s)
             Mean action noise std: 1.55
          Mean value_function loss: 45.7672
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 48.1689
                       Mean reward: 66.19
               Mean episode length: 226.67
    Episode_Reward/reaching_object: 0.8146
    Episode_Reward/rotating_object: 13.7349
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 2.41s
                      Time elapsed: 00:07:15
                               ETA: 00:47:30

################################################################################
                     [1m Learning iteration 199/1500 [0m                      

                       Computation: 40818 steps/s (collection: 2.280s, learning 0.128s)
             Mean action noise std: 1.55
          Mean value_function loss: 48.8776
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 48.1980
                       Mean reward: 93.58
               Mean episode length: 228.55
    Episode_Reward/reaching_object: 0.8391
    Episode_Reward/rotating_object: 17.1118
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 2.41s
                      Time elapsed: 00:07:18
                               ETA: 00:47:29

################################################################################
                     [1m Learning iteration 200/1500 [0m                      

                       Computation: 40955 steps/s (collection: 2.272s, learning 0.128s)
             Mean action noise std: 1.55
          Mean value_function loss: 49.5650
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 48.2283
                       Mean reward: 89.57
               Mean episode length: 229.11
    Episode_Reward/reaching_object: 0.8523
    Episode_Reward/rotating_object: 17.2043
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 2.40s
                      Time elapsed: 00:07:20
                               ETA: 00:47:28

################################################################################
                     [1m Learning iteration 201/1500 [0m                      

                       Computation: 43136 steps/s (collection: 2.164s, learning 0.114s)
             Mean action noise std: 1.55
          Mean value_function loss: 48.9648
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 48.2592
                       Mean reward: 62.32
               Mean episode length: 206.26
    Episode_Reward/reaching_object: 0.7982
    Episode_Reward/rotating_object: 15.1648
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 2.28s
                      Time elapsed: 00:07:22
                               ETA: 00:47:27

################################################################################
                     [1m Learning iteration 202/1500 [0m                      

                       Computation: 43490 steps/s (collection: 2.146s, learning 0.114s)
             Mean action noise std: 1.56
          Mean value_function loss: 51.3204
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 48.2928
                       Mean reward: 79.89
               Mean episode length: 215.22
    Episode_Reward/reaching_object: 0.8036
    Episode_Reward/rotating_object: 16.8000
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 10.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 2.26s
                      Time elapsed: 00:07:24
                               ETA: 00:47:25

################################################################################
                     [1m Learning iteration 203/1500 [0m                      

                       Computation: 43853 steps/s (collection: 2.128s, learning 0.114s)
             Mean action noise std: 1.56
          Mean value_function loss: 55.7754
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 48.3226
                       Mean reward: 85.74
               Mean episode length: 218.29
    Episode_Reward/reaching_object: 0.7779
    Episode_Reward/rotating_object: 15.3055
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 2.24s
                      Time elapsed: 00:07:27
                               ETA: 00:47:23

################################################################################
                     [1m Learning iteration 204/1500 [0m                      

                       Computation: 44405 steps/s (collection: 2.103s, learning 0.110s)
             Mean action noise std: 1.56
          Mean value_function loss: 48.9793
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 48.3497
                       Mean reward: 97.98
               Mean episode length: 218.66
    Episode_Reward/reaching_object: 0.8170
    Episode_Reward/rotating_object: 18.8905
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 2.21s
                      Time elapsed: 00:07:29
                               ETA: 00:47:21

################################################################################
                     [1m Learning iteration 205/1500 [0m                      

                       Computation: 44205 steps/s (collection: 2.113s, learning 0.111s)
             Mean action noise std: 1.56
          Mean value_function loss: 45.4088
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 48.3671
                       Mean reward: 61.76
               Mean episode length: 217.72
    Episode_Reward/reaching_object: 0.8094
    Episode_Reward/rotating_object: 16.4038
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 2.22s
                      Time elapsed: 00:07:31
                               ETA: 00:47:19

################################################################################
                     [1m Learning iteration 206/1500 [0m                      

                       Computation: 44839 steps/s (collection: 2.081s, learning 0.111s)
             Mean action noise std: 1.56
          Mean value_function loss: 50.3497
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 48.3859
                       Mean reward: 99.21
               Mean episode length: 232.31
    Episode_Reward/reaching_object: 0.8337
    Episode_Reward/rotating_object: 18.0148
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 2.19s
                      Time elapsed: 00:07:33
                               ETA: 00:47:17

################################################################################
                     [1m Learning iteration 207/1500 [0m                      

                       Computation: 44815 steps/s (collection: 2.083s, learning 0.111s)
             Mean action noise std: 1.56
          Mean value_function loss: 51.4573
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 48.4208
                       Mean reward: 133.07
               Mean episode length: 218.85
    Episode_Reward/reaching_object: 0.8510
    Episode_Reward/rotating_object: 22.2170
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 2.19s
                      Time elapsed: 00:07:36
                               ETA: 00:47:14

################################################################################
                     [1m Learning iteration 208/1500 [0m                      

                       Computation: 44817 steps/s (collection: 2.083s, learning 0.111s)
             Mean action noise std: 1.57
          Mean value_function loss: 54.8133
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 48.4491
                       Mean reward: 108.90
               Mean episode length: 219.45
    Episode_Reward/reaching_object: 0.8618
    Episode_Reward/rotating_object: 20.3684
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 2.19s
                      Time elapsed: 00:07:38
                               ETA: 00:47:12

################################################################################
                     [1m Learning iteration 209/1500 [0m                      

                       Computation: 44928 steps/s (collection: 2.077s, learning 0.111s)
             Mean action noise std: 1.57
          Mean value_function loss: 50.6157
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 48.4830
                       Mean reward: 86.07
               Mean episode length: 214.75
    Episode_Reward/reaching_object: 0.8118
    Episode_Reward/rotating_object: 17.4806
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 2.19s
                      Time elapsed: 00:07:40
                               ETA: 00:47:10

################################################################################
                     [1m Learning iteration 210/1500 [0m                      

                       Computation: 45057 steps/s (collection: 2.071s, learning 0.111s)
             Mean action noise std: 1.57
          Mean value_function loss: 47.6347
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 48.5209
                       Mean reward: 97.69
               Mean episode length: 213.52
    Episode_Reward/reaching_object: 0.8481
    Episode_Reward/rotating_object: 19.8751
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 2.18s
                      Time elapsed: 00:07:42
                               ETA: 00:47:08

################################################################################
                     [1m Learning iteration 211/1500 [0m                      

                       Computation: 44279 steps/s (collection: 2.108s, learning 0.112s)
             Mean action noise std: 1.57
          Mean value_function loss: 48.6428
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 48.5478
                       Mean reward: 89.06
               Mean episode length: 218.53
    Episode_Reward/reaching_object: 0.8182
    Episode_Reward/rotating_object: 18.5185
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 2.22s
                      Time elapsed: 00:07:44
                               ETA: 00:47:06

################################################################################
                     [1m Learning iteration 212/1500 [0m                      

                       Computation: 41181 steps/s (collection: 2.261s, learning 0.126s)
             Mean action noise std: 1.57
          Mean value_function loss: 46.2653
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 48.5654
                       Mean reward: 92.27
               Mean episode length: 220.03
    Episode_Reward/reaching_object: 0.8192
    Episode_Reward/rotating_object: 17.8846
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 2.39s
                      Time elapsed: 00:07:47
                               ETA: 00:47:05

################################################################################
                     [1m Learning iteration 213/1500 [0m                      

                       Computation: 43642 steps/s (collection: 2.140s, learning 0.113s)
             Mean action noise std: 1.57
          Mean value_function loss: 48.3343
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 48.5792
                       Mean reward: 108.70
               Mean episode length: 219.90
    Episode_Reward/reaching_object: 0.8237
    Episode_Reward/rotating_object: 18.1760
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 2.25s
                      Time elapsed: 00:07:49
                               ETA: 00:47:03

################################################################################
                     [1m Learning iteration 214/1500 [0m                      

                       Computation: 42471 steps/s (collection: 2.185s, learning 0.130s)
             Mean action noise std: 1.57
          Mean value_function loss: 50.3010
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 48.5937
                       Mean reward: 105.31
               Mean episode length: 229.43
    Episode_Reward/reaching_object: 0.7989
    Episode_Reward/rotating_object: 17.5313
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 2.31s
                      Time elapsed: 00:07:51
                               ETA: 00:47:01

################################################################################
                     [1m Learning iteration 215/1500 [0m                      

                       Computation: 42621 steps/s (collection: 2.194s, learning 0.113s)
             Mean action noise std: 1.58
          Mean value_function loss: 54.4352
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 48.6073
                       Mean reward: 117.71
               Mean episode length: 223.91
    Episode_Reward/reaching_object: 0.8296
    Episode_Reward/rotating_object: 19.7706
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 2.31s
                      Time elapsed: 00:07:54
                               ETA: 00:47:00

################################################################################
                     [1m Learning iteration 216/1500 [0m                      

                       Computation: 43215 steps/s (collection: 2.162s, learning 0.113s)
             Mean action noise std: 1.58
          Mean value_function loss: 59.3740
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 48.6302
                       Mean reward: 103.99
               Mean episode length: 213.78
    Episode_Reward/reaching_object: 0.8397
    Episode_Reward/rotating_object: 20.4679
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 2.27s
                      Time elapsed: 00:07:56
                               ETA: 00:46:58

################################################################################
                     [1m Learning iteration 217/1500 [0m                      

                       Computation: 42997 steps/s (collection: 2.176s, learning 0.110s)
             Mean action noise std: 1.58
          Mean value_function loss: 60.5776
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 48.6620
                       Mean reward: 112.07
               Mean episode length: 219.56
    Episode_Reward/reaching_object: 0.8143
    Episode_Reward/rotating_object: 18.6996
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 6.8333
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 2.29s
                      Time elapsed: 00:07:58
                               ETA: 00:46:57

################################################################################
                     [1m Learning iteration 218/1500 [0m                      

                       Computation: 43157 steps/s (collection: 2.166s, learning 0.112s)
             Mean action noise std: 1.58
          Mean value_function loss: 56.5483
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 48.6966
                       Mean reward: 100.19
               Mean episode length: 213.25
    Episode_Reward/reaching_object: 0.8247
    Episode_Reward/rotating_object: 20.8636
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 2.28s
                      Time elapsed: 00:08:00
                               ETA: 00:46:55

################################################################################
                     [1m Learning iteration 219/1500 [0m                      

                       Computation: 43501 steps/s (collection: 2.147s, learning 0.113s)
             Mean action noise std: 1.58
          Mean value_function loss: 59.3553
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 48.7268
                       Mean reward: 93.15
               Mean episode length: 205.37
    Episode_Reward/reaching_object: 0.7929
    Episode_Reward/rotating_object: 19.0216
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 7.1250
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 2.26s
                      Time elapsed: 00:08:03
                               ETA: 00:46:53

################################################################################
                     [1m Learning iteration 220/1500 [0m                      

                       Computation: 43678 steps/s (collection: 2.140s, learning 0.110s)
             Mean action noise std: 1.59
          Mean value_function loss: 57.2627
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 48.7568
                       Mean reward: 95.90
               Mean episode length: 210.46
    Episode_Reward/reaching_object: 0.7912
    Episode_Reward/rotating_object: 19.4662
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 2.25s
                      Time elapsed: 00:08:05
                               ETA: 00:46:51

################################################################################
                     [1m Learning iteration 221/1500 [0m                      

                       Computation: 43747 steps/s (collection: 2.134s, learning 0.113s)
             Mean action noise std: 1.59
          Mean value_function loss: 55.8219
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 48.7825
                       Mean reward: 110.98
               Mean episode length: 199.12
    Episode_Reward/reaching_object: 0.8247
    Episode_Reward/rotating_object: 21.6436
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 2.25s
                      Time elapsed: 00:08:07
                               ETA: 00:46:49

################################################################################
                     [1m Learning iteration 222/1500 [0m                      

                       Computation: 40673 steps/s (collection: 2.290s, learning 0.127s)
             Mean action noise std: 1.59
          Mean value_function loss: 65.2264
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 48.8016
                       Mean reward: 88.43
               Mean episode length: 204.43
    Episode_Reward/reaching_object: 0.7968
    Episode_Reward/rotating_object: 18.2237
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 7.1250
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 2.42s
                      Time elapsed: 00:08:10
                               ETA: 00:46:48

################################################################################
                     [1m Learning iteration 223/1500 [0m                      

                       Computation: 40615 steps/s (collection: 2.292s, learning 0.128s)
             Mean action noise std: 1.59
          Mean value_function loss: 68.1843
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 48.8191
                       Mean reward: 113.20
               Mean episode length: 203.86
    Episode_Reward/reaching_object: 0.7744
    Episode_Reward/rotating_object: 19.8173
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 11.3750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 7.0833
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 2.42s
                      Time elapsed: 00:08:12
                               ETA: 00:46:47

################################################################################
                     [1m Learning iteration 224/1500 [0m                      

                       Computation: 40075 steps/s (collection: 2.321s, learning 0.132s)
             Mean action noise std: 1.59
          Mean value_function loss: 70.2610
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 48.8431
                       Mean reward: 81.46
               Mean episode length: 193.16
    Episode_Reward/reaching_object: 0.7739
    Episode_Reward/rotating_object: 16.9109
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 11.7917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 7.7083
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 2.45s
                      Time elapsed: 00:08:14
                               ETA: 00:46:47

################################################################################
                     [1m Learning iteration 225/1500 [0m                      

                       Computation: 40289 steps/s (collection: 2.312s, learning 0.128s)
             Mean action noise std: 1.59
          Mean value_function loss: 63.4296
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 48.8713
                       Mean reward: 109.76
               Mean episode length: 210.40
    Episode_Reward/reaching_object: 0.8185
    Episode_Reward/rotating_object: 22.4218
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 11.9167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 2.44s
                      Time elapsed: 00:08:17
                               ETA: 00:46:46

################################################################################
                     [1m Learning iteration 226/1500 [0m                      

                       Computation: 41415 steps/s (collection: 2.260s, learning 0.113s)
             Mean action noise std: 1.59
          Mean value_function loss: 70.1046
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 48.9040
                       Mean reward: 119.63
               Mean episode length: 212.90
    Episode_Reward/reaching_object: 0.7901
    Episode_Reward/rotating_object: 18.3441
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 11.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 7.5417
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 2.37s
                      Time elapsed: 00:08:19
                               ETA: 00:46:45

################################################################################
                     [1m Learning iteration 227/1500 [0m                      

                       Computation: 44075 steps/s (collection: 2.120s, learning 0.110s)
             Mean action noise std: 1.60
          Mean value_function loss: 65.5640
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 48.9364
                       Mean reward: 112.07
               Mean episode length: 207.27
    Episode_Reward/reaching_object: 0.8638
    Episode_Reward/rotating_object: 23.1729
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 2.23s
                      Time elapsed: 00:08:22
                               ETA: 00:46:42

################################################################################
                     [1m Learning iteration 228/1500 [0m                      

                       Computation: 44520 steps/s (collection: 2.097s, learning 0.111s)
             Mean action noise std: 1.60
          Mean value_function loss: 67.5545
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 48.9697
                       Mean reward: 129.68
               Mean episode length: 209.00
    Episode_Reward/reaching_object: 0.8292
    Episode_Reward/rotating_object: 22.0309
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 2.21s
                      Time elapsed: 00:08:24
                               ETA: 00:46:40

################################################################################
                     [1m Learning iteration 229/1500 [0m                      

                       Computation: 44284 steps/s (collection: 2.108s, learning 0.112s)
             Mean action noise std: 1.60
          Mean value_function loss: 71.2912
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 48.9958
                       Mean reward: 115.28
               Mean episode length: 214.63
    Episode_Reward/reaching_object: 0.8269
    Episode_Reward/rotating_object: 21.3723
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 2.22s
                      Time elapsed: 00:08:26
                               ETA: 00:46:38

################################################################################
                     [1m Learning iteration 230/1500 [0m                      

                       Computation: 44627 steps/s (collection: 2.092s, learning 0.110s)
             Mean action noise std: 1.60
          Mean value_function loss: 71.1545
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 49.0112
                       Mean reward: 159.38
               Mean episode length: 206.66
    Episode_Reward/reaching_object: 0.8099
    Episode_Reward/rotating_object: 22.6249
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 7.2917
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 2.20s
                      Time elapsed: 00:08:28
                               ETA: 00:46:36

################################################################################
                     [1m Learning iteration 231/1500 [0m                      

                       Computation: 44092 steps/s (collection: 2.109s, learning 0.120s)
             Mean action noise std: 1.60
          Mean value_function loss: 69.6175
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 49.0375
                       Mean reward: 98.50
               Mean episode length: 214.31
    Episode_Reward/reaching_object: 0.8628
    Episode_Reward/rotating_object: 23.5492
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 2.23s
                      Time elapsed: 00:08:30
                               ETA: 00:46:34

################################################################################
                     [1m Learning iteration 232/1500 [0m                      

                       Computation: 44068 steps/s (collection: 2.115s, learning 0.116s)
             Mean action noise std: 1.60
          Mean value_function loss: 72.9257
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 49.0667
                       Mean reward: 90.85
               Mean episode length: 202.89
    Episode_Reward/reaching_object: 0.8110
    Episode_Reward/rotating_object: 22.8088
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 11.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 7.0417
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 2.23s
                      Time elapsed: 00:08:33
                               ETA: 00:46:32

################################################################################
                     [1m Learning iteration 233/1500 [0m                      

                       Computation: 43530 steps/s (collection: 2.144s, learning 0.114s)
             Mean action noise std: 1.61
          Mean value_function loss: 67.0994
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 49.0971
                       Mean reward: 141.03
               Mean episode length: 203.49
    Episode_Reward/reaching_object: 0.8154
    Episode_Reward/rotating_object: 23.0980
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 7.0417
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 2.26s
                      Time elapsed: 00:08:35
                               ETA: 00:46:30

################################################################################
                     [1m Learning iteration 234/1500 [0m                      

                       Computation: 43448 steps/s (collection: 2.139s, learning 0.123s)
             Mean action noise std: 1.61
          Mean value_function loss: 72.0732
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 49.1188
                       Mean reward: 114.69
               Mean episode length: 213.03
    Episode_Reward/reaching_object: 0.8184
    Episode_Reward/rotating_object: 22.2546
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 2.26s
                      Time elapsed: 00:08:37
                               ETA: 00:46:28

################################################################################
                     [1m Learning iteration 235/1500 [0m                      

                       Computation: 43416 steps/s (collection: 2.141s, learning 0.123s)
             Mean action noise std: 1.61
          Mean value_function loss: 71.4780
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 49.1243
                       Mean reward: 128.78
               Mean episode length: 206.23
    Episode_Reward/reaching_object: 0.8053
    Episode_Reward/rotating_object: 21.7152
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 2.26s
                      Time elapsed: 00:08:39
                               ETA: 00:46:26

################################################################################
                     [1m Learning iteration 236/1500 [0m                      

                       Computation: 43179 steps/s (collection: 2.163s, learning 0.114s)
             Mean action noise std: 1.61
          Mean value_function loss: 74.2411
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 49.1369
                       Mean reward: 127.57
               Mean episode length: 212.54
    Episode_Reward/reaching_object: 0.8112
    Episode_Reward/rotating_object: 24.2322
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 7.7500
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 2.28s
                      Time elapsed: 00:08:42
                               ETA: 00:46:24

################################################################################
                     [1m Learning iteration 237/1500 [0m                      

                       Computation: 42519 steps/s (collection: 2.199s, learning 0.113s)
             Mean action noise std: 1.61
          Mean value_function loss: 69.4711
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 49.1602
                       Mean reward: 135.79
               Mean episode length: 206.83
    Episode_Reward/reaching_object: 0.8312
    Episode_Reward/rotating_object: 24.0020
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 2.31s
                      Time elapsed: 00:08:44
                               ETA: 00:46:23

################################################################################
                     [1m Learning iteration 238/1500 [0m                      

                       Computation: 42687 steps/s (collection: 2.192s, learning 0.110s)
             Mean action noise std: 1.61
          Mean value_function loss: 77.3119
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 49.1799
                       Mean reward: 116.59
               Mean episode length: 206.83
    Episode_Reward/reaching_object: 0.8611
    Episode_Reward/rotating_object: 24.9339
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 7.5417
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 2.30s
                      Time elapsed: 00:08:46
                               ETA: 00:46:21

################################################################################
                     [1m Learning iteration 239/1500 [0m                      

                       Computation: 42942 steps/s (collection: 2.178s, learning 0.112s)
             Mean action noise std: 1.61
          Mean value_function loss: 79.2022
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 49.2004
                       Mean reward: 121.13
               Mean episode length: 210.92
    Episode_Reward/reaching_object: 0.8747
    Episode_Reward/rotating_object: 26.2860
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 2.29s
                      Time elapsed: 00:08:49
                               ETA: 00:46:19

################################################################################
                     [1m Learning iteration 240/1500 [0m                      

                       Computation: 42483 steps/s (collection: 2.204s, learning 0.110s)
             Mean action noise std: 1.61
          Mean value_function loss: 76.2437
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 49.2220
                       Mean reward: 130.31
               Mean episode length: 197.55
    Episode_Reward/reaching_object: 0.8585
    Episode_Reward/rotating_object: 26.0521
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 7.0000
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 2.31s
                      Time elapsed: 00:08:51
                               ETA: 00:46:18

################################################################################
                     [1m Learning iteration 241/1500 [0m                      

                       Computation: 42798 steps/s (collection: 2.184s, learning 0.113s)
             Mean action noise std: 1.62
          Mean value_function loss: 81.5432
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 49.2440
                       Mean reward: 131.60
               Mean episode length: 215.05
    Episode_Reward/reaching_object: 0.8626
    Episode_Reward/rotating_object: 25.0024
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 11.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 2.30s
                      Time elapsed: 00:08:53
                               ETA: 00:46:16

################################################################################
                     [1m Learning iteration 242/1500 [0m                      

                       Computation: 42614 steps/s (collection: 2.185s, learning 0.122s)
             Mean action noise std: 1.62
          Mean value_function loss: 75.9663
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 49.2662
                       Mean reward: 138.93
               Mean episode length: 212.35
    Episode_Reward/reaching_object: 0.8564
    Episode_Reward/rotating_object: 27.5672
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 11.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 2.31s
                      Time elapsed: 00:08:55
                               ETA: 00:46:14

################################################################################
                     [1m Learning iteration 243/1500 [0m                      

                       Computation: 42736 steps/s (collection: 2.177s, learning 0.123s)
             Mean action noise std: 1.62
          Mean value_function loss: 85.2208
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 49.2956
                       Mean reward: 138.45
               Mean episode length: 213.08
    Episode_Reward/reaching_object: 0.8881
    Episode_Reward/rotating_object: 27.0948
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 2.30s
                      Time elapsed: 00:08:58
                               ETA: 00:46:13

################################################################################
                     [1m Learning iteration 244/1500 [0m                      

                       Computation: 42865 steps/s (collection: 2.168s, learning 0.125s)
             Mean action noise std: 1.62
          Mean value_function loss: 83.7571
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 49.3209
                       Mean reward: 133.61
               Mean episode length: 210.53
    Episode_Reward/reaching_object: 0.8713
    Episode_Reward/rotating_object: 25.5390
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 2.29s
                      Time elapsed: 00:09:00
                               ETA: 00:46:11

################################################################################
                     [1m Learning iteration 245/1500 [0m                      

                       Computation: 43307 steps/s (collection: 2.154s, learning 0.115s)
             Mean action noise std: 1.62
          Mean value_function loss: 78.0589
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 49.3468
                       Mean reward: 141.19
               Mean episode length: 211.99
    Episode_Reward/reaching_object: 0.8573
    Episode_Reward/rotating_object: 25.9034
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 12.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 7.0417
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 2.27s
                      Time elapsed: 00:09:02
                               ETA: 00:46:09

################################################################################
                     [1m Learning iteration 246/1500 [0m                      

                       Computation: 42684 steps/s (collection: 2.189s, learning 0.114s)
             Mean action noise std: 1.62
          Mean value_function loss: 85.6010
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 49.3750
                       Mean reward: 137.36
               Mean episode length: 194.76
    Episode_Reward/reaching_object: 0.8471
    Episode_Reward/rotating_object: 24.2944
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 12.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 2.30s
                      Time elapsed: 00:09:05
                               ETA: 00:46:07

################################################################################
                     [1m Learning iteration 247/1500 [0m                      

                       Computation: 42656 steps/s (collection: 2.193s, learning 0.111s)
             Mean action noise std: 1.63
          Mean value_function loss: 91.2580
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 49.3967
                       Mean reward: 135.29
               Mean episode length: 207.07
    Episode_Reward/reaching_object: 0.9000
    Episode_Reward/rotating_object: 28.4992
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 2.30s
                      Time elapsed: 00:09:07
                               ETA: 00:46:06

################################################################################
                     [1m Learning iteration 248/1500 [0m                      

                       Computation: 42248 steps/s (collection: 2.198s, learning 0.128s)
             Mean action noise std: 1.63
          Mean value_function loss: 76.3804
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 49.4173
                       Mean reward: 157.51
               Mean episode length: 207.59
    Episode_Reward/reaching_object: 0.8924
    Episode_Reward/rotating_object: 28.2842
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 2.33s
                      Time elapsed: 00:09:09
                               ETA: 00:46:04

################################################################################
                     [1m Learning iteration 249/1500 [0m                      

                       Computation: 42746 steps/s (collection: 2.189s, learning 0.111s)
             Mean action noise std: 1.63
          Mean value_function loss: 66.7722
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 49.4288
                       Mean reward: 151.17
               Mean episode length: 207.28
    Episode_Reward/reaching_object: 0.9035
    Episode_Reward/rotating_object: 30.2929
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 2.30s
                      Time elapsed: 00:09:12
                               ETA: 00:46:02

################################################################################
                     [1m Learning iteration 250/1500 [0m                      

                       Computation: 42537 steps/s (collection: 2.200s, learning 0.111s)
             Mean action noise std: 1.63
          Mean value_function loss: 70.2036
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 49.4454
                       Mean reward: 140.33
               Mean episode length: 214.11
    Episode_Reward/reaching_object: 0.9246
    Episode_Reward/rotating_object: 28.7502
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 2.31s
                      Time elapsed: 00:09:14
                               ETA: 00:46:00

################################################################################
                     [1m Learning iteration 251/1500 [0m                      

                       Computation: 44001 steps/s (collection: 2.123s, learning 0.111s)
             Mean action noise std: 1.63
          Mean value_function loss: 67.0462
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 49.4686
                       Mean reward: 170.97
               Mean episode length: 203.36
    Episode_Reward/reaching_object: 0.8897
    Episode_Reward/rotating_object: 31.2127
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 7.0000
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 2.23s
                      Time elapsed: 00:09:16
                               ETA: 00:45:58

################################################################################
                     [1m Learning iteration 252/1500 [0m                      

                       Computation: 43710 steps/s (collection: 2.138s, learning 0.111s)
             Mean action noise std: 1.63
          Mean value_function loss: 78.7498
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 49.4979
                       Mean reward: 130.35
               Mean episode length: 206.53
    Episode_Reward/reaching_object: 0.8824
    Episode_Reward/rotating_object: 27.1562
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 11.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.8750
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 2.25s
                      Time elapsed: 00:09:18
                               ETA: 00:45:56

################################################################################
                     [1m Learning iteration 253/1500 [0m                      

                       Computation: 43493 steps/s (collection: 2.146s, learning 0.114s)
             Mean action noise std: 1.63
          Mean value_function loss: 80.3387
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 49.5148
                       Mean reward: 139.81
               Mean episode length: 209.52
    Episode_Reward/reaching_object: 0.9159
    Episode_Reward/rotating_object: 31.5580
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 2.26s
                      Time elapsed: 00:09:21
                               ETA: 00:45:54

################################################################################
                     [1m Learning iteration 254/1500 [0m                      

                       Computation: 43064 steps/s (collection: 2.171s, learning 0.112s)
             Mean action noise std: 1.63
          Mean value_function loss: 94.5516
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 49.5335
                       Mean reward: 167.37
               Mean episode length: 207.49
    Episode_Reward/reaching_object: 0.9100
    Episode_Reward/rotating_object: 30.5412
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 11.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 2.28s
                      Time elapsed: 00:09:23
                               ETA: 00:45:53

################################################################################
                     [1m Learning iteration 255/1500 [0m                      

                       Computation: 42422 steps/s (collection: 2.202s, learning 0.115s)
             Mean action noise std: 1.64
          Mean value_function loss: 88.0194
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 49.5511
                       Mean reward: 178.66
               Mean episode length: 214.04
    Episode_Reward/reaching_object: 0.9163
    Episode_Reward/rotating_object: 31.5899
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 2.32s
                      Time elapsed: 00:09:25
                               ETA: 00:45:51

################################################################################
                     [1m Learning iteration 256/1500 [0m                      

                       Computation: 42387 steps/s (collection: 2.205s, learning 0.114s)
             Mean action noise std: 1.64
          Mean value_function loss: 89.6227
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 49.5712
                       Mean reward: 160.90
               Mean episode length: 220.51
    Episode_Reward/reaching_object: 0.9445
    Episode_Reward/rotating_object: 33.1358
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 2.32s
                      Time elapsed: 00:09:28
                               ETA: 00:45:49

################################################################################
                     [1m Learning iteration 257/1500 [0m                      

                       Computation: 42990 steps/s (collection: 2.172s, learning 0.115s)
             Mean action noise std: 1.64
          Mean value_function loss: 89.5659
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 49.5879
                       Mean reward: 137.68
               Mean episode length: 211.58
    Episode_Reward/reaching_object: 0.9182
    Episode_Reward/rotating_object: 30.0403
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 2.29s
                      Time elapsed: 00:09:30
                               ETA: 00:45:47

################################################################################
                     [1m Learning iteration 258/1500 [0m                      

                       Computation: 42856 steps/s (collection: 2.178s, learning 0.116s)
             Mean action noise std: 1.64
          Mean value_function loss: 86.1156
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 49.6028
                       Mean reward: 152.96
               Mean episode length: 207.59
    Episode_Reward/reaching_object: 0.9327
    Episode_Reward/rotating_object: 31.9372
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 2.29s
                      Time elapsed: 00:09:32
                               ETA: 00:45:46

################################################################################
                     [1m Learning iteration 259/1500 [0m                      

                       Computation: 42670 steps/s (collection: 2.191s, learning 0.113s)
             Mean action noise std: 1.64
          Mean value_function loss: 86.0600
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 49.6259
                       Mean reward: 156.85
               Mean episode length: 211.63
    Episode_Reward/reaching_object: 0.9452
    Episode_Reward/rotating_object: 32.2539
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 2.30s
                      Time elapsed: 00:09:34
                               ETA: 00:45:44

################################################################################
                     [1m Learning iteration 260/1500 [0m                      

                       Computation: 42322 steps/s (collection: 2.208s, learning 0.114s)
             Mean action noise std: 1.64
          Mean value_function loss: 85.1600
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 49.6515
                       Mean reward: 148.00
               Mean episode length: 205.64
    Episode_Reward/reaching_object: 0.9360
    Episode_Reward/rotating_object: 33.1077
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 2.32s
                      Time elapsed: 00:09:37
                               ETA: 00:45:42

################################################################################
                     [1m Learning iteration 261/1500 [0m                      

                       Computation: 41756 steps/s (collection: 2.243s, learning 0.111s)
             Mean action noise std: 1.64
          Mean value_function loss: 94.1149
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 49.6843
                       Mean reward: 204.81
               Mean episode length: 215.30
    Episode_Reward/reaching_object: 0.9715
    Episode_Reward/rotating_object: 36.3899
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 2.35s
                      Time elapsed: 00:09:39
                               ETA: 00:45:41

################################################################################
                     [1m Learning iteration 262/1500 [0m                      

                       Computation: 42726 steps/s (collection: 2.188s, learning 0.113s)
             Mean action noise std: 1.65
          Mean value_function loss: 92.5005
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 49.7099
                       Mean reward: 165.02
               Mean episode length: 214.80
    Episode_Reward/reaching_object: 0.9444
    Episode_Reward/rotating_object: 32.4541
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 2.30s
                      Time elapsed: 00:09:41
                               ETA: 00:45:39

################################################################################
                     [1m Learning iteration 263/1500 [0m                      

                       Computation: 42474 steps/s (collection: 2.203s, learning 0.112s)
             Mean action noise std: 1.65
          Mean value_function loss: 89.7350
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 49.7249
                       Mean reward: 174.90
               Mean episode length: 211.64
    Episode_Reward/reaching_object: 0.9573
    Episode_Reward/rotating_object: 34.2142
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 2.31s
                      Time elapsed: 00:09:44
                               ETA: 00:45:37

################################################################################
                     [1m Learning iteration 264/1500 [0m                      

                       Computation: 42515 steps/s (collection: 2.202s, learning 0.111s)
             Mean action noise std: 1.65
          Mean value_function loss: 89.5599
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 49.7334
                       Mean reward: 151.87
               Mean episode length: 208.62
    Episode_Reward/reaching_object: 0.9347
    Episode_Reward/rotating_object: 32.7261
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 2.31s
                      Time elapsed: 00:09:46
                               ETA: 00:45:35

################################################################################
                     [1m Learning iteration 265/1500 [0m                      

                       Computation: 42416 steps/s (collection: 2.205s, learning 0.112s)
             Mean action noise std: 1.65
          Mean value_function loss: 81.5110
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 49.7552
                       Mean reward: 139.09
               Mean episode length: 214.11
    Episode_Reward/reaching_object: 0.9872
    Episode_Reward/rotating_object: 36.5173
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 2.32s
                      Time elapsed: 00:09:48
                               ETA: 00:45:34

################################################################################
                     [1m Learning iteration 266/1500 [0m                      

                       Computation: 42293 steps/s (collection: 2.214s, learning 0.110s)
             Mean action noise std: 1.65
          Mean value_function loss: 87.0275
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 49.7788
                       Mean reward: 190.11
               Mean episode length: 216.44
    Episode_Reward/reaching_object: 0.9823
    Episode_Reward/rotating_object: 36.6515
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 2.32s
                      Time elapsed: 00:09:51
                               ETA: 00:45:32

################################################################################
                     [1m Learning iteration 267/1500 [0m                      

                       Computation: 41944 steps/s (collection: 2.229s, learning 0.114s)
             Mean action noise std: 1.65
          Mean value_function loss: 93.9816
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 49.8045
                       Mean reward: 195.68
               Mean episode length: 210.42
    Episode_Reward/reaching_object: 0.9651
    Episode_Reward/rotating_object: 36.0387
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 2.34s
                      Time elapsed: 00:09:53
                               ETA: 00:45:30

################################################################################
                     [1m Learning iteration 268/1500 [0m                      

                       Computation: 42718 steps/s (collection: 2.191s, learning 0.111s)
             Mean action noise std: 1.65
          Mean value_function loss: 108.3958
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 49.8234
                       Mean reward: 220.01
               Mean episode length: 228.71
    Episode_Reward/reaching_object: 0.9657
    Episode_Reward/rotating_object: 33.7881
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 2.30s
                      Time elapsed: 00:09:55
                               ETA: 00:45:28

################################################################################
                     [1m Learning iteration 269/1500 [0m                      

                       Computation: 43214 steps/s (collection: 2.165s, learning 0.110s)
             Mean action noise std: 1.65
          Mean value_function loss: 115.5113
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 49.8415
                       Mean reward: 201.36
               Mean episode length: 223.94
    Episode_Reward/reaching_object: 0.9684
    Episode_Reward/rotating_object: 36.8756
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 2.27s
                      Time elapsed: 00:09:58
                               ETA: 00:45:26

################################################################################
                     [1m Learning iteration 270/1500 [0m                      

                       Computation: 42561 steps/s (collection: 2.199s, learning 0.111s)
             Mean action noise std: 1.66
          Mean value_function loss: 115.7742
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 49.8641
                       Mean reward: 203.44
               Mean episode length: 223.76
    Episode_Reward/reaching_object: 1.0171
    Episode_Reward/rotating_object: 39.4321
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 2.31s
                      Time elapsed: 00:10:00
                               ETA: 00:45:25

################################################################################
                     [1m Learning iteration 271/1500 [0m                      

                       Computation: 42841 steps/s (collection: 2.184s, learning 0.111s)
             Mean action noise std: 1.66
          Mean value_function loss: 104.7345
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 49.8810
                       Mean reward: 192.38
               Mean episode length: 230.72
    Episode_Reward/reaching_object: 0.9801
    Episode_Reward/rotating_object: 36.8797
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 2.29s
                      Time elapsed: 00:10:02
                               ETA: 00:45:23

################################################################################
                     [1m Learning iteration 272/1500 [0m                      

                       Computation: 42679 steps/s (collection: 2.193s, learning 0.111s)
             Mean action noise std: 1.66
          Mean value_function loss: 102.4781
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 49.8964
                       Mean reward: 170.45
               Mean episode length: 208.06
    Episode_Reward/reaching_object: 1.0082
    Episode_Reward/rotating_object: 38.5110
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 2.30s
                      Time elapsed: 00:10:05
                               ETA: 00:45:21

################################################################################
                     [1m Learning iteration 273/1500 [0m                      

                       Computation: 42923 steps/s (collection: 2.180s, learning 0.110s)
             Mean action noise std: 1.66
          Mean value_function loss: 99.5693
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 49.9159
                       Mean reward: 173.39
               Mean episode length: 212.17
    Episode_Reward/reaching_object: 1.0165
    Episode_Reward/rotating_object: 38.4337
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 2.29s
                      Time elapsed: 00:10:07
                               ETA: 00:45:19

################################################################################
                     [1m Learning iteration 274/1500 [0m                      

                       Computation: 42975 steps/s (collection: 2.174s, learning 0.113s)
             Mean action noise std: 1.66
          Mean value_function loss: 87.5655
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 49.9374
                       Mean reward: 194.59
               Mean episode length: 207.73
    Episode_Reward/reaching_object: 0.9814
    Episode_Reward/rotating_object: 34.3819
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 2.29s
                      Time elapsed: 00:10:09
                               ETA: 00:45:17

################################################################################
                     [1m Learning iteration 275/1500 [0m                      

                       Computation: 41859 steps/s (collection: 2.235s, learning 0.113s)
             Mean action noise std: 1.66
          Mean value_function loss: 93.3481
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 49.9567
                       Mean reward: 187.73
               Mean episode length: 210.34
    Episode_Reward/reaching_object: 0.9735
    Episode_Reward/rotating_object: 35.8737
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 11.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 2.35s
                      Time elapsed: 00:10:11
                               ETA: 00:45:16

################################################################################
                     [1m Learning iteration 276/1500 [0m                      

                       Computation: 41904 steps/s (collection: 2.234s, learning 0.112s)
             Mean action noise std: 1.66
          Mean value_function loss: 95.5647
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 49.9787
                       Mean reward: 209.46
               Mean episode length: 222.39
    Episode_Reward/reaching_object: 1.0374
    Episode_Reward/rotating_object: 40.7335
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 2.35s
                      Time elapsed: 00:10:14
                               ETA: 00:45:14

################################################################################
                     [1m Learning iteration 277/1500 [0m                      

                       Computation: 41918 steps/s (collection: 2.232s, learning 0.113s)
             Mean action noise std: 1.67
          Mean value_function loss: 94.7984
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 49.9961
                       Mean reward: 170.13
               Mean episode length: 213.52
    Episode_Reward/reaching_object: 1.0267
    Episode_Reward/rotating_object: 38.4731
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 2.35s
                      Time elapsed: 00:10:16
                               ETA: 00:45:12

################################################################################
                     [1m Learning iteration 278/1500 [0m                      

                       Computation: 41388 steps/s (collection: 2.262s, learning 0.113s)
             Mean action noise std: 1.67
          Mean value_function loss: 102.4828
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 50.0086
                       Mean reward: 202.06
               Mean episode length: 221.41
    Episode_Reward/reaching_object: 1.0324
    Episode_Reward/rotating_object: 39.2270
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 2.38s
                      Time elapsed: 00:10:19
                               ETA: 00:45:11

################################################################################
                     [1m Learning iteration 279/1500 [0m                      

                       Computation: 42224 steps/s (collection: 2.215s, learning 0.113s)
             Mean action noise std: 1.67
          Mean value_function loss: 97.9385
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.0208
                       Mean reward: 199.39
               Mean episode length: 223.85
    Episode_Reward/reaching_object: 1.0124
    Episode_Reward/rotating_object: 37.6630
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 2.33s
                      Time elapsed: 00:10:21
                               ETA: 00:45:09

################################################################################
                     [1m Learning iteration 280/1500 [0m                      

                       Computation: 41721 steps/s (collection: 2.239s, learning 0.117s)
             Mean action noise std: 1.67
          Mean value_function loss: 105.9120
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 50.0315
                       Mean reward: 222.48
               Mean episode length: 215.50
    Episode_Reward/reaching_object: 1.0247
    Episode_Reward/rotating_object: 41.6013
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 2.36s
                      Time elapsed: 00:10:23
                               ETA: 00:45:07

################################################################################
                     [1m Learning iteration 281/1500 [0m                      

                       Computation: 41643 steps/s (collection: 2.247s, learning 0.113s)
             Mean action noise std: 1.67
          Mean value_function loss: 99.4150
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 50.0460
                       Mean reward: 214.16
               Mean episode length: 223.14
    Episode_Reward/reaching_object: 1.0417
    Episode_Reward/rotating_object: 43.5658
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 2.36s
                      Time elapsed: 00:10:26
                               ETA: 00:45:06

################################################################################
                     [1m Learning iteration 282/1500 [0m                      

                       Computation: 41699 steps/s (collection: 2.244s, learning 0.114s)
             Mean action noise std: 1.67
          Mean value_function loss: 97.9604
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 50.0670
                       Mean reward: 209.57
               Mean episode length: 213.43
    Episode_Reward/reaching_object: 1.0439
    Episode_Reward/rotating_object: 40.6195
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 2.36s
                      Time elapsed: 00:10:28
                               ETA: 00:45:04

################################################################################
                     [1m Learning iteration 283/1500 [0m                      

                       Computation: 41822 steps/s (collection: 2.239s, learning 0.111s)
             Mean action noise std: 1.67
          Mean value_function loss: 103.2848
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 50.0891
                       Mean reward: 254.23
               Mean episode length: 222.88
    Episode_Reward/reaching_object: 1.0322
    Episode_Reward/rotating_object: 44.0344
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 2.35s
                      Time elapsed: 00:10:30
                               ETA: 00:45:02

################################################################################
                     [1m Learning iteration 284/1500 [0m                      

                       Computation: 41482 steps/s (collection: 2.256s, learning 0.113s)
             Mean action noise std: 1.67
          Mean value_function loss: 107.4051
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 50.1023
                       Mean reward: 264.87
               Mean episode length: 219.95
    Episode_Reward/reaching_object: 1.0882
    Episode_Reward/rotating_object: 46.4449
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 2.37s
                      Time elapsed: 00:10:33
                               ETA: 00:45:01

################################################################################
                     [1m Learning iteration 285/1500 [0m                      

                       Computation: 41538 steps/s (collection: 2.255s, learning 0.111s)
             Mean action noise std: 1.67
          Mean value_function loss: 110.3602
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 50.1089
                       Mean reward: 171.67
               Mean episode length: 201.12
    Episode_Reward/reaching_object: 1.0050
    Episode_Reward/rotating_object: 40.2481
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 2.37s
                      Time elapsed: 00:10:35
                               ETA: 00:44:59

################################################################################
                     [1m Learning iteration 286/1500 [0m                      

                       Computation: 41797 steps/s (collection: 2.241s, learning 0.111s)
             Mean action noise std: 1.67
          Mean value_function loss: 99.5872
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 50.1221
                       Mean reward: 253.53
               Mean episode length: 225.45
    Episode_Reward/reaching_object: 1.0553
    Episode_Reward/rotating_object: 44.7053
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 2.35s
                      Time elapsed: 00:10:37
                               ETA: 00:44:58

################################################################################
                     [1m Learning iteration 287/1500 [0m                      

                       Computation: 41748 steps/s (collection: 2.243s, learning 0.111s)
             Mean action noise std: 1.68
          Mean value_function loss: 94.9975
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 50.1334
                       Mean reward: 251.29
               Mean episode length: 226.11
    Episode_Reward/reaching_object: 1.0769
    Episode_Reward/rotating_object: 47.0656
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 2.35s
                      Time elapsed: 00:10:40
                               ETA: 00:44:56

################################################################################
                     [1m Learning iteration 288/1500 [0m                      

                       Computation: 40683 steps/s (collection: 2.276s, learning 0.141s)
             Mean action noise std: 1.68
          Mean value_function loss: 91.7289
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 50.1515
                       Mean reward: 219.65
               Mean episode length: 221.10
    Episode_Reward/reaching_object: 1.0537
    Episode_Reward/rotating_object: 44.4022
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 2.42s
                      Time elapsed: 00:10:42
                               ETA: 00:44:55

################################################################################
                     [1m Learning iteration 289/1500 [0m                      

                       Computation: 41647 steps/s (collection: 2.248s, learning 0.113s)
             Mean action noise std: 1.68
          Mean value_function loss: 93.8662
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 50.1617
                       Mean reward: 231.12
               Mean episode length: 222.06
    Episode_Reward/reaching_object: 1.0794
    Episode_Reward/rotating_object: 47.8280
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 2.36s
                      Time elapsed: 00:10:44
                               ETA: 00:44:53

################################################################################
                     [1m Learning iteration 290/1500 [0m                      

                       Computation: 42034 steps/s (collection: 2.226s, learning 0.112s)
             Mean action noise std: 1.68
          Mean value_function loss: 88.9052
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 50.1680
                       Mean reward: 248.39
               Mean episode length: 228.00
    Episode_Reward/reaching_object: 1.0876
    Episode_Reward/rotating_object: 46.7938
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 2.34s
                      Time elapsed: 00:10:47
                               ETA: 00:44:51

################################################################################
                     [1m Learning iteration 291/1500 [0m                      

                       Computation: 42637 steps/s (collection: 2.194s, learning 0.112s)
             Mean action noise std: 1.68
          Mean value_function loss: 89.0439
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 50.1752
                       Mean reward: 228.52
               Mean episode length: 228.45
    Episode_Reward/reaching_object: 1.0616
    Episode_Reward/rotating_object: 47.7148
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 2.31s
                      Time elapsed: 00:10:49
                               ETA: 00:44:49

################################################################################
                     [1m Learning iteration 292/1500 [0m                      

                       Computation: 42408 steps/s (collection: 2.206s, learning 0.112s)
             Mean action noise std: 1.68
          Mean value_function loss: 91.7387
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 50.1783
                       Mean reward: 239.12
               Mean episode length: 223.57
    Episode_Reward/reaching_object: 1.0594
    Episode_Reward/rotating_object: 45.1157
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 2.32s
                      Time elapsed: 00:10:51
                               ETA: 00:44:47

################################################################################
                     [1m Learning iteration 293/1500 [0m                      

                       Computation: 42674 steps/s (collection: 2.191s, learning 0.112s)
             Mean action noise std: 1.68
          Mean value_function loss: 92.6854
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 50.1858
                       Mean reward: 251.02
               Mean episode length: 219.86
    Episode_Reward/reaching_object: 1.0802
    Episode_Reward/rotating_object: 46.3557
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 2.30s
                      Time elapsed: 00:10:54
                               ETA: 00:44:46

################################################################################
                     [1m Learning iteration 294/1500 [0m                      

                       Computation: 42412 steps/s (collection: 2.206s, learning 0.112s)
             Mean action noise std: 1.68
          Mean value_function loss: 99.7852
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 50.1965
                       Mean reward: 250.17
               Mean episode length: 228.16
    Episode_Reward/reaching_object: 1.0863
    Episode_Reward/rotating_object: 48.6296
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 2.32s
                      Time elapsed: 00:10:56
                               ETA: 00:44:44

################################################################################
                     [1m Learning iteration 295/1500 [0m                      

                       Computation: 41789 steps/s (collection: 2.231s, learning 0.122s)
             Mean action noise std: 1.68
          Mean value_function loss: 99.2906
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 50.2107
                       Mean reward: 248.12
               Mean episode length: 227.28
    Episode_Reward/reaching_object: 1.0806
    Episode_Reward/rotating_object: 46.0782
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 2.35s
                      Time elapsed: 00:10:58
                               ETA: 00:44:42

################################################################################
                     [1m Learning iteration 296/1500 [0m                      

                       Computation: 41468 steps/s (collection: 2.260s, learning 0.111s)
             Mean action noise std: 1.68
          Mean value_function loss: 103.7354
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 50.2201
                       Mean reward: 249.99
               Mean episode length: 215.62
    Episode_Reward/reaching_object: 1.0787
    Episode_Reward/rotating_object: 48.1328
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 2.37s
                      Time elapsed: 00:11:01
                               ETA: 00:44:40

################################################################################
                     [1m Learning iteration 297/1500 [0m                      

                       Computation: 41707 steps/s (collection: 2.246s, learning 0.111s)
             Mean action noise std: 1.68
          Mean value_function loss: 102.4930
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 50.2282
                       Mean reward: 225.22
               Mean episode length: 218.08
    Episode_Reward/reaching_object: 1.0828
    Episode_Reward/rotating_object: 49.2325
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 2.36s
                      Time elapsed: 00:11:03
                               ETA: 00:44:39

################################################################################
                     [1m Learning iteration 298/1500 [0m                      

                       Computation: 41240 steps/s (collection: 2.264s, learning 0.120s)
             Mean action noise std: 1.68
          Mean value_function loss: 99.1681
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 50.2345
                       Mean reward: 278.95
               Mean episode length: 214.47
    Episode_Reward/reaching_object: 1.1063
    Episode_Reward/rotating_object: 50.4856
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 2.38s
                      Time elapsed: 00:11:06
                               ETA: 00:44:37

################################################################################
                     [1m Learning iteration 299/1500 [0m                      

                       Computation: 41862 steps/s (collection: 2.237s, learning 0.112s)
             Mean action noise std: 1.68
          Mean value_function loss: 101.4031
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 50.2442
                       Mean reward: 219.83
               Mean episode length: 218.63
    Episode_Reward/reaching_object: 1.0758
    Episode_Reward/rotating_object: 46.7250
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 2.35s
                      Time elapsed: 00:11:08
                               ETA: 00:44:35

################################################################################
                     [1m Learning iteration 300/1500 [0m                      

                       Computation: 41304 steps/s (collection: 2.267s, learning 0.113s)
             Mean action noise std: 1.68
          Mean value_function loss: 97.0364
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 50.2549
                       Mean reward: 296.22
               Mean episode length: 228.96
    Episode_Reward/reaching_object: 1.1324
    Episode_Reward/rotating_object: 55.5249
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 2.38s
                      Time elapsed: 00:11:10
                               ETA: 00:44:34

################################################################################
                     [1m Learning iteration 301/1500 [0m                      

                       Computation: 41777 steps/s (collection: 2.240s, learning 0.113s)
             Mean action noise std: 1.69
          Mean value_function loss: 92.0943
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 50.2732
                       Mean reward: 251.14
               Mean episode length: 214.49
    Episode_Reward/reaching_object: 1.1098
    Episode_Reward/rotating_object: 53.5848
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 2.35s
                      Time elapsed: 00:11:13
                               ETA: 00:44:32

################################################################################
                     [1m Learning iteration 302/1500 [0m                      

                       Computation: 41962 steps/s (collection: 2.228s, learning 0.114s)
             Mean action noise std: 1.69
          Mean value_function loss: 90.3454
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 50.2942
                       Mean reward: 293.33
               Mean episode length: 217.11
    Episode_Reward/reaching_object: 1.1290
    Episode_Reward/rotating_object: 56.2262
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 2.34s
                      Time elapsed: 00:11:15
                               ETA: 00:44:30

################################################################################
                     [1m Learning iteration 303/1500 [0m                      

                       Computation: 41776 steps/s (collection: 2.241s, learning 0.112s)
             Mean action noise std: 1.69
          Mean value_function loss: 84.7322
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 50.3115
                       Mean reward: 298.91
               Mean episode length: 222.30
    Episode_Reward/reaching_object: 1.1378
    Episode_Reward/rotating_object: 57.1252
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 2.35s
                      Time elapsed: 00:11:17
                               ETA: 00:44:28

################################################################################
                     [1m Learning iteration 304/1500 [0m                      

                       Computation: 42372 steps/s (collection: 2.209s, learning 0.111s)
             Mean action noise std: 1.69
          Mean value_function loss: 79.2270
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 50.3312
                       Mean reward: 303.83
               Mean episode length: 221.36
    Episode_Reward/reaching_object: 1.1429
    Episode_Reward/rotating_object: 57.6758
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 2.32s
                      Time elapsed: 00:11:20
                               ETA: 00:44:27

################################################################################
                     [1m Learning iteration 305/1500 [0m                      

                       Computation: 42241 steps/s (collection: 2.213s, learning 0.114s)
             Mean action noise std: 1.69
          Mean value_function loss: 91.5619
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 50.3489
                       Mean reward: 263.25
               Mean episode length: 212.68
    Episode_Reward/reaching_object: 1.1261
    Episode_Reward/rotating_object: 56.4839
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 2.33s
                      Time elapsed: 00:11:22
                               ETA: 00:44:25

################################################################################
                     [1m Learning iteration 306/1500 [0m                      

                       Computation: 42140 steps/s (collection: 2.217s, learning 0.116s)
             Mean action noise std: 1.69
          Mean value_function loss: 88.1645
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 50.3650
                       Mean reward: 267.28
               Mean episode length: 221.63
    Episode_Reward/reaching_object: 1.1176
    Episode_Reward/rotating_object: 53.6010
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 2.33s
                      Time elapsed: 00:11:24
                               ETA: 00:44:23

################################################################################
                     [1m Learning iteration 307/1500 [0m                      

                       Computation: 40797 steps/s (collection: 2.299s, learning 0.111s)
             Mean action noise std: 1.69
          Mean value_function loss: 93.4962
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 50.3820
                       Mean reward: 292.36
               Mean episode length: 228.36
    Episode_Reward/reaching_object: 1.1303
    Episode_Reward/rotating_object: 57.3910
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 2.41s
                      Time elapsed: 00:11:27
                               ETA: 00:44:21

################################################################################
                     [1m Learning iteration 308/1500 [0m                      

                       Computation: 40913 steps/s (collection: 2.287s, learning 0.116s)
             Mean action noise std: 1.69
          Mean value_function loss: 102.3614
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 50.3955
                       Mean reward: 292.42
               Mean episode length: 225.17
    Episode_Reward/reaching_object: 1.1308
    Episode_Reward/rotating_object: 56.1337
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 2.40s
                      Time elapsed: 00:11:29
                               ETA: 00:44:20

################################################################################
                     [1m Learning iteration 309/1500 [0m                      

                       Computation: 41952 steps/s (collection: 2.233s, learning 0.110s)
             Mean action noise std: 1.69
          Mean value_function loss: 107.2440
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 50.4036
                       Mean reward: 286.85
               Mean episode length: 230.71
    Episode_Reward/reaching_object: 1.1510
    Episode_Reward/rotating_object: 55.5513
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 2.34s
                      Time elapsed: 00:11:31
                               ETA: 00:44:18

################################################################################
                     [1m Learning iteration 310/1500 [0m                      

                       Computation: 42671 steps/s (collection: 2.193s, learning 0.110s)
             Mean action noise std: 1.69
          Mean value_function loss: 95.4309
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 50.4090
                       Mean reward: 330.34
               Mean episode length: 232.33
    Episode_Reward/reaching_object: 1.1623
    Episode_Reward/rotating_object: 56.4660
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 2.30s
                      Time elapsed: 00:11:34
                               ETA: 00:44:16

################################################################################
                     [1m Learning iteration 311/1500 [0m                      

                       Computation: 43255 steps/s (collection: 2.162s, learning 0.110s)
             Mean action noise std: 1.69
          Mean value_function loss: 99.6543
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 50.4155
                       Mean reward: 348.85
               Mean episode length: 232.42
    Episode_Reward/reaching_object: 1.1712
    Episode_Reward/rotating_object: 60.8344
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 2.27s
                      Time elapsed: 00:11:36
                               ETA: 00:44:14

################################################################################
                     [1m Learning iteration 312/1500 [0m                      

                       Computation: 43158 steps/s (collection: 2.167s, learning 0.110s)
             Mean action noise std: 1.70
          Mean value_function loss: 105.1136
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 50.4226
                       Mean reward: 319.59
               Mean episode length: 231.93
    Episode_Reward/reaching_object: 1.1676
    Episode_Reward/rotating_object: 59.1722
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 2.28s
                      Time elapsed: 00:11:38
                               ETA: 00:44:12

################################################################################
                     [1m Learning iteration 313/1500 [0m                      

                       Computation: 43164 steps/s (collection: 2.167s, learning 0.110s)
             Mean action noise std: 1.70
          Mean value_function loss: 105.3996
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.4284
                       Mean reward: 291.32
               Mean episode length: 222.50
    Episode_Reward/reaching_object: 1.1457
    Episode_Reward/rotating_object: 58.3311
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 2.28s
                      Time elapsed: 00:11:41
                               ETA: 00:44:10

################################################################################
                     [1m Learning iteration 314/1500 [0m                      

                       Computation: 43268 steps/s (collection: 2.162s, learning 0.110s)
             Mean action noise std: 1.70
          Mean value_function loss: 105.4988
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 50.4350
                       Mean reward: 335.14
               Mean episode length: 227.66
    Episode_Reward/reaching_object: 1.1729
    Episode_Reward/rotating_object: 59.9986
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 2.27s
                      Time elapsed: 00:11:43
                               ETA: 00:44:08

################################################################################
                     [1m Learning iteration 315/1500 [0m                      

                       Computation: 42175 steps/s (collection: 2.220s, learning 0.110s)
             Mean action noise std: 1.70
          Mean value_function loss: 109.3882
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 50.4468
                       Mean reward: 315.31
               Mean episode length: 218.53
    Episode_Reward/reaching_object: 1.1468
    Episode_Reward/rotating_object: 58.6716
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 2.33s
                      Time elapsed: 00:11:45
                               ETA: 00:44:06

################################################################################
                     [1m Learning iteration 316/1500 [0m                      

                       Computation: 41408 steps/s (collection: 2.263s, learning 0.111s)
             Mean action noise std: 1.70
          Mean value_function loss: 102.0540
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 50.4577
                       Mean reward: 290.26
               Mean episode length: 226.46
    Episode_Reward/reaching_object: 1.1584
    Episode_Reward/rotating_object: 60.7500
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 2.37s
                      Time elapsed: 00:11:48
                               ETA: 00:44:04

################################################################################
                     [1m Learning iteration 317/1500 [0m                      

                       Computation: 40692 steps/s (collection: 2.291s, learning 0.125s)
             Mean action noise std: 1.70
          Mean value_function loss: 112.2809
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 50.4654
                       Mean reward: 291.50
               Mean episode length: 225.52
    Episode_Reward/reaching_object: 1.1592
    Episode_Reward/rotating_object: 58.7932
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 2.42s
                      Time elapsed: 00:11:50
                               ETA: 00:44:03

################################################################################
                     [1m Learning iteration 318/1500 [0m                      

                       Computation: 40305 steps/s (collection: 2.325s, learning 0.114s)
             Mean action noise std: 1.70
          Mean value_function loss: 105.1700
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 50.4781
                       Mean reward: 300.54
               Mean episode length: 224.39
    Episode_Reward/reaching_object: 1.1681
    Episode_Reward/rotating_object: 61.5670
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 2.44s
                      Time elapsed: 00:11:52
                               ETA: 00:44:01

################################################################################
                     [1m Learning iteration 319/1500 [0m                      

                       Computation: 41192 steps/s (collection: 2.271s, learning 0.116s)
             Mean action noise std: 1.70
          Mean value_function loss: 109.8717
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 50.4839
                       Mean reward: 321.13
               Mean episode length: 224.65
    Episode_Reward/reaching_object: 1.1837
    Episode_Reward/rotating_object: 63.8873
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 2.39s
                      Time elapsed: 00:11:55
                               ETA: 00:43:59

################################################################################
                     [1m Learning iteration 320/1500 [0m                      

                       Computation: 41638 steps/s (collection: 2.246s, learning 0.115s)
             Mean action noise std: 1.70
          Mean value_function loss: 110.3022
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 50.4895
                       Mean reward: 359.32
               Mean episode length: 230.92
    Episode_Reward/reaching_object: 1.1815
    Episode_Reward/rotating_object: 64.0836
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 2.36s
                      Time elapsed: 00:11:57
                               ETA: 00:43:58

################################################################################
                     [1m Learning iteration 321/1500 [0m                      

                       Computation: 42246 steps/s (collection: 2.214s, learning 0.113s)
             Mean action noise std: 1.70
          Mean value_function loss: 105.6878
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 50.4960
                       Mean reward: 321.65
               Mean episode length: 219.08
    Episode_Reward/reaching_object: 1.1632
    Episode_Reward/rotating_object: 64.2582
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 2.33s
                      Time elapsed: 00:11:59
                               ETA: 00:43:56

################################################################################
                     [1m Learning iteration 322/1500 [0m                      

                       Computation: 41511 steps/s (collection: 2.242s, learning 0.126s)
             Mean action noise std: 1.70
          Mean value_function loss: 111.9889
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 50.5025
                       Mean reward: 302.29
               Mean episode length: 217.83
    Episode_Reward/reaching_object: 1.1717
    Episode_Reward/rotating_object: 62.7556
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 2.37s
                      Time elapsed: 00:12:02
                               ETA: 00:43:54

################################################################################
                     [1m Learning iteration 323/1500 [0m                      

                       Computation: 40947 steps/s (collection: 2.288s, learning 0.113s)
             Mean action noise std: 1.70
          Mean value_function loss: 115.1858
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 50.5111
                       Mean reward: 344.82
               Mean episode length: 229.30
    Episode_Reward/reaching_object: 1.1954
    Episode_Reward/rotating_object: 67.7183
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 2.40s
                      Time elapsed: 00:12:04
                               ETA: 00:43:52

################################################################################
                     [1m Learning iteration 324/1500 [0m                      

                       Computation: 42265 steps/s (collection: 2.215s, learning 0.111s)
             Mean action noise std: 1.70
          Mean value_function loss: 117.5890
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 50.5196
                       Mean reward: 326.45
               Mean episode length: 232.77
    Episode_Reward/reaching_object: 1.1646
    Episode_Reward/rotating_object: 64.1708
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 2.33s
                      Time elapsed: 00:12:07
                               ETA: 00:43:50

################################################################################
                     [1m Learning iteration 325/1500 [0m                      

                       Computation: 42321 steps/s (collection: 2.211s, learning 0.112s)
             Mean action noise std: 1.70
          Mean value_function loss: 118.0470
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 50.5271
                       Mean reward: 356.69
               Mean episode length: 238.16
    Episode_Reward/reaching_object: 1.1949
    Episode_Reward/rotating_object: 63.3040
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 2.32s
                      Time elapsed: 00:12:09
                               ETA: 00:43:48

################################################################################
                     [1m Learning iteration 326/1500 [0m                      

                       Computation: 42363 steps/s (collection: 2.210s, learning 0.111s)
             Mean action noise std: 1.70
          Mean value_function loss: 114.3406
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 50.5318
                       Mean reward: 336.20
               Mean episode length: 232.68
    Episode_Reward/reaching_object: 1.1980
    Episode_Reward/rotating_object: 64.5091
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 2.32s
                      Time elapsed: 00:12:11
                               ETA: 00:43:47

################################################################################
                     [1m Learning iteration 327/1500 [0m                      

                       Computation: 42295 steps/s (collection: 2.211s, learning 0.113s)
             Mean action noise std: 1.70
          Mean value_function loss: 111.8925
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 50.5379
                       Mean reward: 366.42
               Mean episode length: 225.08
    Episode_Reward/reaching_object: 1.2120
    Episode_Reward/rotating_object: 68.6764
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 2.32s
                      Time elapsed: 00:12:14
                               ETA: 00:43:45

################################################################################
                     [1m Learning iteration 328/1500 [0m                      

                       Computation: 42292 steps/s (collection: 2.209s, learning 0.116s)
             Mean action noise std: 1.70
          Mean value_function loss: 108.2002
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 50.5412
                       Mean reward: 325.91
               Mean episode length: 233.70
    Episode_Reward/reaching_object: 1.2333
    Episode_Reward/rotating_object: 71.2861
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 2.32s
                      Time elapsed: 00:12:16
                               ETA: 00:43:43

################################################################################
                     [1m Learning iteration 329/1500 [0m                      

                       Computation: 42034 steps/s (collection: 2.228s, learning 0.111s)
             Mean action noise std: 1.70
          Mean value_function loss: 111.8667
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 50.5473
                       Mean reward: 394.57
               Mean episode length: 238.28
    Episode_Reward/reaching_object: 1.2082
    Episode_Reward/rotating_object: 67.9315
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 2.34s
                      Time elapsed: 00:12:18
                               ETA: 00:43:41

################################################################################
                     [1m Learning iteration 330/1500 [0m                      

                       Computation: 42514 steps/s (collection: 2.202s, learning 0.110s)
             Mean action noise std: 1.71
          Mean value_function loss: 114.0443
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.5564
                       Mean reward: 330.97
               Mean episode length: 221.26
    Episode_Reward/reaching_object: 1.2018
    Episode_Reward/rotating_object: 69.2350
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 2.31s
                      Time elapsed: 00:12:21
                               ETA: 00:43:39

################################################################################
                     [1m Learning iteration 331/1500 [0m                      

                       Computation: 42933 steps/s (collection: 2.175s, learning 0.115s)
             Mean action noise std: 1.71
          Mean value_function loss: 109.2607
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 50.5652
                       Mean reward: 319.02
               Mean episode length: 220.73
    Episode_Reward/reaching_object: 1.1907
    Episode_Reward/rotating_object: 68.0583
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 2.29s
                      Time elapsed: 00:12:23
                               ETA: 00:43:37

################################################################################
                     [1m Learning iteration 332/1500 [0m                      

                       Computation: 43366 steps/s (collection: 2.157s, learning 0.110s)
             Mean action noise std: 1.71
          Mean value_function loss: 103.6566
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 50.5789
                       Mean reward: 376.85
               Mean episode length: 233.85
    Episode_Reward/reaching_object: 1.2291
    Episode_Reward/rotating_object: 72.2797
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 2.27s
                      Time elapsed: 00:12:25
                               ETA: 00:43:35

################################################################################
                     [1m Learning iteration 333/1500 [0m                      

                       Computation: 43403 steps/s (collection: 2.154s, learning 0.111s)
             Mean action noise std: 1.71
          Mean value_function loss: 92.8749
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 50.5912
                       Mean reward: 289.46
               Mean episode length: 219.61
    Episode_Reward/reaching_object: 1.1448
    Episode_Reward/rotating_object: 63.9911
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 2.26s
                      Time elapsed: 00:12:27
                               ETA: 00:43:32

################################################################################
                     [1m Learning iteration 334/1500 [0m                      

                       Computation: 43283 steps/s (collection: 2.157s, learning 0.114s)
             Mean action noise std: 1.71
          Mean value_function loss: 95.1991
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 50.6045
                       Mean reward: 339.53
               Mean episode length: 223.89
    Episode_Reward/reaching_object: 1.2029
    Episode_Reward/rotating_object: 72.0711
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 2.27s
                      Time elapsed: 00:12:30
                               ETA: 00:43:30

################################################################################
                     [1m Learning iteration 335/1500 [0m                      

                       Computation: 43678 steps/s (collection: 2.140s, learning 0.110s)
             Mean action noise std: 1.71
          Mean value_function loss: 82.6421
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 50.6138
                       Mean reward: 337.96
               Mean episode length: 220.46
    Episode_Reward/reaching_object: 1.1779
    Episode_Reward/rotating_object: 69.2952
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 2.25s
                      Time elapsed: 00:12:32
                               ETA: 00:43:28

################################################################################
                     [1m Learning iteration 336/1500 [0m                      

                       Computation: 42975 steps/s (collection: 2.177s, learning 0.111s)
             Mean action noise std: 1.71
          Mean value_function loss: 89.9793
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 50.6196
                       Mean reward: 386.09
               Mean episode length: 222.85
    Episode_Reward/reaching_object: 1.1678
    Episode_Reward/rotating_object: 71.7219
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 2.29s
                      Time elapsed: 00:12:34
                               ETA: 00:43:26

################################################################################
                     [1m Learning iteration 337/1500 [0m                      

                       Computation: 40871 steps/s (collection: 2.276s, learning 0.130s)
             Mean action noise std: 1.71
          Mean value_function loss: 98.3283
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 50.6334
                       Mean reward: 382.13
               Mean episode length: 224.70
    Episode_Reward/reaching_object: 1.2202
    Episode_Reward/rotating_object: 76.6042
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 2.41s
                      Time elapsed: 00:12:37
                               ETA: 00:43:24

################################################################################
                     [1m Learning iteration 338/1500 [0m                      

                       Computation: 39658 steps/s (collection: 2.351s, learning 0.128s)
             Mean action noise std: 1.71
          Mean value_function loss: 94.6518
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 50.6477
                       Mean reward: 362.04
               Mean episode length: 228.97
    Episode_Reward/reaching_object: 1.1850
    Episode_Reward/rotating_object: 74.4471
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 2.48s
                      Time elapsed: 00:12:39
                               ETA: 00:43:23

################################################################################
                     [1m Learning iteration 339/1500 [0m                      

                       Computation: 40226 steps/s (collection: 2.332s, learning 0.111s)
             Mean action noise std: 1.71
          Mean value_function loss: 103.6245
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 50.6604
                       Mean reward: 358.13
               Mean episode length: 231.07
    Episode_Reward/reaching_object: 1.2043
    Episode_Reward/rotating_object: 76.2480
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 2.44s
                      Time elapsed: 00:12:41
                               ETA: 00:43:21

################################################################################
                     [1m Learning iteration 340/1500 [0m                      

                       Computation: 42051 steps/s (collection: 2.228s, learning 0.110s)
             Mean action noise std: 1.71
          Mean value_function loss: 114.7938
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.6668
                       Mean reward: 356.80
               Mean episode length: 222.70
    Episode_Reward/reaching_object: 1.1609
    Episode_Reward/rotating_object: 68.6557
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 2.34s
                      Time elapsed: 00:12:44
                               ETA: 00:43:20

################################################################################
                     [1m Learning iteration 341/1500 [0m                      

                       Computation: 41892 steps/s (collection: 2.235s, learning 0.111s)
             Mean action noise std: 1.71
          Mean value_function loss: 111.8618
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 50.6709
                       Mean reward: 420.40
               Mean episode length: 233.94
    Episode_Reward/reaching_object: 1.2204
    Episode_Reward/rotating_object: 76.6503
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 2.35s
                      Time elapsed: 00:12:46
                               ETA: 00:43:18

################################################################################
                     [1m Learning iteration 342/1500 [0m                      

                       Computation: 41924 steps/s (collection: 2.230s, learning 0.114s)
             Mean action noise std: 1.71
          Mean value_function loss: 111.8461
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 50.6762
                       Mean reward: 361.65
               Mean episode length: 232.87
    Episode_Reward/reaching_object: 1.1966
    Episode_Reward/rotating_object: 72.0029
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 2.34s
                      Time elapsed: 00:12:49
                               ETA: 00:43:16

################################################################################
                     [1m Learning iteration 343/1500 [0m                      

                       Computation: 42328 steps/s (collection: 2.207s, learning 0.115s)
             Mean action noise std: 1.72
          Mean value_function loss: 117.9439
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 50.6841
                       Mean reward: 323.14
               Mean episode length: 225.26
    Episode_Reward/reaching_object: 1.1891
    Episode_Reward/rotating_object: 69.9812
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 2.32s
                      Time elapsed: 00:12:51
                               ETA: 00:43:14

################################################################################
                     [1m Learning iteration 344/1500 [0m                      

                       Computation: 42065 steps/s (collection: 2.219s, learning 0.118s)
             Mean action noise std: 1.72
          Mean value_function loss: 122.5617
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 50.6944
                       Mean reward: 384.97
               Mean episode length: 231.49
    Episode_Reward/reaching_object: 1.1983
    Episode_Reward/rotating_object: 72.5310
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 2.34s
                      Time elapsed: 00:12:53
                               ETA: 00:43:12

################################################################################
                     [1m Learning iteration 345/1500 [0m                      

                       Computation: 42314 steps/s (collection: 2.211s, learning 0.112s)
             Mean action noise std: 1.72
          Mean value_function loss: 121.5193
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 50.7088
                       Mean reward: 345.95
               Mean episode length: 225.19
    Episode_Reward/reaching_object: 1.2248
    Episode_Reward/rotating_object: 74.4950
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 2.32s
                      Time elapsed: 00:12:55
                               ETA: 00:43:10

################################################################################
                     [1m Learning iteration 346/1500 [0m                      

                       Computation: 42378 steps/s (collection: 2.205s, learning 0.115s)
             Mean action noise std: 1.72
          Mean value_function loss: 110.3245
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 50.7207
                       Mean reward: 401.06
               Mean episode length: 231.65
    Episode_Reward/reaching_object: 1.2010
    Episode_Reward/rotating_object: 73.1249
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 2.32s
                      Time elapsed: 00:12:58
                               ETA: 00:43:08

################################################################################
                     [1m Learning iteration 347/1500 [0m                      

                       Computation: 42018 steps/s (collection: 2.223s, learning 0.116s)
             Mean action noise std: 1.72
          Mean value_function loss: 106.2911
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 50.7329
                       Mean reward: 395.61
               Mean episode length: 224.24
    Episode_Reward/reaching_object: 1.1760
    Episode_Reward/rotating_object: 73.7972
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 2.34s
                      Time elapsed: 00:13:00
                               ETA: 00:43:06

################################################################################
                     [1m Learning iteration 348/1500 [0m                      

                       Computation: 42094 steps/s (collection: 2.223s, learning 0.113s)
             Mean action noise std: 1.72
          Mean value_function loss: 112.0928
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 50.7396
                       Mean reward: 378.31
               Mean episode length: 224.67
    Episode_Reward/reaching_object: 1.2128
    Episode_Reward/rotating_object: 75.7446
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 2.34s
                      Time elapsed: 00:13:02
                               ETA: 00:43:04

################################################################################
                     [1m Learning iteration 349/1500 [0m                      

                       Computation: 41899 steps/s (collection: 2.228s, learning 0.118s)
             Mean action noise std: 1.72
          Mean value_function loss: 106.5607
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 50.7478
                       Mean reward: 367.78
               Mean episode length: 229.16
    Episode_Reward/reaching_object: 1.2553
    Episode_Reward/rotating_object: 77.7403
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 2.35s
                      Time elapsed: 00:13:05
                               ETA: 00:43:02

################################################################################
                     [1m Learning iteration 350/1500 [0m                      

                       Computation: 42541 steps/s (collection: 2.200s, learning 0.111s)
             Mean action noise std: 1.72
          Mean value_function loss: 100.8723
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 50.7569
                       Mean reward: 378.24
               Mean episode length: 226.57
    Episode_Reward/reaching_object: 1.2301
    Episode_Reward/rotating_object: 81.3926
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 2.31s
                      Time elapsed: 00:13:07
                               ETA: 00:43:00

################################################################################
                     [1m Learning iteration 351/1500 [0m                      

                       Computation: 42481 steps/s (collection: 2.203s, learning 0.111s)
             Mean action noise std: 1.72
          Mean value_function loss: 102.3092
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 50.7605
                       Mean reward: 389.87
               Mean episode length: 225.90
    Episode_Reward/reaching_object: 1.1811
    Episode_Reward/rotating_object: 75.7273
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 2.31s
                      Time elapsed: 00:13:09
                               ETA: 00:42:58

################################################################################
                     [1m Learning iteration 352/1500 [0m                      

                       Computation: 43565 steps/s (collection: 2.146s, learning 0.110s)
             Mean action noise std: 1.72
          Mean value_function loss: 106.7874
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 50.7679
                       Mean reward: 393.30
               Mean episode length: 231.91
    Episode_Reward/reaching_object: 1.2237
    Episode_Reward/rotating_object: 74.8224
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 2.26s
                      Time elapsed: 00:13:12
                               ETA: 00:42:56

################################################################################
                     [1m Learning iteration 353/1500 [0m                      

                       Computation: 43156 steps/s (collection: 2.168s, learning 0.110s)
             Mean action noise std: 1.72
          Mean value_function loss: 105.1342
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 50.7787
                       Mean reward: 386.96
               Mean episode length: 223.35
    Episode_Reward/reaching_object: 1.2154
    Episode_Reward/rotating_object: 76.4028
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 2.28s
                      Time elapsed: 00:13:14
                               ETA: 00:42:54

################################################################################
                     [1m Learning iteration 354/1500 [0m                      

                       Computation: 43120 steps/s (collection: 2.169s, learning 0.111s)
             Mean action noise std: 1.72
          Mean value_function loss: 100.8039
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 50.7842
                       Mean reward: 399.10
               Mean episode length: 224.78
    Episode_Reward/reaching_object: 1.2016
    Episode_Reward/rotating_object: 78.1208
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 2.28s
                      Time elapsed: 00:13:16
                               ETA: 00:42:52

################################################################################
                     [1m Learning iteration 355/1500 [0m                      

                       Computation: 42426 steps/s (collection: 2.207s, learning 0.110s)
             Mean action noise std: 1.72
          Mean value_function loss: 95.4535
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 50.7933
                       Mean reward: 395.49
               Mean episode length: 230.77
    Episode_Reward/reaching_object: 1.2301
    Episode_Reward/rotating_object: 79.5834
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 2.32s
                      Time elapsed: 00:13:19
                               ETA: 00:42:50

################################################################################
                     [1m Learning iteration 356/1500 [0m                      

                       Computation: 43544 steps/s (collection: 2.146s, learning 0.111s)
             Mean action noise std: 1.72
          Mean value_function loss: 95.7503
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 50.8017
                       Mean reward: 420.08
               Mean episode length: 227.27
    Episode_Reward/reaching_object: 1.2201
    Episode_Reward/rotating_object: 78.0035
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 2.26s
                      Time elapsed: 00:13:21
                               ETA: 00:42:47

################################################################################
                     [1m Learning iteration 357/1500 [0m                      

                       Computation: 43426 steps/s (collection: 2.153s, learning 0.110s)
             Mean action noise std: 1.73
          Mean value_function loss: 99.7893
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 50.8160
                       Mean reward: 438.80
               Mean episode length: 239.13
    Episode_Reward/reaching_object: 1.2491
    Episode_Reward/rotating_object: 83.5208
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 2.26s
                      Time elapsed: 00:13:23
                               ETA: 00:42:45

################################################################################
                     [1m Learning iteration 358/1500 [0m                      

                       Computation: 42628 steps/s (collection: 2.192s, learning 0.114s)
             Mean action noise std: 1.73
          Mean value_function loss: 108.7740
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 50.8285
                       Mean reward: 423.71
               Mean episode length: 225.96
    Episode_Reward/reaching_object: 1.1991
    Episode_Reward/rotating_object: 80.1267
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 2.31s
                      Time elapsed: 00:13:25
                               ETA: 00:42:43

################################################################################
                     [1m Learning iteration 359/1500 [0m                      

                       Computation: 42231 steps/s (collection: 2.205s, learning 0.122s)
             Mean action noise std: 1.73
          Mean value_function loss: 109.1655
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 50.8362
                       Mean reward: 374.60
               Mean episode length: 216.45
    Episode_Reward/reaching_object: 1.2118
    Episode_Reward/rotating_object: 81.3281
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 2.33s
                      Time elapsed: 00:13:28
                               ETA: 00:42:41

################################################################################
                     [1m Learning iteration 360/1500 [0m                      

                       Computation: 40406 steps/s (collection: 2.320s, learning 0.113s)
             Mean action noise std: 1.73
          Mean value_function loss: 104.3603
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 50.8455
                       Mean reward: 411.94
               Mean episode length: 226.52
    Episode_Reward/reaching_object: 1.2116
    Episode_Reward/rotating_object: 81.9444
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 2.43s
                      Time elapsed: 00:13:30
                               ETA: 00:42:40

################################################################################
                     [1m Learning iteration 361/1500 [0m                      

                       Computation: 42318 steps/s (collection: 2.208s, learning 0.115s)
             Mean action noise std: 1.73
          Mean value_function loss: 103.2029
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 50.8585
                       Mean reward: 434.47
               Mean episode length: 230.48
    Episode_Reward/reaching_object: 1.2156
    Episode_Reward/rotating_object: 83.9350
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 2.32s
                      Time elapsed: 00:13:33
                               ETA: 00:42:38

################################################################################
                     [1m Learning iteration 362/1500 [0m                      

                       Computation: 42226 steps/s (collection: 2.214s, learning 0.114s)
             Mean action noise std: 1.73
          Mean value_function loss: 112.8622
               Mean surrogate loss: 0.0018
                 Mean entropy loss: 50.8681
                       Mean reward: 424.19
               Mean episode length: 224.14
    Episode_Reward/reaching_object: 1.2062
    Episode_Reward/rotating_object: 80.1540
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 2.33s
                      Time elapsed: 00:13:35
                               ETA: 00:42:36

################################################################################
                     [1m Learning iteration 363/1500 [0m                      

                       Computation: 42801 steps/s (collection: 2.186s, learning 0.110s)
             Mean action noise std: 1.73
          Mean value_function loss: 104.7561
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 50.8710
                       Mean reward: 395.56
               Mean episode length: 229.52
    Episode_Reward/reaching_object: 1.1748
    Episode_Reward/rotating_object: 76.8825
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 2.30s
                      Time elapsed: 00:13:37
                               ETA: 00:42:33

################################################################################
                     [1m Learning iteration 364/1500 [0m                      

                       Computation: 42913 steps/s (collection: 2.179s, learning 0.112s)
             Mean action noise std: 1.73
          Mean value_function loss: 102.6624
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 50.8754
                       Mean reward: 418.79
               Mean episode length: 231.18
    Episode_Reward/reaching_object: 1.2256
    Episode_Reward/rotating_object: 84.1632
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 2.29s
                      Time elapsed: 00:13:39
                               ETA: 00:42:31

################################################################################
                     [1m Learning iteration 365/1500 [0m                      

                       Computation: 41720 steps/s (collection: 2.234s, learning 0.122s)
             Mean action noise std: 1.73
          Mean value_function loss: 101.2732
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 50.8854
                       Mean reward: 433.35
               Mean episode length: 223.60
    Episode_Reward/reaching_object: 1.2032
    Episode_Reward/rotating_object: 80.7436
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 2.36s
                      Time elapsed: 00:13:42
                               ETA: 00:42:29

################################################################################
                     [1m Learning iteration 366/1500 [0m                      

                       Computation: 41162 steps/s (collection: 2.274s, learning 0.114s)
             Mean action noise std: 1.73
          Mean value_function loss: 104.4553
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 50.8911
                       Mean reward: 422.90
               Mean episode length: 224.34
    Episode_Reward/reaching_object: 1.2162
    Episode_Reward/rotating_object: 87.7836
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 2.39s
                      Time elapsed: 00:13:44
                               ETA: 00:42:28

################################################################################
                     [1m Learning iteration 367/1500 [0m                      

                       Computation: 42650 steps/s (collection: 2.195s, learning 0.110s)
             Mean action noise std: 1.73
          Mean value_function loss: 109.2534
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 50.8997
                       Mean reward: 392.17
               Mean episode length: 226.08
    Episode_Reward/reaching_object: 1.1925
    Episode_Reward/rotating_object: 80.4380
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 2.30s
                      Time elapsed: 00:13:46
                               ETA: 00:42:26

################################################################################
                     [1m Learning iteration 368/1500 [0m                      

                       Computation: 42403 steps/s (collection: 2.192s, learning 0.127s)
             Mean action noise std: 1.73
          Mean value_function loss: 115.7252
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 50.9141
                       Mean reward: 426.93
               Mean episode length: 224.66
    Episode_Reward/reaching_object: 1.2050
    Episode_Reward/rotating_object: 83.6485
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 2.32s
                      Time elapsed: 00:13:49
                               ETA: 00:42:24

################################################################################
                     [1m Learning iteration 369/1500 [0m                      

                       Computation: 42057 steps/s (collection: 2.226s, learning 0.112s)
             Mean action noise std: 1.73
          Mean value_function loss: 113.6608
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 50.9233
                       Mean reward: 408.47
               Mean episode length: 224.60
    Episode_Reward/reaching_object: 1.1888
    Episode_Reward/rotating_object: 83.1742
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 2.34s
                      Time elapsed: 00:13:51
                               ETA: 00:42:22

################################################################################
                     [1m Learning iteration 370/1500 [0m                      

                       Computation: 42529 steps/s (collection: 2.198s, learning 0.113s)
             Mean action noise std: 1.73
          Mean value_function loss: 96.8689
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 50.9290
                       Mean reward: 432.49
               Mean episode length: 230.15
    Episode_Reward/reaching_object: 1.2075
    Episode_Reward/rotating_object: 85.6702
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 2.31s
                      Time elapsed: 00:13:53
                               ETA: 00:42:20

################################################################################
                     [1m Learning iteration 371/1500 [0m                      

                       Computation: 42696 steps/s (collection: 2.190s, learning 0.113s)
             Mean action noise std: 1.73
          Mean value_function loss: 107.0687
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 50.9343
                       Mean reward: 433.44
               Mean episode length: 229.83
    Episode_Reward/reaching_object: 1.2144
    Episode_Reward/rotating_object: 83.2877
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 2.30s
                      Time elapsed: 00:13:56
                               ETA: 00:42:17

################################################################################
                     [1m Learning iteration 372/1500 [0m                      

                       Computation: 38884 steps/s (collection: 2.418s, learning 0.110s)
             Mean action noise std: 1.73
          Mean value_function loss: 105.1171
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 50.9437
                       Mean reward: 450.41
               Mean episode length: 226.70
    Episode_Reward/reaching_object: 1.2088
    Episode_Reward/rotating_object: 85.7887
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 2.53s
                      Time elapsed: 00:13:58
                               ETA: 00:42:16

################################################################################
                     [1m Learning iteration 373/1500 [0m                      

                       Computation: 39750 steps/s (collection: 2.363s, learning 0.110s)
             Mean action noise std: 1.74
          Mean value_function loss: 92.8719
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 50.9582
                       Mean reward: 408.22
               Mean episode length: 222.74
    Episode_Reward/reaching_object: 1.2172
    Episode_Reward/rotating_object: 87.7071
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 2.47s
                      Time elapsed: 00:14:01
                               ETA: 00:42:14

################################################################################
                     [1m Learning iteration 374/1500 [0m                      

                       Computation: 40077 steps/s (collection: 2.343s, learning 0.110s)
             Mean action noise std: 1.74
          Mean value_function loss: 91.4749
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 50.9706
                       Mean reward: 460.90
               Mean episode length: 234.22
    Episode_Reward/reaching_object: 1.2353
    Episode_Reward/rotating_object: 87.3115
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 2.45s
                      Time elapsed: 00:14:03
                               ETA: 00:42:13

################################################################################
                     [1m Learning iteration 375/1500 [0m                      

                       Computation: 40699 steps/s (collection: 2.305s, learning 0.110s)
             Mean action noise std: 1.74
          Mean value_function loss: 84.9818
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 50.9754
                       Mean reward: 427.51
               Mean episode length: 231.04
    Episode_Reward/reaching_object: 1.2510
    Episode_Reward/rotating_object: 88.1236
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 2.42s
                      Time elapsed: 00:14:06
                               ETA: 00:42:11

################################################################################
                     [1m Learning iteration 376/1500 [0m                      

                       Computation: 42133 steps/s (collection: 2.223s, learning 0.110s)
             Mean action noise std: 1.74
          Mean value_function loss: 94.9920
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 50.9827
                       Mean reward: 446.98
               Mean episode length: 226.35
    Episode_Reward/reaching_object: 1.2037
    Episode_Reward/rotating_object: 86.5431
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 2.33s
                      Time elapsed: 00:14:08
                               ETA: 00:42:09

################################################################################
                     [1m Learning iteration 377/1500 [0m                      

                       Computation: 41607 steps/s (collection: 2.252s, learning 0.110s)
             Mean action noise std: 1.74
          Mean value_function loss: 110.0362
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 50.9915
                       Mean reward: 408.57
               Mean episode length: 224.96
    Episode_Reward/reaching_object: 1.1848
    Episode_Reward/rotating_object: 81.8054
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 2.36s
                      Time elapsed: 00:14:10
                               ETA: 00:42:07

################################################################################
                     [1m Learning iteration 378/1500 [0m                      

                       Computation: 40642 steps/s (collection: 2.305s, learning 0.114s)
             Mean action noise std: 1.74
          Mean value_function loss: 94.8997
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 50.9986
                       Mean reward: 454.27
               Mean episode length: 236.05
    Episode_Reward/reaching_object: 1.2484
    Episode_Reward/rotating_object: 91.6944
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 2.42s
                      Time elapsed: 00:14:13
                               ETA: 00:42:05

################################################################################
                     [1m Learning iteration 379/1500 [0m                      

                       Computation: 42619 steps/s (collection: 2.187s, learning 0.120s)
             Mean action noise std: 1.74
          Mean value_function loss: 102.3730
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 51.0089
                       Mean reward: 441.24
               Mean episode length: 226.82
    Episode_Reward/reaching_object: 1.2048
    Episode_Reward/rotating_object: 86.4426
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 2.31s
                      Time elapsed: 00:14:15
                               ETA: 00:42:03

################################################################################
                     [1m Learning iteration 380/1500 [0m                      

                       Computation: 42675 steps/s (collection: 2.191s, learning 0.112s)
             Mean action noise std: 1.74
          Mean value_function loss: 100.3462
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 51.0215
                       Mean reward: 410.61
               Mean episode length: 220.87
    Episode_Reward/reaching_object: 1.2149
    Episode_Reward/rotating_object: 86.6162
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 2.30s
                      Time elapsed: 00:14:17
                               ETA: 00:42:01

################################################################################
                     [1m Learning iteration 381/1500 [0m                      

                       Computation: 42291 steps/s (collection: 2.210s, learning 0.114s)
             Mean action noise std: 1.74
          Mean value_function loss: 97.1603
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 51.0303
                       Mean reward: 498.91
               Mean episode length: 242.08
    Episode_Reward/reaching_object: 1.2410
    Episode_Reward/rotating_object: 92.2981
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 2.32s
                      Time elapsed: 00:14:20
                               ETA: 00:41:59

################################################################################
                     [1m Learning iteration 382/1500 [0m                      

                       Computation: 42933 steps/s (collection: 2.178s, learning 0.111s)
             Mean action noise std: 1.74
          Mean value_function loss: 100.4877
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 51.0342
                       Mean reward: 443.63
               Mean episode length: 224.13
    Episode_Reward/reaching_object: 1.1925
    Episode_Reward/rotating_object: 87.2764
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 2.29s
                      Time elapsed: 00:14:22
                               ETA: 00:41:57

################################################################################
                     [1m Learning iteration 383/1500 [0m                      

                       Computation: 42428 steps/s (collection: 2.203s, learning 0.114s)
             Mean action noise std: 1.74
          Mean value_function loss: 99.6051
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 51.0417
                       Mean reward: 494.65
               Mean episode length: 234.29
    Episode_Reward/reaching_object: 1.2210
    Episode_Reward/rotating_object: 91.3135
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 2.32s
                      Time elapsed: 00:14:24
                               ETA: 00:41:55

################################################################################
                     [1m Learning iteration 384/1500 [0m                      

                       Computation: 42667 steps/s (collection: 2.191s, learning 0.113s)
             Mean action noise std: 1.74
          Mean value_function loss: 94.9865
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 51.0527
                       Mean reward: 443.63
               Mean episode length: 226.46
    Episode_Reward/reaching_object: 1.2163
    Episode_Reward/rotating_object: 91.9638
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 2.30s
                      Time elapsed: 00:14:27
                               ETA: 00:41:53

################################################################################
                     [1m Learning iteration 385/1500 [0m                      

                       Computation: 41757 steps/s (collection: 2.241s, learning 0.113s)
             Mean action noise std: 1.74
          Mean value_function loss: 101.8016
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 51.0626
                       Mean reward: 424.91
               Mean episode length: 221.86
    Episode_Reward/reaching_object: 1.2058
    Episode_Reward/rotating_object: 87.9233
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 2.35s
                      Time elapsed: 00:14:29
                               ETA: 00:41:51

################################################################################
                     [1m Learning iteration 386/1500 [0m                      

                       Computation: 41788 steps/s (collection: 2.232s, learning 0.121s)
             Mean action noise std: 1.74
          Mean value_function loss: 101.3461
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 51.0747
                       Mean reward: 444.44
               Mean episode length: 233.42
    Episode_Reward/reaching_object: 1.2220
    Episode_Reward/rotating_object: 89.6818
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 2.35s
                      Time elapsed: 00:14:31
                               ETA: 00:41:49

################################################################################
                     [1m Learning iteration 387/1500 [0m                      

                       Computation: 40908 steps/s (collection: 2.287s, learning 0.116s)
             Mean action noise std: 1.75
          Mean value_function loss: 104.9643
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 51.0868
                       Mean reward: 462.86
               Mean episode length: 230.17
    Episode_Reward/reaching_object: 1.2052
    Episode_Reward/rotating_object: 87.6173
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 2.40s
                      Time elapsed: 00:14:34
                               ETA: 00:41:47

################################################################################
                     [1m Learning iteration 388/1500 [0m                      

                       Computation: 42537 steps/s (collection: 2.198s, learning 0.113s)
             Mean action noise std: 1.75
          Mean value_function loss: 101.0901
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 51.1014
                       Mean reward: 433.28
               Mean episode length: 222.98
    Episode_Reward/reaching_object: 1.1936
    Episode_Reward/rotating_object: 87.4681
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 2.31s
                      Time elapsed: 00:14:36
                               ETA: 00:41:45

################################################################################
                     [1m Learning iteration 389/1500 [0m                      

                       Computation: 42990 steps/s (collection: 2.175s, learning 0.112s)
             Mean action noise std: 1.75
          Mean value_function loss: 109.5482
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 51.1106
                       Mean reward: 453.22
               Mean episode length: 229.14
    Episode_Reward/reaching_object: 1.2014
    Episode_Reward/rotating_object: 89.0315
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 2.29s
                      Time elapsed: 00:14:38
                               ETA: 00:41:43

################################################################################
                     [1m Learning iteration 390/1500 [0m                      

                       Computation: 42914 steps/s (collection: 2.177s, learning 0.113s)
             Mean action noise std: 1.75
          Mean value_function loss: 110.0515
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 51.1230
                       Mean reward: 476.30
               Mean episode length: 229.17
    Episode_Reward/reaching_object: 1.1799
    Episode_Reward/rotating_object: 89.9258
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 2.29s
                      Time elapsed: 00:14:41
                               ETA: 00:41:41

################################################################################
                     [1m Learning iteration 391/1500 [0m                      

                       Computation: 42517 steps/s (collection: 2.198s, learning 0.114s)
             Mean action noise std: 1.75
          Mean value_function loss: 108.1197
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 51.1351
                       Mean reward: 462.74
               Mean episode length: 224.30
    Episode_Reward/reaching_object: 1.1635
    Episode_Reward/rotating_object: 86.1169
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 2.31s
                      Time elapsed: 00:14:43
                               ETA: 00:41:39

################################################################################
                     [1m Learning iteration 392/1500 [0m                      

                       Computation: 42815 steps/s (collection: 2.180s, learning 0.116s)
             Mean action noise std: 1.75
          Mean value_function loss: 112.6267
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 51.1442
                       Mean reward: 474.00
               Mean episode length: 230.13
    Episode_Reward/reaching_object: 1.1964
    Episode_Reward/rotating_object: 91.4215
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 2.30s
                      Time elapsed: 00:14:45
                               ETA: 00:41:37

################################################################################
                     [1m Learning iteration 393/1500 [0m                      

                       Computation: 43028 steps/s (collection: 2.172s, learning 0.112s)
             Mean action noise std: 1.75
          Mean value_function loss: 113.9809
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 51.1557
                       Mean reward: 477.17
               Mean episode length: 228.43
    Episode_Reward/reaching_object: 1.2047
    Episode_Reward/rotating_object: 92.1827
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 2.28s
                      Time elapsed: 00:14:47
                               ETA: 00:41:34

################################################################################
                     [1m Learning iteration 394/1500 [0m                      

                       Computation: 43477 steps/s (collection: 2.151s, learning 0.110s)
             Mean action noise std: 1.75
          Mean value_function loss: 106.4344
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 51.1669
                       Mean reward: 439.88
               Mean episode length: 225.63
    Episode_Reward/reaching_object: 1.1772
    Episode_Reward/rotating_object: 85.3086
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 2.26s
                      Time elapsed: 00:14:50
                               ETA: 00:41:32

################################################################################
                     [1m Learning iteration 395/1500 [0m                      

                       Computation: 43427 steps/s (collection: 2.153s, learning 0.111s)
             Mean action noise std: 1.75
          Mean value_function loss: 97.0312
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 51.1771
                       Mean reward: 460.37
               Mean episode length: 229.16
    Episode_Reward/reaching_object: 1.2212
    Episode_Reward/rotating_object: 93.0677
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 2.26s
                      Time elapsed: 00:14:52
                               ETA: 00:41:30

################################################################################
                     [1m Learning iteration 396/1500 [0m                      

                       Computation: 43865 steps/s (collection: 2.130s, learning 0.111s)
             Mean action noise std: 1.75
          Mean value_function loss: 110.3842
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 51.1872
                       Mean reward: 502.01
               Mean episode length: 228.35
    Episode_Reward/reaching_object: 1.1798
    Episode_Reward/rotating_object: 91.7132
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 2.24s
                      Time elapsed: 00:14:54
                               ETA: 00:41:28

################################################################################
                     [1m Learning iteration 397/1500 [0m                      

                       Computation: 43352 steps/s (collection: 2.157s, learning 0.111s)
             Mean action noise std: 1.75
          Mean value_function loss: 103.8272
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 51.1981
                       Mean reward: 485.80
               Mean episode length: 229.43
    Episode_Reward/reaching_object: 1.2082
    Episode_Reward/rotating_object: 94.2211
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 2.27s
                      Time elapsed: 00:14:56
                               ETA: 00:41:25

################################################################################
                     [1m Learning iteration 398/1500 [0m                      

                       Computation: 43003 steps/s (collection: 2.175s, learning 0.111s)
             Mean action noise std: 1.75
          Mean value_function loss: 116.6465
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 51.2126
                       Mean reward: 463.43
               Mean episode length: 223.83
    Episode_Reward/reaching_object: 1.2406
    Episode_Reward/rotating_object: 98.0266
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 2.29s
                      Time elapsed: 00:14:59
                               ETA: 00:41:23

################################################################################
                     [1m Learning iteration 399/1500 [0m                      

                       Computation: 43061 steps/s (collection: 2.172s, learning 0.111s)
             Mean action noise std: 1.76
          Mean value_function loss: 120.1564
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 51.2262
                       Mean reward: 504.81
               Mean episode length: 227.41
    Episode_Reward/reaching_object: 1.2222
    Episode_Reward/rotating_object: 96.1738
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 2.28s
                      Time elapsed: 00:15:01
                               ETA: 00:41:21

################################################################################
                     [1m Learning iteration 400/1500 [0m                      

                       Computation: 42648 steps/s (collection: 2.191s, learning 0.114s)
             Mean action noise std: 1.76
          Mean value_function loss: 139.3125
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 51.2387
                       Mean reward: 472.81
               Mean episode length: 233.34
    Episode_Reward/reaching_object: 1.2320
    Episode_Reward/rotating_object: 93.9436
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 2.30s
                      Time elapsed: 00:15:03
                               ETA: 00:41:19

################################################################################
                     [1m Learning iteration 401/1500 [0m                      

                       Computation: 42557 steps/s (collection: 2.196s, learning 0.113s)
             Mean action noise std: 1.76
          Mean value_function loss: 125.8606
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 51.2485
                       Mean reward: 446.69
               Mean episode length: 219.02
    Episode_Reward/reaching_object: 1.1972
    Episode_Reward/rotating_object: 91.2180
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 2.31s
                      Time elapsed: 00:15:06
                               ETA: 00:41:17

################################################################################
                     [1m Learning iteration 402/1500 [0m                      

                       Computation: 42587 steps/s (collection: 2.194s, learning 0.114s)
             Mean action noise std: 1.76
          Mean value_function loss: 113.6194
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 51.2586
                       Mean reward: 462.61
               Mean episode length: 222.13
    Episode_Reward/reaching_object: 1.2199
    Episode_Reward/rotating_object: 93.6171
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 2.31s
                      Time elapsed: 00:15:08
                               ETA: 00:41:15

################################################################################
                     [1m Learning iteration 403/1500 [0m                      

                       Computation: 42253 steps/s (collection: 2.214s, learning 0.112s)
             Mean action noise std: 1.76
          Mean value_function loss: 112.3641
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 51.2725
                       Mean reward: 503.31
               Mean episode length: 229.32
    Episode_Reward/reaching_object: 1.2498
    Episode_Reward/rotating_object: 97.5885
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 2.33s
                      Time elapsed: 00:15:10
                               ETA: 00:41:13

################################################################################
                     [1m Learning iteration 404/1500 [0m                      

                       Computation: 42260 steps/s (collection: 2.209s, learning 0.117s)
             Mean action noise std: 1.76
          Mean value_function loss: 114.2862
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 51.2819
                       Mean reward: 466.89
               Mean episode length: 226.97
    Episode_Reward/reaching_object: 1.2258
    Episode_Reward/rotating_object: 95.4089
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 2.33s
                      Time elapsed: 00:15:13
                               ETA: 00:41:11

################################################################################
                     [1m Learning iteration 405/1500 [0m                      

                       Computation: 42612 steps/s (collection: 2.195s, learning 0.112s)
             Mean action noise std: 1.76
          Mean value_function loss: 110.0543
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 51.2907
                       Mean reward: 480.73
               Mean episode length: 230.78
    Episode_Reward/reaching_object: 1.2420
    Episode_Reward/rotating_object: 95.0988
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 2.31s
                      Time elapsed: 00:15:15
                               ETA: 00:41:08

################################################################################
                     [1m Learning iteration 406/1500 [0m                      

                       Computation: 42257 steps/s (collection: 2.213s, learning 0.114s)
             Mean action noise std: 1.76
          Mean value_function loss: 110.1941
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 51.2980
                       Mean reward: 471.85
               Mean episode length: 222.25
    Episode_Reward/reaching_object: 1.2349
    Episode_Reward/rotating_object: 96.0147
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 2.33s
                      Time elapsed: 00:15:17
                               ETA: 00:41:06

################################################################################
                     [1m Learning iteration 407/1500 [0m                      

                       Computation: 41610 steps/s (collection: 2.250s, learning 0.113s)
             Mean action noise std: 1.76
          Mean value_function loss: 99.4609
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 51.3083
                       Mean reward: 507.79
               Mean episode length: 238.75
    Episode_Reward/reaching_object: 1.2499
    Episode_Reward/rotating_object: 95.6665
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 2.36s
                      Time elapsed: 00:15:20
                               ETA: 00:41:04

################################################################################
                     [1m Learning iteration 408/1500 [0m                      

                       Computation: 41867 steps/s (collection: 2.236s, learning 0.112s)
             Mean action noise std: 1.76
          Mean value_function loss: 108.2892
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 51.3155
                       Mean reward: 509.57
               Mean episode length: 238.35
    Episode_Reward/reaching_object: 1.2589
    Episode_Reward/rotating_object: 98.5536
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 2.35s
                      Time elapsed: 00:15:22
                               ETA: 00:41:02

################################################################################
                     [1m Learning iteration 409/1500 [0m                      

                       Computation: 41955 steps/s (collection: 2.230s, learning 0.113s)
             Mean action noise std: 1.76
          Mean value_function loss: 112.7925
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 51.3256
                       Mean reward: 500.26
               Mean episode length: 227.65
    Episode_Reward/reaching_object: 1.2345
    Episode_Reward/rotating_object: 98.1116
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 2.34s
                      Time elapsed: 00:15:24
                               ETA: 00:41:00

################################################################################
                     [1m Learning iteration 410/1500 [0m                      

                       Computation: 42066 steps/s (collection: 2.220s, learning 0.116s)
             Mean action noise std: 1.76
          Mean value_function loss: 100.3861
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 51.3385
                       Mean reward: 459.84
               Mean episode length: 223.72
    Episode_Reward/reaching_object: 1.2014
    Episode_Reward/rotating_object: 95.2599
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 2.34s
                      Time elapsed: 00:15:27
                               ETA: 00:40:58

################################################################################
                     [1m Learning iteration 411/1500 [0m                      

                       Computation: 42044 steps/s (collection: 2.226s, learning 0.112s)
             Mean action noise std: 1.77
          Mean value_function loss: 98.2522
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 51.3493
                       Mean reward: 471.26
               Mean episode length: 228.80
    Episode_Reward/reaching_object: 1.2465
    Episode_Reward/rotating_object: 97.6978
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 2.34s
                      Time elapsed: 00:15:29
                               ETA: 00:40:56

################################################################################
                     [1m Learning iteration 412/1500 [0m                      

                       Computation: 41782 steps/s (collection: 2.239s, learning 0.114s)
             Mean action noise std: 1.77
          Mean value_function loss: 98.2301
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 51.3566
                       Mean reward: 516.25
               Mean episode length: 227.49
    Episode_Reward/reaching_object: 1.2346
    Episode_Reward/rotating_object: 98.3613
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 2.35s
                      Time elapsed: 00:15:31
                               ETA: 00:40:54

################################################################################
                     [1m Learning iteration 413/1500 [0m                      

                       Computation: 42070 steps/s (collection: 2.217s, learning 0.120s)
             Mean action noise std: 1.77
          Mean value_function loss: 105.9871
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 51.3689
                       Mean reward: 432.21
               Mean episode length: 216.62
    Episode_Reward/reaching_object: 1.2035
    Episode_Reward/rotating_object: 93.4778
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 2.34s
                      Time elapsed: 00:15:34
                               ETA: 00:40:52

################################################################################
                     [1m Learning iteration 414/1500 [0m                      

                       Computation: 42439 steps/s (collection: 2.203s, learning 0.114s)
             Mean action noise std: 1.77
          Mean value_function loss: 87.4746
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 51.3845
                       Mean reward: 501.28
               Mean episode length: 226.06
    Episode_Reward/reaching_object: 1.2067
    Episode_Reward/rotating_object: 99.9958
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 2.32s
                      Time elapsed: 00:15:36
                               ETA: 00:40:50

################################################################################
                     [1m Learning iteration 415/1500 [0m                      

                       Computation: 42823 steps/s (collection: 2.180s, learning 0.115s)
             Mean action noise std: 1.77
          Mean value_function loss: 91.3553
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 51.3974
                       Mean reward: 459.55
               Mean episode length: 224.21
    Episode_Reward/reaching_object: 1.2048
    Episode_Reward/rotating_object: 97.2284
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 2.30s
                      Time elapsed: 00:15:38
                               ETA: 00:40:48

################################################################################
                     [1m Learning iteration 416/1500 [0m                      

                       Computation: 42887 steps/s (collection: 2.181s, learning 0.111s)
             Mean action noise std: 1.77
          Mean value_function loss: 95.2814
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 51.4080
                       Mean reward: 495.18
               Mean episode length: 227.08
    Episode_Reward/reaching_object: 1.1986
    Episode_Reward/rotating_object: 99.5436
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 2.29s
                      Time elapsed: 00:15:41
                               ETA: 00:40:46

################################################################################
                     [1m Learning iteration 417/1500 [0m                      

                       Computation: 42922 steps/s (collection: 2.178s, learning 0.112s)
             Mean action noise std: 1.77
          Mean value_function loss: 89.4741
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 51.4225
                       Mean reward: 524.08
               Mean episode length: 233.77
    Episode_Reward/reaching_object: 1.2262
    Episode_Reward/rotating_object: 101.2370
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 2.29s
                      Time elapsed: 00:15:43
                               ETA: 00:40:44

################################################################################
                     [1m Learning iteration 418/1500 [0m                      

                       Computation: 42805 steps/s (collection: 2.185s, learning 0.111s)
             Mean action noise std: 1.77
          Mean value_function loss: 91.7707
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 51.4349
                       Mean reward: 522.59
               Mean episode length: 232.09
    Episode_Reward/reaching_object: 1.1986
    Episode_Reward/rotating_object: 98.6766
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 2.30s
                      Time elapsed: 00:15:45
                               ETA: 00:40:42

################################################################################
                     [1m Learning iteration 419/1500 [0m                      

                       Computation: 42596 steps/s (collection: 2.197s, learning 0.111s)
             Mean action noise std: 1.77
          Mean value_function loss: 90.6754
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 51.4521
                       Mean reward: 528.13
               Mean episode length: 233.47
    Episode_Reward/reaching_object: 1.1874
    Episode_Reward/rotating_object: 98.9431
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 2.31s
                      Time elapsed: 00:15:47
                               ETA: 00:40:39

################################################################################
                     [1m Learning iteration 420/1500 [0m                      

                       Computation: 43317 steps/s (collection: 2.158s, learning 0.111s)
             Mean action noise std: 1.77
          Mean value_function loss: 100.7393
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 51.4726
                       Mean reward: 513.39
               Mean episode length: 228.88
    Episode_Reward/reaching_object: 1.2145
    Episode_Reward/rotating_object: 102.6557
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 2.27s
                      Time elapsed: 00:15:50
                               ETA: 00:40:37

################################################################################
                     [1m Learning iteration 421/1500 [0m                      

                       Computation: 43408 steps/s (collection: 2.154s, learning 0.111s)
             Mean action noise std: 1.78
          Mean value_function loss: 91.7165
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 51.4876
                       Mean reward: 527.51
               Mean episode length: 233.15
    Episode_Reward/reaching_object: 1.2159
    Episode_Reward/rotating_object: 100.7772
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 2.26s
                      Time elapsed: 00:15:52
                               ETA: 00:40:35

################################################################################
                     [1m Learning iteration 422/1500 [0m                      

                       Computation: 42706 steps/s (collection: 2.191s, learning 0.111s)
             Mean action noise std: 1.78
          Mean value_function loss: 95.2801
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 51.4990
                       Mean reward: 498.42
               Mean episode length: 228.87
    Episode_Reward/reaching_object: 1.2233
    Episode_Reward/rotating_object: 100.5723
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 2.30s
                      Time elapsed: 00:15:54
                               ETA: 00:40:33

################################################################################
                     [1m Learning iteration 423/1500 [0m                      

                       Computation: 42370 steps/s (collection: 2.203s, learning 0.117s)
             Mean action noise std: 1.78
          Mean value_function loss: 100.2754
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 51.5071
                       Mean reward: 496.53
               Mean episode length: 224.82
    Episode_Reward/reaching_object: 1.2255
    Episode_Reward/rotating_object: 101.1163
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 2.32s
                      Time elapsed: 00:15:57
                               ETA: 00:40:31

################################################################################
                     [1m Learning iteration 424/1500 [0m                      

                       Computation: 41482 steps/s (collection: 2.257s, learning 0.113s)
             Mean action noise std: 1.78
          Mean value_function loss: 106.8160
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 51.5149
                       Mean reward: 517.75
               Mean episode length: 232.21
    Episode_Reward/reaching_object: 1.1704
    Episode_Reward/rotating_object: 95.1852
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 2.37s
                      Time elapsed: 00:15:59
                               ETA: 00:40:29

################################################################################
                     [1m Learning iteration 425/1500 [0m                      

                       Computation: 41509 steps/s (collection: 2.253s, learning 0.115s)
             Mean action noise std: 1.78
          Mean value_function loss: 113.7833
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 51.5219
                       Mean reward: 484.93
               Mean episode length: 219.86
    Episode_Reward/reaching_object: 1.1869
    Episode_Reward/rotating_object: 97.6943
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 2.37s
                      Time elapsed: 00:16:01
                               ETA: 00:40:27

################################################################################
                     [1m Learning iteration 426/1500 [0m                      

                       Computation: 42213 steps/s (collection: 2.216s, learning 0.113s)
             Mean action noise std: 1.78
          Mean value_function loss: 99.9590
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 51.5354
                       Mean reward: 562.16
               Mean episode length: 235.97
    Episode_Reward/reaching_object: 1.2074
    Episode_Reward/rotating_object: 100.2201
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 2.33s
                      Time elapsed: 00:16:04
                               ETA: 00:40:25

################################################################################
                     [1m Learning iteration 427/1500 [0m                      

                       Computation: 42604 steps/s (collection: 2.194s, learning 0.113s)
             Mean action noise std: 1.78
          Mean value_function loss: 71.7237
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 51.5521
                       Mean reward: 502.18
               Mean episode length: 225.44
    Episode_Reward/reaching_object: 1.2112
    Episode_Reward/rotating_object: 101.3462
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 2.31s
                      Time elapsed: 00:16:06
                               ETA: 00:40:23

################################################################################
                     [1m Learning iteration 428/1500 [0m                      

                       Computation: 43514 steps/s (collection: 2.147s, learning 0.112s)
             Mean action noise std: 1.78
          Mean value_function loss: 81.6209
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 51.5646
                       Mean reward: 510.53
               Mean episode length: 231.24
    Episode_Reward/reaching_object: 1.2462
    Episode_Reward/rotating_object: 103.2446
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 2.26s
                      Time elapsed: 00:16:08
                               ETA: 00:40:20

################################################################################
                     [1m Learning iteration 429/1500 [0m                      

                       Computation: 42718 steps/s (collection: 2.187s, learning 0.114s)
             Mean action noise std: 1.78
          Mean value_function loss: 80.1492
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 51.5687
                       Mean reward: 495.69
               Mean episode length: 221.28
    Episode_Reward/reaching_object: 1.2100
    Episode_Reward/rotating_object: 102.0452
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 2.30s
                      Time elapsed: 00:16:11
                               ETA: 00:40:18

################################################################################
                     [1m Learning iteration 430/1500 [0m                      

                       Computation: 43350 steps/s (collection: 2.156s, learning 0.112s)
             Mean action noise std: 1.78
          Mean value_function loss: 82.1192
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 51.5750
                       Mean reward: 479.10
               Mean episode length: 221.17
    Episode_Reward/reaching_object: 1.2244
    Episode_Reward/rotating_object: 103.7953
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 2.27s
                      Time elapsed: 00:16:13
                               ETA: 00:40:16

################################################################################
                     [1m Learning iteration 431/1500 [0m                      

                       Computation: 42954 steps/s (collection: 2.175s, learning 0.114s)
             Mean action noise std: 1.78
          Mean value_function loss: 93.2467
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 51.5895
                       Mean reward: 518.18
               Mean episode length: 226.51
    Episode_Reward/reaching_object: 1.2097
    Episode_Reward/rotating_object: 105.7760
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 2.29s
                      Time elapsed: 00:16:15
                               ETA: 00:40:14

################################################################################
                     [1m Learning iteration 432/1500 [0m                      

                       Computation: 42035 steps/s (collection: 2.226s, learning 0.112s)
             Mean action noise std: 1.78
          Mean value_function loss: 88.5691
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 51.6077
                       Mean reward: 517.04
               Mean episode length: 232.47
    Episode_Reward/reaching_object: 1.1911
    Episode_Reward/rotating_object: 100.0833
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 2.34s
                      Time elapsed: 00:16:17
                               ETA: 00:40:12

################################################################################
                     [1m Learning iteration 433/1500 [0m                      

                       Computation: 42844 steps/s (collection: 2.182s, learning 0.113s)
             Mean action noise std: 1.79
          Mean value_function loss: 90.8583
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 51.6200
                       Mean reward: 541.56
               Mean episode length: 232.17
    Episode_Reward/reaching_object: 1.1986
    Episode_Reward/rotating_object: 100.6101
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 2.29s
                      Time elapsed: 00:16:20
                               ETA: 00:40:10

################################################################################
                     [1m Learning iteration 434/1500 [0m                      

                       Computation: 42615 steps/s (collection: 2.194s, learning 0.113s)
             Mean action noise std: 1.79
          Mean value_function loss: 81.6973
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 51.6265
                       Mean reward: 526.57
               Mean episode length: 230.94
    Episode_Reward/reaching_object: 1.2182
    Episode_Reward/rotating_object: 103.9299
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 2.31s
                      Time elapsed: 00:16:22
                               ETA: 00:40:07

################################################################################
                     [1m Learning iteration 435/1500 [0m                      

                       Computation: 43151 steps/s (collection: 2.167s, learning 0.111s)
             Mean action noise std: 1.79
          Mean value_function loss: 99.2281
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 51.6329
                       Mean reward: 504.47
               Mean episode length: 228.88
    Episode_Reward/reaching_object: 1.2074
    Episode_Reward/rotating_object: 100.9968
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 2.28s
                      Time elapsed: 00:16:24
                               ETA: 00:40:05

################################################################################
                     [1m Learning iteration 436/1500 [0m                      

                       Computation: 43587 steps/s (collection: 2.144s, learning 0.111s)
             Mean action noise std: 1.79
          Mean value_function loss: 99.7291
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 51.6502
                       Mean reward: 520.29
               Mean episode length: 227.02
    Episode_Reward/reaching_object: 1.2166
    Episode_Reward/rotating_object: 104.4232
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 2.26s
                      Time elapsed: 00:16:27
                               ETA: 00:40:03

################################################################################
                     [1m Learning iteration 437/1500 [0m                      

                       Computation: 43506 steps/s (collection: 2.148s, learning 0.111s)
             Mean action noise std: 1.79
          Mean value_function loss: 95.7353
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 51.6717
                       Mean reward: 560.73
               Mean episode length: 243.02
    Episode_Reward/reaching_object: 1.2171
    Episode_Reward/rotating_object: 102.5518
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 2.26s
                      Time elapsed: 00:16:29
                               ETA: 00:40:01

################################################################################
                     [1m Learning iteration 438/1500 [0m                      

                       Computation: 44074 steps/s (collection: 2.120s, learning 0.111s)
             Mean action noise std: 1.79
          Mean value_function loss: 91.1034
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 51.6890
                       Mean reward: 516.04
               Mean episode length: 221.28
    Episode_Reward/reaching_object: 1.2341
    Episode_Reward/rotating_object: 108.6464
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 2.23s
                      Time elapsed: 00:16:31
                               ETA: 00:39:58

################################################################################
                     [1m Learning iteration 439/1500 [0m                      

                       Computation: 43718 steps/s (collection: 2.137s, learning 0.111s)
             Mean action noise std: 1.79
          Mean value_function loss: 95.3257
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 51.7010
                       Mean reward: 521.15
               Mean episode length: 223.07
    Episode_Reward/reaching_object: 1.2160
    Episode_Reward/rotating_object: 105.7890
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 2.25s
                      Time elapsed: 00:16:33
                               ETA: 00:39:56

################################################################################
                     [1m Learning iteration 440/1500 [0m                      

                       Computation: 43955 steps/s (collection: 2.125s, learning 0.111s)
             Mean action noise std: 1.79
          Mean value_function loss: 94.9570
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 51.7114
                       Mean reward: 515.45
               Mean episode length: 221.33
    Episode_Reward/reaching_object: 1.2557
    Episode_Reward/rotating_object: 107.9098
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 2.24s
                      Time elapsed: 00:16:36
                               ETA: 00:39:54

################################################################################
                     [1m Learning iteration 441/1500 [0m                      

                       Computation: 43830 steps/s (collection: 2.132s, learning 0.111s)
             Mean action noise std: 1.79
          Mean value_function loss: 88.9906
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 51.7250
                       Mean reward: 556.97
               Mean episode length: 236.77
    Episode_Reward/reaching_object: 1.2236
    Episode_Reward/rotating_object: 104.2793
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 2.24s
                      Time elapsed: 00:16:38
                               ETA: 00:39:51

################################################################################
                     [1m Learning iteration 442/1500 [0m                      

                       Computation: 43401 steps/s (collection: 2.132s, learning 0.133s)
             Mean action noise std: 1.79
          Mean value_function loss: 84.6804
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 51.7394
                       Mean reward: 512.15
               Mean episode length: 225.51
    Episode_Reward/reaching_object: 1.2159
    Episode_Reward/rotating_object: 104.7169
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 2.26s
                      Time elapsed: 00:16:40
                               ETA: 00:39:49

################################################################################
                     [1m Learning iteration 443/1500 [0m                      

                       Computation: 39699 steps/s (collection: 2.365s, learning 0.112s)
             Mean action noise std: 1.80
          Mean value_function loss: 92.5102
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 51.7494
                       Mean reward: 546.52
               Mean episode length: 230.70
    Episode_Reward/reaching_object: 1.2120
    Episode_Reward/rotating_object: 104.7715
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 2.48s
                      Time elapsed: 00:16:43
                               ETA: 00:39:47

################################################################################
                     [1m Learning iteration 444/1500 [0m                      

                       Computation: 41541 steps/s (collection: 2.252s, learning 0.114s)
             Mean action noise std: 1.80
          Mean value_function loss: 88.6139
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 51.7622
                       Mean reward: 511.31
               Mean episode length: 223.18
    Episode_Reward/reaching_object: 1.1842
    Episode_Reward/rotating_object: 103.3389
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 2.37s
                      Time elapsed: 00:16:45
                               ETA: 00:39:45

################################################################################
                     [1m Learning iteration 445/1500 [0m                      

                       Computation: 43049 steps/s (collection: 2.170s, learning 0.114s)
             Mean action noise std: 1.80
          Mean value_function loss: 91.1869
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 51.7756
                       Mean reward: 504.74
               Mean episode length: 214.12
    Episode_Reward/reaching_object: 1.1784
    Episode_Reward/rotating_object: 102.1775
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 2.28s
                      Time elapsed: 00:16:47
                               ETA: 00:39:43

################################################################################
                     [1m Learning iteration 446/1500 [0m                      

                       Computation: 43121 steps/s (collection: 2.169s, learning 0.111s)
             Mean action noise std: 1.80
          Mean value_function loss: 95.2787
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 51.7880
                       Mean reward: 525.43
               Mean episode length: 226.97
    Episode_Reward/reaching_object: 1.2097
    Episode_Reward/rotating_object: 103.7056
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 2.28s
                      Time elapsed: 00:16:49
                               ETA: 00:39:41

################################################################################
                     [1m Learning iteration 447/1500 [0m                      

                       Computation: 43295 steps/s (collection: 2.157s, learning 0.113s)
             Mean action noise std: 1.80
          Mean value_function loss: 92.1174
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 51.8051
                       Mean reward: 536.20
               Mean episode length: 231.10
    Episode_Reward/reaching_object: 1.2069
    Episode_Reward/rotating_object: 104.0649
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 2.27s
                      Time elapsed: 00:16:52
                               ETA: 00:39:39

################################################################################
                     [1m Learning iteration 448/1500 [0m                      

                       Computation: 43670 steps/s (collection: 2.141s, learning 0.110s)
             Mean action noise std: 1.80
          Mean value_function loss: 95.2746
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 51.8160
                       Mean reward: 509.48
               Mean episode length: 224.29
    Episode_Reward/reaching_object: 1.1900
    Episode_Reward/rotating_object: 103.6763
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 2.25s
                      Time elapsed: 00:16:54
                               ETA: 00:39:36

################################################################################
                     [1m Learning iteration 449/1500 [0m                      

                       Computation: 43533 steps/s (collection: 2.145s, learning 0.113s)
             Mean action noise std: 1.80
          Mean value_function loss: 89.8552
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 51.8294
                       Mean reward: 518.57
               Mean episode length: 226.72
    Episode_Reward/reaching_object: 1.2027
    Episode_Reward/rotating_object: 104.6325
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 2.26s
                      Time elapsed: 00:16:56
                               ETA: 00:39:34

################################################################################
                     [1m Learning iteration 450/1500 [0m                      

                       Computation: 43403 steps/s (collection: 2.151s, learning 0.113s)
             Mean action noise std: 1.80
          Mean value_function loss: 93.9676
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 51.8446
                       Mean reward: 575.11
               Mean episode length: 233.38
    Episode_Reward/reaching_object: 1.2452
    Episode_Reward/rotating_object: 109.9335
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 2.26s
                      Time elapsed: 00:16:59
                               ETA: 00:39:32

################################################################################
                     [1m Learning iteration 451/1500 [0m                      

                       Computation: 43555 steps/s (collection: 2.147s, learning 0.110s)
             Mean action noise std: 1.80
          Mean value_function loss: 102.1215
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 51.8529
                       Mean reward: 517.43
               Mean episode length: 219.54
    Episode_Reward/reaching_object: 1.2255
    Episode_Reward/rotating_object: 109.7018
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 2.26s
                      Time elapsed: 00:17:01
                               ETA: 00:39:30

################################################################################
                     [1m Learning iteration 452/1500 [0m                      

                       Computation: 42188 steps/s (collection: 2.217s, learning 0.113s)
             Mean action noise std: 1.80
          Mean value_function loss: 110.1679
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 51.8664
                       Mean reward: 509.91
               Mean episode length: 223.20
    Episode_Reward/reaching_object: 1.1973
    Episode_Reward/rotating_object: 103.6447
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 2.33s
                      Time elapsed: 00:17:03
                               ETA: 00:39:28

################################################################################
                     [1m Learning iteration 453/1500 [0m                      

                       Computation: 43114 steps/s (collection: 2.168s, learning 0.112s)
             Mean action noise std: 1.81
          Mean value_function loss: 106.5832
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 51.8853
                       Mean reward: 543.37
               Mean episode length: 230.51
    Episode_Reward/reaching_object: 1.2090
    Episode_Reward/rotating_object: 104.8223
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 2.28s
                      Time elapsed: 00:17:05
                               ETA: 00:39:25

################################################################################
                     [1m Learning iteration 454/1500 [0m                      

                       Computation: 42867 steps/s (collection: 2.179s, learning 0.114s)
             Mean action noise std: 1.81
          Mean value_function loss: 88.1778
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 51.9022
                       Mean reward: 507.58
               Mean episode length: 227.06
    Episode_Reward/reaching_object: 1.2244
    Episode_Reward/rotating_object: 105.6505
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 2.29s
                      Time elapsed: 00:17:08
                               ETA: 00:39:23

################################################################################
                     [1m Learning iteration 455/1500 [0m                      

                       Computation: 42907 steps/s (collection: 2.178s, learning 0.113s)
             Mean action noise std: 1.81
          Mean value_function loss: 91.0590
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 51.9110
                       Mean reward: 564.48
               Mean episode length: 236.08
    Episode_Reward/reaching_object: 1.2308
    Episode_Reward/rotating_object: 107.9125
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 2.29s
                      Time elapsed: 00:17:10
                               ETA: 00:39:21

################################################################################
                     [1m Learning iteration 456/1500 [0m                      

                       Computation: 42562 steps/s (collection: 2.187s, learning 0.123s)
             Mean action noise std: 1.81
          Mean value_function loss: 87.5312
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 51.9282
                       Mean reward: 557.24
               Mean episode length: 227.95
    Episode_Reward/reaching_object: 1.2285
    Episode_Reward/rotating_object: 111.1130
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 2.31s
                      Time elapsed: 00:17:12
                               ETA: 00:39:19

################################################################################
                     [1m Learning iteration 457/1500 [0m                      

                       Computation: 43269 steps/s (collection: 2.161s, learning 0.111s)
             Mean action noise std: 1.81
          Mean value_function loss: 94.3164
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 51.9514
                       Mean reward: 584.10
               Mean episode length: 236.87
    Episode_Reward/reaching_object: 1.2226
    Episode_Reward/rotating_object: 107.7646
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 2.27s
                      Time elapsed: 00:17:15
                               ETA: 00:39:17

################################################################################
                     [1m Learning iteration 458/1500 [0m                      

                       Computation: 44208 steps/s (collection: 2.113s, learning 0.110s)
             Mean action noise std: 1.81
          Mean value_function loss: 101.5313
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 51.9616
                       Mean reward: 475.40
               Mean episode length: 217.15
    Episode_Reward/reaching_object: 1.2173
    Episode_Reward/rotating_object: 104.3705
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 2.22s
                      Time elapsed: 00:17:17
                               ETA: 00:39:14

################################################################################
                     [1m Learning iteration 459/1500 [0m                      

                       Computation: 44343 steps/s (collection: 2.107s, learning 0.110s)
             Mean action noise std: 1.81
          Mean value_function loss: 102.5050
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 51.9666
                       Mean reward: 545.43
               Mean episode length: 231.19
    Episode_Reward/reaching_object: 1.2006
    Episode_Reward/rotating_object: 103.9655
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 2.22s
                      Time elapsed: 00:17:19
                               ETA: 00:39:12

################################################################################
                     [1m Learning iteration 460/1500 [0m                      

                       Computation: 44549 steps/s (collection: 2.096s, learning 0.110s)
             Mean action noise std: 1.81
          Mean value_function loss: 104.1717
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 51.9749
                       Mean reward: 558.73
               Mean episode length: 229.15
    Episode_Reward/reaching_object: 1.2332
    Episode_Reward/rotating_object: 109.3228
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 2.21s
                      Time elapsed: 00:17:21
                               ETA: 00:39:10

################################################################################
                     [1m Learning iteration 461/1500 [0m                      

                       Computation: 44493 steps/s (collection: 2.099s, learning 0.110s)
             Mean action noise std: 1.81
          Mean value_function loss: 103.1878
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 51.9874
                       Mean reward: 553.90
               Mean episode length: 226.98
    Episode_Reward/reaching_object: 1.2034
    Episode_Reward/rotating_object: 107.6702
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 2.21s
                      Time elapsed: 00:17:23
                               ETA: 00:39:07

################################################################################
                     [1m Learning iteration 462/1500 [0m                      

                       Computation: 44718 steps/s (collection: 2.088s, learning 0.110s)
             Mean action noise std: 1.82
          Mean value_function loss: 105.2354
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 52.0067
                       Mean reward: 549.03
               Mean episode length: 224.13
    Episode_Reward/reaching_object: 1.2335
    Episode_Reward/rotating_object: 107.7457
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 2.20s
                      Time elapsed: 00:17:26
                               ETA: 00:39:05

################################################################################
                     [1m Learning iteration 463/1500 [0m                      

                       Computation: 44259 steps/s (collection: 2.110s, learning 0.111s)
             Mean action noise std: 1.82
          Mean value_function loss: 105.8662
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.0216
                       Mean reward: 482.53
               Mean episode length: 214.45
    Episode_Reward/reaching_object: 1.1660
    Episode_Reward/rotating_object: 100.8045
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 2.22s
                      Time elapsed: 00:17:28
                               ETA: 00:39:02

################################################################################
                     [1m Learning iteration 464/1500 [0m                      

                       Computation: 44170 steps/s (collection: 2.114s, learning 0.112s)
             Mean action noise std: 1.82
          Mean value_function loss: 99.1455
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 52.0337
                       Mean reward: 499.47
               Mean episode length: 217.63
    Episode_Reward/reaching_object: 1.2275
    Episode_Reward/rotating_object: 106.8353
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 2.23s
                      Time elapsed: 00:17:30
                               ETA: 00:39:00

################################################################################
                     [1m Learning iteration 465/1500 [0m                      

                       Computation: 43611 steps/s (collection: 2.142s, learning 0.112s)
             Mean action noise std: 1.82
          Mean value_function loss: 105.7858
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 52.0457
                       Mean reward: 532.59
               Mean episode length: 222.58
    Episode_Reward/reaching_object: 1.2166
    Episode_Reward/rotating_object: 106.5581
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 2.25s
                      Time elapsed: 00:17:32
                               ETA: 00:38:58

################################################################################
                     [1m Learning iteration 466/1500 [0m                      

                       Computation: 43055 steps/s (collection: 2.173s, learning 0.110s)
             Mean action noise std: 1.82
          Mean value_function loss: 114.4616
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.0635
                       Mean reward: 544.63
               Mean episode length: 228.01
    Episode_Reward/reaching_object: 1.2360
    Episode_Reward/rotating_object: 108.3554
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 2.28s
                      Time elapsed: 00:17:35
                               ETA: 00:38:56

################################################################################
                     [1m Learning iteration 467/1500 [0m                      

                       Computation: 43817 steps/s (collection: 2.131s, learning 0.113s)
             Mean action noise std: 1.82
          Mean value_function loss: 104.0479
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 52.0825
                       Mean reward: 503.04
               Mean episode length: 219.32
    Episode_Reward/reaching_object: 1.2150
    Episode_Reward/rotating_object: 106.3357
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 2.24s
                      Time elapsed: 00:17:37
                               ETA: 00:38:53

################################################################################
                     [1m Learning iteration 468/1500 [0m                      

                       Computation: 43302 steps/s (collection: 2.160s, learning 0.110s)
             Mean action noise std: 1.82
          Mean value_function loss: 102.9409
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 52.0960
                       Mean reward: 586.12
               Mean episode length: 233.32
    Episode_Reward/reaching_object: 1.2162
    Episode_Reward/rotating_object: 107.8943
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 2.27s
                      Time elapsed: 00:17:39
                               ETA: 00:38:51

################################################################################
                     [1m Learning iteration 469/1500 [0m                      

                       Computation: 43777 steps/s (collection: 2.132s, learning 0.113s)
             Mean action noise std: 1.82
          Mean value_function loss: 109.4508
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 52.1087
                       Mean reward: 561.49
               Mean episode length: 239.55
    Episode_Reward/reaching_object: 1.2304
    Episode_Reward/rotating_object: 106.4435
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 2.25s
                      Time elapsed: 00:17:41
                               ETA: 00:38:49

################################################################################
                     [1m Learning iteration 470/1500 [0m                      

                       Computation: 43794 steps/s (collection: 2.132s, learning 0.112s)
             Mean action noise std: 1.82
          Mean value_function loss: 98.1605
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 52.1267
                       Mean reward: 565.70
               Mean episode length: 237.89
    Episode_Reward/reaching_object: 1.2419
    Episode_Reward/rotating_object: 108.6034
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 2.24s
                      Time elapsed: 00:17:44
                               ETA: 00:38:47

################################################################################
                     [1m Learning iteration 471/1500 [0m                      

                       Computation: 44043 steps/s (collection: 2.119s, learning 0.113s)
             Mean action noise std: 1.83
          Mean value_function loss: 101.3479
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 52.1425
                       Mean reward: 590.11
               Mean episode length: 233.65
    Episode_Reward/reaching_object: 1.2361
    Episode_Reward/rotating_object: 109.9751
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 2.23s
                      Time elapsed: 00:17:46
                               ETA: 00:38:44

################################################################################
                     [1m Learning iteration 472/1500 [0m                      

                       Computation: 43840 steps/s (collection: 2.132s, learning 0.110s)
             Mean action noise std: 1.83
          Mean value_function loss: 87.0608
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 52.1575
                       Mean reward: 573.83
               Mean episode length: 235.61
    Episode_Reward/reaching_object: 1.2418
    Episode_Reward/rotating_object: 109.7428
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 2.24s
                      Time elapsed: 00:17:48
                               ETA: 00:38:42

################################################################################
                     [1m Learning iteration 473/1500 [0m                      

                       Computation: 43718 steps/s (collection: 2.134s, learning 0.114s)
             Mean action noise std: 1.83
          Mean value_function loss: 103.0882
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 52.1703
                       Mean reward: 527.83
               Mean episode length: 224.40
    Episode_Reward/reaching_object: 1.2270
    Episode_Reward/rotating_object: 109.8223
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 2.25s
                      Time elapsed: 00:17:50
                               ETA: 00:38:40

################################################################################
                     [1m Learning iteration 474/1500 [0m                      

                       Computation: 43617 steps/s (collection: 2.143s, learning 0.111s)
             Mean action noise std: 1.83
          Mean value_function loss: 97.2228
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 52.1833
                       Mean reward: 517.72
               Mean episode length: 225.59
    Episode_Reward/reaching_object: 1.2421
    Episode_Reward/rotating_object: 108.7009
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 2.25s
                      Time elapsed: 00:17:53
                               ETA: 00:38:37

################################################################################
                     [1m Learning iteration 475/1500 [0m                      

                       Computation: 42718 steps/s (collection: 2.176s, learning 0.125s)
             Mean action noise std: 1.83
          Mean value_function loss: 104.1283
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 52.1940
                       Mean reward: 550.38
               Mean episode length: 225.13
    Episode_Reward/reaching_object: 1.2464
    Episode_Reward/rotating_object: 111.5932
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 2.30s
                      Time elapsed: 00:17:55
                               ETA: 00:38:35

################################################################################
                     [1m Learning iteration 476/1500 [0m                      

                       Computation: 42827 steps/s (collection: 2.183s, learning 0.112s)
             Mean action noise std: 1.83
          Mean value_function loss: 97.0338
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 52.2071
                       Mean reward: 504.51
               Mean episode length: 222.56
    Episode_Reward/reaching_object: 1.2356
    Episode_Reward/rotating_object: 107.2088
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 2.30s
                      Time elapsed: 00:17:57
                               ETA: 00:38:33

################################################################################
                     [1m Learning iteration 477/1500 [0m                      

                       Computation: 43167 steps/s (collection: 2.166s, learning 0.111s)
             Mean action noise std: 1.83
          Mean value_function loss: 116.4372
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 52.2235
                       Mean reward: 525.96
               Mean episode length: 220.84
    Episode_Reward/reaching_object: 1.2232
    Episode_Reward/rotating_object: 108.4824
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 2.28s
                      Time elapsed: 00:17:59
                               ETA: 00:38:31

################################################################################
                     [1m Learning iteration 478/1500 [0m                      

                       Computation: 43357 steps/s (collection: 2.154s, learning 0.113s)
             Mean action noise std: 1.83
          Mean value_function loss: 112.3850
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.2430
                       Mean reward: 553.94
               Mean episode length: 229.32
    Episode_Reward/reaching_object: 1.2044
    Episode_Reward/rotating_object: 105.8808
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 2.27s
                      Time elapsed: 00:18:02
                               ETA: 00:38:29

################################################################################
                     [1m Learning iteration 479/1500 [0m                      

                       Computation: 44372 steps/s (collection: 2.105s, learning 0.111s)
             Mean action noise std: 1.84
          Mean value_function loss: 104.7734
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 52.2664
                       Mean reward: 519.06
               Mean episode length: 229.26
    Episode_Reward/reaching_object: 1.2206
    Episode_Reward/rotating_object: 107.0151
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 2.22s
                      Time elapsed: 00:18:04
                               ETA: 00:38:26

################################################################################
                     [1m Learning iteration 480/1500 [0m                      

                       Computation: 43850 steps/s (collection: 2.131s, learning 0.110s)
             Mean action noise std: 1.84
          Mean value_function loss: 114.1065
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 52.2891
                       Mean reward: 526.55
               Mean episode length: 222.38
    Episode_Reward/reaching_object: 1.2077
    Episode_Reward/rotating_object: 105.7557
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 2.24s
                      Time elapsed: 00:18:06
                               ETA: 00:38:24

################################################################################
                     [1m Learning iteration 481/1500 [0m                      

                       Computation: 44491 steps/s (collection: 2.099s, learning 0.111s)
             Mean action noise std: 1.84
          Mean value_function loss: 96.9859
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 52.3090
                       Mean reward: 556.35
               Mean episode length: 228.12
    Episode_Reward/reaching_object: 1.2532
    Episode_Reward/rotating_object: 114.8841
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 2.21s
                      Time elapsed: 00:18:08
                               ETA: 00:38:22

################################################################################
                     [1m Learning iteration 482/1500 [0m                      

                       Computation: 44912 steps/s (collection: 2.078s, learning 0.111s)
             Mean action noise std: 1.84
          Mean value_function loss: 81.5941
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 52.3312
                       Mean reward: 584.50
               Mean episode length: 233.06
    Episode_Reward/reaching_object: 1.2529
    Episode_Reward/rotating_object: 112.7392
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 2.19s
                      Time elapsed: 00:18:11
                               ETA: 00:38:19

################################################################################
                     [1m Learning iteration 483/1500 [0m                      

                       Computation: 44693 steps/s (collection: 2.089s, learning 0.111s)
             Mean action noise std: 1.84
          Mean value_function loss: 81.6625
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 52.3487
                       Mean reward: 561.08
               Mean episode length: 225.44
    Episode_Reward/reaching_object: 1.2465
    Episode_Reward/rotating_object: 111.3538
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 2.20s
                      Time elapsed: 00:18:13
                               ETA: 00:38:17

################################################################################
                     [1m Learning iteration 484/1500 [0m                      

                       Computation: 44635 steps/s (collection: 2.092s, learning 0.111s)
             Mean action noise std: 1.84
          Mean value_function loss: 85.7631
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 52.3537
                       Mean reward: 578.59
               Mean episode length: 229.85
    Episode_Reward/reaching_object: 1.2552
    Episode_Reward/rotating_object: 112.4468
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 2.20s
                      Time elapsed: 00:18:15
                               ETA: 00:38:14

################################################################################
                     [1m Learning iteration 485/1500 [0m                      

                       Computation: 44125 steps/s (collection: 2.117s, learning 0.111s)
             Mean action noise std: 1.84
          Mean value_function loss: 78.9587
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.3610
                       Mean reward: 541.63
               Mean episode length: 225.52
    Episode_Reward/reaching_object: 1.2326
    Episode_Reward/rotating_object: 111.0835
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 2.23s
                      Time elapsed: 00:18:17
                               ETA: 00:38:12

################################################################################
                     [1m Learning iteration 486/1500 [0m                      

                       Computation: 43979 steps/s (collection: 2.124s, learning 0.112s)
             Mean action noise std: 1.84
          Mean value_function loss: 94.6807
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 52.3776
                       Mean reward: 560.96
               Mean episode length: 230.77
    Episode_Reward/reaching_object: 1.2394
    Episode_Reward/rotating_object: 113.9191
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 2.24s
                      Time elapsed: 00:18:19
                               ETA: 00:38:10

################################################################################
                     [1m Learning iteration 487/1500 [0m                      

                       Computation: 43944 steps/s (collection: 2.122s, learning 0.115s)
             Mean action noise std: 1.85
          Mean value_function loss: 81.3889
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.3993
                       Mean reward: 568.10
               Mean episode length: 227.90
    Episode_Reward/reaching_object: 1.2316
    Episode_Reward/rotating_object: 114.0525
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 2.24s
                      Time elapsed: 00:18:22
                               ETA: 00:38:07

################################################################################
                     [1m Learning iteration 488/1500 [0m                      

                       Computation: 43474 steps/s (collection: 2.149s, learning 0.112s)
             Mean action noise std: 1.85
          Mean value_function loss: 77.2354
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.4229
                       Mean reward: 592.67
               Mean episode length: 234.79
    Episode_Reward/reaching_object: 1.2401
    Episode_Reward/rotating_object: 114.3498
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 2.26s
                      Time elapsed: 00:18:24
                               ETA: 00:38:05

################################################################################
                     [1m Learning iteration 489/1500 [0m                      

                       Computation: 43364 steps/s (collection: 2.154s, learning 0.113s)
             Mean action noise std: 1.85
          Mean value_function loss: 84.2237
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 52.4480
                       Mean reward: 589.41
               Mean episode length: 236.69
    Episode_Reward/reaching_object: 1.2628
    Episode_Reward/rotating_object: 114.4020
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 2.27s
                      Time elapsed: 00:18:26
                               ETA: 00:38:03

################################################################################
                     [1m Learning iteration 490/1500 [0m                      

                       Computation: 42690 steps/s (collection: 2.188s, learning 0.114s)
             Mean action noise std: 1.85
          Mean value_function loss: 88.1065
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 52.4648
                       Mean reward: 554.63
               Mean episode length: 228.77
    Episode_Reward/reaching_object: 1.2327
    Episode_Reward/rotating_object: 113.1570
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 2.30s
                      Time elapsed: 00:18:29
                               ETA: 00:38:01

################################################################################
                     [1m Learning iteration 491/1500 [0m                      

                       Computation: 42385 steps/s (collection: 2.207s, learning 0.112s)
             Mean action noise std: 1.85
          Mean value_function loss: 92.0666
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 52.4804
                       Mean reward: 560.13
               Mean episode length: 224.48
    Episode_Reward/reaching_object: 1.2212
    Episode_Reward/rotating_object: 111.8068
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 2.32s
                      Time elapsed: 00:18:31
                               ETA: 00:37:59

################################################################################
                     [1m Learning iteration 492/1500 [0m                      

                       Computation: 42358 steps/s (collection: 2.208s, learning 0.112s)
             Mean action noise std: 1.85
          Mean value_function loss: 94.7314
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 52.4967
                       Mean reward: 525.63
               Mean episode length: 219.25
    Episode_Reward/reaching_object: 1.1941
    Episode_Reward/rotating_object: 111.5904
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 2.32s
                      Time elapsed: 00:18:33
                               ETA: 00:37:57

################################################################################
                     [1m Learning iteration 493/1500 [0m                      

                       Computation: 43871 steps/s (collection: 2.130s, learning 0.111s)
             Mean action noise std: 1.85
          Mean value_function loss: 78.1331
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 52.5198
                       Mean reward: 597.88
               Mean episode length: 237.75
    Episode_Reward/reaching_object: 1.2319
    Episode_Reward/rotating_object: 113.6606
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 2.24s
                      Time elapsed: 00:18:35
                               ETA: 00:37:54

################################################################################
                     [1m Learning iteration 494/1500 [0m                      

                       Computation: 43961 steps/s (collection: 2.126s, learning 0.110s)
             Mean action noise std: 1.85
          Mean value_function loss: 89.4486
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 52.5360
                       Mean reward: 599.71
               Mean episode length: 231.34
    Episode_Reward/reaching_object: 1.2310
    Episode_Reward/rotating_object: 116.4422
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 2.24s
                      Time elapsed: 00:18:38
                               ETA: 00:37:52

################################################################################
                     [1m Learning iteration 495/1500 [0m                      

                       Computation: 43859 steps/s (collection: 2.129s, learning 0.113s)
             Mean action noise std: 1.86
          Mean value_function loss: 81.0828
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 52.5447
                       Mean reward: 565.57
               Mean episode length: 232.52
    Episode_Reward/reaching_object: 1.2380
    Episode_Reward/rotating_object: 114.2335
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 2.24s
                      Time elapsed: 00:18:40
                               ETA: 00:37:50

################################################################################
                     [1m Learning iteration 496/1500 [0m                      

                       Computation: 43241 steps/s (collection: 2.159s, learning 0.114s)
             Mean action noise std: 1.86
          Mean value_function loss: 87.3069
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 52.5575
                       Mean reward: 594.28
               Mean episode length: 236.78
    Episode_Reward/reaching_object: 1.2558
    Episode_Reward/rotating_object: 116.4818
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 2.27s
                      Time elapsed: 00:18:42
                               ETA: 00:37:47

################################################################################
                     [1m Learning iteration 497/1500 [0m                      

                       Computation: 43844 steps/s (collection: 2.131s, learning 0.111s)
             Mean action noise std: 1.86
          Mean value_function loss: 85.7130
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 52.5771
                       Mean reward: 567.64
               Mean episode length: 233.74
    Episode_Reward/reaching_object: 1.2303
    Episode_Reward/rotating_object: 113.9771
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 2.24s
                      Time elapsed: 00:18:44
                               ETA: 00:37:45

################################################################################
                     [1m Learning iteration 498/1500 [0m                      

                       Computation: 43735 steps/s (collection: 2.135s, learning 0.113s)
             Mean action noise std: 1.86
          Mean value_function loss: 83.7051
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 52.5941
                       Mean reward: 590.51
               Mean episode length: 236.82
    Episode_Reward/reaching_object: 1.2403
    Episode_Reward/rotating_object: 114.8681
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 2.25s
                      Time elapsed: 00:18:47
                               ETA: 00:37:43

################################################################################
                     [1m Learning iteration 499/1500 [0m                      

                       Computation: 43763 steps/s (collection: 2.134s, learning 0.113s)
             Mean action noise std: 1.86
          Mean value_function loss: 79.1258
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 52.6172
                       Mean reward: 613.53
               Mean episode length: 236.20
    Episode_Reward/reaching_object: 1.2442
    Episode_Reward/rotating_object: 115.6434
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 2.25s
                      Time elapsed: 00:18:49
                               ETA: 00:37:41

################################################################################
                     [1m Learning iteration 500/1500 [0m                      

                       Computation: 42976 steps/s (collection: 2.177s, learning 0.111s)
             Mean action noise std: 1.86
          Mean value_function loss: 83.8087
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 52.6369
                       Mean reward: 577.55
               Mean episode length: 232.05
    Episode_Reward/reaching_object: 1.2303
    Episode_Reward/rotating_object: 113.8834
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 2.29s
                      Time elapsed: 00:18:51
                               ETA: 00:37:38

################################################################################
                     [1m Learning iteration 501/1500 [0m                      

                       Computation: 44350 steps/s (collection: 2.106s, learning 0.111s)
             Mean action noise std: 1.86
          Mean value_function loss: 89.3057
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 52.6519
                       Mean reward: 598.78
               Mean episode length: 233.04
    Episode_Reward/reaching_object: 1.2414
    Episode_Reward/rotating_object: 118.0012
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 2.22s
                      Time elapsed: 00:18:53
                               ETA: 00:37:36

################################################################################
                     [1m Learning iteration 502/1500 [0m                      

                       Computation: 44685 steps/s (collection: 2.089s, learning 0.111s)
             Mean action noise std: 1.87
          Mean value_function loss: 104.0419
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 52.6654
                       Mean reward: 568.71
               Mean episode length: 228.43
    Episode_Reward/reaching_object: 1.2192
    Episode_Reward/rotating_object: 113.2435
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 2.20s
                      Time elapsed: 00:18:56
                               ETA: 00:37:34

################################################################################
                     [1m Learning iteration 503/1500 [0m                      

                       Computation: 44598 steps/s (collection: 2.093s, learning 0.111s)
             Mean action noise std: 1.87
          Mean value_function loss: 88.4460
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 52.6865
                       Mean reward: 572.74
               Mean episode length: 234.04
    Episode_Reward/reaching_object: 1.2335
    Episode_Reward/rotating_object: 114.7670
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 2.20s
                      Time elapsed: 00:18:58
                               ETA: 00:37:31

################################################################################
                     [1m Learning iteration 504/1500 [0m                      

                       Computation: 44635 steps/s (collection: 2.092s, learning 0.111s)
             Mean action noise std: 1.87
          Mean value_function loss: 94.2817
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 52.7078
                       Mean reward: 591.64
               Mean episode length: 238.18
    Episode_Reward/reaching_object: 1.2415
    Episode_Reward/rotating_object: 115.8036
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 2.20s
                      Time elapsed: 00:19:00
                               ETA: 00:37:29

################################################################################
                     [1m Learning iteration 505/1500 [0m                      

                       Computation: 44630 steps/s (collection: 2.089s, learning 0.114s)
             Mean action noise std: 1.87
          Mean value_function loss: 101.7392
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 52.7265
                       Mean reward: 552.75
               Mean episode length: 223.39
    Episode_Reward/reaching_object: 1.2270
    Episode_Reward/rotating_object: 111.5642
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 2.20s
                      Time elapsed: 00:19:02
                               ETA: 00:37:27

################################################################################
                     [1m Learning iteration 506/1500 [0m                      

                       Computation: 44471 steps/s (collection: 2.100s, learning 0.110s)
             Mean action noise std: 1.87
          Mean value_function loss: 94.4244
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 52.7424
                       Mean reward: 573.68
               Mean episode length: 238.45
    Episode_Reward/reaching_object: 1.2583
    Episode_Reward/rotating_object: 115.8723
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 2.21s
                      Time elapsed: 00:19:04
                               ETA: 00:37:24

################################################################################
                     [1m Learning iteration 507/1500 [0m                      

                       Computation: 44182 steps/s (collection: 2.114s, learning 0.111s)
             Mean action noise std: 1.87
          Mean value_function loss: 86.9214
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 52.7614
                       Mean reward: 581.28
               Mean episode length: 226.19
    Episode_Reward/reaching_object: 1.2317
    Episode_Reward/rotating_object: 112.5048
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 2.22s
                      Time elapsed: 00:19:07
                               ETA: 00:37:22

################################################################################
                     [1m Learning iteration 508/1500 [0m                      

                       Computation: 43977 steps/s (collection: 2.125s, learning 0.111s)
             Mean action noise std: 1.88
          Mean value_function loss: 105.1551
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 52.7819
                       Mean reward: 580.63
               Mean episode length: 231.15
    Episode_Reward/reaching_object: 1.2455
    Episode_Reward/rotating_object: 115.2761
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 2.24s
                      Time elapsed: 00:19:09
                               ETA: 00:37:20

################################################################################
                     [1m Learning iteration 509/1500 [0m                      

                       Computation: 43872 steps/s (collection: 2.128s, learning 0.113s)
             Mean action noise std: 1.88
          Mean value_function loss: 94.9909
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.8084
                       Mean reward: 610.70
               Mean episode length: 242.92
    Episode_Reward/reaching_object: 1.2583
    Episode_Reward/rotating_object: 113.4111
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 2.24s
                      Time elapsed: 00:19:11
                               ETA: 00:37:17

################################################################################
                     [1m Learning iteration 510/1500 [0m                      

                       Computation: 43835 steps/s (collection: 2.129s, learning 0.114s)
             Mean action noise std: 1.88
          Mean value_function loss: 93.3483
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 52.8291
                       Mean reward: 611.02
               Mean episode length: 234.57
    Episode_Reward/reaching_object: 1.2608
    Episode_Reward/rotating_object: 117.3782
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 2.24s
                      Time elapsed: 00:19:13
                               ETA: 00:37:15

################################################################################
                     [1m Learning iteration 511/1500 [0m                      

                       Computation: 43306 steps/s (collection: 2.155s, learning 0.115s)
             Mean action noise std: 1.88
          Mean value_function loss: 96.2608
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 52.8493
                       Mean reward: 583.18
               Mean episode length: 227.70
    Episode_Reward/reaching_object: 1.2444
    Episode_Reward/rotating_object: 115.4751
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 2.27s
                      Time elapsed: 00:19:16
                               ETA: 00:37:13

################################################################################
                     [1m Learning iteration 512/1500 [0m                      

                       Computation: 43603 steps/s (collection: 2.141s, learning 0.113s)
             Mean action noise std: 1.88
          Mean value_function loss: 90.0278
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 52.8693
                       Mean reward: 617.14
               Mean episode length: 238.35
    Episode_Reward/reaching_object: 1.2805
    Episode_Reward/rotating_object: 117.6277
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 2.25s
                      Time elapsed: 00:19:18
                               ETA: 00:37:10

################################################################################
                     [1m Learning iteration 513/1500 [0m                      

                       Computation: 43393 steps/s (collection: 2.153s, learning 0.113s)
             Mean action noise std: 1.88
          Mean value_function loss: 90.2011
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 52.8814
                       Mean reward: 581.13
               Mean episode length: 226.12
    Episode_Reward/reaching_object: 1.2553
    Episode_Reward/rotating_object: 115.2071
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 2.27s
                      Time elapsed: 00:19:20
                               ETA: 00:37:08

################################################################################
                     [1m Learning iteration 514/1500 [0m                      

                       Computation: 42668 steps/s (collection: 2.190s, learning 0.114s)
             Mean action noise std: 1.88
          Mean value_function loss: 96.9656
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 52.8979
                       Mean reward: 611.75
               Mean episode length: 233.50
    Episode_Reward/reaching_object: 1.2756
    Episode_Reward/rotating_object: 118.0360
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 2.30s
                      Time elapsed: 00:19:22
                               ETA: 00:37:06

################################################################################
                     [1m Learning iteration 515/1500 [0m                      

                       Computation: 40858 steps/s (collection: 2.278s, learning 0.128s)
             Mean action noise std: 1.89
          Mean value_function loss: 104.7860
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 52.9217
                       Mean reward: 554.50
               Mean episode length: 224.70
    Episode_Reward/reaching_object: 1.2285
    Episode_Reward/rotating_object: 112.3868
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 2.41s
                      Time elapsed: 00:19:25
                               ETA: 00:37:04

################################################################################
                     [1m Learning iteration 516/1500 [0m                      

                       Computation: 40634 steps/s (collection: 2.295s, learning 0.125s)
             Mean action noise std: 1.89
          Mean value_function loss: 103.5888
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 52.9444
                       Mean reward: 584.77
               Mean episode length: 231.33
    Episode_Reward/reaching_object: 1.2754
    Episode_Reward/rotating_object: 118.4329
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 2.42s
                      Time elapsed: 00:19:27
                               ETA: 00:37:02

################################################################################
                     [1m Learning iteration 517/1500 [0m                      

                       Computation: 43900 steps/s (collection: 2.128s, learning 0.111s)
             Mean action noise std: 1.89
          Mean value_function loss: 78.9021
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 52.9615
                       Mean reward: 586.05
               Mean episode length: 234.12
    Episode_Reward/reaching_object: 1.2305
    Episode_Reward/rotating_object: 109.5649
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 2.24s
                      Time elapsed: 00:19:30
                               ETA: 00:37:00

################################################################################
                     [1m Learning iteration 518/1500 [0m                      

                       Computation: 44009 steps/s (collection: 2.120s, learning 0.113s)
             Mean action noise std: 1.89
          Mean value_function loss: 79.5528
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 52.9724
                       Mean reward: 561.20
               Mean episode length: 220.38
    Episode_Reward/reaching_object: 1.2652
    Episode_Reward/rotating_object: 115.3432
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 2.23s
                      Time elapsed: 00:19:32
                               ETA: 00:36:58

################################################################################
                     [1m Learning iteration 519/1500 [0m                      

                       Computation: 44070 steps/s (collection: 2.117s, learning 0.114s)
             Mean action noise std: 1.89
          Mean value_function loss: 94.7846
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 52.9896
                       Mean reward: 588.89
               Mean episode length: 234.53
    Episode_Reward/reaching_object: 1.2657
    Episode_Reward/rotating_object: 118.2152
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 2.23s
                      Time elapsed: 00:19:34
                               ETA: 00:36:55

################################################################################
                     [1m Learning iteration 520/1500 [0m                      

                       Computation: 42997 steps/s (collection: 2.175s, learning 0.111s)
             Mean action noise std: 1.89
          Mean value_function loss: 83.0716
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 53.0168
                       Mean reward: 571.57
               Mean episode length: 229.66
    Episode_Reward/reaching_object: 1.2528
    Episode_Reward/rotating_object: 115.3288
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 2.29s
                      Time elapsed: 00:19:36
                               ETA: 00:36:53

################################################################################
                     [1m Learning iteration 521/1500 [0m                      

                       Computation: 40097 steps/s (collection: 2.338s, learning 0.113s)
             Mean action noise std: 1.90
          Mean value_function loss: 93.1904
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 53.0412
                       Mean reward: 596.68
               Mean episode length: 233.26
    Episode_Reward/reaching_object: 1.2483
    Episode_Reward/rotating_object: 117.2382
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 2.45s
                      Time elapsed: 00:19:39
                               ETA: 00:36:51

################################################################################
                     [1m Learning iteration 522/1500 [0m                      

                       Computation: 40625 steps/s (collection: 2.308s, learning 0.112s)
             Mean action noise std: 1.90
          Mean value_function loss: 76.0063
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 53.0649
                       Mean reward: 594.32
               Mean episode length: 230.59
    Episode_Reward/reaching_object: 1.2612
    Episode_Reward/rotating_object: 116.7729
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 2.42s
                      Time elapsed: 00:19:41
                               ETA: 00:36:49

################################################################################
                     [1m Learning iteration 523/1500 [0m                      

                       Computation: 40240 steps/s (collection: 2.332s, learning 0.111s)
             Mean action noise std: 1.90
          Mean value_function loss: 86.5516
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 53.0823
                       Mean reward: 594.00
               Mean episode length: 231.56
    Episode_Reward/reaching_object: 1.2567
    Episode_Reward/rotating_object: 117.7610
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 2.44s
                      Time elapsed: 00:19:44
                               ETA: 00:36:47

################################################################################
                     [1m Learning iteration 524/1500 [0m                      

                       Computation: 40426 steps/s (collection: 2.320s, learning 0.111s)
             Mean action noise std: 1.90
          Mean value_function loss: 92.8859
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 53.0983
                       Mean reward: 617.62
               Mean episode length: 237.13
    Episode_Reward/reaching_object: 1.2313
    Episode_Reward/rotating_object: 114.8891
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 2.43s
                      Time elapsed: 00:19:46
                               ETA: 00:36:45

################################################################################
                     [1m Learning iteration 525/1500 [0m                      

                       Computation: 39781 steps/s (collection: 2.361s, learning 0.110s)
             Mean action noise std: 1.90
          Mean value_function loss: 82.2241
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.1262
                       Mean reward: 631.68
               Mean episode length: 241.18
    Episode_Reward/reaching_object: 1.2517
    Episode_Reward/rotating_object: 117.5828
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 2.47s
                      Time elapsed: 00:19:48
                               ETA: 00:36:43

################################################################################
                     [1m Learning iteration 526/1500 [0m                      

                       Computation: 39552 steps/s (collection: 2.365s, learning 0.121s)
             Mean action noise std: 1.90
          Mean value_function loss: 92.6426
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 53.1526
                       Mean reward: 624.74
               Mean episode length: 239.69
    Episode_Reward/reaching_object: 1.2485
    Episode_Reward/rotating_object: 118.5763
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 2.49s
                      Time elapsed: 00:19:51
                               ETA: 00:36:42

################################################################################
                     [1m Learning iteration 527/1500 [0m                      

                       Computation: 40326 steps/s (collection: 2.326s, learning 0.112s)
             Mean action noise std: 1.91
          Mean value_function loss: 87.3863
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 53.1736
                       Mean reward: 605.15
               Mean episode length: 230.20
    Episode_Reward/reaching_object: 1.2518
    Episode_Reward/rotating_object: 120.1324
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 2.44s
                      Time elapsed: 00:19:53
                               ETA: 00:36:40

################################################################################
                     [1m Learning iteration 528/1500 [0m                      

                       Computation: 41029 steps/s (collection: 2.282s, learning 0.114s)
             Mean action noise std: 1.91
          Mean value_function loss: 97.1797
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 53.2019
                       Mean reward: 594.88
               Mean episode length: 233.89
    Episode_Reward/reaching_object: 1.2142
    Episode_Reward/rotating_object: 111.6910
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 2.40s
                      Time elapsed: 00:19:56
                               ETA: 00:36:38

################################################################################
                     [1m Learning iteration 529/1500 [0m                      

                       Computation: 42514 steps/s (collection: 2.198s, learning 0.114s)
             Mean action noise std: 1.91
          Mean value_function loss: 92.4498
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.2252
                       Mean reward: 602.73
               Mean episode length: 234.91
    Episode_Reward/reaching_object: 1.2413
    Episode_Reward/rotating_object: 116.7416
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 2.31s
                      Time elapsed: 00:19:58
                               ETA: 00:36:35

################################################################################
                     [1m Learning iteration 530/1500 [0m                      

                       Computation: 43622 steps/s (collection: 2.140s, learning 0.113s)
             Mean action noise std: 1.91
          Mean value_function loss: 96.8284
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 53.2526
                       Mean reward: 550.89
               Mean episode length: 226.04
    Episode_Reward/reaching_object: 1.2291
    Episode_Reward/rotating_object: 112.1153
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 2.25s
                      Time elapsed: 00:20:00
                               ETA: 00:36:33

################################################################################
                     [1m Learning iteration 531/1500 [0m                      

                       Computation: 43092 steps/s (collection: 2.169s, learning 0.113s)
             Mean action noise std: 1.91
          Mean value_function loss: 97.9700
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 53.2733
                       Mean reward: 589.09
               Mean episode length: 234.75
    Episode_Reward/reaching_object: 1.2476
    Episode_Reward/rotating_object: 115.3054
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 2.28s
                      Time elapsed: 00:20:03
                               ETA: 00:36:31

################################################################################
                     [1m Learning iteration 532/1500 [0m                      

                       Computation: 43382 steps/s (collection: 2.155s, learning 0.111s)
             Mean action noise std: 1.92
          Mean value_function loss: 94.2771
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.2933
                       Mean reward: 570.51
               Mean episode length: 226.96
    Episode_Reward/reaching_object: 1.2332
    Episode_Reward/rotating_object: 114.0484
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 2.27s
                      Time elapsed: 00:20:05
                               ETA: 00:36:29

################################################################################
                     [1m Learning iteration 533/1500 [0m                      

                       Computation: 43607 steps/s (collection: 2.143s, learning 0.111s)
             Mean action noise std: 1.92
          Mean value_function loss: 102.9127
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 53.3139
                       Mean reward: 571.83
               Mean episode length: 219.27
    Episode_Reward/reaching_object: 1.2307
    Episode_Reward/rotating_object: 115.0847
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 2.25s
                      Time elapsed: 00:20:07
                               ETA: 00:36:26

################################################################################
                     [1m Learning iteration 534/1500 [0m                      

                       Computation: 43711 steps/s (collection: 2.136s, learning 0.113s)
             Mean action noise std: 1.92
          Mean value_function loss: 95.4877
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 53.3398
                       Mean reward: 539.28
               Mean episode length: 225.07
    Episode_Reward/reaching_object: 1.2412
    Episode_Reward/rotating_object: 114.9055
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 2.25s
                      Time elapsed: 00:20:09
                               ETA: 00:36:24

################################################################################
                     [1m Learning iteration 535/1500 [0m                      

                       Computation: 43456 steps/s (collection: 2.147s, learning 0.116s)
             Mean action noise std: 1.92
          Mean value_function loss: 91.4095
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.3645
                       Mean reward: 581.18
               Mean episode length: 231.91
    Episode_Reward/reaching_object: 1.2572
    Episode_Reward/rotating_object: 116.1633
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 2.26s
                      Time elapsed: 00:20:12
                               ETA: 00:36:22

################################################################################
                     [1m Learning iteration 536/1500 [0m                      

                       Computation: 43613 steps/s (collection: 2.142s, learning 0.112s)
             Mean action noise std: 1.92
          Mean value_function loss: 84.8595
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 53.3855
                       Mean reward: 575.57
               Mean episode length: 231.95
    Episode_Reward/reaching_object: 1.2791
    Episode_Reward/rotating_object: 119.4661
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 2.25s
                      Time elapsed: 00:20:14
                               ETA: 00:36:20

################################################################################
                     [1m Learning iteration 537/1500 [0m                      

                       Computation: 43873 steps/s (collection: 2.128s, learning 0.112s)
             Mean action noise std: 1.93
          Mean value_function loss: 88.1945
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 53.4118
                       Mean reward: 594.53
               Mean episode length: 233.27
    Episode_Reward/reaching_object: 1.2516
    Episode_Reward/rotating_object: 117.0937
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 2.24s
                      Time elapsed: 00:20:16
                               ETA: 00:36:17

################################################################################
                     [1m Learning iteration 538/1500 [0m                      

                       Computation: 43759 steps/s (collection: 2.134s, learning 0.113s)
             Mean action noise std: 1.93
          Mean value_function loss: 75.4770
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.4416
                       Mean reward: 606.85
               Mean episode length: 236.78
    Episode_Reward/reaching_object: 1.2831
    Episode_Reward/rotating_object: 121.7704
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 2.25s
                      Time elapsed: 00:20:18
                               ETA: 00:36:15

################################################################################
                     [1m Learning iteration 539/1500 [0m                      

                       Computation: 44038 steps/s (collection: 2.118s, learning 0.114s)
             Mean action noise std: 1.93
          Mean value_function loss: 86.0077
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.4569
                       Mean reward: 565.55
               Mean episode length: 228.88
    Episode_Reward/reaching_object: 1.2520
    Episode_Reward/rotating_object: 117.9903
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 2.23s
                      Time elapsed: 00:20:21
                               ETA: 00:36:13

################################################################################
                     [1m Learning iteration 540/1500 [0m                      

                       Computation: 44210 steps/s (collection: 2.111s, learning 0.112s)
             Mean action noise std: 1.93
          Mean value_function loss: 88.4489
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 53.4718
                       Mean reward: 591.04
               Mean episode length: 230.20
    Episode_Reward/reaching_object: 1.2435
    Episode_Reward/rotating_object: 120.1958
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 2.22s
                      Time elapsed: 00:20:23
                               ETA: 00:36:10

################################################################################
                     [1m Learning iteration 541/1500 [0m                      

                       Computation: 43626 steps/s (collection: 2.137s, learning 0.116s)
             Mean action noise std: 1.93
          Mean value_function loss: 71.5441
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.4916
                       Mean reward: 633.29
               Mean episode length: 240.84
    Episode_Reward/reaching_object: 1.2712
    Episode_Reward/rotating_object: 122.3283
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 2.25s
                      Time elapsed: 00:20:25
                               ETA: 00:36:08

################################################################################
                     [1m Learning iteration 542/1500 [0m                      

                       Computation: 43731 steps/s (collection: 2.137s, learning 0.111s)
             Mean action noise std: 1.93
          Mean value_function loss: 76.5454
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 53.5121
                       Mean reward: 562.66
               Mean episode length: 220.77
    Episode_Reward/reaching_object: 1.2371
    Episode_Reward/rotating_object: 116.1409
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 2.25s
                      Time elapsed: 00:20:27
                               ETA: 00:36:06

################################################################################
                     [1m Learning iteration 543/1500 [0m                      

                       Computation: 44548 steps/s (collection: 2.095s, learning 0.111s)
             Mean action noise std: 1.93
          Mean value_function loss: 81.6608
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 53.5367
                       Mean reward: 600.75
               Mean episode length: 231.01
    Episode_Reward/reaching_object: 1.2507
    Episode_Reward/rotating_object: 122.2349
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 2.21s
                      Time elapsed: 00:20:30
                               ETA: 00:36:03

################################################################################
                     [1m Learning iteration 544/1500 [0m                      

                       Computation: 44335 steps/s (collection: 2.106s, learning 0.111s)
             Mean action noise std: 1.94
          Mean value_function loss: 93.5945
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 53.5558
                       Mean reward: 574.69
               Mean episode length: 219.65
    Episode_Reward/reaching_object: 1.2179
    Episode_Reward/rotating_object: 117.8125
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 2.22s
                      Time elapsed: 00:20:32
                               ETA: 00:36:01

################################################################################
                     [1m Learning iteration 545/1500 [0m                      

                       Computation: 44698 steps/s (collection: 2.088s, learning 0.111s)
             Mean action noise std: 1.94
          Mean value_function loss: 86.1517
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 53.5708
                       Mean reward: 597.14
               Mean episode length: 230.82
    Episode_Reward/reaching_object: 1.2440
    Episode_Reward/rotating_object: 119.4087
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 2.20s
                      Time elapsed: 00:20:34
                               ETA: 00:35:59

################################################################################
                     [1m Learning iteration 546/1500 [0m                      

                       Computation: 45076 steps/s (collection: 2.069s, learning 0.112s)
             Mean action noise std: 1.94
          Mean value_function loss: 78.1831
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 53.5794
                       Mean reward: 581.07
               Mean episode length: 224.58
    Episode_Reward/reaching_object: 1.2306
    Episode_Reward/rotating_object: 118.3878
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 2.18s
                      Time elapsed: 00:20:36
                               ETA: 00:35:56

################################################################################
                     [1m Learning iteration 547/1500 [0m                      

                       Computation: 45037 steps/s (collection: 2.072s, learning 0.111s)
             Mean action noise std: 1.94
          Mean value_function loss: 79.7365
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 53.6055
                       Mean reward: 599.17
               Mean episode length: 228.65
    Episode_Reward/reaching_object: 1.2461
    Episode_Reward/rotating_object: 121.0664
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 2.18s
                      Time elapsed: 00:20:38
                               ETA: 00:35:54

################################################################################
                     [1m Learning iteration 548/1500 [0m                      

                       Computation: 45144 steps/s (collection: 2.067s, learning 0.111s)
             Mean action noise std: 1.94
          Mean value_function loss: 76.7136
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 53.6318
                       Mean reward: 591.85
               Mean episode length: 227.02
    Episode_Reward/reaching_object: 1.2579
    Episode_Reward/rotating_object: 120.6980
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 2.18s
                      Time elapsed: 00:20:41
                               ETA: 00:35:52

################################################################################
                     [1m Learning iteration 549/1500 [0m                      

                       Computation: 44494 steps/s (collection: 2.098s, learning 0.111s)
             Mean action noise std: 1.94
          Mean value_function loss: 64.2618
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 53.6554
                       Mean reward: 586.51
               Mean episode length: 226.83
    Episode_Reward/reaching_object: 1.2388
    Episode_Reward/rotating_object: 119.5253
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 2.21s
                      Time elapsed: 00:20:43
                               ETA: 00:35:49

################################################################################
                     [1m Learning iteration 550/1500 [0m                      

                       Computation: 43598 steps/s (collection: 2.141s, learning 0.114s)
             Mean action noise std: 1.95
          Mean value_function loss: 72.1684
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 53.6827
                       Mean reward: 599.00
               Mean episode length: 233.08
    Episode_Reward/reaching_object: 1.2469
    Episode_Reward/rotating_object: 122.9812
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 2.25s
                      Time elapsed: 00:20:45
                               ETA: 00:35:47

################################################################################
                     [1m Learning iteration 551/1500 [0m                      

                       Computation: 44329 steps/s (collection: 2.103s, learning 0.115s)
             Mean action noise std: 1.95
          Mean value_function loss: 72.5238
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.7232
                       Mean reward: 586.44
               Mean episode length: 223.37
    Episode_Reward/reaching_object: 1.2138
    Episode_Reward/rotating_object: 117.8147
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 2.22s
                      Time elapsed: 00:20:47
                               ETA: 00:35:45

################################################################################
                     [1m Learning iteration 552/1500 [0m                      

                       Computation: 44364 steps/s (collection: 2.104s, learning 0.112s)
             Mean action noise std: 1.95
          Mean value_function loss: 75.1162
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 53.7536
                       Mean reward: 617.63
               Mean episode length: 234.75
    Episode_Reward/reaching_object: 1.2574
    Episode_Reward/rotating_object: 125.8722
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 2.22s
                      Time elapsed: 00:20:49
                               ETA: 00:35:42

################################################################################
                     [1m Learning iteration 553/1500 [0m                      

                       Computation: 44350 steps/s (collection: 2.102s, learning 0.114s)
             Mean action noise std: 1.95
          Mean value_function loss: 68.2237
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.7814
                       Mean reward: 637.65
               Mean episode length: 237.74
    Episode_Reward/reaching_object: 1.2222
    Episode_Reward/rotating_object: 118.7945
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 2.22s
                      Time elapsed: 00:20:52
                               ETA: 00:35:40

################################################################################
                     [1m Learning iteration 554/1500 [0m                      

                       Computation: 44662 steps/s (collection: 2.089s, learning 0.112s)
             Mean action noise std: 1.96
          Mean value_function loss: 74.2146
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 53.8054
                       Mean reward: 588.57
               Mean episode length: 228.43
    Episode_Reward/reaching_object: 1.2468
    Episode_Reward/rotating_object: 123.8979
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 2.20s
                      Time elapsed: 00:20:54
                               ETA: 00:35:38

################################################################################
                     [1m Learning iteration 555/1500 [0m                      

                       Computation: 44544 steps/s (collection: 2.091s, learning 0.115s)
             Mean action noise std: 1.96
          Mean value_function loss: 78.0068
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 53.8237
                       Mean reward: 587.68
               Mean episode length: 235.72
    Episode_Reward/reaching_object: 1.2200
    Episode_Reward/rotating_object: 118.2835
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 2.21s
                      Time elapsed: 00:20:56
                               ETA: 00:35:35

################################################################################
                     [1m Learning iteration 556/1500 [0m                      

                       Computation: 44112 steps/s (collection: 2.117s, learning 0.111s)
             Mean action noise std: 1.96
          Mean value_function loss: 82.1846
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 53.8427
                       Mean reward: 592.95
               Mean episode length: 230.11
    Episode_Reward/reaching_object: 1.2170
    Episode_Reward/rotating_object: 120.4416
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 2.23s
                      Time elapsed: 00:20:58
                               ETA: 00:35:33

################################################################################
                     [1m Learning iteration 557/1500 [0m                      

                       Computation: 44236 steps/s (collection: 2.109s, learning 0.113s)
             Mean action noise std: 1.96
          Mean value_function loss: 82.6698
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 53.8586
                       Mean reward: 571.56
               Mean episode length: 228.23
    Episode_Reward/reaching_object: 1.2078
    Episode_Reward/rotating_object: 116.4833
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 2.22s
                      Time elapsed: 00:21:01
                               ETA: 00:35:31

################################################################################
                     [1m Learning iteration 558/1500 [0m                      

                       Computation: 43749 steps/s (collection: 2.119s, learning 0.128s)
             Mean action noise std: 1.96
          Mean value_function loss: 84.5037
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.8800
                       Mean reward: 624.85
               Mean episode length: 230.50
    Episode_Reward/reaching_object: 1.2149
    Episode_Reward/rotating_object: 119.9158
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 2.25s
                      Time elapsed: 00:21:03
                               ETA: 00:35:28

################################################################################
                     [1m Learning iteration 559/1500 [0m                      

                       Computation: 43328 steps/s (collection: 2.155s, learning 0.114s)
             Mean action noise std: 1.96
          Mean value_function loss: 88.4904
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.9032
                       Mean reward: 585.28
               Mean episode length: 227.44
    Episode_Reward/reaching_object: 1.2165
    Episode_Reward/rotating_object: 117.6776
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 2.27s
                      Time elapsed: 00:21:05
                               ETA: 00:35:26

################################################################################
                     [1m Learning iteration 560/1500 [0m                      

                       Computation: 43037 steps/s (collection: 2.166s, learning 0.119s)
             Mean action noise std: 1.97
          Mean value_function loss: 94.2707
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 53.9277
                       Mean reward: 558.81
               Mean episode length: 222.87
    Episode_Reward/reaching_object: 1.2094
    Episode_Reward/rotating_object: 118.6143
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 2.28s
                      Time elapsed: 00:21:07
                               ETA: 00:35:24

################################################################################
                     [1m Learning iteration 561/1500 [0m                      

                       Computation: 43098 steps/s (collection: 2.161s, learning 0.120s)
             Mean action noise std: 1.97
          Mean value_function loss: 81.9188
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 53.9535
                       Mean reward: 642.96
               Mean episode length: 240.21
    Episode_Reward/reaching_object: 1.2398
    Episode_Reward/rotating_object: 120.5440
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 2.28s
                      Time elapsed: 00:21:10
                               ETA: 00:35:22

################################################################################
                     [1m Learning iteration 562/1500 [0m                      

                       Computation: 43097 steps/s (collection: 2.168s, learning 0.113s)
             Mean action noise std: 1.97
          Mean value_function loss: 95.6814
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 53.9757
                       Mean reward: 637.80
               Mean episode length: 234.82
    Episode_Reward/reaching_object: 1.2302
    Episode_Reward/rotating_object: 120.0300
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 2.28s
                      Time elapsed: 00:21:12
                               ETA: 00:35:19

################################################################################
                     [1m Learning iteration 563/1500 [0m                      

                       Computation: 43995 steps/s (collection: 2.124s, learning 0.110s)
             Mean action noise std: 1.97
          Mean value_function loss: 77.5058
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 54.0082
                       Mean reward: 598.17
               Mean episode length: 234.52
    Episode_Reward/reaching_object: 1.2586
    Episode_Reward/rotating_object: 123.5901
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 2.23s
                      Time elapsed: 00:21:14
                               ETA: 00:35:17

################################################################################
                     [1m Learning iteration 564/1500 [0m                      

                       Computation: 44170 steps/s (collection: 2.115s, learning 0.111s)
             Mean action noise std: 1.97
          Mean value_function loss: 81.7318
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 54.0298
                       Mean reward: 603.36
               Mean episode length: 226.30
    Episode_Reward/reaching_object: 1.2443
    Episode_Reward/rotating_object: 122.0050
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 2.23s
                      Time elapsed: 00:21:16
                               ETA: 00:35:15

################################################################################
                     [1m Learning iteration 565/1500 [0m                      

                       Computation: 45156 steps/s (collection: 2.067s, learning 0.110s)
             Mean action noise std: 1.98
          Mean value_function loss: 85.5895
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 54.0524
                       Mean reward: 612.44
               Mean episode length: 233.02
    Episode_Reward/reaching_object: 1.2293
    Episode_Reward/rotating_object: 117.1806
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 2.18s
                      Time elapsed: 00:21:19
                               ETA: 00:35:12

################################################################################
                     [1m Learning iteration 566/1500 [0m                      

                       Computation: 45061 steps/s (collection: 2.071s, learning 0.111s)
             Mean action noise std: 1.98
          Mean value_function loss: 92.0935
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 54.0726
                       Mean reward: 619.60
               Mean episode length: 236.29
    Episode_Reward/reaching_object: 1.2387
    Episode_Reward/rotating_object: 120.0962
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 2.18s
                      Time elapsed: 00:21:21
                               ETA: 00:35:10

################################################################################
                     [1m Learning iteration 567/1500 [0m                      

                       Computation: 44767 steps/s (collection: 2.085s, learning 0.111s)
             Mean action noise std: 1.98
          Mean value_function loss: 91.8665
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 54.0997
                       Mean reward: 622.87
               Mean episode length: 231.30
    Episode_Reward/reaching_object: 1.2319
    Episode_Reward/rotating_object: 120.6212
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 2.20s
                      Time elapsed: 00:21:23
                               ETA: 00:35:08

################################################################################
                     [1m Learning iteration 568/1500 [0m                      

                       Computation: 45028 steps/s (collection: 2.073s, learning 0.110s)
             Mean action noise std: 1.98
          Mean value_function loss: 101.1125
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 54.1219
                       Mean reward: 611.75
               Mean episode length: 231.02
    Episode_Reward/reaching_object: 1.2184
    Episode_Reward/rotating_object: 117.6688
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 2.18s
                      Time elapsed: 00:21:25
                               ETA: 00:35:05

################################################################################
                     [1m Learning iteration 569/1500 [0m                      

                       Computation: 44879 steps/s (collection: 2.080s, learning 0.110s)
             Mean action noise std: 1.98
          Mean value_function loss: 85.2893
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 54.1489
                       Mean reward: 613.49
               Mean episode length: 237.03
    Episode_Reward/reaching_object: 1.2664
    Episode_Reward/rotating_object: 121.5797
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 2.19s
                      Time elapsed: 00:21:27
                               ETA: 00:35:03

################################################################################
                     [1m Learning iteration 570/1500 [0m                      

                       Computation: 44935 steps/s (collection: 2.077s, learning 0.110s)
             Mean action noise std: 1.99
          Mean value_function loss: 82.5036
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 54.1800
                       Mean reward: 619.90
               Mean episode length: 238.21
    Episode_Reward/reaching_object: 1.2557
    Episode_Reward/rotating_object: 121.8363
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 2.19s
                      Time elapsed: 00:21:29
                               ETA: 00:35:00

################################################################################
                     [1m Learning iteration 571/1500 [0m                      

                       Computation: 44760 steps/s (collection: 2.085s, learning 0.111s)
             Mean action noise std: 1.99
          Mean value_function loss: 79.1711
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 54.2187
                       Mean reward: 589.42
               Mean episode length: 231.26
    Episode_Reward/reaching_object: 1.2454
    Episode_Reward/rotating_object: 119.2865
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 2.20s
                      Time elapsed: 00:21:32
                               ETA: 00:34:58

################################################################################
                     [1m Learning iteration 572/1500 [0m                      

                       Computation: 44169 steps/s (collection: 2.112s, learning 0.114s)
             Mean action noise std: 1.99
          Mean value_function loss: 83.7774
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.2421
                       Mean reward: 613.51
               Mean episode length: 234.37
    Episode_Reward/reaching_object: 1.2374
    Episode_Reward/rotating_object: 121.6108
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 2.23s
                      Time elapsed: 00:21:34
                               ETA: 00:34:56

################################################################################
                     [1m Learning iteration 573/1500 [0m                      

                       Computation: 43244 steps/s (collection: 2.159s, learning 0.114s)
             Mean action noise std: 1.99
          Mean value_function loss: 86.5492
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 54.2698
                       Mean reward: 614.31
               Mean episode length: 230.23
    Episode_Reward/reaching_object: 1.2535
    Episode_Reward/rotating_object: 121.9324
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 2.27s
                      Time elapsed: 00:21:36
                               ETA: 00:34:54

################################################################################
                     [1m Learning iteration 574/1500 [0m                      

                       Computation: 44316 steps/s (collection: 2.104s, learning 0.114s)
             Mean action noise std: 2.00
          Mean value_function loss: 89.6928
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 54.2912
                       Mean reward: 623.01
               Mean episode length: 238.01
    Episode_Reward/reaching_object: 1.2281
    Episode_Reward/rotating_object: 117.7556
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 2.22s
                      Time elapsed: 00:21:38
                               ETA: 00:34:51

################################################################################
                     [1m Learning iteration 575/1500 [0m                      

                       Computation: 43706 steps/s (collection: 2.135s, learning 0.114s)
             Mean action noise std: 2.00
          Mean value_function loss: 79.1210
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 54.3220
                       Mean reward: 624.00
               Mean episode length: 231.87
    Episode_Reward/reaching_object: 1.2364
    Episode_Reward/rotating_object: 120.6236
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 2.25s
                      Time elapsed: 00:21:41
                               ETA: 00:34:49

################################################################################
                     [1m Learning iteration 576/1500 [0m                      

                       Computation: 40665 steps/s (collection: 2.306s, learning 0.111s)
             Mean action noise std: 2.00
          Mean value_function loss: 84.4302
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.3528
                       Mean reward: 644.32
               Mean episode length: 238.74
    Episode_Reward/reaching_object: 1.2520
    Episode_Reward/rotating_object: 120.4929
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 2.42s
                      Time elapsed: 00:21:43
                               ETA: 00:34:47

################################################################################
                     [1m Learning iteration 577/1500 [0m                      

                       Computation: 39931 steps/s (collection: 2.349s, learning 0.113s)
             Mean action noise std: 2.00
          Mean value_function loss: 80.3202
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 54.3793
                       Mean reward: 652.90
               Mean episode length: 240.21
    Episode_Reward/reaching_object: 1.2317
    Episode_Reward/rotating_object: 119.2269
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 2.46s
                      Time elapsed: 00:21:45
                               ETA: 00:34:45

################################################################################
                     [1m Learning iteration 578/1500 [0m                      

                       Computation: 42500 steps/s (collection: 2.201s, learning 0.112s)
             Mean action noise std: 2.01
          Mean value_function loss: 91.2867
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 54.4020
                       Mean reward: 608.56
               Mean episode length: 228.92
    Episode_Reward/reaching_object: 1.2518
    Episode_Reward/rotating_object: 120.3248
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 2.31s
                      Time elapsed: 00:21:48
                               ETA: 00:34:43

################################################################################
                     [1m Learning iteration 579/1500 [0m                      

                       Computation: 44239 steps/s (collection: 2.108s, learning 0.114s)
             Mean action noise std: 2.01
          Mean value_function loss: 90.0104
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 54.4271
                       Mean reward: 653.35
               Mean episode length: 240.56
    Episode_Reward/reaching_object: 1.2769
    Episode_Reward/rotating_object: 126.6322
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 2.22s
                      Time elapsed: 00:21:50
                               ETA: 00:34:41

################################################################################
                     [1m Learning iteration 580/1500 [0m                      

                       Computation: 44202 steps/s (collection: 2.110s, learning 0.114s)
             Mean action noise std: 2.01
          Mean value_function loss: 81.2289
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 54.4583
                       Mean reward: 642.18
               Mean episode length: 233.63
    Episode_Reward/reaching_object: 1.2528
    Episode_Reward/rotating_object: 123.0457
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 2.22s
                      Time elapsed: 00:21:52
                               ETA: 00:34:38

################################################################################
                     [1m Learning iteration 581/1500 [0m                      

                       Computation: 44197 steps/s (collection: 2.110s, learning 0.114s)
             Mean action noise std: 2.01
          Mean value_function loss: 73.6530
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 54.4830
                       Mean reward: 624.68
               Mean episode length: 233.61
    Episode_Reward/reaching_object: 1.2706
    Episode_Reward/rotating_object: 124.7399
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 2.22s
                      Time elapsed: 00:21:54
                               ETA: 00:34:36

################################################################################
                     [1m Learning iteration 582/1500 [0m                      

                       Computation: 44518 steps/s (collection: 2.095s, learning 0.113s)
             Mean action noise std: 2.02
          Mean value_function loss: 74.3962
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 54.5145
                       Mean reward: 631.29
               Mean episode length: 237.07
    Episode_Reward/reaching_object: 1.2623
    Episode_Reward/rotating_object: 121.2223
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 2.21s
                      Time elapsed: 00:21:57
                               ETA: 00:34:34

################################################################################
                     [1m Learning iteration 583/1500 [0m                      

                       Computation: 44593 steps/s (collection: 2.094s, learning 0.111s)
             Mean action noise std: 2.02
          Mean value_function loss: 88.7391
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 54.5416
                       Mean reward: 612.34
               Mean episode length: 230.29
    Episode_Reward/reaching_object: 1.2646
    Episode_Reward/rotating_object: 126.5644
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 2.20s
                      Time elapsed: 00:21:59
                               ETA: 00:34:31

################################################################################
                     [1m Learning iteration 584/1500 [0m                      

                       Computation: 44297 steps/s (collection: 2.106s, learning 0.113s)
             Mean action noise std: 2.02
          Mean value_function loss: 81.5851
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 54.5706
                       Mean reward: 614.80
               Mean episode length: 227.11
    Episode_Reward/reaching_object: 1.2328
    Episode_Reward/rotating_object: 125.2234
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 2.22s
                      Time elapsed: 00:22:01
                               ETA: 00:34:29

################################################################################
                     [1m Learning iteration 585/1500 [0m                      

                       Computation: 44165 steps/s (collection: 2.115s, learning 0.111s)
             Mean action noise std: 2.02
          Mean value_function loss: 84.2978
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 54.5969
                       Mean reward: 604.33
               Mean episode length: 237.08
    Episode_Reward/reaching_object: 1.2591
    Episode_Reward/rotating_object: 122.1681
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 2.23s
                      Time elapsed: 00:22:03
                               ETA: 00:34:27

################################################################################
                     [1m Learning iteration 586/1500 [0m                      

                       Computation: 44246 steps/s (collection: 2.111s, learning 0.111s)
             Mean action noise std: 2.02
          Mean value_function loss: 79.4826
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 54.6241
                       Mean reward: 632.08
               Mean episode length: 235.79
    Episode_Reward/reaching_object: 1.2541
    Episode_Reward/rotating_object: 123.1065
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 2.22s
                      Time elapsed: 00:22:06
                               ETA: 00:34:24

################################################################################
                     [1m Learning iteration 587/1500 [0m                      

                       Computation: 45017 steps/s (collection: 2.073s, learning 0.111s)
             Mean action noise std: 2.03
          Mean value_function loss: 83.0484
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 54.6529
                       Mean reward: 604.50
               Mean episode length: 234.53
    Episode_Reward/reaching_object: 1.2617
    Episode_Reward/rotating_object: 123.2465
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 2.18s
                      Time elapsed: 00:22:08
                               ETA: 00:34:22

################################################################################
                     [1m Learning iteration 588/1500 [0m                      

                       Computation: 45224 steps/s (collection: 2.063s, learning 0.110s)
             Mean action noise std: 2.03
          Mean value_function loss: 84.1646
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 54.6786
                       Mean reward: 603.15
               Mean episode length: 230.93
    Episode_Reward/reaching_object: 1.2456
    Episode_Reward/rotating_object: 122.8488
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 2.17s
                      Time elapsed: 00:22:10
                               ETA: 00:34:19

################################################################################
                     [1m Learning iteration 589/1500 [0m                      

                       Computation: 45185 steps/s (collection: 2.065s, learning 0.110s)
             Mean action noise std: 2.03
          Mean value_function loss: 92.0273
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 54.7058
                       Mean reward: 620.65
               Mean episode length: 235.93
    Episode_Reward/reaching_object: 1.2554
    Episode_Reward/rotating_object: 124.1243
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 2.18s
                      Time elapsed: 00:22:12
                               ETA: 00:34:17

################################################################################
                     [1m Learning iteration 590/1500 [0m                      

                       Computation: 45144 steps/s (collection: 2.067s, learning 0.110s)
             Mean action noise std: 2.03
          Mean value_function loss: 75.2656
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 54.7302
                       Mean reward: 628.45
               Mean episode length: 235.46
    Episode_Reward/reaching_object: 1.2339
    Episode_Reward/rotating_object: 121.5295
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 2.18s
                      Time elapsed: 00:22:14
                               ETA: 00:34:15

################################################################################
                     [1m Learning iteration 591/1500 [0m                      

                       Computation: 45126 steps/s (collection: 2.068s, learning 0.110s)
             Mean action noise std: 2.04
          Mean value_function loss: 85.7529
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 54.7532
                       Mean reward: 643.39
               Mean episode length: 234.92
    Episode_Reward/reaching_object: 1.2546
    Episode_Reward/rotating_object: 124.2253
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 2.18s
                      Time elapsed: 00:22:16
                               ETA: 00:34:12

################################################################################
                     [1m Learning iteration 592/1500 [0m                      

                       Computation: 45143 steps/s (collection: 2.064s, learning 0.114s)
             Mean action noise std: 2.04
          Mean value_function loss: 86.9965
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 54.7824
                       Mean reward: 592.74
               Mean episode length: 224.78
    Episode_Reward/reaching_object: 1.2146
    Episode_Reward/rotating_object: 117.4697
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 2.18s
                      Time elapsed: 00:22:19
                               ETA: 00:34:10

################################################################################
                     [1m Learning iteration 593/1500 [0m                      

                       Computation: 44640 steps/s (collection: 2.089s, learning 0.113s)
             Mean action noise std: 2.04
          Mean value_function loss: 83.2624
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.8022
                       Mean reward: 620.65
               Mean episode length: 231.68
    Episode_Reward/reaching_object: 1.2375
    Episode_Reward/rotating_object: 123.8469
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 2.20s
                      Time elapsed: 00:22:21
                               ETA: 00:34:08

################################################################################
                     [1m Learning iteration 594/1500 [0m                      

                       Computation: 42997 steps/s (collection: 2.172s, learning 0.114s)
             Mean action noise std: 2.04
          Mean value_function loss: 80.6889
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 54.8221
                       Mean reward: 635.30
               Mean episode length: 233.64
    Episode_Reward/reaching_object: 1.2435
    Episode_Reward/rotating_object: 119.4856
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 2.29s
                      Time elapsed: 00:22:23
                               ETA: 00:34:05

################################################################################
                     [1m Learning iteration 595/1500 [0m                      

                       Computation: 43676 steps/s (collection: 2.135s, learning 0.115s)
             Mean action noise std: 2.04
          Mean value_function loss: 78.9060
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 54.8462
                       Mean reward: 605.22
               Mean episode length: 228.04
    Episode_Reward/reaching_object: 1.2325
    Episode_Reward/rotating_object: 121.4436
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 2.25s
                      Time elapsed: 00:22:25
                               ETA: 00:34:03

################################################################################
                     [1m Learning iteration 596/1500 [0m                      

                       Computation: 42574 steps/s (collection: 2.179s, learning 0.130s)
             Mean action noise std: 2.05
          Mean value_function loss: 80.3538
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 54.8768
                       Mean reward: 636.96
               Mean episode length: 241.82
    Episode_Reward/reaching_object: 1.2345
    Episode_Reward/rotating_object: 121.0719
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 2.31s
                      Time elapsed: 00:22:28
                               ETA: 00:34:01

################################################################################
                     [1m Learning iteration 597/1500 [0m                      

                       Computation: 43427 steps/s (collection: 2.153s, learning 0.111s)
             Mean action noise std: 2.05
          Mean value_function loss: 79.0381
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 54.9090
                       Mean reward: 654.24
               Mean episode length: 239.18
    Episode_Reward/reaching_object: 1.2295
    Episode_Reward/rotating_object: 121.0050
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 2.26s
                      Time elapsed: 00:22:30
                               ETA: 00:33:59

################################################################################
                     [1m Learning iteration 598/1500 [0m                      

                       Computation: 43988 steps/s (collection: 2.124s, learning 0.111s)
             Mean action noise std: 2.05
          Mean value_function loss: 86.8308
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 54.9387
                       Mean reward: 618.28
               Mean episode length: 235.25
    Episode_Reward/reaching_object: 1.2495
    Episode_Reward/rotating_object: 123.3793
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 2.23s
                      Time elapsed: 00:22:32
                               ETA: 00:33:56

################################################################################
                     [1m Learning iteration 599/1500 [0m                      

                       Computation: 44797 steps/s (collection: 2.082s, learning 0.113s)
             Mean action noise std: 2.05
          Mean value_function loss: 82.0845
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 54.9688
                       Mean reward: 599.26
               Mean episode length: 230.86
    Episode_Reward/reaching_object: 1.2307
    Episode_Reward/rotating_object: 121.7579
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 2.19s
                      Time elapsed: 00:22:34
                               ETA: 00:33:54

################################################################################
                     [1m Learning iteration 600/1500 [0m                      

                       Computation: 44830 steps/s (collection: 2.080s, learning 0.113s)
             Mean action noise std: 2.06
          Mean value_function loss: 78.0566
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 55.0029
                       Mean reward: 636.10
               Mean episode length: 240.02
    Episode_Reward/reaching_object: 1.2457
    Episode_Reward/rotating_object: 124.9378
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 2.19s
                      Time elapsed: 00:22:37
                               ETA: 00:33:52

################################################################################
                     [1m Learning iteration 601/1500 [0m                      

                       Computation: 44785 steps/s (collection: 2.084s, learning 0.111s)
             Mean action noise std: 2.06
          Mean value_function loss: 93.7555
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 55.0390
                       Mean reward: 622.37
               Mean episode length: 229.92
    Episode_Reward/reaching_object: 1.2285
    Episode_Reward/rotating_object: 122.3238
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 2.19s
                      Time elapsed: 00:22:39
                               ETA: 00:33:49

################################################################################
                     [1m Learning iteration 602/1500 [0m                      

                       Computation: 44061 steps/s (collection: 2.120s, learning 0.111s)
             Mean action noise std: 2.06
          Mean value_function loss: 80.2300
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 55.0718
                       Mean reward: 623.78
               Mean episode length: 230.10
    Episode_Reward/reaching_object: 1.2306
    Episode_Reward/rotating_object: 123.3078
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 2.23s
                      Time elapsed: 00:22:41
                               ETA: 00:33:47

################################################################################
                     [1m Learning iteration 603/1500 [0m                      

                       Computation: 44397 steps/s (collection: 2.103s, learning 0.111s)
             Mean action noise std: 2.06
          Mean value_function loss: 86.4145
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 55.0949
                       Mean reward: 593.28
               Mean episode length: 224.84
    Episode_Reward/reaching_object: 1.2217
    Episode_Reward/rotating_object: 119.3678
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 2.21s
                      Time elapsed: 00:22:43
                               ETA: 00:33:45

################################################################################
                     [1m Learning iteration 604/1500 [0m                      

                       Computation: 44512 steps/s (collection: 2.098s, learning 0.111s)
             Mean action noise std: 2.07
          Mean value_function loss: 77.7251
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 55.1288
                       Mean reward: 633.40
               Mean episode length: 239.86
    Episode_Reward/reaching_object: 1.2361
    Episode_Reward/rotating_object: 124.1553
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 2.21s
                      Time elapsed: 00:22:45
                               ETA: 00:33:42

################################################################################
                     [1m Learning iteration 605/1500 [0m                      

                       Computation: 44565 steps/s (collection: 2.090s, learning 0.116s)
             Mean action noise std: 2.07
          Mean value_function loss: 75.3571
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 55.1706
                       Mean reward: 626.06
               Mean episode length: 239.82
    Episode_Reward/reaching_object: 1.2390
    Episode_Reward/rotating_object: 123.2686
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 2.21s
                      Time elapsed: 00:22:48
                               ETA: 00:33:40

################################################################################
                     [1m Learning iteration 606/1500 [0m                      

                       Computation: 44075 steps/s (collection: 2.116s, learning 0.114s)
             Mean action noise std: 2.07
          Mean value_function loss: 80.1808
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 55.1942
                       Mean reward: 604.20
               Mean episode length: 226.27
    Episode_Reward/reaching_object: 1.2235
    Episode_Reward/rotating_object: 123.1287
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 2.23s
                      Time elapsed: 00:22:50
                               ETA: 00:33:38

################################################################################
                     [1m Learning iteration 607/1500 [0m                      

                       Computation: 44190 steps/s (collection: 2.112s, learning 0.112s)
             Mean action noise std: 2.07
          Mean value_function loss: 70.0832
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.2180
                       Mean reward: 645.24
               Mean episode length: 239.97
    Episode_Reward/reaching_object: 1.2438
    Episode_Reward/rotating_object: 122.6063
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 2.22s
                      Time elapsed: 00:22:52
                               ETA: 00:33:35

################################################################################
                     [1m Learning iteration 608/1500 [0m                      

                       Computation: 44624 steps/s (collection: 2.092s, learning 0.111s)
             Mean action noise std: 2.08
          Mean value_function loss: 89.7750
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 55.2450
                       Mean reward: 614.81
               Mean episode length: 234.59
    Episode_Reward/reaching_object: 1.2342
    Episode_Reward/rotating_object: 125.6319
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 2.20s
                      Time elapsed: 00:22:54
                               ETA: 00:33:33

################################################################################
                     [1m Learning iteration 609/1500 [0m                      

                       Computation: 45119 steps/s (collection: 2.068s, learning 0.111s)
             Mean action noise std: 2.08
          Mean value_function loss: 82.6249
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 55.2811
                       Mean reward: 621.15
               Mean episode length: 235.48
    Episode_Reward/reaching_object: 1.2269
    Episode_Reward/rotating_object: 124.0212
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 2.18s
                      Time elapsed: 00:22:56
                               ETA: 00:33:31

################################################################################
                     [1m Learning iteration 610/1500 [0m                      

                       Computation: 45029 steps/s (collection: 2.072s, learning 0.111s)
             Mean action noise std: 2.08
          Mean value_function loss: 74.3394
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 55.3089
                       Mean reward: 615.24
               Mean episode length: 234.22
    Episode_Reward/reaching_object: 1.2266
    Episode_Reward/rotating_object: 123.5409
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 2.18s
                      Time elapsed: 00:22:59
                               ETA: 00:33:28

################################################################################
                     [1m Learning iteration 611/1500 [0m                      

                       Computation: 44994 steps/s (collection: 2.074s, learning 0.111s)
             Mean action noise std: 2.08
          Mean value_function loss: 85.4718
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 55.3238
                       Mean reward: 565.96
               Mean episode length: 221.08
    Episode_Reward/reaching_object: 1.2057
    Episode_Reward/rotating_object: 117.7340
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 2.18s
                      Time elapsed: 00:23:01
                               ETA: 00:33:26

################################################################################
                     [1m Learning iteration 612/1500 [0m                      

                       Computation: 45267 steps/s (collection: 2.061s, learning 0.110s)
             Mean action noise std: 2.09
          Mean value_function loss: 84.9559
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 55.3579
                       Mean reward: 642.06
               Mean episode length: 237.52
    Episode_Reward/reaching_object: 1.2423
    Episode_Reward/rotating_object: 124.4266
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 2.17s
                      Time elapsed: 00:23:03
                               ETA: 00:33:24

################################################################################
                     [1m Learning iteration 613/1500 [0m                      

                       Computation: 44986 steps/s (collection: 2.075s, learning 0.111s)
             Mean action noise std: 2.09
          Mean value_function loss: 74.4025
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 55.3856
                       Mean reward: 664.13
               Mean episode length: 237.89
    Episode_Reward/reaching_object: 1.2422
    Episode_Reward/rotating_object: 125.2851
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 2.19s
                      Time elapsed: 00:23:05
                               ETA: 00:33:21

################################################################################
                     [1m Learning iteration 614/1500 [0m                      

                       Computation: 44798 steps/s (collection: 2.078s, learning 0.116s)
             Mean action noise std: 2.09
          Mean value_function loss: 81.9347
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 55.4131
                       Mean reward: 624.93
               Mean episode length: 229.12
    Episode_Reward/reaching_object: 1.2385
    Episode_Reward/rotating_object: 125.0184
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 2.19s
                      Time elapsed: 00:23:07
                               ETA: 00:33:19

################################################################################
                     [1m Learning iteration 615/1500 [0m                      

                       Computation: 44689 steps/s (collection: 2.089s, learning 0.110s)
             Mean action noise std: 2.10
          Mean value_function loss: 89.0250
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.4536
                       Mean reward: 621.98
               Mean episode length: 226.99
    Episode_Reward/reaching_object: 1.2455
    Episode_Reward/rotating_object: 124.0860
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 2.20s
                      Time elapsed: 00:23:10
                               ETA: 00:33:17

################################################################################
                     [1m Learning iteration 616/1500 [0m                      

                       Computation: 44497 steps/s (collection: 2.097s, learning 0.112s)
             Mean action noise std: 2.10
          Mean value_function loss: 94.6879
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 55.4849
                       Mean reward: 624.30
               Mean episode length: 228.79
    Episode_Reward/reaching_object: 1.2383
    Episode_Reward/rotating_object: 124.2891
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 2.21s
                      Time elapsed: 00:23:12
                               ETA: 00:33:14

################################################################################
                     [1m Learning iteration 617/1500 [0m                      

                       Computation: 44593 steps/s (collection: 2.094s, learning 0.110s)
             Mean action noise std: 2.10
          Mean value_function loss: 89.1403
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 55.5301
                       Mean reward: 599.99
               Mean episode length: 238.82
    Episode_Reward/reaching_object: 1.2421
    Episode_Reward/rotating_object: 120.6270
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 2.20s
                      Time elapsed: 00:23:14
                               ETA: 00:33:12

################################################################################
                     [1m Learning iteration 618/1500 [0m                      

                       Computation: 44444 steps/s (collection: 2.098s, learning 0.114s)
             Mean action noise std: 2.10
          Mean value_function loss: 90.0525
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.5697
                       Mean reward: 600.77
               Mean episode length: 223.88
    Episode_Reward/reaching_object: 1.2123
    Episode_Reward/rotating_object: 121.1334
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 2.21s
                      Time elapsed: 00:23:16
                               ETA: 00:33:10

################################################################################
                     [1m Learning iteration 619/1500 [0m                      

                       Computation: 44776 steps/s (collection: 2.082s, learning 0.113s)
             Mean action noise std: 2.11
          Mean value_function loss: 85.0836
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 55.5978
                       Mean reward: 653.45
               Mean episode length: 243.78
    Episode_Reward/reaching_object: 1.2242
    Episode_Reward/rotating_object: 120.9871
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 2.20s
                      Time elapsed: 00:23:18
                               ETA: 00:33:07

################################################################################
                     [1m Learning iteration 620/1500 [0m                      

                       Computation: 44223 steps/s (collection: 2.107s, learning 0.116s)
             Mean action noise std: 2.11
          Mean value_function loss: 84.2121
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 55.6250
                       Mean reward: 603.73
               Mean episode length: 228.12
    Episode_Reward/reaching_object: 1.2299
    Episode_Reward/rotating_object: 122.3896
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 2.22s
                      Time elapsed: 00:23:21
                               ETA: 00:33:05

################################################################################
                     [1m Learning iteration 621/1500 [0m                      

                       Computation: 44645 steps/s (collection: 2.089s, learning 0.113s)
             Mean action noise std: 2.11
          Mean value_function loss: 83.4644
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 55.6560
                       Mean reward: 631.39
               Mean episode length: 238.67
    Episode_Reward/reaching_object: 1.2419
    Episode_Reward/rotating_object: 124.0206
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 2.20s
                      Time elapsed: 00:23:23
                               ETA: 00:33:03

################################################################################
                     [1m Learning iteration 622/1500 [0m                      

                       Computation: 45144 steps/s (collection: 2.067s, learning 0.111s)
             Mean action noise std: 2.12
          Mean value_function loss: 72.6084
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 55.6939
                       Mean reward: 608.07
               Mean episode length: 231.86
    Episode_Reward/reaching_object: 1.2303
    Episode_Reward/rotating_object: 120.1155
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 2.18s
                      Time elapsed: 00:23:25
                               ETA: 00:33:00

################################################################################
                     [1m Learning iteration 623/1500 [0m                      

                       Computation: 44097 steps/s (collection: 2.094s, learning 0.135s)
             Mean action noise std: 2.12
          Mean value_function loss: 81.5184
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 55.7461
                       Mean reward: 638.31
               Mean episode length: 235.79
    Episode_Reward/reaching_object: 1.2531
    Episode_Reward/rotating_object: 125.7685
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 2.23s
                      Time elapsed: 00:23:27
                               ETA: 00:32:58

################################################################################
                     [1m Learning iteration 624/1500 [0m                      

                       Computation: 44219 steps/s (collection: 2.109s, learning 0.114s)
             Mean action noise std: 2.12
          Mean value_function loss: 69.3754
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 55.7986
                       Mean reward: 631.99
               Mean episode length: 234.99
    Episode_Reward/reaching_object: 1.2233
    Episode_Reward/rotating_object: 124.1618
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 2.22s
                      Time elapsed: 00:23:29
                               ETA: 00:32:56

################################################################################
                     [1m Learning iteration 625/1500 [0m                      

                       Computation: 44967 steps/s (collection: 2.071s, learning 0.115s)
             Mean action noise std: 2.13
          Mean value_function loss: 74.6875
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 55.8383
                       Mean reward: 623.04
               Mean episode length: 236.36
    Episode_Reward/reaching_object: 1.2047
    Episode_Reward/rotating_object: 120.5355
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 2.19s
                      Time elapsed: 00:23:32
                               ETA: 00:32:53

################################################################################
                     [1m Learning iteration 626/1500 [0m                      

                       Computation: 44606 steps/s (collection: 2.090s, learning 0.113s)
             Mean action noise std: 2.13
          Mean value_function loss: 76.8090
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 55.8644
                       Mean reward: 623.93
               Mean episode length: 232.06
    Episode_Reward/reaching_object: 1.2140
    Episode_Reward/rotating_object: 122.2186
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 2.20s
                      Time elapsed: 00:23:34
                               ETA: 00:32:51

################################################################################
                     [1m Learning iteration 627/1500 [0m                      

                       Computation: 44773 steps/s (collection: 2.083s, learning 0.113s)
             Mean action noise std: 2.13
          Mean value_function loss: 83.9941
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 55.8980
                       Mean reward: 590.04
               Mean episode length: 230.08
    Episode_Reward/reaching_object: 1.2124
    Episode_Reward/rotating_object: 120.7090
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 2.20s
                      Time elapsed: 00:23:36
                               ETA: 00:32:49

################################################################################
                     [1m Learning iteration 628/1500 [0m                      

                       Computation: 44796 steps/s (collection: 2.083s, learning 0.112s)
             Mean action noise std: 2.14
          Mean value_function loss: 64.2862
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 55.9253
                       Mean reward: 603.44
               Mean episode length: 229.11
    Episode_Reward/reaching_object: 1.2240
    Episode_Reward/rotating_object: 126.0588
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 2.19s
                      Time elapsed: 00:23:38
                               ETA: 00:32:46

################################################################################
                     [1m Learning iteration 629/1500 [0m                      

                       Computation: 44521 steps/s (collection: 2.094s, learning 0.114s)
             Mean action noise std: 2.14
          Mean value_function loss: 86.2846
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 55.9574
                       Mean reward: 623.29
               Mean episode length: 233.99
    Episode_Reward/reaching_object: 1.2020
    Episode_Reward/rotating_object: 121.7320
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 2.21s
                      Time elapsed: 00:23:40
                               ETA: 00:32:44

################################################################################
                     [1m Learning iteration 630/1500 [0m                      

                       Computation: 42823 steps/s (collection: 2.185s, learning 0.110s)
             Mean action noise std: 2.14
          Mean value_function loss: 84.9029
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 56.0001
                       Mean reward: 630.29
               Mean episode length: 233.39
    Episode_Reward/reaching_object: 1.2059
    Episode_Reward/rotating_object: 120.9015
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 2.30s
                      Time elapsed: 00:23:43
                               ETA: 00:32:42

################################################################################
                     [1m Learning iteration 631/1500 [0m                      

                       Computation: 44919 steps/s (collection: 2.077s, learning 0.112s)
             Mean action noise std: 2.14
          Mean value_function loss: 90.3210
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 56.0246
                       Mean reward: 589.76
               Mean episode length: 225.17
    Episode_Reward/reaching_object: 1.1985
    Episode_Reward/rotating_object: 121.3957
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 2.19s
                      Time elapsed: 00:23:45
                               ETA: 00:32:39

################################################################################
                     [1m Learning iteration 632/1500 [0m                      

                       Computation: 43740 steps/s (collection: 2.136s, learning 0.111s)
             Mean action noise std: 2.15
          Mean value_function loss: 80.1169
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 56.0455
                       Mean reward: 636.87
               Mean episode length: 233.62
    Episode_Reward/reaching_object: 1.2211
    Episode_Reward/rotating_object: 122.9722
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 2.25s
                      Time elapsed: 00:23:47
                               ETA: 00:32:37

################################################################################
                     [1m Learning iteration 633/1500 [0m                      

                       Computation: 44143 steps/s (collection: 2.116s, learning 0.111s)
             Mean action noise std: 2.15
          Mean value_function loss: 79.1098
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 56.0821
                       Mean reward: 640.81
               Mean episode length: 235.19
    Episode_Reward/reaching_object: 1.1900
    Episode_Reward/rotating_object: 119.0548
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 2.23s
                      Time elapsed: 00:23:49
                               ETA: 00:32:35

################################################################################
                     [1m Learning iteration 634/1500 [0m                      

                       Computation: 44707 steps/s (collection: 2.088s, learning 0.111s)
             Mean action noise std: 2.15
          Mean value_function loss: 58.4040
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 56.1172
                       Mean reward: 635.03
               Mean episode length: 232.91
    Episode_Reward/reaching_object: 1.2272
    Episode_Reward/rotating_object: 125.1966
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 2.20s
                      Time elapsed: 00:23:52
                               ETA: 00:32:33

################################################################################
                     [1m Learning iteration 635/1500 [0m                      

                       Computation: 45698 steps/s (collection: 2.040s, learning 0.112s)
             Mean action noise std: 2.15
          Mean value_function loss: 77.0034
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 56.1424
                       Mean reward: 625.60
               Mean episode length: 236.57
    Episode_Reward/reaching_object: 1.2555
    Episode_Reward/rotating_object: 129.7686
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 2.15s
                      Time elapsed: 00:23:54
                               ETA: 00:32:30

################################################################################
                     [1m Learning iteration 636/1500 [0m                      

                       Computation: 45656 steps/s (collection: 2.040s, learning 0.113s)
             Mean action noise std: 2.16
          Mean value_function loss: 75.4763
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 56.1821
                       Mean reward: 602.09
               Mean episode length: 223.22
    Episode_Reward/reaching_object: 1.2014
    Episode_Reward/rotating_object: 121.3045
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 2.15s
                      Time elapsed: 00:23:56
                               ETA: 00:32:28

################################################################################
                     [1m Learning iteration 637/1500 [0m                      

                       Computation: 44080 steps/s (collection: 2.119s, learning 0.111s)
             Mean action noise std: 2.16
          Mean value_function loss: 77.1912
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 56.2108
                       Mean reward: 636.58
               Mean episode length: 236.38
    Episode_Reward/reaching_object: 1.2473
    Episode_Reward/rotating_object: 126.6685
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 2.23s
                      Time elapsed: 00:23:58
                               ETA: 00:32:25

################################################################################
                     [1m Learning iteration 638/1500 [0m                      

                       Computation: 44454 steps/s (collection: 2.099s, learning 0.113s)
             Mean action noise std: 2.16
          Mean value_function loss: 82.5078
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 56.2505
                       Mean reward: 640.08
               Mean episode length: 233.89
    Episode_Reward/reaching_object: 1.2307
    Episode_Reward/rotating_object: 123.7468
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 2.21s
                      Time elapsed: 00:24:00
                               ETA: 00:32:23

################################################################################
                     [1m Learning iteration 639/1500 [0m                      

                       Computation: 44777 steps/s (collection: 2.085s, learning 0.111s)
             Mean action noise std: 2.17
          Mean value_function loss: 74.1166
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 56.2868
                       Mean reward: 676.18
               Mean episode length: 246.50
    Episode_Reward/reaching_object: 1.2791
    Episode_Reward/rotating_object: 133.5399
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 2.20s
                      Time elapsed: 00:24:03
                               ETA: 00:32:21

################################################################################
                     [1m Learning iteration 640/1500 [0m                      

                       Computation: 44382 steps/s (collection: 2.103s, learning 0.112s)
             Mean action noise std: 2.17
          Mean value_function loss: 91.0469
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 56.3239
                       Mean reward: 598.54
               Mean episode length: 234.94
    Episode_Reward/reaching_object: 1.2286
    Episode_Reward/rotating_object: 123.6903
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 2.21s
                      Time elapsed: 00:24:05
                               ETA: 00:32:19

################################################################################
                     [1m Learning iteration 641/1500 [0m                      

                       Computation: 44760 steps/s (collection: 2.081s, learning 0.115s)
             Mean action noise std: 2.18
          Mean value_function loss: 82.9276
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 56.3693
                       Mean reward: 626.22
               Mean episode length: 231.72
    Episode_Reward/reaching_object: 1.2270
    Episode_Reward/rotating_object: 124.6542
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 2.20s
                      Time elapsed: 00:24:07
                               ETA: 00:32:16

################################################################################
                     [1m Learning iteration 642/1500 [0m                      

                       Computation: 44465 steps/s (collection: 2.098s, learning 0.113s)
             Mean action noise std: 2.18
          Mean value_function loss: 94.2908
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 56.4075
                       Mean reward: 603.44
               Mean episode length: 229.40
    Episode_Reward/reaching_object: 1.2151
    Episode_Reward/rotating_object: 123.4723
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 2.21s
                      Time elapsed: 00:24:09
                               ETA: 00:32:14

################################################################################
                     [1m Learning iteration 643/1500 [0m                      

                       Computation: 44644 steps/s (collection: 2.088s, learning 0.114s)
             Mean action noise std: 2.18
          Mean value_function loss: 78.1277
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 56.4416
                       Mean reward: 640.12
               Mean episode length: 237.04
    Episode_Reward/reaching_object: 1.2248
    Episode_Reward/rotating_object: 125.3119
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 2.20s
                      Time elapsed: 00:24:11
                               ETA: 00:32:12

################################################################################
                     [1m Learning iteration 644/1500 [0m                      

                       Computation: 44424 steps/s (collection: 2.097s, learning 0.116s)
             Mean action noise std: 2.18
          Mean value_function loss: 73.4131
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.4691
                       Mean reward: 585.75
               Mean episode length: 225.37
    Episode_Reward/reaching_object: 1.2131
    Episode_Reward/rotating_object: 119.8254
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 2.21s
                      Time elapsed: 00:24:14
                               ETA: 00:32:09

################################################################################
                     [1m Learning iteration 645/1500 [0m                      

                       Computation: 45015 steps/s (collection: 2.072s, learning 0.112s)
             Mean action noise std: 2.19
          Mean value_function loss: 84.3913
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 56.4936
                       Mean reward: 617.72
               Mean episode length: 226.41
    Episode_Reward/reaching_object: 1.2371
    Episode_Reward/rotating_object: 126.7304
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 2.18s
                      Time elapsed: 00:24:16
                               ETA: 00:32:07

################################################################################
                     [1m Learning iteration 646/1500 [0m                      

                       Computation: 44628 steps/s (collection: 2.088s, learning 0.115s)
             Mean action noise std: 2.19
          Mean value_function loss: 89.8750
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 56.5263
                       Mean reward: 666.51
               Mean episode length: 234.68
    Episode_Reward/reaching_object: 1.2376
    Episode_Reward/rotating_object: 125.5218
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 2.20s
                      Time elapsed: 00:24:18
                               ETA: 00:32:05

################################################################################
                     [1m Learning iteration 647/1500 [0m                      

                       Computation: 44745 steps/s (collection: 2.083s, learning 0.114s)
             Mean action noise std: 2.19
          Mean value_function loss: 95.6894
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 56.5699
                       Mean reward: 661.70
               Mean episode length: 239.30
    Episode_Reward/reaching_object: 1.2144
    Episode_Reward/rotating_object: 120.9189
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 2.20s
                      Time elapsed: 00:24:20
                               ETA: 00:32:02

################################################################################
                     [1m Learning iteration 648/1500 [0m                      

                       Computation: 45015 steps/s (collection: 2.070s, learning 0.114s)
             Mean action noise std: 2.20
          Mean value_function loss: 91.8651
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 56.6072
                       Mean reward: 683.64
               Mean episode length: 240.32
    Episode_Reward/reaching_object: 1.2483
    Episode_Reward/rotating_object: 127.9585
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 2.18s
                      Time elapsed: 00:24:22
                               ETA: 00:32:00

################################################################################
                     [1m Learning iteration 649/1500 [0m                      

                       Computation: 44939 steps/s (collection: 2.074s, learning 0.113s)
             Mean action noise std: 2.20
          Mean value_function loss: 88.4102
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 56.6392
                       Mean reward: 589.32
               Mean episode length: 217.70
    Episode_Reward/reaching_object: 1.2049
    Episode_Reward/rotating_object: 118.9726
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 2.19s
                      Time elapsed: 00:24:25
                               ETA: 00:31:58

################################################################################
                     [1m Learning iteration 650/1500 [0m                      

                       Computation: 44340 steps/s (collection: 2.102s, learning 0.115s)
             Mean action noise std: 2.20
          Mean value_function loss: 78.6537
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 56.6715
                       Mean reward: 634.87
               Mean episode length: 227.74
    Episode_Reward/reaching_object: 1.2377
    Episode_Reward/rotating_object: 122.1055
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 2.22s
                      Time elapsed: 00:24:27
                               ETA: 00:31:55

################################################################################
                     [1m Learning iteration 651/1500 [0m                      

                       Computation: 45125 steps/s (collection: 2.065s, learning 0.114s)
             Mean action noise std: 2.20
          Mean value_function loss: 74.8760
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.6952
                       Mean reward: 653.73
               Mean episode length: 238.68
    Episode_Reward/reaching_object: 1.2528
    Episode_Reward/rotating_object: 126.7331
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 2.18s
                      Time elapsed: 00:24:29
                               ETA: 00:31:53

################################################################################
                     [1m Learning iteration 652/1500 [0m                      

                       Computation: 44994 steps/s (collection: 2.074s, learning 0.111s)
             Mean action noise std: 2.21
          Mean value_function loss: 69.0762
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 56.7254
                       Mean reward: 644.09
               Mean episode length: 239.73
    Episode_Reward/reaching_object: 1.2464
    Episode_Reward/rotating_object: 125.3278
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 2.18s
                      Time elapsed: 00:24:31
                               ETA: 00:31:51

################################################################################
                     [1m Learning iteration 653/1500 [0m                      

                       Computation: 45309 steps/s (collection: 2.059s, learning 0.110s)
             Mean action noise std: 2.21
          Mean value_function loss: 92.3876
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 56.7460
                       Mean reward: 666.93
               Mean episode length: 233.41
    Episode_Reward/reaching_object: 1.2377
    Episode_Reward/rotating_object: 127.6423
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 2.17s
                      Time elapsed: 00:24:33
                               ETA: 00:31:48

################################################################################
                     [1m Learning iteration 654/1500 [0m                      

                       Computation: 45952 steps/s (collection: 2.028s, learning 0.111s)
             Mean action noise std: 2.21
          Mean value_function loss: 83.2054
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 56.7725
                       Mean reward: 618.36
               Mean episode length: 228.23
    Episode_Reward/reaching_object: 1.2236
    Episode_Reward/rotating_object: 124.5143
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 2.14s
                      Time elapsed: 00:24:35
                               ETA: 00:31:46

################################################################################
                     [1m Learning iteration 655/1500 [0m                      

                       Computation: 46008 steps/s (collection: 2.026s, learning 0.110s)
             Mean action noise std: 2.21
          Mean value_function loss: 82.8233
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 56.8046
                       Mean reward: 653.13
               Mean episode length: 229.81
    Episode_Reward/reaching_object: 1.2261
    Episode_Reward/rotating_object: 125.3770
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 2.14s
                      Time elapsed: 00:24:38
                               ETA: 00:31:43

################################################################################
                     [1m Learning iteration 656/1500 [0m                      

                       Computation: 45789 steps/s (collection: 2.036s, learning 0.111s)
             Mean action noise std: 2.22
          Mean value_function loss: 86.7215
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 56.8238
                       Mean reward: 592.00
               Mean episode length: 231.35
    Episode_Reward/reaching_object: 1.2457
    Episode_Reward/rotating_object: 123.0191
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 2.15s
                      Time elapsed: 00:24:40
                               ETA: 00:31:41

################################################################################
                     [1m Learning iteration 657/1500 [0m                      

                       Computation: 45881 steps/s (collection: 2.032s, learning 0.111s)
             Mean action noise std: 2.22
          Mean value_function loss: 70.8808
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 56.8521
                       Mean reward: 660.40
               Mean episode length: 238.05
    Episode_Reward/reaching_object: 1.2523
    Episode_Reward/rotating_object: 127.6131
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 2.14s
                      Time elapsed: 00:24:42
                               ETA: 00:31:39

################################################################################
                     [1m Learning iteration 658/1500 [0m                      

                       Computation: 45283 steps/s (collection: 2.060s, learning 0.111s)
             Mean action noise std: 2.22
          Mean value_function loss: 78.3461
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.8806
                       Mean reward: 592.01
               Mean episode length: 228.26
    Episode_Reward/reaching_object: 1.2074
    Episode_Reward/rotating_object: 120.1972
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 2.17s
                      Time elapsed: 00:24:44
                               ETA: 00:31:36

################################################################################
                     [1m Learning iteration 659/1500 [0m                      

                       Computation: 44992 steps/s (collection: 2.071s, learning 0.114s)
             Mean action noise std: 2.23
          Mean value_function loss: 88.5817
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 56.9121
                       Mean reward: 593.67
               Mean episode length: 226.90
    Episode_Reward/reaching_object: 1.2318
    Episode_Reward/rotating_object: 124.9808
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 2.18s
                      Time elapsed: 00:24:46
                               ETA: 00:31:34

################################################################################
                     [1m Learning iteration 660/1500 [0m                      

                       Computation: 44903 steps/s (collection: 2.076s, learning 0.113s)
             Mean action noise std: 2.23
          Mean value_function loss: 75.1256
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 56.9492
                       Mean reward: 612.26
               Mean episode length: 232.10
    Episode_Reward/reaching_object: 1.2215
    Episode_Reward/rotating_object: 121.6490
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 2.19s
                      Time elapsed: 00:24:48
                               ETA: 00:31:32

################################################################################
                     [1m Learning iteration 661/1500 [0m                      

                       Computation: 43880 steps/s (collection: 2.126s, learning 0.114s)
             Mean action noise std: 2.23
          Mean value_function loss: 81.4373
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 56.9875
                       Mean reward: 599.39
               Mean episode length: 226.38
    Episode_Reward/reaching_object: 1.2268
    Episode_Reward/rotating_object: 124.4547
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 2.24s
                      Time elapsed: 00:24:51
                               ETA: 00:31:29

################################################################################
                     [1m Learning iteration 662/1500 [0m                      

                       Computation: 44789 steps/s (collection: 2.080s, learning 0.114s)
             Mean action noise std: 2.24
          Mean value_function loss: 74.9801
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 57.0324
                       Mean reward: 631.43
               Mean episode length: 235.88
    Episode_Reward/reaching_object: 1.2596
    Episode_Reward/rotating_object: 126.7760
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 2.19s
                      Time elapsed: 00:24:53
                               ETA: 00:31:27

################################################################################
                     [1m Learning iteration 663/1500 [0m                      

                       Computation: 44566 steps/s (collection: 2.085s, learning 0.121s)
             Mean action noise std: 2.24
          Mean value_function loss: 76.5185
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 57.0649
                       Mean reward: 609.00
               Mean episode length: 228.65
    Episode_Reward/reaching_object: 1.2272
    Episode_Reward/rotating_object: 122.7429
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 2.21s
                      Time elapsed: 00:24:55
                               ETA: 00:31:25

################################################################################
                     [1m Learning iteration 664/1500 [0m                      

                       Computation: 43769 steps/s (collection: 2.131s, learning 0.115s)
             Mean action noise std: 2.24
          Mean value_function loss: 87.4475
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.0948
                       Mean reward: 607.58
               Mean episode length: 232.45
    Episode_Reward/reaching_object: 1.2358
    Episode_Reward/rotating_object: 128.3495
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 2.25s
                      Time elapsed: 00:24:57
                               ETA: 00:31:22

################################################################################
                     [1m Learning iteration 665/1500 [0m                      

                       Computation: 44566 steps/s (collection: 2.092s, learning 0.114s)
             Mean action noise std: 2.24
          Mean value_function loss: 71.8699
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 57.1258
                       Mean reward: 625.26
               Mean episode length: 230.33
    Episode_Reward/reaching_object: 1.2190
    Episode_Reward/rotating_object: 124.9590
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 2.21s
                      Time elapsed: 00:24:59
                               ETA: 00:31:20

################################################################################
                     [1m Learning iteration 666/1500 [0m                      

                       Computation: 43666 steps/s (collection: 2.139s, learning 0.112s)
             Mean action noise std: 2.25
          Mean value_function loss: 83.1498
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 57.1621
                       Mean reward: 661.91
               Mean episode length: 237.70
    Episode_Reward/reaching_object: 1.2176
    Episode_Reward/rotating_object: 125.3903
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 2.25s
                      Time elapsed: 00:25:02
                               ETA: 00:31:18

################################################################################
                     [1m Learning iteration 667/1500 [0m                      

                       Computation: 42048 steps/s (collection: 2.224s, learning 0.114s)
             Mean action noise std: 2.25
          Mean value_function loss: 68.3788
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 57.1970
                       Mean reward: 642.61
               Mean episode length: 239.48
    Episode_Reward/reaching_object: 1.2501
    Episode_Reward/rotating_object: 128.1702
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 2.34s
                      Time elapsed: 00:25:04
                               ETA: 00:31:16

################################################################################
                     [1m Learning iteration 668/1500 [0m                      

                       Computation: 41792 steps/s (collection: 2.241s, learning 0.111s)
             Mean action noise std: 2.25
          Mean value_function loss: 84.0970
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 57.2354
                       Mean reward: 592.55
               Mean episode length: 231.06
    Episode_Reward/reaching_object: 1.2230
    Episode_Reward/rotating_object: 122.6048
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 2.35s
                      Time elapsed: 00:25:06
                               ETA: 00:31:14

################################################################################
                     [1m Learning iteration 669/1500 [0m                      

                       Computation: 44803 steps/s (collection: 2.080s, learning 0.114s)
             Mean action noise std: 2.26
          Mean value_function loss: 70.4472
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 57.2685
                       Mean reward: 649.28
               Mean episode length: 237.50
    Episode_Reward/reaching_object: 1.2366
    Episode_Reward/rotating_object: 124.7312
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 2.19s
                      Time elapsed: 00:25:09
                               ETA: 00:31:11

################################################################################
                     [1m Learning iteration 670/1500 [0m                      

                       Computation: 44443 steps/s (collection: 2.097s, learning 0.115s)
             Mean action noise std: 2.26
          Mean value_function loss: 76.8035
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 57.3003
                       Mean reward: 610.34
               Mean episode length: 234.04
    Episode_Reward/reaching_object: 1.2413
    Episode_Reward/rotating_object: 127.3459
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 2.21s
                      Time elapsed: 00:25:11
                               ETA: 00:31:09

################################################################################
                     [1m Learning iteration 671/1500 [0m                      

                       Computation: 44633 steps/s (collection: 2.087s, learning 0.116s)
             Mean action noise std: 2.26
          Mean value_function loss: 77.8536
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 57.3416
                       Mean reward: 638.34
               Mean episode length: 231.18
    Episode_Reward/reaching_object: 1.2367
    Episode_Reward/rotating_object: 126.5520
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 2.20s
                      Time elapsed: 00:25:13
                               ETA: 00:31:07

################################################################################
                     [1m Learning iteration 672/1500 [0m                      

                       Computation: 44307 steps/s (collection: 2.102s, learning 0.116s)
             Mean action noise std: 2.27
          Mean value_function loss: 87.5730
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 57.3692
                       Mean reward: 632.97
               Mean episode length: 229.74
    Episode_Reward/reaching_object: 1.2310
    Episode_Reward/rotating_object: 125.2314
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 2.22s
                      Time elapsed: 00:25:15
                               ETA: 00:31:04

################################################################################
                     [1m Learning iteration 673/1500 [0m                      

                       Computation: 44180 steps/s (collection: 2.112s, learning 0.114s)
             Mean action noise std: 2.27
          Mean value_function loss: 79.4112
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 57.4104
                       Mean reward: 660.33
               Mean episode length: 241.21
    Episode_Reward/reaching_object: 1.2530
    Episode_Reward/rotating_object: 126.3906
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 2.23s
                      Time elapsed: 00:25:17
                               ETA: 00:31:02

################################################################################
                     [1m Learning iteration 674/1500 [0m                      

                       Computation: 45028 steps/s (collection: 2.073s, learning 0.110s)
             Mean action noise std: 2.27
          Mean value_function loss: 92.2659
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 57.4485
                       Mean reward: 637.31
               Mean episode length: 229.07
    Episode_Reward/reaching_object: 1.2247
    Episode_Reward/rotating_object: 124.2576
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 2.18s
                      Time elapsed: 00:25:20
                               ETA: 00:31:00

################################################################################
                     [1m Learning iteration 675/1500 [0m                      

                       Computation: 45616 steps/s (collection: 2.041s, learning 0.114s)
             Mean action noise std: 2.28
          Mean value_function loss: 80.6623
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 57.4770
                       Mean reward: 621.01
               Mean episode length: 228.80
    Episode_Reward/reaching_object: 1.2153
    Episode_Reward/rotating_object: 121.5569
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 2.15s
                      Time elapsed: 00:25:22
                               ETA: 00:30:57

################################################################################
                     [1m Learning iteration 676/1500 [0m                      

                       Computation: 45866 steps/s (collection: 2.033s, learning 0.110s)
             Mean action noise std: 2.28
          Mean value_function loss: 87.7755
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 57.5150
                       Mean reward: 632.76
               Mean episode length: 229.12
    Episode_Reward/reaching_object: 1.2192
    Episode_Reward/rotating_object: 123.1076
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 2.14s
                      Time elapsed: 00:25:24
                               ETA: 00:30:55

################################################################################
                     [1m Learning iteration 677/1500 [0m                      

                       Computation: 45050 steps/s (collection: 2.071s, learning 0.111s)
             Mean action noise std: 2.28
          Mean value_function loss: 72.6944
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 57.5499
                       Mean reward: 649.20
               Mean episode length: 237.37
    Episode_Reward/reaching_object: 1.2510
    Episode_Reward/rotating_object: 126.3395
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 2.18s
                      Time elapsed: 00:25:26
                               ETA: 00:30:53

################################################################################
                     [1m Learning iteration 678/1500 [0m                      

                       Computation: 45758 steps/s (collection: 2.037s, learning 0.111s)
             Mean action noise std: 2.29
          Mean value_function loss: 103.2809
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 57.5855
                       Mean reward: 646.10
               Mean episode length: 239.33
    Episode_Reward/reaching_object: 1.2407
    Episode_Reward/rotating_object: 126.6581
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 2.15s
                      Time elapsed: 00:25:28
                               ETA: 00:30:50

################################################################################
                     [1m Learning iteration 679/1500 [0m                      

                       Computation: 45601 steps/s (collection: 2.042s, learning 0.114s)
             Mean action noise std: 2.29
          Mean value_function loss: 81.2987
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 57.6306
                       Mean reward: 636.57
               Mean episode length: 231.52
    Episode_Reward/reaching_object: 1.2184
    Episode_Reward/rotating_object: 122.7512
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 2.16s
                      Time elapsed: 00:25:30
                               ETA: 00:30:48

################################################################################
                     [1m Learning iteration 680/1500 [0m                      

                       Computation: 45506 steps/s (collection: 2.049s, learning 0.111s)
             Mean action noise std: 2.29
          Mean value_function loss: 81.2439
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 57.6640
                       Mean reward: 612.28
               Mean episode length: 231.27
    Episode_Reward/reaching_object: 1.2367
    Episode_Reward/rotating_object: 126.8769
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 2.16s
                      Time elapsed: 00:25:33
                               ETA: 00:30:46

################################################################################
                     [1m Learning iteration 681/1500 [0m                      

                       Computation: 45280 steps/s (collection: 2.060s, learning 0.111s)
             Mean action noise std: 2.30
          Mean value_function loss: 78.4822
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 57.7019
                       Mean reward: 642.61
               Mean episode length: 234.59
    Episode_Reward/reaching_object: 1.2317
    Episode_Reward/rotating_object: 125.0226
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 2.17s
                      Time elapsed: 00:25:35
                               ETA: 00:30:43

################################################################################
                     [1m Learning iteration 682/1500 [0m                      

                       Computation: 44328 steps/s (collection: 2.106s, learning 0.112s)
             Mean action noise std: 2.30
          Mean value_function loss: 70.4476
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 57.7460
                       Mean reward: 597.96
               Mean episode length: 224.97
    Episode_Reward/reaching_object: 1.2169
    Episode_Reward/rotating_object: 123.7843
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 2.22s
                      Time elapsed: 00:25:37
                               ETA: 00:30:41

################################################################################
                     [1m Learning iteration 683/1500 [0m                      

                       Computation: 44524 steps/s (collection: 2.094s, learning 0.114s)
             Mean action noise std: 2.31
          Mean value_function loss: 69.0444
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 57.7920
                       Mean reward: 618.09
               Mean episode length: 233.17
    Episode_Reward/reaching_object: 1.2379
    Episode_Reward/rotating_object: 124.9006
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 2.21s
                      Time elapsed: 00:25:39
                               ETA: 00:30:39

################################################################################
                     [1m Learning iteration 684/1500 [0m                      

                       Computation: 44782 steps/s (collection: 2.083s, learning 0.112s)
             Mean action noise std: 2.31
          Mean value_function loss: 75.0762
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 57.8211
                       Mean reward: 679.19
               Mean episode length: 235.64
    Episode_Reward/reaching_object: 1.2277
    Episode_Reward/rotating_object: 128.2504
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 2.20s
                      Time elapsed: 00:25:41
                               ETA: 00:30:36

################################################################################
                     [1m Learning iteration 685/1500 [0m                      

                       Computation: 44751 steps/s (collection: 2.082s, learning 0.115s)
             Mean action noise std: 2.31
          Mean value_function loss: 80.2515
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 57.8421
                       Mean reward: 637.94
               Mean episode length: 236.36
    Episode_Reward/reaching_object: 1.2282
    Episode_Reward/rotating_object: 126.3995
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 2.20s
                      Time elapsed: 00:25:44
                               ETA: 00:30:34

################################################################################
                     [1m Learning iteration 686/1500 [0m                      

                       Computation: 44151 steps/s (collection: 2.116s, learning 0.110s)
             Mean action noise std: 2.31
          Mean value_function loss: 74.5241
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 57.8791
                       Mean reward: 652.86
               Mean episode length: 234.69
    Episode_Reward/reaching_object: 1.2235
    Episode_Reward/rotating_object: 127.3016
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 2.23s
                      Time elapsed: 00:25:46
                               ETA: 00:30:32

################################################################################
                     [1m Learning iteration 687/1500 [0m                      

                       Computation: 44796 steps/s (collection: 2.080s, learning 0.114s)
             Mean action noise std: 2.32
          Mean value_function loss: 75.5510
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 57.9188
                       Mean reward: 602.59
               Mean episode length: 234.21
    Episode_Reward/reaching_object: 1.2010
    Episode_Reward/rotating_object: 120.3794
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 2.19s
                      Time elapsed: 00:25:48
                               ETA: 00:30:29

################################################################################
                     [1m Learning iteration 688/1500 [0m                      

                       Computation: 44130 steps/s (collection: 2.116s, learning 0.111s)
             Mean action noise std: 2.32
          Mean value_function loss: 83.6634
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 57.9485
                       Mean reward: 677.56
               Mean episode length: 239.59
    Episode_Reward/reaching_object: 1.1945
    Episode_Reward/rotating_object: 121.4303
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 2.23s
                      Time elapsed: 00:25:50
                               ETA: 00:30:27

################################################################################
                     [1m Learning iteration 689/1500 [0m                      

                       Computation: 43819 steps/s (collection: 2.131s, learning 0.113s)
             Mean action noise std: 2.32
          Mean value_function loss: 77.9528
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 57.9828
                       Mean reward: 661.36
               Mean episode length: 235.23
    Episode_Reward/reaching_object: 1.2437
    Episode_Reward/rotating_object: 127.5106
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 2.24s
                      Time elapsed: 00:25:52
                               ETA: 00:30:25

################################################################################
                     [1m Learning iteration 690/1500 [0m                      

                       Computation: 44692 steps/s (collection: 2.087s, learning 0.113s)
             Mean action noise std: 2.33
          Mean value_function loss: 77.8118
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 58.0149
                       Mean reward: 623.63
               Mean episode length: 237.22
    Episode_Reward/reaching_object: 1.2336
    Episode_Reward/rotating_object: 126.7901
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 2.20s
                      Time elapsed: 00:25:55
                               ETA: 00:30:22

################################################################################
                     [1m Learning iteration 691/1500 [0m                      

                       Computation: 44969 steps/s (collection: 2.075s, learning 0.111s)
             Mean action noise std: 2.33
          Mean value_function loss: 86.1219
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 58.0460
                       Mean reward: 628.95
               Mean episode length: 232.42
    Episode_Reward/reaching_object: 1.2401
    Episode_Reward/rotating_object: 128.3521
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 2.19s
                      Time elapsed: 00:25:57
                               ETA: 00:30:20

################################################################################
                     [1m Learning iteration 692/1500 [0m                      

                       Computation: 44913 steps/s (collection: 2.078s, learning 0.111s)
             Mean action noise std: 2.33
          Mean value_function loss: 76.9773
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 58.0840
                       Mean reward: 617.62
               Mean episode length: 226.53
    Episode_Reward/reaching_object: 1.2059
    Episode_Reward/rotating_object: 124.6464
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 2.19s
                      Time elapsed: 00:25:59
                               ETA: 00:30:18

################################################################################
                     [1m Learning iteration 693/1500 [0m                      

                       Computation: 44505 steps/s (collection: 2.098s, learning 0.111s)
             Mean action noise std: 2.34
          Mean value_function loss: 81.6750
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 58.1166
                       Mean reward: 645.78
               Mean episode length: 231.40
    Episode_Reward/reaching_object: 1.2439
    Episode_Reward/rotating_object: 129.6484
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 2.21s
                      Time elapsed: 00:26:01
                               ETA: 00:30:16

################################################################################
                     [1m Learning iteration 694/1500 [0m                      

                       Computation: 45502 steps/s (collection: 2.050s, learning 0.111s)
             Mean action noise std: 2.34
          Mean value_function loss: 68.1716
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 58.1525
                       Mean reward: 665.33
               Mean episode length: 242.89
    Episode_Reward/reaching_object: 1.2449
    Episode_Reward/rotating_object: 129.2176
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 2.16s
                      Time elapsed: 00:26:03
                               ETA: 00:30:13

################################################################################
                     [1m Learning iteration 695/1500 [0m                      

                       Computation: 45095 steps/s (collection: 2.069s, learning 0.111s)
             Mean action noise std: 2.34
          Mean value_function loss: 67.3345
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 58.1785
                       Mean reward: 670.62
               Mean episode length: 238.09
    Episode_Reward/reaching_object: 1.2391
    Episode_Reward/rotating_object: 129.2094
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 2.18s
                      Time elapsed: 00:26:06
                               ETA: 00:30:11

################################################################################
                     [1m Learning iteration 696/1500 [0m                      

                       Computation: 45118 steps/s (collection: 2.068s, learning 0.111s)
             Mean action noise std: 2.34
          Mean value_function loss: 83.6004
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 58.2080
                       Mean reward: 606.44
               Mean episode length: 223.62
    Episode_Reward/reaching_object: 1.2100
    Episode_Reward/rotating_object: 124.6457
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 2.18s
                      Time elapsed: 00:26:08
                               ETA: 00:30:09

################################################################################
                     [1m Learning iteration 697/1500 [0m                      

                       Computation: 46289 steps/s (collection: 2.012s, learning 0.112s)
             Mean action noise std: 2.35
          Mean value_function loss: 70.8872
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 58.2371
                       Mean reward: 650.54
               Mean episode length: 232.86
    Episode_Reward/reaching_object: 1.2258
    Episode_Reward/rotating_object: 124.9707
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 2.12s
                      Time elapsed: 00:26:10
                               ETA: 00:30:06

################################################################################
                     [1m Learning iteration 698/1500 [0m                      

                       Computation: 45273 steps/s (collection: 2.061s, learning 0.111s)
             Mean action noise std: 2.35
          Mean value_function loss: 79.0221
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 58.2770
                       Mean reward: 595.42
               Mean episode length: 222.01
    Episode_Reward/reaching_object: 1.2325
    Episode_Reward/rotating_object: 127.9170
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 2.17s
                      Time elapsed: 00:26:12
                               ETA: 00:30:04

################################################################################
                     [1m Learning iteration 699/1500 [0m                      

                       Computation: 45998 steps/s (collection: 2.027s, learning 0.110s)
             Mean action noise std: 2.35
          Mean value_function loss: 69.8348
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 58.3059
                       Mean reward: 675.75
               Mean episode length: 242.88
    Episode_Reward/reaching_object: 1.2273
    Episode_Reward/rotating_object: 128.6991
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 2.14s
                      Time elapsed: 00:26:14
                               ETA: 00:30:01

################################################################################
                     [1m Learning iteration 700/1500 [0m                      

                       Computation: 46053 steps/s (collection: 2.024s, learning 0.110s)
             Mean action noise std: 2.36
          Mean value_function loss: 66.1619
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 58.3231
                       Mean reward: 601.99
               Mean episode length: 224.85
    Episode_Reward/reaching_object: 1.2253
    Episode_Reward/rotating_object: 125.8816
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 2.13s
                      Time elapsed: 00:26:16
                               ETA: 00:29:59

################################################################################
                     [1m Learning iteration 701/1500 [0m                      

                       Computation: 46288 steps/s (collection: 2.013s, learning 0.110s)
             Mean action noise std: 2.36
          Mean value_function loss: 79.4009
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 58.3465
                       Mean reward: 619.98
               Mean episode length: 235.31
    Episode_Reward/reaching_object: 1.2561
    Episode_Reward/rotating_object: 128.9503
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 2.12s
                      Time elapsed: 00:26:18
                               ETA: 00:29:57

################################################################################
                     [1m Learning iteration 702/1500 [0m                      

                       Computation: 44818 steps/s (collection: 2.059s, learning 0.135s)
             Mean action noise std: 2.36
          Mean value_function loss: 85.3477
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 58.3822
                       Mean reward: 645.95
               Mean episode length: 232.48
    Episode_Reward/reaching_object: 1.2391
    Episode_Reward/rotating_object: 128.9358
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 2.19s
                      Time elapsed: 00:26:21
                               ETA: 00:29:54

################################################################################
                     [1m Learning iteration 703/1500 [0m                      

                       Computation: 44777 steps/s (collection: 2.069s, learning 0.127s)
             Mean action noise std: 2.37
          Mean value_function loss: 85.6792
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 58.4161
                       Mean reward: 613.37
               Mean episode length: 229.72
    Episode_Reward/reaching_object: 1.2162
    Episode_Reward/rotating_object: 126.8661
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 2.20s
                      Time elapsed: 00:26:23
                               ETA: 00:29:52

################################################################################
                     [1m Learning iteration 704/1500 [0m                      

                       Computation: 42204 steps/s (collection: 2.218s, learning 0.111s)
             Mean action noise std: 2.37
          Mean value_function loss: 88.3164
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 58.4494
                       Mean reward: 624.22
               Mean episode length: 231.04
    Episode_Reward/reaching_object: 1.2196
    Episode_Reward/rotating_object: 126.3236
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 2.33s
                      Time elapsed: 00:26:25
                               ETA: 00:29:50

################################################################################
                     [1m Learning iteration 705/1500 [0m                      

                       Computation: 44292 steps/s (collection: 2.108s, learning 0.112s)
             Mean action noise std: 2.37
          Mean value_function loss: 87.4829
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 58.4819
                       Mean reward: 639.16
               Mean episode length: 230.27
    Episode_Reward/reaching_object: 1.2032
    Episode_Reward/rotating_object: 124.4490
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 2.22s
                      Time elapsed: 00:26:27
                               ETA: 00:29:48

################################################################################
                     [1m Learning iteration 706/1500 [0m                      

                       Computation: 44433 steps/s (collection: 2.100s, learning 0.112s)
             Mean action noise std: 2.37
          Mean value_function loss: 76.6241
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 58.5086
                       Mean reward: 638.48
               Mean episode length: 234.49
    Episode_Reward/reaching_object: 1.2449
    Episode_Reward/rotating_object: 131.5331
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 2.21s
                      Time elapsed: 00:26:30
                               ETA: 00:29:45

################################################################################
                     [1m Learning iteration 707/1500 [0m                      

                       Computation: 45153 steps/s (collection: 2.063s, learning 0.115s)
             Mean action noise std: 2.38
          Mean value_function loss: 80.6180
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 58.5322
                       Mean reward: 658.92
               Mean episode length: 236.44
    Episode_Reward/reaching_object: 1.2427
    Episode_Reward/rotating_object: 130.5451
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 2.18s
                      Time elapsed: 00:26:32
                               ETA: 00:29:43

################################################################################
                     [1m Learning iteration 708/1500 [0m                      

                       Computation: 45277 steps/s (collection: 2.059s, learning 0.112s)
             Mean action noise std: 2.38
          Mean value_function loss: 72.8287
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 58.5643
                       Mean reward: 667.90
               Mean episode length: 233.81
    Episode_Reward/reaching_object: 1.2129
    Episode_Reward/rotating_object: 125.9783
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 2.17s
                      Time elapsed: 00:26:34
                               ETA: 00:29:41

################################################################################
                     [1m Learning iteration 709/1500 [0m                      

                       Computation: 45184 steps/s (collection: 2.065s, learning 0.111s)
             Mean action noise std: 2.38
          Mean value_function loss: 82.0223
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 58.6048
                       Mean reward: 700.32
               Mean episode length: 242.15
    Episode_Reward/reaching_object: 1.2548
    Episode_Reward/rotating_object: 132.1035
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 2.18s
                      Time elapsed: 00:26:36
                               ETA: 00:29:38

################################################################################
                     [1m Learning iteration 710/1500 [0m                      

                       Computation: 45209 steps/s (collection: 2.049s, learning 0.125s)
             Mean action noise std: 2.39
          Mean value_function loss: 67.3057
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 58.6364
                       Mean reward: 649.11
               Mean episode length: 232.54
    Episode_Reward/reaching_object: 1.2478
    Episode_Reward/rotating_object: 131.5403
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 2.17s
                      Time elapsed: 00:26:38
                               ETA: 00:29:36

################################################################################
                     [1m Learning iteration 711/1500 [0m                      

                       Computation: 44408 steps/s (collection: 2.101s, learning 0.113s)
             Mean action noise std: 2.39
          Mean value_function loss: 78.2186
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 58.6640
                       Mean reward: 665.62
               Mean episode length: 239.37
    Episode_Reward/reaching_object: 1.2440
    Episode_Reward/rotating_object: 130.0162
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 2.21s
                      Time elapsed: 00:26:41
                               ETA: 00:29:34

################################################################################
                     [1m Learning iteration 712/1500 [0m                      

                       Computation: 44880 steps/s (collection: 2.078s, learning 0.112s)
             Mean action noise std: 2.39
          Mean value_function loss: 75.4056
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 58.6922
                       Mean reward: 635.16
               Mean episode length: 230.98
    Episode_Reward/reaching_object: 1.2422
    Episode_Reward/rotating_object: 129.2074
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 2.19s
                      Time elapsed: 00:26:43
                               ETA: 00:29:31

################################################################################
                     [1m Learning iteration 713/1500 [0m                      

                       Computation: 44605 steps/s (collection: 2.091s, learning 0.113s)
             Mean action noise std: 2.39
          Mean value_function loss: 91.9974
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 58.7078
                       Mean reward: 615.97
               Mean episode length: 222.71
    Episode_Reward/reaching_object: 1.2421
    Episode_Reward/rotating_object: 129.2231
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 2.20s
                      Time elapsed: 00:26:45
                               ETA: 00:29:29

################################################################################
                     [1m Learning iteration 714/1500 [0m                      

                       Computation: 45301 steps/s (collection: 2.057s, learning 0.113s)
             Mean action noise std: 2.40
          Mean value_function loss: 76.3451
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 58.7380
                       Mean reward: 684.76
               Mean episode length: 238.20
    Episode_Reward/reaching_object: 1.2505
    Episode_Reward/rotating_object: 130.3404
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 2.17s
                      Time elapsed: 00:26:47
                               ETA: 00:29:27

################################################################################
                     [1m Learning iteration 715/1500 [0m                      

                       Computation: 45332 steps/s (collection: 2.053s, learning 0.115s)
             Mean action noise std: 2.40
          Mean value_function loss: 104.0181
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 58.7701
                       Mean reward: 622.65
               Mean episode length: 228.54
    Episode_Reward/reaching_object: 1.2350
    Episode_Reward/rotating_object: 128.2079
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 2.17s
                      Time elapsed: 00:26:49
                               ETA: 00:29:24

################################################################################
                     [1m Learning iteration 716/1500 [0m                      

                       Computation: 45093 steps/s (collection: 2.068s, learning 0.112s)
             Mean action noise std: 2.40
          Mean value_function loss: 87.2929
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 58.7985
                       Mean reward: 682.10
               Mean episode length: 239.21
    Episode_Reward/reaching_object: 1.2318
    Episode_Reward/rotating_object: 127.0701
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 2.18s
                      Time elapsed: 00:26:51
                               ETA: 00:29:22

################################################################################
                     [1m Learning iteration 717/1500 [0m                      

                       Computation: 45464 steps/s (collection: 2.049s, learning 0.113s)
             Mean action noise std: 2.41
          Mean value_function loss: 97.7867
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 58.8305
                       Mean reward: 631.44
               Mean episode length: 228.66
    Episode_Reward/reaching_object: 1.2227
    Episode_Reward/rotating_object: 124.0963
        Episode_Reward/action_rate: -0.0355
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 2.16s
                      Time elapsed: 00:26:54
                               ETA: 00:29:20

################################################################################
                     [1m Learning iteration 718/1500 [0m                      

                       Computation: 44282 steps/s (collection: 2.106s, learning 0.114s)
             Mean action noise std: 2.41
          Mean value_function loss: 74.0439
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 58.8724
                       Mean reward: 657.00
               Mean episode length: 230.99
    Episode_Reward/reaching_object: 1.2200
    Episode_Reward/rotating_object: 124.5696
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 2.22s
                      Time elapsed: 00:26:56
                               ETA: 00:29:17

################################################################################
                     [1m Learning iteration 719/1500 [0m                      

                       Computation: 46121 steps/s (collection: 2.020s, learning 0.111s)
             Mean action noise std: 2.41
          Mean value_function loss: 74.9779
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 58.8970
                       Mean reward: 624.42
               Mean episode length: 223.85
    Episode_Reward/reaching_object: 1.2370
    Episode_Reward/rotating_object: 130.3844
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 2.13s
                      Time elapsed: 00:26:58
                               ETA: 00:29:15

################################################################################
                     [1m Learning iteration 720/1500 [0m                      

                       Computation: 45537 steps/s (collection: 2.048s, learning 0.111s)
             Mean action noise std: 2.41
          Mean value_function loss: 84.6619
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 58.9233
                       Mean reward: 647.63
               Mean episode length: 234.82
    Episode_Reward/reaching_object: 1.2409
    Episode_Reward/rotating_object: 130.2860
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 2.16s
                      Time elapsed: 00:27:00
                               ETA: 00:29:13

################################################################################
                     [1m Learning iteration 721/1500 [0m                      

                       Computation: 46321 steps/s (collection: 2.012s, learning 0.111s)
             Mean action noise std: 2.42
          Mean value_function loss: 74.5417
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 58.9529
                       Mean reward: 633.65
               Mean episode length: 237.29
    Episode_Reward/reaching_object: 1.2766
    Episode_Reward/rotating_object: 133.4122
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 2.12s
                      Time elapsed: 00:27:02
                               ETA: 00:29:10

################################################################################
                     [1m Learning iteration 722/1500 [0m                      

                       Computation: 45448 steps/s (collection: 2.052s, learning 0.111s)
             Mean action noise std: 2.42
          Mean value_function loss: 84.6694
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 58.9838
                       Mean reward: 622.54
               Mean episode length: 227.17
    Episode_Reward/reaching_object: 1.2443
    Episode_Reward/rotating_object: 127.9932
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 2.16s
                      Time elapsed: 00:27:04
                               ETA: 00:29:08

################################################################################
                     [1m Learning iteration 723/1500 [0m                      

                       Computation: 45845 steps/s (collection: 2.033s, learning 0.111s)
             Mean action noise std: 2.43
          Mean value_function loss: 80.6333
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 59.0158
                       Mean reward: 664.52
               Mean episode length: 236.54
    Episode_Reward/reaching_object: 1.2473
    Episode_Reward/rotating_object: 129.8432
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 2.14s
                      Time elapsed: 00:27:07
                               ETA: 00:29:06

################################################################################
                     [1m Learning iteration 724/1500 [0m                      

                       Computation: 45791 steps/s (collection: 2.036s, learning 0.111s)
             Mean action noise std: 2.43
          Mean value_function loss: 73.7798
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 59.0514
                       Mean reward: 637.27
               Mean episode length: 237.14
    Episode_Reward/reaching_object: 1.2442
    Episode_Reward/rotating_object: 125.8455
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 2.15s
                      Time elapsed: 00:27:09
                               ETA: 00:29:03

################################################################################
                     [1m Learning iteration 725/1500 [0m                      

                       Computation: 44847 steps/s (collection: 2.081s, learning 0.111s)
             Mean action noise std: 2.43
          Mean value_function loss: 83.6076
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 59.0851
                       Mean reward: 632.36
               Mean episode length: 233.56
    Episode_Reward/reaching_object: 1.2155
    Episode_Reward/rotating_object: 121.6934
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 2.19s
                      Time elapsed: 00:27:11
                               ETA: 00:29:01

################################################################################
                     [1m Learning iteration 726/1500 [0m                      

                       Computation: 44742 steps/s (collection: 2.084s, learning 0.113s)
             Mean action noise std: 2.43
          Mean value_function loss: 88.4750
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 59.1243
                       Mean reward: 573.45
               Mean episode length: 220.43
    Episode_Reward/reaching_object: 1.2231
    Episode_Reward/rotating_object: 124.8843
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 2.20s
                      Time elapsed: 00:27:13
                               ETA: 00:28:59

################################################################################
                     [1m Learning iteration 727/1500 [0m                      

                       Computation: 45079 steps/s (collection: 2.068s, learning 0.113s)
             Mean action noise std: 2.44
          Mean value_function loss: 80.5778
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 59.1582
                       Mean reward: 670.15
               Mean episode length: 232.67
    Episode_Reward/reaching_object: 1.2580
    Episode_Reward/rotating_object: 132.2151
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 2.18s
                      Time elapsed: 00:27:15
                               ETA: 00:28:56

################################################################################
                     [1m Learning iteration 728/1500 [0m                      

                       Computation: 45315 steps/s (collection: 2.052s, learning 0.117s)
             Mean action noise std: 2.44
          Mean value_function loss: 76.4596
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 59.1875
                       Mean reward: 637.05
               Mean episode length: 231.97
    Episode_Reward/reaching_object: 1.2378
    Episode_Reward/rotating_object: 128.0459
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 2.17s
                      Time elapsed: 00:27:17
                               ETA: 00:28:54

################################################################################
                     [1m Learning iteration 729/1500 [0m                      

                       Computation: 44596 steps/s (collection: 2.080s, learning 0.124s)
             Mean action noise std: 2.44
          Mean value_function loss: 67.8617
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 59.2202
                       Mean reward: 618.65
               Mean episode length: 225.26
    Episode_Reward/reaching_object: 1.2355
    Episode_Reward/rotating_object: 128.5229
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 2.20s
                      Time elapsed: 00:27:20
                               ETA: 00:28:52

################################################################################
                     [1m Learning iteration 730/1500 [0m                      

                       Computation: 45089 steps/s (collection: 2.069s, learning 0.111s)
             Mean action noise std: 2.45
          Mean value_function loss: 70.2305
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.2426
                       Mean reward: 636.29
               Mean episode length: 234.33
    Episode_Reward/reaching_object: 1.2326
    Episode_Reward/rotating_object: 126.6298
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 2.18s
                      Time elapsed: 00:27:22
                               ETA: 00:28:49

################################################################################
                     [1m Learning iteration 731/1500 [0m                      

                       Computation: 44345 steps/s (collection: 2.102s, learning 0.114s)
             Mean action noise std: 2.45
          Mean value_function loss: 79.4095
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 59.2651
                       Mean reward: 641.46
               Mean episode length: 232.98
    Episode_Reward/reaching_object: 1.2359
    Episode_Reward/rotating_object: 128.6229
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 2.22s
                      Time elapsed: 00:27:24
                               ETA: 00:28:47

################################################################################
                     [1m Learning iteration 732/1500 [0m                      

                       Computation: 45200 steps/s (collection: 2.061s, learning 0.114s)
             Mean action noise std: 2.45
          Mean value_function loss: 78.5202
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.2930
                       Mean reward: 593.10
               Mean episode length: 218.45
    Episode_Reward/reaching_object: 1.2092
    Episode_Reward/rotating_object: 123.4282
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 2.17s
                      Time elapsed: 00:27:26
                               ETA: 00:28:45

################################################################################
                     [1m Learning iteration 733/1500 [0m                      

                       Computation: 45424 steps/s (collection: 2.052s, learning 0.112s)
             Mean action noise std: 2.45
          Mean value_function loss: 83.7799
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 59.3220
                       Mean reward: 668.04
               Mean episode length: 235.17
    Episode_Reward/reaching_object: 1.2342
    Episode_Reward/rotating_object: 127.7051
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 2.16s
                      Time elapsed: 00:27:28
                               ETA: 00:28:42

################################################################################
                     [1m Learning iteration 734/1500 [0m                      

                       Computation: 44777 steps/s (collection: 2.078s, learning 0.117s)
             Mean action noise std: 2.46
          Mean value_function loss: 79.6051
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 59.3567
                       Mean reward: 663.63
               Mean episode length: 231.84
    Episode_Reward/reaching_object: 1.2431
    Episode_Reward/rotating_object: 127.6968
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 2.20s
                      Time elapsed: 00:27:31
                               ETA: 00:28:40

################################################################################
                     [1m Learning iteration 735/1500 [0m                      

                       Computation: 45431 steps/s (collection: 2.053s, learning 0.111s)
             Mean action noise std: 2.46
          Mean value_function loss: 79.5213
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 59.4024
                       Mean reward: 652.66
               Mean episode length: 238.39
    Episode_Reward/reaching_object: 1.2489
    Episode_Reward/rotating_object: 127.8575
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 2.16s
                      Time elapsed: 00:27:33
                               ETA: 00:28:38

################################################################################
                     [1m Learning iteration 736/1500 [0m                      

                       Computation: 44163 steps/s (collection: 2.109s, learning 0.117s)
             Mean action noise std: 2.47
          Mean value_function loss: 91.8539
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 59.4364
                       Mean reward: 593.19
               Mean episode length: 224.20
    Episode_Reward/reaching_object: 1.1997
    Episode_Reward/rotating_object: 122.8818
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 2.23s
                      Time elapsed: 00:27:35
                               ETA: 00:28:36

################################################################################
                     [1m Learning iteration 737/1500 [0m                      

                       Computation: 45148 steps/s (collection: 2.067s, learning 0.111s)
             Mean action noise std: 2.47
          Mean value_function loss: 81.7158
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 59.4706
                       Mean reward: 668.28
               Mean episode length: 234.65
    Episode_Reward/reaching_object: 1.2257
    Episode_Reward/rotating_object: 123.9015
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 2.18s
                      Time elapsed: 00:27:37
                               ETA: 00:28:33

################################################################################
                     [1m Learning iteration 738/1500 [0m                      

                       Computation: 44614 steps/s (collection: 2.091s, learning 0.113s)
             Mean action noise std: 2.47
          Mean value_function loss: 82.8393
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 59.5036
                       Mean reward: 663.55
               Mean episode length: 236.37
    Episode_Reward/reaching_object: 1.2073
    Episode_Reward/rotating_object: 124.3973
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 2.20s
                      Time elapsed: 00:27:39
                               ETA: 00:28:31

################################################################################
                     [1m Learning iteration 739/1500 [0m                      

                       Computation: 44543 steps/s (collection: 2.095s, learning 0.112s)
             Mean action noise std: 2.47
          Mean value_function loss: 85.3278
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 59.5283
                       Mean reward: 685.85
               Mean episode length: 239.97
    Episode_Reward/reaching_object: 1.2725
    Episode_Reward/rotating_object: 134.8186
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 2.21s
                      Time elapsed: 00:27:42
                               ETA: 00:28:29

################################################################################
                     [1m Learning iteration 740/1500 [0m                      

                       Computation: 43781 steps/s (collection: 2.131s, learning 0.114s)
             Mean action noise std: 2.48
          Mean value_function loss: 73.0565
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 59.5519
                       Mean reward: 672.43
               Mean episode length: 241.46
    Episode_Reward/reaching_object: 1.2379
    Episode_Reward/rotating_object: 128.9520
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 2.25s
                      Time elapsed: 00:27:44
                               ETA: 00:28:26

################################################################################
                     [1m Learning iteration 741/1500 [0m                      

                       Computation: 44413 steps/s (collection: 2.103s, learning 0.110s)
             Mean action noise std: 2.48
          Mean value_function loss: 81.6217
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 59.5760
                       Mean reward: 647.23
               Mean episode length: 229.22
    Episode_Reward/reaching_object: 1.2080
    Episode_Reward/rotating_object: 124.3527
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 2.21s
                      Time elapsed: 00:27:46
                               ETA: 00:28:24

################################################################################
                     [1m Learning iteration 742/1500 [0m                      

                       Computation: 44593 steps/s (collection: 2.094s, learning 0.110s)
             Mean action noise std: 2.48
          Mean value_function loss: 74.5314
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 59.6077
                       Mean reward: 627.21
               Mean episode length: 225.98
    Episode_Reward/reaching_object: 1.2307
    Episode_Reward/rotating_object: 126.8656
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 2.20s
                      Time elapsed: 00:27:48
                               ETA: 00:28:22

################################################################################
                     [1m Learning iteration 743/1500 [0m                      

                       Computation: 46046 steps/s (collection: 2.025s, learning 0.110s)
             Mean action noise std: 2.49
          Mean value_function loss: 94.9110
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 59.6516
                       Mean reward: 618.68
               Mean episode length: 228.08
    Episode_Reward/reaching_object: 1.2357
    Episode_Reward/rotating_object: 127.7052
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 2.13s
                      Time elapsed: 00:27:50
                               ETA: 00:28:20

################################################################################
                     [1m Learning iteration 744/1500 [0m                      

                       Computation: 46091 steps/s (collection: 2.022s, learning 0.111s)
             Mean action noise std: 2.49
          Mean value_function loss: 79.3012
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 59.7001
                       Mean reward: 650.76
               Mean episode length: 223.47
    Episode_Reward/reaching_object: 1.2105
    Episode_Reward/rotating_object: 126.5475
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 2.13s
                      Time elapsed: 00:27:52
                               ETA: 00:28:17

################################################################################
                     [1m Learning iteration 745/1500 [0m                      

                       Computation: 45945 steps/s (collection: 2.030s, learning 0.110s)
             Mean action noise std: 2.50
          Mean value_function loss: 83.6166
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 59.7392
                       Mean reward: 690.60
               Mean episode length: 237.42
    Episode_Reward/reaching_object: 1.2525
    Episode_Reward/rotating_object: 133.0569
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 2.14s
                      Time elapsed: 00:27:55
                               ETA: 00:28:15

################################################################################
                     [1m Learning iteration 746/1500 [0m                      

                       Computation: 45850 steps/s (collection: 2.033s, learning 0.111s)
             Mean action noise std: 2.50
          Mean value_function loss: 75.1243
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 59.7631
                       Mean reward: 642.17
               Mean episode length: 238.79
    Episode_Reward/reaching_object: 1.2550
    Episode_Reward/rotating_object: 128.3383
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 2.14s
                      Time elapsed: 00:27:57
                               ETA: 00:28:12

################################################################################
                     [1m Learning iteration 747/1500 [0m                      

                       Computation: 46046 steps/s (collection: 2.023s, learning 0.112s)
             Mean action noise std: 2.50
          Mean value_function loss: 67.8391
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 59.7886
                       Mean reward: 631.97
               Mean episode length: 229.29
    Episode_Reward/reaching_object: 1.2438
    Episode_Reward/rotating_object: 130.5436
        Episode_Reward/action_rate: -0.0384
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 2.13s
                      Time elapsed: 00:27:59
                               ETA: 00:28:10

################################################################################
                     [1m Learning iteration 748/1500 [0m                      

                       Computation: 44441 steps/s (collection: 2.099s, learning 0.113s)
             Mean action noise std: 2.50
          Mean value_function loss: 75.1270
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 59.8066
                       Mean reward: 616.72
               Mean episode length: 225.09
    Episode_Reward/reaching_object: 1.2459
    Episode_Reward/rotating_object: 129.3675
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 2.21s
                      Time elapsed: 00:28:01
                               ETA: 00:28:08

################################################################################
                     [1m Learning iteration 749/1500 [0m                      

                       Computation: 44988 steps/s (collection: 2.069s, learning 0.116s)
             Mean action noise std: 2.51
          Mean value_function loss: 93.1513
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 59.8264
                       Mean reward: 642.76
               Mean episode length: 227.99
    Episode_Reward/reaching_object: 1.2127
    Episode_Reward/rotating_object: 129.2165
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 2.19s
                      Time elapsed: 00:28:03
                               ETA: 00:28:06

################################################################################
                     [1m Learning iteration 750/1500 [0m                      

                       Computation: 44897 steps/s (collection: 2.066s, learning 0.123s)
             Mean action noise std: 2.51
          Mean value_function loss: 86.2040
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 59.8563
                       Mean reward: 648.92
               Mean episode length: 239.88
    Episode_Reward/reaching_object: 1.2467
    Episode_Reward/rotating_object: 130.1105
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 2.19s
                      Time elapsed: 00:28:05
                               ETA: 00:28:03

################################################################################
                     [1m Learning iteration 751/1500 [0m                      

                       Computation: 44475 steps/s (collection: 2.084s, learning 0.127s)
             Mean action noise std: 2.51
          Mean value_function loss: 76.8464
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 59.8990
                       Mean reward: 650.96
               Mean episode length: 232.41
    Episode_Reward/reaching_object: 1.2364
    Episode_Reward/rotating_object: 130.2262
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 2.21s
                      Time elapsed: 00:28:08
                               ETA: 00:28:01

################################################################################
                     [1m Learning iteration 752/1500 [0m                      

                       Computation: 45016 steps/s (collection: 2.057s, learning 0.126s)
             Mean action noise std: 2.52
          Mean value_function loss: 75.0337
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 59.9391
                       Mean reward: 652.52
               Mean episode length: 241.12
    Episode_Reward/reaching_object: 1.2527
    Episode_Reward/rotating_object: 129.3775
        Episode_Reward/action_rate: -0.0393
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 2.18s
                      Time elapsed: 00:28:10
                               ETA: 00:27:59

################################################################################
                     [1m Learning iteration 753/1500 [0m                      

                       Computation: 41453 steps/s (collection: 2.246s, learning 0.125s)
             Mean action noise std: 2.52
          Mean value_function loss: 80.2480
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 59.9730
                       Mean reward: 667.62
               Mean episode length: 235.29
    Episode_Reward/reaching_object: 1.2316
    Episode_Reward/rotating_object: 127.6333
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 2.37s
                      Time elapsed: 00:28:12
                               ETA: 00:27:57

################################################################################
                     [1m Learning iteration 754/1500 [0m                      

                       Computation: 41758 steps/s (collection: 2.221s, learning 0.133s)
             Mean action noise std: 2.53
          Mean value_function loss: 75.5525
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 60.0159
                       Mean reward: 674.85
               Mean episode length: 236.65
    Episode_Reward/reaching_object: 1.2455
    Episode_Reward/rotating_object: 131.0726
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 2.35s
                      Time elapsed: 00:28:15
                               ETA: 00:27:54

################################################################################
                     [1m Learning iteration 755/1500 [0m                      

                       Computation: 42073 steps/s (collection: 2.209s, learning 0.127s)
             Mean action noise std: 2.53
          Mean value_function loss: 76.6257
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 60.0576
                       Mean reward: 631.89
               Mean episode length: 230.80
    Episode_Reward/reaching_object: 1.2493
    Episode_Reward/rotating_object: 130.4256
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 2.34s
                      Time elapsed: 00:28:17
                               ETA: 00:27:52

################################################################################
                     [1m Learning iteration 756/1500 [0m                      

                       Computation: 42136 steps/s (collection: 2.208s, learning 0.125s)
             Mean action noise std: 2.54
          Mean value_function loss: 94.6287
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 60.1000
                       Mean reward: 672.07
               Mean episode length: 239.73
    Episode_Reward/reaching_object: 1.2312
    Episode_Reward/rotating_object: 129.9483
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 2.33s
                      Time elapsed: 00:28:19
                               ETA: 00:27:50

################################################################################
                     [1m Learning iteration 757/1500 [0m                      

                       Computation: 42050 steps/s (collection: 2.211s, learning 0.126s)
             Mean action noise std: 2.54
          Mean value_function loss: 99.5682
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 60.1443
                       Mean reward: 645.36
               Mean episode length: 226.49
    Episode_Reward/reaching_object: 1.2223
    Episode_Reward/rotating_object: 128.2707
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 2.34s
                      Time elapsed: 00:28:22
                               ETA: 00:27:48

################################################################################
                     [1m Learning iteration 758/1500 [0m                      

                       Computation: 44370 steps/s (collection: 2.096s, learning 0.120s)
             Mean action noise std: 2.54
          Mean value_function loss: 89.0329
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 60.1729
                       Mean reward: 634.96
               Mean episode length: 231.95
    Episode_Reward/reaching_object: 1.2368
    Episode_Reward/rotating_object: 126.5726
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 2.22s
                      Time elapsed: 00:28:24
                               ETA: 00:27:46

################################################################################
                     [1m Learning iteration 759/1500 [0m                      

                       Computation: 43961 steps/s (collection: 2.115s, learning 0.121s)
             Mean action noise std: 2.54
          Mean value_function loss: 80.6178
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 60.2000
                       Mean reward: 623.34
               Mean episode length: 230.30
    Episode_Reward/reaching_object: 1.2169
    Episode_Reward/rotating_object: 124.9173
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 2.24s
                      Time elapsed: 00:28:26
                               ETA: 00:27:43

################################################################################
                     [1m Learning iteration 760/1500 [0m                      

                       Computation: 42047 steps/s (collection: 2.225s, learning 0.113s)
             Mean action noise std: 2.55
          Mean value_function loss: 75.6313
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 60.2293
                       Mean reward: 660.52
               Mean episode length: 236.83
    Episode_Reward/reaching_object: 1.2556
    Episode_Reward/rotating_object: 130.8590
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 2.34s
                      Time elapsed: 00:28:28
                               ETA: 00:27:41

################################################################################
                     [1m Learning iteration 761/1500 [0m                      

                       Computation: 41025 steps/s (collection: 2.275s, learning 0.121s)
             Mean action noise std: 2.55
          Mean value_function loss: 80.6255
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 60.2591
                       Mean reward: 641.34
               Mean episode length: 228.22
    Episode_Reward/reaching_object: 1.2304
    Episode_Reward/rotating_object: 126.6298
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 2.40s
                      Time elapsed: 00:28:31
                               ETA: 00:27:39

################################################################################
                     [1m Learning iteration 762/1500 [0m                      

                       Computation: 42007 steps/s (collection: 2.227s, learning 0.113s)
             Mean action noise std: 2.55
          Mean value_function loss: 67.9070
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 60.2843
                       Mean reward: 699.94
               Mean episode length: 241.98
    Episode_Reward/reaching_object: 1.2554
    Episode_Reward/rotating_object: 133.3772
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 2.34s
                      Time elapsed: 00:28:33
                               ETA: 00:27:37

################################################################################
                     [1m Learning iteration 763/1500 [0m                      

                       Computation: 42747 steps/s (collection: 2.189s, learning 0.111s)
             Mean action noise std: 2.56
          Mean value_function loss: 78.4366
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 60.3152
                       Mean reward: 645.41
               Mean episode length: 235.59
    Episode_Reward/reaching_object: 1.2353
    Episode_Reward/rotating_object: 130.0421
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 2.30s
                      Time elapsed: 00:28:35
                               ETA: 00:27:35

################################################################################
                     [1m Learning iteration 764/1500 [0m                      

                       Computation: 42518 steps/s (collection: 2.202s, learning 0.110s)
             Mean action noise std: 2.56
          Mean value_function loss: 91.2857
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 60.3389
                       Mean reward: 654.90
               Mean episode length: 234.39
    Episode_Reward/reaching_object: 1.2263
    Episode_Reward/rotating_object: 128.0999
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 2.31s
                      Time elapsed: 00:28:38
                               ETA: 00:27:33

################################################################################
                     [1m Learning iteration 765/1500 [0m                      

                       Computation: 42445 steps/s (collection: 2.205s, learning 0.111s)
             Mean action noise std: 2.56
          Mean value_function loss: 73.7794
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 60.3674
                       Mean reward: 634.02
               Mean episode length: 228.13
    Episode_Reward/reaching_object: 1.2227
    Episode_Reward/rotating_object: 125.2775
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 2.32s
                      Time elapsed: 00:28:40
                               ETA: 00:27:30

################################################################################
                     [1m Learning iteration 766/1500 [0m                      

                       Computation: 42631 steps/s (collection: 2.193s, learning 0.113s)
             Mean action noise std: 2.57
          Mean value_function loss: 66.2087
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 60.3959
                       Mean reward: 688.50
               Mean episode length: 239.45
    Episode_Reward/reaching_object: 1.2363
    Episode_Reward/rotating_object: 129.0072
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 2.31s
                      Time elapsed: 00:28:42
                               ETA: 00:27:28

################################################################################
                     [1m Learning iteration 767/1500 [0m                      

                       Computation: 42920 steps/s (collection: 2.180s, learning 0.111s)
             Mean action noise std: 2.57
          Mean value_function loss: 73.7198
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 60.4168
                       Mean reward: 670.71
               Mean episode length: 236.71
    Episode_Reward/reaching_object: 1.2112
    Episode_Reward/rotating_object: 121.4573
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 2.29s
                      Time elapsed: 00:28:45
                               ETA: 00:27:26

################################################################################
                     [1m Learning iteration 768/1500 [0m                      

                       Computation: 45449 steps/s (collection: 2.049s, learning 0.114s)
             Mean action noise std: 2.57
          Mean value_function loss: 71.5853
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 60.4335
                       Mean reward: 714.62
               Mean episode length: 247.36
    Episode_Reward/reaching_object: 1.2234
    Episode_Reward/rotating_object: 131.8164
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 2.16s
                      Time elapsed: 00:28:47
                               ETA: 00:27:24

################################################################################
                     [1m Learning iteration 769/1500 [0m                      

                       Computation: 45530 steps/s (collection: 2.046s, learning 0.114s)
             Mean action noise std: 2.57
          Mean value_function loss: 80.1652
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 60.4553
                       Mean reward: 680.60
               Mean episode length: 238.80
    Episode_Reward/reaching_object: 1.2166
    Episode_Reward/rotating_object: 128.6918
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 2.16s
                      Time elapsed: 00:28:49
                               ETA: 00:27:21

################################################################################
                     [1m Learning iteration 770/1500 [0m                      

                       Computation: 45011 steps/s (collection: 2.072s, learning 0.111s)
             Mean action noise std: 2.58
          Mean value_function loss: 77.3223
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 60.4902
                       Mean reward: 698.60
               Mean episode length: 242.65
    Episode_Reward/reaching_object: 1.2174
    Episode_Reward/rotating_object: 128.8334
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 2.18s
                      Time elapsed: 00:28:51
                               ETA: 00:27:19

################################################################################
                     [1m Learning iteration 771/1500 [0m                      

                       Computation: 44282 steps/s (collection: 2.103s, learning 0.116s)
             Mean action noise std: 2.58
          Mean value_function loss: 82.2288
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 60.5252
                       Mean reward: 634.26
               Mean episode length: 227.28
    Episode_Reward/reaching_object: 1.2127
    Episode_Reward/rotating_object: 127.4724
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 2.22s
                      Time elapsed: 00:28:53
                               ETA: 00:27:17

################################################################################
                     [1m Learning iteration 772/1500 [0m                      

                       Computation: 44846 steps/s (collection: 2.081s, learning 0.111s)
             Mean action noise std: 2.58
          Mean value_function loss: 91.9631
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 60.5609
                       Mean reward: 639.31
               Mean episode length: 231.55
    Episode_Reward/reaching_object: 1.2159
    Episode_Reward/rotating_object: 128.7786
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 2.19s
                      Time elapsed: 00:28:56
                               ETA: 00:27:15

################################################################################
                     [1m Learning iteration 773/1500 [0m                      

                       Computation: 45063 steps/s (collection: 2.069s, learning 0.113s)
             Mean action noise std: 2.59
          Mean value_function loss: 64.5979
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 60.5963
                       Mean reward: 670.44
               Mean episode length: 239.46
    Episode_Reward/reaching_object: 1.2371
    Episode_Reward/rotating_object: 129.5192
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 2.18s
                      Time elapsed: 00:28:58
                               ETA: 00:27:12

################################################################################
                     [1m Learning iteration 774/1500 [0m                      

                       Computation: 44483 steps/s (collection: 2.097s, learning 0.113s)
             Mean action noise std: 2.59
          Mean value_function loss: 64.8721
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 60.6415
                       Mean reward: 663.83
               Mean episode length: 235.09
    Episode_Reward/reaching_object: 1.2434
    Episode_Reward/rotating_object: 132.8743
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 2.21s
                      Time elapsed: 00:29:00
                               ETA: 00:27:10

################################################################################
                     [1m Learning iteration 775/1500 [0m                      

                       Computation: 43927 steps/s (collection: 2.120s, learning 0.118s)
             Mean action noise std: 2.59
          Mean value_function loss: 75.0397
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 60.6705
                       Mean reward: 672.76
               Mean episode length: 242.08
    Episode_Reward/reaching_object: 1.2106
    Episode_Reward/rotating_object: 128.2995
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 2.24s
                      Time elapsed: 00:29:02
                               ETA: 00:27:08

################################################################################
                     [1m Learning iteration 776/1500 [0m                      

                       Computation: 43637 steps/s (collection: 2.139s, learning 0.113s)
             Mean action noise std: 2.60
          Mean value_function loss: 63.5605
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 60.7029
                       Mean reward: 683.05
               Mean episode length: 238.61
    Episode_Reward/reaching_object: 1.2429
    Episode_Reward/rotating_object: 133.1452
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 2.25s
                      Time elapsed: 00:29:04
                               ETA: 00:27:05

################################################################################
                     [1m Learning iteration 777/1500 [0m                      

                       Computation: 44075 steps/s (collection: 2.116s, learning 0.114s)
             Mean action noise std: 2.60
          Mean value_function loss: 66.8912
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 60.7342
                       Mean reward: 646.30
               Mean episode length: 234.76
    Episode_Reward/reaching_object: 1.2189
    Episode_Reward/rotating_object: 130.3701
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 2.23s
                      Time elapsed: 00:29:07
                               ETA: 00:27:03

################################################################################
                     [1m Learning iteration 778/1500 [0m                      

                       Computation: 44434 steps/s (collection: 2.101s, learning 0.111s)
             Mean action noise std: 2.61
          Mean value_function loss: 63.3805
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 60.7651
                       Mean reward: 675.66
               Mean episode length: 240.30
    Episode_Reward/reaching_object: 1.2349
    Episode_Reward/rotating_object: 131.8118
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 2.21s
                      Time elapsed: 00:29:09
                               ETA: 00:27:01

################################################################################
                     [1m Learning iteration 779/1500 [0m                      

                       Computation: 44920 steps/s (collection: 2.077s, learning 0.111s)
             Mean action noise std: 2.61
          Mean value_function loss: 81.5372
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 60.8004
                       Mean reward: 671.13
               Mean episode length: 236.49
    Episode_Reward/reaching_object: 1.2321
    Episode_Reward/rotating_object: 133.5488
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 2.19s
                      Time elapsed: 00:29:11
                               ETA: 00:26:59

################################################################################
                     [1m Learning iteration 780/1500 [0m                      

                       Computation: 44675 steps/s (collection: 2.087s, learning 0.113s)
             Mean action noise std: 2.61
          Mean value_function loss: 78.1372
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 60.8334
                       Mean reward: 658.51
               Mean episode length: 236.94
    Episode_Reward/reaching_object: 1.2249
    Episode_Reward/rotating_object: 131.3316
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 2.20s
                      Time elapsed: 00:29:13
                               ETA: 00:26:56

################################################################################
                     [1m Learning iteration 781/1500 [0m                      

                       Computation: 45079 steps/s (collection: 2.063s, learning 0.118s)
             Mean action noise std: 2.62
          Mean value_function loss: 68.7137
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 60.8611
                       Mean reward: 692.89
               Mean episode length: 242.14
    Episode_Reward/reaching_object: 1.2168
    Episode_Reward/rotating_object: 131.4290
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 2.18s
                      Time elapsed: 00:29:15
                               ETA: 00:26:54

################################################################################
                     [1m Learning iteration 782/1500 [0m                      

                       Computation: 44764 steps/s (collection: 2.082s, learning 0.114s)
             Mean action noise std: 2.62
          Mean value_function loss: 88.4074
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 60.8884
                       Mean reward: 643.95
               Mean episode length: 229.13
    Episode_Reward/reaching_object: 1.2133
    Episode_Reward/rotating_object: 130.0888
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 2.20s
                      Time elapsed: 00:29:18
                               ETA: 00:26:52

################################################################################
                     [1m Learning iteration 783/1500 [0m                      

                       Computation: 45663 steps/s (collection: 2.041s, learning 0.112s)
             Mean action noise std: 2.62
          Mean value_function loss: 70.8871
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 60.9232
                       Mean reward: 692.91
               Mean episode length: 233.97
    Episode_Reward/reaching_object: 1.2158
    Episode_Reward/rotating_object: 133.3262
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 2.15s
                      Time elapsed: 00:29:20
                               ETA: 00:26:49

################################################################################
                     [1m Learning iteration 784/1500 [0m                      

                       Computation: 44048 steps/s (collection: 2.118s, learning 0.114s)
             Mean action noise std: 2.63
          Mean value_function loss: 72.5594
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 60.9549
                       Mean reward: 672.60
               Mean episode length: 236.90
    Episode_Reward/reaching_object: 1.2028
    Episode_Reward/rotating_object: 128.6065
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 2.23s
                      Time elapsed: 00:29:22
                               ETA: 00:26:47

################################################################################
                     [1m Learning iteration 785/1500 [0m                      

                       Computation: 46041 steps/s (collection: 2.025s, learning 0.111s)
             Mean action noise std: 2.63
          Mean value_function loss: 80.3907
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 60.9925
                       Mean reward: 686.52
               Mean episode length: 234.85
    Episode_Reward/reaching_object: 1.2076
    Episode_Reward/rotating_object: 131.4334
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 2.14s
                      Time elapsed: 00:29:24
                               ETA: 00:26:45

################################################################################
                     [1m Learning iteration 786/1500 [0m                      

                       Computation: 46177 steps/s (collection: 2.019s, learning 0.110s)
             Mean action noise std: 2.63
          Mean value_function loss: 86.8147
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 61.0242
                       Mean reward: 654.68
               Mean episode length: 233.79
    Episode_Reward/reaching_object: 1.2015
    Episode_Reward/rotating_object: 130.3093
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 2.13s
                      Time elapsed: 00:29:26
                               ETA: 00:26:42

################################################################################
                     [1m Learning iteration 787/1500 [0m                      

                       Computation: 46086 steps/s (collection: 2.023s, learning 0.110s)
             Mean action noise std: 2.64
          Mean value_function loss: 81.4726
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 61.0551
                       Mean reward: 650.08
               Mean episode length: 230.68
    Episode_Reward/reaching_object: 1.2120
    Episode_Reward/rotating_object: 132.7093
        Episode_Reward/action_rate: -0.0433
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 2.13s
                      Time elapsed: 00:29:28
                               ETA: 00:26:40

################################################################################
                     [1m Learning iteration 788/1500 [0m                      

                       Computation: 46140 steps/s (collection: 2.019s, learning 0.111s)
             Mean action noise std: 2.64
          Mean value_function loss: 84.8229
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 61.0787
                       Mean reward: 640.97
               Mean episode length: 229.99
    Episode_Reward/reaching_object: 1.2114
    Episode_Reward/rotating_object: 128.2847
        Episode_Reward/action_rate: -0.0434
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 2.13s
                      Time elapsed: 00:29:31
                               ETA: 00:26:38

################################################################################
                     [1m Learning iteration 789/1500 [0m                      

                       Computation: 46259 steps/s (collection: 2.015s, learning 0.110s)
             Mean action noise std: 2.64
          Mean value_function loss: 77.8385
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 61.1171
                       Mean reward: 634.76
               Mean episode length: 227.95
    Episode_Reward/reaching_object: 1.2049
    Episode_Reward/rotating_object: 128.2499
        Episode_Reward/action_rate: -0.0433
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 2.13s
                      Time elapsed: 00:29:33
                               ETA: 00:26:35

################################################################################
                     [1m Learning iteration 790/1500 [0m                      

                       Computation: 45831 steps/s (collection: 2.035s, learning 0.110s)
             Mean action noise std: 2.65
          Mean value_function loss: 95.7919
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 61.1586
                       Mean reward: 679.77
               Mean episode length: 238.70
    Episode_Reward/reaching_object: 1.2080
    Episode_Reward/rotating_object: 129.4366
        Episode_Reward/action_rate: -0.0433
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 2.14s
                      Time elapsed: 00:29:35
                               ETA: 00:26:33

################################################################################
                     [1m Learning iteration 791/1500 [0m                      

                       Computation: 45808 steps/s (collection: 2.036s, learning 0.110s)
             Mean action noise std: 2.65
          Mean value_function loss: 92.4497
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 61.1935
                       Mean reward: 629.99
               Mean episode length: 227.92
    Episode_Reward/reaching_object: 1.2124
    Episode_Reward/rotating_object: 129.5142
        Episode_Reward/action_rate: -0.0436
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 2.15s
                      Time elapsed: 00:29:37
                               ETA: 00:26:31

################################################################################
                     [1m Learning iteration 792/1500 [0m                      

                       Computation: 44611 steps/s (collection: 2.091s, learning 0.112s)
             Mean action noise std: 2.66
          Mean value_function loss: 86.4557
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 61.2219
                       Mean reward: 635.88
               Mean episode length: 222.80
    Episode_Reward/reaching_object: 1.2073
    Episode_Reward/rotating_object: 131.6736
        Episode_Reward/action_rate: -0.0434
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 2.20s
                      Time elapsed: 00:29:39
                               ETA: 00:26:28

################################################################################
                     [1m Learning iteration 793/1500 [0m                      

                       Computation: 45328 steps/s (collection: 2.058s, learning 0.111s)
             Mean action noise std: 2.66
          Mean value_function loss: 72.0180
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 61.2657
                       Mean reward: 689.48
               Mean episode length: 236.67
    Episode_Reward/reaching_object: 1.2100
    Episode_Reward/rotating_object: 133.0063
        Episode_Reward/action_rate: -0.0436
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 2.17s
                      Time elapsed: 00:29:41
                               ETA: 00:26:26

################################################################################
                     [1m Learning iteration 794/1500 [0m                      

                       Computation: 45427 steps/s (collection: 2.050s, learning 0.114s)
             Mean action noise std: 2.66
          Mean value_function loss: 66.3343
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 61.3076
                       Mean reward: 673.07
               Mean episode length: 239.42
    Episode_Reward/reaching_object: 1.2196
    Episode_Reward/rotating_object: 132.6390
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 2.16s
                      Time elapsed: 00:29:44
                               ETA: 00:26:24

################################################################################
                     [1m Learning iteration 795/1500 [0m                      

                       Computation: 44442 steps/s (collection: 2.099s, learning 0.113s)
             Mean action noise std: 2.67
          Mean value_function loss: 86.8335
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 61.3346
                       Mean reward: 679.76
               Mean episode length: 236.46
    Episode_Reward/reaching_object: 1.2203
    Episode_Reward/rotating_object: 134.1285
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 2.21s
                      Time elapsed: 00:29:46
                               ETA: 00:26:22

################################################################################
                     [1m Learning iteration 796/1500 [0m                      

                       Computation: 44614 steps/s (collection: 2.093s, learning 0.110s)
             Mean action noise std: 2.67
          Mean value_function loss: 78.6066
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 61.3608
                       Mean reward: 656.32
               Mean episode length: 238.22
    Episode_Reward/reaching_object: 1.2115
    Episode_Reward/rotating_object: 129.0881
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 2.20s
                      Time elapsed: 00:29:48
                               ETA: 00:26:19

################################################################################
                     [1m Learning iteration 797/1500 [0m                      

                       Computation: 45185 steps/s (collection: 2.062s, learning 0.113s)
             Mean action noise std: 2.67
          Mean value_function loss: 75.6994
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 61.4019
                       Mean reward: 660.81
               Mean episode length: 234.40
    Episode_Reward/reaching_object: 1.2056
    Episode_Reward/rotating_object: 130.1456
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 2.18s
                      Time elapsed: 00:29:50
                               ETA: 00:26:17

################################################################################
                     [1m Learning iteration 798/1500 [0m                      

                       Computation: 45042 steps/s (collection: 2.072s, learning 0.110s)
             Mean action noise std: 2.68
          Mean value_function loss: 71.8175
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 61.4313
                       Mean reward: 629.74
               Mean episode length: 229.23
    Episode_Reward/reaching_object: 1.1986
    Episode_Reward/rotating_object: 129.6441
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 2.18s
                      Time elapsed: 00:29:52
                               ETA: 00:26:15

################################################################################
                     [1m Learning iteration 799/1500 [0m                      

                       Computation: 45620 steps/s (collection: 2.045s, learning 0.110s)
             Mean action noise std: 2.68
          Mean value_function loss: 67.6446
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 61.4666
                       Mean reward: 660.74
               Mean episode length: 234.98
    Episode_Reward/reaching_object: 1.1990
    Episode_Reward/rotating_object: 128.5862
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 2.15s
                      Time elapsed: 00:29:54
                               ETA: 00:26:12

################################################################################
                     [1m Learning iteration 800/1500 [0m                      

                       Computation: 45494 steps/s (collection: 2.047s, learning 0.113s)
             Mean action noise std: 2.68
          Mean value_function loss: 66.2957
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 61.4977
                       Mean reward: 692.16
               Mean episode length: 244.03
    Episode_Reward/reaching_object: 1.2298
    Episode_Reward/rotating_object: 132.5372
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 2.16s
                      Time elapsed: 00:29:57
                               ETA: 00:26:10

################################################################################
                     [1m Learning iteration 801/1500 [0m                      

                       Computation: 44767 steps/s (collection: 2.080s, learning 0.116s)
             Mean action noise std: 2.69
          Mean value_function loss: 65.3546
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 61.5185
                       Mean reward: 667.07
               Mean episode length: 237.92
    Episode_Reward/reaching_object: 1.2220
    Episode_Reward/rotating_object: 132.5411
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 2.20s
                      Time elapsed: 00:29:59
                               ETA: 00:26:08

################################################################################
                     [1m Learning iteration 802/1500 [0m                      

                       Computation: 44931 steps/s (collection: 2.074s, learning 0.114s)
             Mean action noise std: 2.69
          Mean value_function loss: 77.1228
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 61.5317
                       Mean reward: 680.64
               Mean episode length: 237.15
    Episode_Reward/reaching_object: 1.1956
    Episode_Reward/rotating_object: 130.8923
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 2.19s
                      Time elapsed: 00:30:01
                               ETA: 00:26:05

################################################################################
                     [1m Learning iteration 803/1500 [0m                      

                       Computation: 45133 steps/s (collection: 2.064s, learning 0.114s)
             Mean action noise std: 2.69
          Mean value_function loss: 66.8813
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 61.5539
                       Mean reward: 666.47
               Mean episode length: 239.82
    Episode_Reward/reaching_object: 1.1984
    Episode_Reward/rotating_object: 131.0509
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 2.18s
                      Time elapsed: 00:30:03
                               ETA: 00:26:03

################################################################################
                     [1m Learning iteration 804/1500 [0m                      

                       Computation: 44936 steps/s (collection: 2.075s, learning 0.113s)
             Mean action noise std: 2.70
          Mean value_function loss: 75.3006
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 61.5868
                       Mean reward: 686.58
               Mean episode length: 235.31
    Episode_Reward/reaching_object: 1.2245
    Episode_Reward/rotating_object: 132.3404
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 2.19s
                      Time elapsed: 00:30:05
                               ETA: 00:26:01

################################################################################
                     [1m Learning iteration 805/1500 [0m                      

                       Computation: 45196 steps/s (collection: 2.064s, learning 0.111s)
             Mean action noise std: 2.70
          Mean value_function loss: 77.7848
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 61.6284
                       Mean reward: 632.29
               Mean episode length: 236.06
    Episode_Reward/reaching_object: 1.2221
    Episode_Reward/rotating_object: 133.1302
        Episode_Reward/action_rate: -0.0456
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 2.18s
                      Time elapsed: 00:30:08
                               ETA: 00:25:59

################################################################################
                     [1m Learning iteration 806/1500 [0m                      

                       Computation: 45183 steps/s (collection: 2.063s, learning 0.112s)
             Mean action noise std: 2.70
          Mean value_function loss: 84.2007
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 61.6694
                       Mean reward: 647.46
               Mean episode length: 233.61
    Episode_Reward/reaching_object: 1.2142
    Episode_Reward/rotating_object: 130.5409
        Episode_Reward/action_rate: -0.0456
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 2.18s
                      Time elapsed: 00:30:10
                               ETA: 00:25:56

################################################################################
                     [1m Learning iteration 807/1500 [0m                      

                       Computation: 45386 steps/s (collection: 2.040s, learning 0.126s)
             Mean action noise std: 2.71
          Mean value_function loss: 76.6008
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 61.7127
                       Mean reward: 695.23
               Mean episode length: 243.14
    Episode_Reward/reaching_object: 1.2226
    Episode_Reward/rotating_object: 134.2527
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 2.17s
                      Time elapsed: 00:30:12
                               ETA: 00:25:54

################################################################################
                     [1m Learning iteration 808/1500 [0m                      

                       Computation: 45655 steps/s (collection: 2.042s, learning 0.111s)
             Mean action noise std: 2.71
          Mean value_function loss: 69.2597
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 61.7532
                       Mean reward: 591.70
               Mean episode length: 220.19
    Episode_Reward/reaching_object: 1.1655
    Episode_Reward/rotating_object: 125.9729
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 2.15s
                      Time elapsed: 00:30:14
                               ETA: 00:25:52

################################################################################
                     [1m Learning iteration 809/1500 [0m                      

                       Computation: 45760 steps/s (collection: 2.024s, learning 0.125s)
             Mean action noise std: 2.72
          Mean value_function loss: 84.2388
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 61.7769
                       Mean reward: 694.39
               Mean episode length: 238.76
    Episode_Reward/reaching_object: 1.2047
    Episode_Reward/rotating_object: 131.9000
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 2.15s
                      Time elapsed: 00:30:16
                               ETA: 00:25:49

################################################################################
                     [1m Learning iteration 810/1500 [0m                      

                       Computation: 44905 steps/s (collection: 2.064s, learning 0.125s)
             Mean action noise std: 2.72
          Mean value_function loss: 78.8246
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 61.8122
                       Mean reward: 643.19
               Mean episode length: 233.09
    Episode_Reward/reaching_object: 1.1800
    Episode_Reward/rotating_object: 127.6023
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 2.19s
                      Time elapsed: 00:30:18
                               ETA: 00:25:47

################################################################################
                     [1m Learning iteration 811/1500 [0m                      

                       Computation: 44663 steps/s (collection: 2.087s, learning 0.114s)
             Mean action noise std: 2.72
          Mean value_function loss: 88.8152
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 61.8396
                       Mean reward: 617.73
               Mean episode length: 221.46
    Episode_Reward/reaching_object: 1.1904
    Episode_Reward/rotating_object: 129.6885
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 2.20s
                      Time elapsed: 00:30:21
                               ETA: 00:25:45

################################################################################
                     [1m Learning iteration 812/1500 [0m                      

                       Computation: 46355 steps/s (collection: 2.004s, learning 0.117s)
             Mean action noise std: 2.73
          Mean value_function loss: 90.9834
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 61.8736
                       Mean reward: 637.32
               Mean episode length: 225.39
    Episode_Reward/reaching_object: 1.1922
    Episode_Reward/rotating_object: 132.9178
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 2.12s
                      Time elapsed: 00:30:23
                               ETA: 00:25:42

################################################################################
                     [1m Learning iteration 813/1500 [0m                      

                       Computation: 44583 steps/s (collection: 2.094s, learning 0.111s)
             Mean action noise std: 2.73
          Mean value_function loss: 79.2661
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 61.9070
                       Mean reward: 648.82
               Mean episode length: 231.41
    Episode_Reward/reaching_object: 1.2100
    Episode_Reward/rotating_object: 131.0025
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 2.20s
                      Time elapsed: 00:30:25
                               ETA: 00:25:40

################################################################################
                     [1m Learning iteration 814/1500 [0m                      

                       Computation: 44908 steps/s (collection: 2.076s, learning 0.113s)
             Mean action noise std: 2.73
          Mean value_function loss: 82.9469
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 61.9402
                       Mean reward: 632.62
               Mean episode length: 227.34
    Episode_Reward/reaching_object: 1.1859
    Episode_Reward/rotating_object: 126.5638
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 2.19s
                      Time elapsed: 00:30:27
                               ETA: 00:25:38

################################################################################
                     [1m Learning iteration 815/1500 [0m                      

                       Computation: 44856 steps/s (collection: 2.079s, learning 0.113s)
             Mean action noise std: 2.74
          Mean value_function loss: 96.2446
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 61.9717
                       Mean reward: 648.29
               Mean episode length: 238.08
    Episode_Reward/reaching_object: 1.1893
    Episode_Reward/rotating_object: 126.4438
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 2.19s
                      Time elapsed: 00:30:29
                               ETA: 00:25:36

################################################################################
                     [1m Learning iteration 816/1500 [0m                      

                       Computation: 45008 steps/s (collection: 2.071s, learning 0.113s)
             Mean action noise std: 2.74
          Mean value_function loss: 89.8151
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 61.9994
                       Mean reward: 630.48
               Mean episode length: 229.07
    Episode_Reward/reaching_object: 1.1918
    Episode_Reward/rotating_object: 128.6337
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 2.18s
                      Time elapsed: 00:30:31
                               ETA: 00:25:33

################################################################################
                     [1m Learning iteration 817/1500 [0m                      

                       Computation: 45176 steps/s (collection: 2.063s, learning 0.113s)
             Mean action noise std: 2.74
          Mean value_function loss: 97.6445
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 62.0246
                       Mean reward: 625.76
               Mean episode length: 224.56
    Episode_Reward/reaching_object: 1.1996
    Episode_Reward/rotating_object: 128.0057
        Episode_Reward/action_rate: -0.0459
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 2.18s
                      Time elapsed: 00:30:34
                               ETA: 00:25:31

################################################################################
                     [1m Learning iteration 818/1500 [0m                      

                       Computation: 44637 steps/s (collection: 2.091s, learning 0.111s)
             Mean action noise std: 2.75
          Mean value_function loss: 90.1112
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 62.0509
                       Mean reward: 644.00
               Mean episode length: 233.28
    Episode_Reward/reaching_object: 1.1803
    Episode_Reward/rotating_object: 125.1352
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 2.20s
                      Time elapsed: 00:30:36
                               ETA: 00:25:29

################################################################################
                     [1m Learning iteration 819/1500 [0m                      

                       Computation: 44988 steps/s (collection: 2.055s, learning 0.130s)
             Mean action noise std: 2.75
          Mean value_function loss: 97.0936
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 62.0787
                       Mean reward: 604.38
               Mean episode length: 220.43
    Episode_Reward/reaching_object: 1.1882
    Episode_Reward/rotating_object: 128.0309
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 2.19s
                      Time elapsed: 00:30:38
                               ETA: 00:25:26

################################################################################
                     [1m Learning iteration 820/1500 [0m                      

                       Computation: 44782 steps/s (collection: 2.084s, learning 0.111s)
             Mean action noise std: 2.75
          Mean value_function loss: 75.6297
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 62.1006
                       Mean reward: 607.04
               Mean episode length: 232.74
    Episode_Reward/reaching_object: 1.2224
    Episode_Reward/rotating_object: 128.2956
        Episode_Reward/action_rate: -0.0472
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 2.20s
                      Time elapsed: 00:30:40
                               ETA: 00:25:24

################################################################################
                     [1m Learning iteration 821/1500 [0m                      

                       Computation: 45383 steps/s (collection: 2.055s, learning 0.111s)
             Mean action noise std: 2.75
          Mean value_function loss: 76.1068
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 62.1249
                       Mean reward: 694.68
               Mean episode length: 237.93
    Episode_Reward/reaching_object: 1.2265
    Episode_Reward/rotating_object: 132.5265
        Episode_Reward/action_rate: -0.0471
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 2.17s
                      Time elapsed: 00:30:42
                               ETA: 00:25:22

################################################################################
                     [1m Learning iteration 822/1500 [0m                      

                       Computation: 45373 steps/s (collection: 2.054s, learning 0.113s)
             Mean action noise std: 2.76
          Mean value_function loss: 70.3094
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 62.1611
                       Mean reward: 684.25
               Mean episode length: 240.76
    Episode_Reward/reaching_object: 1.2243
    Episode_Reward/rotating_object: 132.2263
        Episode_Reward/action_rate: -0.0471
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 2.17s
                      Time elapsed: 00:30:45
                               ETA: 00:25:19

################################################################################
                     [1m Learning iteration 823/1500 [0m                      

                       Computation: 44438 steps/s (collection: 2.101s, learning 0.111s)
             Mean action noise std: 2.76
          Mean value_function loss: 86.3316
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 62.2011
                       Mean reward: 726.74
               Mean episode length: 245.38
    Episode_Reward/reaching_object: 1.2303
    Episode_Reward/rotating_object: 135.5053
        Episode_Reward/action_rate: -0.0475
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 2.21s
                      Time elapsed: 00:30:47
                               ETA: 00:25:17

################################################################################
                     [1m Learning iteration 824/1500 [0m                      

                       Computation: 45454 steps/s (collection: 2.052s, learning 0.111s)
             Mean action noise std: 2.77
          Mean value_function loss: 80.8513
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 62.2355
                       Mean reward: 625.76
               Mean episode length: 230.64
    Episode_Reward/reaching_object: 1.2199
    Episode_Reward/rotating_object: 129.1730
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 2.16s
                      Time elapsed: 00:30:49
                               ETA: 00:25:15

################################################################################
                     [1m Learning iteration 825/1500 [0m                      

                       Computation: 44655 steps/s (collection: 2.085s, learning 0.117s)
             Mean action noise std: 2.77
          Mean value_function loss: 68.9331
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 62.2722
                       Mean reward: 647.60
               Mean episode length: 239.90
    Episode_Reward/reaching_object: 1.2044
    Episode_Reward/rotating_object: 129.7062
        Episode_Reward/action_rate: -0.0468
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 2.20s
                      Time elapsed: 00:30:51
                               ETA: 00:25:13

################################################################################
                     [1m Learning iteration 826/1500 [0m                      

                       Computation: 44778 steps/s (collection: 2.082s, learning 0.113s)
             Mean action noise std: 2.77
          Mean value_function loss: 58.2275
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 62.3015
                       Mean reward: 685.87
               Mean episode length: 244.27
    Episode_Reward/reaching_object: 1.2301
    Episode_Reward/rotating_object: 131.4596
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 2.20s
                      Time elapsed: 00:30:53
                               ETA: 00:25:10

################################################################################
                     [1m Learning iteration 827/1500 [0m                      

                       Computation: 45403 steps/s (collection: 2.055s, learning 0.111s)
             Mean action noise std: 2.78
          Mean value_function loss: 90.5130
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 62.3310
                       Mean reward: 666.57
               Mean episode length: 235.57
    Episode_Reward/reaching_object: 1.2075
    Episode_Reward/rotating_object: 129.9768
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 2.17s
                      Time elapsed: 00:30:55
                               ETA: 00:25:08

################################################################################
                     [1m Learning iteration 828/1500 [0m                      

                       Computation: 45169 steps/s (collection: 2.064s, learning 0.112s)
             Mean action noise std: 2.78
          Mean value_function loss: 73.9618
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 62.3546
                       Mean reward: 631.93
               Mean episode length: 235.65
    Episode_Reward/reaching_object: 1.2302
    Episode_Reward/rotating_object: 130.9665
        Episode_Reward/action_rate: -0.0482
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 2.18s
                      Time elapsed: 00:30:58
                               ETA: 00:25:06

################################################################################
                     [1m Learning iteration 829/1500 [0m                      

                       Computation: 45425 steps/s (collection: 2.053s, learning 0.111s)
             Mean action noise std: 2.78
          Mean value_function loss: 82.7730
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 62.3786
                       Mean reward: 657.85
               Mean episode length: 236.48
    Episode_Reward/reaching_object: 1.2132
    Episode_Reward/rotating_object: 131.5418
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 2.16s
                      Time elapsed: 00:31:00
                               ETA: 00:25:03

################################################################################
                     [1m Learning iteration 830/1500 [0m                      

                       Computation: 46449 steps/s (collection: 2.005s, learning 0.111s)
             Mean action noise std: 2.78
          Mean value_function loss: 65.2069
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 62.3983
                       Mean reward: 686.57
               Mean episode length: 241.74
    Episode_Reward/reaching_object: 1.2377
    Episode_Reward/rotating_object: 134.1371
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 2.12s
                      Time elapsed: 00:31:02
                               ETA: 00:25:01

################################################################################
                     [1m Learning iteration 831/1500 [0m                      

                       Computation: 45626 steps/s (collection: 2.043s, learning 0.111s)
             Mean action noise std: 2.79
          Mean value_function loss: 73.9326
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 62.4157
                       Mean reward: 670.96
               Mean episode length: 235.84
    Episode_Reward/reaching_object: 1.2000
    Episode_Reward/rotating_object: 129.8940
        Episode_Reward/action_rate: -0.0475
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 2.15s
                      Time elapsed: 00:31:04
                               ETA: 00:24:59

################################################################################
                     [1m Learning iteration 832/1500 [0m                      

                       Computation: 46223 steps/s (collection: 2.015s, learning 0.112s)
             Mean action noise std: 2.79
          Mean value_function loss: 77.0238
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 62.4370
                       Mean reward: 647.19
               Mean episode length: 228.69
    Episode_Reward/reaching_object: 1.2178
    Episode_Reward/rotating_object: 133.5030
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 2.13s
                      Time elapsed: 00:31:06
                               ETA: 00:24:56

################################################################################
                     [1m Learning iteration 833/1500 [0m                      

                       Computation: 46185 steps/s (collection: 2.017s, learning 0.111s)
             Mean action noise std: 2.79
          Mean value_function loss: 77.9870
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 62.4650
                       Mean reward: 661.81
               Mean episode length: 234.21
    Episode_Reward/reaching_object: 1.2166
    Episode_Reward/rotating_object: 129.4683
        Episode_Reward/action_rate: -0.0484
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 2.13s
                      Time elapsed: 00:31:08
                               ETA: 00:24:54

################################################################################
                     [1m Learning iteration 834/1500 [0m                      

                       Computation: 45885 steps/s (collection: 2.031s, learning 0.111s)
             Mean action noise std: 2.80
          Mean value_function loss: 74.4863
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 62.4947
                       Mean reward: 651.23
               Mean episode length: 230.98
    Episode_Reward/reaching_object: 1.1906
    Episode_Reward/rotating_object: 129.7763
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 2.14s
                      Time elapsed: 00:31:10
                               ETA: 00:24:52

################################################################################
                     [1m Learning iteration 835/1500 [0m                      

                       Computation: 45938 steps/s (collection: 2.029s, learning 0.111s)
             Mean action noise std: 2.80
          Mean value_function loss: 87.8439
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 62.5227
                       Mean reward: 649.51
               Mean episode length: 227.96
    Episode_Reward/reaching_object: 1.1987
    Episode_Reward/rotating_object: 130.0878
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 2.14s
                      Time elapsed: 00:31:13
                               ETA: 00:24:49

################################################################################
                     [1m Learning iteration 836/1500 [0m                      

                       Computation: 45522 steps/s (collection: 2.049s, learning 0.111s)
             Mean action noise std: 2.80
          Mean value_function loss: 78.6043
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 62.5536
                       Mean reward: 670.24
               Mean episode length: 233.75
    Episode_Reward/reaching_object: 1.2286
    Episode_Reward/rotating_object: 135.1084
        Episode_Reward/action_rate: -0.0490
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 2.16s
                      Time elapsed: 00:31:15
                               ETA: 00:24:47

################################################################################
                     [1m Learning iteration 837/1500 [0m                      

                       Computation: 44808 steps/s (collection: 2.081s, learning 0.113s)
             Mean action noise std: 2.81
          Mean value_function loss: 80.9663
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 62.5792
                       Mean reward: 659.28
               Mean episode length: 227.12
    Episode_Reward/reaching_object: 1.1947
    Episode_Reward/rotating_object: 129.9057
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 2.19s
                      Time elapsed: 00:31:17
                               ETA: 00:24:45

################################################################################
                     [1m Learning iteration 838/1500 [0m                      

                       Computation: 44670 steps/s (collection: 2.083s, learning 0.118s)
             Mean action noise std: 2.81
          Mean value_function loss: 79.1011
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 62.6012
                       Mean reward: 630.53
               Mean episode length: 235.23
    Episode_Reward/reaching_object: 1.1955
    Episode_Reward/rotating_object: 124.0172
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 2.20s
                      Time elapsed: 00:31:19
                               ETA: 00:24:43

################################################################################
                     [1m Learning iteration 839/1500 [0m                      

                       Computation: 45373 steps/s (collection: 2.055s, learning 0.112s)
             Mean action noise std: 2.81
          Mean value_function loss: 86.3474
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 62.6263
                       Mean reward: 667.42
               Mean episode length: 228.34
    Episode_Reward/reaching_object: 1.2094
    Episode_Reward/rotating_object: 132.5915
        Episode_Reward/action_rate: -0.0482
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 2.17s
                      Time elapsed: 00:31:21
                               ETA: 00:24:40

################################################################################
                     [1m Learning iteration 840/1500 [0m                      

                       Computation: 45411 steps/s (collection: 2.054s, learning 0.110s)
             Mean action noise std: 2.82
          Mean value_function loss: 94.0298
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 62.6612
                       Mean reward: 633.65
               Mean episode length: 222.12
    Episode_Reward/reaching_object: 1.1811
    Episode_Reward/rotating_object: 126.7811
        Episode_Reward/action_rate: -0.0475
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 2.16s
                      Time elapsed: 00:31:24
                               ETA: 00:24:38

################################################################################
                     [1m Learning iteration 841/1500 [0m                      

                       Computation: 45867 steps/s (collection: 2.030s, learning 0.113s)
             Mean action noise std: 2.82
          Mean value_function loss: 61.5774
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 62.6917
                       Mean reward: 674.65
               Mean episode length: 239.29
    Episode_Reward/reaching_object: 1.2285
    Episode_Reward/rotating_object: 133.0555
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 2.14s
                      Time elapsed: 00:31:26
                               ETA: 00:24:36

################################################################################
                     [1m Learning iteration 842/1500 [0m                      

                       Computation: 45530 steps/s (collection: 2.048s, learning 0.111s)
             Mean action noise std: 2.82
          Mean value_function loss: 83.1785
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 62.7176
                       Mean reward: 671.51
               Mean episode length: 236.02
    Episode_Reward/reaching_object: 1.2234
    Episode_Reward/rotating_object: 133.0859
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 2.16s
                      Time elapsed: 00:31:28
                               ETA: 00:24:33

################################################################################
                     [1m Learning iteration 843/1500 [0m                      

                       Computation: 43395 steps/s (collection: 2.152s, learning 0.113s)
             Mean action noise std: 2.83
          Mean value_function loss: 80.6165
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 62.7536
                       Mean reward: 606.07
               Mean episode length: 226.26
    Episode_Reward/reaching_object: 1.2132
    Episode_Reward/rotating_object: 131.7993
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 2.27s
                      Time elapsed: 00:31:30
                               ETA: 00:24:31

################################################################################
                     [1m Learning iteration 844/1500 [0m                      

                       Computation: 45265 steps/s (collection: 2.058s, learning 0.114s)
             Mean action noise std: 2.83
          Mean value_function loss: 91.2332
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 62.7938
                       Mean reward: 657.19
               Mean episode length: 230.84
    Episode_Reward/reaching_object: 1.2125
    Episode_Reward/rotating_object: 132.5874
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 2.17s
                      Time elapsed: 00:31:32
                               ETA: 00:24:29

################################################################################
                     [1m Learning iteration 845/1500 [0m                      

                       Computation: 45263 steps/s (collection: 2.058s, learning 0.114s)
             Mean action noise std: 2.83
          Mean value_function loss: 74.3529
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 62.8173
                       Mean reward: 659.04
               Mean episode length: 234.03
    Episode_Reward/reaching_object: 1.2119
    Episode_Reward/rotating_object: 132.2201
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 2.17s
                      Time elapsed: 00:31:34
                               ETA: 00:24:27

################################################################################
                     [1m Learning iteration 846/1500 [0m                      

                       Computation: 44798 steps/s (collection: 2.084s, learning 0.110s)
             Mean action noise std: 2.84
          Mean value_function loss: 77.2951
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 62.8515
                       Mean reward: 646.33
               Mean episode length: 228.42
    Episode_Reward/reaching_object: 1.1978
    Episode_Reward/rotating_object: 129.6372
        Episode_Reward/action_rate: -0.0484
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 2.19s
                      Time elapsed: 00:31:37
                               ETA: 00:24:24

################################################################################
                     [1m Learning iteration 847/1500 [0m                      

                       Computation: 44227 steps/s (collection: 2.098s, learning 0.125s)
             Mean action noise std: 2.84
          Mean value_function loss: 91.5229
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 62.8814
                       Mean reward: 595.75
               Mean episode length: 234.41
    Episode_Reward/reaching_object: 1.1940
    Episode_Reward/rotating_object: 125.7218
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 2.22s
                      Time elapsed: 00:31:39
                               ETA: 00:24:22

################################################################################
                     [1m Learning iteration 848/1500 [0m                      

                       Computation: 44593 steps/s (collection: 2.083s, learning 0.122s)
             Mean action noise std: 2.85
          Mean value_function loss: 103.3941
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 62.9064
                       Mean reward: 650.62
               Mean episode length: 224.76
    Episode_Reward/reaching_object: 1.2020
    Episode_Reward/rotating_object: 133.0150
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 2.20s
                      Time elapsed: 00:31:41
                               ETA: 00:24:20

################################################################################
                     [1m Learning iteration 849/1500 [0m                      

                       Computation: 43944 steps/s (collection: 2.123s, learning 0.114s)
             Mean action noise std: 2.85
          Mean value_function loss: 81.5355
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 62.9438
                       Mean reward: 633.60
               Mean episode length: 229.19
    Episode_Reward/reaching_object: 1.2139
    Episode_Reward/rotating_object: 130.0053
        Episode_Reward/action_rate: -0.0493
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 2.24s
                      Time elapsed: 00:31:43
                               ETA: 00:24:18

################################################################################
                     [1m Learning iteration 850/1500 [0m                      

                       Computation: 44128 steps/s (collection: 2.114s, learning 0.113s)
             Mean action noise std: 2.85
          Mean value_function loss: 90.0098
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 62.9760
                       Mean reward: 669.17
               Mean episode length: 229.41
    Episode_Reward/reaching_object: 1.2249
    Episode_Reward/rotating_object: 132.7967
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 2.23s
                      Time elapsed: 00:31:46
                               ETA: 00:24:15

################################################################################
                     [1m Learning iteration 851/1500 [0m                      

                       Computation: 44762 steps/s (collection: 2.085s, learning 0.111s)
             Mean action noise std: 2.85
          Mean value_function loss: 88.4635
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 62.9959
                       Mean reward: 633.14
               Mean episode length: 227.40
    Episode_Reward/reaching_object: 1.2213
    Episode_Reward/rotating_object: 131.6414
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 2.20s
                      Time elapsed: 00:31:48
                               ETA: 00:24:13

################################################################################
                     [1m Learning iteration 852/1500 [0m                      

                       Computation: 45955 steps/s (collection: 2.029s, learning 0.111s)
             Mean action noise std: 2.86
          Mean value_function loss: 82.9446
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 63.0182
                       Mean reward: 686.48
               Mean episode length: 237.24
    Episode_Reward/reaching_object: 1.2120
    Episode_Reward/rotating_object: 131.0118
        Episode_Reward/action_rate: -0.0495
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 2.14s
                      Time elapsed: 00:31:50
                               ETA: 00:24:11

################################################################################
                     [1m Learning iteration 853/1500 [0m                      

                       Computation: 46108 steps/s (collection: 2.022s, learning 0.110s)
             Mean action noise std: 2.86
          Mean value_function loss: 90.3657
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 63.0489
                       Mean reward: 649.01
               Mean episode length: 224.62
    Episode_Reward/reaching_object: 1.2140
    Episode_Reward/rotating_object: 130.8368
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 2.13s
                      Time elapsed: 00:31:52
                               ETA: 00:24:08

################################################################################
                     [1m Learning iteration 854/1500 [0m                      

                       Computation: 46421 steps/s (collection: 2.007s, learning 0.110s)
             Mean action noise std: 2.86
          Mean value_function loss: 86.1735
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 63.0832
                       Mean reward: 647.12
               Mean episode length: 231.30
    Episode_Reward/reaching_object: 1.2158
    Episode_Reward/rotating_object: 129.4118
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 2.12s
                      Time elapsed: 00:31:54
                               ETA: 00:24:06

################################################################################
                     [1m Learning iteration 855/1500 [0m                      

                       Computation: 46465 steps/s (collection: 2.005s, learning 0.110s)
             Mean action noise std: 2.87
          Mean value_function loss: 82.6476
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 63.0997
                       Mean reward: 662.94
               Mean episode length: 238.65
    Episode_Reward/reaching_object: 1.2077
    Episode_Reward/rotating_object: 130.3586
        Episode_Reward/action_rate: -0.0495
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 2.12s
                      Time elapsed: 00:31:56
                               ETA: 00:24:04

################################################################################
                     [1m Learning iteration 856/1500 [0m                      

                       Computation: 46241 steps/s (collection: 2.016s, learning 0.110s)
             Mean action noise std: 2.87
          Mean value_function loss: 79.1805
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 63.1072
                       Mean reward: 677.52
               Mean episode length: 239.17
    Episode_Reward/reaching_object: 1.1964
    Episode_Reward/rotating_object: 126.4604
        Episode_Reward/action_rate: -0.0495
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 2.13s
                      Time elapsed: 00:31:58
                               ETA: 00:24:01

################################################################################
                     [1m Learning iteration 857/1500 [0m                      

                       Computation: 46223 steps/s (collection: 2.016s, learning 0.111s)
             Mean action noise std: 2.87
          Mean value_function loss: 95.5862
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 63.1236
                       Mean reward: 648.33
               Mean episode length: 225.94
    Episode_Reward/reaching_object: 1.1975
    Episode_Reward/rotating_object: 128.5893
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 2.13s
                      Time elapsed: 00:32:00
                               ETA: 00:23:59

################################################################################
                     [1m Learning iteration 858/1500 [0m                      

                       Computation: 46375 steps/s (collection: 2.007s, learning 0.113s)
             Mean action noise std: 2.87
          Mean value_function loss: 90.9750
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 63.1587
                       Mean reward: 620.91
               Mean episode length: 232.09
    Episode_Reward/reaching_object: 1.1788
    Episode_Reward/rotating_object: 124.5526
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 2.12s
                      Time elapsed: 00:32:03
                               ETA: 00:23:57

################################################################################
                     [1m Learning iteration 859/1500 [0m                      

                       Computation: 44984 steps/s (collection: 2.071s, learning 0.114s)
             Mean action noise std: 2.88
          Mean value_function loss: 81.3821
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 63.1894
                       Mean reward: 643.87
               Mean episode length: 229.87
    Episode_Reward/reaching_object: 1.2027
    Episode_Reward/rotating_object: 132.5236
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 2.19s
                      Time elapsed: 00:32:05
                               ETA: 00:23:55

################################################################################
                     [1m Learning iteration 860/1500 [0m                      

                       Computation: 45710 steps/s (collection: 2.037s, learning 0.113s)
             Mean action noise std: 2.88
          Mean value_function loss: 71.5842
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 63.2248
                       Mean reward: 677.37
               Mean episode length: 239.38
    Episode_Reward/reaching_object: 1.2310
    Episode_Reward/rotating_object: 134.2933
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 2.15s
                      Time elapsed: 00:32:07
                               ETA: 00:23:52

################################################################################
                     [1m Learning iteration 861/1500 [0m                      

                       Computation: 45370 steps/s (collection: 2.053s, learning 0.114s)
             Mean action noise std: 2.88
          Mean value_function loss: 84.9457
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 63.2485
                       Mean reward: 649.49
               Mean episode length: 235.38
    Episode_Reward/reaching_object: 1.2275
    Episode_Reward/rotating_object: 131.3660
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 2.17s
                      Time elapsed: 00:32:09
                               ETA: 00:23:50

################################################################################
                     [1m Learning iteration 862/1500 [0m                      

                       Computation: 45575 steps/s (collection: 2.044s, learning 0.113s)
             Mean action noise std: 2.89
          Mean value_function loss: 83.0287
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 63.2780
                       Mean reward: 692.00
               Mean episode length: 245.80
    Episode_Reward/reaching_object: 1.2222
    Episode_Reward/rotating_object: 133.8155
        Episode_Reward/action_rate: -0.0511
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 2.16s
                      Time elapsed: 00:32:11
                               ETA: 00:23:48

################################################################################
                     [1m Learning iteration 863/1500 [0m                      

                       Computation: 45356 steps/s (collection: 2.055s, learning 0.112s)
             Mean action noise std: 2.89
          Mean value_function loss: 82.9611
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 63.3097
                       Mean reward: 645.39
               Mean episode length: 236.07
    Episode_Reward/reaching_object: 1.1985
    Episode_Reward/rotating_object: 128.7167
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 2.17s
                      Time elapsed: 00:32:13
                               ETA: 00:23:45

################################################################################
                     [1m Learning iteration 864/1500 [0m                      

                       Computation: 45270 steps/s (collection: 2.061s, learning 0.110s)
             Mean action noise std: 2.89
          Mean value_function loss: 87.6580
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 63.3282
                       Mean reward: 648.53
               Mean episode length: 230.49
    Episode_Reward/reaching_object: 1.2196
    Episode_Reward/rotating_object: 133.3576
        Episode_Reward/action_rate: -0.0514
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 2.17s
                      Time elapsed: 00:32:16
                               ETA: 00:23:43

################################################################################
                     [1m Learning iteration 865/1500 [0m                      

                       Computation: 45544 steps/s (collection: 2.045s, learning 0.114s)
             Mean action noise std: 2.90
          Mean value_function loss: 72.1561
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 63.3650
                       Mean reward: 674.51
               Mean episode length: 243.67
    Episode_Reward/reaching_object: 1.2084
    Episode_Reward/rotating_object: 129.7160
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 2.16s
                      Time elapsed: 00:32:18
                               ETA: 00:23:41

################################################################################
                     [1m Learning iteration 866/1500 [0m                      

                       Computation: 44709 steps/s (collection: 2.088s, learning 0.110s)
             Mean action noise std: 2.90
          Mean value_function loss: 70.3785
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 63.3918
                       Mean reward: 689.84
               Mean episode length: 239.60
    Episode_Reward/reaching_object: 1.2273
    Episode_Reward/rotating_object: 133.7399
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 2.20s
                      Time elapsed: 00:32:20
                               ETA: 00:23:38

################################################################################
                     [1m Learning iteration 867/1500 [0m                      

                       Computation: 45138 steps/s (collection: 2.047s, learning 0.130s)
             Mean action noise std: 2.90
          Mean value_function loss: 68.3832
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 63.4157
                       Mean reward: 645.62
               Mean episode length: 236.33
    Episode_Reward/reaching_object: 1.2255
    Episode_Reward/rotating_object: 132.6194
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 2.18s
                      Time elapsed: 00:32:22
                               ETA: 00:23:36

################################################################################
                     [1m Learning iteration 868/1500 [0m                      

                       Computation: 45754 steps/s (collection: 2.037s, learning 0.112s)
             Mean action noise std: 2.91
          Mean value_function loss: 73.8436
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 63.4441
                       Mean reward: 641.03
               Mean episode length: 230.62
    Episode_Reward/reaching_object: 1.2102
    Episode_Reward/rotating_object: 130.7411
        Episode_Reward/action_rate: -0.0515
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 2.15s
                      Time elapsed: 00:32:24
                               ETA: 00:23:34

################################################################################
                     [1m Learning iteration 869/1500 [0m                      

                       Computation: 45208 steps/s (collection: 2.063s, learning 0.111s)
             Mean action noise std: 2.91
          Mean value_function loss: 79.7523
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 63.4815
                       Mean reward: 638.95
               Mean episode length: 230.69
    Episode_Reward/reaching_object: 1.2094
    Episode_Reward/rotating_object: 129.9193
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 2.17s
                      Time elapsed: 00:32:26
                               ETA: 00:23:32

################################################################################
                     [1m Learning iteration 870/1500 [0m                      

                       Computation: 45420 steps/s (collection: 2.052s, learning 0.112s)
             Mean action noise std: 2.92
          Mean value_function loss: 73.1872
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 63.5230
                       Mean reward: 684.48
               Mean episode length: 242.19
    Episode_Reward/reaching_object: 1.2337
    Episode_Reward/rotating_object: 134.4171
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 2.16s
                      Time elapsed: 00:32:29
                               ETA: 00:23:29

################################################################################
                     [1m Learning iteration 871/1500 [0m                      

                       Computation: 45672 steps/s (collection: 2.042s, learning 0.110s)
             Mean action noise std: 2.92
          Mean value_function loss: 84.3279
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 63.5617
                       Mean reward: 644.88
               Mean episode length: 229.34
    Episode_Reward/reaching_object: 1.1884
    Episode_Reward/rotating_object: 128.4308
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 2.15s
                      Time elapsed: 00:32:31
                               ETA: 00:23:27

################################################################################
                     [1m Learning iteration 872/1500 [0m                      

                       Computation: 45048 steps/s (collection: 2.068s, learning 0.114s)
             Mean action noise std: 2.92
          Mean value_function loss: 72.7393
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 63.5993
                       Mean reward: 661.39
               Mean episode length: 234.49
    Episode_Reward/reaching_object: 1.1788
    Episode_Reward/rotating_object: 126.6726
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 2.18s
                      Time elapsed: 00:32:33
                               ETA: 00:23:25

################################################################################
                     [1m Learning iteration 873/1500 [0m                      

                       Computation: 44928 steps/s (collection: 2.074s, learning 0.114s)
             Mean action noise std: 2.93
          Mean value_function loss: 76.1222
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 63.6288
                       Mean reward: 648.32
               Mean episode length: 232.47
    Episode_Reward/reaching_object: 1.1876
    Episode_Reward/rotating_object: 129.9749
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 2.19s
                      Time elapsed: 00:32:35
                               ETA: 00:23:22

################################################################################
                     [1m Learning iteration 874/1500 [0m                      

                       Computation: 45606 steps/s (collection: 2.046s, learning 0.110s)
             Mean action noise std: 2.93
          Mean value_function loss: 79.3556
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 63.6528
                       Mean reward: 629.67
               Mean episode length: 227.81
    Episode_Reward/reaching_object: 1.1861
    Episode_Reward/rotating_object: 128.5872
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 2.16s
                      Time elapsed: 00:32:37
                               ETA: 00:23:20

################################################################################
                     [1m Learning iteration 875/1500 [0m                      

                       Computation: 46097 steps/s (collection: 2.023s, learning 0.110s)
             Mean action noise std: 2.93
          Mean value_function loss: 85.8805
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 63.6876
                       Mean reward: 715.51
               Mean episode length: 242.93
    Episode_Reward/reaching_object: 1.1914
    Episode_Reward/rotating_object: 131.6525
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 2.13s
                      Time elapsed: 00:32:39
                               ETA: 00:23:18

################################################################################
                     [1m Learning iteration 876/1500 [0m                      

                       Computation: 46206 steps/s (collection: 2.014s, learning 0.113s)
             Mean action noise std: 2.94
          Mean value_function loss: 78.2173
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 63.7250
                       Mean reward: 630.19
               Mean episode length: 230.53
    Episode_Reward/reaching_object: 1.1925
    Episode_Reward/rotating_object: 130.6223
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 2.13s
                      Time elapsed: 00:32:42
                               ETA: 00:23:16

################################################################################
                     [1m Learning iteration 877/1500 [0m                      

                       Computation: 46307 steps/s (collection: 2.013s, learning 0.110s)
             Mean action noise std: 2.94
          Mean value_function loss: 81.4093
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 63.7514
                       Mean reward: 628.80
               Mean episode length: 225.86
    Episode_Reward/reaching_object: 1.1912
    Episode_Reward/rotating_object: 133.0195
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 2.12s
                      Time elapsed: 00:32:44
                               ETA: 00:23:13

################################################################################
                     [1m Learning iteration 878/1500 [0m                      

                       Computation: 46530 steps/s (collection: 2.003s, learning 0.110s)
             Mean action noise std: 2.95
          Mean value_function loss: 78.5712
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 63.7822
                       Mean reward: 719.86
               Mean episode length: 241.70
    Episode_Reward/reaching_object: 1.2235
    Episode_Reward/rotating_object: 138.7228
        Episode_Reward/action_rate: -0.0536
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 2.11s
                      Time elapsed: 00:32:46
                               ETA: 00:23:11

################################################################################
                     [1m Learning iteration 879/1500 [0m                      

                       Computation: 46177 steps/s (collection: 2.018s, learning 0.111s)
             Mean action noise std: 2.95
          Mean value_function loss: 78.2432
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 63.8211
                       Mean reward: 663.11
               Mean episode length: 238.80
    Episode_Reward/reaching_object: 1.2192
    Episode_Reward/rotating_object: 135.2848
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 2.13s
                      Time elapsed: 00:32:48
                               ETA: 00:23:09

################################################################################
                     [1m Learning iteration 880/1500 [0m                      

                       Computation: 46008 steps/s (collection: 2.027s, learning 0.110s)
             Mean action noise std: 2.95
          Mean value_function loss: 82.8955
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 63.8540
                       Mean reward: 681.92
               Mean episode length: 235.77
    Episode_Reward/reaching_object: 1.1986
    Episode_Reward/rotating_object: 133.4466
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 2.14s
                      Time elapsed: 00:32:50
                               ETA: 00:23:06

################################################################################
                     [1m Learning iteration 881/1500 [0m                      

                       Computation: 45870 steps/s (collection: 2.033s, learning 0.110s)
             Mean action noise std: 2.96
          Mean value_function loss: 82.9217
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 63.8777
                       Mean reward: 691.74
               Mean episode length: 236.62
    Episode_Reward/reaching_object: 1.2008
    Episode_Reward/rotating_object: 135.3456
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 2.14s
                      Time elapsed: 00:32:52
                               ETA: 00:23:04

################################################################################
                     [1m Learning iteration 882/1500 [0m                      

                       Computation: 45557 steps/s (collection: 2.047s, learning 0.110s)
             Mean action noise std: 2.96
          Mean value_function loss: 81.2315
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 63.9125
                       Mean reward: 681.85
               Mean episode length: 238.82
    Episode_Reward/reaching_object: 1.2007
    Episode_Reward/rotating_object: 133.2842
        Episode_Reward/action_rate: -0.0536
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 2.16s
                      Time elapsed: 00:32:54
                               ETA: 00:23:02

################################################################################
                     [1m Learning iteration 883/1500 [0m                      

                       Computation: 45026 steps/s (collection: 2.071s, learning 0.113s)
             Mean action noise std: 2.96
          Mean value_function loss: 88.2798
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 63.9400
                       Mean reward: 700.46
               Mean episode length: 242.19
    Episode_Reward/reaching_object: 1.1889
    Episode_Reward/rotating_object: 131.6920
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 2.18s
                      Time elapsed: 00:32:57
                               ETA: 00:22:59

################################################################################
                     [1m Learning iteration 884/1500 [0m                      

                       Computation: 44256 steps/s (collection: 2.105s, learning 0.116s)
             Mean action noise std: 2.96
          Mean value_function loss: 82.4257
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 63.9491
                       Mean reward: 645.26
               Mean episode length: 236.13
    Episode_Reward/reaching_object: 1.1688
    Episode_Reward/rotating_object: 126.9439
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 2.22s
                      Time elapsed: 00:32:59
                               ETA: 00:22:57

################################################################################
                     [1m Learning iteration 885/1500 [0m                      

                       Computation: 44747 steps/s (collection: 2.084s, learning 0.113s)
             Mean action noise std: 2.97
          Mean value_function loss: 78.0603
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 63.9672
                       Mean reward: 680.93
               Mean episode length: 232.22
    Episode_Reward/reaching_object: 1.2013
    Episode_Reward/rotating_object: 129.3067
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 2.20s
                      Time elapsed: 00:33:01
                               ETA: 00:22:55

################################################################################
                     [1m Learning iteration 886/1500 [0m                      

                       Computation: 43352 steps/s (collection: 2.157s, learning 0.111s)
             Mean action noise std: 2.97
          Mean value_function loss: 94.5172
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 63.9968
                       Mean reward: 635.76
               Mean episode length: 226.05
    Episode_Reward/reaching_object: 1.1873
    Episode_Reward/rotating_object: 129.9509
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 2.27s
                      Time elapsed: 00:33:03
                               ETA: 00:22:53

################################################################################
                     [1m Learning iteration 887/1500 [0m                      

                       Computation: 44236 steps/s (collection: 2.102s, learning 0.120s)
             Mean action noise std: 2.97
          Mean value_function loss: 90.8581
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 64.0234
                       Mean reward: 658.07
               Mean episode length: 227.13
    Episode_Reward/reaching_object: 1.1819
    Episode_Reward/rotating_object: 129.2027
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 2.22s
                      Time elapsed: 00:33:05
                               ETA: 00:22:50

################################################################################
                     [1m Learning iteration 888/1500 [0m                      

                       Computation: 43818 steps/s (collection: 2.127s, learning 0.117s)
             Mean action noise std: 2.98
          Mean value_function loss: 79.5400
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 64.0509
                       Mean reward: 632.85
               Mean episode length: 233.63
    Episode_Reward/reaching_object: 1.1797
    Episode_Reward/rotating_object: 127.4096
        Episode_Reward/action_rate: -0.0538
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 2.24s
                      Time elapsed: 00:33:08
                               ETA: 00:22:48

################################################################################
                     [1m Learning iteration 889/1500 [0m                      

                       Computation: 44678 steps/s (collection: 2.086s, learning 0.114s)
             Mean action noise std: 2.98
          Mean value_function loss: 80.4519
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 64.0729
                       Mean reward: 621.03
               Mean episode length: 225.29
    Episode_Reward/reaching_object: 1.1871
    Episode_Reward/rotating_object: 131.2067
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 2.20s
                      Time elapsed: 00:33:10
                               ETA: 00:22:46

################################################################################
                     [1m Learning iteration 890/1500 [0m                      

                       Computation: 45268 steps/s (collection: 2.058s, learning 0.113s)
             Mean action noise std: 2.98
          Mean value_function loss: 86.3188
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 64.0980
                       Mean reward: 679.78
               Mean episode length: 237.48
    Episode_Reward/reaching_object: 1.1979
    Episode_Reward/rotating_object: 132.3774
        Episode_Reward/action_rate: -0.0544
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 2.17s
                      Time elapsed: 00:33:12
                               ETA: 00:22:44

################################################################################
                     [1m Learning iteration 891/1500 [0m                      

                       Computation: 45686 steps/s (collection: 2.040s, learning 0.112s)
             Mean action noise std: 2.99
          Mean value_function loss: 83.0057
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 64.1191
                       Mean reward: 687.58
               Mean episode length: 238.33
    Episode_Reward/reaching_object: 1.1976
    Episode_Reward/rotating_object: 132.7648
        Episode_Reward/action_rate: -0.0545
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 2.15s
                      Time elapsed: 00:33:14
                               ETA: 00:22:41

################################################################################
                     [1m Learning iteration 892/1500 [0m                      

                       Computation: 45361 steps/s (collection: 2.056s, learning 0.111s)
             Mean action noise std: 2.99
          Mean value_function loss: 84.2930
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 64.1463
                       Mean reward: 713.83
               Mean episode length: 237.89
    Episode_Reward/reaching_object: 1.2003
    Episode_Reward/rotating_object: 133.1525
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 2.17s
                      Time elapsed: 00:33:16
                               ETA: 00:22:39

################################################################################
                     [1m Learning iteration 893/1500 [0m                      

                       Computation: 45356 steps/s (collection: 2.054s, learning 0.114s)
             Mean action noise std: 2.99
          Mean value_function loss: 81.1736
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 64.1747
                       Mean reward: 649.43
               Mean episode length: 231.42
    Episode_Reward/reaching_object: 1.1705
    Episode_Reward/rotating_object: 126.9893
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 2.17s
                      Time elapsed: 00:33:19
                               ETA: 00:22:37

################################################################################
                     [1m Learning iteration 894/1500 [0m                      

                       Computation: 44979 steps/s (collection: 2.074s, learning 0.111s)
             Mean action noise std: 3.00
          Mean value_function loss: 88.0669
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 64.2042
                       Mean reward: 650.39
               Mean episode length: 232.10
    Episode_Reward/reaching_object: 1.1757
    Episode_Reward/rotating_object: 129.0247
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 2.19s
                      Time elapsed: 00:33:21
                               ETA: 00:22:35

################################################################################
                     [1m Learning iteration 895/1500 [0m                      

                       Computation: 44977 steps/s (collection: 2.056s, learning 0.129s)
             Mean action noise std: 3.00
          Mean value_function loss: 70.4756
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 64.2240
                       Mean reward: 642.02
               Mean episode length: 229.95
    Episode_Reward/reaching_object: 1.2014
    Episode_Reward/rotating_object: 134.3067
        Episode_Reward/action_rate: -0.0551
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 2.19s
                      Time elapsed: 00:33:23
                               ETA: 00:22:32

################################################################################
                     [1m Learning iteration 896/1500 [0m                      

                       Computation: 43301 steps/s (collection: 2.145s, learning 0.125s)
             Mean action noise std: 3.00
          Mean value_function loss: 74.3086
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 64.2495
                       Mean reward: 627.34
               Mean episode length: 232.64
    Episode_Reward/reaching_object: 1.1849
    Episode_Reward/rotating_object: 126.7047
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 2.27s
                      Time elapsed: 00:33:25
                               ETA: 00:22:30

################################################################################
                     [1m Learning iteration 897/1500 [0m                      

                       Computation: 42989 steps/s (collection: 2.161s, learning 0.126s)
             Mean action noise std: 3.00
          Mean value_function loss: 91.0780
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 64.2727
                       Mean reward: 667.72
               Mean episode length: 234.81
    Episode_Reward/reaching_object: 1.2061
    Episode_Reward/rotating_object: 135.6918
        Episode_Reward/action_rate: -0.0558
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 2.29s
                      Time elapsed: 00:33:27
                               ETA: 00:22:28

################################################################################
                     [1m Learning iteration 898/1500 [0m                      

                       Computation: 43291 steps/s (collection: 2.156s, learning 0.115s)
             Mean action noise std: 3.01
          Mean value_function loss: 86.8025
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 64.2987
                       Mean reward: 694.94
               Mean episode length: 240.34
    Episode_Reward/reaching_object: 1.2014
    Episode_Reward/rotating_object: 135.0017
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 2.27s
                      Time elapsed: 00:33:30
                               ETA: 00:22:26

################################################################################
                     [1m Learning iteration 899/1500 [0m                      

                       Computation: 46334 steps/s (collection: 2.010s, learning 0.112s)
             Mean action noise std: 3.01
          Mean value_function loss: 88.7484
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 64.3354
                       Mean reward: 669.56
               Mean episode length: 232.30
    Episode_Reward/reaching_object: 1.1911
    Episode_Reward/rotating_object: 131.4626
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 2.12s
                      Time elapsed: 00:33:32
                               ETA: 00:22:23

################################################################################
                     [1m Learning iteration 900/1500 [0m                      

                       Computation: 46354 steps/s (collection: 2.006s, learning 0.115s)
             Mean action noise std: 3.02
          Mean value_function loss: 90.6647
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 64.3685
                       Mean reward: 645.25
               Mean episode length: 228.03
    Episode_Reward/reaching_object: 1.1601
    Episode_Reward/rotating_object: 127.8936
        Episode_Reward/action_rate: -0.0544
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 2.12s
                      Time elapsed: 00:33:34
                               ETA: 00:22:21

################################################################################
                     [1m Learning iteration 901/1500 [0m                      

                       Computation: 46026 steps/s (collection: 2.023s, learning 0.112s)
             Mean action noise std: 3.02
          Mean value_function loss: 100.2976
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 64.4004
                       Mean reward: 673.04
               Mean episode length: 229.58
    Episode_Reward/reaching_object: 1.1811
    Episode_Reward/rotating_object: 131.3171
        Episode_Reward/action_rate: -0.0556
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 2.14s
                      Time elapsed: 00:33:36
                               ETA: 00:22:19

################################################################################
                     [1m Learning iteration 902/1500 [0m                      

                       Computation: 45849 steps/s (collection: 2.030s, learning 0.114s)
             Mean action noise std: 3.02
          Mean value_function loss: 83.8999
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 64.4348
                       Mean reward: 676.84
               Mean episode length: 233.01
    Episode_Reward/reaching_object: 1.1574
    Episode_Reward/rotating_object: 127.8909
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 2.14s
                      Time elapsed: 00:33:38
                               ETA: 00:22:16

################################################################################
                     [1m Learning iteration 903/1500 [0m                      

                       Computation: 45599 steps/s (collection: 2.042s, learning 0.113s)
             Mean action noise std: 3.03
          Mean value_function loss: 81.8519
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 64.4666
                       Mean reward: 639.50
               Mean episode length: 226.76
    Episode_Reward/reaching_object: 1.1520
    Episode_Reward/rotating_object: 128.0925
        Episode_Reward/action_rate: -0.0545
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 2.16s
                      Time elapsed: 00:33:40
                               ETA: 00:22:14

################################################################################
                     [1m Learning iteration 904/1500 [0m                      

                       Computation: 45416 steps/s (collection: 2.051s, learning 0.113s)
             Mean action noise std: 3.03
          Mean value_function loss: 92.7390
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 64.4945
                       Mean reward: 665.57
               Mean episode length: 238.49
    Episode_Reward/reaching_object: 1.2053
    Episode_Reward/rotating_object: 131.8985
        Episode_Reward/action_rate: -0.0571
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 2.16s
                      Time elapsed: 00:33:43
                               ETA: 00:22:12

################################################################################
                     [1m Learning iteration 905/1500 [0m                      

                       Computation: 45197 steps/s (collection: 2.063s, learning 0.112s)
             Mean action noise std: 3.03
          Mean value_function loss: 89.6380
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 64.5201
                       Mean reward: 649.43
               Mean episode length: 228.76
    Episode_Reward/reaching_object: 1.1802
    Episode_Reward/rotating_object: 131.6810
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 2.17s
                      Time elapsed: 00:33:45
                               ETA: 00:22:10

################################################################################
                     [1m Learning iteration 906/1500 [0m                      

                       Computation: 45599 steps/s (collection: 2.043s, learning 0.113s)
             Mean action noise std: 3.04
          Mean value_function loss: 86.9642
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 64.5453
                       Mean reward: 649.15
               Mean episode length: 227.27
    Episode_Reward/reaching_object: 1.1790
    Episode_Reward/rotating_object: 128.5455
        Episode_Reward/action_rate: -0.0561
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 2.16s
                      Time elapsed: 00:33:47
                               ETA: 00:22:07

################################################################################
                     [1m Learning iteration 907/1500 [0m                      

                       Computation: 45027 steps/s (collection: 2.072s, learning 0.111s)
             Mean action noise std: 3.04
          Mean value_function loss: 73.9645
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 64.5707
                       Mean reward: 635.91
               Mean episode length: 228.10
    Episode_Reward/reaching_object: 1.1718
    Episode_Reward/rotating_object: 126.9219
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 2.18s
                      Time elapsed: 00:33:49
                               ETA: 00:22:05

################################################################################
                     [1m Learning iteration 908/1500 [0m                      

                       Computation: 45334 steps/s (collection: 2.056s, learning 0.112s)
             Mean action noise std: 3.04
          Mean value_function loss: 75.3642
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 64.5908
                       Mean reward: 637.76
               Mean episode length: 236.54
    Episode_Reward/reaching_object: 1.1885
    Episode_Reward/rotating_object: 129.1682
        Episode_Reward/action_rate: -0.0571
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 2.17s
                      Time elapsed: 00:33:51
                               ETA: 00:22:03

################################################################################
                     [1m Learning iteration 909/1500 [0m                      

                       Computation: 45420 steps/s (collection: 2.049s, learning 0.115s)
             Mean action noise std: 3.05
          Mean value_function loss: 80.9317
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 64.6132
                       Mean reward: 639.08
               Mean episode length: 237.34
    Episode_Reward/reaching_object: 1.1887
    Episode_Reward/rotating_object: 129.2908
        Episode_Reward/action_rate: -0.0568
          Episode_Reward/joint_vel: -0.0353
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 2.16s
                      Time elapsed: 00:33:53
                               ETA: 00:22:00

################################################################################
                     [1m Learning iteration 910/1500 [0m                      

                       Computation: 45201 steps/s (collection: 2.063s, learning 0.112s)
             Mean action noise std: 3.05
          Mean value_function loss: 86.8353
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 64.6437
                       Mean reward: 595.81
               Mean episode length: 231.97
    Episode_Reward/reaching_object: 1.1848
    Episode_Reward/rotating_object: 126.8648
        Episode_Reward/action_rate: -0.0566
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 2.17s
                      Time elapsed: 00:33:56
                               ETA: 00:21:58

################################################################################
                     [1m Learning iteration 911/1500 [0m                      

                       Computation: 45469 steps/s (collection: 2.047s, learning 0.115s)
             Mean action noise std: 3.05
          Mean value_function loss: 86.2593
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 64.6651
                       Mean reward: 653.25
               Mean episode length: 231.44
    Episode_Reward/reaching_object: 1.1984
    Episode_Reward/rotating_object: 133.1844
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 2.16s
                      Time elapsed: 00:33:58
                               ETA: 00:21:56

################################################################################
                     [1m Learning iteration 912/1500 [0m                      

                       Computation: 44449 steps/s (collection: 2.084s, learning 0.127s)
             Mean action noise std: 3.06
          Mean value_function loss: 90.1292
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 64.6993
                       Mean reward: 660.87
               Mean episode length: 228.42
    Episode_Reward/reaching_object: 1.1682
    Episode_Reward/rotating_object: 129.2332
        Episode_Reward/action_rate: -0.0562
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 2.21s
                      Time elapsed: 00:34:00
                               ETA: 00:21:54

################################################################################
                     [1m Learning iteration 913/1500 [0m                      

                       Computation: 43006 steps/s (collection: 2.163s, learning 0.123s)
             Mean action noise std: 3.06
          Mean value_function loss: 91.8928
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 64.7308
                       Mean reward: 643.58
               Mean episode length: 232.40
    Episode_Reward/reaching_object: 1.1891
    Episode_Reward/rotating_object: 130.5473
        Episode_Reward/action_rate: -0.0572
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 2.29s
                      Time elapsed: 00:34:02
                               ETA: 00:21:51

################################################################################
                     [1m Learning iteration 914/1500 [0m                      

                       Computation: 42790 steps/s (collection: 2.174s, learning 0.124s)
             Mean action noise std: 3.06
          Mean value_function loss: 77.6629
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 64.7494
                       Mean reward: 643.84
               Mean episode length: 231.63
    Episode_Reward/reaching_object: 1.1756
    Episode_Reward/rotating_object: 126.6994
        Episode_Reward/action_rate: -0.0568
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 2.30s
                      Time elapsed: 00:34:05
                               ETA: 00:21:49

################################################################################
                     [1m Learning iteration 915/1500 [0m                      

                       Computation: 42338 steps/s (collection: 2.196s, learning 0.126s)
             Mean action noise std: 3.07
          Mean value_function loss: 79.8853
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 64.7686
                       Mean reward: 660.17
               Mean episode length: 236.79
    Episode_Reward/reaching_object: 1.1930
    Episode_Reward/rotating_object: 130.7621
        Episode_Reward/action_rate: -0.0576
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 2.32s
                      Time elapsed: 00:34:07
                               ETA: 00:21:47

################################################################################
                     [1m Learning iteration 916/1500 [0m                      

                       Computation: 43062 steps/s (collection: 2.157s, learning 0.126s)
             Mean action noise std: 3.07
          Mean value_function loss: 75.8099
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 64.7875
                       Mean reward: 630.14
               Mean episode length: 233.94
    Episode_Reward/reaching_object: 1.2165
    Episode_Reward/rotating_object: 133.4068
        Episode_Reward/action_rate: -0.0586
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 2.28s
                      Time elapsed: 00:34:09
                               ETA: 00:21:45

################################################################################
                     [1m Learning iteration 917/1500 [0m                      

                       Computation: 44642 steps/s (collection: 2.079s, learning 0.123s)
             Mean action noise std: 3.07
          Mean value_function loss: 88.2209
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 64.8139
                       Mean reward: 675.02
               Mean episode length: 233.94
    Episode_Reward/reaching_object: 1.1965
    Episode_Reward/rotating_object: 131.6591
        Episode_Reward/action_rate: -0.0579
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 2.20s
                      Time elapsed: 00:34:11
                               ETA: 00:21:43

################################################################################
                     [1m Learning iteration 918/1500 [0m                      

                       Computation: 45116 steps/s (collection: 2.056s, learning 0.123s)
             Mean action noise std: 3.08
          Mean value_function loss: 84.4586
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 64.8482
                       Mean reward: 696.38
               Mean episode length: 236.47
    Episode_Reward/reaching_object: 1.1964
    Episode_Reward/rotating_object: 133.5839
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 2.18s
                      Time elapsed: 00:34:14
                               ETA: 00:21:40

################################################################################
                     [1m Learning iteration 919/1500 [0m                      

                       Computation: 45785 steps/s (collection: 2.023s, learning 0.124s)
             Mean action noise std: 3.08
          Mean value_function loss: 81.7041
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 64.8792
                       Mean reward: 627.81
               Mean episode length: 224.25
    Episode_Reward/reaching_object: 1.1735
    Episode_Reward/rotating_object: 128.1565
        Episode_Reward/action_rate: -0.0573
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 2.15s
                      Time elapsed: 00:34:16
                               ETA: 00:21:38

################################################################################
                     [1m Learning iteration 920/1500 [0m                      

                       Computation: 46338 steps/s (collection: 1.999s, learning 0.123s)
             Mean action noise std: 3.08
          Mean value_function loss: 80.2562
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 64.9091
                       Mean reward: 645.23
               Mean episode length: 231.29
    Episode_Reward/reaching_object: 1.1807
    Episode_Reward/rotating_object: 127.9540
        Episode_Reward/action_rate: -0.0576
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 2.12s
                      Time elapsed: 00:34:18
                               ETA: 00:21:36

################################################################################
                     [1m Learning iteration 921/1500 [0m                      

                       Computation: 45330 steps/s (collection: 2.047s, learning 0.121s)
             Mean action noise std: 3.09
          Mean value_function loss: 72.4354
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 64.9455
                       Mean reward: 639.21
               Mean episode length: 233.62
    Episode_Reward/reaching_object: 1.2215
    Episode_Reward/rotating_object: 136.7772
        Episode_Reward/action_rate: -0.0596
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 2.17s
                      Time elapsed: 00:34:20
                               ETA: 00:21:33

################################################################################
                     [1m Learning iteration 922/1500 [0m                      

                       Computation: 46082 steps/s (collection: 2.023s, learning 0.110s)
             Mean action noise std: 3.09
          Mean value_function loss: 80.9911
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 64.9763
                       Mean reward: 697.79
               Mean episode length: 239.50
    Episode_Reward/reaching_object: 1.2104
    Episode_Reward/rotating_object: 134.6328
        Episode_Reward/action_rate: -0.0592
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 2.13s
                      Time elapsed: 00:34:22
                               ETA: 00:21:31

################################################################################
                     [1m Learning iteration 923/1500 [0m                      

                       Computation: 44774 steps/s (collection: 2.083s, learning 0.112s)
             Mean action noise std: 3.10
          Mean value_function loss: 89.9698
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 64.9999
                       Mean reward: 665.77
               Mean episode length: 229.15
    Episode_Reward/reaching_object: 1.1871
    Episode_Reward/rotating_object: 130.3264
        Episode_Reward/action_rate: -0.0582
          Episode_Reward/joint_vel: -0.0353
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 2.20s
                      Time elapsed: 00:34:24
                               ETA: 00:21:29

################################################################################
                     [1m Learning iteration 924/1500 [0m                      

                       Computation: 45225 steps/s (collection: 2.064s, learning 0.110s)
             Mean action noise std: 3.10
          Mean value_function loss: 83.0214
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 65.0273
                       Mean reward: 671.35
               Mean episode length: 239.09
    Episode_Reward/reaching_object: 1.1888
    Episode_Reward/rotating_object: 132.4209
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 2.17s
                      Time elapsed: 00:34:26
                               ETA: 00:21:27

################################################################################
                     [1m Learning iteration 925/1500 [0m                      

                       Computation: 45290 steps/s (collection: 2.060s, learning 0.110s)
             Mean action noise std: 3.10
          Mean value_function loss: 73.3863
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 65.0492
                       Mean reward: 652.38
               Mean episode length: 233.83
    Episode_Reward/reaching_object: 1.2001
    Episode_Reward/rotating_object: 133.3993
        Episode_Reward/action_rate: -0.0595
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 2.17s
                      Time elapsed: 00:34:29
                               ETA: 00:21:24

################################################################################
                     [1m Learning iteration 926/1500 [0m                      

                       Computation: 45367 steps/s (collection: 2.056s, learning 0.111s)
             Mean action noise std: 3.10
          Mean value_function loss: 87.8483
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 65.0758
                       Mean reward: 664.81
               Mean episode length: 230.35
    Episode_Reward/reaching_object: 1.1823
    Episode_Reward/rotating_object: 130.0234
        Episode_Reward/action_rate: -0.0585
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 2.17s
                      Time elapsed: 00:34:31
                               ETA: 00:21:22

################################################################################
                     [1m Learning iteration 927/1500 [0m                      

                       Computation: 45225 steps/s (collection: 2.060s, learning 0.113s)
             Mean action noise std: 3.11
          Mean value_function loss: 81.9672
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 65.1043
                       Mean reward: 661.84
               Mean episode length: 231.79
    Episode_Reward/reaching_object: 1.1970
    Episode_Reward/rotating_object: 129.5411
        Episode_Reward/action_rate: -0.0595
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 2.17s
                      Time elapsed: 00:34:33
                               ETA: 00:21:20

################################################################################
                     [1m Learning iteration 928/1500 [0m                      

                       Computation: 45535 steps/s (collection: 2.047s, learning 0.112s)
             Mean action noise std: 3.11
          Mean value_function loss: 73.2641
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 65.1414
                       Mean reward: 670.82
               Mean episode length: 238.30
    Episode_Reward/reaching_object: 1.1913
    Episode_Reward/rotating_object: 133.5579
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 2.16s
                      Time elapsed: 00:34:35
                               ETA: 00:21:18

################################################################################
                     [1m Learning iteration 929/1500 [0m                      

                       Computation: 45182 steps/s (collection: 2.062s, learning 0.113s)
             Mean action noise std: 3.12
          Mean value_function loss: 66.9529
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 65.1774
                       Mean reward: 663.65
               Mean episode length: 237.14
    Episode_Reward/reaching_object: 1.2127
    Episode_Reward/rotating_object: 134.5059
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 2.18s
                      Time elapsed: 00:34:37
                               ETA: 00:21:15

################################################################################
                     [1m Learning iteration 930/1500 [0m                      

                       Computation: 45618 steps/s (collection: 2.042s, learning 0.113s)
             Mean action noise std: 3.12
          Mean value_function loss: 70.8599
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 65.1969
                       Mean reward: 671.90
               Mean episode length: 242.02
    Episode_Reward/reaching_object: 1.2346
    Episode_Reward/rotating_object: 137.8328
        Episode_Reward/action_rate: -0.0611
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 2.15s
                      Time elapsed: 00:34:39
                               ETA: 00:21:13

################################################################################
                     [1m Learning iteration 931/1500 [0m                      

                       Computation: 45081 steps/s (collection: 2.068s, learning 0.113s)
             Mean action noise std: 3.12
          Mean value_function loss: 90.6319
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 65.2152
                       Mean reward: 641.95
               Mean episode length: 234.78
    Episode_Reward/reaching_object: 1.2027
    Episode_Reward/rotating_object: 131.7592
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 2.18s
                      Time elapsed: 00:34:42
                               ETA: 00:21:11

################################################################################
                     [1m Learning iteration 932/1500 [0m                      

                       Computation: 44979 steps/s (collection: 2.055s, learning 0.131s)
             Mean action noise std: 3.13
          Mean value_function loss: 85.3175
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 65.2480
                       Mean reward: 631.50
               Mean episode length: 228.91
    Episode_Reward/reaching_object: 1.1794
    Episode_Reward/rotating_object: 129.9519
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 2.19s
                      Time elapsed: 00:34:44
                               ETA: 00:21:08

################################################################################
                     [1m Learning iteration 933/1500 [0m                      

                       Computation: 45669 steps/s (collection: 2.041s, learning 0.111s)
             Mean action noise std: 3.13
          Mean value_function loss: 73.6964
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 65.2844
                       Mean reward: 679.62
               Mean episode length: 237.41
    Episode_Reward/reaching_object: 1.1895
    Episode_Reward/rotating_object: 130.8800
        Episode_Reward/action_rate: -0.0598
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 2.15s
                      Time elapsed: 00:34:46
                               ETA: 00:21:06

################################################################################
                     [1m Learning iteration 934/1500 [0m                      

                       Computation: 45549 steps/s (collection: 2.048s, learning 0.111s)
             Mean action noise std: 3.14
          Mean value_function loss: 65.9137
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 65.3154
                       Mean reward: 675.82
               Mean episode length: 240.46
    Episode_Reward/reaching_object: 1.2311
    Episode_Reward/rotating_object: 137.3808
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 2.16s
                      Time elapsed: 00:34:48
                               ETA: 00:21:04

################################################################################
                     [1m Learning iteration 935/1500 [0m                      

                       Computation: 45150 steps/s (collection: 2.059s, learning 0.119s)
             Mean action noise std: 3.14
          Mean value_function loss: 75.3095
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 65.3414
                       Mean reward: 685.66
               Mean episode length: 235.41
    Episode_Reward/reaching_object: 1.1915
    Episode_Reward/rotating_object: 133.9318
        Episode_Reward/action_rate: -0.0599
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 2.18s
                      Time elapsed: 00:34:50
                               ETA: 00:21:02

################################################################################
                     [1m Learning iteration 936/1500 [0m                      

                       Computation: 45061 steps/s (collection: 2.071s, learning 0.111s)
             Mean action noise std: 3.14
          Mean value_function loss: 74.5132
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 65.3695
                       Mean reward: 676.13
               Mean episode length: 239.64
    Episode_Reward/reaching_object: 1.1857
    Episode_Reward/rotating_object: 131.7111
        Episode_Reward/action_rate: -0.0596
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 2.18s
                      Time elapsed: 00:34:53
                               ETA: 00:20:59

################################################################################
                     [1m Learning iteration 937/1500 [0m                      

                       Computation: 45320 steps/s (collection: 2.055s, learning 0.114s)
             Mean action noise std: 3.14
          Mean value_function loss: 78.3137
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 65.3918
                       Mean reward: 685.19
               Mean episode length: 244.09
    Episode_Reward/reaching_object: 1.1837
    Episode_Reward/rotating_object: 130.1511
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 2.17s
                      Time elapsed: 00:34:55
                               ETA: 00:20:57

################################################################################
                     [1m Learning iteration 938/1500 [0m                      

                       Computation: 45224 steps/s (collection: 2.062s, learning 0.111s)
             Mean action noise std: 3.15
          Mean value_function loss: 81.1576
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 65.4123
                       Mean reward: 677.03
               Mean episode length: 232.94
    Episode_Reward/reaching_object: 1.2002
    Episode_Reward/rotating_object: 136.7584
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0353
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 2.17s
                      Time elapsed: 00:34:57
                               ETA: 00:20:55

################################################################################
                     [1m Learning iteration 939/1500 [0m                      

                       Computation: 45338 steps/s (collection: 2.057s, learning 0.112s)
             Mean action noise std: 3.15
          Mean value_function loss: 82.1865
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 65.4399
                       Mean reward: 693.37
               Mean episode length: 242.75
    Episode_Reward/reaching_object: 1.2346
    Episode_Reward/rotating_object: 140.5142
        Episode_Reward/action_rate: -0.0625
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 2.17s
                      Time elapsed: 00:34:59
                               ETA: 00:20:53

################################################################################
                     [1m Learning iteration 940/1500 [0m                      

                       Computation: 45371 steps/s (collection: 2.056s, learning 0.111s)
             Mean action noise std: 3.15
          Mean value_function loss: 85.3673
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 65.4669
                       Mean reward: 656.09
               Mean episode length: 233.04
    Episode_Reward/reaching_object: 1.2006
    Episode_Reward/rotating_object: 131.2223
        Episode_Reward/action_rate: -0.0611
          Episode_Reward/joint_vel: -0.0348
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 2.17s
                      Time elapsed: 00:35:01
                               ETA: 00:20:50

################################################################################
                     [1m Learning iteration 941/1500 [0m                      

                       Computation: 46071 steps/s (collection: 2.023s, learning 0.111s)
             Mean action noise std: 3.16
          Mean value_function loss: 83.8144
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 65.4878
                       Mean reward: 659.44
               Mean episode length: 233.82
    Episode_Reward/reaching_object: 1.1599
    Episode_Reward/rotating_object: 125.6662
        Episode_Reward/action_rate: -0.0591
          Episode_Reward/joint_vel: -0.0348
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 2.13s
                      Time elapsed: 00:35:03
                               ETA: 00:20:48

################################################################################
                     [1m Learning iteration 942/1500 [0m                      

                       Computation: 46391 steps/s (collection: 2.009s, learning 0.110s)
             Mean action noise std: 3.16
          Mean value_function loss: 91.4280
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 65.5220
                       Mean reward: 651.98
               Mean episode length: 226.82
    Episode_Reward/reaching_object: 1.1893
    Episode_Reward/rotating_object: 131.1225
        Episode_Reward/action_rate: -0.0605
          Episode_Reward/joint_vel: -0.0348
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 2.12s
                      Time elapsed: 00:35:05
                               ETA: 00:20:46

################################################################################
                     [1m Learning iteration 943/1500 [0m                      

                       Computation: 46070 steps/s (collection: 2.018s, learning 0.116s)
             Mean action noise std: 3.17
          Mean value_function loss: 80.8181
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 65.5607
                       Mean reward: 659.92
               Mean episode length: 235.18
    Episode_Reward/reaching_object: 1.2078
    Episode_Reward/rotating_object: 133.4599
        Episode_Reward/action_rate: -0.0616
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 2.13s
                      Time elapsed: 00:35:08
                               ETA: 00:20:43

################################################################################
                     [1m Learning iteration 944/1500 [0m                      

                       Computation: 46389 steps/s (collection: 2.007s, learning 0.112s)
             Mean action noise std: 3.17
          Mean value_function loss: 72.3818
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 65.5905
                       Mean reward: 695.48
               Mean episode length: 238.20
    Episode_Reward/reaching_object: 1.1967
    Episode_Reward/rotating_object: 132.4851
        Episode_Reward/action_rate: -0.0608
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 2.12s
                      Time elapsed: 00:35:10
                               ETA: 00:20:41

################################################################################
                     [1m Learning iteration 945/1500 [0m                      

                       Computation: 46403 steps/s (collection: 2.007s, learning 0.111s)
             Mean action noise std: 3.17
          Mean value_function loss: 78.9245
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 65.6187
                       Mean reward: 634.39
               Mean episode length: 231.09
    Episode_Reward/reaching_object: 1.2034
    Episode_Reward/rotating_object: 129.1031
        Episode_Reward/action_rate: -0.0616
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 2.12s
                      Time elapsed: 00:35:12
                               ETA: 00:20:39

################################################################################
                     [1m Learning iteration 946/1500 [0m                      

                       Computation: 46000 steps/s (collection: 2.019s, learning 0.118s)
             Mean action noise std: 3.18
          Mean value_function loss: 84.0713
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 65.6519
                       Mean reward: 646.77
               Mean episode length: 233.60
    Episode_Reward/reaching_object: 1.2119
    Episode_Reward/rotating_object: 131.0505
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 2.14s
                      Time elapsed: 00:35:14
                               ETA: 00:20:36

################################################################################
                     [1m Learning iteration 947/1500 [0m                      

                       Computation: 45289 steps/s (collection: 2.042s, learning 0.128s)
             Mean action noise std: 3.18
          Mean value_function loss: 92.8053
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 65.6808
                       Mean reward: 656.05
               Mean episode length: 240.02
    Episode_Reward/reaching_object: 1.2119
    Episode_Reward/rotating_object: 133.3854
        Episode_Reward/action_rate: -0.0621
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 2.17s
                      Time elapsed: 00:35:16
                               ETA: 00:20:34

################################################################################
                     [1m Learning iteration 948/1500 [0m                      

                       Computation: 45109 steps/s (collection: 2.065s, learning 0.115s)
             Mean action noise std: 3.18
          Mean value_function loss: 88.7933
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 65.7039
                       Mean reward: 626.14
               Mean episode length: 233.63
    Episode_Reward/reaching_object: 1.2371
    Episode_Reward/rotating_object: 135.7695
        Episode_Reward/action_rate: -0.0629
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 2.18s
                      Time elapsed: 00:35:18
                               ETA: 00:20:32

################################################################################
                     [1m Learning iteration 949/1500 [0m                      

                       Computation: 45552 steps/s (collection: 2.043s, learning 0.115s)
             Mean action noise std: 3.19
          Mean value_function loss: 86.3284
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 65.7288
                       Mean reward: 660.74
               Mean episode length: 238.81
    Episode_Reward/reaching_object: 1.2076
    Episode_Reward/rotating_object: 130.1816
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 2.16s
                      Time elapsed: 00:35:20
                               ETA: 00:20:30

################################################################################
                     [1m Learning iteration 950/1500 [0m                      

                       Computation: 45876 steps/s (collection: 2.027s, learning 0.116s)
             Mean action noise std: 3.19
          Mean value_function loss: 83.5783
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 65.7487
                       Mean reward: 663.65
               Mean episode length: 234.81
    Episode_Reward/reaching_object: 1.2157
    Episode_Reward/rotating_object: 133.8118
        Episode_Reward/action_rate: -0.0625
          Episode_Reward/joint_vel: -0.0353
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 2.14s
                      Time elapsed: 00:35:23
                               ETA: 00:20:27

################################################################################
                     [1m Learning iteration 951/1500 [0m                      

                       Computation: 46001 steps/s (collection: 2.022s, learning 0.115s)
             Mean action noise std: 3.19
          Mean value_function loss: 87.3778
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 65.7668
                       Mean reward: 662.56
               Mean episode length: 235.48
    Episode_Reward/reaching_object: 1.2022
    Episode_Reward/rotating_object: 128.3235
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 2.14s
                      Time elapsed: 00:35:25
                               ETA: 00:20:25

################################################################################
                     [1m Learning iteration 952/1500 [0m                      

                       Computation: 45301 steps/s (collection: 2.051s, learning 0.119s)
             Mean action noise std: 3.20
          Mean value_function loss: 81.5822
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 65.7901
                       Mean reward: 645.13
               Mean episode length: 231.17
    Episode_Reward/reaching_object: 1.2195
    Episode_Reward/rotating_object: 134.5977
        Episode_Reward/action_rate: -0.0630
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 2.17s
                      Time elapsed: 00:35:27
                               ETA: 00:20:23

################################################################################
                     [1m Learning iteration 953/1500 [0m                      

                       Computation: 46012 steps/s (collection: 2.024s, learning 0.113s)
             Mean action noise std: 3.20
          Mean value_function loss: 83.7556
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 65.8083
                       Mean reward: 674.84
               Mean episode length: 235.76
    Episode_Reward/reaching_object: 1.1784
    Episode_Reward/rotating_object: 130.8378
        Episode_Reward/action_rate: -0.0613
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 2.14s
                      Time elapsed: 00:35:29
                               ETA: 00:20:21

################################################################################
                     [1m Learning iteration 954/1500 [0m                      

                       Computation: 45726 steps/s (collection: 2.038s, learning 0.112s)
             Mean action noise std: 3.20
          Mean value_function loss: 84.4209
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 65.8299
                       Mean reward: 645.69
               Mean episode length: 235.05
    Episode_Reward/reaching_object: 1.1780
    Episode_Reward/rotating_object: 126.1737
        Episode_Reward/action_rate: -0.0621
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 2.15s
                      Time elapsed: 00:35:31
                               ETA: 00:20:18

################################################################################
                     [1m Learning iteration 955/1500 [0m                      

                       Computation: 46288 steps/s (collection: 2.013s, learning 0.111s)
             Mean action noise std: 3.20
          Mean value_function loss: 68.4688
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 65.8534
                       Mean reward: 643.12
               Mean episode length: 233.50
    Episode_Reward/reaching_object: 1.2073
    Episode_Reward/rotating_object: 129.0006
        Episode_Reward/action_rate: -0.0631
          Episode_Reward/joint_vel: -0.0348
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 2.12s
                      Time elapsed: 00:35:33
                               ETA: 00:20:16

################################################################################
                     [1m Learning iteration 956/1500 [0m                      

                       Computation: 43186 steps/s (collection: 2.156s, learning 0.120s)
             Mean action noise std: 3.21
          Mean value_function loss: 82.7314
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 65.8758
                       Mean reward: 660.02
               Mean episode length: 243.99
    Episode_Reward/reaching_object: 1.2057
    Episode_Reward/rotating_object: 132.8766
        Episode_Reward/action_rate: -0.0633
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 2.28s
                      Time elapsed: 00:35:36
                               ETA: 00:20:14

################################################################################
                     [1m Learning iteration 957/1500 [0m                      

                       Computation: 45499 steps/s (collection: 2.047s, learning 0.113s)
             Mean action noise std: 3.21
          Mean value_function loss: 84.4157
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 65.9067
                       Mean reward: 647.04
               Mean episode length: 240.30
    Episode_Reward/reaching_object: 1.1684
    Episode_Reward/rotating_object: 127.0704
        Episode_Reward/action_rate: -0.0616
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 2.16s
                      Time elapsed: 00:35:38
                               ETA: 00:20:11

################################################################################
                     [1m Learning iteration 958/1500 [0m                      

                       Computation: 44909 steps/s (collection: 2.078s, learning 0.111s)
             Mean action noise std: 3.22
          Mean value_function loss: 105.5577
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 65.9355
                       Mean reward: 634.23
               Mean episode length: 232.68
    Episode_Reward/reaching_object: 1.1952
    Episode_Reward/rotating_object: 131.5059
        Episode_Reward/action_rate: -0.0632
          Episode_Reward/joint_vel: -0.0353
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 2.19s
                      Time elapsed: 00:35:40
                               ETA: 00:20:09

################################################################################
                     [1m Learning iteration 959/1500 [0m                      

                       Computation: 44073 steps/s (collection: 2.103s, learning 0.127s)
             Mean action noise std: 3.22
          Mean value_function loss: 86.3267
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 65.9627
                       Mean reward: 627.01
               Mean episode length: 230.37
    Episode_Reward/reaching_object: 1.2001
    Episode_Reward/rotating_object: 130.4236
        Episode_Reward/action_rate: -0.0634
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 2.23s
                      Time elapsed: 00:35:42
                               ETA: 00:20:07

################################################################################
                     [1m Learning iteration 960/1500 [0m                      

                       Computation: 44708 steps/s (collection: 2.086s, learning 0.113s)
             Mean action noise std: 3.22
          Mean value_function loss: 82.7394
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 65.9868
                       Mean reward: 628.75
               Mean episode length: 232.12
    Episode_Reward/reaching_object: 1.2013
    Episode_Reward/rotating_object: 130.8793
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 2.20s
                      Time elapsed: 00:35:44
                               ETA: 00:20:05

################################################################################
                     [1m Learning iteration 961/1500 [0m                      

                       Computation: 45035 steps/s (collection: 2.073s, learning 0.110s)
             Mean action noise std: 3.23
          Mean value_function loss: 78.1255
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 66.0083
                       Mean reward: 667.24
               Mean episode length: 225.68
    Episode_Reward/reaching_object: 1.1910
    Episode_Reward/rotating_object: 130.1784
        Episode_Reward/action_rate: -0.0629
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 2.18s
                      Time elapsed: 00:35:47
                               ETA: 00:20:02

################################################################################
                     [1m Learning iteration 962/1500 [0m                      

                       Computation: 45799 steps/s (collection: 2.034s, learning 0.112s)
             Mean action noise std: 3.23
          Mean value_function loss: 67.6067
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 66.0311
                       Mean reward: 652.49
               Mean episode length: 238.26
    Episode_Reward/reaching_object: 1.2168
    Episode_Reward/rotating_object: 132.9672
        Episode_Reward/action_rate: -0.0646
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 2.15s
                      Time elapsed: 00:35:49
                               ETA: 00:20:00

################################################################################
                     [1m Learning iteration 963/1500 [0m                      

                       Computation: 46473 steps/s (collection: 2.005s, learning 0.110s)
             Mean action noise std: 3.23
          Mean value_function loss: 86.8981
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 66.0486
                       Mean reward: 680.05
               Mean episode length: 235.98
    Episode_Reward/reaching_object: 1.2141
    Episode_Reward/rotating_object: 133.3758
        Episode_Reward/action_rate: -0.0641
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 2.12s
                      Time elapsed: 00:35:51
                               ETA: 00:19:58

################################################################################
                     [1m Learning iteration 964/1500 [0m                      

                       Computation: 46981 steps/s (collection: 1.982s, learning 0.110s)
             Mean action noise std: 3.24
          Mean value_function loss: 78.2631
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 66.0772
                       Mean reward: 694.12
               Mean episode length: 242.25
    Episode_Reward/reaching_object: 1.2280
    Episode_Reward/rotating_object: 134.8471
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 2.09s
                      Time elapsed: 00:35:53
                               ETA: 00:19:56

################################################################################
                     [1m Learning iteration 965/1500 [0m                      

                       Computation: 46699 steps/s (collection: 1.995s, learning 0.110s)
             Mean action noise std: 3.24
          Mean value_function loss: 87.6065
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 66.1070
                       Mean reward: 674.17
               Mean episode length: 239.88
    Episode_Reward/reaching_object: 1.2138
    Episode_Reward/rotating_object: 135.6894
        Episode_Reward/action_rate: -0.0642
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 2.11s
                      Time elapsed: 00:35:55
                               ETA: 00:19:53

################################################################################
                     [1m Learning iteration 966/1500 [0m                      

                       Computation: 47147 steps/s (collection: 1.974s, learning 0.111s)
             Mean action noise std: 3.24
          Mean value_function loss: 73.5021
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 66.1343
                       Mean reward: 668.73
               Mean episode length: 235.25
    Episode_Reward/reaching_object: 1.1999
    Episode_Reward/rotating_object: 131.2178
        Episode_Reward/action_rate: -0.0641
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 2.09s
                      Time elapsed: 00:35:57
                               ETA: 00:19:51

################################################################################
                     [1m Learning iteration 967/1500 [0m                      

                       Computation: 46928 steps/s (collection: 1.985s, learning 0.110s)
             Mean action noise std: 3.25
          Mean value_function loss: 70.2204
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 66.1600
                       Mean reward: 645.36
               Mean episode length: 232.12
    Episode_Reward/reaching_object: 1.1902
    Episode_Reward/rotating_object: 129.7181
        Episode_Reward/action_rate: -0.0638
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 2.09s
                      Time elapsed: 00:35:59
                               ETA: 00:19:49

################################################################################
                     [1m Learning iteration 968/1500 [0m                      

                       Computation: 47030 steps/s (collection: 1.980s, learning 0.110s)
             Mean action noise std: 3.25
          Mean value_function loss: 82.6262
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 66.1775
                       Mean reward: 682.10
               Mean episode length: 239.09
    Episode_Reward/reaching_object: 1.2145
    Episode_Reward/rotating_object: 132.3262
        Episode_Reward/action_rate: -0.0652
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 2.09s
                      Time elapsed: 00:36:01
                               ETA: 00:19:46

################################################################################
                     [1m Learning iteration 969/1500 [0m                      

                       Computation: 46533 steps/s (collection: 2.002s, learning 0.111s)
             Mean action noise std: 3.25
          Mean value_function loss: 87.4794
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 66.2037
                       Mean reward: 688.01
               Mean episode length: 230.96
    Episode_Reward/reaching_object: 1.2020
    Episode_Reward/rotating_object: 135.0606
        Episode_Reward/action_rate: -0.0643
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 2.11s
                      Time elapsed: 00:36:03
                               ETA: 00:19:44

################################################################################
                     [1m Learning iteration 970/1500 [0m                      

                       Computation: 45986 steps/s (collection: 2.024s, learning 0.114s)
             Mean action noise std: 3.26
          Mean value_function loss: 84.3066
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 66.2339
                       Mean reward: 690.88
               Mean episode length: 233.47
    Episode_Reward/reaching_object: 1.2000
    Episode_Reward/rotating_object: 133.2902
        Episode_Reward/action_rate: -0.0645
          Episode_Reward/joint_vel: -0.0348
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 2.14s
                      Time elapsed: 00:36:06
                               ETA: 00:19:42

################################################################################
                     [1m Learning iteration 971/1500 [0m                      

                       Computation: 46171 steps/s (collection: 2.018s, learning 0.111s)
             Mean action noise std: 3.26
          Mean value_function loss: 89.9982
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 66.2601
                       Mean reward: 682.36
               Mean episode length: 238.38
    Episode_Reward/reaching_object: 1.1749
    Episode_Reward/rotating_object: 131.9052
        Episode_Reward/action_rate: -0.0635
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 2.13s
                      Time elapsed: 00:36:08
                               ETA: 00:19:40

################################################################################
                     [1m Learning iteration 972/1500 [0m                      

                       Computation: 45979 steps/s (collection: 2.028s, learning 0.110s)
             Mean action noise std: 3.26
          Mean value_function loss: 82.0542
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 66.2762
                       Mean reward: 652.98
               Mean episode length: 235.45
    Episode_Reward/reaching_object: 1.2045
    Episode_Reward/rotating_object: 130.0777
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 2.14s
                      Time elapsed: 00:36:10
                               ETA: 00:19:37

################################################################################
                     [1m Learning iteration 973/1500 [0m                      

                       Computation: 45387 steps/s (collection: 2.054s, learning 0.112s)
             Mean action noise std: 3.27
          Mean value_function loss: 76.2566
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 66.3029
                       Mean reward: 700.23
               Mean episode length: 243.88
    Episode_Reward/reaching_object: 1.2073
    Episode_Reward/rotating_object: 133.9420
        Episode_Reward/action_rate: -0.0649
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 2.17s
                      Time elapsed: 00:36:12
                               ETA: 00:19:35

################################################################################
                     [1m Learning iteration 974/1500 [0m                      

                       Computation: 45708 steps/s (collection: 2.040s, learning 0.111s)
             Mean action noise std: 3.27
          Mean value_function loss: 77.8933
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 66.3378
                       Mean reward: 690.45
               Mean episode length: 242.50
    Episode_Reward/reaching_object: 1.2097
    Episode_Reward/rotating_object: 132.2401
        Episode_Reward/action_rate: -0.0656
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 2.15s
                      Time elapsed: 00:36:14
                               ETA: 00:19:33

################################################################################
                     [1m Learning iteration 975/1500 [0m                      

                       Computation: 45793 steps/s (collection: 2.031s, learning 0.116s)
             Mean action noise std: 3.27
          Mean value_function loss: 88.2766
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 66.3588
                       Mean reward: 654.93
               Mean episode length: 231.78
    Episode_Reward/reaching_object: 1.1922
    Episode_Reward/rotating_object: 133.2044
        Episode_Reward/action_rate: -0.0644
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 2.15s
                      Time elapsed: 00:36:16
                               ETA: 00:19:30

################################################################################
                     [1m Learning iteration 976/1500 [0m                      

                       Computation: 45516 steps/s (collection: 2.049s, learning 0.111s)
             Mean action noise std: 3.27
          Mean value_function loss: 81.4758
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 66.3774
                       Mean reward: 664.07
               Mean episode length: 230.74
    Episode_Reward/reaching_object: 1.2033
    Episode_Reward/rotating_object: 135.0960
        Episode_Reward/action_rate: -0.0652
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 2.16s
                      Time elapsed: 00:36:18
                               ETA: 00:19:28

################################################################################
                     [1m Learning iteration 977/1500 [0m                      

                       Computation: 46132 steps/s (collection: 2.020s, learning 0.111s)
             Mean action noise std: 3.28
          Mean value_function loss: 86.5355
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 66.3954
                       Mean reward: 664.44
               Mean episode length: 236.23
    Episode_Reward/reaching_object: 1.2046
    Episode_Reward/rotating_object: 133.8265
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 2.13s
                      Time elapsed: 00:36:21
                               ETA: 00:19:26

################################################################################
                     [1m Learning iteration 978/1500 [0m                      

                       Computation: 46030 steps/s (collection: 2.023s, learning 0.112s)
             Mean action noise std: 3.28
          Mean value_function loss: 88.8731
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 66.4119
                       Mean reward: 714.59
               Mean episode length: 243.85
    Episode_Reward/reaching_object: 1.2002
    Episode_Reward/rotating_object: 135.1776
        Episode_Reward/action_rate: -0.0656
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 2.14s
                      Time elapsed: 00:36:23
                               ETA: 00:19:24

################################################################################
                     [1m Learning iteration 979/1500 [0m                      

                       Computation: 45977 steps/s (collection: 2.026s, learning 0.113s)
             Mean action noise std: 3.28
          Mean value_function loss: 83.4554
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 66.4354
                       Mean reward: 649.59
               Mean episode length: 233.70
    Episode_Reward/reaching_object: 1.2026
    Episode_Reward/rotating_object: 133.2908
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 2.14s
                      Time elapsed: 00:36:25
                               ETA: 00:19:21

################################################################################
                     [1m Learning iteration 980/1500 [0m                      

                       Computation: 45813 steps/s (collection: 2.031s, learning 0.115s)
             Mean action noise std: 3.29
          Mean value_function loss: 98.1534
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 66.4636
                       Mean reward: 702.09
               Mean episode length: 238.09
    Episode_Reward/reaching_object: 1.1962
    Episode_Reward/rotating_object: 133.2919
        Episode_Reward/action_rate: -0.0654
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 2.15s
                      Time elapsed: 00:36:27
                               ETA: 00:19:19

################################################################################
                     [1m Learning iteration 981/1500 [0m                      

                       Computation: 45106 steps/s (collection: 2.066s, learning 0.113s)
             Mean action noise std: 3.29
          Mean value_function loss: 77.2504
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 66.5046
                       Mean reward: 664.11
               Mean episode length: 234.27
    Episode_Reward/reaching_object: 1.1868
    Episode_Reward/rotating_object: 129.8503
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 2.18s
                      Time elapsed: 00:36:29
                               ETA: 00:19:17

################################################################################
                     [1m Learning iteration 982/1500 [0m                      

                       Computation: 46105 steps/s (collection: 2.021s, learning 0.111s)
             Mean action noise std: 3.29
          Mean value_function loss: 82.7643
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 66.5271
                       Mean reward: 701.12
               Mean episode length: 237.65
    Episode_Reward/reaching_object: 1.1868
    Episode_Reward/rotating_object: 131.2474
        Episode_Reward/action_rate: -0.0652
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 2.13s
                      Time elapsed: 00:36:31
                               ETA: 00:19:14

################################################################################
                     [1m Learning iteration 983/1500 [0m                      

                       Computation: 45838 steps/s (collection: 2.031s, learning 0.113s)
             Mean action noise std: 3.30
          Mean value_function loss: 80.2577
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 66.5421
                       Mean reward: 648.24
               Mean episode length: 235.62
    Episode_Reward/reaching_object: 1.1937
    Episode_Reward/rotating_object: 131.2025
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 2.14s
                      Time elapsed: 00:36:33
                               ETA: 00:19:12

################################################################################
                     [1m Learning iteration 984/1500 [0m                      

                       Computation: 45810 steps/s (collection: 2.030s, learning 0.115s)
             Mean action noise std: 3.30
          Mean value_function loss: 79.7722
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 66.5527
                       Mean reward: 668.48
               Mean episode length: 238.26
    Episode_Reward/reaching_object: 1.2089
    Episode_Reward/rotating_object: 134.5213
        Episode_Reward/action_rate: -0.0668
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 2.15s
                      Time elapsed: 00:36:36
                               ETA: 00:19:10

################################################################################
                     [1m Learning iteration 985/1500 [0m                      

                       Computation: 45680 steps/s (collection: 2.040s, learning 0.112s)
             Mean action noise std: 3.30
          Mean value_function loss: 91.8508
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 66.5733
                       Mean reward: 704.54
               Mean episode length: 234.94
    Episode_Reward/reaching_object: 1.1929
    Episode_Reward/rotating_object: 134.1250
        Episode_Reward/action_rate: -0.0661
          Episode_Reward/joint_vel: -0.0348
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 2.15s
                      Time elapsed: 00:36:38
                               ETA: 00:19:08

################################################################################
                     [1m Learning iteration 986/1500 [0m                      

                       Computation: 46474 steps/s (collection: 2.005s, learning 0.111s)
             Mean action noise std: 3.31
          Mean value_function loss: 86.9136
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 66.6003
                       Mean reward: 616.22
               Mean episode length: 226.29
    Episode_Reward/reaching_object: 1.1901
    Episode_Reward/rotating_object: 129.2005
        Episode_Reward/action_rate: -0.0665
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 2.12s
                      Time elapsed: 00:36:40
                               ETA: 00:19:05

################################################################################
                     [1m Learning iteration 987/1500 [0m                      

                       Computation: 46687 steps/s (collection: 1.995s, learning 0.110s)
             Mean action noise std: 3.31
          Mean value_function loss: 92.8399
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 66.6275
                       Mean reward: 656.78
               Mean episode length: 234.00
    Episode_Reward/reaching_object: 1.2043
    Episode_Reward/rotating_object: 133.7715
        Episode_Reward/action_rate: -0.0669
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 2.11s
                      Time elapsed: 00:36:42
                               ETA: 00:19:03

################################################################################
                     [1m Learning iteration 988/1500 [0m                      

                       Computation: 46068 steps/s (collection: 2.023s, learning 0.110s)
             Mean action noise std: 3.31
          Mean value_function loss: 91.3047
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 66.6542
                       Mean reward: 694.76
               Mean episode length: 236.35
    Episode_Reward/reaching_object: 1.1946
    Episode_Reward/rotating_object: 134.9478
        Episode_Reward/action_rate: -0.0663
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 2.13s
                      Time elapsed: 00:36:44
                               ETA: 00:19:01

################################################################################
                     [1m Learning iteration 989/1500 [0m                      

                       Computation: 46449 steps/s (collection: 2.006s, learning 0.111s)
             Mean action noise std: 3.32
          Mean value_function loss: 92.9312
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 66.6832
                       Mean reward: 658.08
               Mean episode length: 235.85
    Episode_Reward/reaching_object: 1.1956
    Episode_Reward/rotating_object: 132.8280
        Episode_Reward/action_rate: -0.0665
          Episode_Reward/joint_vel: -0.0353
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 2.12s
                      Time elapsed: 00:36:46
                               ETA: 00:18:59

################################################################################
                     [1m Learning iteration 990/1500 [0m                      

                       Computation: 46522 steps/s (collection: 2.002s, learning 0.111s)
             Mean action noise std: 3.32
          Mean value_function loss: 92.9813
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 66.7076
                       Mean reward: 631.82
               Mean episode length: 227.64
    Episode_Reward/reaching_object: 1.1864
    Episode_Reward/rotating_object: 129.1569
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 2.11s
                      Time elapsed: 00:36:48
                               ETA: 00:18:56

################################################################################
                     [1m Learning iteration 991/1500 [0m                      

                       Computation: 45990 steps/s (collection: 2.027s, learning 0.110s)
             Mean action noise std: 3.32
          Mean value_function loss: 92.5322
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 66.7298
                       Mean reward: 604.49
               Mean episode length: 220.64
    Episode_Reward/reaching_object: 1.1814
    Episode_Reward/rotating_object: 130.2465
        Episode_Reward/action_rate: -0.0660
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 2.14s
                      Time elapsed: 00:36:50
                               ETA: 00:18:54

################################################################################
                     [1m Learning iteration 992/1500 [0m                      

                       Computation: 45667 steps/s (collection: 2.042s, learning 0.111s)
             Mean action noise std: 3.33
          Mean value_function loss: 92.4886
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 66.7570
                       Mean reward: 597.82
               Mean episode length: 224.03
    Episode_Reward/reaching_object: 1.1704
    Episode_Reward/rotating_object: 124.9380
        Episode_Reward/action_rate: -0.0656
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 2.15s
                      Time elapsed: 00:36:53
                               ETA: 00:18:52

################################################################################
                     [1m Learning iteration 993/1500 [0m                      

                       Computation: 45156 steps/s (collection: 2.062s, learning 0.115s)
             Mean action noise std: 3.33
          Mean value_function loss: 88.1246
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 66.7786
                       Mean reward: 670.45
               Mean episode length: 234.13
    Episode_Reward/reaching_object: 1.2023
    Episode_Reward/rotating_object: 132.7871
        Episode_Reward/action_rate: -0.0671
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 2.18s
                      Time elapsed: 00:36:55
                               ETA: 00:18:49

################################################################################
                     [1m Learning iteration 994/1500 [0m                      

                       Computation: 45055 steps/s (collection: 2.069s, learning 0.113s)
             Mean action noise std: 3.33
          Mean value_function loss: 86.1990
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 66.8035
                       Mean reward: 668.62
               Mean episode length: 235.47
    Episode_Reward/reaching_object: 1.2093
    Episode_Reward/rotating_object: 132.1577
        Episode_Reward/action_rate: -0.0678
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 2.18s
                      Time elapsed: 00:36:57
                               ETA: 00:18:47

################################################################################
                     [1m Learning iteration 995/1500 [0m                      

                       Computation: 44517 steps/s (collection: 2.098s, learning 0.110s)
             Mean action noise std: 3.34
          Mean value_function loss: 95.2437
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 66.8317
                       Mean reward: 649.41
               Mean episode length: 226.96
    Episode_Reward/reaching_object: 1.2067
    Episode_Reward/rotating_object: 134.3799
        Episode_Reward/action_rate: -0.0675
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 2.21s
                      Time elapsed: 00:36:59
                               ETA: 00:18:45

################################################################################
                     [1m Learning iteration 996/1500 [0m                      

                       Computation: 43830 steps/s (collection: 2.131s, learning 0.111s)
             Mean action noise std: 3.34
          Mean value_function loss: 87.5305
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 66.8617
                       Mean reward: 664.68
               Mean episode length: 238.84
    Episode_Reward/reaching_object: 1.2039
    Episode_Reward/rotating_object: 132.8279
        Episode_Reward/action_rate: -0.0681
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 2.24s
                      Time elapsed: 00:37:01
                               ETA: 00:18:43

################################################################################
                     [1m Learning iteration 997/1500 [0m                      

                       Computation: 44230 steps/s (collection: 2.111s, learning 0.112s)
             Mean action noise std: 3.34
          Mean value_function loss: 76.4537
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 66.8927
                       Mean reward: 621.98
               Mean episode length: 226.91
    Episode_Reward/reaching_object: 1.2059
    Episode_Reward/rotating_object: 131.7586
        Episode_Reward/action_rate: -0.0679
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 2.22s
                      Time elapsed: 00:37:04
                               ETA: 00:18:40

################################################################################
                     [1m Learning iteration 998/1500 [0m                      

                       Computation: 44898 steps/s (collection: 2.075s, learning 0.115s)
             Mean action noise std: 3.35
          Mean value_function loss: 83.3209
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 66.9191
                       Mean reward: 635.51
               Mean episode length: 235.96
    Episode_Reward/reaching_object: 1.2097
    Episode_Reward/rotating_object: 133.7219
        Episode_Reward/action_rate: -0.0683
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 2.19s
                      Time elapsed: 00:37:06
                               ETA: 00:18:38

################################################################################
                     [1m Learning iteration 999/1500 [0m                      

                       Computation: 45823 steps/s (collection: 2.034s, learning 0.111s)
             Mean action noise std: 3.35
          Mean value_function loss: 98.1872
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 66.9552
                       Mean reward: 651.37
               Mean episode length: 227.33
    Episode_Reward/reaching_object: 1.1907
    Episode_Reward/rotating_object: 132.6887
        Episode_Reward/action_rate: -0.0678
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 2.15s
                      Time elapsed: 00:37:08
                               ETA: 00:18:36

################################################################################
                     [1m Learning iteration 1000/1500 [0m                     

                       Computation: 46074 steps/s (collection: 2.021s, learning 0.112s)
             Mean action noise std: 3.36
          Mean value_function loss: 81.0217
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 66.9894
                       Mean reward: 666.23
               Mean episode length: 236.57
    Episode_Reward/reaching_object: 1.1879
    Episode_Reward/rotating_object: 133.6842
        Episode_Reward/action_rate: -0.0679
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 2.13s
                      Time elapsed: 00:37:10
                               ETA: 00:18:34

################################################################################
                     [1m Learning iteration 1001/1500 [0m                     

                       Computation: 45279 steps/s (collection: 2.054s, learning 0.117s)
             Mean action noise std: 3.36
          Mean value_function loss: 82.6967
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 67.0193
                       Mean reward: 622.50
               Mean episode length: 226.58
    Episode_Reward/reaching_object: 1.1797
    Episode_Reward/rotating_object: 130.0256
        Episode_Reward/action_rate: -0.0676
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 2.17s
                      Time elapsed: 00:37:12
                               ETA: 00:18:31

################################################################################
                     [1m Learning iteration 1002/1500 [0m                     

                       Computation: 45743 steps/s (collection: 2.038s, learning 0.111s)
             Mean action noise std: 3.36
          Mean value_function loss: 85.3554
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 67.0410
                       Mean reward: 623.58
               Mean episode length: 236.03
    Episode_Reward/reaching_object: 1.1854
    Episode_Reward/rotating_object: 131.1005
        Episode_Reward/action_rate: -0.0685
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 2.15s
                      Time elapsed: 00:37:14
                               ETA: 00:18:29

################################################################################
                     [1m Learning iteration 1003/1500 [0m                     

                       Computation: 45788 steps/s (collection: 2.035s, learning 0.112s)
             Mean action noise std: 3.37
          Mean value_function loss: 86.8069
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 67.0641
                       Mean reward: 672.33
               Mean episode length: 230.57
    Episode_Reward/reaching_object: 1.1951
    Episode_Reward/rotating_object: 133.3913
        Episode_Reward/action_rate: -0.0683
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 2.15s
                      Time elapsed: 00:37:17
                               ETA: 00:18:27

################################################################################
                     [1m Learning iteration 1004/1500 [0m                     

                       Computation: 45839 steps/s (collection: 2.030s, learning 0.115s)
             Mean action noise std: 3.37
          Mean value_function loss: 90.7382
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 67.0853
                       Mean reward: 624.40
               Mean episode length: 230.04
    Episode_Reward/reaching_object: 1.1940
    Episode_Reward/rotating_object: 129.5860
        Episode_Reward/action_rate: -0.0688
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 2.14s
                      Time elapsed: 00:37:19
                               ETA: 00:18:25

################################################################################
                     [1m Learning iteration 1005/1500 [0m                     

                       Computation: 43891 steps/s (collection: 2.127s, learning 0.113s)
             Mean action noise std: 3.37
          Mean value_function loss: 95.9916
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 67.1080
                       Mean reward: 669.51
               Mean episode length: 231.97
    Episode_Reward/reaching_object: 1.1790
    Episode_Reward/rotating_object: 130.7621
        Episode_Reward/action_rate: -0.0683
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 2.24s
                      Time elapsed: 00:37:21
                               ETA: 00:18:22

################################################################################
                     [1m Learning iteration 1006/1500 [0m                     

                       Computation: 45419 steps/s (collection: 2.052s, learning 0.113s)
             Mean action noise std: 3.38
          Mean value_function loss: 89.9754
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 67.1287
                       Mean reward: 711.52
               Mean episode length: 234.37
    Episode_Reward/reaching_object: 1.1897
    Episode_Reward/rotating_object: 133.9516
        Episode_Reward/action_rate: -0.0687
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 2.16s
                      Time elapsed: 00:37:23
                               ETA: 00:18:20

################################################################################
                     [1m Learning iteration 1007/1500 [0m                     

                       Computation: 45888 steps/s (collection: 2.029s, learning 0.113s)
             Mean action noise std: 3.38
          Mean value_function loss: 91.3857
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 67.1529
                       Mean reward: 677.88
               Mean episode length: 232.77
    Episode_Reward/reaching_object: 1.1792
    Episode_Reward/rotating_object: 130.3304
        Episode_Reward/action_rate: -0.0685
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 2.14s
                      Time elapsed: 00:37:25
                               ETA: 00:18:18

################################################################################
                     [1m Learning iteration 1008/1500 [0m                     

                       Computation: 44922 steps/s (collection: 2.077s, learning 0.111s)
             Mean action noise std: 3.38
          Mean value_function loss: 81.8621
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 67.1791
                       Mean reward: 645.30
               Mean episode length: 223.20
    Episode_Reward/reaching_object: 1.1647
    Episode_Reward/rotating_object: 126.3061
        Episode_Reward/action_rate: -0.0682
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 2.19s
                      Time elapsed: 00:37:27
                               ETA: 00:18:16

################################################################################
                     [1m Learning iteration 1009/1500 [0m                     

                       Computation: 46745 steps/s (collection: 1.992s, learning 0.111s)
             Mean action noise std: 3.39
          Mean value_function loss: 87.4928
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 67.2222
                       Mean reward: 666.16
               Mean episode length: 236.40
    Episode_Reward/reaching_object: 1.2010
    Episode_Reward/rotating_object: 133.3339
        Episode_Reward/action_rate: -0.0702
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 2.10s
                      Time elapsed: 00:37:30
                               ETA: 00:18:13

################################################################################
                     [1m Learning iteration 1010/1500 [0m                     

                       Computation: 46728 steps/s (collection: 1.993s, learning 0.110s)
             Mean action noise std: 3.39
          Mean value_function loss: 96.2158
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 67.2558
                       Mean reward: 675.15
               Mean episode length: 233.36
    Episode_Reward/reaching_object: 1.1768
    Episode_Reward/rotating_object: 132.5494
        Episode_Reward/action_rate: -0.0685
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 2.10s
                      Time elapsed: 00:37:32
                               ETA: 00:18:11

################################################################################
                     [1m Learning iteration 1011/1500 [0m                     

                       Computation: 46591 steps/s (collection: 2.000s, learning 0.110s)
             Mean action noise std: 3.40
          Mean value_function loss: 100.3976
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 67.2778
                       Mean reward: 652.98
               Mean episode length: 233.45
    Episode_Reward/reaching_object: 1.1881
    Episode_Reward/rotating_object: 130.4637
        Episode_Reward/action_rate: -0.0691
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 2.11s
                      Time elapsed: 00:37:34
                               ETA: 00:18:09

################################################################################
                     [1m Learning iteration 1012/1500 [0m                     

                       Computation: 46702 steps/s (collection: 1.994s, learning 0.110s)
             Mean action noise std: 3.40
          Mean value_function loss: 87.9328
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 67.3056
                       Mean reward: 644.64
               Mean episode length: 225.75
    Episode_Reward/reaching_object: 1.1959
    Episode_Reward/rotating_object: 132.1925
        Episode_Reward/action_rate: -0.0697
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 2.10s
                      Time elapsed: 00:37:36
                               ETA: 00:18:06

################################################################################
                     [1m Learning iteration 1013/1500 [0m                     

                       Computation: 46244 steps/s (collection: 2.016s, learning 0.110s)
             Mean action noise std: 3.40
          Mean value_function loss: 100.5130
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 67.3311
                       Mean reward: 606.15
               Mean episode length: 223.14
    Episode_Reward/reaching_object: 1.1747
    Episode_Reward/rotating_object: 127.8993
        Episode_Reward/action_rate: -0.0689
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 2.13s
                      Time elapsed: 00:37:38
                               ETA: 00:18:04

################################################################################
                     [1m Learning iteration 1014/1500 [0m                     

                       Computation: 46829 steps/s (collection: 1.989s, learning 0.110s)
             Mean action noise std: 3.41
          Mean value_function loss: 96.9646
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 67.3523
                       Mean reward: 662.12
               Mean episode length: 232.97
    Episode_Reward/reaching_object: 1.1988
    Episode_Reward/rotating_object: 131.1718
        Episode_Reward/action_rate: -0.0699
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 2.10s
                      Time elapsed: 00:37:40
                               ETA: 00:18:02

################################################################################
                     [1m Learning iteration 1015/1500 [0m                     

                       Computation: 46116 steps/s (collection: 2.020s, learning 0.111s)
             Mean action noise std: 3.41
          Mean value_function loss: 89.8508
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 67.3884
                       Mean reward: 678.92
               Mean episode length: 225.65
    Episode_Reward/reaching_object: 1.1835
    Episode_Reward/rotating_object: 131.7951
        Episode_Reward/action_rate: -0.0694
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 2.13s
                      Time elapsed: 00:37:42
                               ETA: 00:18:00

################################################################################
                     [1m Learning iteration 1016/1500 [0m                     

                       Computation: 45732 steps/s (collection: 2.038s, learning 0.112s)
             Mean action noise std: 3.42
          Mean value_function loss: 101.5339
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 67.4200
                       Mean reward: 592.56
               Mean episode length: 221.05
    Episode_Reward/reaching_object: 1.1636
    Episode_Reward/rotating_object: 126.4303
        Episode_Reward/action_rate: -0.0690
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 2.15s
                      Time elapsed: 00:37:44
                               ETA: 00:17:57

################################################################################
                     [1m Learning iteration 1017/1500 [0m                     

                       Computation: 45702 steps/s (collection: 2.038s, learning 0.113s)
             Mean action noise std: 3.42
          Mean value_function loss: 92.6398
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 67.4414
                       Mean reward: 635.31
               Mean episode length: 225.09
    Episode_Reward/reaching_object: 1.1773
    Episode_Reward/rotating_object: 125.5184
        Episode_Reward/action_rate: -0.0697
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 2.15s
                      Time elapsed: 00:37:47
                               ETA: 00:17:55

################################################################################
                     [1m Learning iteration 1018/1500 [0m                     

                       Computation: 45873 steps/s (collection: 2.030s, learning 0.113s)
             Mean action noise std: 3.42
          Mean value_function loss: 84.9957
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 67.4549
                       Mean reward: 681.35
               Mean episode length: 228.21
    Episode_Reward/reaching_object: 1.2129
    Episode_Reward/rotating_object: 137.0751
        Episode_Reward/action_rate: -0.0715
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 2.14s
                      Time elapsed: 00:37:49
                               ETA: 00:17:53

################################################################################
                     [1m Learning iteration 1019/1500 [0m                     

                       Computation: 45691 steps/s (collection: 2.040s, learning 0.112s)
             Mean action noise std: 3.42
          Mean value_function loss: 85.3662
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 67.4746
                       Mean reward: 633.83
               Mean episode length: 231.61
    Episode_Reward/reaching_object: 1.1878
    Episode_Reward/rotating_object: 127.1310
        Episode_Reward/action_rate: -0.0709
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 2.15s
                      Time elapsed: 00:37:51
                               ETA: 00:17:51

################################################################################
                     [1m Learning iteration 1020/1500 [0m                     

                       Computation: 45540 steps/s (collection: 2.048s, learning 0.111s)
             Mean action noise std: 3.43
          Mean value_function loss: 80.8179
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 67.5066
                       Mean reward: 661.62
               Mean episode length: 234.59
    Episode_Reward/reaching_object: 1.2172
    Episode_Reward/rotating_object: 135.8275
        Episode_Reward/action_rate: -0.0722
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 2.16s
                      Time elapsed: 00:37:53
                               ETA: 00:17:48

################################################################################
                     [1m Learning iteration 1021/1500 [0m                     

                       Computation: 45719 steps/s (collection: 2.037s, learning 0.114s)
             Mean action noise std: 3.43
          Mean value_function loss: 84.1686
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 67.5284
                       Mean reward: 675.88
               Mean episode length: 230.56
    Episode_Reward/reaching_object: 1.1889
    Episode_Reward/rotating_object: 132.7253
        Episode_Reward/action_rate: -0.0710
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 2.15s
                      Time elapsed: 00:37:55
                               ETA: 00:17:46

################################################################################
                     [1m Learning iteration 1022/1500 [0m                     

                       Computation: 45641 steps/s (collection: 2.037s, learning 0.117s)
             Mean action noise std: 3.43
          Mean value_function loss: 97.7648
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 67.5441
                       Mean reward: 690.01
               Mean episode length: 236.97
    Episode_Reward/reaching_object: 1.1959
    Episode_Reward/rotating_object: 132.9414
        Episode_Reward/action_rate: -0.0717
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 2.15s
                      Time elapsed: 00:37:57
                               ETA: 00:17:44

################################################################################
                     [1m Learning iteration 1023/1500 [0m                     

                       Computation: 45319 steps/s (collection: 2.056s, learning 0.113s)
             Mean action noise std: 3.43
          Mean value_function loss: 92.3486
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 67.5613
                       Mean reward: 647.89
               Mean episode length: 225.65
    Episode_Reward/reaching_object: 1.1675
    Episode_Reward/rotating_object: 127.9793
        Episode_Reward/action_rate: -0.0710
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 2.17s
                      Time elapsed: 00:37:59
                               ETA: 00:17:42

################################################################################
                     [1m Learning iteration 1024/1500 [0m                     

                       Computation: 45377 steps/s (collection: 2.041s, learning 0.125s)
             Mean action noise std: 3.44
          Mean value_function loss: 82.5216
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 67.5830
                       Mean reward: 650.13
               Mean episode length: 232.62
    Episode_Reward/reaching_object: 1.1736
    Episode_Reward/rotating_object: 130.3122
        Episode_Reward/action_rate: -0.0710
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 2.17s
                      Time elapsed: 00:38:02
                               ETA: 00:17:39

################################################################################
                     [1m Learning iteration 1025/1500 [0m                     

                       Computation: 45872 steps/s (collection: 2.033s, learning 0.110s)
             Mean action noise std: 3.44
          Mean value_function loss: 78.6623
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 67.6079
                       Mean reward: 661.15
               Mean episode length: 233.75
    Episode_Reward/reaching_object: 1.1856
    Episode_Reward/rotating_object: 129.3199
        Episode_Reward/action_rate: -0.0717
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 2.14s
                      Time elapsed: 00:38:04
                               ETA: 00:17:37

################################################################################
                     [1m Learning iteration 1026/1500 [0m                     

                       Computation: 45405 steps/s (collection: 2.053s, learning 0.112s)
             Mean action noise std: 3.44
          Mean value_function loss: 80.8533
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 67.6264
                       Mean reward: 674.46
               Mean episode length: 232.95
    Episode_Reward/reaching_object: 1.2054
    Episode_Reward/rotating_object: 136.4211
        Episode_Reward/action_rate: -0.0730
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 2.17s
                      Time elapsed: 00:38:06
                               ETA: 00:17:35

################################################################################
                     [1m Learning iteration 1027/1500 [0m                     

                       Computation: 45678 steps/s (collection: 2.038s, learning 0.114s)
             Mean action noise std: 3.45
          Mean value_function loss: 83.1684
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 67.6534
                       Mean reward: 682.47
               Mean episode length: 233.36
    Episode_Reward/reaching_object: 1.1908
    Episode_Reward/rotating_object: 135.3663
        Episode_Reward/action_rate: -0.0724
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 2.15s
                      Time elapsed: 00:38:08
                               ETA: 00:17:33

################################################################################
                     [1m Learning iteration 1028/1500 [0m                     

                       Computation: 45964 steps/s (collection: 2.028s, learning 0.110s)
             Mean action noise std: 3.45
          Mean value_function loss: 85.7731
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 67.6788
                       Mean reward: 654.39
               Mean episode length: 231.29
    Episode_Reward/reaching_object: 1.1964
    Episode_Reward/rotating_object: 132.5012
        Episode_Reward/action_rate: -0.0728
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 2.14s
                      Time elapsed: 00:38:10
                               ETA: 00:17:30

################################################################################
                     [1m Learning iteration 1029/1500 [0m                     

                       Computation: 45757 steps/s (collection: 2.038s, learning 0.110s)
             Mean action noise std: 3.45
          Mean value_function loss: 77.5397
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 67.6970
                       Mean reward: 670.35
               Mean episode length: 240.34
    Episode_Reward/reaching_object: 1.1890
    Episode_Reward/rotating_object: 132.2429
        Episode_Reward/action_rate: -0.0728
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 2.15s
                      Time elapsed: 00:38:12
                               ETA: 00:17:28

################################################################################
                     [1m Learning iteration 1030/1500 [0m                     

                       Computation: 45353 steps/s (collection: 2.056s, learning 0.112s)
             Mean action noise std: 3.46
          Mean value_function loss: 74.6695
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 67.7210
                       Mean reward: 695.51
               Mean episode length: 235.36
    Episode_Reward/reaching_object: 1.1994
    Episode_Reward/rotating_object: 137.4821
        Episode_Reward/action_rate: -0.0735
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 2.17s
                      Time elapsed: 00:38:15
                               ETA: 00:17:26

################################################################################
                     [1m Learning iteration 1031/1500 [0m                     

                       Computation: 46111 steps/s (collection: 2.022s, learning 0.110s)
             Mean action noise std: 3.46
          Mean value_function loss: 84.6093
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 67.7443
                       Mean reward: 724.33
               Mean episode length: 241.34
    Episode_Reward/reaching_object: 1.1941
    Episode_Reward/rotating_object: 135.1085
        Episode_Reward/action_rate: -0.0732
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 2.13s
                      Time elapsed: 00:38:17
                               ETA: 00:17:23

################################################################################
                     [1m Learning iteration 1032/1500 [0m                     

                       Computation: 45916 steps/s (collection: 2.031s, learning 0.110s)
             Mean action noise std: 3.46
          Mean value_function loss: 86.4433
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 67.7611
                       Mean reward: 640.34
               Mean episode length: 237.50
    Episode_Reward/reaching_object: 1.1994
    Episode_Reward/rotating_object: 130.9305
        Episode_Reward/action_rate: -0.0737
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 2.14s
                      Time elapsed: 00:38:19
                               ETA: 00:17:21

################################################################################
                     [1m Learning iteration 1033/1500 [0m                     

                       Computation: 45290 steps/s (collection: 2.060s, learning 0.110s)
             Mean action noise std: 3.47
          Mean value_function loss: 94.2520
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 67.7810
                       Mean reward: 618.50
               Mean episode length: 223.72
    Episode_Reward/reaching_object: 1.1834
    Episode_Reward/rotating_object: 130.7629
        Episode_Reward/action_rate: -0.0726
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 2.17s
                      Time elapsed: 00:38:21
                               ETA: 00:17:19

################################################################################
                     [1m Learning iteration 1034/1500 [0m                     

                       Computation: 45187 steps/s (collection: 2.065s, learning 0.110s)
             Mean action noise std: 3.47
          Mean value_function loss: 94.2122
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 67.8013
                       Mean reward: 647.89
               Mean episode length: 228.44
    Episode_Reward/reaching_object: 1.1746
    Episode_Reward/rotating_object: 127.8542
        Episode_Reward/action_rate: -0.0726
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 2.18s
                      Time elapsed: 00:38:23
                               ETA: 00:17:17

################################################################################
                     [1m Learning iteration 1035/1500 [0m                     

                       Computation: 45088 steps/s (collection: 2.070s, learning 0.110s)
             Mean action noise std: 3.47
          Mean value_function loss: 74.5362
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 67.8232
                       Mean reward: 695.95
               Mean episode length: 239.09
    Episode_Reward/reaching_object: 1.1856
    Episode_Reward/rotating_object: 130.2521
        Episode_Reward/action_rate: -0.0730
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 2.18s
                      Time elapsed: 00:38:25
                               ETA: 00:17:14

################################################################################
                     [1m Learning iteration 1036/1500 [0m                     

                       Computation: 45857 steps/s (collection: 2.031s, learning 0.113s)
             Mean action noise std: 3.48
          Mean value_function loss: 81.6573
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 67.8474
                       Mean reward: 665.29
               Mean episode length: 232.37
    Episode_Reward/reaching_object: 1.2098
    Episode_Reward/rotating_object: 137.4880
        Episode_Reward/action_rate: -0.0744
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 2.14s
                      Time elapsed: 00:38:27
                               ETA: 00:17:12

################################################################################
                     [1m Learning iteration 1037/1500 [0m                     

                       Computation: 45317 steps/s (collection: 2.056s, learning 0.114s)
             Mean action noise std: 3.48
          Mean value_function loss: 96.5469
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 67.8707
                       Mean reward: 651.88
               Mean episode length: 228.80
    Episode_Reward/reaching_object: 1.1816
    Episode_Reward/rotating_object: 130.2511
        Episode_Reward/action_rate: -0.0732
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 2.17s
                      Time elapsed: 00:38:30
                               ETA: 00:17:10

################################################################################
                     [1m Learning iteration 1038/1500 [0m                     

                       Computation: 45538 steps/s (collection: 2.048s, learning 0.111s)
             Mean action noise std: 3.48
          Mean value_function loss: 88.6342
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 67.8990
                       Mean reward: 703.59
               Mean episode length: 234.95
    Episode_Reward/reaching_object: 1.1899
    Episode_Reward/rotating_object: 133.9356
        Episode_Reward/action_rate: -0.0736
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 2.16s
                      Time elapsed: 00:38:32
                               ETA: 00:17:08

################################################################################
                     [1m Learning iteration 1039/1500 [0m                     

                       Computation: 45563 steps/s (collection: 2.039s, learning 0.119s)
             Mean action noise std: 3.49
          Mean value_function loss: 83.3639
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 67.9176
                       Mean reward: 680.00
               Mean episode length: 227.77
    Episode_Reward/reaching_object: 1.1836
    Episode_Reward/rotating_object: 134.0035
        Episode_Reward/action_rate: -0.0738
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 2.16s
                      Time elapsed: 00:38:34
                               ETA: 00:17:05

################################################################################
                     [1m Learning iteration 1040/1500 [0m                     

                       Computation: 42115 steps/s (collection: 2.201s, learning 0.133s)
             Mean action noise std: 3.49
          Mean value_function loss: 82.8126
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 67.9345
                       Mean reward: 646.43
               Mean episode length: 224.32
    Episode_Reward/reaching_object: 1.1917
    Episode_Reward/rotating_object: 137.6866
        Episode_Reward/action_rate: -0.0745
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 2.33s
                      Time elapsed: 00:38:36
                               ETA: 00:17:03

################################################################################
                     [1m Learning iteration 1041/1500 [0m                     

                       Computation: 42121 steps/s (collection: 2.208s, learning 0.126s)
             Mean action noise std: 3.49
          Mean value_function loss: 70.1813
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 67.9571
                       Mean reward: 667.84
               Mean episode length: 241.73
    Episode_Reward/reaching_object: 1.2176
    Episode_Reward/rotating_object: 135.2231
        Episode_Reward/action_rate: -0.0763
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 2.33s
                      Time elapsed: 00:38:39
                               ETA: 00:17:01

################################################################################
                     [1m Learning iteration 1042/1500 [0m                     

                       Computation: 42054 steps/s (collection: 2.211s, learning 0.126s)
             Mean action noise std: 3.49
          Mean value_function loss: 90.5723
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 67.9801
                       Mean reward: 692.30
               Mean episode length: 246.57
    Episode_Reward/reaching_object: 1.1962
    Episode_Reward/rotating_object: 135.0043
        Episode_Reward/action_rate: -0.0753
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 2.34s
                      Time elapsed: 00:38:41
                               ETA: 00:16:59

################################################################################
                     [1m Learning iteration 1043/1500 [0m                     

                       Computation: 41927 steps/s (collection: 2.217s, learning 0.128s)
             Mean action noise std: 3.50
          Mean value_function loss: 89.5351
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 68.0048
                       Mean reward: 695.72
               Mean episode length: 237.26
    Episode_Reward/reaching_object: 1.1704
    Episode_Reward/rotating_object: 132.3339
        Episode_Reward/action_rate: -0.0739
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 2.34s
                      Time elapsed: 00:38:43
                               ETA: 00:16:57

################################################################################
                     [1m Learning iteration 1044/1500 [0m                     

                       Computation: 42051 steps/s (collection: 2.210s, learning 0.128s)
             Mean action noise std: 3.50
          Mean value_function loss: 95.2358
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 68.0244
                       Mean reward: 630.04
               Mean episode length: 227.07
    Episode_Reward/reaching_object: 1.1486
    Episode_Reward/rotating_object: 128.3561
        Episode_Reward/action_rate: -0.0727
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 2.34s
                      Time elapsed: 00:38:46
                               ETA: 00:16:55

################################################################################
                     [1m Learning iteration 1045/1500 [0m                     

                       Computation: 41718 steps/s (collection: 2.222s, learning 0.135s)
             Mean action noise std: 3.50
          Mean value_function loss: 83.5193
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 68.0420
                       Mean reward: 658.65
               Mean episode length: 232.25
    Episode_Reward/reaching_object: 1.1942
    Episode_Reward/rotating_object: 136.9717
        Episode_Reward/action_rate: -0.0753
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 2.36s
                      Time elapsed: 00:38:48
                               ETA: 00:16:52

################################################################################
                     [1m Learning iteration 1046/1500 [0m                     

                       Computation: 42082 steps/s (collection: 2.211s, learning 0.125s)
             Mean action noise std: 3.51
          Mean value_function loss: 76.4910
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 68.0606
                       Mean reward: 631.62
               Mean episode length: 233.74
    Episode_Reward/reaching_object: 1.1763
    Episode_Reward/rotating_object: 128.5896
        Episode_Reward/action_rate: -0.0746
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 2.34s
                      Time elapsed: 00:38:50
                               ETA: 00:16:50

################################################################################
                     [1m Learning iteration 1047/1500 [0m                     

                       Computation: 42406 steps/s (collection: 2.193s, learning 0.125s)
             Mean action noise std: 3.51
          Mean value_function loss: 75.6161
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 68.0748
                       Mean reward: 662.25
               Mean episode length: 235.16
    Episode_Reward/reaching_object: 1.1867
    Episode_Reward/rotating_object: 132.7530
        Episode_Reward/action_rate: -0.0754
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 2.32s
                      Time elapsed: 00:38:53
                               ETA: 00:16:48

################################################################################
                     [1m Learning iteration 1048/1500 [0m                     

                       Computation: 45205 steps/s (collection: 2.061s, learning 0.113s)
             Mean action noise std: 3.51
          Mean value_function loss: 72.7220
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 68.0909
                       Mean reward: 710.07
               Mean episode length: 236.23
    Episode_Reward/reaching_object: 1.2095
    Episode_Reward/rotating_object: 137.1216
        Episode_Reward/action_rate: -0.0767
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 2.17s
                      Time elapsed: 00:38:55
                               ETA: 00:16:46

################################################################################
                     [1m Learning iteration 1049/1500 [0m                     

                       Computation: 45744 steps/s (collection: 2.038s, learning 0.111s)
             Mean action noise std: 3.51
          Mean value_function loss: 85.5305
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 68.1160
                       Mean reward: 644.96
               Mean episode length: 226.41
    Episode_Reward/reaching_object: 1.1722
    Episode_Reward/rotating_object: 132.1040
        Episode_Reward/action_rate: -0.0744
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 2.15s
                      Time elapsed: 00:38:57
                               ETA: 00:16:44

################################################################################
                     [1m Learning iteration 1050/1500 [0m                     

                       Computation: 45396 steps/s (collection: 2.053s, learning 0.113s)
             Mean action noise std: 3.52
          Mean value_function loss: 79.3384
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 68.1317
                       Mean reward: 733.84
               Mean episode length: 245.89
    Episode_Reward/reaching_object: 1.2081
    Episode_Reward/rotating_object: 136.9587
        Episode_Reward/action_rate: -0.0765
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 2.17s
                      Time elapsed: 00:38:59
                               ETA: 00:16:41

################################################################################
                     [1m Learning iteration 1051/1500 [0m                     

                       Computation: 46234 steps/s (collection: 2.016s, learning 0.110s)
             Mean action noise std: 3.52
          Mean value_function loss: 93.5977
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 68.1438
                       Mean reward: 637.90
               Mean episode length: 233.29
    Episode_Reward/reaching_object: 1.1668
    Episode_Reward/rotating_object: 127.7692
        Episode_Reward/action_rate: -0.0743
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 2.13s
                      Time elapsed: 00:39:01
                               ETA: 00:16:39

################################################################################
                     [1m Learning iteration 1052/1500 [0m                     

                       Computation: 45841 steps/s (collection: 2.035s, learning 0.110s)
             Mean action noise std: 3.52
          Mean value_function loss: 72.0388
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 68.1659
                       Mean reward: 677.05
               Mean episode length: 232.95
    Episode_Reward/reaching_object: 1.1649
    Episode_Reward/rotating_object: 130.3230
        Episode_Reward/action_rate: -0.0742
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 2.14s
                      Time elapsed: 00:39:03
                               ETA: 00:16:37

################################################################################
                     [1m Learning iteration 1053/1500 [0m                     

                       Computation: 46895 steps/s (collection: 1.986s, learning 0.110s)
             Mean action noise std: 3.52
          Mean value_function loss: 77.7105
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 68.1840
                       Mean reward: 699.85
               Mean episode length: 235.54
    Episode_Reward/reaching_object: 1.1929
    Episode_Reward/rotating_object: 135.2128
        Episode_Reward/action_rate: -0.0756
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 2.10s
                      Time elapsed: 00:39:06
                               ETA: 00:16:34

################################################################################
                     [1m Learning iteration 1054/1500 [0m                     

                       Computation: 46551 steps/s (collection: 2.002s, learning 0.110s)
             Mean action noise std: 3.53
          Mean value_function loss: 97.6809
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 68.1951
                       Mean reward: 658.52
               Mean episode length: 230.28
    Episode_Reward/reaching_object: 1.1786
    Episode_Reward/rotating_object: 132.3135
        Episode_Reward/action_rate: -0.0751
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 2.11s
                      Time elapsed: 00:39:08
                               ETA: 00:16:32

################################################################################
                     [1m Learning iteration 1055/1500 [0m                     

                       Computation: 46724 steps/s (collection: 1.993s, learning 0.110s)
             Mean action noise std: 3.53
          Mean value_function loss: 96.7101
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 68.2129
                       Mean reward: 675.98
               Mean episode length: 225.57
    Episode_Reward/reaching_object: 1.1878
    Episode_Reward/rotating_object: 134.3891
        Episode_Reward/action_rate: -0.0754
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 2.10s
                      Time elapsed: 00:39:10
                               ETA: 00:16:30

################################################################################
                     [1m Learning iteration 1056/1500 [0m                     

                       Computation: 45944 steps/s (collection: 2.029s, learning 0.110s)
             Mean action noise std: 3.53
          Mean value_function loss: 89.5059
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 68.2319
                       Mean reward: 659.73
               Mean episode length: 225.47
    Episode_Reward/reaching_object: 1.1822
    Episode_Reward/rotating_object: 133.0099
        Episode_Reward/action_rate: -0.0755
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 2.14s
                      Time elapsed: 00:39:12
                               ETA: 00:16:28

################################################################################
                     [1m Learning iteration 1057/1500 [0m                     

                       Computation: 47015 steps/s (collection: 1.981s, learning 0.110s)
             Mean action noise std: 3.54
          Mean value_function loss: 105.2334
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 68.2538
                       Mean reward: 683.34
               Mean episode length: 238.92
    Episode_Reward/reaching_object: 1.1791
    Episode_Reward/rotating_object: 131.7485
        Episode_Reward/action_rate: -0.0750
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 2.09s
                      Time elapsed: 00:39:14
                               ETA: 00:16:25

################################################################################
                     [1m Learning iteration 1058/1500 [0m                     

                       Computation: 46732 steps/s (collection: 1.993s, learning 0.110s)
             Mean action noise std: 3.54
          Mean value_function loss: 88.6089
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 68.2741
                       Mean reward: 667.17
               Mean episode length: 231.45
    Episode_Reward/reaching_object: 1.1963
    Episode_Reward/rotating_object: 136.4729
        Episode_Reward/action_rate: -0.0763
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 2.10s
                      Time elapsed: 00:39:16
                               ETA: 00:16:23

################################################################################
                     [1m Learning iteration 1059/1500 [0m                     

                       Computation: 46869 steps/s (collection: 1.987s, learning 0.110s)
             Mean action noise std: 3.54
          Mean value_function loss: 87.6829
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 68.2892
                       Mean reward: 704.76
               Mean episode length: 239.31
    Episode_Reward/reaching_object: 1.2025
    Episode_Reward/rotating_object: 135.4752
        Episode_Reward/action_rate: -0.0762
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 2.10s
                      Time elapsed: 00:39:18
                               ETA: 00:16:21

################################################################################
                     [1m Learning iteration 1060/1500 [0m                     

                       Computation: 46116 steps/s (collection: 2.019s, learning 0.112s)
             Mean action noise std: 3.54
          Mean value_function loss: 85.7253
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 68.3052
                       Mean reward: 645.82
               Mean episode length: 235.57
    Episode_Reward/reaching_object: 1.2087
    Episode_Reward/rotating_object: 134.8628
        Episode_Reward/action_rate: -0.0768
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 2.13s
                      Time elapsed: 00:39:20
                               ETA: 00:16:19

################################################################################
                     [1m Learning iteration 1061/1500 [0m                     

                       Computation: 45497 steps/s (collection: 2.050s, learning 0.110s)
             Mean action noise std: 3.55
          Mean value_function loss: 110.1511
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 68.3253
                       Mean reward: 640.55
               Mean episode length: 225.26
    Episode_Reward/reaching_object: 1.1635
    Episode_Reward/rotating_object: 132.2045
        Episode_Reward/action_rate: -0.0743
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 2.16s
                      Time elapsed: 00:39:22
                               ETA: 00:16:16

################################################################################
                     [1m Learning iteration 1062/1500 [0m                     

                       Computation: 46149 steps/s (collection: 2.020s, learning 0.110s)
             Mean action noise std: 3.55
          Mean value_function loss: 87.5574
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 68.3564
                       Mean reward: 648.91
               Mean episode length: 233.84
    Episode_Reward/reaching_object: 1.2031
    Episode_Reward/rotating_object: 130.8887
        Episode_Reward/action_rate: -0.0765
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 2.13s
                      Time elapsed: 00:39:25
                               ETA: 00:16:14

################################################################################
                     [1m Learning iteration 1063/1500 [0m                     

                       Computation: 45947 steps/s (collection: 2.029s, learning 0.111s)
             Mean action noise std: 3.55
          Mean value_function loss: 84.3746
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 68.3863
                       Mean reward: 604.74
               Mean episode length: 227.61
    Episode_Reward/reaching_object: 1.2022
    Episode_Reward/rotating_object: 132.2522
        Episode_Reward/action_rate: -0.0769
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 2.14s
                      Time elapsed: 00:39:27
                               ETA: 00:16:12

################################################################################
                     [1m Learning iteration 1064/1500 [0m                     

                       Computation: 45932 steps/s (collection: 2.029s, learning 0.111s)
             Mean action noise std: 3.56
          Mean value_function loss: 87.9006
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 68.4047
                       Mean reward: 702.97
               Mean episode length: 238.25
    Episode_Reward/reaching_object: 1.2083
    Episode_Reward/rotating_object: 130.4957
        Episode_Reward/action_rate: -0.0773
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 2.14s
                      Time elapsed: 00:39:29
                               ETA: 00:16:10

################################################################################
                     [1m Learning iteration 1065/1500 [0m                     

                       Computation: 46029 steps/s (collection: 2.024s, learning 0.111s)
             Mean action noise std: 3.56
          Mean value_function loss: 92.8019
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 68.4328
                       Mean reward: 651.17
               Mean episode length: 227.62
    Episode_Reward/reaching_object: 1.2042
    Episode_Reward/rotating_object: 132.7390
        Episode_Reward/action_rate: -0.0765
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 2.14s
                      Time elapsed: 00:39:31
                               ETA: 00:16:07

################################################################################
                     [1m Learning iteration 1066/1500 [0m                     

                       Computation: 42172 steps/s (collection: 2.204s, learning 0.127s)
             Mean action noise std: 3.57
          Mean value_function loss: 96.7383
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 68.4569
                       Mean reward: 675.72
               Mean episode length: 240.82
    Episode_Reward/reaching_object: 1.2231
    Episode_Reward/rotating_object: 134.2462
        Episode_Reward/action_rate: -0.0780
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 2.33s
                      Time elapsed: 00:39:33
                               ETA: 00:16:05

################################################################################
                     [1m Learning iteration 1067/1500 [0m                     

                       Computation: 38999 steps/s (collection: 2.391s, learning 0.129s)
             Mean action noise std: 3.57
          Mean value_function loss: 96.4668
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 68.4848
                       Mean reward: 666.17
               Mean episode length: 244.62
    Episode_Reward/reaching_object: 1.2180
    Episode_Reward/rotating_object: 129.9329
        Episode_Reward/action_rate: -0.0778
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 2.52s
                      Time elapsed: 00:39:36
                               ETA: 00:16:03

################################################################################
                     [1m Learning iteration 1068/1500 [0m                     

                       Computation: 39703 steps/s (collection: 2.348s, learning 0.127s)
             Mean action noise std: 3.57
          Mean value_function loss: 93.0879
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 68.5155
                       Mean reward: 672.26
               Mean episode length: 241.82
    Episode_Reward/reaching_object: 1.2132
    Episode_Reward/rotating_object: 133.5072
        Episode_Reward/action_rate: -0.0778
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 2.48s
                      Time elapsed: 00:39:38
                               ETA: 00:16:01

################################################################################
                     [1m Learning iteration 1069/1500 [0m                     

                       Computation: 39711 steps/s (collection: 2.352s, learning 0.124s)
             Mean action noise std: 3.58
          Mean value_function loss: 107.9386
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 68.5387
                       Mean reward: 633.73
               Mean episode length: 230.11
    Episode_Reward/reaching_object: 1.1948
    Episode_Reward/rotating_object: 129.5638
        Episode_Reward/action_rate: -0.0764
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 2.48s
                      Time elapsed: 00:39:41
                               ETA: 00:15:59

################################################################################
                     [1m Learning iteration 1070/1500 [0m                     

                       Computation: 42255 steps/s (collection: 2.206s, learning 0.120s)
             Mean action noise std: 3.58
          Mean value_function loss: 86.6464
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 68.5589
                       Mean reward: 675.25
               Mean episode length: 240.40
    Episode_Reward/reaching_object: 1.2124
    Episode_Reward/rotating_object: 131.8076
        Episode_Reward/action_rate: -0.0779
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 2.33s
                      Time elapsed: 00:39:43
                               ETA: 00:15:57

################################################################################
                     [1m Learning iteration 1071/1500 [0m                     

                       Computation: 43277 steps/s (collection: 2.159s, learning 0.112s)
             Mean action noise std: 3.58
          Mean value_function loss: 86.8077
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 68.5766
                       Mean reward: 677.99
               Mean episode length: 238.80
    Episode_Reward/reaching_object: 1.2060
    Episode_Reward/rotating_object: 130.9658
        Episode_Reward/action_rate: -0.0776
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 2.27s
                      Time elapsed: 00:39:45
                               ETA: 00:15:54

################################################################################
                     [1m Learning iteration 1072/1500 [0m                     

                       Computation: 43187 steps/s (collection: 2.164s, learning 0.113s)
             Mean action noise std: 3.59
          Mean value_function loss: 86.5917
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 68.5972
                       Mean reward: 655.37
               Mean episode length: 228.58
    Episode_Reward/reaching_object: 1.2066
    Episode_Reward/rotating_object: 132.9808
        Episode_Reward/action_rate: -0.0773
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 2.28s
                      Time elapsed: 00:39:48
                               ETA: 00:15:52

################################################################################
                     [1m Learning iteration 1073/1500 [0m                     

                       Computation: 42054 steps/s (collection: 2.212s, learning 0.125s)
             Mean action noise std: 3.59
          Mean value_function loss: 79.9905
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 68.6210
                       Mean reward: 647.42
               Mean episode length: 231.69
    Episode_Reward/reaching_object: 1.2124
    Episode_Reward/rotating_object: 130.8715
        Episode_Reward/action_rate: -0.0787
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 2.34s
                      Time elapsed: 00:39:50
                               ETA: 00:15:50

################################################################################
                     [1m Learning iteration 1074/1500 [0m                     

                       Computation: 43903 steps/s (collection: 2.129s, learning 0.111s)
             Mean action noise std: 3.59
          Mean value_function loss: 84.8604
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 68.6347
                       Mean reward: 688.11
               Mean episode length: 234.01
    Episode_Reward/reaching_object: 1.1873
    Episode_Reward/rotating_object: 131.2410
        Episode_Reward/action_rate: -0.0773
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 2.24s
                      Time elapsed: 00:39:52
                               ETA: 00:15:48

################################################################################
                     [1m Learning iteration 1075/1500 [0m                     

                       Computation: 47003 steps/s (collection: 1.981s, learning 0.111s)
             Mean action noise std: 3.60
          Mean value_function loss: 80.4886
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 68.6518
                       Mean reward: 711.02
               Mean episode length: 237.46
    Episode_Reward/reaching_object: 1.1629
    Episode_Reward/rotating_object: 129.9290
        Episode_Reward/action_rate: -0.0761
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 2.09s
                      Time elapsed: 00:39:54
                               ETA: 00:15:45

################################################################################
                     [1m Learning iteration 1076/1500 [0m                     

                       Computation: 47086 steps/s (collection: 1.977s, learning 0.111s)
             Mean action noise std: 3.60
          Mean value_function loss: 84.9505
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 68.6716
                       Mean reward: 702.29
               Mean episode length: 241.65
    Episode_Reward/reaching_object: 1.2128
    Episode_Reward/rotating_object: 134.1579
        Episode_Reward/action_rate: -0.0790
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 2.09s
                      Time elapsed: 00:39:56
                               ETA: 00:15:43

################################################################################
                     [1m Learning iteration 1077/1500 [0m                     

                       Computation: 46444 steps/s (collection: 2.006s, learning 0.111s)
             Mean action noise std: 3.60
          Mean value_function loss: 82.7612
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 68.6944
                       Mean reward: 600.18
               Mean episode length: 228.88
    Episode_Reward/reaching_object: 1.2076
    Episode_Reward/rotating_object: 132.3873
        Episode_Reward/action_rate: -0.0793
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 2.12s
                      Time elapsed: 00:39:59
                               ETA: 00:15:41

################################################################################
                     [1m Learning iteration 1078/1500 [0m                     

                       Computation: 46737 steps/s (collection: 1.993s, learning 0.111s)
             Mean action noise std: 3.60
          Mean value_function loss: 81.0993
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 68.7155
                       Mean reward: 644.19
               Mean episode length: 235.17
    Episode_Reward/reaching_object: 1.1995
    Episode_Reward/rotating_object: 129.9786
        Episode_Reward/action_rate: -0.0792
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 2.10s
                      Time elapsed: 00:40:01
                               ETA: 00:15:39

################################################################################
                     [1m Learning iteration 1079/1500 [0m                     

                       Computation: 46561 steps/s (collection: 2.000s, learning 0.111s)
             Mean action noise std: 3.61
          Mean value_function loss: 90.8717
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 68.7346
                       Mean reward: 702.39
               Mean episode length: 239.37
    Episode_Reward/reaching_object: 1.2023
    Episode_Reward/rotating_object: 135.8389
        Episode_Reward/action_rate: -0.0793
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 2.11s
                      Time elapsed: 00:40:03
                               ETA: 00:15:36

################################################################################
                     [1m Learning iteration 1080/1500 [0m                     

                       Computation: 46675 steps/s (collection: 1.996s, learning 0.111s)
             Mean action noise std: 3.61
          Mean value_function loss: 86.5098
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 68.7529
                       Mean reward: 723.08
               Mean episode length: 241.97
    Episode_Reward/reaching_object: 1.1968
    Episode_Reward/rotating_object: 134.9433
        Episode_Reward/action_rate: -0.0791
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 2.11s
                      Time elapsed: 00:40:05
                               ETA: 00:15:34

################################################################################
                     [1m Learning iteration 1081/1500 [0m                     

                       Computation: 46498 steps/s (collection: 2.003s, learning 0.111s)
             Mean action noise std: 3.61
          Mean value_function loss: 88.2209
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 68.7708
                       Mean reward: 653.83
               Mean episode length: 226.54
    Episode_Reward/reaching_object: 1.1748
    Episode_Reward/rotating_object: 131.1225
        Episode_Reward/action_rate: -0.0783
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 2.11s
                      Time elapsed: 00:40:07
                               ETA: 00:15:32

################################################################################
                     [1m Learning iteration 1082/1500 [0m                     

                       Computation: 45859 steps/s (collection: 2.018s, learning 0.126s)
             Mean action noise std: 3.62
          Mean value_function loss: 85.1232
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 68.8004
                       Mean reward: 708.20
               Mean episode length: 240.05
    Episode_Reward/reaching_object: 1.1990
    Episode_Reward/rotating_object: 136.5888
        Episode_Reward/action_rate: -0.0796
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 2.14s
                      Time elapsed: 00:40:09
                               ETA: 00:15:30

################################################################################
                     [1m Learning iteration 1083/1500 [0m                     

                       Computation: 45924 steps/s (collection: 2.030s, learning 0.110s)
             Mean action noise std: 3.62
          Mean value_function loss: 90.6126
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 68.8318
                       Mean reward: 706.11
               Mean episode length: 238.85
    Episode_Reward/reaching_object: 1.2031
    Episode_Reward/rotating_object: 135.4233
        Episode_Reward/action_rate: -0.0799
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 2.14s
                      Time elapsed: 00:40:11
                               ETA: 00:15:27

################################################################################
                     [1m Learning iteration 1084/1500 [0m                     

                       Computation: 46215 steps/s (collection: 2.014s, learning 0.113s)
             Mean action noise std: 3.62
          Mean value_function loss: 66.7857
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 68.8601
                       Mean reward: 712.83
               Mean episode length: 242.70
    Episode_Reward/reaching_object: 1.2383
    Episode_Reward/rotating_object: 141.5849
        Episode_Reward/action_rate: -0.0823
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 2.13s
                      Time elapsed: 00:40:13
                               ETA: 00:15:25

################################################################################
                     [1m Learning iteration 1085/1500 [0m                     

                       Computation: 46293 steps/s (collection: 2.013s, learning 0.111s)
             Mean action noise std: 3.63
          Mean value_function loss: 85.1474
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 68.8892
                       Mean reward: 655.92
               Mean episode length: 227.67
    Episode_Reward/reaching_object: 1.1720
    Episode_Reward/rotating_object: 133.9859
        Episode_Reward/action_rate: -0.0788
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 2.12s
                      Time elapsed: 00:40:16
                               ETA: 00:15:23

################################################################################
                     [1m Learning iteration 1086/1500 [0m                     

                       Computation: 45904 steps/s (collection: 2.024s, learning 0.117s)
             Mean action noise std: 3.63
          Mean value_function loss: 88.9180
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 68.9113
                       Mean reward: 656.13
               Mean episode length: 231.01
    Episode_Reward/reaching_object: 1.1752
    Episode_Reward/rotating_object: 134.0866
        Episode_Reward/action_rate: -0.0794
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 2.14s
                      Time elapsed: 00:40:18
                               ETA: 00:15:20

################################################################################
                     [1m Learning iteration 1087/1500 [0m                     

                       Computation: 45926 steps/s (collection: 2.029s, learning 0.111s)
             Mean action noise std: 3.63
          Mean value_function loss: 91.1439
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 68.9302
                       Mean reward: 686.32
               Mean episode length: 236.60
    Episode_Reward/reaching_object: 1.1998
    Episode_Reward/rotating_object: 137.8428
        Episode_Reward/action_rate: -0.0804
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 2.14s
                      Time elapsed: 00:40:20
                               ETA: 00:15:18

################################################################################
                     [1m Learning iteration 1088/1500 [0m                     

                       Computation: 45853 steps/s (collection: 2.029s, learning 0.115s)
             Mean action noise std: 3.64
          Mean value_function loss: 101.3027
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 68.9466
                       Mean reward: 668.34
               Mean episode length: 231.17
    Episode_Reward/reaching_object: 1.1893
    Episode_Reward/rotating_object: 135.9275
        Episode_Reward/action_rate: -0.0802
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 2.14s
                      Time elapsed: 00:40:22
                               ETA: 00:15:16

################################################################################
                     [1m Learning iteration 1089/1500 [0m                     

                       Computation: 45704 steps/s (collection: 2.040s, learning 0.111s)
             Mean action noise std: 3.64
          Mean value_function loss: 101.6311
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 68.9682
                       Mean reward: 589.79
               Mean episode length: 217.25
    Episode_Reward/reaching_object: 1.1677
    Episode_Reward/rotating_object: 128.1286
        Episode_Reward/action_rate: -0.0789
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 2.15s
                      Time elapsed: 00:40:24
                               ETA: 00:15:14

################################################################################
                     [1m Learning iteration 1090/1500 [0m                     

                       Computation: 45711 steps/s (collection: 2.038s, learning 0.113s)
             Mean action noise std: 3.64
          Mean value_function loss: 93.2117
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 68.9960
                       Mean reward: 691.87
               Mean episode length: 237.49
    Episode_Reward/reaching_object: 1.1977
    Episode_Reward/rotating_object: 134.6835
        Episode_Reward/action_rate: -0.0813
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 2.15s
                      Time elapsed: 00:40:26
                               ETA: 00:15:11

################################################################################
                     [1m Learning iteration 1091/1500 [0m                     

                       Computation: 45607 steps/s (collection: 2.044s, learning 0.111s)
             Mean action noise std: 3.65
          Mean value_function loss: 92.7021
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 69.0242
                       Mean reward: 641.28
               Mean episode length: 241.34
    Episode_Reward/reaching_object: 1.2041
    Episode_Reward/rotating_object: 132.8699
        Episode_Reward/action_rate: -0.0812
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 2.16s
                      Time elapsed: 00:40:28
                               ETA: 00:15:09

################################################################################
                     [1m Learning iteration 1092/1500 [0m                     

                       Computation: 45640 steps/s (collection: 2.043s, learning 0.111s)
             Mean action noise std: 3.65
          Mean value_function loss: 95.5899
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 69.0400
                       Mean reward: 631.05
               Mean episode length: 231.36
    Episode_Reward/reaching_object: 1.1894
    Episode_Reward/rotating_object: 131.6490
        Episode_Reward/action_rate: -0.0809
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 2.15s
                      Time elapsed: 00:40:31
                               ETA: 00:15:07

################################################################################
                     [1m Learning iteration 1093/1500 [0m                     

                       Computation: 45557 steps/s (collection: 2.034s, learning 0.124s)
             Mean action noise std: 3.65
          Mean value_function loss: 110.6734
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 69.0545
                       Mean reward: 683.98
               Mean episode length: 230.56
    Episode_Reward/reaching_object: 1.1702
    Episode_Reward/rotating_object: 130.1071
        Episode_Reward/action_rate: -0.0796
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 2.16s
                      Time elapsed: 00:40:33
                               ETA: 00:15:05

################################################################################
                     [1m Learning iteration 1094/1500 [0m                     

                       Computation: 45301 steps/s (collection: 2.045s, learning 0.125s)
             Mean action noise std: 3.66
          Mean value_function loss: 76.0215
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 69.0754
                       Mean reward: 665.79
               Mean episode length: 238.10
    Episode_Reward/reaching_object: 1.2059
    Episode_Reward/rotating_object: 136.9739
        Episode_Reward/action_rate: -0.0815
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 2.17s
                      Time elapsed: 00:40:35
                               ETA: 00:15:02

################################################################################
                     [1m Learning iteration 1095/1500 [0m                     

                       Computation: 44721 steps/s (collection: 2.072s, learning 0.126s)
             Mean action noise std: 3.66
          Mean value_function loss: 94.0474
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 69.0939
                       Mean reward: 677.34
               Mean episode length: 231.12
    Episode_Reward/reaching_object: 1.1832
    Episode_Reward/rotating_object: 131.8036
        Episode_Reward/action_rate: -0.0809
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 2.20s
                      Time elapsed: 00:40:37
                               ETA: 00:15:00

################################################################################
                     [1m Learning iteration 1096/1500 [0m                     

                       Computation: 44922 steps/s (collection: 2.055s, learning 0.133s)
             Mean action noise std: 3.66
          Mean value_function loss: 84.0410
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 69.1163
                       Mean reward: 694.42
               Mean episode length: 238.21
    Episode_Reward/reaching_object: 1.1844
    Episode_Reward/rotating_object: 132.7975
        Episode_Reward/action_rate: -0.0807
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 2.19s
                      Time elapsed: 00:40:39
                               ETA: 00:14:58

################################################################################
                     [1m Learning iteration 1097/1500 [0m                     

                       Computation: 46238 steps/s (collection: 2.014s, learning 0.112s)
             Mean action noise std: 3.67
          Mean value_function loss: 90.9626
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 69.1460
                       Mean reward: 666.80
               Mean episode length: 238.25
    Episode_Reward/reaching_object: 1.1720
    Episode_Reward/rotating_object: 130.3324
        Episode_Reward/action_rate: -0.0797
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 2.13s
                      Time elapsed: 00:40:41
                               ETA: 00:14:56

################################################################################
                     [1m Learning iteration 1098/1500 [0m                     

                       Computation: 46757 steps/s (collection: 1.991s, learning 0.111s)
             Mean action noise std: 3.67
          Mean value_function loss: 91.7554
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 69.1665
                       Mean reward: 635.54
               Mean episode length: 227.01
    Episode_Reward/reaching_object: 1.1550
    Episode_Reward/rotating_object: 124.5800
        Episode_Reward/action_rate: -0.0798
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 2.10s
                      Time elapsed: 00:40:44
                               ETA: 00:14:53

################################################################################
                     [1m Learning iteration 1099/1500 [0m                     

                       Computation: 46843 steps/s (collection: 1.988s, learning 0.111s)
             Mean action noise std: 3.67
          Mean value_function loss: 81.4130
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 69.1825
                       Mean reward: 680.53
               Mean episode length: 236.82
    Episode_Reward/reaching_object: 1.2123
    Episode_Reward/rotating_object: 135.7655
        Episode_Reward/action_rate: -0.0828
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 2.10s
                      Time elapsed: 00:40:46
                               ETA: 00:14:51

################################################################################
                     [1m Learning iteration 1100/1500 [0m                     

                       Computation: 46650 steps/s (collection: 1.996s, learning 0.111s)
             Mean action noise std: 3.67
          Mean value_function loss: 91.0914
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 69.1944
                       Mean reward: 691.12
               Mean episode length: 241.68
    Episode_Reward/reaching_object: 1.2124
    Episode_Reward/rotating_object: 134.1151
        Episode_Reward/action_rate: -0.0831
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 2.11s
                      Time elapsed: 00:40:48
                               ETA: 00:14:49

################################################################################
                     [1m Learning iteration 1101/1500 [0m                     

                       Computation: 46683 steps/s (collection: 1.995s, learning 0.111s)
             Mean action noise std: 3.68
          Mean value_function loss: 83.7710
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 69.2028
                       Mean reward: 702.41
               Mean episode length: 245.56
    Episode_Reward/reaching_object: 1.2100
    Episode_Reward/rotating_object: 135.0909
        Episode_Reward/action_rate: -0.0830
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 2.11s
                      Time elapsed: 00:40:50
                               ETA: 00:14:47

################################################################################
                     [1m Learning iteration 1102/1500 [0m                     

                       Computation: 45989 steps/s (collection: 2.027s, learning 0.111s)
             Mean action noise std: 3.68
          Mean value_function loss: 85.2411
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 69.2194
                       Mean reward: 627.82
               Mean episode length: 232.29
    Episode_Reward/reaching_object: 1.1829
    Episode_Reward/rotating_object: 128.6867
        Episode_Reward/action_rate: -0.0815
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 2.14s
                      Time elapsed: 00:40:52
                               ETA: 00:14:44

################################################################################
                     [1m Learning iteration 1103/1500 [0m                     

                       Computation: 46310 steps/s (collection: 2.012s, learning 0.111s)
             Mean action noise std: 3.68
          Mean value_function loss: 82.5674
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 69.2380
                       Mean reward: 725.27
               Mean episode length: 241.48
    Episode_Reward/reaching_object: 1.2126
    Episode_Reward/rotating_object: 138.7439
        Episode_Reward/action_rate: -0.0830
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 2.12s
                      Time elapsed: 00:40:54
                               ETA: 00:14:42

################################################################################
                     [1m Learning iteration 1104/1500 [0m                     

                       Computation: 44879 steps/s (collection: 2.077s, learning 0.113s)
             Mean action noise std: 3.69
          Mean value_function loss: 85.9849
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 69.2592
                       Mean reward: 615.96
               Mean episode length: 216.40
    Episode_Reward/reaching_object: 1.1956
    Episode_Reward/rotating_object: 134.0620
        Episode_Reward/action_rate: -0.0823
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 2.19s
                      Time elapsed: 00:40:56
                               ETA: 00:14:40

################################################################################
                     [1m Learning iteration 1105/1500 [0m                     

                       Computation: 45179 steps/s (collection: 2.064s, learning 0.112s)
             Mean action noise std: 3.69
          Mean value_function loss: 89.0383
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 69.2777
                       Mean reward: 611.40
               Mean episode length: 222.74
    Episode_Reward/reaching_object: 1.1868
    Episode_Reward/rotating_object: 129.1719
        Episode_Reward/action_rate: -0.0821
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 2.18s
                      Time elapsed: 00:40:58
                               ETA: 00:14:38

################################################################################
                     [1m Learning iteration 1106/1500 [0m                     

                       Computation: 44621 steps/s (collection: 2.092s, learning 0.111s)
             Mean action noise std: 3.69
          Mean value_function loss: 90.8714
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 69.2957
                       Mean reward: 664.93
               Mean episode length: 228.74
    Episode_Reward/reaching_object: 1.1753
    Episode_Reward/rotating_object: 132.0650
        Episode_Reward/action_rate: -0.0813
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 2.20s
                      Time elapsed: 00:41:01
                               ETA: 00:14:35

################################################################################
                     [1m Learning iteration 1107/1500 [0m                     

                       Computation: 44160 steps/s (collection: 2.110s, learning 0.116s)
             Mean action noise std: 3.69
          Mean value_function loss: 75.0488
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 69.3145
                       Mean reward: 688.42
               Mean episode length: 231.64
    Episode_Reward/reaching_object: 1.1931
    Episode_Reward/rotating_object: 135.8430
        Episode_Reward/action_rate: -0.0829
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 2.23s
                      Time elapsed: 00:41:03
                               ETA: 00:14:33

################################################################################
                     [1m Learning iteration 1108/1500 [0m                     

                       Computation: 45484 steps/s (collection: 2.049s, learning 0.113s)
             Mean action noise std: 3.70
          Mean value_function loss: 104.0638
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 69.3352
                       Mean reward: 676.51
               Mean episode length: 229.16
    Episode_Reward/reaching_object: 1.1801
    Episode_Reward/rotating_object: 135.3226
        Episode_Reward/action_rate: -0.0820
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 2.16s
                      Time elapsed: 00:41:05
                               ETA: 00:14:31

################################################################################
                     [1m Learning iteration 1109/1500 [0m                     

                       Computation: 45109 steps/s (collection: 2.068s, learning 0.112s)
             Mean action noise std: 3.70
          Mean value_function loss: 82.6930
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 69.3616
                       Mean reward: 656.16
               Mean episode length: 236.08
    Episode_Reward/reaching_object: 1.1895
    Episode_Reward/rotating_object: 130.1950
        Episode_Reward/action_rate: -0.0826
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 2.18s
                      Time elapsed: 00:41:07
                               ETA: 00:14:29

################################################################################
                     [1m Learning iteration 1110/1500 [0m                     

                       Computation: 46230 steps/s (collection: 2.016s, learning 0.111s)
             Mean action noise std: 3.71
          Mean value_function loss: 91.7059
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 69.3922
                       Mean reward: 674.76
               Mean episode length: 237.21
    Episode_Reward/reaching_object: 1.2101
    Episode_Reward/rotating_object: 136.2765
        Episode_Reward/action_rate: -0.0842
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 2.13s
                      Time elapsed: 00:41:09
                               ETA: 00:14:27

################################################################################
                     [1m Learning iteration 1111/1500 [0m                     

                       Computation: 45454 steps/s (collection: 2.051s, learning 0.112s)
             Mean action noise std: 3.71
          Mean value_function loss: 86.6755
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 69.4055
                       Mean reward: 714.11
               Mean episode length: 234.33
    Episode_Reward/reaching_object: 1.1974
    Episode_Reward/rotating_object: 136.6803
        Episode_Reward/action_rate: -0.0834
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 2.16s
                      Time elapsed: 00:41:12
                               ETA: 00:14:24

################################################################################
                     [1m Learning iteration 1112/1500 [0m                     

                       Computation: 46188 steps/s (collection: 2.018s, learning 0.110s)
             Mean action noise std: 3.71
          Mean value_function loss: 88.8064
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 69.4172
                       Mean reward: 699.66
               Mean episode length: 238.62
    Episode_Reward/reaching_object: 1.1962
    Episode_Reward/rotating_object: 132.0429
        Episode_Reward/action_rate: -0.0836
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 2.13s
                      Time elapsed: 00:41:14
                               ETA: 00:14:22

################################################################################
                     [1m Learning iteration 1113/1500 [0m                     

                       Computation: 45978 steps/s (collection: 2.024s, learning 0.114s)
             Mean action noise std: 3.71
          Mean value_function loss: 96.6604
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 69.4381
                       Mean reward: 700.94
               Mean episode length: 232.14
    Episode_Reward/reaching_object: 1.1920
    Episode_Reward/rotating_object: 134.1486
        Episode_Reward/action_rate: -0.0834
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 2.14s
                      Time elapsed: 00:41:16
                               ETA: 00:14:20

################################################################################
                     [1m Learning iteration 1114/1500 [0m                     

                       Computation: 45935 steps/s (collection: 2.027s, learning 0.113s)
             Mean action noise std: 3.72
          Mean value_function loss: 89.2332
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 69.4588
                       Mean reward: 694.40
               Mean episode length: 234.88
    Episode_Reward/reaching_object: 1.1747
    Episode_Reward/rotating_object: 131.9876
        Episode_Reward/action_rate: -0.0822
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 2.14s
                      Time elapsed: 00:41:18
                               ETA: 00:14:17

################################################################################
                     [1m Learning iteration 1115/1500 [0m                     

                       Computation: 45968 steps/s (collection: 2.028s, learning 0.110s)
             Mean action noise std: 3.72
          Mean value_function loss: 85.3812
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 69.4817
                       Mean reward: 700.39
               Mean episode length: 239.84
    Episode_Reward/reaching_object: 1.1903
    Episode_Reward/rotating_object: 129.5916
        Episode_Reward/action_rate: -0.0830
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 2.14s
                      Time elapsed: 00:41:20
                               ETA: 00:14:15

################################################################################
                     [1m Learning iteration 1116/1500 [0m                     

                       Computation: 45130 steps/s (collection: 2.060s, learning 0.119s)
             Mean action noise std: 3.72
          Mean value_function loss: 90.7096
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 69.5049
                       Mean reward: 653.84
               Mean episode length: 227.15
    Episode_Reward/reaching_object: 1.1975
    Episode_Reward/rotating_object: 133.5522
        Episode_Reward/action_rate: -0.0836
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 2.18s
                      Time elapsed: 00:41:22
                               ETA: 00:14:13

################################################################################
                     [1m Learning iteration 1117/1500 [0m                     

                       Computation: 42208 steps/s (collection: 2.209s, learning 0.120s)
             Mean action noise std: 3.73
          Mean value_function loss: 86.4412
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 69.5335
                       Mean reward: 642.09
               Mean episode length: 218.44
    Episode_Reward/reaching_object: 1.1630
    Episode_Reward/rotating_object: 130.3021
        Episode_Reward/action_rate: -0.0817
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 2.33s
                      Time elapsed: 00:41:25
                               ETA: 00:14:11

################################################################################
                     [1m Learning iteration 1118/1500 [0m                     

                       Computation: 45741 steps/s (collection: 2.034s, learning 0.115s)
             Mean action noise std: 3.73
          Mean value_function loss: 103.0092
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 69.5538
                       Mean reward: 667.89
               Mean episode length: 225.19
    Episode_Reward/reaching_object: 1.1629
    Episode_Reward/rotating_object: 131.7550
        Episode_Reward/action_rate: -0.0817
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 2.15s
                      Time elapsed: 00:41:27
                               ETA: 00:14:09

################################################################################
                     [1m Learning iteration 1119/1500 [0m                     

                       Computation: 45443 steps/s (collection: 2.050s, learning 0.113s)
             Mean action noise std: 3.73
          Mean value_function loss: 80.0174
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 69.5682
                       Mean reward: 670.28
               Mean episode length: 233.15
    Episode_Reward/reaching_object: 1.1869
    Episode_Reward/rotating_object: 132.2413
        Episode_Reward/action_rate: -0.0839
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 2.16s
                      Time elapsed: 00:41:29
                               ETA: 00:14:06

################################################################################
                     [1m Learning iteration 1120/1500 [0m                     

                       Computation: 47076 steps/s (collection: 1.978s, learning 0.110s)
             Mean action noise std: 3.73
          Mean value_function loss: 100.0010
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 69.5825
                       Mean reward: 676.31
               Mean episode length: 229.24
    Episode_Reward/reaching_object: 1.2022
    Episode_Reward/rotating_object: 135.8198
        Episode_Reward/action_rate: -0.0849
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 2.09s
                      Time elapsed: 00:41:31
                               ETA: 00:14:04

################################################################################
                     [1m Learning iteration 1121/1500 [0m                     

                       Computation: 47202 steps/s (collection: 1.969s, learning 0.114s)
             Mean action noise std: 3.74
          Mean value_function loss: 102.8536
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 69.6017
                       Mean reward: 664.50
               Mean episode length: 225.02
    Episode_Reward/reaching_object: 1.1761
    Episode_Reward/rotating_object: 133.7244
        Episode_Reward/action_rate: -0.0837
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 2.08s
                      Time elapsed: 00:41:33
                               ETA: 00:14:02

################################################################################
                     [1m Learning iteration 1122/1500 [0m                     

                       Computation: 47098 steps/s (collection: 1.977s, learning 0.110s)
             Mean action noise std: 3.74
          Mean value_function loss: 103.5012
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 69.6162
                       Mean reward: 594.24
               Mean episode length: 220.07
    Episode_Reward/reaching_object: 1.1571
    Episode_Reward/rotating_object: 131.2102
        Episode_Reward/action_rate: -0.0825
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 2.09s
                      Time elapsed: 00:41:35
                               ETA: 00:14:00

################################################################################
                     [1m Learning iteration 1123/1500 [0m                     

                       Computation: 47157 steps/s (collection: 1.974s, learning 0.110s)
             Mean action noise std: 3.74
          Mean value_function loss: 93.7481
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 69.6323
                       Mean reward: 713.81
               Mean episode length: 236.72
    Episode_Reward/reaching_object: 1.1766
    Episode_Reward/rotating_object: 136.7707
        Episode_Reward/action_rate: -0.0838
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 2.08s
                      Time elapsed: 00:41:37
                               ETA: 00:13:57

################################################################################
                     [1m Learning iteration 1124/1500 [0m                     

                       Computation: 47562 steps/s (collection: 1.957s, learning 0.110s)
             Mean action noise std: 3.75
          Mean value_function loss: 102.3514
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 69.6556
                       Mean reward: 661.23
               Mean episode length: 234.91
    Episode_Reward/reaching_object: 1.1848
    Episode_Reward/rotating_object: 133.5432
        Episode_Reward/action_rate: -0.0846
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 2.07s
                      Time elapsed: 00:41:39
                               ETA: 00:13:55

################################################################################
                     [1m Learning iteration 1125/1500 [0m                     

                       Computation: 47382 steps/s (collection: 1.965s, learning 0.110s)
             Mean action noise std: 3.75
          Mean value_function loss: 92.0523
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 69.6750
                       Mean reward: 713.16
               Mean episode length: 240.80
    Episode_Reward/reaching_object: 1.1750
    Episode_Reward/rotating_object: 130.6206
        Episode_Reward/action_rate: -0.0842
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 2.07s
                      Time elapsed: 00:41:41
                               ETA: 00:13:53

################################################################################
                     [1m Learning iteration 1126/1500 [0m                     

                       Computation: 47230 steps/s (collection: 1.967s, learning 0.115s)
             Mean action noise std: 3.75
          Mean value_function loss: 110.2689
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 69.7005
                       Mean reward: 685.81
               Mean episode length: 229.73
    Episode_Reward/reaching_object: 1.1322
    Episode_Reward/rotating_object: 127.6964
        Episode_Reward/action_rate: -0.0815
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 2.08s
                      Time elapsed: 00:41:43
                               ETA: 00:13:50

################################################################################
                     [1m Learning iteration 1127/1500 [0m                     

                       Computation: 46568 steps/s (collection: 1.998s, learning 0.113s)
             Mean action noise std: 3.76
          Mean value_function loss: 106.8574
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 69.7254
                       Mean reward: 635.40
               Mean episode length: 229.66
    Episode_Reward/reaching_object: 1.1672
    Episode_Reward/rotating_object: 130.9449
        Episode_Reward/action_rate: -0.0839
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 2.11s
                      Time elapsed: 00:41:46
                               ETA: 00:13:48

################################################################################
                     [1m Learning iteration 1128/1500 [0m                     

                       Computation: 45533 steps/s (collection: 2.046s, learning 0.113s)
             Mean action noise std: 3.76
          Mean value_function loss: 90.7338
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 69.7486
                       Mean reward: 697.62
               Mean episode length: 228.40
    Episode_Reward/reaching_object: 1.1706
    Episode_Reward/rotating_object: 133.3276
        Episode_Reward/action_rate: -0.0840
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 2.16s
                      Time elapsed: 00:41:48
                               ETA: 00:13:46

################################################################################
                     [1m Learning iteration 1129/1500 [0m                     

                       Computation: 45018 steps/s (collection: 2.070s, learning 0.113s)
             Mean action noise std: 3.76
          Mean value_function loss: 97.1484
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 69.7666
                       Mean reward: 656.62
               Mean episode length: 226.11
    Episode_Reward/reaching_object: 1.1803
    Episode_Reward/rotating_object: 134.4367
        Episode_Reward/action_rate: -0.0849
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 2.18s
                      Time elapsed: 00:41:50
                               ETA: 00:13:44

################################################################################
                     [1m Learning iteration 1130/1500 [0m                     

                       Computation: 42954 steps/s (collection: 2.163s, learning 0.126s)
             Mean action noise std: 3.76
          Mean value_function loss: 102.2187
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 69.7801
                       Mean reward: 662.31
               Mean episode length: 229.11
    Episode_Reward/reaching_object: 1.1932
    Episode_Reward/rotating_object: 133.2991
        Episode_Reward/action_rate: -0.0858
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 2.29s
                      Time elapsed: 00:41:52
                               ETA: 00:13:42

################################################################################
                     [1m Learning iteration 1131/1500 [0m                     

                       Computation: 42578 steps/s (collection: 2.197s, learning 0.112s)
             Mean action noise std: 3.77
          Mean value_function loss: 105.2879
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 69.7958
                       Mean reward: 599.01
               Mean episode length: 219.97
    Episode_Reward/reaching_object: 1.1551
    Episode_Reward/rotating_object: 128.8101
        Episode_Reward/action_rate: -0.0839
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 2.31s
                      Time elapsed: 00:41:54
                               ETA: 00:13:39

################################################################################
                     [1m Learning iteration 1132/1500 [0m                     

                       Computation: 42731 steps/s (collection: 2.179s, learning 0.121s)
             Mean action noise std: 3.77
          Mean value_function loss: 78.1156
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 69.8192
                       Mean reward: 679.01
               Mean episode length: 237.93
    Episode_Reward/reaching_object: 1.1968
    Episode_Reward/rotating_object: 133.2473
        Episode_Reward/action_rate: -0.0862
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 2.30s
                      Time elapsed: 00:41:57
                               ETA: 00:13:37

################################################################################
                     [1m Learning iteration 1133/1500 [0m                     

                       Computation: 45558 steps/s (collection: 2.035s, learning 0.123s)
             Mean action noise std: 3.77
          Mean value_function loss: 110.2544
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 69.8431
                       Mean reward: 674.47
               Mean episode length: 233.60
    Episode_Reward/reaching_object: 1.1862
    Episode_Reward/rotating_object: 137.5521
        Episode_Reward/action_rate: -0.0854
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 2.16s
                      Time elapsed: 00:41:59
                               ETA: 00:13:35

################################################################################
                     [1m Learning iteration 1134/1500 [0m                     

                       Computation: 46278 steps/s (collection: 2.008s, learning 0.116s)
             Mean action noise std: 3.78
          Mean value_function loss: 102.5545
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 69.8619
                       Mean reward: 680.27
               Mean episode length: 232.06
    Episode_Reward/reaching_object: 1.1574
    Episode_Reward/rotating_object: 131.4089
        Episode_Reward/action_rate: -0.0833
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 2.12s
                      Time elapsed: 00:42:01
                               ETA: 00:13:33

################################################################################
                     [1m Learning iteration 1135/1500 [0m                     

                       Computation: 46070 steps/s (collection: 2.023s, learning 0.111s)
             Mean action noise std: 3.78
          Mean value_function loss: 97.6332
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 69.8737
                       Mean reward: 689.10
               Mean episode length: 231.62
    Episode_Reward/reaching_object: 1.1844
    Episode_Reward/rotating_object: 133.7776
        Episode_Reward/action_rate: -0.0865
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 2.13s
                      Time elapsed: 00:42:03
                               ETA: 00:13:30

################################################################################
                     [1m Learning iteration 1136/1500 [0m                     

                       Computation: 46275 steps/s (collection: 2.011s, learning 0.113s)
             Mean action noise std: 3.78
          Mean value_function loss: 95.4531
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 69.8950
                       Mean reward: 629.49
               Mean episode length: 231.76
    Episode_Reward/reaching_object: 1.1706
    Episode_Reward/rotating_object: 126.3667
        Episode_Reward/action_rate: -0.0852
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 2.12s
                      Time elapsed: 00:42:05
                               ETA: 00:13:28

################################################################################
                     [1m Learning iteration 1137/1500 [0m                     

                       Computation: 46068 steps/s (collection: 2.021s, learning 0.113s)
             Mean action noise std: 3.78
          Mean value_function loss: 86.2086
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 69.9197
                       Mean reward: 700.74
               Mean episode length: 237.87
    Episode_Reward/reaching_object: 1.1940
    Episode_Reward/rotating_object: 131.4479
        Episode_Reward/action_rate: -0.0869
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 2.13s
                      Time elapsed: 00:42:07
                               ETA: 00:13:26

################################################################################
                     [1m Learning iteration 1138/1500 [0m                     

                       Computation: 46201 steps/s (collection: 2.012s, learning 0.116s)
             Mean action noise std: 3.79
          Mean value_function loss: 95.2868
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 69.9360
                       Mean reward: 706.34
               Mean episode length: 235.82
    Episode_Reward/reaching_object: 1.1664
    Episode_Reward/rotating_object: 131.0064
        Episode_Reward/action_rate: -0.0851
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 2.13s
                      Time elapsed: 00:42:10
                               ETA: 00:13:24

################################################################################
                     [1m Learning iteration 1139/1500 [0m                     

                       Computation: 44775 steps/s (collection: 2.080s, learning 0.115s)
             Mean action noise std: 3.79
          Mean value_function loss: 88.6994
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 69.9563
                       Mean reward: 674.43
               Mean episode length: 233.47
    Episode_Reward/reaching_object: 1.2021
    Episode_Reward/rotating_object: 136.1882
        Episode_Reward/action_rate: -0.0875
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 2.20s
                      Time elapsed: 00:42:12
                               ETA: 00:13:21

################################################################################
                     [1m Learning iteration 1140/1500 [0m                     

                       Computation: 45471 steps/s (collection: 2.051s, learning 0.110s)
             Mean action noise std: 3.79
          Mean value_function loss: 107.2937
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 69.9795
                       Mean reward: 637.14
               Mean episode length: 225.19
    Episode_Reward/reaching_object: 1.1764
    Episode_Reward/rotating_object: 131.3794
        Episode_Reward/action_rate: -0.0858
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 2.16s
                      Time elapsed: 00:42:14
                               ETA: 00:13:19

################################################################################
                     [1m Learning iteration 1141/1500 [0m                     

                       Computation: 46003 steps/s (collection: 2.022s, learning 0.115s)
             Mean action noise std: 3.80
          Mean value_function loss: 121.4752
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 70.0006
                       Mean reward: 678.29
               Mean episode length: 230.29
    Episode_Reward/reaching_object: 1.1684
    Episode_Reward/rotating_object: 131.9428
        Episode_Reward/action_rate: -0.0853
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 2.14s
                      Time elapsed: 00:42:16
                               ETA: 00:13:17

################################################################################
                     [1m Learning iteration 1142/1500 [0m                     

                       Computation: 46527 steps/s (collection: 2.002s, learning 0.111s)
             Mean action noise std: 3.80
          Mean value_function loss: 92.2191
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 70.0229
                       Mean reward: 677.11
               Mean episode length: 233.13
    Episode_Reward/reaching_object: 1.1869
    Episode_Reward/rotating_object: 135.8346
        Episode_Reward/action_rate: -0.0870
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 2.11s
                      Time elapsed: 00:42:18
                               ETA: 00:13:15

################################################################################
                     [1m Learning iteration 1143/1500 [0m                     

                       Computation: 46323 steps/s (collection: 2.011s, learning 0.111s)
             Mean action noise std: 3.80
          Mean value_function loss: 97.0514
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 70.0403
                       Mean reward: 693.20
               Mean episode length: 235.46
    Episode_Reward/reaching_object: 1.1909
    Episode_Reward/rotating_object: 132.4656
        Episode_Reward/action_rate: -0.0872
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 2.12s
                      Time elapsed: 00:42:20
                               ETA: 00:13:12

################################################################################
                     [1m Learning iteration 1144/1500 [0m                     

                       Computation: 46584 steps/s (collection: 1.999s, learning 0.111s)
             Mean action noise std: 3.81
          Mean value_function loss: 106.7446
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 70.0612
                       Mean reward: 658.14
               Mean episode length: 227.46
    Episode_Reward/reaching_object: 1.1752
    Episode_Reward/rotating_object: 131.0815
        Episode_Reward/action_rate: -0.0860
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 2.11s
                      Time elapsed: 00:42:22
                               ETA: 00:13:10

################################################################################
                     [1m Learning iteration 1145/1500 [0m                     

                       Computation: 46959 steps/s (collection: 1.983s, learning 0.110s)
             Mean action noise std: 3.81
          Mean value_function loss: 78.5379
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 70.0820
                       Mean reward: 697.52
               Mean episode length: 246.00
    Episode_Reward/reaching_object: 1.1992
    Episode_Reward/rotating_object: 133.0572
        Episode_Reward/action_rate: -0.0876
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 2.09s
                      Time elapsed: 00:42:25
                               ETA: 00:13:08

################################################################################
                     [1m Learning iteration 1146/1500 [0m                     

                       Computation: 46704 steps/s (collection: 1.994s, learning 0.110s)
             Mean action noise std: 3.81
          Mean value_function loss: 87.9762
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 70.0992
                       Mean reward: 684.22
               Mean episode length: 235.10
    Episode_Reward/reaching_object: 1.1795
    Episode_Reward/rotating_object: 131.5785
        Episode_Reward/action_rate: -0.0867
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 2.10s
                      Time elapsed: 00:42:27
                               ETA: 00:13:06

################################################################################
                     [1m Learning iteration 1147/1500 [0m                     

                       Computation: 46699 steps/s (collection: 1.994s, learning 0.111s)
             Mean action noise std: 3.82
          Mean value_function loss: 94.5408
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 70.1160
                       Mean reward: 602.73
               Mean episode length: 223.07
    Episode_Reward/reaching_object: 1.1743
    Episode_Reward/rotating_object: 127.3790
        Episode_Reward/action_rate: -0.0869
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 2.11s
                      Time elapsed: 00:42:29
                               ETA: 00:13:03

################################################################################
                     [1m Learning iteration 1148/1500 [0m                     

                       Computation: 47038 steps/s (collection: 1.980s, learning 0.110s)
             Mean action noise std: 3.82
          Mean value_function loss: 96.8199
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 70.1439
                       Mean reward: 653.47
               Mean episode length: 234.47
    Episode_Reward/reaching_object: 1.1749
    Episode_Reward/rotating_object: 130.2942
        Episode_Reward/action_rate: -0.0865
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 2.09s
                      Time elapsed: 00:42:31
                               ETA: 00:13:01

################################################################################
                     [1m Learning iteration 1149/1500 [0m                     

                       Computation: 46595 steps/s (collection: 1.997s, learning 0.113s)
             Mean action noise std: 3.82
          Mean value_function loss: 85.3117
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 70.1613
                       Mean reward: 657.30
               Mean episode length: 235.15
    Episode_Reward/reaching_object: 1.1973
    Episode_Reward/rotating_object: 133.8160
        Episode_Reward/action_rate: -0.0883
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 2.11s
                      Time elapsed: 00:42:33
                               ETA: 00:12:59

################################################################################
                     [1m Learning iteration 1150/1500 [0m                     

                       Computation: 46011 steps/s (collection: 2.026s, learning 0.110s)
             Mean action noise std: 3.83
          Mean value_function loss: 92.3923
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 70.1790
                       Mean reward: 693.22
               Mean episode length: 236.82
    Episode_Reward/reaching_object: 1.2233
    Episode_Reward/rotating_object: 137.0911
        Episode_Reward/action_rate: -0.0898
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 2.14s
                      Time elapsed: 00:42:35
                               ETA: 00:12:57

################################################################################
                     [1m Learning iteration 1151/1500 [0m                     

                       Computation: 46065 steps/s (collection: 2.024s, learning 0.110s)
             Mean action noise std: 3.83
          Mean value_function loss: 98.7022
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 70.2001
                       Mean reward: 640.79
               Mean episode length: 229.89
    Episode_Reward/reaching_object: 1.1934
    Episode_Reward/rotating_object: 132.6084
        Episode_Reward/action_rate: -0.0881
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 2.13s
                      Time elapsed: 00:42:37
                               ETA: 00:12:54

################################################################################
                     [1m Learning iteration 1152/1500 [0m                     

                       Computation: 46295 steps/s (collection: 2.011s, learning 0.112s)
             Mean action noise std: 3.83
          Mean value_function loss: 94.0151
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 70.2227
                       Mean reward: 646.67
               Mean episode length: 232.72
    Episode_Reward/reaching_object: 1.1970
    Episode_Reward/rotating_object: 132.4231
        Episode_Reward/action_rate: -0.0883
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 2.12s
                      Time elapsed: 00:42:39
                               ETA: 00:12:52

################################################################################
                     [1m Learning iteration 1153/1500 [0m                     

                       Computation: 46005 steps/s (collection: 2.026s, learning 0.111s)
             Mean action noise std: 3.83
          Mean value_function loss: 101.8082
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 70.2416
                       Mean reward: 629.56
               Mean episode length: 225.33
    Episode_Reward/reaching_object: 1.1896
    Episode_Reward/rotating_object: 132.2870
        Episode_Reward/action_rate: -0.0880
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 2.14s
                      Time elapsed: 00:42:41
                               ETA: 00:12:50

################################################################################
                     [1m Learning iteration 1154/1500 [0m                     

                       Computation: 46142 steps/s (collection: 2.016s, learning 0.115s)
             Mean action noise std: 3.84
          Mean value_function loss: 90.4691
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 70.2580
                       Mean reward: 680.71
               Mean episode length: 234.45
    Episode_Reward/reaching_object: 1.1941
    Episode_Reward/rotating_object: 133.3076
        Episode_Reward/action_rate: -0.0892
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 2.13s
                      Time elapsed: 00:42:44
                               ETA: 00:12:48

################################################################################
                     [1m Learning iteration 1155/1500 [0m                     

                       Computation: 46204 steps/s (collection: 2.017s, learning 0.110s)
             Mean action noise std: 3.84
          Mean value_function loss: 116.6792
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 70.2764
                       Mean reward: 701.85
               Mean episode length: 232.60
    Episode_Reward/reaching_object: 1.1787
    Episode_Reward/rotating_object: 135.0845
        Episode_Reward/action_rate: -0.0875
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 2.13s
                      Time elapsed: 00:42:46
                               ETA: 00:12:45

################################################################################
                     [1m Learning iteration 1156/1500 [0m                     

                       Computation: 46178 steps/s (collection: 2.018s, learning 0.111s)
             Mean action noise std: 3.84
          Mean value_function loss: 92.7886
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 70.2930
                       Mean reward: 708.07
               Mean episode length: 232.02
    Episode_Reward/reaching_object: 1.1890
    Episode_Reward/rotating_object: 133.1179
        Episode_Reward/action_rate: -0.0888
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 2.13s
                      Time elapsed: 00:42:48
                               ETA: 00:12:43

################################################################################
                     [1m Learning iteration 1157/1500 [0m                     

                       Computation: 45404 steps/s (collection: 2.042s, learning 0.123s)
             Mean action noise std: 3.85
          Mean value_function loss: 93.7617
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 70.3162
                       Mean reward: 640.13
               Mean episode length: 229.71
    Episode_Reward/reaching_object: 1.1662
    Episode_Reward/rotating_object: 126.1446
        Episode_Reward/action_rate: -0.0874
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 2.17s
                      Time elapsed: 00:42:50
                               ETA: 00:12:41

################################################################################
                     [1m Learning iteration 1158/1500 [0m                     

                       Computation: 45422 steps/s (collection: 2.053s, learning 0.111s)
             Mean action noise std: 3.85
          Mean value_function loss: 97.9878
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 70.3408
                       Mean reward: 644.34
               Mean episode length: 229.35
    Episode_Reward/reaching_object: 1.1931
    Episode_Reward/rotating_object: 134.4314
        Episode_Reward/action_rate: -0.0892
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 2.16s
                      Time elapsed: 00:42:52
                               ETA: 00:12:39

################################################################################
                     [1m Learning iteration 1159/1500 [0m                     

                       Computation: 46305 steps/s (collection: 2.010s, learning 0.113s)
             Mean action noise std: 3.85
          Mean value_function loss: 108.4859
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 70.3709
                       Mean reward: 650.56
               Mean episode length: 226.40
    Episode_Reward/reaching_object: 1.1627
    Episode_Reward/rotating_object: 129.7790
        Episode_Reward/action_rate: -0.0871
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 2.12s
                      Time elapsed: 00:42:54
                               ETA: 00:12:36

################################################################################
                     [1m Learning iteration 1160/1500 [0m                     

                       Computation: 46006 steps/s (collection: 2.024s, learning 0.113s)
             Mean action noise std: 3.86
          Mean value_function loss: 86.3240
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 70.3935
                       Mean reward: 653.89
               Mean episode length: 237.68
    Episode_Reward/reaching_object: 1.2035
    Episode_Reward/rotating_object: 132.1441
        Episode_Reward/action_rate: -0.0903
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 2.14s
                      Time elapsed: 00:42:56
                               ETA: 00:12:34

################################################################################
                     [1m Learning iteration 1161/1500 [0m                     

                       Computation: 46307 steps/s (collection: 2.012s, learning 0.111s)
             Mean action noise std: 3.86
          Mean value_function loss: 93.2972
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 70.4068
                       Mean reward: 683.16
               Mean episode length: 235.02
    Episode_Reward/reaching_object: 1.2006
    Episode_Reward/rotating_object: 135.3471
        Episode_Reward/action_rate: -0.0897
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 2.12s
                      Time elapsed: 00:42:59
                               ETA: 00:12:32

################################################################################
                     [1m Learning iteration 1162/1500 [0m                     

                       Computation: 46323 steps/s (collection: 2.006s, learning 0.116s)
             Mean action noise std: 3.86
          Mean value_function loss: 101.3451
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 70.4237
                       Mean reward: 686.57
               Mean episode length: 232.47
    Episode_Reward/reaching_object: 1.2109
    Episode_Reward/rotating_object: 133.1100
        Episode_Reward/action_rate: -0.0906
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 2.12s
                      Time elapsed: 00:43:01
                               ETA: 00:12:30

################################################################################
                     [1m Learning iteration 1163/1500 [0m                     

                       Computation: 45991 steps/s (collection: 2.026s, learning 0.112s)
             Mean action noise std: 3.86
          Mean value_function loss: 100.3283
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 70.4394
                       Mean reward: 627.30
               Mean episode length: 226.65
    Episode_Reward/reaching_object: 1.1778
    Episode_Reward/rotating_object: 128.5208
        Episode_Reward/action_rate: -0.0884
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 2.14s
                      Time elapsed: 00:43:03
                               ETA: 00:12:27

################################################################################
                     [1m Learning iteration 1164/1500 [0m                     

                       Computation: 47221 steps/s (collection: 1.972s, learning 0.110s)
             Mean action noise std: 3.87
          Mean value_function loss: 85.0321
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 70.4549
                       Mean reward: 658.04
               Mean episode length: 235.68
    Episode_Reward/reaching_object: 1.1915
    Episode_Reward/rotating_object: 131.5796
        Episode_Reward/action_rate: -0.0892
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 2.08s
                      Time elapsed: 00:43:05
                               ETA: 00:12:25

################################################################################
                     [1m Learning iteration 1165/1500 [0m                     

                       Computation: 46732 steps/s (collection: 1.994s, learning 0.110s)
             Mean action noise std: 3.87
          Mean value_function loss: 89.2639
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 70.4726
                       Mean reward: 645.66
               Mean episode length: 225.91
    Episode_Reward/reaching_object: 1.1946
    Episode_Reward/rotating_object: 128.5676
        Episode_Reward/action_rate: -0.0899
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 2.10s
                      Time elapsed: 00:43:07
                               ETA: 00:12:23

################################################################################
                     [1m Learning iteration 1166/1500 [0m                     

                       Computation: 47481 steps/s (collection: 1.960s, learning 0.111s)
             Mean action noise std: 3.87
          Mean value_function loss: 102.1856
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 70.4972
                       Mean reward: 611.11
               Mean episode length: 219.84
    Episode_Reward/reaching_object: 1.1831
    Episode_Reward/rotating_object: 129.7410
        Episode_Reward/action_rate: -0.0888
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 2.07s
                      Time elapsed: 00:43:09
                               ETA: 00:12:21

################################################################################
                     [1m Learning iteration 1167/1500 [0m                     

                       Computation: 47083 steps/s (collection: 1.972s, learning 0.116s)
             Mean action noise std: 3.88
          Mean value_function loss: 83.0008
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 70.5165
                       Mean reward: 652.80
               Mean episode length: 231.83
    Episode_Reward/reaching_object: 1.2122
    Episode_Reward/rotating_object: 135.4465
        Episode_Reward/action_rate: -0.0910
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 2.09s
                      Time elapsed: 00:43:11
                               ETA: 00:12:18

################################################################################
                     [1m Learning iteration 1168/1500 [0m                     

                       Computation: 47168 steps/s (collection: 1.974s, learning 0.110s)
             Mean action noise std: 3.88
          Mean value_function loss: 98.9586
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 70.5301
                       Mean reward: 675.52
               Mean episode length: 229.22
    Episode_Reward/reaching_object: 1.1624
    Episode_Reward/rotating_object: 131.0155
        Episode_Reward/action_rate: -0.0883
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 2.08s
                      Time elapsed: 00:43:13
                               ETA: 00:12:16

################################################################################
                     [1m Learning iteration 1169/1500 [0m                     

                       Computation: 47240 steps/s (collection: 1.967s, learning 0.114s)
             Mean action noise std: 3.88
          Mean value_function loss: 83.8253
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 70.5417
                       Mean reward: 703.12
               Mean episode length: 233.69
    Episode_Reward/reaching_object: 1.2155
    Episode_Reward/rotating_object: 133.9150
        Episode_Reward/action_rate: -0.0918
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 2.08s
                      Time elapsed: 00:43:15
                               ETA: 00:12:14

################################################################################
                     [1m Learning iteration 1170/1500 [0m                     

                       Computation: 47360 steps/s (collection: 1.966s, learning 0.110s)
             Mean action noise std: 3.88
          Mean value_function loss: 86.4082
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 70.5633
                       Mean reward: 697.63
               Mean episode length: 233.82
    Episode_Reward/reaching_object: 1.1872
    Episode_Reward/rotating_object: 131.4963
        Episode_Reward/action_rate: -0.0903
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 2.08s
                      Time elapsed: 00:43:17
                               ETA: 00:12:12

################################################################################
                     [1m Learning iteration 1171/1500 [0m                     

                       Computation: 47521 steps/s (collection: 1.956s, learning 0.113s)
             Mean action noise std: 3.89
          Mean value_function loss: 88.6165
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 70.5905
                       Mean reward: 641.88
               Mean episode length: 235.13
    Episode_Reward/reaching_object: 1.1926
    Episode_Reward/rotating_object: 130.8682
        Episode_Reward/action_rate: -0.0910
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 2.07s
                      Time elapsed: 00:43:19
                               ETA: 00:12:09

################################################################################
                     [1m Learning iteration 1172/1500 [0m                     

                       Computation: 46593 steps/s (collection: 1.987s, learning 0.122s)
             Mean action noise std: 3.89
          Mean value_function loss: 75.4953
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 70.6169
                       Mean reward: 653.31
               Mean episode length: 235.00
    Episode_Reward/reaching_object: 1.1959
    Episode_Reward/rotating_object: 131.8315
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 2.11s
                      Time elapsed: 00:43:22
                               ETA: 00:12:07

################################################################################
                     [1m Learning iteration 1173/1500 [0m                     

                       Computation: 46015 steps/s (collection: 2.023s, learning 0.113s)
             Mean action noise std: 3.90
          Mean value_function loss: 72.0963
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 70.6437
                       Mean reward: 682.54
               Mean episode length: 238.21
    Episode_Reward/reaching_object: 1.1966
    Episode_Reward/rotating_object: 133.9743
        Episode_Reward/action_rate: -0.0920
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 2.14s
                      Time elapsed: 00:43:24
                               ETA: 00:12:05

################################################################################
                     [1m Learning iteration 1174/1500 [0m                     

                       Computation: 46499 steps/s (collection: 2.000s, learning 0.115s)
             Mean action noise std: 3.90
          Mean value_function loss: 83.1903
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 70.6634
                       Mean reward: 698.11
               Mean episode length: 239.21
    Episode_Reward/reaching_object: 1.1747
    Episode_Reward/rotating_object: 132.9363
        Episode_Reward/action_rate: -0.0903
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 2.11s
                      Time elapsed: 00:43:26
                               ETA: 00:12:03

################################################################################
                     [1m Learning iteration 1175/1500 [0m                     

                       Computation: 46599 steps/s (collection: 1.995s, learning 0.115s)
             Mean action noise std: 3.90
          Mean value_function loss: 87.8172
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 70.6743
                       Mean reward: 664.29
               Mean episode length: 237.34
    Episode_Reward/reaching_object: 1.1920
    Episode_Reward/rotating_object: 134.9632
        Episode_Reward/action_rate: -0.0920
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 2.11s
                      Time elapsed: 00:43:28
                               ETA: 00:12:00

################################################################################
                     [1m Learning iteration 1176/1500 [0m                     

                       Computation: 43257 steps/s (collection: 2.146s, learning 0.127s)
             Mean action noise std: 3.90
          Mean value_function loss: 91.1592
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 70.6875
                       Mean reward: 694.99
               Mean episode length: 240.93
    Episode_Reward/reaching_object: 1.1761
    Episode_Reward/rotating_object: 131.9958
        Episode_Reward/action_rate: -0.0905
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 2.27s
                      Time elapsed: 00:43:30
                               ETA: 00:11:58

################################################################################
                     [1m Learning iteration 1177/1500 [0m                     

                       Computation: 43039 steps/s (collection: 2.159s, learning 0.125s)
             Mean action noise std: 3.91
          Mean value_function loss: 110.6108
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 70.7066
                       Mean reward: 645.79
               Mean episode length: 227.04
    Episode_Reward/reaching_object: 1.1695
    Episode_Reward/rotating_object: 130.8510
        Episode_Reward/action_rate: -0.0902
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 2.28s
                      Time elapsed: 00:43:33
                               ETA: 00:11:56

################################################################################
                     [1m Learning iteration 1178/1500 [0m                     

                       Computation: 42522 steps/s (collection: 2.183s, learning 0.128s)
             Mean action noise std: 3.91
          Mean value_function loss: 96.4279
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 70.7242
                       Mean reward: 663.87
               Mean episode length: 234.45
    Episode_Reward/reaching_object: 1.2009
    Episode_Reward/rotating_object: 136.7020
        Episode_Reward/action_rate: -0.0923
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 2.31s
                      Time elapsed: 00:43:35
                               ETA: 00:11:54

################################################################################
                     [1m Learning iteration 1179/1500 [0m                     

                       Computation: 44516 steps/s (collection: 2.096s, learning 0.113s)
             Mean action noise std: 3.91
          Mean value_function loss: 92.9410
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 70.7455
                       Mean reward: 645.17
               Mean episode length: 226.05
    Episode_Reward/reaching_object: 1.2011
    Episode_Reward/rotating_object: 134.8024
        Episode_Reward/action_rate: -0.0920
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 2.21s
                      Time elapsed: 00:43:37
                               ETA: 00:11:52

################################################################################
                     [1m Learning iteration 1180/1500 [0m                     

                       Computation: 44994 steps/s (collection: 2.062s, learning 0.123s)
             Mean action noise std: 3.91
          Mean value_function loss: 82.7497
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 70.7646
                       Mean reward: 717.53
               Mean episode length: 242.50
    Episode_Reward/reaching_object: 1.2069
    Episode_Reward/rotating_object: 139.2106
        Episode_Reward/action_rate: -0.0928
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 2.18s
                      Time elapsed: 00:43:39
                               ETA: 00:11:49

################################################################################
                     [1m Learning iteration 1181/1500 [0m                     

                       Computation: 45186 steps/s (collection: 2.051s, learning 0.124s)
             Mean action noise std: 3.92
          Mean value_function loss: 67.6647
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 70.7878
                       Mean reward: 720.93
               Mean episode length: 233.23
    Episode_Reward/reaching_object: 1.2075
    Episode_Reward/rotating_object: 137.8407
        Episode_Reward/action_rate: -0.0928
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 2.18s
                      Time elapsed: 00:43:41
                               ETA: 00:11:47

################################################################################
                     [1m Learning iteration 1182/1500 [0m                     

                       Computation: 45975 steps/s (collection: 2.026s, learning 0.112s)
             Mean action noise std: 3.92
          Mean value_function loss: 85.5316
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 70.8069
                       Mean reward: 699.45
               Mean episode length: 237.80
    Episode_Reward/reaching_object: 1.2039
    Episode_Reward/rotating_object: 136.9538
        Episode_Reward/action_rate: -0.0928
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 2.14s
                      Time elapsed: 00:43:44
                               ETA: 00:11:45

################################################################################
                     [1m Learning iteration 1183/1500 [0m                     

                       Computation: 46354 steps/s (collection: 2.008s, learning 0.113s)
             Mean action noise std: 3.93
          Mean value_function loss: 93.7947
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 70.8284
                       Mean reward: 708.92
               Mean episode length: 241.33
    Episode_Reward/reaching_object: 1.2200
    Episode_Reward/rotating_object: 139.0385
        Episode_Reward/action_rate: -0.0940
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 2.12s
                      Time elapsed: 00:43:46
                               ETA: 00:11:43

################################################################################
                     [1m Learning iteration 1184/1500 [0m                     

                       Computation: 46530 steps/s (collection: 2.003s, learning 0.110s)
             Mean action noise std: 3.93
          Mean value_function loss: 96.8209
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 70.8540
                       Mean reward: 694.08
               Mean episode length: 237.07
    Episode_Reward/reaching_object: 1.1812
    Episode_Reward/rotating_object: 135.5289
        Episode_Reward/action_rate: -0.0913
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 2.11s
                      Time elapsed: 00:43:48
                               ETA: 00:11:40

################################################################################
                     [1m Learning iteration 1185/1500 [0m                     

                       Computation: 45585 steps/s (collection: 2.045s, learning 0.112s)
             Mean action noise std: 3.93
          Mean value_function loss: 89.5736
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 70.8718
                       Mean reward: 694.05
               Mean episode length: 241.19
    Episode_Reward/reaching_object: 1.1815
    Episode_Reward/rotating_object: 133.9635
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 2.16s
                      Time elapsed: 00:43:50
                               ETA: 00:11:38

################################################################################
                     [1m Learning iteration 1186/1500 [0m                     

                       Computation: 45700 steps/s (collection: 2.038s, learning 0.113s)
             Mean action noise std: 3.93
          Mean value_function loss: 103.2527
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 70.8887
                       Mean reward: 671.84
               Mean episode length: 237.31
    Episode_Reward/reaching_object: 1.2011
    Episode_Reward/rotating_object: 133.3535
        Episode_Reward/action_rate: -0.0936
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 2.15s
                      Time elapsed: 00:43:52
                               ETA: 00:11:36

################################################################################
                     [1m Learning iteration 1187/1500 [0m                     

                       Computation: 46258 steps/s (collection: 2.014s, learning 0.111s)
             Mean action noise std: 3.94
          Mean value_function loss: 74.6370
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 70.9115
                       Mean reward: 642.75
               Mean episode length: 236.06
    Episode_Reward/reaching_object: 1.2079
    Episode_Reward/rotating_object: 130.4727
        Episode_Reward/action_rate: -0.0944
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 2.13s
                      Time elapsed: 00:43:54
                               ETA: 00:11:34

################################################################################
                     [1m Learning iteration 1188/1500 [0m                     

                       Computation: 46115 steps/s (collection: 2.022s, learning 0.110s)
             Mean action noise std: 3.94
          Mean value_function loss: 81.6808
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 70.9348
                       Mean reward: 678.93
               Mean episode length: 240.67
    Episode_Reward/reaching_object: 1.2008
    Episode_Reward/rotating_object: 134.2852
        Episode_Reward/action_rate: -0.0939
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 2.13s
                      Time elapsed: 00:43:56
                               ETA: 00:11:31

################################################################################
                     [1m Learning iteration 1189/1500 [0m                     

                       Computation: 47586 steps/s (collection: 1.956s, learning 0.110s)
             Mean action noise std: 3.94
          Mean value_function loss: 81.3062
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 70.9546
                       Mean reward: 706.44
               Mean episode length: 242.55
    Episode_Reward/reaching_object: 1.2057
    Episode_Reward/rotating_object: 136.8484
        Episode_Reward/action_rate: -0.0949
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 2.07s
                      Time elapsed: 00:43:58
                               ETA: 00:11:29

################################################################################
                     [1m Learning iteration 1190/1500 [0m                     

                       Computation: 47396 steps/s (collection: 1.964s, learning 0.110s)
             Mean action noise std: 3.95
          Mean value_function loss: 77.3684
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 70.9718
                       Mean reward: 726.26
               Mean episode length: 235.97
    Episode_Reward/reaching_object: 1.1980
    Episode_Reward/rotating_object: 136.6433
        Episode_Reward/action_rate: -0.0942
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 2.07s
                      Time elapsed: 00:44:00
                               ETA: 00:11:27

################################################################################
                     [1m Learning iteration 1191/1500 [0m                     

                       Computation: 46667 steps/s (collection: 1.997s, learning 0.110s)
             Mean action noise std: 3.95
          Mean value_function loss: 94.8960
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 70.9972
                       Mean reward: 679.61
               Mean episode length: 232.87
    Episode_Reward/reaching_object: 1.1979
    Episode_Reward/rotating_object: 136.1220
        Episode_Reward/action_rate: -0.0943
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 2.11s
                      Time elapsed: 00:44:03
                               ETA: 00:11:25

################################################################################
                     [1m Learning iteration 1192/1500 [0m                     

                       Computation: 47143 steps/s (collection: 1.975s, learning 0.110s)
             Mean action noise std: 3.95
          Mean value_function loss: 88.7935
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 71.0152
                       Mean reward: 608.52
               Mean episode length: 223.61
    Episode_Reward/reaching_object: 1.1924
    Episode_Reward/rotating_object: 132.3546
        Episode_Reward/action_rate: -0.0941
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 2.09s
                      Time elapsed: 00:44:05
                               ETA: 00:11:22

################################################################################
                     [1m Learning iteration 1193/1500 [0m                     

                       Computation: 47155 steps/s (collection: 1.975s, learning 0.110s)
             Mean action noise std: 3.96
          Mean value_function loss: 87.0988
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 71.0347
                       Mean reward: 689.08
               Mean episode length: 239.11
    Episode_Reward/reaching_object: 1.2046
    Episode_Reward/rotating_object: 135.3963
        Episode_Reward/action_rate: -0.0950
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 2.08s
                      Time elapsed: 00:44:07
                               ETA: 00:11:20

################################################################################
                     [1m Learning iteration 1194/1500 [0m                     

                       Computation: 47151 steps/s (collection: 1.975s, learning 0.110s)
             Mean action noise std: 3.96
          Mean value_function loss: 77.6322
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 71.0587
                       Mean reward: 691.24
               Mean episode length: 242.34
    Episode_Reward/reaching_object: 1.1876
    Episode_Reward/rotating_object: 133.4742
        Episode_Reward/action_rate: -0.0940
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 2.08s
                      Time elapsed: 00:44:09
                               ETA: 00:11:18

################################################################################
                     [1m Learning iteration 1195/1500 [0m                     

                       Computation: 46363 steps/s (collection: 2.009s, learning 0.111s)
             Mean action noise std: 3.96
          Mean value_function loss: 89.5329
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 71.0713
                       Mean reward: 688.79
               Mean episode length: 248.24
    Episode_Reward/reaching_object: 1.1761
    Episode_Reward/rotating_object: 130.0191
        Episode_Reward/action_rate: -0.0936
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 2.12s
                      Time elapsed: 00:44:11
                               ETA: 00:11:16

################################################################################
                     [1m Learning iteration 1196/1500 [0m                     

                       Computation: 45898 steps/s (collection: 2.032s, learning 0.110s)
             Mean action noise std: 3.97
          Mean value_function loss: 92.5444
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 71.0934
                       Mean reward: 685.44
               Mean episode length: 236.09
    Episode_Reward/reaching_object: 1.2080
    Episode_Reward/rotating_object: 135.6327
        Episode_Reward/action_rate: -0.0960
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 2.14s
                      Time elapsed: 00:44:13
                               ETA: 00:11:13

################################################################################
                     [1m Learning iteration 1197/1500 [0m                     

                       Computation: 45974 steps/s (collection: 2.025s, learning 0.113s)
             Mean action noise std: 3.97
          Mean value_function loss: 102.9700
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 71.1199
                       Mean reward: 669.46
               Mean episode length: 231.01
    Episode_Reward/reaching_object: 1.1639
    Episode_Reward/rotating_object: 133.6135
        Episode_Reward/action_rate: -0.0930
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 2.14s
                      Time elapsed: 00:44:15
                               ETA: 00:11:11

################################################################################
                     [1m Learning iteration 1198/1500 [0m                     

                       Computation: 45808 steps/s (collection: 2.034s, learning 0.112s)
             Mean action noise std: 3.97
          Mean value_function loss: 91.2859
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 71.1380
                       Mean reward: 656.32
               Mean episode length: 226.26
    Episode_Reward/reaching_object: 1.1877
    Episode_Reward/rotating_object: 131.2507
        Episode_Reward/action_rate: -0.0946
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 2.15s
                      Time elapsed: 00:44:17
                               ETA: 00:11:09

################################################################################
                     [1m Learning iteration 1199/1500 [0m                     

                       Computation: 45172 steps/s (collection: 2.059s, learning 0.117s)
             Mean action noise std: 3.97
          Mean value_function loss: 99.0086
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 71.1548
                       Mean reward: 675.03
               Mean episode length: 238.66
    Episode_Reward/reaching_object: 1.1796
    Episode_Reward/rotating_object: 130.3252
        Episode_Reward/action_rate: -0.0940
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 2.18s
                      Time elapsed: 00:44:20
                               ETA: 00:11:07

################################################################################
                     [1m Learning iteration 1200/1500 [0m                     

                       Computation: 45767 steps/s (collection: 2.034s, learning 0.114s)
             Mean action noise std: 3.98
          Mean value_function loss: 95.6347
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 71.1755
                       Mean reward: 642.70
               Mean episode length: 227.62
    Episode_Reward/reaching_object: 1.1973
    Episode_Reward/rotating_object: 133.9326
        Episode_Reward/action_rate: -0.0954
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 2.15s
                      Time elapsed: 00:44:22
                               ETA: 00:11:04

################################################################################
                     [1m Learning iteration 1201/1500 [0m                     

                       Computation: 42932 steps/s (collection: 2.164s, learning 0.125s)
             Mean action noise std: 3.98
          Mean value_function loss: 92.0547
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 71.1991
                       Mean reward: 665.78
               Mean episode length: 231.08
    Episode_Reward/reaching_object: 1.1939
    Episode_Reward/rotating_object: 132.1627
        Episode_Reward/action_rate: -0.0957
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 2.29s
                      Time elapsed: 00:44:24
                               ETA: 00:11:02

################################################################################
                     [1m Learning iteration 1202/1500 [0m                     

                       Computation: 45915 steps/s (collection: 2.014s, learning 0.127s)
             Mean action noise std: 3.99
          Mean value_function loss: 89.5020
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 71.2237
                       Mean reward: 681.97
               Mean episode length: 237.11
    Episode_Reward/reaching_object: 1.1886
    Episode_Reward/rotating_object: 134.1929
        Episode_Reward/action_rate: -0.0952
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 2.14s
                      Time elapsed: 00:44:26
                               ETA: 00:11:00

################################################################################
                     [1m Learning iteration 1203/1500 [0m                     

                       Computation: 45475 steps/s (collection: 2.024s, learning 0.137s)
             Mean action noise std: 3.99
          Mean value_function loss: 89.6189
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 71.2422
                       Mean reward: 695.04
               Mean episode length: 236.46
    Episode_Reward/reaching_object: 1.1933
    Episode_Reward/rotating_object: 134.3646
        Episode_Reward/action_rate: -0.0955
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 2.16s
                      Time elapsed: 00:44:28
                               ETA: 00:10:58

################################################################################
                     [1m Learning iteration 1204/1500 [0m                     

                       Computation: 45679 steps/s (collection: 2.029s, learning 0.123s)
             Mean action noise std: 3.99
          Mean value_function loss: 88.4019
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 71.2577
                       Mean reward: 655.02
               Mean episode length: 235.37
    Episode_Reward/reaching_object: 1.1735
    Episode_Reward/rotating_object: 131.4483
        Episode_Reward/action_rate: -0.0942
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 2.15s
                      Time elapsed: 00:44:30
                               ETA: 00:10:56

################################################################################
                     [1m Learning iteration 1205/1500 [0m                     

                       Computation: 45971 steps/s (collection: 2.013s, learning 0.125s)
             Mean action noise std: 3.99
          Mean value_function loss: 75.0607
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 71.2740
                       Mean reward: 657.20
               Mean episode length: 230.34
    Episode_Reward/reaching_object: 1.2094
    Episode_Reward/rotating_object: 135.1556
        Episode_Reward/action_rate: -0.0969
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 2.14s
                      Time elapsed: 00:44:33
                               ETA: 00:10:53

################################################################################
                     [1m Learning iteration 1206/1500 [0m                     

                       Computation: 45828 steps/s (collection: 2.021s, learning 0.124s)
             Mean action noise std: 3.99
          Mean value_function loss: 92.9560
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 71.2830
                       Mean reward: 689.31
               Mean episode length: 238.43
    Episode_Reward/reaching_object: 1.2174
    Episode_Reward/rotating_object: 137.7448
        Episode_Reward/action_rate: -0.0984
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 2.15s
                      Time elapsed: 00:44:35
                               ETA: 00:10:51

################################################################################
                     [1m Learning iteration 1207/1500 [0m                     

                       Computation: 45744 steps/s (collection: 2.026s, learning 0.123s)
             Mean action noise std: 4.00
          Mean value_function loss: 81.2020
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 71.2927
                       Mean reward: 687.52
               Mean episode length: 232.71
    Episode_Reward/reaching_object: 1.1932
    Episode_Reward/rotating_object: 135.9019
        Episode_Reward/action_rate: -0.0957
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 2.15s
                      Time elapsed: 00:44:37
                               ETA: 00:10:49

################################################################################
                     [1m Learning iteration 1208/1500 [0m                     

                       Computation: 45805 steps/s (collection: 2.021s, learning 0.125s)
             Mean action noise std: 4.00
          Mean value_function loss: 78.6412
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 71.3070
                       Mean reward: 673.15
               Mean episode length: 230.58
    Episode_Reward/reaching_object: 1.2006
    Episode_Reward/rotating_object: 135.9648
        Episode_Reward/action_rate: -0.0969
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 2.15s
                      Time elapsed: 00:44:39
                               ETA: 00:10:47

################################################################################
                     [1m Learning iteration 1209/1500 [0m                     

                       Computation: 45258 steps/s (collection: 2.043s, learning 0.129s)
             Mean action noise std: 4.00
          Mean value_function loss: 89.2626
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 71.3260
                       Mean reward: 683.51
               Mean episode length: 231.17
    Episode_Reward/reaching_object: 1.1798
    Episode_Reward/rotating_object: 133.2710
        Episode_Reward/action_rate: -0.0952
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 2.17s
                      Time elapsed: 00:44:41
                               ETA: 00:10:44

################################################################################
                     [1m Learning iteration 1210/1500 [0m                     

                       Computation: 45480 steps/s (collection: 2.039s, learning 0.123s)
             Mean action noise std: 4.01
          Mean value_function loss: 78.9728
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 71.3434
                       Mean reward: 629.05
               Mean episode length: 223.90
    Episode_Reward/reaching_object: 1.1882
    Episode_Reward/rotating_object: 134.3943
        Episode_Reward/action_rate: -0.0964
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 2.16s
                      Time elapsed: 00:44:43
                               ETA: 00:10:42

################################################################################
                     [1m Learning iteration 1211/1500 [0m                     

                       Computation: 47182 steps/s (collection: 1.972s, learning 0.111s)
             Mean action noise std: 4.01
          Mean value_function loss: 91.1235
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 71.3623
                       Mean reward: 662.51
               Mean episode length: 233.17
    Episode_Reward/reaching_object: 1.1859
    Episode_Reward/rotating_object: 133.9782
        Episode_Reward/action_rate: -0.0965
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 2.08s
                      Time elapsed: 00:44:45
                               ETA: 00:10:40

################################################################################
                     [1m Learning iteration 1212/1500 [0m                     

                       Computation: 46893 steps/s (collection: 1.986s, learning 0.110s)
             Mean action noise std: 4.01
          Mean value_function loss: 101.6574
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 71.3810
                       Mean reward: 671.59
               Mean episode length: 235.29
    Episode_Reward/reaching_object: 1.1788
    Episode_Reward/rotating_object: 132.7158
        Episode_Reward/action_rate: -0.0955
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 2.10s
                      Time elapsed: 00:44:48
                               ETA: 00:10:38

################################################################################
                     [1m Learning iteration 1213/1500 [0m                     

                       Computation: 46586 steps/s (collection: 1.999s, learning 0.111s)
             Mean action noise std: 4.02
          Mean value_function loss: 97.9096
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 71.4009
                       Mean reward: 650.90
               Mean episode length: 228.47
    Episode_Reward/reaching_object: 1.1977
    Episode_Reward/rotating_object: 135.0179
        Episode_Reward/action_rate: -0.0972
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 2.11s
                      Time elapsed: 00:44:50
                               ETA: 00:10:35

################################################################################
                     [1m Learning iteration 1214/1500 [0m                     

                       Computation: 46847 steps/s (collection: 1.988s, learning 0.111s)
             Mean action noise std: 4.02
          Mean value_function loss: 86.7698
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 71.4220
                       Mean reward: 692.88
               Mean episode length: 232.05
    Episode_Reward/reaching_object: 1.1861
    Episode_Reward/rotating_object: 134.6952
        Episode_Reward/action_rate: -0.0966
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 2.10s
                      Time elapsed: 00:44:52
                               ETA: 00:10:33

################################################################################
                     [1m Learning iteration 1215/1500 [0m                     

                       Computation: 46361 steps/s (collection: 2.010s, learning 0.111s)
             Mean action noise std: 4.02
          Mean value_function loss: 98.5290
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 71.4436
                       Mean reward: 637.28
               Mean episode length: 230.34
    Episode_Reward/reaching_object: 1.1586
    Episode_Reward/rotating_object: 130.1527
        Episode_Reward/action_rate: -0.0946
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 2.12s
                      Time elapsed: 00:44:54
                               ETA: 00:10:31

################################################################################
                     [1m Learning iteration 1216/1500 [0m                     

                       Computation: 45986 steps/s (collection: 2.027s, learning 0.110s)
             Mean action noise std: 4.03
          Mean value_function loss: 98.2466
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 71.4597
                       Mean reward: 676.52
               Mean episode length: 235.60
    Episode_Reward/reaching_object: 1.1946
    Episode_Reward/rotating_object: 135.5149
        Episode_Reward/action_rate: -0.0971
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 2.14s
                      Time elapsed: 00:44:56
                               ETA: 00:10:29

################################################################################
                     [1m Learning iteration 1217/1500 [0m                     

                       Computation: 45245 steps/s (collection: 2.062s, learning 0.111s)
             Mean action noise std: 4.03
          Mean value_function loss: 81.7548
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 71.4751
                       Mean reward: 685.57
               Mean episode length: 232.58
    Episode_Reward/reaching_object: 1.2083
    Episode_Reward/rotating_object: 139.0139
        Episode_Reward/action_rate: -0.0980
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 2.17s
                      Time elapsed: 00:44:58
                               ETA: 00:10:27

################################################################################
                     [1m Learning iteration 1218/1500 [0m                     

                       Computation: 44529 steps/s (collection: 2.096s, learning 0.111s)
             Mean action noise std: 4.03
          Mean value_function loss: 95.9963
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 71.4858
                       Mean reward: 668.41
               Mean episode length: 228.85
    Episode_Reward/reaching_object: 1.2081
    Episode_Reward/rotating_object: 137.6979
        Episode_Reward/action_rate: -0.0981
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 2.21s
                      Time elapsed: 00:45:00
                               ETA: 00:10:24

################################################################################
                     [1m Learning iteration 1219/1500 [0m                     

                       Computation: 44611 steps/s (collection: 2.090s, learning 0.114s)
             Mean action noise std: 4.03
          Mean value_function loss: 78.4393
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 71.4912
                       Mean reward: 717.36
               Mean episode length: 243.60
    Episode_Reward/reaching_object: 1.2167
    Episode_Reward/rotating_object: 140.2237
        Episode_Reward/action_rate: -0.0988
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 2.20s
                      Time elapsed: 00:45:03
                               ETA: 00:10:22

################################################################################
                     [1m Learning iteration 1220/1500 [0m                     

                       Computation: 45998 steps/s (collection: 2.020s, learning 0.117s)
             Mean action noise std: 4.03
          Mean value_function loss: 79.6842
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 71.5034
                       Mean reward: 629.42
               Mean episode length: 232.77
    Episode_Reward/reaching_object: 1.1928
    Episode_Reward/rotating_object: 132.7881
        Episode_Reward/action_rate: -0.0975
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 2.14s
                      Time elapsed: 00:45:05
                               ETA: 00:10:20

################################################################################
                     [1m Learning iteration 1221/1500 [0m                     

                       Computation: 46256 steps/s (collection: 2.012s, learning 0.113s)
             Mean action noise std: 4.04
          Mean value_function loss: 81.2355
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 71.5285
                       Mean reward: 669.77
               Mean episode length: 231.22
    Episode_Reward/reaching_object: 1.1885
    Episode_Reward/rotating_object: 132.3179
        Episode_Reward/action_rate: -0.0971
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 2.13s
                      Time elapsed: 00:45:07
                               ETA: 00:10:18

################################################################################
                     [1m Learning iteration 1222/1500 [0m                     

                       Computation: 42925 steps/s (collection: 2.130s, learning 0.160s)
             Mean action noise std: 4.04
          Mean value_function loss: 90.0365
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 71.5483
                       Mean reward: 667.18
               Mean episode length: 232.21
    Episode_Reward/reaching_object: 1.1967
    Episode_Reward/rotating_object: 134.6229
        Episode_Reward/action_rate: -0.0980
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 2.29s
                      Time elapsed: 00:45:09
                               ETA: 00:10:15

################################################################################
                     [1m Learning iteration 1223/1500 [0m                     

                       Computation: 45760 steps/s (collection: 2.033s, learning 0.115s)
             Mean action noise std: 4.04
          Mean value_function loss: 83.6655
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 71.5643
                       Mean reward: 694.46
               Mean episode length: 233.01
    Episode_Reward/reaching_object: 1.1981
    Episode_Reward/rotating_object: 134.0226
        Episode_Reward/action_rate: -0.0982
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 2.15s
                      Time elapsed: 00:45:11
                               ETA: 00:10:13

################################################################################
                     [1m Learning iteration 1224/1500 [0m                     

                       Computation: 45938 steps/s (collection: 2.012s, learning 0.128s)
             Mean action noise std: 4.05
          Mean value_function loss: 85.0283
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 71.5945
                       Mean reward: 666.95
               Mean episode length: 228.32
    Episode_Reward/reaching_object: 1.1943
    Episode_Reward/rotating_object: 134.6777
        Episode_Reward/action_rate: -0.0985
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 2.14s
                      Time elapsed: 00:45:13
                               ETA: 00:10:11

################################################################################
                     [1m Learning iteration 1225/1500 [0m                     

                       Computation: 41646 steps/s (collection: 2.231s, learning 0.129s)
             Mean action noise std: 4.05
          Mean value_function loss: 99.5264
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 71.6197
                       Mean reward: 687.24
               Mean episode length: 237.41
    Episode_Reward/reaching_object: 1.1993
    Episode_Reward/rotating_object: 132.9060
        Episode_Reward/action_rate: -0.0990
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 2.36s
                      Time elapsed: 00:45:16
                               ETA: 00:10:09

################################################################################
                     [1m Learning iteration 1226/1500 [0m                     

                       Computation: 41996 steps/s (collection: 2.213s, learning 0.127s)
             Mean action noise std: 4.05
          Mean value_function loss: 101.2872
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 71.6341
                       Mean reward: 701.66
               Mean episode length: 238.77
    Episode_Reward/reaching_object: 1.1743
    Episode_Reward/rotating_object: 133.1825
        Episode_Reward/action_rate: -0.0977
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 2.34s
                      Time elapsed: 00:45:18
                               ETA: 00:10:07

################################################################################
                     [1m Learning iteration 1227/1500 [0m                     

                       Computation: 41775 steps/s (collection: 2.225s, learning 0.128s)
             Mean action noise std: 4.05
          Mean value_function loss: 75.2320
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 71.6448
                       Mean reward: 679.64
               Mean episode length: 230.64
    Episode_Reward/reaching_object: 1.1950
    Episode_Reward/rotating_object: 134.0805
        Episode_Reward/action_rate: -0.0991
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 2.35s
                      Time elapsed: 00:45:20
                               ETA: 00:10:04

################################################################################
                     [1m Learning iteration 1228/1500 [0m                     

                       Computation: 42229 steps/s (collection: 2.201s, learning 0.127s)
             Mean action noise std: 4.06
          Mean value_function loss: 89.3692
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 71.6564
                       Mean reward: 744.29
               Mean episode length: 239.72
    Episode_Reward/reaching_object: 1.1878
    Episode_Reward/rotating_object: 135.9026
        Episode_Reward/action_rate: -0.0990
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 2.33s
                      Time elapsed: 00:45:23
                               ETA: 00:10:02

################################################################################
                     [1m Learning iteration 1229/1500 [0m                     

                       Computation: 42449 steps/s (collection: 2.188s, learning 0.128s)
             Mean action noise std: 4.06
          Mean value_function loss: 93.8418
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 71.6726
                       Mean reward: 679.50
               Mean episode length: 241.11
    Episode_Reward/reaching_object: 1.2052
    Episode_Reward/rotating_object: 138.5150
        Episode_Reward/action_rate: -0.1002
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 2.32s
                      Time elapsed: 00:45:25
                               ETA: 00:10:00

################################################################################
                     [1m Learning iteration 1230/1500 [0m                     

                       Computation: 45604 steps/s (collection: 2.031s, learning 0.125s)
             Mean action noise std: 4.06
          Mean value_function loss: 87.6797
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 71.6895
                       Mean reward: 664.53
               Mean episode length: 233.64
    Episode_Reward/reaching_object: 1.1923
    Episode_Reward/rotating_object: 138.2929
        Episode_Reward/action_rate: -0.1002
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 2.16s
                      Time elapsed: 00:45:27
                               ETA: 00:09:58

################################################################################
                     [1m Learning iteration 1231/1500 [0m                     

                       Computation: 45185 steps/s (collection: 2.049s, learning 0.127s)
             Mean action noise std: 4.07
          Mean value_function loss: 91.4292
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 71.7076
                       Mean reward: 674.44
               Mean episode length: 232.36
    Episode_Reward/reaching_object: 1.1903
    Episode_Reward/rotating_object: 137.9470
        Episode_Reward/action_rate: -0.1000
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 2.18s
                      Time elapsed: 00:45:29
                               ETA: 00:09:56

################################################################################
                     [1m Learning iteration 1232/1500 [0m                     

                       Computation: 45830 steps/s (collection: 2.032s, learning 0.113s)
             Mean action noise std: 4.07
          Mean value_function loss: 77.9579
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 71.7309
                       Mean reward: 659.16
               Mean episode length: 225.12
    Episode_Reward/reaching_object: 1.1932
    Episode_Reward/rotating_object: 137.1134
        Episode_Reward/action_rate: -0.1003
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 2.14s
                      Time elapsed: 00:45:32
                               ETA: 00:09:53

################################################################################
                     [1m Learning iteration 1233/1500 [0m                     

                       Computation: 46289 steps/s (collection: 2.005s, learning 0.118s)
             Mean action noise std: 4.07
          Mean value_function loss: 73.2702
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 71.7542
                       Mean reward: 661.93
               Mean episode length: 227.00
    Episode_Reward/reaching_object: 1.1881
    Episode_Reward/rotating_object: 137.4946
        Episode_Reward/action_rate: -0.1001
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 2.12s
                      Time elapsed: 00:45:34
                               ETA: 00:09:51

################################################################################
                     [1m Learning iteration 1234/1500 [0m                     

                       Computation: 45515 steps/s (collection: 2.046s, learning 0.113s)
             Mean action noise std: 4.08
          Mean value_function loss: 80.9381
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 71.7698
                       Mean reward: 701.82
               Mean episode length: 240.54
    Episode_Reward/reaching_object: 1.2042
    Episode_Reward/rotating_object: 137.6625
        Episode_Reward/action_rate: -0.1015
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 2.16s
                      Time elapsed: 00:45:36
                               ETA: 00:09:49

################################################################################
                     [1m Learning iteration 1235/1500 [0m                     

                       Computation: 46725 steps/s (collection: 1.993s, learning 0.111s)
             Mean action noise std: 4.08
          Mean value_function loss: 74.0738
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 71.7917
                       Mean reward: 648.92
               Mean episode length: 235.57
    Episode_Reward/reaching_object: 1.1946
    Episode_Reward/rotating_object: 133.8721
        Episode_Reward/action_rate: -0.1009
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 2.10s
                      Time elapsed: 00:45:38
                               ETA: 00:09:47

################################################################################
                     [1m Learning iteration 1236/1500 [0m                     

                       Computation: 46950 steps/s (collection: 1.983s, learning 0.111s)
             Mean action noise std: 4.08
          Mean value_function loss: 97.0071
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 71.8105
                       Mean reward: 752.92
               Mean episode length: 241.62
    Episode_Reward/reaching_object: 1.1986
    Episode_Reward/rotating_object: 140.3034
        Episode_Reward/action_rate: -0.1009
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 2.09s
                      Time elapsed: 00:45:40
                               ETA: 00:09:44

################################################################################
                     [1m Learning iteration 1237/1500 [0m                     

                       Computation: 45907 steps/s (collection: 2.028s, learning 0.113s)
             Mean action noise std: 4.08
          Mean value_function loss: 92.3687
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 71.8284
                       Mean reward: 696.36
               Mean episode length: 234.75
    Episode_Reward/reaching_object: 1.1651
    Episode_Reward/rotating_object: 132.4012
        Episode_Reward/action_rate: -0.0987
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 2.14s
                      Time elapsed: 00:45:42
                               ETA: 00:09:42

################################################################################
                     [1m Learning iteration 1238/1500 [0m                     

                       Computation: 46870 steps/s (collection: 1.987s, learning 0.111s)
             Mean action noise std: 4.09
          Mean value_function loss: 88.3963
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 71.8443
                       Mean reward: 604.63
               Mean episode length: 230.48
    Episode_Reward/reaching_object: 1.1857
    Episode_Reward/rotating_object: 131.7664
        Episode_Reward/action_rate: -0.1013
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 2.10s
                      Time elapsed: 00:45:44
                               ETA: 00:09:40

################################################################################
                     [1m Learning iteration 1239/1500 [0m                     

                       Computation: 46580 steps/s (collection: 1.997s, learning 0.113s)
             Mean action noise std: 4.09
          Mean value_function loss: 81.7447
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 71.8656
                       Mean reward: 638.20
               Mean episode length: 225.31
    Episode_Reward/reaching_object: 1.1796
    Episode_Reward/rotating_object: 133.2275
        Episode_Reward/action_rate: -0.1004
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 2.11s
                      Time elapsed: 00:45:46
                               ETA: 00:09:38

################################################################################
                     [1m Learning iteration 1240/1500 [0m                     

                       Computation: 46331 steps/s (collection: 1.994s, learning 0.128s)
             Mean action noise std: 4.10
          Mean value_function loss: 80.4040
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 71.8898
                       Mean reward: 675.73
               Mean episode length: 241.04
    Episode_Reward/reaching_object: 1.1821
    Episode_Reward/rotating_object: 133.6490
        Episode_Reward/action_rate: -0.1012
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 2.12s
                      Time elapsed: 00:45:49
                               ETA: 00:09:35

################################################################################
                     [1m Learning iteration 1241/1500 [0m                     

                       Computation: 45626 steps/s (collection: 2.041s, learning 0.113s)
             Mean action noise std: 4.10
          Mean value_function loss: 83.5657
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 71.9074
                       Mean reward: 707.13
               Mean episode length: 239.88
    Episode_Reward/reaching_object: 1.1752
    Episode_Reward/rotating_object: 134.8822
        Episode_Reward/action_rate: -0.1007
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 2.15s
                      Time elapsed: 00:45:51
                               ETA: 00:09:33

################################################################################
                     [1m Learning iteration 1242/1500 [0m                     

                       Computation: 43911 steps/s (collection: 2.117s, learning 0.122s)
             Mean action noise std: 4.10
          Mean value_function loss: 87.9562
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 71.9270
                       Mean reward: 672.85
               Mean episode length: 228.94
    Episode_Reward/reaching_object: 1.1625
    Episode_Reward/rotating_object: 136.8011
        Episode_Reward/action_rate: -0.0999
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 2.24s
                      Time elapsed: 00:45:53
                               ETA: 00:09:31

################################################################################
                     [1m Learning iteration 1243/1500 [0m                     

                       Computation: 46697 steps/s (collection: 1.988s, learning 0.117s)
             Mean action noise std: 4.10
          Mean value_function loss: 84.5373
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 71.9442
                       Mean reward: 729.36
               Mean episode length: 239.88
    Episode_Reward/reaching_object: 1.1914
    Episode_Reward/rotating_object: 140.8866
        Episode_Reward/action_rate: -0.1021
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 2.11s
                      Time elapsed: 00:45:55
                               ETA: 00:09:29

################################################################################
                     [1m Learning iteration 1244/1500 [0m                     

                       Computation: 46502 steps/s (collection: 2.002s, learning 0.112s)
             Mean action noise std: 4.11
          Mean value_function loss: 97.2603
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 71.9610
                       Mean reward: 672.68
               Mean episode length: 235.24
    Episode_Reward/reaching_object: 1.1800
    Episode_Reward/rotating_object: 136.3905
        Episode_Reward/action_rate: -0.1020
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 2.11s
                      Time elapsed: 00:45:57
                               ETA: 00:09:27

################################################################################
                     [1m Learning iteration 1245/1500 [0m                     

                       Computation: 46608 steps/s (collection: 1.998s, learning 0.111s)
             Mean action noise std: 4.11
          Mean value_function loss: 81.1271
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 71.9764
                       Mean reward: 716.86
               Mean episode length: 237.68
    Episode_Reward/reaching_object: 1.1808
    Episode_Reward/rotating_object: 134.3997
        Episode_Reward/action_rate: -0.1023
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 2.11s
                      Time elapsed: 00:45:59
                               ETA: 00:09:24

################################################################################
                     [1m Learning iteration 1246/1500 [0m                     

                       Computation: 46228 steps/s (collection: 2.013s, learning 0.113s)
             Mean action noise std: 4.11
          Mean value_function loss: 78.0951
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 71.9910
                       Mean reward: 671.76
               Mean episode length: 231.07
    Episode_Reward/reaching_object: 1.1628
    Episode_Reward/rotating_object: 132.1803
        Episode_Reward/action_rate: -0.1009
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 2.13s
                      Time elapsed: 00:46:01
                               ETA: 00:09:22

################################################################################
                     [1m Learning iteration 1247/1500 [0m                     

                       Computation: 46152 steps/s (collection: 2.011s, learning 0.119s)
             Mean action noise std: 4.12
          Mean value_function loss: 83.5738
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 72.0035
                       Mean reward: 706.85
               Mean episode length: 238.12
    Episode_Reward/reaching_object: 1.1722
    Episode_Reward/rotating_object: 137.7527
        Episode_Reward/action_rate: -0.1021
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 2.13s
                      Time elapsed: 00:46:04
                               ETA: 00:09:20

################################################################################
                     [1m Learning iteration 1248/1500 [0m                     

                       Computation: 45075 steps/s (collection: 2.049s, learning 0.132s)
             Mean action noise std: 4.12
          Mean value_function loss: 82.4240
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 72.0218
                       Mean reward: 741.42
               Mean episode length: 249.70
    Episode_Reward/reaching_object: 1.1702
    Episode_Reward/rotating_object: 135.9881
        Episode_Reward/action_rate: -0.1019
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 2.18s
                      Time elapsed: 00:46:06
                               ETA: 00:09:18

################################################################################
                     [1m Learning iteration 1249/1500 [0m                     

                       Computation: 46163 steps/s (collection: 2.013s, learning 0.116s)
             Mean action noise std: 4.12
          Mean value_function loss: 78.4810
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 72.0366
                       Mean reward: 679.77
               Mean episode length: 235.92
    Episode_Reward/reaching_object: 1.1728
    Episode_Reward/rotating_object: 135.5734
        Episode_Reward/action_rate: -0.1027
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 2.13s
                      Time elapsed: 00:46:08
                               ETA: 00:09:15

################################################################################
                     [1m Learning iteration 1250/1500 [0m                     

                       Computation: 46519 steps/s (collection: 2.003s, learning 0.110s)
             Mean action noise std: 4.12
          Mean value_function loss: 73.0868
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 72.0565
                       Mean reward: 697.98
               Mean episode length: 238.35
    Episode_Reward/reaching_object: 1.1648
    Episode_Reward/rotating_object: 137.8918
        Episode_Reward/action_rate: -0.1024
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 2.11s
                      Time elapsed: 00:46:10
                               ETA: 00:09:13

################################################################################
                     [1m Learning iteration 1251/1500 [0m                     

                       Computation: 45922 steps/s (collection: 2.026s, learning 0.114s)
             Mean action noise std: 4.13
          Mean value_function loss: 89.7383
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 72.0730
                       Mean reward: 663.94
               Mean episode length: 231.17
    Episode_Reward/reaching_object: 1.1669
    Episode_Reward/rotating_object: 138.2025
        Episode_Reward/action_rate: -0.1026
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 2.14s
                      Time elapsed: 00:46:12
                               ETA: 00:09:11

################################################################################
                     [1m Learning iteration 1252/1500 [0m                     

                       Computation: 45738 steps/s (collection: 2.031s, learning 0.118s)
             Mean action noise std: 4.13
          Mean value_function loss: 71.5313
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 72.0936
                       Mean reward: 689.62
               Mean episode length: 236.38
    Episode_Reward/reaching_object: 1.1672
    Episode_Reward/rotating_object: 133.2066
        Episode_Reward/action_rate: -0.1027
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 2.15s
                      Time elapsed: 00:46:14
                               ETA: 00:09:09

################################################################################
                     [1m Learning iteration 1253/1500 [0m                     

                       Computation: 45061 steps/s (collection: 2.069s, learning 0.113s)
             Mean action noise std: 4.13
          Mean value_function loss: 78.3051
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 72.1198
                       Mean reward: 659.95
               Mean episode length: 231.42
    Episode_Reward/reaching_object: 1.1648
    Episode_Reward/rotating_object: 135.3759
        Episode_Reward/action_rate: -0.1032
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 2.18s
                      Time elapsed: 00:46:16
                               ETA: 00:09:06

################################################################################
                     [1m Learning iteration 1254/1500 [0m                     

                       Computation: 45577 steps/s (collection: 2.043s, learning 0.114s)
             Mean action noise std: 4.14
          Mean value_function loss: 74.1123
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 72.1421
                       Mean reward: 669.73
               Mean episode length: 222.87
    Episode_Reward/reaching_object: 1.1734
    Episode_Reward/rotating_object: 134.8944
        Episode_Reward/action_rate: -0.1036
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 2.16s
                      Time elapsed: 00:46:19
                               ETA: 00:09:04

################################################################################
                     [1m Learning iteration 1255/1500 [0m                     

                       Computation: 45383 steps/s (collection: 2.052s, learning 0.114s)
             Mean action noise std: 4.14
          Mean value_function loss: 75.4847
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 72.1633
                       Mean reward: 749.89
               Mean episode length: 245.26
    Episode_Reward/reaching_object: 1.1670
    Episode_Reward/rotating_object: 137.4989
        Episode_Reward/action_rate: -0.1034
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 2.17s
                      Time elapsed: 00:46:21
                               ETA: 00:09:02

################################################################################
                     [1m Learning iteration 1256/1500 [0m                     

                       Computation: 47693 steps/s (collection: 1.950s, learning 0.111s)
             Mean action noise std: 4.14
          Mean value_function loss: 69.9679
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 72.1802
                       Mean reward: 719.73
               Mean episode length: 240.58
    Episode_Reward/reaching_object: 1.1929
    Episode_Reward/rotating_object: 140.5519
        Episode_Reward/action_rate: -0.1054
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 2.06s
                      Time elapsed: 00:46:23
                               ETA: 00:09:00

################################################################################
                     [1m Learning iteration 1257/1500 [0m                     

                       Computation: 46559 steps/s (collection: 2.001s, learning 0.110s)
             Mean action noise std: 4.15
          Mean value_function loss: 80.9601
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 72.1991
                       Mean reward: 711.73
               Mean episode length: 241.37
    Episode_Reward/reaching_object: 1.2110
    Episode_Reward/rotating_object: 140.4442
        Episode_Reward/action_rate: -0.1066
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 2.11s
                      Time elapsed: 00:46:25
                               ETA: 00:08:58

################################################################################
                     [1m Learning iteration 1258/1500 [0m                     

                       Computation: 47098 steps/s (collection: 1.977s, learning 0.110s)
             Mean action noise std: 4.15
          Mean value_function loss: 87.9496
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 72.2190
                       Mean reward: 682.53
               Mean episode length: 235.71
    Episode_Reward/reaching_object: 1.1637
    Episode_Reward/rotating_object: 133.5685
        Episode_Reward/action_rate: -0.1030
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 2.09s
                      Time elapsed: 00:46:27
                               ETA: 00:08:55

################################################################################
                     [1m Learning iteration 1259/1500 [0m                     

                       Computation: 47007 steps/s (collection: 1.981s, learning 0.110s)
             Mean action noise std: 4.15
          Mean value_function loss: 82.2743
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 72.2364
                       Mean reward: 716.03
               Mean episode length: 233.44
    Episode_Reward/reaching_object: 1.1799
    Episode_Reward/rotating_object: 140.4647
        Episode_Reward/action_rate: -0.1042
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 2.09s
                      Time elapsed: 00:46:29
                               ETA: 00:08:53

################################################################################
                     [1m Learning iteration 1260/1500 [0m                     

                       Computation: 47015 steps/s (collection: 1.980s, learning 0.110s)
             Mean action noise std: 4.16
          Mean value_function loss: 79.3916
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 72.2503
                       Mean reward: 667.30
               Mean episode length: 233.29
    Episode_Reward/reaching_object: 1.1896
    Episode_Reward/rotating_object: 134.9668
        Episode_Reward/action_rate: -0.1049
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 2.09s
                      Time elapsed: 00:46:31
                               ETA: 00:08:51

################################################################################
                     [1m Learning iteration 1261/1500 [0m                     

                       Computation: 47353 steps/s (collection: 1.966s, learning 0.110s)
             Mean action noise std: 4.16
          Mean value_function loss: 82.8308
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 72.2690
                       Mean reward: 720.30
               Mean episode length: 233.82
    Episode_Reward/reaching_object: 1.1877
    Episode_Reward/rotating_object: 138.4165
        Episode_Reward/action_rate: -0.1051
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 2.08s
                      Time elapsed: 00:46:33
                               ETA: 00:08:49

################################################################################
                     [1m Learning iteration 1262/1500 [0m                     

                       Computation: 46727 steps/s (collection: 1.994s, learning 0.110s)
             Mean action noise std: 4.16
          Mean value_function loss: 78.8810
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 72.2886
                       Mean reward: 710.36
               Mean episode length: 234.67
    Episode_Reward/reaching_object: 1.1822
    Episode_Reward/rotating_object: 137.9005
        Episode_Reward/action_rate: -0.1047
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 2.10s
                      Time elapsed: 00:46:35
                               ETA: 00:08:46

################################################################################
                     [1m Learning iteration 1263/1500 [0m                     

                       Computation: 46776 steps/s (collection: 1.991s, learning 0.110s)
             Mean action noise std: 4.17
          Mean value_function loss: 88.9837
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 72.3116
                       Mean reward: 668.56
               Mean episode length: 230.16
    Episode_Reward/reaching_object: 1.1848
    Episode_Reward/rotating_object: 136.2769
        Episode_Reward/action_rate: -0.1053
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 2.10s
                      Time elapsed: 00:46:37
                               ETA: 00:08:44

################################################################################
                     [1m Learning iteration 1264/1500 [0m                     

                       Computation: 46705 steps/s (collection: 1.993s, learning 0.112s)
             Mean action noise std: 4.17
          Mean value_function loss: 90.7534
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 72.3350
                       Mean reward: 704.12
               Mean episode length: 234.06
    Episode_Reward/reaching_object: 1.1799
    Episode_Reward/rotating_object: 136.0005
        Episode_Reward/action_rate: -0.1049
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 2.10s
                      Time elapsed: 00:46:40
                               ETA: 00:08:42

################################################################################
                     [1m Learning iteration 1265/1500 [0m                     

                       Computation: 46474 steps/s (collection: 2.004s, learning 0.111s)
             Mean action noise std: 4.17
          Mean value_function loss: 98.2146
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 72.3589
                       Mean reward: 696.59
               Mean episode length: 231.43
    Episode_Reward/reaching_object: 1.1717
    Episode_Reward/rotating_object: 138.3971
        Episode_Reward/action_rate: -0.1041
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 2.12s
                      Time elapsed: 00:46:42
                               ETA: 00:08:40

################################################################################
                     [1m Learning iteration 1266/1500 [0m                     

                       Computation: 46359 steps/s (collection: 2.010s, learning 0.110s)
             Mean action noise std: 4.18
          Mean value_function loss: 74.0965
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 72.3810
                       Mean reward: 712.18
               Mean episode length: 243.65
    Episode_Reward/reaching_object: 1.2044
    Episode_Reward/rotating_object: 138.5442
        Episode_Reward/action_rate: -0.1075
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 2.12s
                      Time elapsed: 00:46:44
                               ETA: 00:08:37

################################################################################
                     [1m Learning iteration 1267/1500 [0m                     

                       Computation: 46762 steps/s (collection: 1.992s, learning 0.110s)
             Mean action noise std: 4.18
          Mean value_function loss: 78.2521
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 72.3975
                       Mean reward: 638.37
               Mean episode length: 219.69
    Episode_Reward/reaching_object: 1.1777
    Episode_Reward/rotating_object: 136.4548
        Episode_Reward/action_rate: -0.1050
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 2.10s
                      Time elapsed: 00:46:46
                               ETA: 00:08:35

################################################################################
                     [1m Learning iteration 1268/1500 [0m                     

                       Computation: 46774 steps/s (collection: 1.990s, learning 0.112s)
             Mean action noise std: 4.18
          Mean value_function loss: 89.4935
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 72.4161
                       Mean reward: 688.13
               Mean episode length: 234.21
    Episode_Reward/reaching_object: 1.2121
    Episode_Reward/rotating_object: 140.7661
        Episode_Reward/action_rate: -0.1080
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 2.10s
                      Time elapsed: 00:46:48
                               ETA: 00:08:33

################################################################################
                     [1m Learning iteration 1269/1500 [0m                     

                       Computation: 45777 steps/s (collection: 2.033s, learning 0.114s)
             Mean action noise std: 4.19
          Mean value_function loss: 94.3022
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 72.4350
                       Mean reward: 723.69
               Mean episode length: 236.81
    Episode_Reward/reaching_object: 1.2058
    Episode_Reward/rotating_object: 142.0813
        Episode_Reward/action_rate: -0.1078
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 2.15s
                      Time elapsed: 00:46:50
                               ETA: 00:08:31

################################################################################
                     [1m Learning iteration 1270/1500 [0m                     

                       Computation: 45938 steps/s (collection: 2.027s, learning 0.113s)
             Mean action noise std: 4.19
          Mean value_function loss: 79.3747
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 72.4525
                       Mean reward: 739.31
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 1.1833
    Episode_Reward/rotating_object: 136.5947
        Episode_Reward/action_rate: -0.1061
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 2.14s
                      Time elapsed: 00:46:52
                               ETA: 00:08:29

################################################################################
                     [1m Learning iteration 1271/1500 [0m                     

                       Computation: 46204 steps/s (collection: 2.014s, learning 0.113s)
             Mean action noise std: 4.19
          Mean value_function loss: 80.6361
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 72.4716
                       Mean reward: 697.42
               Mean episode length: 240.48
    Episode_Reward/reaching_object: 1.1811
    Episode_Reward/rotating_object: 135.1042
        Episode_Reward/action_rate: -0.1061
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 2.13s
                      Time elapsed: 00:46:54
                               ETA: 00:08:26

################################################################################
                     [1m Learning iteration 1272/1500 [0m                     

                       Computation: 45774 steps/s (collection: 2.035s, learning 0.113s)
             Mean action noise std: 4.19
          Mean value_function loss: 92.3155
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 72.4845
                       Mean reward: 674.11
               Mean episode length: 226.69
    Episode_Reward/reaching_object: 1.1760
    Episode_Reward/rotating_object: 136.9698
        Episode_Reward/action_rate: -0.1052
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 2.15s
                      Time elapsed: 00:46:57
                               ETA: 00:08:24

################################################################################
                     [1m Learning iteration 1273/1500 [0m                     

                       Computation: 45680 steps/s (collection: 2.025s, learning 0.127s)
             Mean action noise std: 4.20
          Mean value_function loss: 92.7104
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 72.5016
                       Mean reward: 661.36
               Mean episode length: 236.78
    Episode_Reward/reaching_object: 1.1897
    Episode_Reward/rotating_object: 133.8895
        Episode_Reward/action_rate: -0.1065
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 2.15s
                      Time elapsed: 00:46:59
                               ETA: 00:08:22

################################################################################
                     [1m Learning iteration 1274/1500 [0m                     

                       Computation: 46205 steps/s (collection: 2.015s, learning 0.113s)
             Mean action noise std: 4.20
          Mean value_function loss: 85.8570
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 72.5170
                       Mean reward: 681.60
               Mean episode length: 233.91
    Episode_Reward/reaching_object: 1.1884
    Episode_Reward/rotating_object: 134.4877
        Episode_Reward/action_rate: -0.1062
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 2.13s
                      Time elapsed: 00:47:01
                               ETA: 00:08:20

################################################################################
                     [1m Learning iteration 1275/1500 [0m                     

                       Computation: 45923 steps/s (collection: 2.027s, learning 0.113s)
             Mean action noise std: 4.20
          Mean value_function loss: 94.0411
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 72.5324
                       Mean reward: 660.70
               Mean episode length: 231.48
    Episode_Reward/reaching_object: 1.1816
    Episode_Reward/rotating_object: 131.3031
        Episode_Reward/action_rate: -0.1057
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 2.14s
                      Time elapsed: 00:47:03
                               ETA: 00:08:17

################################################################################
                     [1m Learning iteration 1276/1500 [0m                     

                       Computation: 45339 steps/s (collection: 2.058s, learning 0.110s)
             Mean action noise std: 4.21
          Mean value_function loss: 85.9127
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 72.5500
                       Mean reward: 720.04
               Mean episode length: 240.02
    Episode_Reward/reaching_object: 1.2026
    Episode_Reward/rotating_object: 136.3248
        Episode_Reward/action_rate: -0.1079
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 2.17s
                      Time elapsed: 00:47:05
                               ETA: 00:08:15

################################################################################
                     [1m Learning iteration 1277/1500 [0m                     

                       Computation: 46767 steps/s (collection: 1.992s, learning 0.110s)
             Mean action noise std: 4.21
          Mean value_function loss: 88.0827
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 72.5709
                       Mean reward: 673.56
               Mean episode length: 241.47
    Episode_Reward/reaching_object: 1.1658
    Episode_Reward/rotating_object: 132.1488
        Episode_Reward/action_rate: -0.1045
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 2.10s
                      Time elapsed: 00:47:07
                               ETA: 00:08:13

################################################################################
                     [1m Learning iteration 1278/1500 [0m                     

                       Computation: 45552 steps/s (collection: 2.042s, learning 0.116s)
             Mean action noise std: 4.21
          Mean value_function loss: 85.1628
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 72.5952
                       Mean reward: 668.74
               Mean episode length: 232.27
    Episode_Reward/reaching_object: 1.1988
    Episode_Reward/rotating_object: 135.0283
        Episode_Reward/action_rate: -0.1075
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 2.16s
                      Time elapsed: 00:47:09
                               ETA: 00:08:11

################################################################################
                     [1m Learning iteration 1279/1500 [0m                     

                       Computation: 44927 steps/s (collection: 2.065s, learning 0.123s)
             Mean action noise std: 4.22
          Mean value_function loss: 98.9481
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 72.6145
                       Mean reward: 710.10
               Mean episode length: 235.63
    Episode_Reward/reaching_object: 1.1780
    Episode_Reward/rotating_object: 135.8084
        Episode_Reward/action_rate: -0.1061
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 2.19s
                      Time elapsed: 00:47:12
                               ETA: 00:08:08

################################################################################
                     [1m Learning iteration 1280/1500 [0m                     

                       Computation: 46749 steps/s (collection: 1.992s, learning 0.111s)
             Mean action noise std: 4.22
          Mean value_function loss: 103.5967
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 72.6329
                       Mean reward: 675.08
               Mean episode length: 239.13
    Episode_Reward/reaching_object: 1.1996
    Episode_Reward/rotating_object: 137.9385
        Episode_Reward/action_rate: -0.1080
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 2.10s
                      Time elapsed: 00:47:14
                               ETA: 00:08:06

################################################################################
                     [1m Learning iteration 1281/1500 [0m                     

                       Computation: 46746 steps/s (collection: 1.992s, learning 0.111s)
             Mean action noise std: 4.22
          Mean value_function loss: 89.7495
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 72.6537
                       Mean reward: 701.98
               Mean episode length: 240.44
    Episode_Reward/reaching_object: 1.2014
    Episode_Reward/rotating_object: 137.7367
        Episode_Reward/action_rate: -0.1086
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 2.10s
                      Time elapsed: 00:47:16
                               ETA: 00:08:04

################################################################################
                     [1m Learning iteration 1282/1500 [0m                     

                       Computation: 47047 steps/s (collection: 1.978s, learning 0.111s)
             Mean action noise std: 4.23
          Mean value_function loss: 95.8627
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 72.6726
                       Mean reward: 652.21
               Mean episode length: 228.68
    Episode_Reward/reaching_object: 1.1780
    Episode_Reward/rotating_object: 134.6497
        Episode_Reward/action_rate: -0.1069
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 2.09s
                      Time elapsed: 00:47:18
                               ETA: 00:08:02

################################################################################
                     [1m Learning iteration 1283/1500 [0m                     

                       Computation: 47232 steps/s (collection: 1.970s, learning 0.111s)
             Mean action noise std: 4.23
          Mean value_function loss: 81.0400
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 72.6918
                       Mean reward: 651.50
               Mean episode length: 228.93
    Episode_Reward/reaching_object: 1.1871
    Episode_Reward/rotating_object: 133.1679
        Episode_Reward/action_rate: -0.1082
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 2.08s
                      Time elapsed: 00:47:20
                               ETA: 00:08:00

################################################################################
                     [1m Learning iteration 1284/1500 [0m                     

                       Computation: 47039 steps/s (collection: 1.979s, learning 0.111s)
             Mean action noise std: 4.23
          Mean value_function loss: 76.8820
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 72.7142
                       Mean reward: 620.88
               Mean episode length: 230.20
    Episode_Reward/reaching_object: 1.1881
    Episode_Reward/rotating_object: 133.7812
        Episode_Reward/action_rate: -0.1079
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 2.09s
                      Time elapsed: 00:47:22
                               ETA: 00:07:57

################################################################################
                     [1m Learning iteration 1285/1500 [0m                     

                       Computation: 46993 steps/s (collection: 1.979s, learning 0.113s)
             Mean action noise std: 4.24
          Mean value_function loss: 82.9232
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 72.7359
                       Mean reward: 690.53
               Mean episode length: 234.01
    Episode_Reward/reaching_object: 1.2087
    Episode_Reward/rotating_object: 141.0249
        Episode_Reward/action_rate: -0.1105
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 2.09s
                      Time elapsed: 00:47:24
                               ETA: 00:07:55

################################################################################
                     [1m Learning iteration 1286/1500 [0m                     

                       Computation: 46056 steps/s (collection: 2.021s, learning 0.113s)
             Mean action noise std: 4.24
          Mean value_function loss: 79.4129
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 72.7542
                       Mean reward: 672.85
               Mean episode length: 233.51
    Episode_Reward/reaching_object: 1.1909
    Episode_Reward/rotating_object: 135.4015
        Episode_Reward/action_rate: -0.1090
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 2.13s
                      Time elapsed: 00:47:26
                               ETA: 00:07:53

################################################################################
                     [1m Learning iteration 1287/1500 [0m                     

                       Computation: 45860 steps/s (collection: 2.033s, learning 0.111s)
             Mean action noise std: 4.24
          Mean value_function loss: 77.3953
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 72.7693
                       Mean reward: 667.53
               Mean episode length: 235.97
    Episode_Reward/reaching_object: 1.2003
    Episode_Reward/rotating_object: 138.2578
        Episode_Reward/action_rate: -0.1096
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 2.14s
                      Time elapsed: 00:47:28
                               ETA: 00:07:51

################################################################################
                     [1m Learning iteration 1288/1500 [0m                     

                       Computation: 46376 steps/s (collection: 2.009s, learning 0.111s)
             Mean action noise std: 4.25
          Mean value_function loss: 93.7052
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 72.7911
                       Mean reward: 693.96
               Mean episode length: 235.45
    Episode_Reward/reaching_object: 1.2104
    Episode_Reward/rotating_object: 139.1851
        Episode_Reward/action_rate: -0.1109
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 2.12s
                      Time elapsed: 00:47:31
                               ETA: 00:07:48

################################################################################
                     [1m Learning iteration 1289/1500 [0m                     

                       Computation: 44950 steps/s (collection: 2.076s, learning 0.111s)
             Mean action noise std: 4.25
          Mean value_function loss: 95.8869
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 72.8136
                       Mean reward: 616.86
               Mean episode length: 227.22
    Episode_Reward/reaching_object: 1.1493
    Episode_Reward/rotating_object: 127.5398
        Episode_Reward/action_rate: -0.1062
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 2.19s
                      Time elapsed: 00:47:33
                               ETA: 00:07:46

################################################################################
                     [1m Learning iteration 1290/1500 [0m                     

                       Computation: 45570 steps/s (collection: 2.046s, learning 0.111s)
             Mean action noise std: 4.25
          Mean value_function loss: 97.5993
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 72.8321
                       Mean reward: 638.20
               Mean episode length: 232.52
    Episode_Reward/reaching_object: 1.1969
    Episode_Reward/rotating_object: 135.0249
        Episode_Reward/action_rate: -0.1103
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 2.16s
                      Time elapsed: 00:47:35
                               ETA: 00:07:44

################################################################################
                     [1m Learning iteration 1291/1500 [0m                     

                       Computation: 44110 steps/s (collection: 2.117s, learning 0.112s)
             Mean action noise std: 4.25
          Mean value_function loss: 106.9086
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 72.8472
                       Mean reward: 650.32
               Mean episode length: 231.17
    Episode_Reward/reaching_object: 1.1580
    Episode_Reward/rotating_object: 127.9084
        Episode_Reward/action_rate: -0.1068
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 2.23s
                      Time elapsed: 00:47:37
                               ETA: 00:07:42

################################################################################
                     [1m Learning iteration 1292/1500 [0m                     

                       Computation: 44670 steps/s (collection: 2.090s, learning 0.111s)
             Mean action noise std: 4.26
          Mean value_function loss: 103.3727
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 72.8634
                       Mean reward: 671.25
               Mean episode length: 233.14
    Episode_Reward/reaching_object: 1.1976
    Episode_Reward/rotating_object: 136.8079
        Episode_Reward/action_rate: -0.1102
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 2.20s
                      Time elapsed: 00:47:39
                               ETA: 00:07:40

################################################################################
                     [1m Learning iteration 1293/1500 [0m                     

                       Computation: 44584 steps/s (collection: 2.093s, learning 0.112s)
             Mean action noise std: 4.26
          Mean value_function loss: 91.9014
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 72.8856
                       Mean reward: 704.20
               Mean episode length: 239.01
    Episode_Reward/reaching_object: 1.1700
    Episode_Reward/rotating_object: 133.3379
        Episode_Reward/action_rate: -0.1076
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 2.20s
                      Time elapsed: 00:47:42
                               ETA: 00:07:37

################################################################################
                     [1m Learning iteration 1294/1500 [0m                     

                       Computation: 45875 steps/s (collection: 2.030s, learning 0.113s)
             Mean action noise std: 4.26
          Mean value_function loss: 94.7262
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 72.9026
                       Mean reward: 679.68
               Mean episode length: 228.78
    Episode_Reward/reaching_object: 1.1878
    Episode_Reward/rotating_object: 133.7568
        Episode_Reward/action_rate: -0.1096
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 2.14s
                      Time elapsed: 00:47:44
                               ETA: 00:07:35

################################################################################
                     [1m Learning iteration 1295/1500 [0m                     

                       Computation: 45234 steps/s (collection: 2.061s, learning 0.112s)
             Mean action noise std: 4.27
          Mean value_function loss: 89.9205
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 72.9217
                       Mean reward: 673.52
               Mean episode length: 233.76
    Episode_Reward/reaching_object: 1.1919
    Episode_Reward/rotating_object: 135.6977
        Episode_Reward/action_rate: -0.1102
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 2.17s
                      Time elapsed: 00:47:46
                               ETA: 00:07:33

################################################################################
                     [1m Learning iteration 1296/1500 [0m                     

                       Computation: 45586 steps/s (collection: 2.043s, learning 0.113s)
             Mean action noise std: 4.27
          Mean value_function loss: 88.2023
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 72.9395
                       Mean reward: 688.10
               Mean episode length: 233.60
    Episode_Reward/reaching_object: 1.1862
    Episode_Reward/rotating_object: 133.8664
        Episode_Reward/action_rate: -0.1100
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 2.16s
                      Time elapsed: 00:47:48
                               ETA: 00:07:31

################################################################################
                     [1m Learning iteration 1297/1500 [0m                     

                       Computation: 45708 steps/s (collection: 2.038s, learning 0.113s)
             Mean action noise std: 4.27
          Mean value_function loss: 84.0573
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 72.9606
                       Mean reward: 672.98
               Mean episode length: 234.39
    Episode_Reward/reaching_object: 1.1918
    Episode_Reward/rotating_object: 134.0380
        Episode_Reward/action_rate: -0.1098
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 2.15s
                      Time elapsed: 00:47:50
                               ETA: 00:07:28

################################################################################
                     [1m Learning iteration 1298/1500 [0m                     

                       Computation: 46129 steps/s (collection: 2.018s, learning 0.113s)
             Mean action noise std: 4.28
          Mean value_function loss: 84.8129
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 72.9796
                       Mean reward: 721.38
               Mean episode length: 243.87
    Episode_Reward/reaching_object: 1.1988
    Episode_Reward/rotating_object: 137.7898
        Episode_Reward/action_rate: -0.1110
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 2.13s
                      Time elapsed: 00:47:52
                               ETA: 00:07:26

################################################################################
                     [1m Learning iteration 1299/1500 [0m                     

                       Computation: 46098 steps/s (collection: 2.020s, learning 0.112s)
             Mean action noise std: 4.28
          Mean value_function loss: 103.2100
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 72.9958
                       Mean reward: 677.85
               Mean episode length: 233.22
    Episode_Reward/reaching_object: 1.1999
    Episode_Reward/rotating_object: 137.8400
        Episode_Reward/action_rate: -0.1108
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 2.13s
                      Time elapsed: 00:47:54
                               ETA: 00:07:24

################################################################################
                     [1m Learning iteration 1300/1500 [0m                     

                       Computation: 45545 steps/s (collection: 2.043s, learning 0.116s)
             Mean action noise std: 4.28
          Mean value_function loss: 80.9475
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 73.0073
                       Mean reward: 688.95
               Mean episode length: 235.86
    Episode_Reward/reaching_object: 1.1909
    Episode_Reward/rotating_object: 136.4886
        Episode_Reward/action_rate: -0.1113
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 2.16s
                      Time elapsed: 00:47:57
                               ETA: 00:07:22

################################################################################
                     [1m Learning iteration 1301/1500 [0m                     

                       Computation: 46335 steps/s (collection: 2.010s, learning 0.112s)
             Mean action noise std: 4.28
          Mean value_function loss: 90.3828
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 73.0186
                       Mean reward: 700.70
               Mean episode length: 237.60
    Episode_Reward/reaching_object: 1.1827
    Episode_Reward/rotating_object: 133.2561
        Episode_Reward/action_rate: -0.1105
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 2.12s
                      Time elapsed: 00:47:59
                               ETA: 00:07:20

################################################################################
                     [1m Learning iteration 1302/1500 [0m                     

                       Computation: 46754 steps/s (collection: 1.989s, learning 0.114s)
             Mean action noise std: 4.29
          Mean value_function loss: 85.3783
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 73.0333
                       Mean reward: 695.32
               Mean episode length: 239.43
    Episode_Reward/reaching_object: 1.2235
    Episode_Reward/rotating_object: 140.3668
        Episode_Reward/action_rate: -0.1137
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 2.10s
                      Time elapsed: 00:48:01
                               ETA: 00:07:17

################################################################################
                     [1m Learning iteration 1303/1500 [0m                     

                       Computation: 45778 steps/s (collection: 2.032s, learning 0.115s)
             Mean action noise std: 4.29
          Mean value_function loss: 79.1177
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 73.0506
                       Mean reward: 661.69
               Mean episode length: 237.43
    Episode_Reward/reaching_object: 1.1783
    Episode_Reward/rotating_object: 134.5757
        Episode_Reward/action_rate: -0.1108
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 2.15s
                      Time elapsed: 00:48:03
                               ETA: 00:07:15

################################################################################
                     [1m Learning iteration 1304/1500 [0m                     

                       Computation: 46951 steps/s (collection: 1.972s, learning 0.122s)
             Mean action noise std: 4.29
          Mean value_function loss: 83.1421
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 73.0731
                       Mean reward: 725.74
               Mean episode length: 242.16
    Episode_Reward/reaching_object: 1.2070
    Episode_Reward/rotating_object: 139.9593
        Episode_Reward/action_rate: -0.1126
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 2.09s
                      Time elapsed: 00:48:05
                               ETA: 00:07:13

################################################################################
                     [1m Learning iteration 1305/1500 [0m                     

                       Computation: 46695 steps/s (collection: 1.980s, learning 0.125s)
             Mean action noise std: 4.30
          Mean value_function loss: 74.5977
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 73.0988
                       Mean reward: 725.13
               Mean episode length: 241.61
    Episode_Reward/reaching_object: 1.2120
    Episode_Reward/rotating_object: 139.4786
        Episode_Reward/action_rate: -0.1139
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 2.11s
                      Time elapsed: 00:48:07
                               ETA: 00:07:11

################################################################################
                     [1m Learning iteration 1306/1500 [0m                     

                       Computation: 46641 steps/s (collection: 1.985s, learning 0.123s)
             Mean action noise std: 4.30
          Mean value_function loss: 81.5944
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 73.1207
                       Mean reward: 688.24
               Mean episode length: 235.31
    Episode_Reward/reaching_object: 1.1883
    Episode_Reward/rotating_object: 134.5569
        Episode_Reward/action_rate: -0.1116
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 2.11s
                      Time elapsed: 00:48:09
                               ETA: 00:07:08

################################################################################
                     [1m Learning iteration 1307/1500 [0m                     

                       Computation: 46447 steps/s (collection: 1.992s, learning 0.124s)
             Mean action noise std: 4.30
          Mean value_function loss: 92.0253
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 73.1337
                       Mean reward: 688.49
               Mean episode length: 238.50
    Episode_Reward/reaching_object: 1.1898
    Episode_Reward/rotating_object: 137.1713
        Episode_Reward/action_rate: -0.1119
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 2.12s
                      Time elapsed: 00:48:11
                               ETA: 00:07:06

################################################################################
                     [1m Learning iteration 1308/1500 [0m                     

                       Computation: 46933 steps/s (collection: 1.979s, learning 0.115s)
             Mean action noise std: 4.31
          Mean value_function loss: 80.1166
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 73.1516
                       Mean reward: 687.39
               Mean episode length: 235.83
    Episode_Reward/reaching_object: 1.1687
    Episode_Reward/rotating_object: 129.4038
        Episode_Reward/action_rate: -0.1101
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 2.09s
                      Time elapsed: 00:48:13
                               ETA: 00:07:04

################################################################################
                     [1m Learning iteration 1309/1500 [0m                     

                       Computation: 46348 steps/s (collection: 2.008s, learning 0.113s)
             Mean action noise std: 4.31
          Mean value_function loss: 85.3382
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 73.1691
                       Mean reward: 721.67
               Mean episode length: 241.97
    Episode_Reward/reaching_object: 1.2177
    Episode_Reward/rotating_object: 141.6631
        Episode_Reward/action_rate: -0.1146
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 2.12s
                      Time elapsed: 00:48:16
                               ETA: 00:07:02

################################################################################
                     [1m Learning iteration 1310/1500 [0m                     

                       Computation: 46212 steps/s (collection: 2.015s, learning 0.112s)
             Mean action noise std: 4.31
          Mean value_function loss: 90.7880
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 73.1855
                       Mean reward: 669.54
               Mean episode length: 235.02
    Episode_Reward/reaching_object: 1.1970
    Episode_Reward/rotating_object: 136.9776
        Episode_Reward/action_rate: -0.1130
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 2.13s
                      Time elapsed: 00:48:18
                               ETA: 00:07:00

################################################################################
                     [1m Learning iteration 1311/1500 [0m                     

                       Computation: 45610 steps/s (collection: 2.044s, learning 0.111s)
             Mean action noise std: 4.31
          Mean value_function loss: 88.2188
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 73.2009
                       Mean reward: 695.65
               Mean episode length: 234.62
    Episode_Reward/reaching_object: 1.1907
    Episode_Reward/rotating_object: 134.8725
        Episode_Reward/action_rate: -0.1123
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 2.16s
                      Time elapsed: 00:48:20
                               ETA: 00:06:57

################################################################################
                     [1m Learning iteration 1312/1500 [0m                     

                       Computation: 46779 steps/s (collection: 1.991s, learning 0.110s)
             Mean action noise std: 4.32
          Mean value_function loss: 97.1167
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 73.2171
                       Mean reward: 657.98
               Mean episode length: 228.93
    Episode_Reward/reaching_object: 1.1652
    Episode_Reward/rotating_object: 134.1473
        Episode_Reward/action_rate: -0.1100
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 2.10s
                      Time elapsed: 00:48:22
                               ETA: 00:06:55

################################################################################
                     [1m Learning iteration 1313/1500 [0m                     

                       Computation: 46189 steps/s (collection: 2.015s, learning 0.114s)
             Mean action noise std: 4.32
          Mean value_function loss: 88.3822
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 73.2302
                       Mean reward: 643.40
               Mean episode length: 233.14
    Episode_Reward/reaching_object: 1.1951
    Episode_Reward/rotating_object: 137.9512
        Episode_Reward/action_rate: -0.1128
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 2.13s
                      Time elapsed: 00:48:24
                               ETA: 00:06:53

################################################################################
                     [1m Learning iteration 1314/1500 [0m                     

                       Computation: 46679 steps/s (collection: 1.994s, learning 0.112s)
             Mean action noise std: 4.32
          Mean value_function loss: 87.2840
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 73.2386
                       Mean reward: 679.89
               Mean episode length: 234.25
    Episode_Reward/reaching_object: 1.1945
    Episode_Reward/rotating_object: 136.0040
        Episode_Reward/action_rate: -0.1127
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 2.11s
                      Time elapsed: 00:48:26
                               ETA: 00:06:51

################################################################################
                     [1m Learning iteration 1315/1500 [0m                     

                       Computation: 47185 steps/s (collection: 1.970s, learning 0.113s)
             Mean action noise std: 4.32
          Mean value_function loss: 71.2173
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 73.2542
                       Mean reward: 726.89
               Mean episode length: 243.03
    Episode_Reward/reaching_object: 1.2123
    Episode_Reward/rotating_object: 141.1145
        Episode_Reward/action_rate: -0.1146
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 2.08s
                      Time elapsed: 00:48:28
                               ETA: 00:06:48

################################################################################
                     [1m Learning iteration 1316/1500 [0m                     

                       Computation: 46811 steps/s (collection: 1.989s, learning 0.111s)
             Mean action noise std: 4.33
          Mean value_function loss: 79.2383
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 73.2700
                       Mean reward: 685.58
               Mean episode length: 235.18
    Episode_Reward/reaching_object: 1.1863
    Episode_Reward/rotating_object: 135.2086
        Episode_Reward/action_rate: -0.1127
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 2.10s
                      Time elapsed: 00:48:30
                               ETA: 00:06:46

################################################################################
                     [1m Learning iteration 1317/1500 [0m                     

                       Computation: 46973 steps/s (collection: 1.980s, learning 0.113s)
             Mean action noise std: 4.33
          Mean value_function loss: 84.0512
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 73.2852
                       Mean reward: 729.32
               Mean episode length: 247.43
    Episode_Reward/reaching_object: 1.2258
    Episode_Reward/rotating_object: 143.7872
        Episode_Reward/action_rate: -0.1160
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 2.09s
                      Time elapsed: 00:48:32
                               ETA: 00:06:44

################################################################################
                     [1m Learning iteration 1318/1500 [0m                     

                       Computation: 46636 steps/s (collection: 1.994s, learning 0.114s)
             Mean action noise std: 4.33
          Mean value_function loss: 89.6116
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 73.2958
                       Mean reward: 684.67
               Mean episode length: 232.06
    Episode_Reward/reaching_object: 1.1705
    Episode_Reward/rotating_object: 136.2405
        Episode_Reward/action_rate: -0.1114
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 2.11s
                      Time elapsed: 00:48:35
                               ETA: 00:06:42

################################################################################
                     [1m Learning iteration 1319/1500 [0m                     

                       Computation: 47000 steps/s (collection: 1.979s, learning 0.112s)
             Mean action noise std: 4.33
          Mean value_function loss: 94.1701
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 73.3076
                       Mean reward: 663.88
               Mean episode length: 220.33
    Episode_Reward/reaching_object: 1.1705
    Episode_Reward/rotating_object: 133.8518
        Episode_Reward/action_rate: -0.1122
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 2.09s
                      Time elapsed: 00:48:37
                               ETA: 00:06:40

################################################################################
                     [1m Learning iteration 1320/1500 [0m                     

                       Computation: 46651 steps/s (collection: 1.995s, learning 0.112s)
             Mean action noise std: 4.34
          Mean value_function loss: 86.4320
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 73.3284
                       Mean reward: 707.74
               Mean episode length: 237.30
    Episode_Reward/reaching_object: 1.1924
    Episode_Reward/rotating_object: 136.5077
        Episode_Reward/action_rate: -0.1145
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 2.11s
                      Time elapsed: 00:48:39
                               ETA: 00:06:37

################################################################################
                     [1m Learning iteration 1321/1500 [0m                     

                       Computation: 46513 steps/s (collection: 2.000s, learning 0.113s)
             Mean action noise std: 4.34
          Mean value_function loss: 74.7122
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 73.3482
                       Mean reward: 717.67
               Mean episode length: 241.76
    Episode_Reward/reaching_object: 1.2058
    Episode_Reward/rotating_object: 138.4767
        Episode_Reward/action_rate: -0.1151
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 2.11s
                      Time elapsed: 00:48:41
                               ETA: 00:06:35

################################################################################
                     [1m Learning iteration 1322/1500 [0m                     

                       Computation: 46275 steps/s (collection: 2.011s, learning 0.113s)
             Mean action noise std: 4.34
          Mean value_function loss: 89.1632
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 73.3641
                       Mean reward: 633.66
               Mean episode length: 233.63
    Episode_Reward/reaching_object: 1.1708
    Episode_Reward/rotating_object: 133.2698
        Episode_Reward/action_rate: -0.1122
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 2.12s
                      Time elapsed: 00:48:43
                               ETA: 00:06:33

################################################################################
                     [1m Learning iteration 1323/1500 [0m                     

                       Computation: 46589 steps/s (collection: 1.998s, learning 0.112s)
             Mean action noise std: 4.34
          Mean value_function loss: 107.1710
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 73.3759
                       Mean reward: 705.59
               Mean episode length: 233.75
    Episode_Reward/reaching_object: 1.1983
    Episode_Reward/rotating_object: 140.4977
        Episode_Reward/action_rate: -0.1147
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 2.11s
                      Time elapsed: 00:48:45
                               ETA: 00:06:31

################################################################################
                     [1m Learning iteration 1324/1500 [0m                     

                       Computation: 46080 steps/s (collection: 2.023s, learning 0.110s)
             Mean action noise std: 4.35
          Mean value_function loss: 76.5907
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 73.3920
                       Mean reward: 716.68
               Mean episode length: 239.05
    Episode_Reward/reaching_object: 1.2049
    Episode_Reward/rotating_object: 138.0659
        Episode_Reward/action_rate: -0.1162
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 2.13s
                      Time elapsed: 00:48:47
                               ETA: 00:06:28

################################################################################
                     [1m Learning iteration 1325/1500 [0m                     

                       Computation: 47707 steps/s (collection: 1.951s, learning 0.110s)
             Mean action noise std: 4.35
          Mean value_function loss: 88.6922
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 73.4138
                       Mean reward: 708.55
               Mean episode length: 233.12
    Episode_Reward/reaching_object: 1.1809
    Episode_Reward/rotating_object: 136.4679
        Episode_Reward/action_rate: -0.1137
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 2.06s
                      Time elapsed: 00:48:49
                               ETA: 00:06:26

################################################################################
                     [1m Learning iteration 1326/1500 [0m                     

                       Computation: 47115 steps/s (collection: 1.975s, learning 0.111s)
             Mean action noise std: 4.35
          Mean value_function loss: 76.7532
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 73.4340
                       Mean reward: 664.76
               Mean episode length: 231.49
    Episode_Reward/reaching_object: 1.1879
    Episode_Reward/rotating_object: 136.4237
        Episode_Reward/action_rate: -0.1142
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 2.09s
                      Time elapsed: 00:48:51
                               ETA: 00:06:24

################################################################################
                     [1m Learning iteration 1327/1500 [0m                     

                       Computation: 46920 steps/s (collection: 1.984s, learning 0.111s)
             Mean action noise std: 4.36
          Mean value_function loss: 80.3831
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 73.4532
                       Mean reward: 658.29
               Mean episode length: 230.69
    Episode_Reward/reaching_object: 1.1891
    Episode_Reward/rotating_object: 135.7210
        Episode_Reward/action_rate: -0.1143
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 2.10s
                      Time elapsed: 00:48:54
                               ETA: 00:06:22

################################################################################
                     [1m Learning iteration 1328/1500 [0m                     

                       Computation: 46062 steps/s (collection: 2.023s, learning 0.111s)
             Mean action noise std: 4.36
          Mean value_function loss: 64.4595
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 73.4653
                       Mean reward: 715.96
               Mean episode length: 245.23
    Episode_Reward/reaching_object: 1.2288
    Episode_Reward/rotating_object: 142.6924
        Episode_Reward/action_rate: -0.1177
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 2.13s
                      Time elapsed: 00:48:56
                               ETA: 00:06:19

################################################################################
                     [1m Learning iteration 1329/1500 [0m                     

                       Computation: 46147 steps/s (collection: 2.019s, learning 0.111s)
             Mean action noise std: 4.36
          Mean value_function loss: 91.3738
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 73.4763
                       Mean reward: 727.37
               Mean episode length: 239.53
    Episode_Reward/reaching_object: 1.1974
    Episode_Reward/rotating_object: 140.3015
        Episode_Reward/action_rate: -0.1153
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 2.13s
                      Time elapsed: 00:48:58
                               ETA: 00:06:17

################################################################################
                     [1m Learning iteration 1330/1500 [0m                     

                       Computation: 43674 steps/s (collection: 2.126s, learning 0.125s)
             Mean action noise std: 4.36
          Mean value_function loss: 84.5438
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 73.4883
                       Mean reward: 663.03
               Mean episode length: 225.58
    Episode_Reward/reaching_object: 1.1969
    Episode_Reward/rotating_object: 139.0413
        Episode_Reward/action_rate: -0.1157
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 2.25s
                      Time elapsed: 00:49:00
                               ETA: 00:06:15

################################################################################
                     [1m Learning iteration 1331/1500 [0m                     

                       Computation: 45304 steps/s (collection: 2.059s, learning 0.111s)
             Mean action noise std: 4.37
          Mean value_function loss: 73.6012
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 73.5045
                       Mean reward: 724.56
               Mean episode length: 243.85
    Episode_Reward/reaching_object: 1.2201
    Episode_Reward/rotating_object: 142.9727
        Episode_Reward/action_rate: -0.1177
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 2.17s
                      Time elapsed: 00:49:02
                               ETA: 00:06:13

################################################################################
                     [1m Learning iteration 1332/1500 [0m                     

                       Computation: 46316 steps/s (collection: 2.007s, learning 0.115s)
             Mean action noise std: 4.37
          Mean value_function loss: 93.0020
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 73.5167
                       Mean reward: 637.16
               Mean episode length: 232.86
    Episode_Reward/reaching_object: 1.1940
    Episode_Reward/rotating_object: 136.4792
        Episode_Reward/action_rate: -0.1160
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 2.12s
                      Time elapsed: 00:49:04
                               ETA: 00:06:11

################################################################################
                     [1m Learning iteration 1333/1500 [0m                     

                       Computation: 46713 steps/s (collection: 1.994s, learning 0.111s)
             Mean action noise std: 4.37
          Mean value_function loss: 82.6934
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 73.5298
                       Mean reward: 721.86
               Mean episode length: 237.02
    Episode_Reward/reaching_object: 1.2166
    Episode_Reward/rotating_object: 138.4738
        Episode_Reward/action_rate: -0.1181
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 2.10s
                      Time elapsed: 00:49:06
                               ETA: 00:06:08

################################################################################
                     [1m Learning iteration 1334/1500 [0m                     

                       Computation: 46352 steps/s (collection: 2.008s, learning 0.113s)
             Mean action noise std: 4.37
          Mean value_function loss: 101.3217
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 73.5362
                       Mean reward: 725.23
               Mean episode length: 238.80
    Episode_Reward/reaching_object: 1.1855
    Episode_Reward/rotating_object: 135.5451
        Episode_Reward/action_rate: -0.1160
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 2.12s
                      Time elapsed: 00:49:09
                               ETA: 00:06:06

################################################################################
                     [1m Learning iteration 1335/1500 [0m                     

                       Computation: 46575 steps/s (collection: 1.991s, learning 0.120s)
             Mean action noise std: 4.38
          Mean value_function loss: 75.3700
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 73.5486
                       Mean reward: 727.25
               Mean episode length: 232.59
    Episode_Reward/reaching_object: 1.1776
    Episode_Reward/rotating_object: 140.7157
        Episode_Reward/action_rate: -0.1145
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 2.11s
                      Time elapsed: 00:49:11
                               ETA: 00:06:04

################################################################################
                     [1m Learning iteration 1336/1500 [0m                     

                       Computation: 46457 steps/s (collection: 2.006s, learning 0.110s)
             Mean action noise std: 4.38
          Mean value_function loss: 76.1779
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 73.5652
                       Mean reward: 706.63
               Mean episode length: 237.03
    Episode_Reward/reaching_object: 1.1882
    Episode_Reward/rotating_object: 137.2667
        Episode_Reward/action_rate: -0.1158
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 2.12s
                      Time elapsed: 00:49:13
                               ETA: 00:06:02

################################################################################
                     [1m Learning iteration 1337/1500 [0m                     

                       Computation: 44657 steps/s (collection: 2.090s, learning 0.112s)
             Mean action noise std: 4.38
          Mean value_function loss: 80.7634
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 73.5821
                       Mean reward: 714.01
               Mean episode length: 237.74
    Episode_Reward/reaching_object: 1.2080
    Episode_Reward/rotating_object: 142.8371
        Episode_Reward/action_rate: -0.1179
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 2.20s
                      Time elapsed: 00:49:15
                               ETA: 00:06:00

################################################################################
                     [1m Learning iteration 1338/1500 [0m                     

                       Computation: 43952 steps/s (collection: 2.124s, learning 0.113s)
             Mean action noise std: 4.39
          Mean value_function loss: 76.3028
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 73.5993
                       Mean reward: 704.68
               Mean episode length: 232.69
    Episode_Reward/reaching_object: 1.1720
    Episode_Reward/rotating_object: 139.1165
        Episode_Reward/action_rate: -0.1159
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 2.24s
                      Time elapsed: 00:49:17
                               ETA: 00:05:57

################################################################################
                     [1m Learning iteration 1339/1500 [0m                     

                       Computation: 46374 steps/s (collection: 2.009s, learning 0.111s)
             Mean action noise std: 4.39
          Mean value_function loss: 91.0416
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 73.6121
                       Mean reward: 721.90
               Mean episode length: 241.28
    Episode_Reward/reaching_object: 1.1963
    Episode_Reward/rotating_object: 140.7165
        Episode_Reward/action_rate: -0.1173
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 2.12s
                      Time elapsed: 00:49:19
                               ETA: 00:05:55

################################################################################
                     [1m Learning iteration 1340/1500 [0m                     

                       Computation: 46599 steps/s (collection: 1.998s, learning 0.112s)
             Mean action noise std: 4.39
          Mean value_function loss: 82.4498
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 73.6265
                       Mean reward: 684.72
               Mean episode length: 227.02
    Episode_Reward/reaching_object: 1.1729
    Episode_Reward/rotating_object: 139.2820
        Episode_Reward/action_rate: -0.1160
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 2.11s
                      Time elapsed: 00:49:21
                               ETA: 00:05:53

################################################################################
                     [1m Learning iteration 1341/1500 [0m                     

                       Computation: 46292 steps/s (collection: 2.011s, learning 0.113s)
             Mean action noise std: 4.39
          Mean value_function loss: 71.0383
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 73.6424
                       Mean reward: 650.93
               Mean episode length: 235.23
    Episode_Reward/reaching_object: 1.1848
    Episode_Reward/rotating_object: 136.3761
        Episode_Reward/action_rate: -0.1177
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 2.12s
                      Time elapsed: 00:49:24
                               ETA: 00:05:51

################################################################################
                     [1m Learning iteration 1342/1500 [0m                     

                       Computation: 46923 steps/s (collection: 1.985s, learning 0.110s)
             Mean action noise std: 4.39
          Mean value_function loss: 96.8326
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 73.6545
                       Mean reward: 645.95
               Mean episode length: 224.83
    Episode_Reward/reaching_object: 1.1550
    Episode_Reward/rotating_object: 134.0251
        Episode_Reward/action_rate: -0.1158
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 2.10s
                      Time elapsed: 00:49:26
                               ETA: 00:05:48

################################################################################
                     [1m Learning iteration 1343/1500 [0m                     

                       Computation: 46136 steps/s (collection: 2.020s, learning 0.111s)
             Mean action noise std: 4.40
          Mean value_function loss: 91.0152
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 73.6681
                       Mean reward: 690.23
               Mean episode length: 227.74
    Episode_Reward/reaching_object: 1.1645
    Episode_Reward/rotating_object: 138.1652
        Episode_Reward/action_rate: -0.1166
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 2.13s
                      Time elapsed: 00:49:28
                               ETA: 00:05:46

################################################################################
                     [1m Learning iteration 1344/1500 [0m                     

                       Computation: 45831 steps/s (collection: 2.022s, learning 0.122s)
             Mean action noise std: 4.40
          Mean value_function loss: 93.4487
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 73.6822
                       Mean reward: 714.02
               Mean episode length: 235.87
    Episode_Reward/reaching_object: 1.1748
    Episode_Reward/rotating_object: 139.2005
        Episode_Reward/action_rate: -0.1177
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 2.14s
                      Time elapsed: 00:49:30
                               ETA: 00:05:44

################################################################################
                     [1m Learning iteration 1345/1500 [0m                     

                       Computation: 46446 steps/s (collection: 2.006s, learning 0.111s)
             Mean action noise std: 4.40
          Mean value_function loss: 82.9832
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 73.6970
                       Mean reward: 688.28
               Mean episode length: 231.44
    Episode_Reward/reaching_object: 1.1805
    Episode_Reward/rotating_object: 140.7054
        Episode_Reward/action_rate: -0.1184
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 2.12s
                      Time elapsed: 00:49:32
                               ETA: 00:05:42

################################################################################
                     [1m Learning iteration 1346/1500 [0m                     

                       Computation: 46593 steps/s (collection: 1.999s, learning 0.111s)
             Mean action noise std: 4.41
          Mean value_function loss: 74.3982
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 73.7173
                       Mean reward: 739.76
               Mean episode length: 237.67
    Episode_Reward/reaching_object: 1.1802
    Episode_Reward/rotating_object: 142.0353
        Episode_Reward/action_rate: -0.1187
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 2.11s
                      Time elapsed: 00:49:34
                               ETA: 00:05:40

################################################################################
                     [1m Learning iteration 1347/1500 [0m                     

                       Computation: 47075 steps/s (collection: 1.978s, learning 0.110s)
             Mean action noise std: 4.41
          Mean value_function loss: 91.0669
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 73.7330
                       Mean reward: 711.46
               Mean episode length: 235.92
    Episode_Reward/reaching_object: 1.1756
    Episode_Reward/rotating_object: 141.9058
        Episode_Reward/action_rate: -0.1184
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 2.09s
                      Time elapsed: 00:49:36
                               ETA: 00:05:37

################################################################################
                     [1m Learning iteration 1348/1500 [0m                     

                       Computation: 46966 steps/s (collection: 1.982s, learning 0.111s)
             Mean action noise std: 4.41
          Mean value_function loss: 74.4283
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 73.7481
                       Mean reward: 748.41
               Mean episode length: 244.89
    Episode_Reward/reaching_object: 1.1900
    Episode_Reward/rotating_object: 139.9385
        Episode_Reward/action_rate: -0.1200
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 2.09s
                      Time elapsed: 00:49:38
                               ETA: 00:05:35

################################################################################
                     [1m Learning iteration 1349/1500 [0m                     

                       Computation: 46511 steps/s (collection: 2.003s, learning 0.111s)
             Mean action noise std: 4.41
          Mean value_function loss: 67.1621
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 73.7618
                       Mean reward: 710.98
               Mean episode length: 235.78
    Episode_Reward/reaching_object: 1.1759
    Episode_Reward/rotating_object: 135.7882
        Episode_Reward/action_rate: -0.1192
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 2.11s
                      Time elapsed: 00:49:40
                               ETA: 00:05:33

################################################################################
                     [1m Learning iteration 1350/1500 [0m                     

                       Computation: 47136 steps/s (collection: 1.975s, learning 0.111s)
             Mean action noise std: 4.42
          Mean value_function loss: 74.5465
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 73.7781
                       Mean reward: 710.02
               Mean episode length: 235.62
    Episode_Reward/reaching_object: 1.1852
    Episode_Reward/rotating_object: 140.4826
        Episode_Reward/action_rate: -0.1196
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 2.09s
                      Time elapsed: 00:49:43
                               ETA: 00:05:31

################################################################################
                     [1m Learning iteration 1351/1500 [0m                     

                       Computation: 47054 steps/s (collection: 1.978s, learning 0.111s)
             Mean action noise std: 4.42
          Mean value_function loss: 75.9248
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 73.8001
                       Mean reward: 637.37
               Mean episode length: 233.24
    Episode_Reward/reaching_object: 1.1822
    Episode_Reward/rotating_object: 139.9938
        Episode_Reward/action_rate: -0.1200
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 2.09s
                      Time elapsed: 00:49:45
                               ETA: 00:05:28

################################################################################
                     [1m Learning iteration 1352/1500 [0m                     

                       Computation: 46947 steps/s (collection: 1.983s, learning 0.111s)
             Mean action noise std: 4.42
          Mean value_function loss: 86.5238
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 73.8127
                       Mean reward: 698.35
               Mean episode length: 236.31
    Episode_Reward/reaching_object: 1.1684
    Episode_Reward/rotating_object: 137.4327
        Episode_Reward/action_rate: -0.1191
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 2.09s
                      Time elapsed: 00:49:47
                               ETA: 00:05:26

################################################################################
                     [1m Learning iteration 1353/1500 [0m                     

                       Computation: 47378 steps/s (collection: 1.964s, learning 0.111s)
             Mean action noise std: 4.43
          Mean value_function loss: 71.8518
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 73.8296
                       Mean reward: 673.38
               Mean episode length: 238.16
    Episode_Reward/reaching_object: 1.1954
    Episode_Reward/rotating_object: 140.8569
        Episode_Reward/action_rate: -0.1215
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 2.07s
                      Time elapsed: 00:49:49
                               ETA: 00:05:24

################################################################################
                     [1m Learning iteration 1354/1500 [0m                     

                       Computation: 46644 steps/s (collection: 1.995s, learning 0.113s)
             Mean action noise std: 4.43
          Mean value_function loss: 90.6854
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 73.8498
                       Mean reward: 727.61
               Mean episode length: 244.09
    Episode_Reward/reaching_object: 1.1934
    Episode_Reward/rotating_object: 143.5778
        Episode_Reward/action_rate: -0.1212
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 2.11s
                      Time elapsed: 00:49:51
                               ETA: 00:05:22

################################################################################
                     [1m Learning iteration 1355/1500 [0m                     

                       Computation: 46699 steps/s (collection: 1.992s, learning 0.114s)
             Mean action noise std: 4.43
          Mean value_function loss: 64.3773
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 73.8720
                       Mean reward: 743.56
               Mean episode length: 240.45
    Episode_Reward/reaching_object: 1.1832
    Episode_Reward/rotating_object: 141.7887
        Episode_Reward/action_rate: -0.1206
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 2.11s
                      Time elapsed: 00:49:53
                               ETA: 00:05:20

################################################################################
                     [1m Learning iteration 1356/1500 [0m                     

                       Computation: 46597 steps/s (collection: 1.997s, learning 0.113s)
             Mean action noise std: 4.44
          Mean value_function loss: 68.7783
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 73.8880
                       Mean reward: 718.09
               Mean episode length: 237.32
    Episode_Reward/reaching_object: 1.1871
    Episode_Reward/rotating_object: 142.6965
        Episode_Reward/action_rate: -0.1211
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 2.11s
                      Time elapsed: 00:49:55
                               ETA: 00:05:17

################################################################################
                     [1m Learning iteration 1357/1500 [0m                     

                       Computation: 46718 steps/s (collection: 1.990s, learning 0.115s)
             Mean action noise std: 4.44
          Mean value_function loss: 82.7843
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 73.8996
                       Mean reward: 680.02
               Mean episode length: 232.40
    Episode_Reward/reaching_object: 1.1593
    Episode_Reward/rotating_object: 136.1111
        Episode_Reward/action_rate: -0.1196
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 2.10s
                      Time elapsed: 00:49:57
                               ETA: 00:05:15

################################################################################
                     [1m Learning iteration 1358/1500 [0m                     

                       Computation: 46861 steps/s (collection: 1.987s, learning 0.110s)
             Mean action noise std: 4.44
          Mean value_function loss: 68.4171
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 73.9104
                       Mean reward: 716.99
               Mean episode length: 235.82
    Episode_Reward/reaching_object: 1.1820
    Episode_Reward/rotating_object: 143.8832
        Episode_Reward/action_rate: -0.1214
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 2.10s
                      Time elapsed: 00:49:59
                               ETA: 00:05:13

################################################################################
                     [1m Learning iteration 1359/1500 [0m                     

                       Computation: 46729 steps/s (collection: 1.991s, learning 0.112s)
             Mean action noise std: 4.44
          Mean value_function loss: 77.6980
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 73.9296
                       Mean reward: 706.43
               Mean episode length: 235.81
    Episode_Reward/reaching_object: 1.1690
    Episode_Reward/rotating_object: 140.7700
        Episode_Reward/action_rate: -0.1202
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 2.10s
                      Time elapsed: 00:50:01
                               ETA: 00:05:11

################################################################################
                     [1m Learning iteration 1360/1500 [0m                     

                       Computation: 46127 steps/s (collection: 2.018s, learning 0.113s)
             Mean action noise std: 4.45
          Mean value_function loss: 65.5138
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 73.9443
                       Mean reward: 743.67
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 1.1930
    Episode_Reward/rotating_object: 143.5855
        Episode_Reward/action_rate: -0.1227
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 2.13s
                      Time elapsed: 00:50:04
                               ETA: 00:05:09

################################################################################
                     [1m Learning iteration 1361/1500 [0m                     

                       Computation: 46246 steps/s (collection: 2.012s, learning 0.114s)
             Mean action noise std: 4.45
          Mean value_function loss: 87.2296
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 73.9572
                       Mean reward: 645.87
               Mean episode length: 236.13
    Episode_Reward/reaching_object: 1.1563
    Episode_Reward/rotating_object: 133.6165
        Episode_Reward/action_rate: -0.1192
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 2.13s
                      Time elapsed: 00:50:06
                               ETA: 00:05:06

################################################################################
                     [1m Learning iteration 1362/1500 [0m                     

                       Computation: 46198 steps/s (collection: 2.015s, learning 0.113s)
             Mean action noise std: 4.45
          Mean value_function loss: 82.1013
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 73.9786
                       Mean reward: 719.81
               Mean episode length: 240.71
    Episode_Reward/reaching_object: 1.1615
    Episode_Reward/rotating_object: 138.3238
        Episode_Reward/action_rate: -0.1201
          Episode_Reward/joint_vel: -0.0353
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 2.13s
                      Time elapsed: 00:50:08
                               ETA: 00:05:04

################################################################################
                     [1m Learning iteration 1363/1500 [0m                     

                       Computation: 45087 steps/s (collection: 2.066s, learning 0.115s)
             Mean action noise std: 4.46
          Mean value_function loss: 94.5896
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 73.9998
                       Mean reward: 676.61
               Mean episode length: 235.29
    Episode_Reward/reaching_object: 1.1628
    Episode_Reward/rotating_object: 135.2487
        Episode_Reward/action_rate: -0.1202
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 2.18s
                      Time elapsed: 00:50:10
                               ETA: 00:05:02

################################################################################
                     [1m Learning iteration 1364/1500 [0m                     

                       Computation: 44686 steps/s (collection: 2.088s, learning 0.112s)
             Mean action noise std: 4.46
          Mean value_function loss: 71.3733
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 74.0212
                       Mean reward: 766.36
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 1.1781
    Episode_Reward/rotating_object: 140.0432
        Episode_Reward/action_rate: -0.1216
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 2.20s
                      Time elapsed: 00:50:12
                               ETA: 00:05:00

################################################################################
                     [1m Learning iteration 1365/1500 [0m                     

                       Computation: 44277 steps/s (collection: 2.106s, learning 0.114s)
             Mean action noise std: 4.46
          Mean value_function loss: 72.6487
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 74.0396
                       Mean reward: 729.40
               Mean episode length: 237.90
    Episode_Reward/reaching_object: 1.1943
    Episode_Reward/rotating_object: 141.6744
        Episode_Reward/action_rate: -0.1234
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 2.22s
                      Time elapsed: 00:50:14
                               ETA: 00:04:57

################################################################################
                     [1m Learning iteration 1366/1500 [0m                     

                       Computation: 43803 steps/s (collection: 2.129s, learning 0.115s)
             Mean action noise std: 4.47
          Mean value_function loss: 80.5968
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 74.0602
                       Mean reward: 669.71
               Mean episode length: 237.37
    Episode_Reward/reaching_object: 1.1804
    Episode_Reward/rotating_object: 141.9341
        Episode_Reward/action_rate: -0.1217
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 2.24s
                      Time elapsed: 00:50:17
                               ETA: 00:04:55

################################################################################
                     [1m Learning iteration 1367/1500 [0m                     

                       Computation: 44654 steps/s (collection: 2.088s, learning 0.113s)
             Mean action noise std: 4.47
          Mean value_function loss: 83.2420
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 74.0790
                       Mean reward: 677.91
               Mean episode length: 230.26
    Episode_Reward/reaching_object: 1.1667
    Episode_Reward/rotating_object: 139.6555
        Episode_Reward/action_rate: -0.1203
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 2.20s
                      Time elapsed: 00:50:19
                               ETA: 00:04:53

################################################################################
                     [1m Learning iteration 1368/1500 [0m                     

                       Computation: 46214 steps/s (collection: 2.014s, learning 0.114s)
             Mean action noise std: 4.47
          Mean value_function loss: 84.2455
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 74.0899
                       Mean reward: 727.08
               Mean episode length: 236.21
    Episode_Reward/reaching_object: 1.1681
    Episode_Reward/rotating_object: 135.6117
        Episode_Reward/action_rate: -0.1210
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 2.13s
                      Time elapsed: 00:50:21
                               ETA: 00:04:51

################################################################################
                     [1m Learning iteration 1369/1500 [0m                     

                       Computation: 46006 steps/s (collection: 2.024s, learning 0.113s)
             Mean action noise std: 4.47
          Mean value_function loss: 75.9978
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 74.1077
                       Mean reward: 693.40
               Mean episode length: 236.53
    Episode_Reward/reaching_object: 1.1821
    Episode_Reward/rotating_object: 139.0733
        Episode_Reward/action_rate: -0.1225
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 2.14s
                      Time elapsed: 00:50:23
                               ETA: 00:04:49

################################################################################
                     [1m Learning iteration 1370/1500 [0m                     

                       Computation: 47033 steps/s (collection: 1.979s, learning 0.111s)
             Mean action noise std: 4.48
          Mean value_function loss: 77.2909
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 74.1217
                       Mean reward: 692.84
               Mean episode length: 235.27
    Episode_Reward/reaching_object: 1.1642
    Episode_Reward/rotating_object: 136.7665
        Episode_Reward/action_rate: -0.1210
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 2.09s
                      Time elapsed: 00:50:25
                               ETA: 00:04:46

################################################################################
                     [1m Learning iteration 1371/1500 [0m                     

                       Computation: 47480 steps/s (collection: 1.960s, learning 0.110s)
             Mean action noise std: 4.48
          Mean value_function loss: 75.3078
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 74.1342
                       Mean reward: 707.65
               Mean episode length: 233.41
    Episode_Reward/reaching_object: 1.1579
    Episode_Reward/rotating_object: 134.4286
        Episode_Reward/action_rate: -0.1203
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 2.07s
                      Time elapsed: 00:50:27
                               ETA: 00:04:44

################################################################################
                     [1m Learning iteration 1372/1500 [0m                     

                       Computation: 47302 steps/s (collection: 1.968s, learning 0.110s)
             Mean action noise std: 4.48
          Mean value_function loss: 80.4772
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 74.1521
                       Mean reward: 693.92
               Mean episode length: 232.58
    Episode_Reward/reaching_object: 1.1750
    Episode_Reward/rotating_object: 140.2761
        Episode_Reward/action_rate: -0.1224
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 2.08s
                      Time elapsed: 00:50:29
                               ETA: 00:04:42

################################################################################
                     [1m Learning iteration 1373/1500 [0m                     

                       Computation: 47487 steps/s (collection: 1.960s, learning 0.110s)
             Mean action noise std: 4.49
          Mean value_function loss: 76.0790
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 74.1710
                       Mean reward: 704.73
               Mean episode length: 241.17
    Episode_Reward/reaching_object: 1.1790
    Episode_Reward/rotating_object: 138.2872
        Episode_Reward/action_rate: -0.1230
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 2.07s
                      Time elapsed: 00:50:31
                               ETA: 00:04:40

################################################################################
                     [1m Learning iteration 1374/1500 [0m                     

                       Computation: 47256 steps/s (collection: 1.970s, learning 0.110s)
             Mean action noise std: 4.49
          Mean value_function loss: 83.5871
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 74.1951
                       Mean reward: 730.01
               Mean episode length: 239.84
    Episode_Reward/reaching_object: 1.1831
    Episode_Reward/rotating_object: 143.0802
        Episode_Reward/action_rate: -0.1232
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 18.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 2.08s
                      Time elapsed: 00:50:34
                               ETA: 00:04:38

################################################################################
                     [1m Learning iteration 1375/1500 [0m                     

                       Computation: 47018 steps/s (collection: 1.980s, learning 0.111s)
             Mean action noise std: 4.49
          Mean value_function loss: 92.6989
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 74.2132
                       Mean reward: 683.53
               Mean episode length: 232.74
    Episode_Reward/reaching_object: 1.1634
    Episode_Reward/rotating_object: 138.2751
        Episode_Reward/action_rate: -0.1215
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 2.09s
                      Time elapsed: 00:50:36
                               ETA: 00:04:35

################################################################################
                     [1m Learning iteration 1376/1500 [0m                     

                       Computation: 46664 steps/s (collection: 1.995s, learning 0.111s)
             Mean action noise std: 4.50
          Mean value_function loss: 91.1448
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 74.2304
                       Mean reward: 704.32
               Mean episode length: 237.30
    Episode_Reward/reaching_object: 1.1720
    Episode_Reward/rotating_object: 137.0377
        Episode_Reward/action_rate: -0.1222
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 2.11s
                      Time elapsed: 00:50:38
                               ETA: 00:04:33

################################################################################
                     [1m Learning iteration 1377/1500 [0m                     

                       Computation: 46331 steps/s (collection: 2.009s, learning 0.112s)
             Mean action noise std: 4.50
          Mean value_function loss: 82.1096
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 74.2454
                       Mean reward: 706.63
               Mean episode length: 235.40
    Episode_Reward/reaching_object: 1.1718
    Episode_Reward/rotating_object: 138.1687
        Episode_Reward/action_rate: -0.1227
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 2.12s
                      Time elapsed: 00:50:40
                               ETA: 00:04:31

################################################################################
                     [1m Learning iteration 1378/1500 [0m                     

                       Computation: 46603 steps/s (collection: 1.996s, learning 0.113s)
             Mean action noise std: 4.50
          Mean value_function loss: 74.3660
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 74.2591
                       Mean reward: 647.70
               Mean episode length: 224.34
    Episode_Reward/reaching_object: 1.1716
    Episode_Reward/rotating_object: 139.8805
        Episode_Reward/action_rate: -0.1221
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 2.11s
                      Time elapsed: 00:50:42
                               ETA: 00:04:29

################################################################################
                     [1m Learning iteration 1379/1500 [0m                     

                       Computation: 46463 steps/s (collection: 2.004s, learning 0.112s)
             Mean action noise std: 4.51
          Mean value_function loss: 86.8709
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 74.2685
                       Mean reward: 736.59
               Mean episode length: 239.47
    Episode_Reward/reaching_object: 1.1791
    Episode_Reward/rotating_object: 141.8838
        Episode_Reward/action_rate: -0.1228
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 2.12s
                      Time elapsed: 00:50:44
                               ETA: 00:04:26

################################################################################
                     [1m Learning iteration 1380/1500 [0m                     

                       Computation: 46448 steps/s (collection: 2.006s, learning 0.110s)
             Mean action noise std: 4.51
          Mean value_function loss: 78.1585
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 74.2739
                       Mean reward: 701.99
               Mean episode length: 240.04
    Episode_Reward/reaching_object: 1.2066
    Episode_Reward/rotating_object: 143.6841
        Episode_Reward/action_rate: -0.1258
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 2.12s
                      Time elapsed: 00:50:46
                               ETA: 00:04:24

################################################################################
                     [1m Learning iteration 1381/1500 [0m                     

                       Computation: 46464 steps/s (collection: 2.005s, learning 0.111s)
             Mean action noise std: 4.51
          Mean value_function loss: 85.9150
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 74.2836
                       Mean reward: 671.84
               Mean episode length: 236.16
    Episode_Reward/reaching_object: 1.1657
    Episode_Reward/rotating_object: 138.1884
        Episode_Reward/action_rate: -0.1219
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 2.12s
                      Time elapsed: 00:50:48
                               ETA: 00:04:22

################################################################################
                     [1m Learning iteration 1382/1500 [0m                     

                       Computation: 46403 steps/s (collection: 2.004s, learning 0.114s)
             Mean action noise std: 4.51
          Mean value_function loss: 73.2303
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 74.2964
                       Mean reward: 739.39
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 1.2187
    Episode_Reward/rotating_object: 143.7004
        Episode_Reward/action_rate: -0.1269
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 2.12s
                      Time elapsed: 00:50:50
                               ETA: 00:04:20

################################################################################
                     [1m Learning iteration 1383/1500 [0m                     

                       Computation: 45693 steps/s (collection: 2.039s, learning 0.113s)
             Mean action noise std: 4.51
          Mean value_function loss: 86.4956
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 74.3068
                       Mean reward: 677.21
               Mean episode length: 232.11
    Episode_Reward/reaching_object: 1.1845
    Episode_Reward/rotating_object: 137.5323
        Episode_Reward/action_rate: -0.1240
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 2.15s
                      Time elapsed: 00:50:53
                               ETA: 00:04:18

################################################################################
                     [1m Learning iteration 1384/1500 [0m                     

                       Computation: 46143 steps/s (collection: 2.014s, learning 0.117s)
             Mean action noise std: 4.52
          Mean value_function loss: 76.9367
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 74.3186
                       Mean reward: 711.25
               Mean episode length: 233.85
    Episode_Reward/reaching_object: 1.2007
    Episode_Reward/rotating_object: 144.3789
        Episode_Reward/action_rate: -0.1248
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 2.13s
                      Time elapsed: 00:50:55
                               ETA: 00:04:15

################################################################################
                     [1m Learning iteration 1385/1500 [0m                     

                       Computation: 46086 steps/s (collection: 2.011s, learning 0.122s)
             Mean action noise std: 4.52
          Mean value_function loss: 85.1039
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 74.3342
                       Mean reward: 667.89
               Mean episode length: 230.09
    Episode_Reward/reaching_object: 1.1808
    Episode_Reward/rotating_object: 137.5248
        Episode_Reward/action_rate: -0.1234
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 2.13s
                      Time elapsed: 00:50:57
                               ETA: 00:04:13

################################################################################
                     [1m Learning iteration 1386/1500 [0m                     

                       Computation: 45708 steps/s (collection: 2.034s, learning 0.117s)
             Mean action noise std: 4.52
          Mean value_function loss: 65.6402
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 74.3491
                       Mean reward: 729.16
               Mean episode length: 242.61
    Episode_Reward/reaching_object: 1.2096
    Episode_Reward/rotating_object: 137.8678
        Episode_Reward/action_rate: -0.1262
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 2.15s
                      Time elapsed: 00:50:59
                               ETA: 00:04:11

################################################################################
                     [1m Learning iteration 1387/1500 [0m                     

                       Computation: 45881 steps/s (collection: 2.032s, learning 0.111s)
             Mean action noise std: 4.52
          Mean value_function loss: 83.2382
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 74.3606
                       Mean reward: 715.80
               Mean episode length: 235.21
    Episode_Reward/reaching_object: 1.1850
    Episode_Reward/rotating_object: 138.8490
        Episode_Reward/action_rate: -0.1234
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 2.14s
                      Time elapsed: 00:51:01
                               ETA: 00:04:09

################################################################################
                     [1m Learning iteration 1388/1500 [0m                     

                       Computation: 46575 steps/s (collection: 2.000s, learning 0.111s)
             Mean action noise std: 4.53
          Mean value_function loss: 73.6284
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 74.3791
                       Mean reward: 710.66
               Mean episode length: 239.38
    Episode_Reward/reaching_object: 1.2048
    Episode_Reward/rotating_object: 144.7953
        Episode_Reward/action_rate: -0.1252
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 2.11s
                      Time elapsed: 00:51:03
                               ETA: 00:04:07

################################################################################
                     [1m Learning iteration 1389/1500 [0m                     

                       Computation: 46218 steps/s (collection: 2.014s, learning 0.113s)
             Mean action noise std: 4.53
          Mean value_function loss: 66.7467
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 74.3976
                       Mean reward: 697.85
               Mean episode length: 238.95
    Episode_Reward/reaching_object: 1.2127
    Episode_Reward/rotating_object: 139.7579
        Episode_Reward/action_rate: -0.1271
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 2.13s
                      Time elapsed: 00:51:05
                               ETA: 00:04:04

################################################################################
                     [1m Learning iteration 1390/1500 [0m                     

                       Computation: 46591 steps/s (collection: 1.997s, learning 0.112s)
             Mean action noise std: 4.53
          Mean value_function loss: 84.8004
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 74.4085
                       Mean reward: 669.02
               Mean episode length: 227.83
    Episode_Reward/reaching_object: 1.2088
    Episode_Reward/rotating_object: 142.0395
        Episode_Reward/action_rate: -0.1261
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 2.11s
                      Time elapsed: 00:51:07
                               ETA: 00:04:02

################################################################################
                     [1m Learning iteration 1391/1500 [0m                     

                       Computation: 46099 steps/s (collection: 2.017s, learning 0.116s)
             Mean action noise std: 4.54
          Mean value_function loss: 77.6277
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 74.4216
                       Mean reward: 715.53
               Mean episode length: 236.40
    Episode_Reward/reaching_object: 1.1950
    Episode_Reward/rotating_object: 140.6418
        Episode_Reward/action_rate: -0.1254
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 2.13s
                      Time elapsed: 00:51:10
                               ETA: 00:04:00

################################################################################
                     [1m Learning iteration 1392/1500 [0m                     

                       Computation: 44792 steps/s (collection: 2.082s, learning 0.113s)
             Mean action noise std: 4.54
          Mean value_function loss: 78.2831
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 74.4392
                       Mean reward: 699.33
               Mean episode length: 238.20
    Episode_Reward/reaching_object: 1.1887
    Episode_Reward/rotating_object: 137.9319
        Episode_Reward/action_rate: -0.1246
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 2.19s
                      Time elapsed: 00:51:12
                               ETA: 00:03:58

################################################################################
                     [1m Learning iteration 1393/1500 [0m                     

                       Computation: 45524 steps/s (collection: 2.048s, learning 0.111s)
             Mean action noise std: 4.54
          Mean value_function loss: 80.0503
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 74.4562
                       Mean reward: 689.72
               Mean episode length: 233.58
    Episode_Reward/reaching_object: 1.1983
    Episode_Reward/rotating_object: 140.2937
        Episode_Reward/action_rate: -0.1265
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 2.16s
                      Time elapsed: 00:51:14
                               ETA: 00:03:55

################################################################################
                     [1m Learning iteration 1394/1500 [0m                     

                       Computation: 45104 steps/s (collection: 2.068s, learning 0.111s)
             Mean action noise std: 4.55
          Mean value_function loss: 89.7636
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 74.4710
                       Mean reward: 723.90
               Mean episode length: 234.99
    Episode_Reward/reaching_object: 1.1902
    Episode_Reward/rotating_object: 140.9516
        Episode_Reward/action_rate: -0.1256
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 2.18s
                      Time elapsed: 00:51:16
                               ETA: 00:03:53

################################################################################
                     [1m Learning iteration 1395/1500 [0m                     

                       Computation: 45100 steps/s (collection: 2.067s, learning 0.112s)
             Mean action noise std: 4.55
          Mean value_function loss: 80.9736
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 74.4883
                       Mean reward: 688.75
               Mean episode length: 239.74
    Episode_Reward/reaching_object: 1.1866
    Episode_Reward/rotating_object: 136.9424
        Episode_Reward/action_rate: -0.1250
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 2.18s
                      Time elapsed: 00:51:18
                               ETA: 00:03:51

################################################################################
                     [1m Learning iteration 1396/1500 [0m                     

                       Computation: 45808 steps/s (collection: 2.035s, learning 0.111s)
             Mean action noise std: 4.55
          Mean value_function loss: 76.5525
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 74.5053
                       Mean reward: 722.20
               Mean episode length: 236.24
    Episode_Reward/reaching_object: 1.2019
    Episode_Reward/rotating_object: 142.2886
        Episode_Reward/action_rate: -0.1271
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 2.15s
                      Time elapsed: 00:51:20
                               ETA: 00:03:49

################################################################################
                     [1m Learning iteration 1397/1500 [0m                     

                       Computation: 44675 steps/s (collection: 2.086s, learning 0.115s)
             Mean action noise std: 4.55
          Mean value_function loss: 85.3764
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 74.5230
                       Mean reward: 685.63
               Mean episode length: 234.93
    Episode_Reward/reaching_object: 1.1845
    Episode_Reward/rotating_object: 139.2827
        Episode_Reward/action_rate: -0.1256
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 2.20s
                      Time elapsed: 00:51:23
                               ETA: 00:03:47

################################################################################
                     [1m Learning iteration 1398/1500 [0m                     

                       Computation: 45308 steps/s (collection: 2.059s, learning 0.111s)
             Mean action noise std: 4.56
          Mean value_function loss: 87.9322
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 74.5376
                       Mean reward: 700.06
               Mean episode length: 232.05
    Episode_Reward/reaching_object: 1.1848
    Episode_Reward/rotating_object: 138.0627
        Episode_Reward/action_rate: -0.1248
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 2.17s
                      Time elapsed: 00:51:25
                               ETA: 00:03:44

################################################################################
                     [1m Learning iteration 1399/1500 [0m                     

                       Computation: 44994 steps/s (collection: 2.071s, learning 0.113s)
             Mean action noise std: 4.56
          Mean value_function loss: 76.5718
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 74.5508
                       Mean reward: 644.79
               Mean episode length: 224.39
    Episode_Reward/reaching_object: 1.1851
    Episode_Reward/rotating_object: 139.6225
        Episode_Reward/action_rate: -0.1254
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 2.18s
                      Time elapsed: 00:51:27
                               ETA: 00:03:42

################################################################################
                     [1m Learning iteration 1400/1500 [0m                     

                       Computation: 45014 steps/s (collection: 2.068s, learning 0.115s)
             Mean action noise std: 4.56
          Mean value_function loss: 80.5742
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 74.5662
                       Mean reward: 685.41
               Mean episode length: 228.31
    Episode_Reward/reaching_object: 1.1809
    Episode_Reward/rotating_object: 138.0794
        Episode_Reward/action_rate: -0.1256
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 2.18s
                      Time elapsed: 00:51:29
                               ETA: 00:03:40

################################################################################
                     [1m Learning iteration 1401/1500 [0m                     

                       Computation: 43914 steps/s (collection: 2.126s, learning 0.112s)
             Mean action noise std: 4.57
          Mean value_function loss: 77.0061
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 74.5830
                       Mean reward: 710.86
               Mean episode length: 234.59
    Episode_Reward/reaching_object: 1.1861
    Episode_Reward/rotating_object: 138.6094
        Episode_Reward/action_rate: -0.1265
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 2.24s
                      Time elapsed: 00:51:31
                               ETA: 00:03:38

################################################################################
                     [1m Learning iteration 1402/1500 [0m                     

                       Computation: 44733 steps/s (collection: 2.084s, learning 0.113s)
             Mean action noise std: 4.57
          Mean value_function loss: 60.4210
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 74.6019
                       Mean reward: 724.73
               Mean episode length: 238.71
    Episode_Reward/reaching_object: 1.2101
    Episode_Reward/rotating_object: 143.2758
        Episode_Reward/action_rate: -0.1287
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 2.20s
                      Time elapsed: 00:51:34
                               ETA: 00:03:36

################################################################################
                     [1m Learning iteration 1403/1500 [0m                     

                       Computation: 45321 steps/s (collection: 2.055s, learning 0.114s)
             Mean action noise std: 4.57
          Mean value_function loss: 86.0211
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 74.6155
                       Mean reward: 709.85
               Mean episode length: 234.70
    Episode_Reward/reaching_object: 1.2058
    Episode_Reward/rotating_object: 142.2576
        Episode_Reward/action_rate: -0.1281
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 2.17s
                      Time elapsed: 00:51:36
                               ETA: 00:03:33

################################################################################
                     [1m Learning iteration 1404/1500 [0m                     

                       Computation: 44662 steps/s (collection: 2.087s, learning 0.114s)
             Mean action noise std: 4.57
          Mean value_function loss: 57.9428
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 74.6231
                       Mean reward: 762.72
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 1.2032
    Episode_Reward/rotating_object: 141.4409
        Episode_Reward/action_rate: -0.1282
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 2.20s
                      Time elapsed: 00:51:38
                               ETA: 00:03:31

################################################################################
                     [1m Learning iteration 1405/1500 [0m                     

                       Computation: 44644 steps/s (collection: 2.087s, learning 0.115s)
             Mean action noise std: 4.58
          Mean value_function loss: 70.7113
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 74.6350
                       Mean reward: 737.29
               Mean episode length: 239.83
    Episode_Reward/reaching_object: 1.2174
    Episode_Reward/rotating_object: 143.8894
        Episode_Reward/action_rate: -0.1293
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 2.20s
                      Time elapsed: 00:51:40
                               ETA: 00:03:29

################################################################################
                     [1m Learning iteration 1406/1500 [0m                     

                       Computation: 44090 steps/s (collection: 2.097s, learning 0.132s)
             Mean action noise std: 4.58
          Mean value_function loss: 74.7000
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 74.6532
                       Mean reward: 676.04
               Mean episode length: 235.55
    Episode_Reward/reaching_object: 1.1985
    Episode_Reward/rotating_object: 142.0846
        Episode_Reward/action_rate: -0.1287
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 2.23s
                      Time elapsed: 00:51:42
                               ETA: 00:03:27

################################################################################
                     [1m Learning iteration 1407/1500 [0m                     

                       Computation: 44179 steps/s (collection: 2.110s, learning 0.115s)
             Mean action noise std: 4.58
          Mean value_function loss: 81.5659
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 74.6678
                       Mean reward: 713.16
               Mean episode length: 231.50
    Episode_Reward/reaching_object: 1.1870
    Episode_Reward/rotating_object: 140.7932
        Episode_Reward/action_rate: -0.1272
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 2.23s
                      Time elapsed: 00:51:45
                               ETA: 00:03:25

################################################################################
                     [1m Learning iteration 1408/1500 [0m                     

                       Computation: 44993 steps/s (collection: 2.071s, learning 0.114s)
             Mean action noise std: 4.58
          Mean value_function loss: 80.6178
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 74.6802
                       Mean reward: 713.26
               Mean episode length: 233.18
    Episode_Reward/reaching_object: 1.1918
    Episode_Reward/rotating_object: 141.2121
        Episode_Reward/action_rate: -0.1277
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 2.18s
                      Time elapsed: 00:51:47
                               ETA: 00:03:22

################################################################################
                     [1m Learning iteration 1409/1500 [0m                     

                       Computation: 44527 steps/s (collection: 2.090s, learning 0.118s)
             Mean action noise std: 4.59
          Mean value_function loss: 72.9083
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 74.6981
                       Mean reward: 723.87
               Mean episode length: 233.10
    Episode_Reward/reaching_object: 1.1788
    Episode_Reward/rotating_object: 142.2941
        Episode_Reward/action_rate: -0.1269
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 2.21s
                      Time elapsed: 00:51:49
                               ETA: 00:03:20

################################################################################
                     [1m Learning iteration 1410/1500 [0m                     

                       Computation: 45411 steps/s (collection: 2.050s, learning 0.114s)
             Mean action noise std: 4.59
          Mean value_function loss: 67.2955
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 74.7098
                       Mean reward: 691.85
               Mean episode length: 230.61
    Episode_Reward/reaching_object: 1.1978
    Episode_Reward/rotating_object: 142.0672
        Episode_Reward/action_rate: -0.1290
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 2.16s
                      Time elapsed: 00:51:51
                               ETA: 00:03:18

################################################################################
                     [1m Learning iteration 1411/1500 [0m                     

                       Computation: 44377 steps/s (collection: 2.087s, learning 0.128s)
             Mean action noise std: 4.59
          Mean value_function loss: 76.7986
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 74.7202
                       Mean reward: 724.55
               Mean episode length: 237.49
    Episode_Reward/reaching_object: 1.1921
    Episode_Reward/rotating_object: 142.6503
        Episode_Reward/action_rate: -0.1285
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 2.22s
                      Time elapsed: 00:51:53
                               ETA: 00:03:16

################################################################################
                     [1m Learning iteration 1412/1500 [0m                     

                       Computation: 44757 steps/s (collection: 2.069s, learning 0.127s)
             Mean action noise std: 4.59
          Mean value_function loss: 85.2179
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 74.7318
                       Mean reward: 695.40
               Mean episode length: 231.76
    Episode_Reward/reaching_object: 1.1886
    Episode_Reward/rotating_object: 139.4928
        Episode_Reward/action_rate: -0.1278
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 2.20s
                      Time elapsed: 00:51:56
                               ETA: 00:03:14

################################################################################
                     [1m Learning iteration 1413/1500 [0m                     

                       Computation: 44852 steps/s (collection: 2.075s, learning 0.117s)
             Mean action noise std: 4.60
          Mean value_function loss: 71.5120
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 74.7462
                       Mean reward: 707.86
               Mean episode length: 231.73
    Episode_Reward/reaching_object: 1.1945
    Episode_Reward/rotating_object: 143.5071
        Episode_Reward/action_rate: -0.1292
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 2.19s
                      Time elapsed: 00:51:58
                               ETA: 00:03:11

################################################################################
                     [1m Learning iteration 1414/1500 [0m                     

                       Computation: 44659 steps/s (collection: 2.066s, learning 0.135s)
             Mean action noise std: 4.60
          Mean value_function loss: 77.4137
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 74.7660
                       Mean reward: 715.96
               Mean episode length: 241.66
    Episode_Reward/reaching_object: 1.1978
    Episode_Reward/rotating_object: 140.0612
        Episode_Reward/action_rate: -0.1293
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 2.20s
                      Time elapsed: 00:52:00
                               ETA: 00:03:09

################################################################################
                     [1m Learning iteration 1415/1500 [0m                     

                       Computation: 46143 steps/s (collection: 2.019s, learning 0.111s)
             Mean action noise std: 4.60
          Mean value_function loss: 65.2942
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 74.7835
                       Mean reward: 742.94
               Mean episode length: 248.06
    Episode_Reward/reaching_object: 1.2285
    Episode_Reward/rotating_object: 144.9224
        Episode_Reward/action_rate: -0.1324
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 2.13s
                      Time elapsed: 00:52:02
                               ETA: 00:03:07

################################################################################
                     [1m Learning iteration 1416/1500 [0m                     

                       Computation: 44988 steps/s (collection: 2.073s, learning 0.112s)
             Mean action noise std: 4.61
          Mean value_function loss: 71.0757
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 74.7939
                       Mean reward: 709.89
               Mean episode length: 231.05
    Episode_Reward/reaching_object: 1.2043
    Episode_Reward/rotating_object: 143.5958
        Episode_Reward/action_rate: -0.1298
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 2.19s
                      Time elapsed: 00:52:04
                               ETA: 00:03:05

################################################################################
                     [1m Learning iteration 1417/1500 [0m                     

                       Computation: 45421 steps/s (collection: 2.052s, learning 0.112s)
             Mean action noise std: 4.61
          Mean value_function loss: 77.0547
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 74.8045
                       Mean reward: 678.41
               Mean episode length: 233.00
    Episode_Reward/reaching_object: 1.2009
    Episode_Reward/rotating_object: 140.8305
        Episode_Reward/action_rate: -0.1294
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 2.16s
                      Time elapsed: 00:52:07
                               ETA: 00:03:03

################################################################################
                     [1m Learning iteration 1418/1500 [0m                     

                       Computation: 44912 steps/s (collection: 2.075s, learning 0.113s)
             Mean action noise std: 4.61
          Mean value_function loss: 76.9334
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 74.8286
                       Mean reward: 697.52
               Mean episode length: 228.25
    Episode_Reward/reaching_object: 1.1922
    Episode_Reward/rotating_object: 142.7106
        Episode_Reward/action_rate: -0.1292
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 2.19s
                      Time elapsed: 00:52:09
                               ETA: 00:03:00

################################################################################
                     [1m Learning iteration 1419/1500 [0m                     

                       Computation: 45054 steps/s (collection: 2.054s, learning 0.128s)
             Mean action noise std: 4.62
          Mean value_function loss: 83.9453
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 74.8507
                       Mean reward: 745.05
               Mean episode length: 236.51
    Episode_Reward/reaching_object: 1.1837
    Episode_Reward/rotating_object: 141.7643
        Episode_Reward/action_rate: -0.1283
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 2.18s
                      Time elapsed: 00:52:11
                               ETA: 00:02:58

################################################################################
                     [1m Learning iteration 1420/1500 [0m                     

                       Computation: 45713 steps/s (collection: 2.039s, learning 0.112s)
             Mean action noise std: 4.62
          Mean value_function loss: 68.4456
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 74.8664
                       Mean reward: 702.79
               Mean episode length: 239.57
    Episode_Reward/reaching_object: 1.1967
    Episode_Reward/rotating_object: 142.7924
        Episode_Reward/action_rate: -0.1300
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 2.15s
                      Time elapsed: 00:52:13
                               ETA: 00:02:56

################################################################################
                     [1m Learning iteration 1421/1500 [0m                     

                       Computation: 45140 steps/s (collection: 2.065s, learning 0.112s)
             Mean action noise std: 4.62
          Mean value_function loss: 76.6383
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 74.8804
                       Mean reward: 715.92
               Mean episode length: 238.95
    Episode_Reward/reaching_object: 1.1937
    Episode_Reward/rotating_object: 139.7274
        Episode_Reward/action_rate: -0.1295
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 2.18s
                      Time elapsed: 00:52:15
                               ETA: 00:02:54

################################################################################
                     [1m Learning iteration 1422/1500 [0m                     

                       Computation: 45179 steps/s (collection: 2.064s, learning 0.112s)
             Mean action noise std: 4.62
          Mean value_function loss: 65.6214
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 74.8920
                       Mean reward: 710.82
               Mean episode length: 231.65
    Episode_Reward/reaching_object: 1.2034
    Episode_Reward/rotating_object: 144.1896
        Episode_Reward/action_rate: -0.1304
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 2.18s
                      Time elapsed: 00:52:17
                               ETA: 00:02:51

################################################################################
                     [1m Learning iteration 1423/1500 [0m                     

                       Computation: 44876 steps/s (collection: 2.079s, learning 0.112s)
             Mean action noise std: 4.63
          Mean value_function loss: 71.7038
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 74.9026
                       Mean reward: 722.32
               Mean episode length: 239.26
    Episode_Reward/reaching_object: 1.2103
    Episode_Reward/rotating_object: 141.2766
        Episode_Reward/action_rate: -0.1308
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 2.19s
                      Time elapsed: 00:52:20
                               ETA: 00:02:49

################################################################################
                     [1m Learning iteration 1424/1500 [0m                     

                       Computation: 44658 steps/s (collection: 2.086s, learning 0.115s)
             Mean action noise std: 4.63
          Mean value_function loss: 68.8249
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 74.9171
                       Mean reward: 715.32
               Mean episode length: 234.05
    Episode_Reward/reaching_object: 1.2018
    Episode_Reward/rotating_object: 137.6490
        Episode_Reward/action_rate: -0.1309
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 2.20s
                      Time elapsed: 00:52:22
                               ETA: 00:02:47

################################################################################
                     [1m Learning iteration 1425/1500 [0m                     

                       Computation: 45291 steps/s (collection: 2.060s, learning 0.111s)
             Mean action noise std: 4.63
          Mean value_function loss: 79.0370
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 74.9258
                       Mean reward: 737.90
               Mean episode length: 234.94
    Episode_Reward/reaching_object: 1.2216
    Episode_Reward/rotating_object: 141.9180
        Episode_Reward/action_rate: -0.1327
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 2.17s
                      Time elapsed: 00:52:24
                               ETA: 00:02:45

################################################################################
                     [1m Learning iteration 1426/1500 [0m                     

                       Computation: 45027 steps/s (collection: 2.072s, learning 0.111s)
             Mean action noise std: 4.63
          Mean value_function loss: 76.4410
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 74.9373
                       Mean reward: 723.69
               Mean episode length: 243.84
    Episode_Reward/reaching_object: 1.2237
    Episode_Reward/rotating_object: 143.9733
        Episode_Reward/action_rate: -0.1330
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 2.18s
                      Time elapsed: 00:52:26
                               ETA: 00:02:43

################################################################################
                     [1m Learning iteration 1427/1500 [0m                     

                       Computation: 45520 steps/s (collection: 2.044s, learning 0.115s)
             Mean action noise std: 4.64
          Mean value_function loss: 76.3999
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 74.9496
                       Mean reward: 728.65
               Mean episode length: 236.33
    Episode_Reward/reaching_object: 1.2055
    Episode_Reward/rotating_object: 145.7895
        Episode_Reward/action_rate: -0.1316
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 2.16s
                      Time elapsed: 00:52:28
                               ETA: 00:02:40

################################################################################
                     [1m Learning iteration 1428/1500 [0m                     

                       Computation: 45096 steps/s (collection: 2.069s, learning 0.111s)
             Mean action noise std: 4.64
          Mean value_function loss: 79.5401
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 74.9593
                       Mean reward: 664.64
               Mean episode length: 231.08
    Episode_Reward/reaching_object: 1.1751
    Episode_Reward/rotating_object: 135.3230
        Episode_Reward/action_rate: -0.1291
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 2.18s
                      Time elapsed: 00:52:30
                               ETA: 00:02:38

################################################################################
                     [1m Learning iteration 1429/1500 [0m                     

                       Computation: 45176 steps/s (collection: 2.061s, learning 0.115s)
             Mean action noise std: 4.64
          Mean value_function loss: 66.3379
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 74.9690
                       Mean reward: 717.37
               Mean episode length: 237.48
    Episode_Reward/reaching_object: 1.2142
    Episode_Reward/rotating_object: 144.7542
        Episode_Reward/action_rate: -0.1327
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 2.18s
                      Time elapsed: 00:52:33
                               ETA: 00:02:36

################################################################################
                     [1m Learning iteration 1430/1500 [0m                     

                       Computation: 45574 steps/s (collection: 2.034s, learning 0.123s)
             Mean action noise std: 4.64
          Mean value_function loss: 92.1470
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 74.9798
                       Mean reward: 756.79
               Mean episode length: 237.85
    Episode_Reward/reaching_object: 1.1965
    Episode_Reward/rotating_object: 143.2781
        Episode_Reward/action_rate: -0.1306
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 2.16s
                      Time elapsed: 00:52:35
                               ETA: 00:02:34

################################################################################
                     [1m Learning iteration 1431/1500 [0m                     

                       Computation: 44714 steps/s (collection: 2.085s, learning 0.113s)
             Mean action noise std: 4.65
          Mean value_function loss: 72.5334
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 74.9907
                       Mean reward: 716.25
               Mean episode length: 242.47
    Episode_Reward/reaching_object: 1.1951
    Episode_Reward/rotating_object: 137.7351
        Episode_Reward/action_rate: -0.1313
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 2.20s
                      Time elapsed: 00:52:37
                               ETA: 00:02:32

################################################################################
                     [1m Learning iteration 1432/1500 [0m                     

                       Computation: 45033 steps/s (collection: 2.057s, learning 0.126s)
             Mean action noise std: 4.65
          Mean value_function loss: 83.8884
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 75.0030
                       Mean reward: 710.14
               Mean episode length: 234.46
    Episode_Reward/reaching_object: 1.1833
    Episode_Reward/rotating_object: 140.2038
        Episode_Reward/action_rate: -0.1296
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 2.18s
                      Time elapsed: 00:52:39
                               ETA: 00:02:29

################################################################################
                     [1m Learning iteration 1433/1500 [0m                     

                       Computation: 44479 steps/s (collection: 2.098s, learning 0.112s)
             Mean action noise std: 4.65
          Mean value_function loss: 79.6164
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 75.0201
                       Mean reward: 744.90
               Mean episode length: 242.43
    Episode_Reward/reaching_object: 1.2036
    Episode_Reward/rotating_object: 141.6280
        Episode_Reward/action_rate: -0.1324
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 2.21s
                      Time elapsed: 00:52:41
                               ETA: 00:02:27

################################################################################
                     [1m Learning iteration 1434/1500 [0m                     

                       Computation: 45316 steps/s (collection: 2.042s, learning 0.128s)
             Mean action noise std: 4.65
          Mean value_function loss: 86.4572
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 75.0351
                       Mean reward: 703.95
               Mean episode length: 231.99
    Episode_Reward/reaching_object: 1.2082
    Episode_Reward/rotating_object: 145.3410
        Episode_Reward/action_rate: -0.1328
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 2.17s
                      Time elapsed: 00:52:44
                               ETA: 00:02:25

################################################################################
                     [1m Learning iteration 1435/1500 [0m                     

                       Computation: 44857 steps/s (collection: 2.073s, learning 0.118s)
             Mean action noise std: 4.66
          Mean value_function loss: 61.9219
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 75.0451
                       Mean reward: 704.18
               Mean episode length: 234.94
    Episode_Reward/reaching_object: 1.2140
    Episode_Reward/rotating_object: 143.9245
        Episode_Reward/action_rate: -0.1331
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 2.19s
                      Time elapsed: 00:52:46
                               ETA: 00:02:23

################################################################################
                     [1m Learning iteration 1436/1500 [0m                     

                       Computation: 44804 steps/s (collection: 2.074s, learning 0.120s)
             Mean action noise std: 4.66
          Mean value_function loss: 82.7585
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 75.0565
                       Mean reward: 718.70
               Mean episode length: 235.57
    Episode_Reward/reaching_object: 1.2078
    Episode_Reward/rotating_object: 142.8099
        Episode_Reward/action_rate: -0.1326
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 2.19s
                      Time elapsed: 00:52:48
                               ETA: 00:02:21

################################################################################
                     [1m Learning iteration 1437/1500 [0m                     

                       Computation: 45321 steps/s (collection: 2.057s, learning 0.112s)
             Mean action noise std: 4.66
          Mean value_function loss: 86.7124
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 75.0708
                       Mean reward: 693.36
               Mean episode length: 226.60
    Episode_Reward/reaching_object: 1.1752
    Episode_Reward/rotating_object: 139.7479
        Episode_Reward/action_rate: -0.1289
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 2.17s
                      Time elapsed: 00:52:50
                               ETA: 00:02:18

################################################################################
                     [1m Learning iteration 1438/1500 [0m                     

                       Computation: 45320 steps/s (collection: 2.058s, learning 0.111s)
             Mean action noise std: 4.66
          Mean value_function loss: 74.4811
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 75.0823
                       Mean reward: 748.91
               Mean episode length: 239.85
    Episode_Reward/reaching_object: 1.2084
    Episode_Reward/rotating_object: 142.0136
        Episode_Reward/action_rate: -0.1330
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 2.17s
                      Time elapsed: 00:52:52
                               ETA: 00:02:16

################################################################################
                     [1m Learning iteration 1439/1500 [0m                     

                       Computation: 46240 steps/s (collection: 2.015s, learning 0.111s)
             Mean action noise std: 4.66
          Mean value_function loss: 76.4250
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 75.0943
                       Mean reward: 740.72
               Mean episode length: 239.54
    Episode_Reward/reaching_object: 1.1897
    Episode_Reward/rotating_object: 139.7280
        Episode_Reward/action_rate: -0.1311
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 2.13s
                      Time elapsed: 00:52:54
                               ETA: 00:02:14

################################################################################
                     [1m Learning iteration 1440/1500 [0m                     

                       Computation: 45430 steps/s (collection: 2.052s, learning 0.111s)
             Mean action noise std: 4.67
          Mean value_function loss: 64.3212
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 75.1039
                       Mean reward: 752.10
               Mean episode length: 246.11
    Episode_Reward/reaching_object: 1.2024
    Episode_Reward/rotating_object: 142.6446
        Episode_Reward/action_rate: -0.1325
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 2.16s
                      Time elapsed: 00:52:57
                               ETA: 00:02:12

################################################################################
                     [1m Learning iteration 1441/1500 [0m                     

                       Computation: 46152 steps/s (collection: 2.017s, learning 0.113s)
             Mean action noise std: 4.67
          Mean value_function loss: 77.5349
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 75.1170
                       Mean reward: 713.61
               Mean episode length: 235.02
    Episode_Reward/reaching_object: 1.2103
    Episode_Reward/rotating_object: 143.3498
        Episode_Reward/action_rate: -0.1333
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 2.13s
                      Time elapsed: 00:52:59
                               ETA: 00:02:10

################################################################################
                     [1m Learning iteration 1442/1500 [0m                     

                       Computation: 44599 steps/s (collection: 2.088s, learning 0.116s)
             Mean action noise std: 4.67
          Mean value_function loss: 71.9438
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 75.1334
                       Mean reward: 693.41
               Mean episode length: 231.30
    Episode_Reward/reaching_object: 1.2155
    Episode_Reward/rotating_object: 144.0634
        Episode_Reward/action_rate: -0.1341
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 2.20s
                      Time elapsed: 00:53:01
                               ETA: 00:02:07

################################################################################
                     [1m Learning iteration 1443/1500 [0m                     

                       Computation: 44854 steps/s (collection: 2.081s, learning 0.111s)
             Mean action noise std: 4.67
          Mean value_function loss: 77.0962
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 75.1531
                       Mean reward: 713.55
               Mean episode length: 242.75
    Episode_Reward/reaching_object: 1.2066
    Episode_Reward/rotating_object: 139.5353
        Episode_Reward/action_rate: -0.1336
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 2.19s
                      Time elapsed: 00:53:03
                               ETA: 00:02:05

################################################################################
                     [1m Learning iteration 1444/1500 [0m                     

                       Computation: 45309 steps/s (collection: 2.043s, learning 0.126s)
             Mean action noise std: 4.68
          Mean value_function loss: 82.4843
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 75.1655
                       Mean reward: 725.45
               Mean episode length: 233.13
    Episode_Reward/reaching_object: 1.2037
    Episode_Reward/rotating_object: 142.6128
        Episode_Reward/action_rate: -0.1335
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 2.17s
                      Time elapsed: 00:53:05
                               ETA: 00:02:03

################################################################################
                     [1m Learning iteration 1445/1500 [0m                     

                       Computation: 41674 steps/s (collection: 2.227s, learning 0.132s)
             Mean action noise std: 4.68
          Mean value_function loss: 72.2890
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 75.1787
                       Mean reward: 688.50
               Mean episode length: 227.42
    Episode_Reward/reaching_object: 1.1812
    Episode_Reward/rotating_object: 140.9006
        Episode_Reward/action_rate: -0.1320
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 2.36s
                      Time elapsed: 00:53:08
                               ETA: 00:02:01

################################################################################
                     [1m Learning iteration 1446/1500 [0m                     

                       Computation: 45579 steps/s (collection: 2.041s, learning 0.116s)
             Mean action noise std: 4.68
          Mean value_function loss: 81.6708
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 75.1911
                       Mean reward: 697.98
               Mean episode length: 229.73
    Episode_Reward/reaching_object: 1.1913
    Episode_Reward/rotating_object: 142.1566
        Episode_Reward/action_rate: -0.1325
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 2.16s
                      Time elapsed: 00:53:10
                               ETA: 00:01:59

################################################################################
                     [1m Learning iteration 1447/1500 [0m                     

                       Computation: 45460 steps/s (collection: 2.048s, learning 0.115s)
             Mean action noise std: 4.68
          Mean value_function loss: 66.9224
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 75.1982
                       Mean reward: 719.27
               Mean episode length: 237.99
    Episode_Reward/reaching_object: 1.2008
    Episode_Reward/rotating_object: 145.2594
        Episode_Reward/action_rate: -0.1342
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 2.16s
                      Time elapsed: 00:53:12
                               ETA: 00:01:56

################################################################################
                     [1m Learning iteration 1448/1500 [0m                     

                       Computation: 44337 steps/s (collection: 2.085s, learning 0.132s)
             Mean action noise std: 4.69
          Mean value_function loss: 64.5511
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 75.2127
                       Mean reward: 726.61
               Mean episode length: 241.70
    Episode_Reward/reaching_object: 1.1921
    Episode_Reward/rotating_object: 143.0728
        Episode_Reward/action_rate: -0.1337
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 2.22s
                      Time elapsed: 00:53:14
                               ETA: 00:01:54

################################################################################
                     [1m Learning iteration 1449/1500 [0m                     

                       Computation: 45619 steps/s (collection: 2.044s, learning 0.111s)
             Mean action noise std: 4.69
          Mean value_function loss: 66.6630
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 75.2294
                       Mean reward: 718.67
               Mean episode length: 239.59
    Episode_Reward/reaching_object: 1.1913
    Episode_Reward/rotating_object: 141.7663
        Episode_Reward/action_rate: -0.1340
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 2.15s
                      Time elapsed: 00:53:16
                               ETA: 00:01:52

################################################################################
                     [1m Learning iteration 1450/1500 [0m                     

                       Computation: 45016 steps/s (collection: 2.059s, learning 0.125s)
             Mean action noise std: 4.69
          Mean value_function loss: 56.3221
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 75.2401
                       Mean reward: 760.37
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 1.2129
    Episode_Reward/rotating_object: 145.2604
        Episode_Reward/action_rate: -0.1364
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 2.18s
                      Time elapsed: 00:53:19
                               ETA: 00:01:50

################################################################################
                     [1m Learning iteration 1451/1500 [0m                     

                       Computation: 46074 steps/s (collection: 2.022s, learning 0.112s)
             Mean action noise std: 4.69
          Mean value_function loss: 59.8677
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 75.2512
                       Mean reward: 692.11
               Mean episode length: 234.29
    Episode_Reward/reaching_object: 1.2063
    Episode_Reward/rotating_object: 142.9505
        Episode_Reward/action_rate: -0.1355
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 2.13s
                      Time elapsed: 00:53:21
                               ETA: 00:01:48

################################################################################
                     [1m Learning iteration 1452/1500 [0m                     

                       Computation: 45346 steps/s (collection: 2.057s, learning 0.111s)
             Mean action noise std: 4.69
          Mean value_function loss: 71.7697
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 75.2681
                       Mean reward: 706.62
               Mean episode length: 243.16
    Episode_Reward/reaching_object: 1.2004
    Episode_Reward/rotating_object: 142.4208
        Episode_Reward/action_rate: -0.1353
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 2.17s
                      Time elapsed: 00:53:23
                               ETA: 00:01:45

################################################################################
                     [1m Learning iteration 1453/1500 [0m                     

                       Computation: 45623 steps/s (collection: 2.040s, learning 0.115s)
             Mean action noise std: 4.70
          Mean value_function loss: 60.0278
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 75.2788
                       Mean reward: 692.97
               Mean episode length: 235.47
    Episode_Reward/reaching_object: 1.1870
    Episode_Reward/rotating_object: 142.3647
        Episode_Reward/action_rate: -0.1339
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 2.15s
                      Time elapsed: 00:53:25
                               ETA: 00:01:43

################################################################################
                     [1m Learning iteration 1454/1500 [0m                     

                       Computation: 45099 steps/s (collection: 2.066s, learning 0.114s)
             Mean action noise std: 4.70
          Mean value_function loss: 64.8089
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 75.2885
                       Mean reward: 702.25
               Mean episode length: 239.90
    Episode_Reward/reaching_object: 1.2104
    Episode_Reward/rotating_object: 143.5850
        Episode_Reward/action_rate: -0.1374
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 2.18s
                      Time elapsed: 00:53:27
                               ETA: 00:01:41

################################################################################
                     [1m Learning iteration 1455/1500 [0m                     

                       Computation: 44854 steps/s (collection: 2.077s, learning 0.114s)
             Mean action noise std: 4.70
          Mean value_function loss: 64.9106
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 75.3013
                       Mean reward: 718.29
               Mean episode length: 243.99
    Episode_Reward/reaching_object: 1.2204
    Episode_Reward/rotating_object: 148.4401
        Episode_Reward/action_rate: -0.1374
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 2.19s
                      Time elapsed: 00:53:29
                               ETA: 00:01:39

################################################################################
                     [1m Learning iteration 1456/1500 [0m                     

                       Computation: 46046 steps/s (collection: 2.001s, learning 0.134s)
             Mean action noise std: 4.70
          Mean value_function loss: 65.8681
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 75.3151
                       Mean reward: 721.61
               Mean episode length: 235.58
    Episode_Reward/reaching_object: 1.2037
    Episode_Reward/rotating_object: 144.4870
        Episode_Reward/action_rate: -0.1361
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 2.13s
                      Time elapsed: 00:53:31
                               ETA: 00:01:36

################################################################################
                     [1m Learning iteration 1457/1500 [0m                     

                       Computation: 45092 steps/s (collection: 2.067s, learning 0.113s)
             Mean action noise std: 4.71
          Mean value_function loss: 85.3180
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 75.3346
                       Mean reward: 733.69
               Mean episode length: 231.62
    Episode_Reward/reaching_object: 1.1979
    Episode_Reward/rotating_object: 147.9979
        Episode_Reward/action_rate: -0.1352
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 2.18s
                      Time elapsed: 00:53:34
                               ETA: 00:01:34

################################################################################
                     [1m Learning iteration 1458/1500 [0m                     

                       Computation: 46085 steps/s (collection: 2.019s, learning 0.114s)
             Mean action noise std: 4.71
          Mean value_function loss: 66.8099
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 75.3541
                       Mean reward: 701.11
               Mean episode length: 234.06
    Episode_Reward/reaching_object: 1.1817
    Episode_Reward/rotating_object: 142.5306
        Episode_Reward/action_rate: -0.1344
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 2.13s
                      Time elapsed: 00:53:36
                               ETA: 00:01:32

################################################################################
                     [1m Learning iteration 1459/1500 [0m                     

                       Computation: 46154 steps/s (collection: 2.019s, learning 0.110s)
             Mean action noise std: 4.71
          Mean value_function loss: 64.5660
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 75.3674
                       Mean reward: 739.26
               Mean episode length: 242.01
    Episode_Reward/reaching_object: 1.1991
    Episode_Reward/rotating_object: 147.6341
        Episode_Reward/action_rate: -0.1365
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 2.13s
                      Time elapsed: 00:53:38
                               ETA: 00:01:30

################################################################################
                     [1m Learning iteration 1460/1500 [0m                     

                       Computation: 46556 steps/s (collection: 2.000s, learning 0.111s)
             Mean action noise std: 4.72
          Mean value_function loss: 73.1120
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 75.3872
                       Mean reward: 790.11
               Mean episode length: 248.48
    Episode_Reward/reaching_object: 1.1823
    Episode_Reward/rotating_object: 144.5638
        Episode_Reward/action_rate: -0.1352
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 2.11s
                      Time elapsed: 00:53:40
                               ETA: 00:01:28

################################################################################
                     [1m Learning iteration 1461/1500 [0m                     

                       Computation: 47243 steps/s (collection: 1.971s, learning 0.110s)
             Mean action noise std: 4.72
          Mean value_function loss: 69.3198
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 75.4028
                       Mean reward: 750.77
               Mean episode length: 239.04
    Episode_Reward/reaching_object: 1.2052
    Episode_Reward/rotating_object: 145.4467
        Episode_Reward/action_rate: -0.1378
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 2.08s
                      Time elapsed: 00:53:42
                               ETA: 00:01:25

################################################################################
                     [1m Learning iteration 1462/1500 [0m                     

                       Computation: 46403 steps/s (collection: 2.008s, learning 0.110s)
             Mean action noise std: 4.72
          Mean value_function loss: 59.5728
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 75.4128
                       Mean reward: 748.09
               Mean episode length: 234.39
    Episode_Reward/reaching_object: 1.1998
    Episode_Reward/rotating_object: 148.8242
        Episode_Reward/action_rate: -0.1375
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 2.12s
                      Time elapsed: 00:53:44
                               ETA: 00:01:23

################################################################################
                     [1m Learning iteration 1463/1500 [0m                     

                       Computation: 47024 steps/s (collection: 1.977s, learning 0.114s)
             Mean action noise std: 4.73
          Mean value_function loss: 78.8435
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 75.4277
                       Mean reward: 712.31
               Mean episode length: 230.08
    Episode_Reward/reaching_object: 1.1794
    Episode_Reward/rotating_object: 142.4262
        Episode_Reward/action_rate: -0.1364
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 2.09s
                      Time elapsed: 00:53:46
                               ETA: 00:01:21

################################################################################
                     [1m Learning iteration 1464/1500 [0m                     

                       Computation: 45497 steps/s (collection: 2.047s, learning 0.113s)
             Mean action noise std: 4.73
          Mean value_function loss: 70.1036
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 75.4472
                       Mean reward: 697.66
               Mean episode length: 236.93
    Episode_Reward/reaching_object: 1.1777
    Episode_Reward/rotating_object: 143.1607
        Episode_Reward/action_rate: -0.1367
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 2.16s
                      Time elapsed: 00:53:48
                               ETA: 00:01:19

################################################################################
                     [1m Learning iteration 1465/1500 [0m                     

                       Computation: 46498 steps/s (collection: 2.002s, learning 0.112s)
             Mean action noise std: 4.73
          Mean value_function loss: 75.5427
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 75.4611
                       Mean reward: 743.57
               Mean episode length: 237.23
    Episode_Reward/reaching_object: 1.1868
    Episode_Reward/rotating_object: 145.2981
        Episode_Reward/action_rate: -0.1375
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 2.11s
                      Time elapsed: 00:53:51
                               ETA: 00:01:17

################################################################################
                     [1m Learning iteration 1466/1500 [0m                     

                       Computation: 45809 steps/s (collection: 2.033s, learning 0.113s)
             Mean action noise std: 4.73
          Mean value_function loss: 69.1869
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 75.4738
                       Mean reward: 749.57
               Mean episode length: 245.85
    Episode_Reward/reaching_object: 1.1977
    Episode_Reward/rotating_object: 145.1962
        Episode_Reward/action_rate: -0.1384
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 2.15s
                      Time elapsed: 00:53:53
                               ETA: 00:01:14

################################################################################
                     [1m Learning iteration 1467/1500 [0m                     

                       Computation: 45158 steps/s (collection: 2.066s, learning 0.111s)
             Mean action noise std: 4.74
          Mean value_function loss: 68.6064
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 75.4863
                       Mean reward: 705.20
               Mean episode length: 235.41
    Episode_Reward/reaching_object: 1.1779
    Episode_Reward/rotating_object: 139.5559
        Episode_Reward/action_rate: -0.1364
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 2.18s
                      Time elapsed: 00:53:55
                               ETA: 00:01:12

################################################################################
                     [1m Learning iteration 1468/1500 [0m                     

                       Computation: 46149 steps/s (collection: 2.016s, learning 0.114s)
             Mean action noise std: 4.74
          Mean value_function loss: 77.4668
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 75.5000
                       Mean reward: 690.44
               Mean episode length: 230.93
    Episode_Reward/reaching_object: 1.1785
    Episode_Reward/rotating_object: 141.5992
        Episode_Reward/action_rate: -0.1365
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 2.13s
                      Time elapsed: 00:53:57
                               ETA: 00:01:10

################################################################################
                     [1m Learning iteration 1469/1500 [0m                     

                       Computation: 45532 steps/s (collection: 2.044s, learning 0.115s)
             Mean action noise std: 4.74
          Mean value_function loss: 79.9710
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 75.5106
                       Mean reward: 733.29
               Mean episode length: 237.52
    Episode_Reward/reaching_object: 1.1850
    Episode_Reward/rotating_object: 143.3497
        Episode_Reward/action_rate: -0.1375
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 2.16s
                      Time elapsed: 00:53:59
                               ETA: 00:01:08

################################################################################
                     [1m Learning iteration 1470/1500 [0m                     

                       Computation: 42272 steps/s (collection: 2.197s, learning 0.128s)
             Mean action noise std: 4.74
          Mean value_function loss: 69.8664
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 75.5217
                       Mean reward: 710.20
               Mean episode length: 239.05
    Episode_Reward/reaching_object: 1.2118
    Episode_Reward/rotating_object: 145.9299
        Episode_Reward/action_rate: -0.1400
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 2.33s
                      Time elapsed: 00:54:02
                               ETA: 00:01:06

################################################################################
                     [1m Learning iteration 1471/1500 [0m                     

                       Computation: 41749 steps/s (collection: 2.221s, learning 0.133s)
             Mean action noise std: 4.75
          Mean value_function loss: 70.2246
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 75.5344
                       Mean reward: 704.33
               Mean episode length: 239.70
    Episode_Reward/reaching_object: 1.1971
    Episode_Reward/rotating_object: 144.1575
        Episode_Reward/action_rate: -0.1388
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 2.35s
                      Time elapsed: 00:54:04
                               ETA: 00:01:03

################################################################################
                     [1m Learning iteration 1472/1500 [0m                     

                       Computation: 41751 steps/s (collection: 2.225s, learning 0.129s)
             Mean action noise std: 4.75
          Mean value_function loss: 75.6914
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 75.5406
                       Mean reward: 731.09
               Mean episode length: 238.95
    Episode_Reward/reaching_object: 1.1955
    Episode_Reward/rotating_object: 145.8906
        Episode_Reward/action_rate: -0.1385
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 2.35s
                      Time elapsed: 00:54:06
                               ETA: 00:01:01

################################################################################
                     [1m Learning iteration 1473/1500 [0m                     

                       Computation: 42728 steps/s (collection: 2.173s, learning 0.128s)
             Mean action noise std: 4.75
          Mean value_function loss: 74.1524
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 75.5520
                       Mean reward: 708.92
               Mean episode length: 241.67
    Episode_Reward/reaching_object: 1.1899
    Episode_Reward/rotating_object: 142.2572
        Episode_Reward/action_rate: -0.1374
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 2.30s
                      Time elapsed: 00:54:09
                               ETA: 00:00:59

################################################################################
                     [1m Learning iteration 1474/1500 [0m                     

                       Computation: 41848 steps/s (collection: 2.231s, learning 0.118s)
             Mean action noise std: 4.75
          Mean value_function loss: 59.3013
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 75.5671
                       Mean reward: 731.77
               Mean episode length: 237.90
    Episode_Reward/reaching_object: 1.2109
    Episode_Reward/rotating_object: 147.8988
        Episode_Reward/action_rate: -0.1398
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 2.35s
                      Time elapsed: 00:54:11
                               ETA: 00:00:57

################################################################################
                     [1m Learning iteration 1475/1500 [0m                     

                       Computation: 45775 steps/s (collection: 2.036s, learning 0.111s)
             Mean action noise std: 4.75
          Mean value_function loss: 70.2703
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 75.5813
                       Mean reward: 753.95
               Mean episode length: 241.72
    Episode_Reward/reaching_object: 1.2032
    Episode_Reward/rotating_object: 144.7764
        Episode_Reward/action_rate: -0.1403
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 2.15s
                      Time elapsed: 00:54:13
                               ETA: 00:00:55

################################################################################
                     [1m Learning iteration 1476/1500 [0m                     

                       Computation: 44717 steps/s (collection: 2.075s, learning 0.123s)
             Mean action noise std: 4.76
          Mean value_function loss: 69.1126
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 75.5921
                       Mean reward: 700.39
               Mean episode length: 233.29
    Episode_Reward/reaching_object: 1.1933
    Episode_Reward/rotating_object: 144.3581
        Episode_Reward/action_rate: -0.1392
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 2.20s
                      Time elapsed: 00:54:15
                               ETA: 00:00:52

################################################################################
                     [1m Learning iteration 1477/1500 [0m                     

                       Computation: 45002 steps/s (collection: 2.059s, learning 0.125s)
             Mean action noise std: 4.76
          Mean value_function loss: 76.3391
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 75.5955
                       Mean reward: 713.15
               Mean episode length: 229.46
    Episode_Reward/reaching_object: 1.1851
    Episode_Reward/rotating_object: 144.2822
        Episode_Reward/action_rate: -0.1387
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 2.18s
                      Time elapsed: 00:54:17
                               ETA: 00:00:50

################################################################################
                     [1m Learning iteration 1478/1500 [0m                     

                       Computation: 45632 steps/s (collection: 2.040s, learning 0.114s)
             Mean action noise std: 4.76
          Mean value_function loss: 75.9033
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 75.6093
                       Mean reward: 691.74
               Mean episode length: 242.96
    Episode_Reward/reaching_object: 1.1781
    Episode_Reward/rotating_object: 141.4399
        Episode_Reward/action_rate: -0.1381
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 2.15s
                      Time elapsed: 00:54:20
                               ETA: 00:00:48

################################################################################
                     [1m Learning iteration 1479/1500 [0m                     

                       Computation: 45315 steps/s (collection: 2.053s, learning 0.116s)
             Mean action noise std: 4.76
          Mean value_function loss: 77.1766
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 75.6260
                       Mean reward: 719.79
               Mean episode length: 230.08
    Episode_Reward/reaching_object: 1.1810
    Episode_Reward/rotating_object: 140.7369
        Episode_Reward/action_rate: -0.1385
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 2.17s
                      Time elapsed: 00:54:22
                               ETA: 00:00:46

################################################################################
                     [1m Learning iteration 1480/1500 [0m                     

                       Computation: 46008 steps/s (collection: 2.023s, learning 0.113s)
             Mean action noise std: 4.77
          Mean value_function loss: 75.1773
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 75.6386
                       Mean reward: 722.58
               Mean episode length: 238.82
    Episode_Reward/reaching_object: 1.1839
    Episode_Reward/rotating_object: 144.6946
        Episode_Reward/action_rate: -0.1389
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 2.14s
                      Time elapsed: 00:54:24
                               ETA: 00:00:44

################################################################################
                     [1m Learning iteration 1481/1500 [0m                     

                       Computation: 45128 steps/s (collection: 2.067s, learning 0.111s)
             Mean action noise std: 4.77
          Mean value_function loss: 71.6910
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 75.6462
                       Mean reward: 691.92
               Mean episode length: 238.89
    Episode_Reward/reaching_object: 1.1919
    Episode_Reward/rotating_object: 143.8156
        Episode_Reward/action_rate: -0.1396
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 2.18s
                      Time elapsed: 00:54:26
                               ETA: 00:00:41

################################################################################
                     [1m Learning iteration 1482/1500 [0m                     

                       Computation: 46139 steps/s (collection: 2.017s, learning 0.114s)
             Mean action noise std: 4.77
          Mean value_function loss: 67.1168
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 75.6520
                       Mean reward: 705.85
               Mean episode length: 233.94
    Episode_Reward/reaching_object: 1.1766
    Episode_Reward/rotating_object: 138.5705
        Episode_Reward/action_rate: -0.1385
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 2.13s
                      Time elapsed: 00:54:28
                               ETA: 00:00:39

################################################################################
                     [1m Learning iteration 1483/1500 [0m                     

                       Computation: 46940 steps/s (collection: 1.982s, learning 0.112s)
             Mean action noise std: 4.77
          Mean value_function loss: 71.2532
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 75.6664
                       Mean reward: 665.61
               Mean episode length: 229.96
    Episode_Reward/reaching_object: 1.1964
    Episode_Reward/rotating_object: 140.4840
        Episode_Reward/action_rate: -0.1404
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 2.09s
                      Time elapsed: 00:54:30
                               ETA: 00:00:37

################################################################################
                     [1m Learning iteration 1484/1500 [0m                     

                       Computation: 46132 steps/s (collection: 2.020s, learning 0.111s)
             Mean action noise std: 4.78
          Mean value_function loss: 71.6643
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 75.6882
                       Mean reward: 748.33
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.1992
    Episode_Reward/rotating_object: 145.9374
        Episode_Reward/action_rate: -0.1403
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 2.13s
                      Time elapsed: 00:54:32
                               ETA: 00:00:35

################################################################################
                     [1m Learning iteration 1485/1500 [0m                     

                       Computation: 47508 steps/s (collection: 1.957s, learning 0.112s)
             Mean action noise std: 4.78
          Mean value_function loss: 69.4428
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 75.7092
                       Mean reward: 729.32
               Mean episode length: 247.38
    Episode_Reward/reaching_object: 1.2022
    Episode_Reward/rotating_object: 143.3600
        Episode_Reward/action_rate: -0.1413
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 2.07s
                      Time elapsed: 00:54:34
                               ETA: 00:00:33

################################################################################
                     [1m Learning iteration 1486/1500 [0m                     

                       Computation: 46712 steps/s (collection: 1.993s, learning 0.112s)
             Mean action noise std: 4.78
          Mean value_function loss: 79.1092
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 75.7211
                       Mean reward: 729.72
               Mean episode length: 239.56
    Episode_Reward/reaching_object: 1.1965
    Episode_Reward/rotating_object: 145.1257
        Episode_Reward/action_rate: -0.1400
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 2.10s
                      Time elapsed: 00:54:37
                               ETA: 00:00:30

################################################################################
                     [1m Learning iteration 1487/1500 [0m                     

                       Computation: 47606 steps/s (collection: 1.953s, learning 0.112s)
             Mean action noise std: 4.78
          Mean value_function loss: 76.0902
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 75.7346
                       Mean reward: 685.99
               Mean episode length: 228.16
    Episode_Reward/reaching_object: 1.1870
    Episode_Reward/rotating_object: 142.0944
        Episode_Reward/action_rate: -0.1397
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 2.06s
                      Time elapsed: 00:54:39
                               ETA: 00:00:28

################################################################################
                     [1m Learning iteration 1488/1500 [0m                     

                       Computation: 46767 steps/s (collection: 1.987s, learning 0.115s)
             Mean action noise std: 4.79
          Mean value_function loss: 58.9438
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 75.7506
                       Mean reward: 677.73
               Mean episode length: 239.29
    Episode_Reward/reaching_object: 1.2111
    Episode_Reward/rotating_object: 145.3553
        Episode_Reward/action_rate: -0.1421
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 2.10s
                      Time elapsed: 00:54:41
                               ETA: 00:00:26

################################################################################
                     [1m Learning iteration 1489/1500 [0m                     

                       Computation: 46501 steps/s (collection: 2.003s, learning 0.111s)
             Mean action noise std: 4.79
          Mean value_function loss: 61.3297
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 75.7667
                       Mean reward: 788.36
               Mean episode length: 246.31
    Episode_Reward/reaching_object: 1.2271
    Episode_Reward/rotating_object: 151.8338
        Episode_Reward/action_rate: -0.1441
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 2.11s
                      Time elapsed: 00:54:43
                               ETA: 00:00:24

################################################################################
                     [1m Learning iteration 1490/1500 [0m                     

                       Computation: 46656 steps/s (collection: 1.992s, learning 0.115s)
             Mean action noise std: 4.79
          Mean value_function loss: 63.9412
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 75.7796
                       Mean reward: 720.49
               Mean episode length: 236.74
    Episode_Reward/reaching_object: 1.2072
    Episode_Reward/rotating_object: 147.0631
        Episode_Reward/action_rate: -0.1419
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 2.11s
                      Time elapsed: 00:54:45
                               ETA: 00:00:22

################################################################################
                     [1m Learning iteration 1491/1500 [0m                     

                       Computation: 46529 steps/s (collection: 2.001s, learning 0.112s)
             Mean action noise std: 4.79
          Mean value_function loss: 66.5913
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 75.7885
                       Mean reward: 723.39
               Mean episode length: 241.51
    Episode_Reward/reaching_object: 1.2125
    Episode_Reward/rotating_object: 145.4967
        Episode_Reward/action_rate: -0.1435
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 2.11s
                      Time elapsed: 00:54:47
                               ETA: 00:00:19

################################################################################
                     [1m Learning iteration 1492/1500 [0m                     

                       Computation: 46553 steps/s (collection: 1.997s, learning 0.114s)
             Mean action noise std: 4.80
          Mean value_function loss: 76.1796
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 75.8022
                       Mean reward: 715.61
               Mean episode length: 237.53
    Episode_Reward/reaching_object: 1.1881
    Episode_Reward/rotating_object: 144.3995
        Episode_Reward/action_rate: -0.1407
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 2.11s
                      Time elapsed: 00:54:49
                               ETA: 00:00:17

################################################################################
                     [1m Learning iteration 1493/1500 [0m                     

                       Computation: 45273 steps/s (collection: 2.059s, learning 0.113s)
             Mean action noise std: 4.80
          Mean value_function loss: 63.4337
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 75.8152
                       Mean reward: 725.53
               Mean episode length: 241.53
    Episode_Reward/reaching_object: 1.1892
    Episode_Reward/rotating_object: 140.2867
        Episode_Reward/action_rate: -0.1410
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 2.17s
                      Time elapsed: 00:54:51
                               ETA: 00:00:15

################################################################################
                     [1m Learning iteration 1494/1500 [0m                     

                       Computation: 46002 steps/s (collection: 2.018s, learning 0.119s)
             Mean action noise std: 4.80
          Mean value_function loss: 66.7917
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 75.8239
                       Mean reward: 722.15
               Mean episode length: 244.43
    Episode_Reward/reaching_object: 1.2057
    Episode_Reward/rotating_object: 144.6838
        Episode_Reward/action_rate: -0.1442
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 2.14s
                      Time elapsed: 00:54:53
                               ETA: 00:00:13

################################################################################
                     [1m Learning iteration 1495/1500 [0m                     

                       Computation: 42805 steps/s (collection: 2.167s, learning 0.129s)
             Mean action noise std: 4.80
          Mean value_function loss: 65.8406
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 75.8318
                       Mean reward: 752.73
               Mean episode length: 239.51
    Episode_Reward/reaching_object: 1.2054
    Episode_Reward/rotating_object: 145.0544
        Episode_Reward/action_rate: -0.1433
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 2.30s
                      Time elapsed: 00:54:56
                               ETA: 00:00:11

################################################################################
                     [1m Learning iteration 1496/1500 [0m                     

                       Computation: 42602 steps/s (collection: 2.180s, learning 0.128s)
             Mean action noise std: 4.81
          Mean value_function loss: 79.3858
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 75.8434
                       Mean reward: 726.39
               Mean episode length: 240.17
    Episode_Reward/reaching_object: 1.1951
    Episode_Reward/rotating_object: 144.2538
        Episode_Reward/action_rate: -0.1423
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 2.31s
                      Time elapsed: 00:54:58
                               ETA: 00:00:08

################################################################################
                     [1m Learning iteration 1497/1500 [0m                     

                       Computation: 42916 steps/s (collection: 2.160s, learning 0.130s)
             Mean action noise std: 4.81
          Mean value_function loss: 64.5841
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 75.8576
                       Mean reward: 742.17
               Mean episode length: 241.65
    Episode_Reward/reaching_object: 1.2125
    Episode_Reward/rotating_object: 147.6110
        Episode_Reward/action_rate: -0.1441
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 2.29s
                      Time elapsed: 00:55:00
                               ETA: 00:00:06

################################################################################
                     [1m Learning iteration 1498/1500 [0m                     

                       Computation: 42352 steps/s (collection: 2.195s, learning 0.126s)
             Mean action noise std: 4.81
          Mean value_function loss: 79.7713
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 75.8713
                       Mean reward: 756.15
               Mean episode length: 243.51
    Episode_Reward/reaching_object: 1.2008
    Episode_Reward/rotating_object: 147.6897
        Episode_Reward/action_rate: -0.1431
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 2.32s
                      Time elapsed: 00:55:03
                               ETA: 00:00:04

################################################################################
                     [1m Learning iteration 1499/1500 [0m                     

                       Computation: 42955 steps/s (collection: 2.164s, learning 0.125s)
             Mean action noise std: 4.81
          Mean value_function loss: 62.7043
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 75.8849
                       Mean reward: 709.23
               Mean episode length: 235.59
    Episode_Reward/reaching_object: 1.1839
    Episode_Reward/rotating_object: 142.3906
        Episode_Reward/action_rate: -0.1420
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 2.29s
                      Time elapsed: 00:55:05
                               ETA: 00:00:02

