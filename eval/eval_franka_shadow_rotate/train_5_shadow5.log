################################################################################
                      [1m Learning iteration 0/1500 [0m                       

                       Computation: 10467 steps/s (collection: 9.021s, learning 0.370s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0069
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 44.0141
                       Mean reward: 0.00
               Mean episode length: 21.40
    Episode_Reward/reaching_object: 0.0010
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0003
          Episode_Reward/joint_vel: -0.0004
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 9.39s
                      Time elapsed: 00:00:09
                               ETA: 03:54:46

################################################################################
                      [1m Learning iteration 1/1500 [0m                       

                       Computation: 14443 steps/s (collection: 6.683s, learning 0.124s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0010
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 44.1239
                       Mean reward: 0.00
               Mean episode length: 45.09
    Episode_Reward/reaching_object: 0.0026
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0009
          Episode_Reward/joint_vel: -0.0013
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 6.81s
                      Time elapsed: 00:00:16
                               ETA: 03:22:19

################################################################################
                      [1m Learning iteration 2/1500 [0m                       

                       Computation: 14650 steps/s (collection: 6.564s, learning 0.146s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0003
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 44.2172
                       Mean reward: 0.00
               Mean episode length: 69.30
    Episode_Reward/reaching_object: 0.0042
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0015
          Episode_Reward/joint_vel: -0.0022
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 6.71s
                      Time elapsed: 00:00:22
                               ETA: 03:10:38

################################################################################
                      [1m Learning iteration 3/1500 [0m                       

                       Computation: 14568 steps/s (collection: 6.601s, learning 0.147s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 44.2970
                       Mean reward: 0.00
               Mean episode length: 93.06
    Episode_Reward/reaching_object: 0.0061
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0021
          Episode_Reward/joint_vel: -0.0031
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 6.75s
                      Time elapsed: 00:00:29
                               ETA: 03:04:58

################################################################################
                      [1m Learning iteration 4/1500 [0m                       

                       Computation: 14472 steps/s (collection: 6.643s, learning 0.150s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 44.3383
                       Mean reward: 0.00
               Mean episode length: 117.24
    Episode_Reward/reaching_object: 0.0074
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0027
          Episode_Reward/joint_vel: -0.0040
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 6.79s
                      Time elapsed: 00:00:36
                               ETA: 03:01:45

################################################################################
                      [1m Learning iteration 5/1500 [0m                       

                       Computation: 14445 steps/s (collection: 6.655s, learning 0.151s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 44.3664
                       Mean reward: 0.00
               Mean episode length: 141.16
    Episode_Reward/reaching_object: 0.0088
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0033
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 6.81s
                      Time elapsed: 00:00:43
                               ETA: 02:59:37

################################################################################
                      [1m Learning iteration 6/1500 [0m                       

                       Computation: 14338 steps/s (collection: 6.679s, learning 0.177s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 44.4372
                       Mean reward: 0.00
               Mean episode length: 165.69
    Episode_Reward/reaching_object: 0.0103
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0040
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 6.86s
                      Time elapsed: 00:00:50
                               ETA: 02:58:14

################################################################################
                      [1m Learning iteration 7/1500 [0m                       

                       Computation: 14540 steps/s (collection: 6.624s, learning 0.137s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 44.4858
                       Mean reward: 0.00
               Mean episode length: 189.43
    Episode_Reward/reaching_object: 0.0117
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 6.76s
                      Time elapsed: 00:00:56
                               ETA: 02:56:53

################################################################################
                      [1m Learning iteration 8/1500 [0m                       

                       Computation: 16746 steps/s (collection: 5.737s, learning 0.133s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 44.5088
                       Mean reward: 0.00
               Mean episode length: 213.24
    Episode_Reward/reaching_object: 0.0129
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 5.87s
                      Time elapsed: 00:01:02
                               ETA: 02:53:20

################################################################################
                      [1m Learning iteration 9/1500 [0m                       

                       Computation: 53085 steps/s (collection: 1.740s, learning 0.112s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 44.5427
                       Mean reward: 0.01
               Mean episode length: 237.77
    Episode_Reward/reaching_object: 0.0150
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 1.85s
                      Time elapsed: 00:01:04
                               ETA: 02:40:30

################################################################################
                      [1m Learning iteration 10/1500 [0m                      

                       Computation: 53196 steps/s (collection: 1.674s, learning 0.174s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 44.5903
                       Mean reward: -0.00
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0155
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 1.85s
                      Time elapsed: 00:01:06
                               ETA: 02:29:59

################################################################################
                      [1m Learning iteration 11/1500 [0m                      

                       Computation: 56727 steps/s (collection: 1.578s, learning 0.155s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 44.6491
                       Mean reward: 0.01
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0173
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 1.73s
                      Time elapsed: 00:01:08
                               ETA: 02:20:59

################################################################################
                      [1m Learning iteration 12/1500 [0m                      

                       Computation: 55516 steps/s (collection: 1.679s, learning 0.092s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 44.6585
                       Mean reward: 0.01
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0176
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 1.77s
                      Time elapsed: 00:01:09
                               ETA: 02:13:25

################################################################################
                      [1m Learning iteration 13/1500 [0m                      

                       Computation: 58149 steps/s (collection: 1.573s, learning 0.118s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 44.6521
                       Mean reward: 0.04
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0207
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 1.69s
                      Time elapsed: 00:01:11
                               ETA: 02:06:48

################################################################################
                      [1m Learning iteration 14/1500 [0m                      

                       Computation: 58187 steps/s (collection: 1.563s, learning 0.126s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 44.6484
                       Mean reward: 0.04
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0217
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 1.69s
                      Time elapsed: 00:01:13
                               ETA: 02:01:03

################################################################################
                      [1m Learning iteration 15/1500 [0m                      

                       Computation: 58770 steps/s (collection: 1.550s, learning 0.123s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 44.6364
                       Mean reward: 0.05
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0264
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 1.67s
                      Time elapsed: 00:01:14
                               ETA: 01:56:00

################################################################################
                      [1m Learning iteration 16/1500 [0m                      

                       Computation: 59763 steps/s (collection: 1.552s, learning 0.093s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 44.6967
                       Mean reward: 0.08
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0317
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 1.64s
                      Time elapsed: 00:01:16
                               ETA: 01:51:30

################################################################################
                      [1m Learning iteration 17/1500 [0m                      

                       Computation: 59320 steps/s (collection: 1.556s, learning 0.101s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 44.7555
                       Mean reward: 0.11
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0364
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 1.66s
                      Time elapsed: 00:01:18
                               ETA: 01:47:30

################################################################################
                      [1m Learning iteration 18/1500 [0m                      

                       Computation: 58140 steps/s (collection: 1.541s, learning 0.150s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 44.8304
                       Mean reward: 0.15
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0454
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 1.69s
                      Time elapsed: 00:01:19
                               ETA: 01:43:59

################################################################################
                      [1m Learning iteration 19/1500 [0m                      

                       Computation: 57032 steps/s (collection: 1.602s, learning 0.122s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0004
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 44.8974
                       Mean reward: 0.26
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0574
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 1.72s
                      Time elapsed: 00:01:21
                               ETA: 01:40:50

################################################################################
                      [1m Learning iteration 20/1500 [0m                      

                       Computation: 57844 steps/s (collection: 1.589s, learning 0.111s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0006
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 44.9735
                       Mean reward: 0.32
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0787
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 1.70s
                      Time elapsed: 00:01:23
                               ETA: 01:37:58

################################################################################
                      [1m Learning iteration 21/1500 [0m                      

                       Computation: 53748 steps/s (collection: 1.694s, learning 0.135s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0010
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 45.0255
                       Mean reward: 0.40
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0911
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 1.83s
                      Time elapsed: 00:01:25
                               ETA: 01:35:30

################################################################################
                      [1m Learning iteration 22/1500 [0m                      

                       Computation: 54375 steps/s (collection: 1.652s, learning 0.156s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0017
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 45.1207
                       Mean reward: 0.60
               Mean episode length: 249.87
    Episode_Reward/reaching_object: 0.1209
    Episode_Reward/rotating_object: 0.0001
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 1.81s
                      Time elapsed: 00:01:27
                               ETA: 01:33:13

################################################################################
                      [1m Learning iteration 23/1500 [0m                      

                       Computation: 53730 steps/s (collection: 1.724s, learning 0.106s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0027
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 45.2137
                       Mean reward: 0.76
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.1555
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 1.83s
                      Time elapsed: 00:01:28
                               ETA: 01:31:09

################################################################################
                      [1m Learning iteration 24/1500 [0m                      

                       Computation: 51644 steps/s (collection: 1.792s, learning 0.112s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0036
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 45.2934
                       Mean reward: 1.08
               Mean episode length: 249.37
    Episode_Reward/reaching_object: 0.2081
    Episode_Reward/rotating_object: 0.0003
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 1.90s
                      Time elapsed: 00:01:30
                               ETA: 01:29:19

################################################################################
                      [1m Learning iteration 25/1500 [0m                      

                       Computation: 52316 steps/s (collection: 1.764s, learning 0.115s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0070
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 45.3832
                       Mean reward: 1.36
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 0.2622
    Episode_Reward/rotating_object: 0.0004
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 1.88s
                      Time elapsed: 00:01:32
                               ETA: 01:27:36

################################################################################
                      [1m Learning iteration 26/1500 [0m                      

                       Computation: 50975 steps/s (collection: 1.810s, learning 0.118s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0062
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 45.4617
                       Mean reward: 1.75
               Mean episode length: 245.57
    Episode_Reward/reaching_object: 0.3178
    Episode_Reward/rotating_object: 0.0011
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 1.93s
                      Time elapsed: 00:01:34
                               ETA: 01:26:03

################################################################################
                      [1m Learning iteration 27/1500 [0m                      

                       Computation: 50888 steps/s (collection: 1.822s, learning 0.109s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0128
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 45.5476
                       Mean reward: 1.99
               Mean episode length: 243.16
    Episode_Reward/reaching_object: 0.3723
    Episode_Reward/rotating_object: 0.0027
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 1.93s
                      Time elapsed: 00:01:36
                               ETA: 01:24:37

################################################################################
                      [1m Learning iteration 28/1500 [0m                      

                       Computation: 51133 steps/s (collection: 1.824s, learning 0.099s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0256
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 45.6228
                       Mean reward: 2.35
               Mean episode length: 239.42
    Episode_Reward/reaching_object: 0.4318
    Episode_Reward/rotating_object: 0.0161
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 1.92s
                      Time elapsed: 00:01:38
                               ETA: 01:23:16

################################################################################
                      [1m Learning iteration 29/1500 [0m                      

                       Computation: 51067 steps/s (collection: 1.828s, learning 0.097s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0156
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 45.7608
                       Mean reward: 2.48
               Mean episode length: 239.29
    Episode_Reward/reaching_object: 0.4689
    Episode_Reward/rotating_object: 0.0225
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 11.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.2917
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 1.92s
                      Time elapsed: 00:01:40
                               ETA: 01:22:01

################################################################################
                      [1m Learning iteration 30/1500 [0m                      

                       Computation: 50120 steps/s (collection: 1.865s, learning 0.096s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0219
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 45.8644
                       Mean reward: 2.76
               Mean episode length: 228.64
    Episode_Reward/reaching_object: 0.5171
    Episode_Reward/rotating_object: 0.0294
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 8.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.3333
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 1.96s
                      Time elapsed: 00:01:42
                               ETA: 01:20:52

################################################################################
                      [1m Learning iteration 31/1500 [0m                      

                       Computation: 49663 steps/s (collection: 1.884s, learning 0.095s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.1058
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 45.9852
                       Mean reward: 3.11
               Mean episode length: 227.33
    Episode_Reward/reaching_object: 0.5544
    Episode_Reward/rotating_object: 0.0466
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 7.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 1.98s
                      Time elapsed: 00:01:44
                               ETA: 01:19:48

################################################################################
                      [1m Learning iteration 32/1500 [0m                      

                       Computation: 49771 steps/s (collection: 1.869s, learning 0.106s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.1140
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 46.1825
                       Mean reward: 3.04
               Mean episode length: 215.86
    Episode_Reward/reaching_object: 0.5800
    Episode_Reward/rotating_object: 0.0344
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 4.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 1.98s
                      Time elapsed: 00:01:46
                               ETA: 01:18:48

################################################################################
                      [1m Learning iteration 33/1500 [0m                      

                       Computation: 49322 steps/s (collection: 1.902s, learning 0.092s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.0522
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 46.2468
                       Mean reward: 3.16
               Mean episode length: 217.85
    Episode_Reward/reaching_object: 0.6107
    Episode_Reward/rotating_object: 0.0871
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 3.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 1.99s
                      Time elapsed: 00:01:48
                               ETA: 01:17:51

################################################################################
                      [1m Learning iteration 34/1500 [0m                      

                       Computation: 49008 steps/s (collection: 1.884s, learning 0.122s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.0730
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 46.3600
                       Mean reward: 3.45
               Mean episode length: 214.58
    Episode_Reward/reaching_object: 0.6515
    Episode_Reward/rotating_object: 0.0861
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 3.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 2.01s
                      Time elapsed: 00:01:50
                               ETA: 01:16:59

################################################################################
                      [1m Learning iteration 35/1500 [0m                      

                       Computation: 46886 steps/s (collection: 1.938s, learning 0.159s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.2646
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 46.5292
                       Mean reward: 3.73
               Mean episode length: 210.75
    Episode_Reward/reaching_object: 0.6652
    Episode_Reward/rotating_object: 0.0785
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 2.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 2.10s
                      Time elapsed: 00:01:52
                               ETA: 01:16:13

################################################################################
                      [1m Learning iteration 36/1500 [0m                      

                       Computation: 46151 steps/s (collection: 2.030s, learning 0.100s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.3618
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 46.6036
                       Mean reward: 4.99
               Mean episode length: 204.52
    Episode_Reward/reaching_object: 0.7048
    Episode_Reward/rotating_object: 0.1373
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 3.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 2.13s
                      Time elapsed: 00:01:54
                               ETA: 01:15:30

################################################################################
                      [1m Learning iteration 37/1500 [0m                      

                       Computation: 46618 steps/s (collection: 1.979s, learning 0.130s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.1079
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 46.7739
                       Mean reward: 4.10
               Mean episode length: 213.47
    Episode_Reward/reaching_object: 0.7683
    Episode_Reward/rotating_object: 0.1627
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 2.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 2.11s
                      Time elapsed: 00:01:56
                               ETA: 01:14:49

################################################################################
                      [1m Learning iteration 38/1500 [0m                      

                       Computation: 47067 steps/s (collection: 1.951s, learning 0.138s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.1660
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 46.9208
                       Mean reward: 4.14
               Mean episode length: 215.39
    Episode_Reward/reaching_object: 0.7917
    Episode_Reward/rotating_object: 0.1220
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 2.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 2.09s
                      Time elapsed: 00:01:58
                               ETA: 01:14:09

################################################################################
                      [1m Learning iteration 39/1500 [0m                      

                       Computation: 44649 steps/s (collection: 2.098s, learning 0.103s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.2588
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 47.0023
                       Mean reward: 4.75
               Mean episode length: 215.49
    Episode_Reward/reaching_object: 0.8271
    Episode_Reward/rotating_object: 0.1206
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 2.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 2.20s
                      Time elapsed: 00:02:00
                               ETA: 01:13:36

################################################################################
                      [1m Learning iteration 40/1500 [0m                      

                       Computation: 47492 steps/s (collection: 1.974s, learning 0.096s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.4224
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 47.1206
                       Mean reward: 4.70
               Mean episode length: 217.86
    Episode_Reward/reaching_object: 0.8230
    Episode_Reward/rotating_object: 0.0998
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 4.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 2.07s
                      Time elapsed: 00:02:02
                               ETA: 01:12:59

################################################################################
                      [1m Learning iteration 41/1500 [0m                      

                       Computation: 46376 steps/s (collection: 2.010s, learning 0.110s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.3788
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 47.1824
                       Mean reward: 5.01
               Mean episode length: 221.26
    Episode_Reward/reaching_object: 0.8739
    Episode_Reward/rotating_object: 0.2614
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 4.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 11.5417
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 2.12s
                      Time elapsed: 00:02:05
                               ETA: 01:12:25

################################################################################
                      [1m Learning iteration 42/1500 [0m                      

                       Computation: 48886 steps/s (collection: 1.916s, learning 0.095s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.5445
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 47.2787
                       Mean reward: 5.45
               Mean episode length: 229.05
    Episode_Reward/reaching_object: 0.9566
    Episode_Reward/rotating_object: 0.1811
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 7.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.9167
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 2.01s
                      Time elapsed: 00:02:07
                               ETA: 01:11:49

################################################################################
                      [1m Learning iteration 43/1500 [0m                      

                       Computation: 46884 steps/s (collection: 1.962s, learning 0.134s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.4868
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 47.4559
                       Mean reward: 5.78
               Mean episode length: 235.63
    Episode_Reward/reaching_object: 0.9737
    Episode_Reward/rotating_object: 0.4117
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 8.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 2.10s
                      Time elapsed: 00:02:09
                               ETA: 01:11:18

################################################################################
                      [1m Learning iteration 44/1500 [0m                      

                       Computation: 45823 steps/s (collection: 2.045s, learning 0.101s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.3173
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 47.5171
                       Mean reward: 5.61
               Mean episode length: 239.13
    Episode_Reward/reaching_object: 1.0041
    Episode_Reward/rotating_object: 0.3294
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 10.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 2.15s
                      Time elapsed: 00:02:11
                               ETA: 01:10:49

################################################################################
                      [1m Learning iteration 45/1500 [0m                      

                       Computation: 49417 steps/s (collection: 1.889s, learning 0.100s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.2616
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 47.6550
                       Mean reward: 5.92
               Mean episode length: 241.83
    Episode_Reward/reaching_object: 0.9954
    Episode_Reward/rotating_object: 0.3446
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 1.99s
                      Time elapsed: 00:02:13
                               ETA: 01:10:17

################################################################################
                      [1m Learning iteration 46/1500 [0m                      

                       Computation: 48722 steps/s (collection: 1.922s, learning 0.096s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.1758
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 47.7042
                       Mean reward: 5.55
               Mean episode length: 244.10
    Episode_Reward/reaching_object: 0.9739
    Episode_Reward/rotating_object: 0.2783
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 2.02s
                      Time elapsed: 00:02:15
                               ETA: 01:09:47

################################################################################
                      [1m Learning iteration 47/1500 [0m                      

                       Computation: 48056 steps/s (collection: 1.921s, learning 0.125s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.2408
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 47.8341
                       Mean reward: 5.67
               Mean episode length: 244.40
    Episode_Reward/reaching_object: 0.9801
    Episode_Reward/rotating_object: 0.1821
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 2.05s
                      Time elapsed: 00:02:17
                               ETA: 01:09:19

################################################################################
                      [1m Learning iteration 48/1500 [0m                      

                       Computation: 48884 steps/s (collection: 1.919s, learning 0.092s)
             Mean action noise std: 1.14
          Mean value_function loss: 0.2864
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 47.9454
                       Mean reward: 6.30
               Mean episode length: 239.92
    Episode_Reward/reaching_object: 0.9477
    Episode_Reward/rotating_object: 0.1561
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 11.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 2.01s
                      Time elapsed: 00:02:19
                               ETA: 01:08:51

################################################################################
                      [1m Learning iteration 49/1500 [0m                      

                       Computation: 43805 steps/s (collection: 2.095s, learning 0.149s)
             Mean action noise std: 1.14
          Mean value_function loss: 0.4040
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 48.0799
                       Mean reward: 6.60
               Mean episode length: 239.27
    Episode_Reward/reaching_object: 0.9422
    Episode_Reward/rotating_object: 0.2654
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 12.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 2.24s
                      Time elapsed: 00:02:21
                               ETA: 01:08:30

################################################################################
                      [1m Learning iteration 50/1500 [0m                      

                       Computation: 48249 steps/s (collection: 1.950s, learning 0.088s)
             Mean action noise std: 1.14
          Mean value_function loss: 0.2827
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 48.1366
                       Mean reward: 6.79
               Mean episode length: 243.54
    Episode_Reward/reaching_object: 0.9638
    Episode_Reward/rotating_object: 0.2603
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 11.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 2.04s
                      Time elapsed: 00:02:23
                               ETA: 01:08:05

################################################################################
                      [1m Learning iteration 51/1500 [0m                      

                       Computation: 47359 steps/s (collection: 1.984s, learning 0.092s)
             Mean action noise std: 1.15
          Mean value_function loss: 0.1275
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 48.2023
                       Mean reward: 4.95
               Mean episode length: 234.95
    Episode_Reward/reaching_object: 0.9665
    Episode_Reward/rotating_object: 0.2829
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 2.08s
                      Time elapsed: 00:02:25
                               ETA: 01:07:41

################################################################################
                      [1m Learning iteration 52/1500 [0m                      

                       Computation: 48662 steps/s (collection: 1.913s, learning 0.107s)
             Mean action noise std: 1.15
          Mean value_function loss: 0.2473
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 48.3218
                       Mean reward: 5.35
               Mean episode length: 230.89
    Episode_Reward/reaching_object: 0.9437
    Episode_Reward/rotating_object: 0.2255
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 2.02s
                      Time elapsed: 00:02:27
                               ETA: 01:07:17

################################################################################
                      [1m Learning iteration 53/1500 [0m                      

                       Computation: 46223 steps/s (collection: 2.026s, learning 0.101s)
             Mean action noise std: 1.16
          Mean value_function loss: 0.4236
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 48.4231
                       Mean reward: 5.75
               Mean episode length: 236.08
    Episode_Reward/reaching_object: 0.9369
    Episode_Reward/rotating_object: 0.2362
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 10.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 2.13s
                      Time elapsed: 00:02:29
                               ETA: 01:06:57

################################################################################
                      [1m Learning iteration 54/1500 [0m                      

                       Computation: 47638 steps/s (collection: 1.975s, learning 0.088s)
             Mean action noise std: 1.16
          Mean value_function loss: 0.4002
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 48.4575
                       Mean reward: 6.36
               Mean episode length: 234.49
    Episode_Reward/reaching_object: 0.9651
    Episode_Reward/rotating_object: 0.2280
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 10.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 2.06s
                      Time elapsed: 00:02:31
                               ETA: 01:06:35

################################################################################
                      [1m Learning iteration 55/1500 [0m                      

                       Computation: 46443 steps/s (collection: 1.994s, learning 0.123s)
             Mean action noise std: 1.16
          Mean value_function loss: 0.2718
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 48.5722
                       Mean reward: 7.43
               Mean episode length: 234.67
    Episode_Reward/reaching_object: 0.9766
    Episode_Reward/rotating_object: 0.3392
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 11.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.8333
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 2.12s
                      Time elapsed: 00:02:34
                               ETA: 01:06:16

################################################################################
                      [1m Learning iteration 56/1500 [0m                      

                       Computation: 46904 steps/s (collection: 1.984s, learning 0.112s)
             Mean action noise std: 1.17
          Mean value_function loss: 0.4843
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 48.6925
                       Mean reward: 5.79
               Mean episode length: 231.15
    Episode_Reward/reaching_object: 1.0373
    Episode_Reward/rotating_object: 0.3401
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 11.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.8333
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 2.10s
                      Time elapsed: 00:02:36
                               ETA: 01:05:56

################################################################################
                      [1m Learning iteration 57/1500 [0m                      

                       Computation: 48557 steps/s (collection: 1.928s, learning 0.097s)
             Mean action noise std: 1.17
          Mean value_function loss: 0.7723
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 48.7896
                       Mean reward: 8.66
               Mean episode length: 235.33
    Episode_Reward/reaching_object: 1.0560
    Episode_Reward/rotating_object: 0.3297
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 11.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 2.02s
                      Time elapsed: 00:02:38
                               ETA: 01:05:36

################################################################################
                      [1m Learning iteration 58/1500 [0m                      

                       Computation: 45534 steps/s (collection: 1.985s, learning 0.173s)
             Mean action noise std: 1.17
          Mean value_function loss: 0.5881
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 48.8993
                       Mean reward: 6.69
               Mean episode length: 232.34
    Episode_Reward/reaching_object: 1.0787
    Episode_Reward/rotating_object: 0.2535
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 12.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 2.16s
                      Time elapsed: 00:02:40
                               ETA: 01:05:19

################################################################################
                      [1m Learning iteration 59/1500 [0m                      

                       Computation: 46287 steps/s (collection: 1.971s, learning 0.153s)
             Mean action noise std: 1.18
          Mean value_function loss: 0.5896
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 49.0296
                       Mean reward: 6.71
               Mean episode length: 233.62
    Episode_Reward/reaching_object: 1.1232
    Episode_Reward/rotating_object: 0.3014
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 2.12s
                      Time elapsed: 00:02:42
                               ETA: 01:05:02

################################################################################
                      [1m Learning iteration 60/1500 [0m                      

                       Computation: 45707 steps/s (collection: 2.018s, learning 0.133s)
             Mean action noise std: 1.18
          Mean value_function loss: 0.5341
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 49.1463
                       Mean reward: 7.78
               Mean episode length: 229.72
    Episode_Reward/reaching_object: 1.1013
    Episode_Reward/rotating_object: 0.5712
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 10.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 2.15s
                      Time elapsed: 00:02:44
                               ETA: 01:04:46

################################################################################
                      [1m Learning iteration 61/1500 [0m                      

                       Computation: 48275 steps/s (collection: 1.944s, learning 0.092s)
             Mean action noise std: 1.19
          Mean value_function loss: 0.3648
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 49.2690
                       Mean reward: 7.53
               Mean episode length: 239.15
    Episode_Reward/reaching_object: 1.1434
    Episode_Reward/rotating_object: 0.5440
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 11.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 2.04s
                      Time elapsed: 00:02:46
                               ETA: 01:04:28

################################################################################
                      [1m Learning iteration 62/1500 [0m                      

                       Computation: 47029 steps/s (collection: 1.989s, learning 0.101s)
             Mean action noise std: 1.19
          Mean value_function loss: 0.3928
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 49.3825
                       Mean reward: 6.12
               Mean episode length: 235.02
    Episode_Reward/reaching_object: 1.1225
    Episode_Reward/rotating_object: 0.3963
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 11.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 2.09s
                      Time elapsed: 00:02:48
                               ETA: 01:04:12

################################################################################
                      [1m Learning iteration 63/1500 [0m                      

                       Computation: 44877 steps/s (collection: 2.027s, learning 0.163s)
             Mean action noise std: 1.20
          Mean value_function loss: 0.6519
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 49.4974
                       Mean reward: 6.85
               Mean episode length: 235.85
    Episode_Reward/reaching_object: 1.2150
    Episode_Reward/rotating_object: 0.4441
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 2.19s
                      Time elapsed: 00:02:50
                               ETA: 01:03:58

################################################################################
                      [1m Learning iteration 64/1500 [0m                      

                       Computation: 46583 steps/s (collection: 2.015s, learning 0.095s)
             Mean action noise std: 1.20
          Mean value_function loss: 0.6229
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 49.6246
                       Mean reward: 7.88
               Mean episode length: 238.79
    Episode_Reward/reaching_object: 1.1910
    Episode_Reward/rotating_object: 0.5112
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 2.11s
                      Time elapsed: 00:02:53
                               ETA: 01:03:43

################################################################################
                      [1m Learning iteration 65/1500 [0m                      

                       Computation: 47706 steps/s (collection: 1.958s, learning 0.103s)
             Mean action noise std: 1.21
          Mean value_function loss: 0.5991
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 49.7642
                       Mean reward: 6.95
               Mean episode length: 244.89
    Episode_Reward/reaching_object: 1.2047
    Episode_Reward/rotating_object: 0.4617
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 2.06s
                      Time elapsed: 00:02:55
                               ETA: 01:03:27

################################################################################
                      [1m Learning iteration 66/1500 [0m                      

                       Computation: 45550 steps/s (collection: 2.022s, learning 0.137s)
             Mean action noise std: 1.21
          Mean value_function loss: 0.7248
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 49.8533
                       Mean reward: 9.50
               Mean episode length: 239.46
    Episode_Reward/reaching_object: 1.2305
    Episode_Reward/rotating_object: 0.5421
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 2.16s
                      Time elapsed: 00:02:57
                               ETA: 01:03:14

################################################################################
                      [1m Learning iteration 67/1500 [0m                      

                       Computation: 43519 steps/s (collection: 2.135s, learning 0.124s)
             Mean action noise std: 1.21
          Mean value_function loss: 0.6619
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 49.8832
                       Mean reward: 15.40
               Mean episode length: 242.41
    Episode_Reward/reaching_object: 1.1965
    Episode_Reward/rotating_object: 0.8076
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 2.26s
                      Time elapsed: 00:02:59
                               ETA: 01:03:03

################################################################################
                      [1m Learning iteration 68/1500 [0m                      

                       Computation: 47265 steps/s (collection: 1.989s, learning 0.091s)
             Mean action noise std: 1.22
          Mean value_function loss: 0.6420
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 49.9932
                       Mean reward: 9.20
               Mean episode length: 246.11
    Episode_Reward/reaching_object: 1.2390
    Episode_Reward/rotating_object: 0.4693
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 2.08s
                      Time elapsed: 00:03:01
                               ETA: 01:02:49

################################################################################
                      [1m Learning iteration 69/1500 [0m                      

                       Computation: 48466 steps/s (collection: 1.939s, learning 0.089s)
             Mean action noise std: 1.22
          Mean value_function loss: 0.5091
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 50.1201
                       Mean reward: 7.01
               Mean episode length: 245.32
    Episode_Reward/reaching_object: 1.2052
    Episode_Reward/rotating_object: 0.6472
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 2.03s
                      Time elapsed: 00:03:03
                               ETA: 01:02:34

################################################################################
                      [1m Learning iteration 70/1500 [0m                      

                       Computation: 46820 steps/s (collection: 1.957s, learning 0.142s)
             Mean action noise std: 1.22
          Mean value_function loss: 0.8212
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 50.2038
                       Mean reward: 8.18
               Mean episode length: 243.98
    Episode_Reward/reaching_object: 1.2381
    Episode_Reward/rotating_object: 0.6478
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 2.10s
                      Time elapsed: 00:03:05
                               ETA: 01:02:21

################################################################################
                      [1m Learning iteration 71/1500 [0m                      

                       Computation: 46680 steps/s (collection: 2.014s, learning 0.092s)
             Mean action noise std: 1.23
          Mean value_function loss: 0.8621
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 50.2936
                       Mean reward: 7.54
               Mean episode length: 241.23
    Episode_Reward/reaching_object: 1.1780
    Episode_Reward/rotating_object: 0.4620
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 2.11s
                      Time elapsed: 00:03:07
                               ETA: 01:02:08

################################################################################
                      [1m Learning iteration 72/1500 [0m                      

                       Computation: 47355 steps/s (collection: 1.984s, learning 0.092s)
             Mean action noise std: 1.23
          Mean value_function loss: 0.9873
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 50.4205
                       Mean reward: 11.19
               Mean episode length: 246.46
    Episode_Reward/reaching_object: 1.1968
    Episode_Reward/rotating_object: 0.6049
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 2.08s
                      Time elapsed: 00:03:09
                               ETA: 01:01:55

################################################################################
                      [1m Learning iteration 73/1500 [0m                      

                       Computation: 47646 steps/s (collection: 1.967s, learning 0.096s)
             Mean action noise std: 1.24
          Mean value_function loss: 1.0296
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 50.5332
                       Mean reward: 12.44
               Mean episode length: 244.46
    Episode_Reward/reaching_object: 1.2208
    Episode_Reward/rotating_object: 0.9042
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 2.06s
                      Time elapsed: 00:03:12
                               ETA: 01:01:42

################################################################################
                      [1m Learning iteration 74/1500 [0m                      

                       Computation: 47050 steps/s (collection: 1.988s, learning 0.102s)
             Mean action noise std: 1.24
          Mean value_function loss: 1.2426
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 50.6744
                       Mean reward: 9.83
               Mean episode length: 247.05
    Episode_Reward/reaching_object: 1.2333
    Episode_Reward/rotating_object: 0.4681
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 2.09s
                      Time elapsed: 00:03:14
                               ETA: 01:01:30

################################################################################
                      [1m Learning iteration 75/1500 [0m                      

                       Computation: 45801 steps/s (collection: 2.031s, learning 0.115s)
             Mean action noise std: 1.25
          Mean value_function loss: 1.8362
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 50.7563
                       Mean reward: 9.22
               Mean episode length: 246.80
    Episode_Reward/reaching_object: 1.2224
    Episode_Reward/rotating_object: 0.5530
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 2.15s
                      Time elapsed: 00:03:16
                               ETA: 01:01:19

################################################################################
                      [1m Learning iteration 76/1500 [0m                      

                       Computation: 44814 steps/s (collection: 2.047s, learning 0.147s)
             Mean action noise std: 1.25
          Mean value_function loss: 1.4989
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 50.8699
                       Mean reward: 12.37
               Mean episode length: 247.13
    Episode_Reward/reaching_object: 1.2241
    Episode_Reward/rotating_object: 1.4399
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 2.19s
                      Time elapsed: 00:03:18
                               ETA: 01:01:09

################################################################################
                      [1m Learning iteration 77/1500 [0m                      

                       Computation: 45252 steps/s (collection: 2.058s, learning 0.115s)
             Mean action noise std: 1.25
          Mean value_function loss: 1.8130
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 50.9394
                       Mean reward: 10.16
               Mean episode length: 246.84
    Episode_Reward/reaching_object: 1.2284
    Episode_Reward/rotating_object: 0.8781
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 2.17s
                      Time elapsed: 00:03:20
                               ETA: 01:00:59

################################################################################
                      [1m Learning iteration 78/1500 [0m                      

                       Computation: 45650 steps/s (collection: 2.054s, learning 0.099s)
             Mean action noise std: 1.26
          Mean value_function loss: 1.4491
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 51.0755
                       Mean reward: 8.65
               Mean episode length: 246.85
    Episode_Reward/reaching_object: 1.2410
    Episode_Reward/rotating_object: 0.9100
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 2.15s
                      Time elapsed: 00:03:22
                               ETA: 01:00:49

################################################################################
                      [1m Learning iteration 79/1500 [0m                      

                       Computation: 46274 steps/s (collection: 1.985s, learning 0.139s)
             Mean action noise std: 1.26
          Mean value_function loss: 1.2214
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 51.1935
                       Mean reward: 14.13
               Mean episode length: 248.24
    Episode_Reward/reaching_object: 1.2716
    Episode_Reward/rotating_object: 1.2296
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 2.12s
                      Time elapsed: 00:03:24
                               ETA: 01:00:39

################################################################################
                      [1m Learning iteration 80/1500 [0m                      

                       Computation: 46209 steps/s (collection: 1.980s, learning 0.148s)
             Mean action noise std: 1.27
          Mean value_function loss: 1.4163
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 51.2891
                       Mean reward: 13.87
               Mean episode length: 246.16
    Episode_Reward/reaching_object: 1.2799
    Episode_Reward/rotating_object: 1.3978
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 2.13s
                      Time elapsed: 00:03:27
                               ETA: 01:00:29

################################################################################
                      [1m Learning iteration 81/1500 [0m                      

                       Computation: 48001 steps/s (collection: 1.945s, learning 0.103s)
             Mean action noise std: 1.27
          Mean value_function loss: 1.3044
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 51.3889
                       Mean reward: 10.68
               Mean episode length: 245.70
    Episode_Reward/reaching_object: 1.2546
    Episode_Reward/rotating_object: 0.8969
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 2.05s
                      Time elapsed: 00:03:29
                               ETA: 01:00:17

################################################################################
                      [1m Learning iteration 82/1500 [0m                      

                       Computation: 45467 steps/s (collection: 2.036s, learning 0.127s)
             Mean action noise std: 1.28
          Mean value_function loss: 2.0000
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 51.5178
                       Mean reward: 12.11
               Mean episode length: 242.36
    Episode_Reward/reaching_object: 1.2491
    Episode_Reward/rotating_object: 1.1494
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 2.16s
                      Time elapsed: 00:03:31
                               ETA: 01:00:08

################################################################################
                      [1m Learning iteration 83/1500 [0m                      

                       Computation: 46772 steps/s (collection: 2.001s, learning 0.100s)
             Mean action noise std: 1.28
          Mean value_function loss: 2.3212
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 51.6018
                       Mean reward: 10.09
               Mean episode length: 243.97
    Episode_Reward/reaching_object: 1.2715
    Episode_Reward/rotating_object: 1.1660
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 2.10s
                      Time elapsed: 00:03:33
                               ETA: 00:59:58

################################################################################
                      [1m Learning iteration 84/1500 [0m                      

                       Computation: 47359 steps/s (collection: 1.967s, learning 0.109s)
             Mean action noise std: 1.28
          Mean value_function loss: 2.3416
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 51.6837
                       Mean reward: 14.20
               Mean episode length: 242.74
    Episode_Reward/reaching_object: 1.2341
    Episode_Reward/rotating_object: 1.4511
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 2.08s
                      Time elapsed: 00:03:35
                               ETA: 00:59:48

################################################################################
                      [1m Learning iteration 85/1500 [0m                      

                       Computation: 47841 steps/s (collection: 1.912s, learning 0.143s)
             Mean action noise std: 1.29
          Mean value_function loss: 2.8212
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 51.7832
                       Mean reward: 14.53
               Mean episode length: 243.30
    Episode_Reward/reaching_object: 1.2405
    Episode_Reward/rotating_object: 1.5965
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 2.05s
                      Time elapsed: 00:03:37
                               ETA: 00:59:37

################################################################################
                      [1m Learning iteration 86/1500 [0m                      

                       Computation: 44036 steps/s (collection: 2.043s, learning 0.189s)
             Mean action noise std: 1.29
          Mean value_function loss: 2.4594
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 51.8764
                       Mean reward: 14.91
               Mean episode length: 245.55
    Episode_Reward/reaching_object: 1.2643
    Episode_Reward/rotating_object: 1.8761
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 2.23s
                      Time elapsed: 00:03:39
                               ETA: 00:59:30

################################################################################
                      [1m Learning iteration 87/1500 [0m                      

                       Computation: 45909 steps/s (collection: 1.980s, learning 0.162s)
             Mean action noise std: 1.30
          Mean value_function loss: 2.8465
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 51.9859
                       Mean reward: 12.33
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 1.2398
    Episode_Reward/rotating_object: 1.8400
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 2.14s
                      Time elapsed: 00:03:41
                               ETA: 00:59:21

################################################################################
                      [1m Learning iteration 88/1500 [0m                      

                       Computation: 47025 steps/s (collection: 1.987s, learning 0.103s)
             Mean action noise std: 1.30
          Mean value_function loss: 3.2693
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 52.0682
                       Mean reward: 22.48
               Mean episode length: 246.27
    Episode_Reward/reaching_object: 1.2064
    Episode_Reward/rotating_object: 1.8824
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 2.09s
                      Time elapsed: 00:03:43
                               ETA: 00:59:12

################################################################################
                      [1m Learning iteration 89/1500 [0m                      

                       Computation: 48344 steps/s (collection: 1.944s, learning 0.090s)
             Mean action noise std: 1.30
          Mean value_function loss: 3.2288
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 52.1374
                       Mean reward: 14.67
               Mean episode length: 244.89
    Episode_Reward/reaching_object: 1.2547
    Episode_Reward/rotating_object: 2.0545
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 2.03s
                      Time elapsed: 00:03:45
                               ETA: 00:59:02

################################################################################
                      [1m Learning iteration 90/1500 [0m                      

                       Computation: 48235 steps/s (collection: 1.944s, learning 0.094s)
             Mean action noise std: 1.31
          Mean value_function loss: 3.2744
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 52.2557
                       Mean reward: 15.64
               Mean episode length: 246.94
    Episode_Reward/reaching_object: 1.2743
    Episode_Reward/rotating_object: 1.8502
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 2.04s
                      Time elapsed: 00:03:47
                               ETA: 00:58:52

################################################################################
                      [1m Learning iteration 91/1500 [0m                      

                       Computation: 46695 steps/s (collection: 2.013s, learning 0.093s)
             Mean action noise std: 1.31
          Mean value_function loss: 3.1986
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 52.3929
                       Mean reward: 15.13
               Mean episode length: 240.08
    Episode_Reward/reaching_object: 1.2437
    Episode_Reward/rotating_object: 2.2283
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 2.11s
                      Time elapsed: 00:03:50
                               ETA: 00:58:44

################################################################################
                      [1m Learning iteration 92/1500 [0m                      

                       Computation: 48060 steps/s (collection: 1.945s, learning 0.100s)
             Mean action noise std: 1.32
          Mean value_function loss: 3.7302
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 52.4896
                       Mean reward: 14.19
               Mean episode length: 246.02
    Episode_Reward/reaching_object: 1.2337
    Episode_Reward/rotating_object: 2.4476
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 2.05s
                      Time elapsed: 00:03:52
                               ETA: 00:58:34

################################################################################
                      [1m Learning iteration 93/1500 [0m                      

                       Computation: 45332 steps/s (collection: 2.075s, learning 0.094s)
             Mean action noise std: 1.32
          Mean value_function loss: 4.1059
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 52.6098
                       Mean reward: 13.89
               Mean episode length: 247.08
    Episode_Reward/reaching_object: 1.2097
    Episode_Reward/rotating_object: 2.2047
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 2.17s
                      Time elapsed: 00:03:54
                               ETA: 00:58:27

################################################################################
                      [1m Learning iteration 94/1500 [0m                      

                       Computation: 46012 steps/s (collection: 2.034s, learning 0.103s)
             Mean action noise std: 1.33
          Mean value_function loss: 3.4120
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 52.7290
                       Mean reward: 17.93
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 1.2253
    Episode_Reward/rotating_object: 2.8941
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 2.14s
                      Time elapsed: 00:03:56
                               ETA: 00:58:19

################################################################################
                      [1m Learning iteration 95/1500 [0m                      

                       Computation: 46584 steps/s (collection: 1.961s, learning 0.150s)
             Mean action noise std: 1.33
          Mean value_function loss: 3.0884
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 52.8478
                       Mean reward: 17.87
               Mean episode length: 245.90
    Episode_Reward/reaching_object: 1.1621
    Episode_Reward/rotating_object: 2.3334
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 2.11s
                      Time elapsed: 00:03:58
                               ETA: 00:58:11

################################################################################
                      [1m Learning iteration 96/1500 [0m                      

                       Computation: 46650 steps/s (collection: 2.008s, learning 0.100s)
             Mean action noise std: 1.34
          Mean value_function loss: 3.6500
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 52.9054
                       Mean reward: 16.26
               Mean episode length: 245.04
    Episode_Reward/reaching_object: 1.1880
    Episode_Reward/rotating_object: 2.4686
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 2.11s
                      Time elapsed: 00:04:00
                               ETA: 00:58:03

################################################################################
                      [1m Learning iteration 97/1500 [0m                      

                       Computation: 46073 steps/s (collection: 2.026s, learning 0.107s)
             Mean action noise std: 1.34
          Mean value_function loss: 3.9472
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 52.9991
                       Mean reward: 16.99
               Mean episode length: 244.05
    Episode_Reward/reaching_object: 1.1679
    Episode_Reward/rotating_object: 2.3219
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 2.13s
                      Time elapsed: 00:04:02
                               ETA: 00:57:56

################################################################################
                      [1m Learning iteration 98/1500 [0m                      

                       Computation: 46570 steps/s (collection: 1.994s, learning 0.117s)
             Mean action noise std: 1.34
          Mean value_function loss: 4.3856
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 53.0729
                       Mean reward: 20.75
               Mean episode length: 244.95
    Episode_Reward/reaching_object: 1.2145
    Episode_Reward/rotating_object: 2.2278
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 2.11s
                      Time elapsed: 00:04:04
                               ETA: 00:57:48

################################################################################
                      [1m Learning iteration 99/1500 [0m                      

                       Computation: 48299 steps/s (collection: 1.943s, learning 0.092s)
             Mean action noise std: 1.35
          Mean value_function loss: 3.9266
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.1465
                       Mean reward: 14.63
               Mean episode length: 245.15
    Episode_Reward/reaching_object: 1.1878
    Episode_Reward/rotating_object: 3.0675
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 2.04s
                      Time elapsed: 00:04:06
                               ETA: 00:57:39

################################################################################
                     [1m Learning iteration 100/1500 [0m                      

                       Computation: 46880 steps/s (collection: 1.985s, learning 0.111s)
             Mean action noise std: 1.35
          Mean value_function loss: 4.2746
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 53.2213
                       Mean reward: 15.82
               Mean episode length: 243.08
    Episode_Reward/reaching_object: 1.2224
    Episode_Reward/rotating_object: 2.6235
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 2.10s
                      Time elapsed: 00:04:09
                               ETA: 00:57:32

################################################################################
                     [1m Learning iteration 101/1500 [0m                      

                       Computation: 46557 steps/s (collection: 2.015s, learning 0.096s)
             Mean action noise std: 1.35
          Mean value_function loss: 4.5290
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 53.3131
                       Mean reward: 19.19
               Mean episode length: 242.17
    Episode_Reward/reaching_object: 1.1698
    Episode_Reward/rotating_object: 3.1469
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 2.11s
                      Time elapsed: 00:04:11
                               ETA: 00:57:24

################################################################################
                     [1m Learning iteration 102/1500 [0m                      

                       Computation: 48273 steps/s (collection: 1.944s, learning 0.093s)
             Mean action noise std: 1.36
          Mean value_function loss: 4.4105
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 53.4092
                       Mean reward: 20.32
               Mean episode length: 241.29
    Episode_Reward/reaching_object: 1.1963
    Episode_Reward/rotating_object: 2.8835
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 2.04s
                      Time elapsed: 00:04:13
                               ETA: 00:57:16

################################################################################
                     [1m Learning iteration 103/1500 [0m                      

                       Computation: 47722 steps/s (collection: 1.964s, learning 0.096s)
             Mean action noise std: 1.36
          Mean value_function loss: 5.0626
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 53.5219
                       Mean reward: 16.49
               Mean episode length: 239.18
    Episode_Reward/reaching_object: 1.1837
    Episode_Reward/rotating_object: 2.4189
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 2.06s
                      Time elapsed: 00:04:15
                               ETA: 00:57:08

################################################################################
                     [1m Learning iteration 104/1500 [0m                      

                       Computation: 45634 steps/s (collection: 1.981s, learning 0.173s)
             Mean action noise std: 1.37
          Mean value_function loss: 5.5119
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 53.6116
                       Mean reward: 18.57
               Mean episode length: 238.25
    Episode_Reward/reaching_object: 1.1795
    Episode_Reward/rotating_object: 2.5275
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 2.15s
                      Time elapsed: 00:04:17
                               ETA: 00:57:02

################################################################################
                     [1m Learning iteration 105/1500 [0m                      

                       Computation: 45631 steps/s (collection: 2.051s, learning 0.103s)
             Mean action noise std: 1.37
          Mean value_function loss: 5.1914
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 53.6723
                       Mean reward: 19.58
               Mean episode length: 240.94
    Episode_Reward/reaching_object: 1.2135
    Episode_Reward/rotating_object: 3.2064
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 2.15s
                      Time elapsed: 00:04:19
                               ETA: 00:56:55

################################################################################
                     [1m Learning iteration 106/1500 [0m                      

                       Computation: 46118 steps/s (collection: 1.973s, learning 0.159s)
             Mean action noise std: 1.37
          Mean value_function loss: 5.5846
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 53.7414
                       Mean reward: 17.75
               Mean episode length: 238.25
    Episode_Reward/reaching_object: 1.2433
    Episode_Reward/rotating_object: 2.7890
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 2.13s
                      Time elapsed: 00:04:21
                               ETA: 00:56:49

################################################################################
                     [1m Learning iteration 107/1500 [0m                      

                       Computation: 45225 steps/s (collection: 2.050s, learning 0.123s)
             Mean action noise std: 1.38
          Mean value_function loss: 5.4973
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 53.8223
                       Mean reward: 19.57
               Mean episode length: 240.84
    Episode_Reward/reaching_object: 1.1564
    Episode_Reward/rotating_object: 3.2843
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 2.17s
                      Time elapsed: 00:04:23
                               ETA: 00:56:43

################################################################################
                     [1m Learning iteration 108/1500 [0m                      

                       Computation: 46565 steps/s (collection: 2.015s, learning 0.097s)
             Mean action noise std: 1.38
          Mean value_function loss: 5.1295
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 53.9035
                       Mean reward: 12.90
               Mean episode length: 232.55
    Episode_Reward/reaching_object: 1.1592
    Episode_Reward/rotating_object: 2.5815
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 2.11s
                      Time elapsed: 00:04:25
                               ETA: 00:56:36

################################################################################
                     [1m Learning iteration 109/1500 [0m                      

                       Computation: 48632 steps/s (collection: 1.931s, learning 0.090s)
             Mean action noise std: 1.38
          Mean value_function loss: 5.3205
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 53.9706
                       Mean reward: 21.56
               Mean episode length: 244.90
    Episode_Reward/reaching_object: 1.1736
    Episode_Reward/rotating_object: 3.4568
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 2.02s
                      Time elapsed: 00:04:27
                               ETA: 00:56:28

################################################################################
                     [1m Learning iteration 110/1500 [0m                      

                       Computation: 47838 steps/s (collection: 1.962s, learning 0.093s)
             Mean action noise std: 1.39
          Mean value_function loss: 4.9458
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 54.0456
                       Mean reward: 21.00
               Mean episode length: 237.67
    Episode_Reward/reaching_object: 1.1993
    Episode_Reward/rotating_object: 2.9887
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 2.05s
                      Time elapsed: 00:04:30
                               ETA: 00:56:21

################################################################################
                     [1m Learning iteration 111/1500 [0m                      

                       Computation: 48608 steps/s (collection: 1.918s, learning 0.104s)
             Mean action noise std: 1.39
          Mean value_function loss: 5.6329
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 54.1226
                       Mean reward: 28.14
               Mean episode length: 241.12
    Episode_Reward/reaching_object: 1.2255
    Episode_Reward/rotating_object: 3.6822
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 2.02s
                      Time elapsed: 00:04:32
                               ETA: 00:56:14

################################################################################
                     [1m Learning iteration 112/1500 [0m                      

                       Computation: 47922 steps/s (collection: 1.957s, learning 0.094s)
             Mean action noise std: 1.39
          Mean value_function loss: 5.4953
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 54.1899
                       Mean reward: 16.49
               Mean episode length: 244.03
    Episode_Reward/reaching_object: 1.1577
    Episode_Reward/rotating_object: 2.5206
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 2.05s
                      Time elapsed: 00:04:34
                               ETA: 00:56:07

################################################################################
                     [1m Learning iteration 113/1500 [0m                      

                       Computation: 48647 steps/s (collection: 1.926s, learning 0.095s)
             Mean action noise std: 1.40
          Mean value_function loss: 5.5616
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 54.2592
                       Mean reward: 19.67
               Mean episode length: 238.67
    Episode_Reward/reaching_object: 1.2219
    Episode_Reward/rotating_object: 2.8649
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 2.02s
                      Time elapsed: 00:04:36
                               ETA: 00:55:59

################################################################################
                     [1m Learning iteration 114/1500 [0m                      

                       Computation: 48497 steps/s (collection: 1.933s, learning 0.094s)
             Mean action noise std: 1.40
          Mean value_function loss: 6.1356
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 54.3307
                       Mean reward: 22.33
               Mean episode length: 236.30
    Episode_Reward/reaching_object: 1.2043
    Episode_Reward/rotating_object: 3.1472
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 2.03s
                      Time elapsed: 00:04:38
                               ETA: 00:55:52

################################################################################
                     [1m Learning iteration 115/1500 [0m                      

                       Computation: 47643 steps/s (collection: 1.967s, learning 0.097s)
             Mean action noise std: 1.40
          Mean value_function loss: 7.3923
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 54.4129
                       Mean reward: 19.52
               Mean episode length: 236.47
    Episode_Reward/reaching_object: 1.1737
    Episode_Reward/rotating_object: 2.5739
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 2.06s
                      Time elapsed: 00:04:40
                               ETA: 00:55:45

################################################################################
                     [1m Learning iteration 116/1500 [0m                      

                       Computation: 47976 steps/s (collection: 1.956s, learning 0.093s)
             Mean action noise std: 1.41
          Mean value_function loss: 7.9114
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 54.4792
                       Mean reward: 20.25
               Mean episode length: 240.65
    Episode_Reward/reaching_object: 1.1718
    Episode_Reward/rotating_object: 3.0977
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 2.05s
                      Time elapsed: 00:04:42
                               ETA: 00:55:39

################################################################################
                     [1m Learning iteration 117/1500 [0m                      

                       Computation: 48015 steps/s (collection: 1.955s, learning 0.092s)
             Mean action noise std: 1.41
          Mean value_function loss: 6.9030
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 54.5492
                       Mean reward: 28.31
               Mean episode length: 239.61
    Episode_Reward/reaching_object: 1.1934
    Episode_Reward/rotating_object: 3.8209
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 2.05s
                      Time elapsed: 00:04:44
                               ETA: 00:55:32

################################################################################
                     [1m Learning iteration 118/1500 [0m                      

                       Computation: 48433 steps/s (collection: 1.936s, learning 0.094s)
             Mean action noise std: 1.41
          Mean value_function loss: 7.1761
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 54.6222
                       Mean reward: 18.52
               Mean episode length: 239.98
    Episode_Reward/reaching_object: 1.1527
    Episode_Reward/rotating_object: 3.6492
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 2.03s
                      Time elapsed: 00:04:46
                               ETA: 00:55:25

################################################################################
                     [1m Learning iteration 119/1500 [0m                      

                       Computation: 46028 steps/s (collection: 2.047s, learning 0.089s)
             Mean action noise std: 1.42
          Mean value_function loss: 8.6779
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 54.6996
                       Mean reward: 21.36
               Mean episode length: 230.65
    Episode_Reward/reaching_object: 1.1530
    Episode_Reward/rotating_object: 3.0895
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 2.14s
                      Time elapsed: 00:04:48
                               ETA: 00:55:20

################################################################################
                     [1m Learning iteration 120/1500 [0m                      

                       Computation: 47937 steps/s (collection: 1.956s, learning 0.094s)
             Mean action noise std: 1.42
          Mean value_function loss: 10.4820
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 54.7539
                       Mean reward: 20.10
               Mean episode length: 239.03
    Episode_Reward/reaching_object: 1.1844
    Episode_Reward/rotating_object: 3.3556
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 2.05s
                      Time elapsed: 00:04:50
                               ETA: 00:55:13

################################################################################
                     [1m Learning iteration 121/1500 [0m                      

                       Computation: 48827 steps/s (collection: 1.916s, learning 0.098s)
             Mean action noise std: 1.42
          Mean value_function loss: 8.1284
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 54.7904
                       Mean reward: 22.64
               Mean episode length: 242.08
    Episode_Reward/reaching_object: 1.1498
    Episode_Reward/rotating_object: 3.2576
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 2.01s
                      Time elapsed: 00:04:52
                               ETA: 00:55:06

################################################################################
                     [1m Learning iteration 122/1500 [0m                      

                       Computation: 44782 steps/s (collection: 2.047s, learning 0.148s)
             Mean action noise std: 1.42
          Mean value_function loss: 8.5765
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 54.8576
                       Mean reward: 20.17
               Mean episode length: 230.01
    Episode_Reward/reaching_object: 1.1406
    Episode_Reward/rotating_object: 3.1425
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 2.20s
                      Time elapsed: 00:04:54
                               ETA: 00:55:02

################################################################################
                     [1m Learning iteration 123/1500 [0m                      

                       Computation: 46738 steps/s (collection: 1.991s, learning 0.112s)
             Mean action noise std: 1.43
          Mean value_function loss: 10.8376
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 54.9182
                       Mean reward: 25.50
               Mean episode length: 237.23
    Episode_Reward/reaching_object: 1.1514
    Episode_Reward/rotating_object: 4.2594
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 2.10s
                      Time elapsed: 00:04:56
                               ETA: 00:54:56

################################################################################
                     [1m Learning iteration 124/1500 [0m                      

                       Computation: 45646 steps/s (collection: 1.994s, learning 0.159s)
             Mean action noise std: 1.43
          Mean value_function loss: 9.6558
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 54.9659
                       Mean reward: 20.30
               Mean episode length: 230.43
    Episode_Reward/reaching_object: 1.1423
    Episode_Reward/rotating_object: 3.5826
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 2.15s
                      Time elapsed: 00:04:59
                               ETA: 00:54:51

################################################################################
                     [1m Learning iteration 125/1500 [0m                      

                       Computation: 47099 steps/s (collection: 1.977s, learning 0.110s)
             Mean action noise std: 1.43
          Mean value_function loss: 9.9638
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 55.0365
                       Mean reward: 20.56
               Mean episode length: 235.22
    Episode_Reward/reaching_object: 1.1108
    Episode_Reward/rotating_object: 4.4389
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 2.09s
                      Time elapsed: 00:05:01
                               ETA: 00:54:45

################################################################################
                     [1m Learning iteration 126/1500 [0m                      

                       Computation: 48838 steps/s (collection: 1.910s, learning 0.103s)
             Mean action noise std: 1.43
          Mean value_function loss: 10.7808
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 55.1054
                       Mean reward: 23.45
               Mean episode length: 234.01
    Episode_Reward/reaching_object: 1.1092
    Episode_Reward/rotating_object: 4.0106
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 2.01s
                      Time elapsed: 00:05:03
                               ETA: 00:54:39

################################################################################
                     [1m Learning iteration 127/1500 [0m                      

                       Computation: 48025 steps/s (collection: 1.945s, learning 0.102s)
             Mean action noise std: 1.44
          Mean value_function loss: 9.0765
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 55.1806
                       Mean reward: 26.97
               Mean episode length: 235.31
    Episode_Reward/reaching_object: 1.1020
    Episode_Reward/rotating_object: 4.4391
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 2.05s
                      Time elapsed: 00:05:05
                               ETA: 00:54:33

################################################################################
                     [1m Learning iteration 128/1500 [0m                      

                       Computation: 48023 steps/s (collection: 1.951s, learning 0.096s)
             Mean action noise std: 1.44
          Mean value_function loss: 11.9889
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 55.2569
                       Mean reward: 31.20
               Mean episode length: 244.37
    Episode_Reward/reaching_object: 1.1012
    Episode_Reward/rotating_object: 4.0705
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 2.05s
                      Time elapsed: 00:05:07
                               ETA: 00:54:27

################################################################################
                     [1m Learning iteration 129/1500 [0m                      

                       Computation: 49049 steps/s (collection: 1.913s, learning 0.092s)
             Mean action noise std: 1.44
          Mean value_function loss: 12.6173
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 55.3219
                       Mean reward: 32.37
               Mean episode length: 237.32
    Episode_Reward/reaching_object: 1.1072
    Episode_Reward/rotating_object: 3.8396
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 2.00s
                      Time elapsed: 00:05:09
                               ETA: 00:54:21

################################################################################
                     [1m Learning iteration 130/1500 [0m                      

                       Computation: 48057 steps/s (collection: 1.953s, learning 0.093s)
             Mean action noise std: 1.45
          Mean value_function loss: 12.6377
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 55.3963
                       Mean reward: 19.64
               Mean episode length: 234.82
    Episode_Reward/reaching_object: 1.0662
    Episode_Reward/rotating_object: 4.1402
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 2.05s
                      Time elapsed: 00:05:11
                               ETA: 00:54:15

################################################################################
                     [1m Learning iteration 131/1500 [0m                      

                       Computation: 49158 steps/s (collection: 1.907s, learning 0.092s)
             Mean action noise std: 1.45
          Mean value_function loss: 12.1788
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 55.4685
                       Mean reward: 40.62
               Mean episode length: 239.47
    Episode_Reward/reaching_object: 1.1036
    Episode_Reward/rotating_object: 4.6543
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 2.00s
                      Time elapsed: 00:05:13
                               ETA: 00:54:08

################################################################################
                     [1m Learning iteration 132/1500 [0m                      

                       Computation: 47214 steps/s (collection: 1.970s, learning 0.113s)
             Mean action noise std: 1.46
          Mean value_function loss: 13.5257
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 55.5463
                       Mean reward: 31.64
               Mean episode length: 240.21
    Episode_Reward/reaching_object: 1.0338
    Episode_Reward/rotating_object: 4.4671
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 2.08s
                      Time elapsed: 00:05:15
                               ETA: 00:54:03

################################################################################
                     [1m Learning iteration 133/1500 [0m                      

                       Computation: 48240 steps/s (collection: 1.946s, learning 0.092s)
             Mean action noise std: 1.46
          Mean value_function loss: 11.2551
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 55.6337
                       Mean reward: 18.61
               Mean episode length: 229.97
    Episode_Reward/reaching_object: 1.0439
    Episode_Reward/rotating_object: 3.6953
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 2.04s
                      Time elapsed: 00:05:17
                               ETA: 00:53:57

################################################################################
                     [1m Learning iteration 134/1500 [0m                      

                       Computation: 48287 steps/s (collection: 1.939s, learning 0.097s)
             Mean action noise std: 1.46
          Mean value_function loss: 11.3929
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 55.7116
                       Mean reward: 33.43
               Mean episode length: 235.80
    Episode_Reward/reaching_object: 1.1021
    Episode_Reward/rotating_object: 4.7235
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 2.04s
                      Time elapsed: 00:05:19
                               ETA: 00:53:51

################################################################################
                     [1m Learning iteration 135/1500 [0m                      

                       Computation: 48975 steps/s (collection: 1.913s, learning 0.095s)
             Mean action noise std: 1.47
          Mean value_function loss: 9.8259
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 55.7800
                       Mean reward: 27.41
               Mean episode length: 227.60
    Episode_Reward/reaching_object: 1.0518
    Episode_Reward/rotating_object: 4.4106
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 2.01s
                      Time elapsed: 00:05:21
                               ETA: 00:53:46

################################################################################
                     [1m Learning iteration 136/1500 [0m                      

                       Computation: 48683 steps/s (collection: 1.926s, learning 0.094s)
             Mean action noise std: 1.47
          Mean value_function loss: 9.1698
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 55.8371
                       Mean reward: 26.13
               Mean episode length: 222.97
    Episode_Reward/reaching_object: 1.0020
    Episode_Reward/rotating_object: 4.3970
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 2.02s
                      Time elapsed: 00:05:23
                               ETA: 00:53:40

################################################################################
                     [1m Learning iteration 137/1500 [0m                      

                       Computation: 48184 steps/s (collection: 1.941s, learning 0.099s)
             Mean action noise std: 1.47
          Mean value_function loss: 10.0918
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 55.8920
                       Mean reward: 29.72
               Mean episode length: 231.27
    Episode_Reward/reaching_object: 1.0179
    Episode_Reward/rotating_object: 5.2879
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 2.04s
                      Time elapsed: 00:05:25
                               ETA: 00:53:34

################################################################################
                     [1m Learning iteration 138/1500 [0m                      

                       Computation: 47831 steps/s (collection: 1.962s, learning 0.093s)
             Mean action noise std: 1.47
          Mean value_function loss: 9.7321
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 55.9505
                       Mean reward: 35.85
               Mean episode length: 230.09
    Episode_Reward/reaching_object: 1.0499
    Episode_Reward/rotating_object: 4.9759
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 2.06s
                      Time elapsed: 00:05:27
                               ETA: 00:53:29

################################################################################
                     [1m Learning iteration 139/1500 [0m                      

                       Computation: 48243 steps/s (collection: 1.931s, learning 0.107s)
             Mean action noise std: 1.48
          Mean value_function loss: 10.3232
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 55.9999
                       Mean reward: 30.63
               Mean episode length: 228.37
    Episode_Reward/reaching_object: 1.0053
    Episode_Reward/rotating_object: 4.6114
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 2.04s
                      Time elapsed: 00:05:29
                               ETA: 00:53:23

################################################################################
                     [1m Learning iteration 140/1500 [0m                      

                       Computation: 48797 steps/s (collection: 1.922s, learning 0.093s)
             Mean action noise std: 1.48
          Mean value_function loss: 12.1932
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 56.0475
                       Mean reward: 18.61
               Mean episode length: 227.93
    Episode_Reward/reaching_object: 0.9722
    Episode_Reward/rotating_object: 4.0790
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 2.01s
                      Time elapsed: 00:05:31
                               ETA: 00:53:18

################################################################################
                     [1m Learning iteration 141/1500 [0m                      

                       Computation: 46894 steps/s (collection: 1.993s, learning 0.104s)
             Mean action noise std: 1.48
          Mean value_function loss: 11.3166
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 56.0996
                       Mean reward: 26.14
               Mean episode length: 235.44
    Episode_Reward/reaching_object: 1.0369
    Episode_Reward/rotating_object: 4.7425
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 2.10s
                      Time elapsed: 00:05:33
                               ETA: 00:53:13

################################################################################
                     [1m Learning iteration 142/1500 [0m                      

                       Computation: 49092 steps/s (collection: 1.898s, learning 0.104s)
             Mean action noise std: 1.49
          Mean value_function loss: 11.0653
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 56.1776
                       Mean reward: 20.44
               Mean episode length: 232.94
    Episode_Reward/reaching_object: 0.9738
    Episode_Reward/rotating_object: 4.3369
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 2.00s
                      Time elapsed: 00:05:35
                               ETA: 00:53:07

################################################################################
                     [1m Learning iteration 143/1500 [0m                      

                       Computation: 48146 steps/s (collection: 1.947s, learning 0.095s)
             Mean action noise std: 1.49
          Mean value_function loss: 12.4907
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 56.2507
                       Mean reward: 16.81
               Mean episode length: 232.24
    Episode_Reward/reaching_object: 0.9676
    Episode_Reward/rotating_object: 4.1673
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 2.04s
                      Time elapsed: 00:05:37
                               ETA: 00:53:02

################################################################################
                     [1m Learning iteration 144/1500 [0m                      

                       Computation: 48444 steps/s (collection: 1.934s, learning 0.095s)
             Mean action noise std: 1.49
          Mean value_function loss: 11.7059
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 56.3346
                       Mean reward: 20.84
               Mean episode length: 225.42
    Episode_Reward/reaching_object: 0.9363
    Episode_Reward/rotating_object: 3.1923
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 2.03s
                      Time elapsed: 00:05:39
                               ETA: 00:52:57

################################################################################
                     [1m Learning iteration 145/1500 [0m                      

                       Computation: 48171 steps/s (collection: 1.941s, learning 0.099s)
             Mean action noise std: 1.50
          Mean value_function loss: 12.6020
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 56.4090
                       Mean reward: 23.07
               Mean episode length: 238.15
    Episode_Reward/reaching_object: 0.9635
    Episode_Reward/rotating_object: 4.4774
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 2.04s
                      Time elapsed: 00:05:41
                               ETA: 00:52:52

################################################################################
                     [1m Learning iteration 146/1500 [0m                      

                       Computation: 46881 steps/s (collection: 1.997s, learning 0.100s)
             Mean action noise std: 1.50
          Mean value_function loss: 12.3667
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 56.4840
                       Mean reward: 28.29
               Mean episode length: 225.69
    Episode_Reward/reaching_object: 0.9356
    Episode_Reward/rotating_object: 4.4411
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 2.10s
                      Time elapsed: 00:05:43
                               ETA: 00:52:47

################################################################################
                     [1m Learning iteration 147/1500 [0m                      

                       Computation: 47952 steps/s (collection: 1.892s, learning 0.158s)
             Mean action noise std: 1.50
          Mean value_function loss: 13.2670
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 56.5428
                       Mean reward: 26.49
               Mean episode length: 233.45
    Episode_Reward/reaching_object: 0.9742
    Episode_Reward/rotating_object: 5.0668
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 2.05s
                      Time elapsed: 00:05:45
                               ETA: 00:52:42

################################################################################
                     [1m Learning iteration 148/1500 [0m                      

                       Computation: 47629 steps/s (collection: 1.918s, learning 0.146s)
             Mean action noise std: 1.50
          Mean value_function loss: 13.3342
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 56.5976
                       Mean reward: 20.31
               Mean episode length: 224.53
    Episode_Reward/reaching_object: 0.9375
    Episode_Reward/rotating_object: 4.4387
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 2.06s
                      Time elapsed: 00:05:48
                               ETA: 00:52:37

################################################################################
                     [1m Learning iteration 149/1500 [0m                      

                       Computation: 47712 steps/s (collection: 1.949s, learning 0.111s)
             Mean action noise std: 1.51
          Mean value_function loss: 12.2232
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 56.6424
                       Mean reward: 28.54
               Mean episode length: 233.03
    Episode_Reward/reaching_object: 0.9572
    Episode_Reward/rotating_object: 4.4767
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 2.06s
                      Time elapsed: 00:05:50
                               ETA: 00:52:32

################################################################################
                     [1m Learning iteration 150/1500 [0m                      

                       Computation: 47486 steps/s (collection: 1.912s, learning 0.158s)
             Mean action noise std: 1.51
          Mean value_function loss: 12.7131
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 56.7016
                       Mean reward: 39.75
               Mean episode length: 230.60
    Episode_Reward/reaching_object: 0.9416
    Episode_Reward/rotating_object: 4.6212
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 2.07s
                      Time elapsed: 00:05:52
                               ETA: 00:52:28

################################################################################
                     [1m Learning iteration 151/1500 [0m                      

                       Computation: 47759 steps/s (collection: 1.963s, learning 0.095s)
             Mean action noise std: 1.51
          Mean value_function loss: 13.4220
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 56.7427
                       Mean reward: 35.70
               Mean episode length: 232.96
    Episode_Reward/reaching_object: 0.9466
    Episode_Reward/rotating_object: 4.6942
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 2.06s
                      Time elapsed: 00:05:54
                               ETA: 00:52:23

################################################################################
                     [1m Learning iteration 152/1500 [0m                      

                       Computation: 49167 steps/s (collection: 1.909s, learning 0.091s)
             Mean action noise std: 1.51
          Mean value_function loss: 14.5983
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 56.7937
                       Mean reward: 32.07
               Mean episode length: 228.90
    Episode_Reward/reaching_object: 0.9860
    Episode_Reward/rotating_object: 5.4084
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 2.00s
                      Time elapsed: 00:05:56
                               ETA: 00:52:18

################################################################################
                     [1m Learning iteration 153/1500 [0m                      

                       Computation: 46990 steps/s (collection: 1.970s, learning 0.122s)
             Mean action noise std: 1.52
          Mean value_function loss: 13.4577
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 56.8330
                       Mean reward: 38.90
               Mean episode length: 230.41
    Episode_Reward/reaching_object: 1.0083
    Episode_Reward/rotating_object: 5.2473
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 2.09s
                      Time elapsed: 00:05:58
                               ETA: 00:52:13

################################################################################
                     [1m Learning iteration 154/1500 [0m                      

                       Computation: 47758 steps/s (collection: 1.942s, learning 0.117s)
             Mean action noise std: 1.52
          Mean value_function loss: 13.6146
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 56.8856
                       Mean reward: 37.69
               Mean episode length: 232.31
    Episode_Reward/reaching_object: 1.0179
    Episode_Reward/rotating_object: 5.3075
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 2.06s
                      Time elapsed: 00:06:00
                               ETA: 00:52:09

################################################################################
                     [1m Learning iteration 155/1500 [0m                      

                       Computation: 48015 steps/s (collection: 1.945s, learning 0.103s)
             Mean action noise std: 1.52
          Mean value_function loss: 17.1881
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 56.9349
                       Mean reward: 30.56
               Mean episode length: 233.98
    Episode_Reward/reaching_object: 1.0154
    Episode_Reward/rotating_object: 5.2014
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 2.05s
                      Time elapsed: 00:06:02
                               ETA: 00:52:04

################################################################################
                     [1m Learning iteration 156/1500 [0m                      

                       Computation: 48087 steps/s (collection: 1.945s, learning 0.100s)
             Mean action noise std: 1.53
          Mean value_function loss: 15.2795
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 56.9984
                       Mean reward: 31.78
               Mean episode length: 229.05
    Episode_Reward/reaching_object: 0.9945
    Episode_Reward/rotating_object: 5.7574
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 2.04s
                      Time elapsed: 00:06:04
                               ETA: 00:51:59

################################################################################
                     [1m Learning iteration 157/1500 [0m                      

                       Computation: 48143 steps/s (collection: 1.941s, learning 0.101s)
             Mean action noise std: 1.53
          Mean value_function loss: 16.1683
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 57.0671
                       Mean reward: 25.63
               Mean episode length: 229.22
    Episode_Reward/reaching_object: 1.0020
    Episode_Reward/rotating_object: 5.1252
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 2.04s
                      Time elapsed: 00:06:06
                               ETA: 00:51:55

################################################################################
                     [1m Learning iteration 158/1500 [0m                      

                       Computation: 46273 steps/s (collection: 2.020s, learning 0.105s)
             Mean action noise std: 1.53
          Mean value_function loss: 15.7597
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 57.1264
                       Mean reward: 22.29
               Mean episode length: 226.35
    Episode_Reward/reaching_object: 1.0287
    Episode_Reward/rotating_object: 5.6499
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 2.12s
                      Time elapsed: 00:06:08
                               ETA: 00:51:51

################################################################################
                     [1m Learning iteration 159/1500 [0m                      

                       Computation: 47669 steps/s (collection: 1.962s, learning 0.101s)
             Mean action noise std: 1.53
          Mean value_function loss: 14.6380
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 57.1781
                       Mean reward: 34.08
               Mean episode length: 230.40
    Episode_Reward/reaching_object: 1.0450
    Episode_Reward/rotating_object: 5.7459
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 2.06s
                      Time elapsed: 00:06:10
                               ETA: 00:51:46

################################################################################
                     [1m Learning iteration 160/1500 [0m                      

                       Computation: 47106 steps/s (collection: 1.965s, learning 0.122s)
             Mean action noise std: 1.54
          Mean value_function loss: 15.2238
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 57.2449
                       Mean reward: 24.16
               Mean episode length: 228.70
    Episode_Reward/reaching_object: 1.0433
    Episode_Reward/rotating_object: 6.7918
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 2.09s
                      Time elapsed: 00:06:12
                               ETA: 00:51:42

################################################################################
                     [1m Learning iteration 161/1500 [0m                      

                       Computation: 45395 steps/s (collection: 2.017s, learning 0.149s)
             Mean action noise std: 1.54
          Mean value_function loss: 16.9100
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 57.2976
                       Mean reward: 35.03
               Mean episode length: 231.12
    Episode_Reward/reaching_object: 1.0332
    Episode_Reward/rotating_object: 6.3304
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 2.17s
                      Time elapsed: 00:06:14
                               ETA: 00:51:38

################################################################################
                     [1m Learning iteration 162/1500 [0m                      

                       Computation: 48841 steps/s (collection: 1.924s, learning 0.089s)
             Mean action noise std: 1.54
          Mean value_function loss: 18.7965
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 57.3641
                       Mean reward: 26.22
               Mean episode length: 229.39
    Episode_Reward/reaching_object: 1.0339
    Episode_Reward/rotating_object: 5.8644
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 2.01s
                      Time elapsed: 00:06:16
                               ETA: 00:51:34

################################################################################
                     [1m Learning iteration 163/1500 [0m                      

                       Computation: 48560 steps/s (collection: 1.935s, learning 0.089s)
             Mean action noise std: 1.55
          Mean value_function loss: 17.6179
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 57.4164
                       Mean reward: 34.46
               Mean episode length: 223.45
    Episode_Reward/reaching_object: 1.0014
    Episode_Reward/rotating_object: 5.8681
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 2.02s
                      Time elapsed: 00:06:18
                               ETA: 00:51:29

################################################################################
                     [1m Learning iteration 164/1500 [0m                      

                       Computation: 46428 steps/s (collection: 2.020s, learning 0.098s)
             Mean action noise std: 1.55
          Mean value_function loss: 20.9709
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 57.4835
                       Mean reward: 31.87
               Mean episode length: 234.99
    Episode_Reward/reaching_object: 1.0520
    Episode_Reward/rotating_object: 5.8808
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 2.12s
                      Time elapsed: 00:06:21
                               ETA: 00:51:25

################################################################################
                     [1m Learning iteration 165/1500 [0m                      

                       Computation: 47436 steps/s (collection: 1.970s, learning 0.102s)
             Mean action noise std: 1.55
          Mean value_function loss: 21.3177
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 57.5417
                       Mean reward: 31.32
               Mean episode length: 233.23
    Episode_Reward/reaching_object: 1.0445
    Episode_Reward/rotating_object: 6.7612
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 2.07s
                      Time elapsed: 00:06:23
                               ETA: 00:51:21

################################################################################
                     [1m Learning iteration 166/1500 [0m                      

                       Computation: 47512 steps/s (collection: 1.963s, learning 0.106s)
             Mean action noise std: 1.56
          Mean value_function loss: 16.6465
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 57.6122
                       Mean reward: 27.95
               Mean episode length: 230.97
    Episode_Reward/reaching_object: 1.0644
    Episode_Reward/rotating_object: 6.4734
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 2.07s
                      Time elapsed: 00:06:25
                               ETA: 00:51:17

################################################################################
                     [1m Learning iteration 167/1500 [0m                      

                       Computation: 47194 steps/s (collection: 1.969s, learning 0.114s)
             Mean action noise std: 1.56
          Mean value_function loss: 14.1745
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 57.6717
                       Mean reward: 25.13
               Mean episode length: 226.34
    Episode_Reward/reaching_object: 1.0598
    Episode_Reward/rotating_object: 5.2266
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 2.08s
                      Time elapsed: 00:06:27
                               ETA: 00:51:13

################################################################################
                     [1m Learning iteration 168/1500 [0m                      

                       Computation: 47027 steps/s (collection: 1.992s, learning 0.098s)
             Mean action noise std: 1.56
          Mean value_function loss: 16.1723
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 57.7372
                       Mean reward: 34.14
               Mean episode length: 219.72
    Episode_Reward/reaching_object: 1.0544
    Episode_Reward/rotating_object: 5.9289
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 2.09s
                      Time elapsed: 00:06:29
                               ETA: 00:51:09

################################################################################
                     [1m Learning iteration 169/1500 [0m                      

                       Computation: 46129 steps/s (collection: 2.031s, learning 0.101s)
             Mean action noise std: 1.57
          Mean value_function loss: 16.4234
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 57.8109
                       Mean reward: 38.87
               Mean episode length: 234.21
    Episode_Reward/reaching_object: 1.0535
    Episode_Reward/rotating_object: 6.4828
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 2.13s
                      Time elapsed: 00:06:31
                               ETA: 00:51:05

################################################################################
                     [1m Learning iteration 170/1500 [0m                      

                       Computation: 46378 steps/s (collection: 2.018s, learning 0.102s)
             Mean action noise std: 1.57
          Mean value_function loss: 15.6822
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 57.8874
                       Mean reward: 20.99
               Mean episode length: 228.04
    Episode_Reward/reaching_object: 0.9990
    Episode_Reward/rotating_object: 4.7714
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 2.12s
                      Time elapsed: 00:06:33
                               ETA: 00:51:01

################################################################################
                     [1m Learning iteration 171/1500 [0m                      

                       Computation: 47734 steps/s (collection: 1.959s, learning 0.101s)
             Mean action noise std: 1.57
          Mean value_function loss: 14.5409
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 57.9518
                       Mean reward: 37.16
               Mean episode length: 231.31
    Episode_Reward/reaching_object: 1.0303
    Episode_Reward/rotating_object: 6.7502
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 2.06s
                      Time elapsed: 00:06:35
                               ETA: 00:50:57

################################################################################
                     [1m Learning iteration 172/1500 [0m                      

                       Computation: 46754 steps/s (collection: 1.999s, learning 0.104s)
             Mean action noise std: 1.58
          Mean value_function loss: 15.7195
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 58.0123
                       Mean reward: 30.59
               Mean episode length: 230.23
    Episode_Reward/reaching_object: 1.0594
    Episode_Reward/rotating_object: 7.1513
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 2.10s
                      Time elapsed: 00:06:37
                               ETA: 00:50:53

################################################################################
                     [1m Learning iteration 173/1500 [0m                      

                       Computation: 46608 steps/s (collection: 1.996s, learning 0.113s)
             Mean action noise std: 1.58
          Mean value_function loss: 18.4949
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 58.0639
                       Mean reward: 33.81
               Mean episode length: 225.14
    Episode_Reward/reaching_object: 1.0160
    Episode_Reward/rotating_object: 5.9911
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 2.11s
                      Time elapsed: 00:06:39
                               ETA: 00:50:49

################################################################################
                     [1m Learning iteration 174/1500 [0m                      

                       Computation: 47413 steps/s (collection: 1.972s, learning 0.102s)
             Mean action noise std: 1.58
          Mean value_function loss: 16.8021
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 58.1272
                       Mean reward: 20.38
               Mean episode length: 207.90
    Episode_Reward/reaching_object: 0.9833
    Episode_Reward/rotating_object: 5.4397
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 2.07s
                      Time elapsed: 00:06:41
                               ETA: 00:50:45

################################################################################
                     [1m Learning iteration 175/1500 [0m                      

                       Computation: 46773 steps/s (collection: 1.985s, learning 0.117s)
             Mean action noise std: 1.58
          Mean value_function loss: 16.5023
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 58.1816
                       Mean reward: 32.43
               Mean episode length: 225.05
    Episode_Reward/reaching_object: 1.0231
    Episode_Reward/rotating_object: 5.3677
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 2.10s
                      Time elapsed: 00:06:44
                               ETA: 00:50:42

################################################################################
                     [1m Learning iteration 176/1500 [0m                      

                       Computation: 46911 steps/s (collection: 1.970s, learning 0.126s)
             Mean action noise std: 1.59
          Mean value_function loss: 15.6226
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 58.2339
                       Mean reward: 24.99
               Mean episode length: 226.12
    Episode_Reward/reaching_object: 1.0080
    Episode_Reward/rotating_object: 5.2698
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 2.10s
                      Time elapsed: 00:06:46
                               ETA: 00:50:38

################################################################################
                     [1m Learning iteration 177/1500 [0m                      

                       Computation: 45761 steps/s (collection: 2.005s, learning 0.143s)
             Mean action noise std: 1.59
          Mean value_function loss: 15.9371
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 58.2787
                       Mean reward: 35.90
               Mean episode length: 227.10
    Episode_Reward/reaching_object: 1.0293
    Episode_Reward/rotating_object: 6.8438
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 2.15s
                      Time elapsed: 00:06:48
                               ETA: 00:50:34

################################################################################
                     [1m Learning iteration 178/1500 [0m                      

                       Computation: 46795 steps/s (collection: 1.954s, learning 0.147s)
             Mean action noise std: 1.59
          Mean value_function loss: 15.8654
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 58.3180
                       Mean reward: 39.12
               Mean episode length: 232.25
    Episode_Reward/reaching_object: 0.9981
    Episode_Reward/rotating_object: 6.0167
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 2.10s
                      Time elapsed: 00:06:50
                               ETA: 00:50:31

################################################################################
                     [1m Learning iteration 179/1500 [0m                      

                       Computation: 46431 steps/s (collection: 1.979s, learning 0.139s)
             Mean action noise std: 1.59
          Mean value_function loss: 17.0792
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 58.3589
                       Mean reward: 25.82
               Mean episode length: 223.23
    Episode_Reward/reaching_object: 1.0107
    Episode_Reward/rotating_object: 6.1432
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 2.12s
                      Time elapsed: 00:06:52
                               ETA: 00:50:27

################################################################################
                     [1m Learning iteration 180/1500 [0m                      

                       Computation: 48643 steps/s (collection: 1.896s, learning 0.125s)
             Mean action noise std: 1.60
          Mean value_function loss: 14.8625
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 58.4068
                       Mean reward: 33.62
               Mean episode length: 228.40
    Episode_Reward/reaching_object: 1.0320
    Episode_Reward/rotating_object: 6.8594
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 2.02s
                      Time elapsed: 00:06:54
                               ETA: 00:50:23

################################################################################
                     [1m Learning iteration 181/1500 [0m                      

                       Computation: 47743 steps/s (collection: 1.960s, learning 0.099s)
             Mean action noise std: 1.60
          Mean value_function loss: 17.0112
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 58.4718
                       Mean reward: 26.33
               Mean episode length: 216.53
    Episode_Reward/reaching_object: 0.9820
    Episode_Reward/rotating_object: 5.5549
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 2.06s
                      Time elapsed: 00:06:56
                               ETA: 00:50:19

################################################################################
                     [1m Learning iteration 182/1500 [0m                      

                       Computation: 46466 steps/s (collection: 2.013s, learning 0.103s)
             Mean action noise std: 1.60
          Mean value_function loss: 14.8677
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 58.5266
                       Mean reward: 36.17
               Mean episode length: 230.52
    Episode_Reward/reaching_object: 1.0190
    Episode_Reward/rotating_object: 6.1320
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 2.12s
                      Time elapsed: 00:06:58
                               ETA: 00:50:15

################################################################################
                     [1m Learning iteration 183/1500 [0m                      

                       Computation: 48115 steps/s (collection: 1.939s, learning 0.105s)
             Mean action noise std: 1.61
          Mean value_function loss: 16.0835
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 58.5796
                       Mean reward: 44.55
               Mean episode length: 225.57
    Episode_Reward/reaching_object: 0.9919
    Episode_Reward/rotating_object: 6.0508
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 2.04s
                      Time elapsed: 00:07:00
                               ETA: 00:50:11

################################################################################
                     [1m Learning iteration 184/1500 [0m                      

                       Computation: 46944 steps/s (collection: 1.980s, learning 0.114s)
             Mean action noise std: 1.61
          Mean value_function loss: 15.6508
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 58.6358
                       Mean reward: 41.87
               Mean episode length: 227.64
    Episode_Reward/reaching_object: 1.0027
    Episode_Reward/rotating_object: 6.3146
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 2.09s
                      Time elapsed: 00:07:02
                               ETA: 00:50:08

################################################################################
                     [1m Learning iteration 185/1500 [0m                      

                       Computation: 47300 steps/s (collection: 1.979s, learning 0.099s)
             Mean action noise std: 1.61
          Mean value_function loss: 16.6931
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 58.6785
                       Mean reward: 49.20
               Mean episode length: 235.39
    Episode_Reward/reaching_object: 1.0380
    Episode_Reward/rotating_object: 7.2409
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 2.08s
                      Time elapsed: 00:07:04
                               ETA: 00:50:04

################################################################################
                     [1m Learning iteration 186/1500 [0m                      

                       Computation: 48106 steps/s (collection: 1.939s, learning 0.104s)
             Mean action noise std: 1.61
          Mean value_function loss: 16.5767
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 58.7198
                       Mean reward: 34.58
               Mean episode length: 236.10
    Episode_Reward/reaching_object: 1.0095
    Episode_Reward/rotating_object: 5.4677
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 2.04s
                      Time elapsed: 00:07:07
                               ETA: 00:50:00

################################################################################
                     [1m Learning iteration 187/1500 [0m                      

                       Computation: 47802 steps/s (collection: 1.959s, learning 0.097s)
             Mean action noise std: 1.61
          Mean value_function loss: 16.8211
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 58.7632
                       Mean reward: 41.14
               Mean episode length: 222.32
    Episode_Reward/reaching_object: 0.9617
    Episode_Reward/rotating_object: 6.5689
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 2.06s
                      Time elapsed: 00:07:09
                               ETA: 00:49:56

################################################################################
                     [1m Learning iteration 188/1500 [0m                      

                       Computation: 48318 steps/s (collection: 1.937s, learning 0.098s)
             Mean action noise std: 1.62
          Mean value_function loss: 17.7863
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 58.8250
                       Mean reward: 31.88
               Mean episode length: 230.88
    Episode_Reward/reaching_object: 0.9966
    Episode_Reward/rotating_object: 5.5657
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 2.03s
                      Time elapsed: 00:07:11
                               ETA: 00:49:52

################################################################################
                     [1m Learning iteration 189/1500 [0m                      

                       Computation: 47365 steps/s (collection: 1.971s, learning 0.105s)
             Mean action noise std: 1.62
          Mean value_function loss: 17.2379
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 58.8869
                       Mean reward: 36.03
               Mean episode length: 222.31
    Episode_Reward/reaching_object: 0.9932
    Episode_Reward/rotating_object: 6.1308
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 2.08s
                      Time elapsed: 00:07:13
                               ETA: 00:49:48

################################################################################
                     [1m Learning iteration 190/1500 [0m                      

                       Computation: 48507 steps/s (collection: 1.927s, learning 0.100s)
             Mean action noise std: 1.62
          Mean value_function loss: 18.9688
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 58.9409
                       Mean reward: 49.18
               Mean episode length: 226.97
    Episode_Reward/reaching_object: 1.0057
    Episode_Reward/rotating_object: 5.8892
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 2.03s
                      Time elapsed: 00:07:15
                               ETA: 00:49:44

################################################################################
                     [1m Learning iteration 191/1500 [0m                      

                       Computation: 46079 steps/s (collection: 2.030s, learning 0.104s)
             Mean action noise std: 1.63
          Mean value_function loss: 17.4796
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 58.9887
                       Mean reward: 36.24
               Mean episode length: 229.08
    Episode_Reward/reaching_object: 0.9871
    Episode_Reward/rotating_object: 4.8678
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 2.13s
                      Time elapsed: 00:07:17
                               ETA: 00:49:41

################################################################################
                     [1m Learning iteration 192/1500 [0m                      

                       Computation: 46911 steps/s (collection: 1.996s, learning 0.100s)
             Mean action noise std: 1.63
          Mean value_function loss: 17.2930
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 59.0448
                       Mean reward: 44.72
               Mean episode length: 219.85
    Episode_Reward/reaching_object: 0.9957
    Episode_Reward/rotating_object: 6.7036
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 2.10s
                      Time elapsed: 00:07:19
                               ETA: 00:49:38

################################################################################
                     [1m Learning iteration 193/1500 [0m                      

                       Computation: 47118 steps/s (collection: 1.942s, learning 0.145s)
             Mean action noise std: 1.63
          Mean value_function loss: 18.0354
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 59.1022
                       Mean reward: 36.28
               Mean episode length: 222.21
    Episode_Reward/reaching_object: 0.9851
    Episode_Reward/rotating_object: 5.9916
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 2.09s
                      Time elapsed: 00:07:21
                               ETA: 00:49:34

################################################################################
                     [1m Learning iteration 194/1500 [0m                      

                       Computation: 45760 steps/s (collection: 1.986s, learning 0.163s)
             Mean action noise std: 1.64
          Mean value_function loss: 15.5886
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 59.1596
                       Mean reward: 42.69
               Mean episode length: 228.51
    Episode_Reward/reaching_object: 1.0307
    Episode_Reward/rotating_object: 6.7314
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 2.15s
                      Time elapsed: 00:07:23
                               ETA: 00:49:31

################################################################################
                     [1m Learning iteration 195/1500 [0m                      

                       Computation: 47619 steps/s (collection: 1.971s, learning 0.093s)
             Mean action noise std: 1.64
          Mean value_function loss: 15.7978
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 59.2167
                       Mean reward: 40.26
               Mean episode length: 229.04
    Episode_Reward/reaching_object: 1.0246
    Episode_Reward/rotating_object: 7.4297
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 2.06s
                      Time elapsed: 00:07:25
                               ETA: 00:49:27

################################################################################
                     [1m Learning iteration 196/1500 [0m                      

                       Computation: 48223 steps/s (collection: 1.923s, learning 0.115s)
             Mean action noise std: 1.64
          Mean value_function loss: 16.2588
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 59.2726
                       Mean reward: 43.85
               Mean episode length: 225.29
    Episode_Reward/reaching_object: 0.9895
    Episode_Reward/rotating_object: 5.9802
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0348
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 2.04s
                      Time elapsed: 00:07:27
                               ETA: 00:49:23

################################################################################
                     [1m Learning iteration 197/1500 [0m                      

                       Computation: 47783 steps/s (collection: 1.957s, learning 0.100s)
             Mean action noise std: 1.64
          Mean value_function loss: 14.7137
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 59.3293
                       Mean reward: 42.87
               Mean episode length: 233.11
    Episode_Reward/reaching_object: 0.9944
    Episode_Reward/rotating_object: 6.4624
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 2.06s
                      Time elapsed: 00:07:29
                               ETA: 00:49:20

################################################################################
                     [1m Learning iteration 198/1500 [0m                      

                       Computation: 48232 steps/s (collection: 1.948s, learning 0.090s)
             Mean action noise std: 1.65
          Mean value_function loss: 15.6421
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 59.3848
                       Mean reward: 25.00
               Mean episode length: 230.33
    Episode_Reward/reaching_object: 0.9740
    Episode_Reward/rotating_object: 5.2330
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 2.04s
                      Time elapsed: 00:07:31
                               ETA: 00:49:16

################################################################################
                     [1m Learning iteration 199/1500 [0m                      

                       Computation: 48132 steps/s (collection: 1.949s, learning 0.093s)
             Mean action noise std: 1.65
          Mean value_function loss: 15.3976
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 59.4277
                       Mean reward: 41.85
               Mean episode length: 228.53
    Episode_Reward/reaching_object: 0.9981
    Episode_Reward/rotating_object: 5.6711
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 2.04s
                      Time elapsed: 00:07:33
                               ETA: 00:49:12

################################################################################
                     [1m Learning iteration 200/1500 [0m                      

                       Computation: 47963 steps/s (collection: 1.959s, learning 0.090s)
             Mean action noise std: 1.65
          Mean value_function loss: 13.4408
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 59.4594
                       Mean reward: 25.89
               Mean episode length: 228.02
    Episode_Reward/reaching_object: 0.9822
    Episode_Reward/rotating_object: 5.0420
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 2.05s
                      Time elapsed: 00:07:35
                               ETA: 00:49:08

################################################################################
                     [1m Learning iteration 201/1500 [0m                      

                       Computation: 45350 steps/s (collection: 2.032s, learning 0.136s)
             Mean action noise std: 1.65
          Mean value_function loss: 17.9100
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 59.5180
                       Mean reward: 46.61
               Mean episode length: 231.43
    Episode_Reward/reaching_object: 0.9709
    Episode_Reward/rotating_object: 6.2655
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 2.17s
                      Time elapsed: 00:07:38
                               ETA: 00:49:06

################################################################################
                     [1m Learning iteration 202/1500 [0m                      

                       Computation: 47670 steps/s (collection: 1.962s, learning 0.101s)
             Mean action noise std: 1.66
          Mean value_function loss: 17.2143
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 59.5596
                       Mean reward: 30.86
               Mean episode length: 226.38
    Episode_Reward/reaching_object: 1.0142
    Episode_Reward/rotating_object: 5.8563
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 2.06s
                      Time elapsed: 00:07:40
                               ETA: 00:49:02

################################################################################
                     [1m Learning iteration 203/1500 [0m                      

                       Computation: 48280 steps/s (collection: 1.943s, learning 0.094s)
             Mean action noise std: 1.66
          Mean value_function loss: 14.8997
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 59.6163
                       Mean reward: 49.57
               Mean episode length: 211.94
    Episode_Reward/reaching_object: 1.0341
    Episode_Reward/rotating_object: 7.2342
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 2.04s
                      Time elapsed: 00:07:42
                               ETA: 00:48:58

################################################################################
                     [1m Learning iteration 204/1500 [0m                      

                       Computation: 46930 steps/s (collection: 1.977s, learning 0.118s)
             Mean action noise std: 1.66
          Mean value_function loss: 15.7867
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 59.6649
                       Mean reward: 39.49
               Mean episode length: 233.60
    Episode_Reward/reaching_object: 0.9778
    Episode_Reward/rotating_object: 5.6419
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 2.09s
                      Time elapsed: 00:07:44
                               ETA: 00:48:55

################################################################################
                     [1m Learning iteration 205/1500 [0m                      

                       Computation: 48150 steps/s (collection: 1.939s, learning 0.103s)
             Mean action noise std: 1.67
          Mean value_function loss: 14.8686
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 59.7139
                       Mean reward: 33.93
               Mean episode length: 225.29
    Episode_Reward/reaching_object: 1.0443
    Episode_Reward/rotating_object: 6.9864
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 2.04s
                      Time elapsed: 00:07:46
                               ETA: 00:48:51

################################################################################
                     [1m Learning iteration 206/1500 [0m                      

                       Computation: 48964 steps/s (collection: 1.906s, learning 0.102s)
             Mean action noise std: 1.67
          Mean value_function loss: 14.8764
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 59.7651
                       Mean reward: 29.50
               Mean episode length: 230.84
    Episode_Reward/reaching_object: 1.0131
    Episode_Reward/rotating_object: 5.7633
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 2.01s
                      Time elapsed: 00:07:48
                               ETA: 00:48:47

################################################################################
                     [1m Learning iteration 207/1500 [0m                      

                       Computation: 47131 steps/s (collection: 1.949s, learning 0.136s)
             Mean action noise std: 1.67
          Mean value_function loss: 14.7983
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 59.8218
                       Mean reward: 31.68
               Mean episode length: 235.57
    Episode_Reward/reaching_object: 1.0079
    Episode_Reward/rotating_object: 6.0611
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 2.09s
                      Time elapsed: 00:07:50
                               ETA: 00:48:44

################################################################################
                     [1m Learning iteration 208/1500 [0m                      

                       Computation: 48116 steps/s (collection: 1.939s, learning 0.104s)
             Mean action noise std: 1.68
          Mean value_function loss: 15.5123
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 59.8959
                       Mean reward: 26.17
               Mean episode length: 230.20
    Episode_Reward/reaching_object: 0.9952
    Episode_Reward/rotating_object: 5.3810
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 2.04s
                      Time elapsed: 00:07:52
                               ETA: 00:48:40

################################################################################
                     [1m Learning iteration 209/1500 [0m                      

                       Computation: 48130 steps/s (collection: 1.931s, learning 0.111s)
             Mean action noise std: 1.68
          Mean value_function loss: 17.3662
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 59.9461
                       Mean reward: 35.58
               Mean episode length: 239.16
    Episode_Reward/reaching_object: 1.0301
    Episode_Reward/rotating_object: 6.1439
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 2.04s
                      Time elapsed: 00:07:54
                               ETA: 00:48:37

################################################################################
                     [1m Learning iteration 210/1500 [0m                      

                       Computation: 48123 steps/s (collection: 1.926s, learning 0.117s)
             Mean action noise std: 1.68
          Mean value_function loss: 16.6075
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 59.9881
                       Mean reward: 22.89
               Mean episode length: 222.18
    Episode_Reward/reaching_object: 1.0051
    Episode_Reward/rotating_object: 5.5245
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 2.04s
                      Time elapsed: 00:07:56
                               ETA: 00:48:33

################################################################################
                     [1m Learning iteration 211/1500 [0m                      

                       Computation: 45752 steps/s (collection: 2.013s, learning 0.135s)
             Mean action noise std: 1.68
          Mean value_function loss: 16.5809
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 60.0374
                       Mean reward: 31.55
               Mean episode length: 225.82
    Episode_Reward/reaching_object: 1.0204
    Episode_Reward/rotating_object: 6.3353
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 2.15s
                      Time elapsed: 00:07:58
                               ETA: 00:48:30

################################################################################
                     [1m Learning iteration 212/1500 [0m                      

                       Computation: 45649 steps/s (collection: 1.981s, learning 0.173s)
             Mean action noise std: 1.69
          Mean value_function loss: 16.2601
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 60.1053
                       Mean reward: 30.47
               Mean episode length: 225.41
    Episode_Reward/reaching_object: 0.9863
    Episode_Reward/rotating_object: 5.7131
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 2.15s
                      Time elapsed: 00:08:00
                               ETA: 00:48:27

################################################################################
                     [1m Learning iteration 213/1500 [0m                      

                       Computation: 46306 steps/s (collection: 2.011s, learning 0.112s)
             Mean action noise std: 1.69
          Mean value_function loss: 18.4723
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 60.1590
                       Mean reward: 29.97
               Mean episode length: 225.49
    Episode_Reward/reaching_object: 1.0086
    Episode_Reward/rotating_object: 6.7307
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 2.12s
                      Time elapsed: 00:08:02
                               ETA: 00:48:24

################################################################################
                     [1m Learning iteration 214/1500 [0m                      

                       Computation: 47994 steps/s (collection: 1.947s, learning 0.101s)
             Mean action noise std: 1.69
          Mean value_function loss: 17.1449
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 60.2129
                       Mean reward: 38.61
               Mean episode length: 225.11
    Episode_Reward/reaching_object: 0.9630
    Episode_Reward/rotating_object: 4.9614
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 2.05s
                      Time elapsed: 00:08:05
                               ETA: 00:48:21

################################################################################
                     [1m Learning iteration 215/1500 [0m                      

                       Computation: 45143 steps/s (collection: 2.086s, learning 0.092s)
             Mean action noise std: 1.69
          Mean value_function loss: 17.6542
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 60.2458
                       Mean reward: 38.30
               Mean episode length: 221.56
    Episode_Reward/reaching_object: 0.9821
    Episode_Reward/rotating_object: 5.5247
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 2.18s
                      Time elapsed: 00:08:07
                               ETA: 00:48:18

################################################################################
                     [1m Learning iteration 216/1500 [0m                      

                       Computation: 47456 steps/s (collection: 1.979s, learning 0.092s)
             Mean action noise std: 1.70
          Mean value_function loss: 16.2439
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 60.2958
                       Mean reward: 28.35
               Mean episode length: 233.34
    Episode_Reward/reaching_object: 1.0104
    Episode_Reward/rotating_object: 5.7640
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 2.07s
                      Time elapsed: 00:08:09
                               ETA: 00:48:15

################################################################################
                     [1m Learning iteration 217/1500 [0m                      

                       Computation: 47904 steps/s (collection: 1.962s, learning 0.090s)
             Mean action noise std: 1.70
          Mean value_function loss: 14.8157
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 60.3486
                       Mean reward: 36.15
               Mean episode length: 216.98
    Episode_Reward/reaching_object: 0.9734
    Episode_Reward/rotating_object: 6.4410
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 2.05s
                      Time elapsed: 00:08:11
                               ETA: 00:48:11

################################################################################
                     [1m Learning iteration 218/1500 [0m                      

                       Computation: 45054 steps/s (collection: 2.044s, learning 0.138s)
             Mean action noise std: 1.70
          Mean value_function loss: 16.4316
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 60.3963
                       Mean reward: 39.00
               Mean episode length: 220.85
    Episode_Reward/reaching_object: 0.9556
    Episode_Reward/rotating_object: 5.7836
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 2.18s
                      Time elapsed: 00:08:13
                               ETA: 00:48:09

################################################################################
                     [1m Learning iteration 219/1500 [0m                      

                       Computation: 47012 steps/s (collection: 1.946s, learning 0.145s)
             Mean action noise std: 1.70
          Mean value_function loss: 16.9740
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 60.4316
                       Mean reward: 33.90
               Mean episode length: 226.43
    Episode_Reward/reaching_object: 0.9712
    Episode_Reward/rotating_object: 5.8130
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 2.09s
                      Time elapsed: 00:08:15
                               ETA: 00:48:05

################################################################################
                     [1m Learning iteration 220/1500 [0m                      

                       Computation: 47488 steps/s (collection: 1.965s, learning 0.105s)
             Mean action noise std: 1.71
          Mean value_function loss: 16.5734
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 60.4788
                       Mean reward: 35.21
               Mean episode length: 220.53
    Episode_Reward/reaching_object: 0.9835
    Episode_Reward/rotating_object: 5.7274
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 2.07s
                      Time elapsed: 00:08:17
                               ETA: 00:48:02

################################################################################
                     [1m Learning iteration 221/1500 [0m                      

                       Computation: 47869 steps/s (collection: 1.942s, learning 0.112s)
             Mean action noise std: 1.71
          Mean value_function loss: 17.3766
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 60.5173
                       Mean reward: 28.09
               Mean episode length: 220.84
    Episode_Reward/reaching_object: 0.9752
    Episode_Reward/rotating_object: 5.6732
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 2.05s
                      Time elapsed: 00:08:19
                               ETA: 00:47:59

################################################################################
                     [1m Learning iteration 222/1500 [0m                      

                       Computation: 48159 steps/s (collection: 1.945s, learning 0.096s)
             Mean action noise std: 1.71
          Mean value_function loss: 18.4110
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 60.5660
                       Mean reward: 39.82
               Mean episode length: 223.26
    Episode_Reward/reaching_object: 1.0107
    Episode_Reward/rotating_object: 5.7479
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 2.04s
                      Time elapsed: 00:08:21
                               ETA: 00:47:55

################################################################################
                     [1m Learning iteration 223/1500 [0m                      

                       Computation: 47253 steps/s (collection: 1.984s, learning 0.097s)
             Mean action noise std: 1.72
          Mean value_function loss: 15.4609
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 60.6309
                       Mean reward: 25.01
               Mean episode length: 220.21
    Episode_Reward/reaching_object: 0.9723
    Episode_Reward/rotating_object: 5.5460
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 2.08s
                      Time elapsed: 00:08:23
                               ETA: 00:47:52

################################################################################
                     [1m Learning iteration 224/1500 [0m                      

                       Computation: 48100 steps/s (collection: 1.952s, learning 0.092s)
             Mean action noise std: 1.72
          Mean value_function loss: 17.4144
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 60.6834
                       Mean reward: 35.58
               Mean episode length: 221.56
    Episode_Reward/reaching_object: 0.9786
    Episode_Reward/rotating_object: 5.2236
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 2.04s
                      Time elapsed: 00:08:25
                               ETA: 00:47:49

################################################################################
                     [1m Learning iteration 225/1500 [0m                      

                       Computation: 49329 steps/s (collection: 1.900s, learning 0.092s)
             Mean action noise std: 1.72
          Mean value_function loss: 16.5841
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 60.7284
                       Mean reward: 39.50
               Mean episode length: 224.19
    Episode_Reward/reaching_object: 0.9475
    Episode_Reward/rotating_object: 5.0954
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 1.99s
                      Time elapsed: 00:08:27
                               ETA: 00:47:45

################################################################################
                     [1m Learning iteration 226/1500 [0m                      

                       Computation: 49405 steps/s (collection: 1.900s, learning 0.090s)
             Mean action noise std: 1.72
          Mean value_function loss: 18.2511
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 60.7824
                       Mean reward: 33.23
               Mean episode length: 224.16
    Episode_Reward/reaching_object: 0.9721
    Episode_Reward/rotating_object: 5.8246
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 12.2083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 1.99s
                      Time elapsed: 00:08:29
                               ETA: 00:47:41

################################################################################
                     [1m Learning iteration 227/1500 [0m                      

                       Computation: 48646 steps/s (collection: 1.910s, learning 0.111s)
             Mean action noise std: 1.73
          Mean value_function loss: 18.1899
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 60.8292
                       Mean reward: 34.09
               Mean episode length: 228.80
    Episode_Reward/reaching_object: 0.9948
    Episode_Reward/rotating_object: 6.7900
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 2.02s
                      Time elapsed: 00:08:31
                               ETA: 00:47:38

################################################################################
                     [1m Learning iteration 228/1500 [0m                      

                       Computation: 49481 steps/s (collection: 1.897s, learning 0.090s)
             Mean action noise std: 1.73
          Mean value_function loss: 18.0900
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 60.8721
                       Mean reward: 41.93
               Mean episode length: 231.02
    Episode_Reward/reaching_object: 0.9853
    Episode_Reward/rotating_object: 6.4090
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 1.99s
                      Time elapsed: 00:08:33
                               ETA: 00:47:34

################################################################################
                     [1m Learning iteration 229/1500 [0m                      

                       Computation: 46840 steps/s (collection: 1.957s, learning 0.142s)
             Mean action noise std: 1.73
          Mean value_function loss: 19.0504
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 60.9071
                       Mean reward: 44.23
               Mean episode length: 232.02
    Episode_Reward/reaching_object: 0.9979
    Episode_Reward/rotating_object: 6.4791
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 2.10s
                      Time elapsed: 00:08:35
                               ETA: 00:47:31

################################################################################
                     [1m Learning iteration 230/1500 [0m                      

                       Computation: 49333 steps/s (collection: 1.901s, learning 0.092s)
             Mean action noise std: 1.73
          Mean value_function loss: 18.6813
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 60.9532
                       Mean reward: 35.45
               Mean episode length: 231.13
    Episode_Reward/reaching_object: 1.0283
    Episode_Reward/rotating_object: 6.8083
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 1.99s
                      Time elapsed: 00:08:37
                               ETA: 00:47:27

################################################################################
                     [1m Learning iteration 231/1500 [0m                      

                       Computation: 48078 steps/s (collection: 1.955s, learning 0.090s)
             Mean action noise std: 1.74
          Mean value_function loss: 16.9647
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 60.9969
                       Mean reward: 30.94
               Mean episode length: 224.66
    Episode_Reward/reaching_object: 0.9956
    Episode_Reward/rotating_object: 5.7620
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 2.04s
                      Time elapsed: 00:08:40
                               ETA: 00:47:24

################################################################################
                     [1m Learning iteration 232/1500 [0m                      

                       Computation: 49524 steps/s (collection: 1.886s, learning 0.099s)
             Mean action noise std: 1.74
          Mean value_function loss: 16.6614
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 61.0285
                       Mean reward: 26.03
               Mean episode length: 218.34
    Episode_Reward/reaching_object: 0.9899
    Episode_Reward/rotating_object: 4.9335
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 1.98s
                      Time elapsed: 00:08:42
                               ETA: 00:47:20

################################################################################
                     [1m Learning iteration 233/1500 [0m                      

                       Computation: 49685 steps/s (collection: 1.883s, learning 0.096s)
             Mean action noise std: 1.74
          Mean value_function loss: 18.4834
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 61.0617
                       Mean reward: 43.82
               Mean episode length: 226.32
    Episode_Reward/reaching_object: 0.9960
    Episode_Reward/rotating_object: 6.8675
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 1.98s
                      Time elapsed: 00:08:43
                               ETA: 00:47:17

################################################################################
                     [1m Learning iteration 234/1500 [0m                      

                       Computation: 49882 steps/s (collection: 1.882s, learning 0.089s)
             Mean action noise std: 1.74
          Mean value_function loss: 17.3532
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 61.0894
                       Mean reward: 45.42
               Mean episode length: 226.27
    Episode_Reward/reaching_object: 1.0055
    Episode_Reward/rotating_object: 6.6793
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 1.97s
                      Time elapsed: 00:08:45
                               ETA: 00:47:13

################################################################################
                     [1m Learning iteration 235/1500 [0m                      

                       Computation: 49380 steps/s (collection: 1.899s, learning 0.092s)
             Mean action noise std: 1.74
          Mean value_function loss: 16.1668
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 61.1325
                       Mean reward: 43.62
               Mean episode length: 232.29
    Episode_Reward/reaching_object: 1.0169
    Episode_Reward/rotating_object: 7.0673
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 1.99s
                      Time elapsed: 00:08:47
                               ETA: 00:47:09

################################################################################
                     [1m Learning iteration 236/1500 [0m                      

                       Computation: 48452 steps/s (collection: 1.918s, learning 0.110s)
             Mean action noise std: 1.75
          Mean value_function loss: 16.4754
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 61.1633
                       Mean reward: 39.55
               Mean episode length: 230.05
    Episode_Reward/reaching_object: 0.9871
    Episode_Reward/rotating_object: 5.7577
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 11.8333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 2.03s
                      Time elapsed: 00:08:49
                               ETA: 00:47:06

################################################################################
                     [1m Learning iteration 237/1500 [0m                      

                       Computation: 48578 steps/s (collection: 1.920s, learning 0.104s)
             Mean action noise std: 1.75
          Mean value_function loss: 14.9183
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 61.2094
                       Mean reward: 29.82
               Mean episode length: 229.50
    Episode_Reward/reaching_object: 1.0008
    Episode_Reward/rotating_object: 5.7165
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 2.02s
                      Time elapsed: 00:08:52
                               ETA: 00:47:03

################################################################################
                     [1m Learning iteration 238/1500 [0m                      

                       Computation: 48510 steps/s (collection: 1.927s, learning 0.100s)
             Mean action noise std: 1.75
          Mean value_function loss: 15.5245
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 61.2606
                       Mean reward: 32.18
               Mean episode length: 223.78
    Episode_Reward/reaching_object: 0.9922
    Episode_Reward/rotating_object: 6.3101
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 2.03s
                      Time elapsed: 00:08:54
                               ETA: 00:46:59

################################################################################
                     [1m Learning iteration 239/1500 [0m                      

                       Computation: 48129 steps/s (collection: 1.938s, learning 0.105s)
             Mean action noise std: 1.75
          Mean value_function loss: 15.0877
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 61.3086
                       Mean reward: 28.94
               Mean episode length: 238.56
    Episode_Reward/reaching_object: 0.9925
    Episode_Reward/rotating_object: 5.1487
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 2.04s
                      Time elapsed: 00:08:56
                               ETA: 00:46:56

################################################################################
                     [1m Learning iteration 240/1500 [0m                      

                       Computation: 45321 steps/s (collection: 2.067s, learning 0.102s)
             Mean action noise std: 1.76
          Mean value_function loss: 13.6506
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 61.3482
                       Mean reward: 36.99
               Mean episode length: 238.87
    Episode_Reward/reaching_object: 0.9526
    Episode_Reward/rotating_object: 5.6944
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 2.17s
                      Time elapsed: 00:08:58
                               ETA: 00:46:54

################################################################################
                     [1m Learning iteration 241/1500 [0m                      

                       Computation: 46254 steps/s (collection: 2.007s, learning 0.119s)
             Mean action noise std: 1.76
          Mean value_function loss: 15.7020
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 61.3844
                       Mean reward: 40.71
               Mean episode length: 230.14
    Episode_Reward/reaching_object: 0.9684
    Episode_Reward/rotating_object: 5.9390
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 2.13s
                      Time elapsed: 00:09:00
                               ETA: 00:46:51

################################################################################
                     [1m Learning iteration 242/1500 [0m                      

                       Computation: 46896 steps/s (collection: 1.971s, learning 0.126s)
             Mean action noise std: 1.76
          Mean value_function loss: 15.0952
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 61.4400
                       Mean reward: 24.63
               Mean episode length: 221.84
    Episode_Reward/reaching_object: 0.9797
    Episode_Reward/rotating_object: 5.7300
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 2.10s
                      Time elapsed: 00:09:02
                               ETA: 00:46:48

################################################################################
                     [1m Learning iteration 243/1500 [0m                      

                       Computation: 47042 steps/s (collection: 1.988s, learning 0.102s)
             Mean action noise std: 1.76
          Mean value_function loss: 14.6441
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 61.4895
                       Mean reward: 42.29
               Mean episode length: 233.11
    Episode_Reward/reaching_object: 0.9958
    Episode_Reward/rotating_object: 6.5130
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 2.09s
                      Time elapsed: 00:09:04
                               ETA: 00:46:45

################################################################################
                     [1m Learning iteration 244/1500 [0m                      

                       Computation: 48458 steps/s (collection: 1.917s, learning 0.112s)
             Mean action noise std: 1.77
          Mean value_function loss: 15.3692
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 61.5334
                       Mean reward: 27.66
               Mean episode length: 222.23
    Episode_Reward/reaching_object: 0.9614
    Episode_Reward/rotating_object: 6.5106
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 2.03s
                      Time elapsed: 00:09:06
                               ETA: 00:46:42

################################################################################
                     [1m Learning iteration 245/1500 [0m                      

                       Computation: 44501 steps/s (collection: 2.086s, learning 0.123s)
             Mean action noise std: 1.77
          Mean value_function loss: 14.8381
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 61.5760
                       Mean reward: 37.95
               Mean episode length: 224.47
    Episode_Reward/reaching_object: 0.9562
    Episode_Reward/rotating_object: 5.2157
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 2.21s
                      Time elapsed: 00:09:08
                               ETA: 00:46:39

################################################################################
                     [1m Learning iteration 246/1500 [0m                      

                       Computation: 46786 steps/s (collection: 1.965s, learning 0.136s)
             Mean action noise std: 1.77
          Mean value_function loss: 14.6115
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 61.6148
                       Mean reward: 32.54
               Mean episode length: 229.95
    Episode_Reward/reaching_object: 0.9372
    Episode_Reward/rotating_object: 5.2022
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 2.10s
                      Time elapsed: 00:09:10
                               ETA: 00:46:36

################################################################################
                     [1m Learning iteration 247/1500 [0m                      

                       Computation: 47202 steps/s (collection: 1.948s, learning 0.135s)
             Mean action noise std: 1.77
          Mean value_function loss: 14.9687
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 61.6597
                       Mean reward: 32.09
               Mean episode length: 233.73
    Episode_Reward/reaching_object: 0.9571
    Episode_Reward/rotating_object: 5.3010
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 2.08s
                      Time elapsed: 00:09:12
                               ETA: 00:46:33

################################################################################
                     [1m Learning iteration 248/1500 [0m                      

                       Computation: 48275 steps/s (collection: 1.941s, learning 0.095s)
             Mean action noise std: 1.78
          Mean value_function loss: 16.7153
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 61.6949
                       Mean reward: 21.83
               Mean episode length: 226.89
    Episode_Reward/reaching_object: 0.9643
    Episode_Reward/rotating_object: 5.3416
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 2.04s
                      Time elapsed: 00:09:15
                               ETA: 00:46:30

################################################################################
                     [1m Learning iteration 249/1500 [0m                      

                       Computation: 47931 steps/s (collection: 1.940s, learning 0.111s)
             Mean action noise std: 1.78
          Mean value_function loss: 16.5157
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 61.7332
                       Mean reward: 26.75
               Mean episode length: 226.63
    Episode_Reward/reaching_object: 0.9674
    Episode_Reward/rotating_object: 5.1275
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 2.05s
                      Time elapsed: 00:09:17
                               ETA: 00:46:27

################################################################################
                     [1m Learning iteration 250/1500 [0m                      

                       Computation: 47781 steps/s (collection: 1.958s, learning 0.099s)
             Mean action noise std: 1.78
          Mean value_function loss: 16.6755
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 61.7644
                       Mean reward: 27.36
               Mean episode length: 231.59
    Episode_Reward/reaching_object: 0.9355
    Episode_Reward/rotating_object: 5.5670
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 2.06s
                      Time elapsed: 00:09:19
                               ETA: 00:46:24

################################################################################
                     [1m Learning iteration 251/1500 [0m                      

                       Computation: 46946 steps/s (collection: 1.994s, learning 0.100s)
             Mean action noise std: 1.78
          Mean value_function loss: 16.4461
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 61.8042
                       Mean reward: 34.50
               Mean episode length: 226.05
    Episode_Reward/reaching_object: 0.9515
    Episode_Reward/rotating_object: 5.1859
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 2.09s
                      Time elapsed: 00:09:21
                               ETA: 00:46:21

################################################################################
                     [1m Learning iteration 252/1500 [0m                      

                       Computation: 44452 steps/s (collection: 2.092s, learning 0.120s)
             Mean action noise std: 1.78
          Mean value_function loss: 15.0861
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 61.8441
                       Mean reward: 34.81
               Mean episode length: 230.72
    Episode_Reward/reaching_object: 0.9591
    Episode_Reward/rotating_object: 5.6081
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 2.21s
                      Time elapsed: 00:09:23
                               ETA: 00:46:19

################################################################################
                     [1m Learning iteration 253/1500 [0m                      

                       Computation: 47815 steps/s (collection: 1.953s, learning 0.103s)
             Mean action noise std: 1.79
          Mean value_function loss: 16.9977
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 61.8967
                       Mean reward: 27.11
               Mean episode length: 225.78
    Episode_Reward/reaching_object: 0.9284
    Episode_Reward/rotating_object: 5.4381
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 2.06s
                      Time elapsed: 00:09:25
                               ETA: 00:46:16

################################################################################
                     [1m Learning iteration 254/1500 [0m                      

                       Computation: 44305 steps/s (collection: 2.019s, learning 0.200s)
             Mean action noise std: 1.79
          Mean value_function loss: 15.4891
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 61.9420
                       Mean reward: 37.52
               Mean episode length: 231.80
    Episode_Reward/reaching_object: 0.9869
    Episode_Reward/rotating_object: 5.6486
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 2.22s
                      Time elapsed: 00:09:27
                               ETA: 00:46:13

################################################################################
                     [1m Learning iteration 255/1500 [0m                      

                       Computation: 45519 steps/s (collection: 2.043s, learning 0.116s)
             Mean action noise std: 1.79
          Mean value_function loss: 16.6540
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 61.9774
                       Mean reward: 35.59
               Mean episode length: 230.29
    Episode_Reward/reaching_object: 0.9509
    Episode_Reward/rotating_object: 5.6900
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 2.16s
                      Time elapsed: 00:09:29
                               ETA: 00:46:11

################################################################################
                     [1m Learning iteration 256/1500 [0m                      

                       Computation: 47689 steps/s (collection: 1.959s, learning 0.103s)
             Mean action noise std: 1.79
          Mean value_function loss: 15.8195
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 62.0121
                       Mean reward: 35.43
               Mean episode length: 234.88
    Episode_Reward/reaching_object: 0.9638
    Episode_Reward/rotating_object: 5.2492
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 2.06s
                      Time elapsed: 00:09:31
                               ETA: 00:46:08

################################################################################
                     [1m Learning iteration 257/1500 [0m                      

                       Computation: 47752 steps/s (collection: 1.945s, learning 0.114s)
             Mean action noise std: 1.80
          Mean value_function loss: 17.2559
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 62.0524
                       Mean reward: 36.28
               Mean episode length: 222.55
    Episode_Reward/reaching_object: 0.9409
    Episode_Reward/rotating_object: 5.5436
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 2.06s
                      Time elapsed: 00:09:33
                               ETA: 00:46:05

################################################################################
                     [1m Learning iteration 258/1500 [0m                      

                       Computation: 47219 steps/s (collection: 1.973s, learning 0.109s)
             Mean action noise std: 1.80
          Mean value_function loss: 16.6336
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 62.0984
                       Mean reward: 48.02
               Mean episode length: 237.01
    Episode_Reward/reaching_object: 0.9943
    Episode_Reward/rotating_object: 6.2585
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 2.08s
                      Time elapsed: 00:09:36
                               ETA: 00:46:02

################################################################################
                     [1m Learning iteration 259/1500 [0m                      

                       Computation: 46667 steps/s (collection: 1.993s, learning 0.114s)
             Mean action noise std: 1.80
          Mean value_function loss: 16.1332
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 62.1286
                       Mean reward: 24.30
               Mean episode length: 229.98
    Episode_Reward/reaching_object: 0.9563
    Episode_Reward/rotating_object: 5.7369
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 2.11s
                      Time elapsed: 00:09:38
                               ETA: 00:45:59

################################################################################
                     [1m Learning iteration 260/1500 [0m                      

                       Computation: 46255 steps/s (collection: 2.024s, learning 0.101s)
             Mean action noise std: 1.80
          Mean value_function loss: 18.2758
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 62.1740
                       Mean reward: 28.84
               Mean episode length: 230.84
    Episode_Reward/reaching_object: 0.9648
    Episode_Reward/rotating_object: 5.8451
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 2.13s
                      Time elapsed: 00:09:40
                               ETA: 00:45:56

################################################################################
                     [1m Learning iteration 261/1500 [0m                      

                       Computation: 48744 steps/s (collection: 1.923s, learning 0.094s)
             Mean action noise std: 1.80
          Mean value_function loss: 16.0122
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 62.2080
                       Mean reward: 35.09
               Mean episode length: 229.81
    Episode_Reward/reaching_object: 0.9551
    Episode_Reward/rotating_object: 5.3884
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 2.02s
                      Time elapsed: 00:09:42
                               ETA: 00:45:53

################################################################################
                     [1m Learning iteration 262/1500 [0m                      

                       Computation: 43918 steps/s (collection: 2.106s, learning 0.132s)
             Mean action noise std: 1.81
          Mean value_function loss: 17.8957
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 62.2436
                       Mean reward: 41.81
               Mean episode length: 222.64
    Episode_Reward/reaching_object: 0.9399
    Episode_Reward/rotating_object: 6.6505
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 2.24s
                      Time elapsed: 00:09:44
                               ETA: 00:45:51

################################################################################
                     [1m Learning iteration 263/1500 [0m                      

                       Computation: 47749 steps/s (collection: 1.959s, learning 0.100s)
             Mean action noise std: 1.81
          Mean value_function loss: 17.3708
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 62.2973
                       Mean reward: 35.02
               Mean episode length: 232.28
    Episode_Reward/reaching_object: 0.9773
    Episode_Reward/rotating_object: 6.0192
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 2.06s
                      Time elapsed: 00:09:46
                               ETA: 00:45:48

################################################################################
                     [1m Learning iteration 264/1500 [0m                      

                       Computation: 44657 steps/s (collection: 2.063s, learning 0.139s)
             Mean action noise std: 1.81
          Mean value_function loss: 18.0886
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 62.3362
                       Mean reward: 47.68
               Mean episode length: 227.61
    Episode_Reward/reaching_object: 0.9643
    Episode_Reward/rotating_object: 6.1324
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 2.20s
                      Time elapsed: 00:09:48
                               ETA: 00:45:46

################################################################################
                     [1m Learning iteration 265/1500 [0m                      

                       Computation: 46041 steps/s (collection: 1.956s, learning 0.179s)
             Mean action noise std: 1.82
          Mean value_function loss: 17.6185
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 62.3765
                       Mean reward: 36.38
               Mean episode length: 234.88
    Episode_Reward/reaching_object: 0.9591
    Episode_Reward/rotating_object: 6.5767
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 2.14s
                      Time elapsed: 00:09:50
                               ETA: 00:45:43

################################################################################
                     [1m Learning iteration 266/1500 [0m                      

                       Computation: 43008 steps/s (collection: 2.139s, learning 0.147s)
             Mean action noise std: 1.82
          Mean value_function loss: 17.6703
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 62.4237
                       Mean reward: 37.38
               Mean episode length: 232.09
    Episode_Reward/reaching_object: 0.9604
    Episode_Reward/rotating_object: 6.7164
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0468
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 2.29s
                      Time elapsed: 00:09:53
                               ETA: 00:45:41

################################################################################
                     [1m Learning iteration 267/1500 [0m                      

                       Computation: 46490 steps/s (collection: 1.966s, learning 0.148s)
             Mean action noise std: 1.82
          Mean value_function loss: 18.2350
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 62.4744
                       Mean reward: 34.26
               Mean episode length: 224.56
    Episode_Reward/reaching_object: 0.9505
    Episode_Reward/rotating_object: 6.4051
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 2.11s
                      Time elapsed: 00:09:55
                               ETA: 00:45:39

################################################################################
                     [1m Learning iteration 268/1500 [0m                      

                       Computation: 42343 steps/s (collection: 2.157s, learning 0.165s)
             Mean action noise std: 1.82
          Mean value_function loss: 19.0300
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 62.5137
                       Mean reward: 23.48
               Mean episode length: 225.86
    Episode_Reward/reaching_object: 0.9261
    Episode_Reward/rotating_object: 4.5307
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 2.32s
                      Time elapsed: 00:09:57
                               ETA: 00:45:37

################################################################################
                     [1m Learning iteration 269/1500 [0m                      

                       Computation: 43076 steps/s (collection: 2.146s, learning 0.136s)
             Mean action noise std: 1.83
          Mean value_function loss: 17.9307
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 62.5513
                       Mean reward: 27.38
               Mean episode length: 229.41
    Episode_Reward/reaching_object: 0.9726
    Episode_Reward/rotating_object: 6.0673
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 2.28s
                      Time elapsed: 00:09:59
                               ETA: 00:45:35

################################################################################
                     [1m Learning iteration 270/1500 [0m                      

                       Computation: 45998 steps/s (collection: 1.971s, learning 0.167s)
             Mean action noise std: 1.83
          Mean value_function loss: 17.4557
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 62.5882
                       Mean reward: 46.16
               Mean episode length: 228.46
    Episode_Reward/reaching_object: 0.9541
    Episode_Reward/rotating_object: 6.6227
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 2.14s
                      Time elapsed: 00:10:02
                               ETA: 00:45:32

################################################################################
                     [1m Learning iteration 271/1500 [0m                      

                       Computation: 46699 steps/s (collection: 1.956s, learning 0.149s)
             Mean action noise std: 1.83
          Mean value_function loss: 16.6148
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 62.6427
                       Mean reward: 35.64
               Mean episode length: 223.58
    Episode_Reward/reaching_object: 0.9617
    Episode_Reward/rotating_object: 6.1156
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 2.11s
                      Time elapsed: 00:10:04
                               ETA: 00:45:29

################################################################################
                     [1m Learning iteration 272/1500 [0m                      

                       Computation: 46806 steps/s (collection: 1.972s, learning 0.129s)
             Mean action noise std: 1.83
          Mean value_function loss: 15.1756
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 62.7007
                       Mean reward: 42.00
               Mean episode length: 233.30
    Episode_Reward/reaching_object: 0.9157
    Episode_Reward/rotating_object: 6.3983
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 2.10s
                      Time elapsed: 00:10:06
                               ETA: 00:45:27

################################################################################
                     [1m Learning iteration 273/1500 [0m                      

                       Computation: 47611 steps/s (collection: 1.970s, learning 0.095s)
             Mean action noise std: 1.84
          Mean value_function loss: 15.9656
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 62.7457
                       Mean reward: 27.29
               Mean episode length: 230.46
    Episode_Reward/reaching_object: 0.9519
    Episode_Reward/rotating_object: 6.5265
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0494
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 2.06s
                      Time elapsed: 00:10:08
                               ETA: 00:45:24

################################################################################
                     [1m Learning iteration 274/1500 [0m                      

                       Computation: 47158 steps/s (collection: 1.986s, learning 0.098s)
             Mean action noise std: 1.84
          Mean value_function loss: 15.0540
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 62.8032
                       Mean reward: 36.97
               Mean episode length: 227.29
    Episode_Reward/reaching_object: 0.9523
    Episode_Reward/rotating_object: 7.3420
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 2.08s
                      Time elapsed: 00:10:10
                               ETA: 00:45:21

################################################################################
                     [1m Learning iteration 275/1500 [0m                      

                       Computation: 46585 steps/s (collection: 1.994s, learning 0.116s)
             Mean action noise std: 1.84
          Mean value_function loss: 14.6256
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 62.8547
                       Mean reward: 38.98
               Mean episode length: 232.23
    Episode_Reward/reaching_object: 0.9390
    Episode_Reward/rotating_object: 6.6325
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 2.11s
                      Time elapsed: 00:10:12
                               ETA: 00:45:18

################################################################################
                     [1m Learning iteration 276/1500 [0m                      

                       Computation: 46259 steps/s (collection: 1.999s, learning 0.126s)
             Mean action noise std: 1.85
          Mean value_function loss: 16.6403
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 62.9089
                       Mean reward: 37.04
               Mean episode length: 233.07
    Episode_Reward/reaching_object: 0.9498
    Episode_Reward/rotating_object: 6.6580
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0507
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 2.13s
                      Time elapsed: 00:10:14
                               ETA: 00:45:16

################################################################################
                     [1m Learning iteration 277/1500 [0m                      

                       Computation: 46917 steps/s (collection: 1.994s, learning 0.102s)
             Mean action noise std: 1.85
          Mean value_function loss: 16.1438
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 62.9474
                       Mean reward: 37.89
               Mean episode length: 228.19
    Episode_Reward/reaching_object: 0.9286
    Episode_Reward/rotating_object: 6.2182
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 2.10s
                      Time elapsed: 00:10:16
                               ETA: 00:45:13

################################################################################
                     [1m Learning iteration 278/1500 [0m                      

                       Computation: 44921 steps/s (collection: 2.018s, learning 0.171s)
             Mean action noise std: 1.85
          Mean value_function loss: 14.8243
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 62.9870
                       Mean reward: 28.35
               Mean episode length: 232.30
    Episode_Reward/reaching_object: 0.9309
    Episode_Reward/rotating_object: 5.3820
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0514
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 2.19s
                      Time elapsed: 00:10:18
                               ETA: 00:45:11

################################################################################
                     [1m Learning iteration 279/1500 [0m                      

                       Computation: 46393 steps/s (collection: 1.996s, learning 0.122s)
             Mean action noise std: 1.85
          Mean value_function loss: 17.7327
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 63.0332
                       Mean reward: 24.31
               Mean episode length: 233.38
    Episode_Reward/reaching_object: 0.9711
    Episode_Reward/rotating_object: 5.3038
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0519
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 2.12s
                      Time elapsed: 00:10:21
                               ETA: 00:45:08

################################################################################
                     [1m Learning iteration 280/1500 [0m                      

                       Computation: 46887 steps/s (collection: 1.970s, learning 0.127s)
             Mean action noise std: 1.86
          Mean value_function loss: 14.0418
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 63.0856
                       Mean reward: 29.50
               Mean episode length: 229.34
    Episode_Reward/reaching_object: 0.9416
    Episode_Reward/rotating_object: 4.9970
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0511
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 2.10s
                      Time elapsed: 00:10:23
                               ETA: 00:45:05

################################################################################
                     [1m Learning iteration 281/1500 [0m                      

                       Computation: 45826 steps/s (collection: 2.023s, learning 0.122s)
             Mean action noise std: 1.86
          Mean value_function loss: 17.1182
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 63.1216
                       Mean reward: 23.12
               Mean episode length: 223.84
    Episode_Reward/reaching_object: 0.9558
    Episode_Reward/rotating_object: 5.1751
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0524
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 2.15s
                      Time elapsed: 00:10:25
                               ETA: 00:45:03

################################################################################
                     [1m Learning iteration 282/1500 [0m                      

                       Computation: 46940 steps/s (collection: 1.975s, learning 0.120s)
             Mean action noise std: 1.86
          Mean value_function loss: 14.8007
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 63.1649
                       Mean reward: 45.44
               Mean episode length: 232.03
    Episode_Reward/reaching_object: 0.9629
    Episode_Reward/rotating_object: 5.3006
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0519
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 2.09s
                      Time elapsed: 00:10:27
                               ETA: 00:45:00

################################################################################
                     [1m Learning iteration 283/1500 [0m                      

                       Computation: 46790 steps/s (collection: 2.003s, learning 0.098s)
             Mean action noise std: 1.86
          Mean value_function loss: 15.7652
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 63.2094
                       Mean reward: 27.15
               Mean episode length: 228.44
    Episode_Reward/reaching_object: 0.9235
    Episode_Reward/rotating_object: 5.6626
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0512
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 2.10s
                      Time elapsed: 00:10:29
                               ETA: 00:44:57

################################################################################
                     [1m Learning iteration 284/1500 [0m                      

                       Computation: 47158 steps/s (collection: 1.982s, learning 0.103s)
             Mean action noise std: 1.87
          Mean value_function loss: 16.6957
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 63.2541
                       Mean reward: 40.57
               Mean episode length: 230.68
    Episode_Reward/reaching_object: 0.9365
    Episode_Reward/rotating_object: 5.8215
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0515
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 2.08s
                      Time elapsed: 00:10:31
                               ETA: 00:44:54

################################################################################
                     [1m Learning iteration 285/1500 [0m                      

                       Computation: 47440 steps/s (collection: 1.962s, learning 0.111s)
             Mean action noise std: 1.87
          Mean value_function loss: 16.8129
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 63.2928
                       Mean reward: 34.47
               Mean episode length: 232.44
    Episode_Reward/reaching_object: 0.9701
    Episode_Reward/rotating_object: 5.5802
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0528
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 2.07s
                      Time elapsed: 00:10:33
                               ETA: 00:44:52

################################################################################
                     [1m Learning iteration 286/1500 [0m                      

                       Computation: 47004 steps/s (collection: 1.977s, learning 0.114s)
             Mean action noise std: 1.87
          Mean value_function loss: 16.2922
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 63.3258
                       Mean reward: 29.98
               Mean episode length: 228.68
    Episode_Reward/reaching_object: 0.9341
    Episode_Reward/rotating_object: 6.0524
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0516
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 2.09s
                      Time elapsed: 00:10:35
                               ETA: 00:44:49

################################################################################
                     [1m Learning iteration 287/1500 [0m                      

                       Computation: 47460 steps/s (collection: 1.968s, learning 0.103s)
             Mean action noise std: 1.87
          Mean value_function loss: 15.8692
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 63.3670
                       Mean reward: 38.34
               Mean episode length: 235.01
    Episode_Reward/reaching_object: 0.9481
    Episode_Reward/rotating_object: 6.2473
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0514
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 2.07s
                      Time elapsed: 00:10:37
                               ETA: 00:44:46

################################################################################
                     [1m Learning iteration 288/1500 [0m                      

                       Computation: 46244 steps/s (collection: 2.020s, learning 0.106s)
             Mean action noise std: 1.88
          Mean value_function loss: 15.7977
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 63.4067
                       Mean reward: 22.47
               Mean episode length: 230.72
    Episode_Reward/reaching_object: 0.9494
    Episode_Reward/rotating_object: 5.0016
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0526
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 2.13s
                      Time elapsed: 00:10:39
                               ETA: 00:44:43

################################################################################
                     [1m Learning iteration 289/1500 [0m                      

                       Computation: 46772 steps/s (collection: 2.002s, learning 0.100s)
             Mean action noise std: 1.88
          Mean value_function loss: 17.8681
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 63.4430
                       Mean reward: 34.07
               Mean episode length: 228.17
    Episode_Reward/reaching_object: 0.9234
    Episode_Reward/rotating_object: 6.2624
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0523
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 2.10s
                      Time elapsed: 00:10:42
                               ETA: 00:44:41

################################################################################
                     [1m Learning iteration 290/1500 [0m                      

                       Computation: 45212 steps/s (collection: 2.002s, learning 0.172s)
             Mean action noise std: 1.88
          Mean value_function loss: 18.1124
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 63.4798
                       Mean reward: 35.16
               Mean episode length: 223.59
    Episode_Reward/reaching_object: 0.9500
    Episode_Reward/rotating_object: 6.2846
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0527
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 2.17s
                      Time elapsed: 00:10:44
                               ETA: 00:44:38

################################################################################
                     [1m Learning iteration 291/1500 [0m                      

                       Computation: 46651 steps/s (collection: 1.997s, learning 0.111s)
             Mean action noise std: 1.88
          Mean value_function loss: 20.6633
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 63.5140
                       Mean reward: 35.21
               Mean episode length: 227.87
    Episode_Reward/reaching_object: 0.9622
    Episode_Reward/rotating_object: 6.1419
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0534
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 2.11s
                      Time elapsed: 00:10:46
                               ETA: 00:44:36

################################################################################
                     [1m Learning iteration 292/1500 [0m                      

                       Computation: 46339 steps/s (collection: 1.992s, learning 0.129s)
             Mean action noise std: 1.89
          Mean value_function loss: 17.9211
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 63.5576
                       Mean reward: 27.02
               Mean episode length: 226.73
    Episode_Reward/reaching_object: 0.9387
    Episode_Reward/rotating_object: 5.4357
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0529
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 2.12s
                      Time elapsed: 00:10:48
                               ETA: 00:44:33

################################################################################
                     [1m Learning iteration 293/1500 [0m                      

                       Computation: 45511 steps/s (collection: 2.055s, learning 0.105s)
             Mean action noise std: 1.89
          Mean value_function loss: 18.2902
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 63.5879
                       Mean reward: 30.10
               Mean episode length: 230.95
    Episode_Reward/reaching_object: 0.9469
    Episode_Reward/rotating_object: 6.2558
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0537
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 2.16s
                      Time elapsed: 00:10:50
                               ETA: 00:44:31

################################################################################
                     [1m Learning iteration 294/1500 [0m                      

                       Computation: 47077 steps/s (collection: 1.980s, learning 0.108s)
             Mean action noise std: 1.89
          Mean value_function loss: 18.8333
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 63.6208
                       Mean reward: 22.38
               Mean episode length: 230.51
    Episode_Reward/reaching_object: 0.9755
    Episode_Reward/rotating_object: 6.3440
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0536
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 2.09s
                      Time elapsed: 00:10:52
                               ETA: 00:44:28

################################################################################
                     [1m Learning iteration 295/1500 [0m                      

                       Computation: 45307 steps/s (collection: 2.072s, learning 0.098s)
             Mean action noise std: 1.89
          Mean value_function loss: 19.4863
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 63.6587
                       Mean reward: 34.09
               Mean episode length: 234.33
    Episode_Reward/reaching_object: 0.9801
    Episode_Reward/rotating_object: 5.6463
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0541
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 2.17s
                      Time elapsed: 00:10:54
                               ETA: 00:44:26

################################################################################
                     [1m Learning iteration 296/1500 [0m                      

                       Computation: 45005 steps/s (collection: 2.014s, learning 0.170s)
             Mean action noise std: 1.89
          Mean value_function loss: 20.2450
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 63.6940
                       Mean reward: 34.89
               Mean episode length: 229.19
    Episode_Reward/reaching_object: 0.9576
    Episode_Reward/rotating_object: 6.7897
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0542
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 2.18s
                      Time elapsed: 00:10:57
                               ETA: 00:44:23

################################################################################
                     [1m Learning iteration 297/1500 [0m                      

                       Computation: 45850 steps/s (collection: 2.041s, learning 0.103s)
             Mean action noise std: 1.90
          Mean value_function loss: 22.9875
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 63.7308
                       Mean reward: 30.69
               Mean episode length: 224.64
    Episode_Reward/reaching_object: 1.0206
    Episode_Reward/rotating_object: 6.6001
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0531
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 2.14s
                      Time elapsed: 00:10:59
                               ETA: 00:44:21

################################################################################
                     [1m Learning iteration 298/1500 [0m                      

                       Computation: 45879 steps/s (collection: 2.000s, learning 0.143s)
             Mean action noise std: 1.90
          Mean value_function loss: 20.8467
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 63.7620
                       Mean reward: 34.59
               Mean episode length: 231.92
    Episode_Reward/reaching_object: 0.9571
    Episode_Reward/rotating_object: 6.0196
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0535
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 2.14s
                      Time elapsed: 00:11:01
                               ETA: 00:44:18

################################################################################
                     [1m Learning iteration 299/1500 [0m                      

                       Computation: 43184 steps/s (collection: 2.111s, learning 0.165s)
             Mean action noise std: 1.90
          Mean value_function loss: 19.8069
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 63.7985
                       Mean reward: 49.47
               Mean episode length: 229.13
    Episode_Reward/reaching_object: 0.9568
    Episode_Reward/rotating_object: 7.4653
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0535
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 2.28s
                      Time elapsed: 00:11:03
                               ETA: 00:44:16

################################################################################
                     [1m Learning iteration 300/1500 [0m                      

                       Computation: 42088 steps/s (collection: 2.234s, learning 0.102s)
             Mean action noise std: 1.90
          Mean value_function loss: 20.2874
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 63.8439
                       Mean reward: 34.55
               Mean episode length: 230.34
    Episode_Reward/reaching_object: 0.9595
    Episode_Reward/rotating_object: 6.0138
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0531
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 2.34s
                      Time elapsed: 00:11:05
                               ETA: 00:44:15

################################################################################
                     [1m Learning iteration 301/1500 [0m                      

                       Computation: 44070 steps/s (collection: 2.010s, learning 0.221s)
             Mean action noise std: 1.91
          Mean value_function loss: 23.4160
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 63.8779
                       Mean reward: 27.54
               Mean episode length: 230.89
    Episode_Reward/reaching_object: 1.0173
    Episode_Reward/rotating_object: 6.1282
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0543
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 2.23s
                      Time elapsed: 00:11:08
                               ETA: 00:44:12

################################################################################
                     [1m Learning iteration 302/1500 [0m                      

                       Computation: 45317 steps/s (collection: 1.997s, learning 0.173s)
             Mean action noise std: 1.91
          Mean value_function loss: 20.0893
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 63.9182
                       Mean reward: 38.44
               Mean episode length: 229.86
    Episode_Reward/reaching_object: 0.9961
    Episode_Reward/rotating_object: 7.1108
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0535
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 2.17s
                      Time elapsed: 00:11:10
                               ETA: 00:44:10

################################################################################
                     [1m Learning iteration 303/1500 [0m                      

                       Computation: 43459 steps/s (collection: 2.166s, learning 0.096s)
             Mean action noise std: 1.91
          Mean value_function loss: 22.6107
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 63.9564
                       Mean reward: 25.03
               Mean episode length: 232.54
    Episode_Reward/reaching_object: 1.0051
    Episode_Reward/rotating_object: 6.3972
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0555
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 2.26s
                      Time elapsed: 00:11:12
                               ETA: 00:44:08

################################################################################
                     [1m Learning iteration 304/1500 [0m                      

                       Computation: 45253 steps/s (collection: 2.055s, learning 0.117s)
             Mean action noise std: 1.91
          Mean value_function loss: 19.3334
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 63.9940
                       Mean reward: 53.63
               Mean episode length: 231.95
    Episode_Reward/reaching_object: 0.9820
    Episode_Reward/rotating_object: 7.7488
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0544
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 2.17s
                      Time elapsed: 00:11:14
                               ETA: 00:44:06

################################################################################
                     [1m Learning iteration 305/1500 [0m                      

                       Computation: 42483 steps/s (collection: 2.171s, learning 0.143s)
             Mean action noise std: 1.91
          Mean value_function loss: 17.5128
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 64.0225
                       Mean reward: 37.74
               Mean episode length: 234.68
    Episode_Reward/reaching_object: 1.0169
    Episode_Reward/rotating_object: 7.3792
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0550
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 2.31s
                      Time elapsed: 00:11:17
                               ETA: 00:44:04

################################################################################
                     [1m Learning iteration 306/1500 [0m                      

                       Computation: 42077 steps/s (collection: 2.228s, learning 0.108s)
             Mean action noise std: 1.92
          Mean value_function loss: 20.1199
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 64.0571
                       Mean reward: 51.82
               Mean episode length: 233.58
    Episode_Reward/reaching_object: 0.9791
    Episode_Reward/rotating_object: 7.0734
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0559
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 2.34s
                      Time elapsed: 00:11:19
                               ETA: 00:44:02

################################################################################
                     [1m Learning iteration 307/1500 [0m                      

                       Computation: 43558 steps/s (collection: 2.135s, learning 0.122s)
             Mean action noise std: 1.92
          Mean value_function loss: 18.0998
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 64.0966
                       Mean reward: 34.77
               Mean episode length: 229.04
    Episode_Reward/reaching_object: 1.0174
    Episode_Reward/rotating_object: 6.1883
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0566
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 2.26s
                      Time elapsed: 00:11:21
                               ETA: 00:44:00

################################################################################
                     [1m Learning iteration 308/1500 [0m                      

                       Computation: 44864 steps/s (collection: 2.049s, learning 0.142s)
             Mean action noise std: 1.92
          Mean value_function loss: 19.4861
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 64.1377
                       Mean reward: 33.05
               Mean episode length: 230.93
    Episode_Reward/reaching_object: 0.9996
    Episode_Reward/rotating_object: 6.7085
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0547
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 2.19s
                      Time elapsed: 00:11:23
                               ETA: 00:43:58

################################################################################
                     [1m Learning iteration 309/1500 [0m                      

                       Computation: 45553 steps/s (collection: 2.035s, learning 0.123s)
             Mean action noise std: 1.92
          Mean value_function loss: 18.9962
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 64.1797
                       Mean reward: 29.94
               Mean episode length: 223.55
    Episode_Reward/reaching_object: 0.9694
    Episode_Reward/rotating_object: 5.8207
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0539
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 2.16s
                      Time elapsed: 00:11:26
                               ETA: 00:43:55

################################################################################
                     [1m Learning iteration 310/1500 [0m                      

                       Computation: 43413 steps/s (collection: 2.155s, learning 0.109s)
             Mean action noise std: 1.93
          Mean value_function loss: 24.1190
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 64.2308
                       Mean reward: 44.60
               Mean episode length: 233.25
    Episode_Reward/reaching_object: 1.0268
    Episode_Reward/rotating_object: 7.8539
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0547
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 2.26s
                      Time elapsed: 00:11:28
                               ETA: 00:43:53

################################################################################
                     [1m Learning iteration 311/1500 [0m                      

                       Computation: 46468 steps/s (collection: 1.989s, learning 0.126s)
             Mean action noise std: 1.93
          Mean value_function loss: 22.5627
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 64.2662
                       Mean reward: 43.55
               Mean episode length: 229.17
    Episode_Reward/reaching_object: 0.9897
    Episode_Reward/rotating_object: 6.4925
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0543
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 2.12s
                      Time elapsed: 00:11:30
                               ETA: 00:43:51

################################################################################
                     [1m Learning iteration 312/1500 [0m                      

                       Computation: 46527 steps/s (collection: 2.014s, learning 0.099s)
             Mean action noise std: 1.93
          Mean value_function loss: 22.7257
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 64.2989
                       Mean reward: 43.81
               Mean episode length: 237.62
    Episode_Reward/reaching_object: 1.0288
    Episode_Reward/rotating_object: 7.5570
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0537
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 2.11s
                      Time elapsed: 00:11:32
                               ETA: 00:43:48

################################################################################
                     [1m Learning iteration 313/1500 [0m                      

                       Computation: 47896 steps/s (collection: 1.956s, learning 0.096s)
             Mean action noise std: 1.93
          Mean value_function loss: 21.8760
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 64.3359
                       Mean reward: 34.30
               Mean episode length: 228.41
    Episode_Reward/reaching_object: 0.9956
    Episode_Reward/rotating_object: 6.8700
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0558
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 2.05s
                      Time elapsed: 00:11:34
                               ETA: 00:43:45

################################################################################
                     [1m Learning iteration 314/1500 [0m                      

                       Computation: 47392 steps/s (collection: 1.981s, learning 0.093s)
             Mean action noise std: 1.94
          Mean value_function loss: 22.8864
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 64.3861
                       Mean reward: 45.99
               Mean episode length: 233.65
    Episode_Reward/reaching_object: 1.0207
    Episode_Reward/rotating_object: 7.7905
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0546
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 2.07s
                      Time elapsed: 00:11:36
                               ETA: 00:43:43

################################################################################
                     [1m Learning iteration 315/1500 [0m                      

                       Computation: 46743 steps/s (collection: 1.981s, learning 0.122s)
             Mean action noise std: 1.94
          Mean value_function loss: 24.2139
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 64.4235
                       Mean reward: 25.93
               Mean episode length: 227.05
    Episode_Reward/reaching_object: 1.0173
    Episode_Reward/rotating_object: 6.9121
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0535
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 2.10s
                      Time elapsed: 00:11:38
                               ETA: 00:43:40

################################################################################
                     [1m Learning iteration 316/1500 [0m                      

                       Computation: 46149 steps/s (collection: 2.000s, learning 0.130s)
             Mean action noise std: 1.94
          Mean value_function loss: 23.1183
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 64.4531
                       Mean reward: 32.37
               Mean episode length: 235.93
    Episode_Reward/reaching_object: 1.0172
    Episode_Reward/rotating_object: 6.2204
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0545
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 2.13s
                      Time elapsed: 00:11:40
                               ETA: 00:43:37

################################################################################
                     [1m Learning iteration 317/1500 [0m                      

                       Computation: 43325 steps/s (collection: 2.130s, learning 0.139s)
             Mean action noise std: 1.94
          Mean value_function loss: 18.0931
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 64.4862
                       Mean reward: 23.34
               Mean episode length: 227.13
    Episode_Reward/reaching_object: 1.0006
    Episode_Reward/rotating_object: 6.2595
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 2.27s
                      Time elapsed: 00:11:43
                               ETA: 00:43:35

################################################################################
                     [1m Learning iteration 318/1500 [0m                      

                       Computation: 45065 steps/s (collection: 2.055s, learning 0.126s)
             Mean action noise std: 1.95
          Mean value_function loss: 20.6195
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 64.5256
                       Mean reward: 39.85
               Mean episode length: 226.63
    Episode_Reward/reaching_object: 1.0177
    Episode_Reward/rotating_object: 6.9513
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0532
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 2.18s
                      Time elapsed: 00:11:45
                               ETA: 00:43:33

################################################################################
                     [1m Learning iteration 319/1500 [0m                      

                       Computation: 42834 steps/s (collection: 2.175s, learning 0.120s)
             Mean action noise std: 1.95
          Mean value_function loss: 21.2601
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 64.5649
                       Mean reward: 35.28
               Mean episode length: 230.82
    Episode_Reward/reaching_object: 1.0353
    Episode_Reward/rotating_object: 7.6493
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0553
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 2.29s
                      Time elapsed: 00:11:47
                               ETA: 00:43:31

################################################################################
                     [1m Learning iteration 320/1500 [0m                      

                       Computation: 45732 steps/s (collection: 2.044s, learning 0.106s)
             Mean action noise std: 1.95
          Mean value_function loss: 23.9455
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 64.6022
                       Mean reward: 47.31
               Mean episode length: 234.06
    Episode_Reward/reaching_object: 1.0650
    Episode_Reward/rotating_object: 7.5218
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0558
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 2.15s
                      Time elapsed: 00:11:49
                               ETA: 00:43:29

################################################################################
                     [1m Learning iteration 321/1500 [0m                      

                       Computation: 44704 steps/s (collection: 2.080s, learning 0.119s)
             Mean action noise std: 1.95
          Mean value_function loss: 22.5512
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 64.6368
                       Mean reward: 39.50
               Mean episode length: 233.40
    Episode_Reward/reaching_object: 1.0059
    Episode_Reward/rotating_object: 7.8016
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0554
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 2.20s
                      Time elapsed: 00:11:52
                               ETA: 00:43:27

################################################################################
                     [1m Learning iteration 322/1500 [0m                      

                       Computation: 46074 steps/s (collection: 2.031s, learning 0.103s)
             Mean action noise std: 1.95
          Mean value_function loss: 28.6410
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 64.6713
                       Mean reward: 53.78
               Mean episode length: 235.84
    Episode_Reward/reaching_object: 1.0550
    Episode_Reward/rotating_object: 8.1293
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0547
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 2.13s
                      Time elapsed: 00:11:54
                               ETA: 00:43:24

################################################################################
                     [1m Learning iteration 323/1500 [0m                      

                       Computation: 43617 steps/s (collection: 2.148s, learning 0.106s)
             Mean action noise std: 1.96
          Mean value_function loss: 21.2446
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 64.7083
                       Mean reward: 33.26
               Mean episode length: 226.16
    Episode_Reward/reaching_object: 1.0339
    Episode_Reward/rotating_object: 7.3568
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 2.25s
                      Time elapsed: 00:11:56
                               ETA: 00:43:22

################################################################################
                     [1m Learning iteration 324/1500 [0m                      

                       Computation: 43395 steps/s (collection: 2.115s, learning 0.151s)
             Mean action noise std: 1.96
          Mean value_function loss: 21.4414
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 64.7354
                       Mean reward: 43.59
               Mean episode length: 234.94
    Episode_Reward/reaching_object: 1.0715
    Episode_Reward/rotating_object: 7.9913
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0563
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 2.27s
                      Time elapsed: 00:11:58
                               ETA: 00:43:20

################################################################################
                     [1m Learning iteration 325/1500 [0m                      

                       Computation: 45638 steps/s (collection: 2.049s, learning 0.105s)
             Mean action noise std: 1.96
          Mean value_function loss: 23.0231
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 64.7666
                       Mean reward: 42.71
               Mean episode length: 231.43
    Episode_Reward/reaching_object: 1.0210
    Episode_Reward/rotating_object: 9.0051
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0554
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 2.15s
                      Time elapsed: 00:12:00
                               ETA: 00:43:18

################################################################################
                     [1m Learning iteration 326/1500 [0m                      

                       Computation: 44006 steps/s (collection: 2.114s, learning 0.120s)
             Mean action noise std: 1.96
          Mean value_function loss: 23.7465
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 64.7985
                       Mean reward: 57.55
               Mean episode length: 239.74
    Episode_Reward/reaching_object: 1.0489
    Episode_Reward/rotating_object: 7.5256
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0553
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 2.23s
                      Time elapsed: 00:12:03
                               ETA: 00:43:15

################################################################################
                     [1m Learning iteration 327/1500 [0m                      

                       Computation: 46070 steps/s (collection: 2.037s, learning 0.097s)
             Mean action noise std: 1.97
          Mean value_function loss: 23.4759
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 64.8357
                       Mean reward: 33.40
               Mean episode length: 232.79
    Episode_Reward/reaching_object: 1.0525
    Episode_Reward/rotating_object: 7.9138
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0571
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 2.13s
                      Time elapsed: 00:12:05
                               ETA: 00:43:13

################################################################################
                     [1m Learning iteration 328/1500 [0m                      

                       Computation: 45455 steps/s (collection: 2.007s, learning 0.156s)
             Mean action noise std: 1.97
          Mean value_function loss: 22.2635
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 64.8703
                       Mean reward: 38.96
               Mean episode length: 230.97
    Episode_Reward/reaching_object: 1.0332
    Episode_Reward/rotating_object: 6.1169
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0570
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 2.16s
                      Time elapsed: 00:12:07
                               ETA: 00:43:11

################################################################################
                     [1m Learning iteration 329/1500 [0m                      

                       Computation: 46518 steps/s (collection: 1.970s, learning 0.143s)
             Mean action noise std: 1.97
          Mean value_function loss: 27.5359
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 64.8998
                       Mean reward: 31.80
               Mean episode length: 230.94
    Episode_Reward/reaching_object: 1.0578
    Episode_Reward/rotating_object: 7.2386
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0575
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 2.11s
                      Time elapsed: 00:12:09
                               ETA: 00:43:08

################################################################################
                     [1m Learning iteration 330/1500 [0m                      

                       Computation: 44379 steps/s (collection: 2.107s, learning 0.108s)
             Mean action noise std: 1.97
          Mean value_function loss: 28.9352
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 64.9372
                       Mean reward: 38.07
               Mean episode length: 229.48
    Episode_Reward/reaching_object: 1.0541
    Episode_Reward/rotating_object: 7.2318
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0577
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 2.22s
                      Time elapsed: 00:12:11
                               ETA: 00:43:06

################################################################################
                     [1m Learning iteration 331/1500 [0m                      

                       Computation: 46820 steps/s (collection: 2.002s, learning 0.098s)
             Mean action noise std: 1.97
          Mean value_function loss: 23.6545
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 64.9686
                       Mean reward: 58.82
               Mean episode length: 234.85
    Episode_Reward/reaching_object: 1.0742
    Episode_Reward/rotating_object: 8.2248
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0561
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 2.10s
                      Time elapsed: 00:12:13
                               ETA: 00:43:03

################################################################################
                     [1m Learning iteration 332/1500 [0m                      

                       Computation: 44967 steps/s (collection: 2.069s, learning 0.117s)
             Mean action noise std: 1.98
          Mean value_function loss: 24.4965
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 64.9998
                       Mean reward: 44.65
               Mean episode length: 223.41
    Episode_Reward/reaching_object: 1.0395
    Episode_Reward/rotating_object: 8.6730
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0550
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 2.19s
                      Time elapsed: 00:12:15
                               ETA: 00:43:01

################################################################################
                     [1m Learning iteration 333/1500 [0m                      

                       Computation: 18926 steps/s (collection: 5.014s, learning 0.180s)
             Mean action noise std: 1.98
          Mean value_function loss: 25.8798
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 65.0412
                       Mean reward: 48.57
               Mean episode length: 236.14
    Episode_Reward/reaching_object: 1.0601
    Episode_Reward/rotating_object: 8.2923
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0549
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 5.19s
                      Time elapsed: 00:12:21
                               ETA: 00:43:09

################################################################################
                     [1m Learning iteration 334/1500 [0m                      

                       Computation: 14421 steps/s (collection: 6.693s, learning 0.124s)
             Mean action noise std: 1.98
          Mean value_function loss: 25.7483
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 65.0872
                       Mean reward: 31.62
               Mean episode length: 229.01
    Episode_Reward/reaching_object: 1.0610
    Episode_Reward/rotating_object: 7.2813
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0582
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 6.82s
                      Time elapsed: 00:12:27
                               ETA: 00:43:23

################################################################################
                     [1m Learning iteration 335/1500 [0m                      

                       Computation: 14513 steps/s (collection: 6.637s, learning 0.137s)
             Mean action noise std: 1.98
          Mean value_function loss: 25.0887
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 65.1264
                       Mean reward: 43.49
               Mean episode length: 227.39
    Episode_Reward/reaching_object: 1.0539
    Episode_Reward/rotating_object: 8.7963
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0567
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 6.77s
                      Time elapsed: 00:12:34
                               ETA: 00:43:36

################################################################################
                     [1m Learning iteration 336/1500 [0m                      

                       Computation: 14359 steps/s (collection: 6.712s, learning 0.134s)
             Mean action noise std: 1.99
          Mean value_function loss: 26.9430
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 65.1619
                       Mean reward: 58.46
               Mean episode length: 225.20
    Episode_Reward/reaching_object: 1.0834
    Episode_Reward/rotating_object: 9.6528
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 6.85s
                      Time elapsed: 00:12:41
                               ETA: 00:43:50

################################################################################
                     [1m Learning iteration 337/1500 [0m                      

                       Computation: 14501 steps/s (collection: 6.656s, learning 0.124s)
             Mean action noise std: 1.99
          Mean value_function loss: 27.3364
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 65.1960
                       Mean reward: 59.73
               Mean episode length: 231.18
    Episode_Reward/reaching_object: 1.0740
    Episode_Reward/rotating_object: 10.1589
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0580
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 6.78s
                      Time elapsed: 00:12:48
                               ETA: 00:44:03

################################################################################
                     [1m Learning iteration 338/1500 [0m                      

                       Computation: 14513 steps/s (collection: 6.657s, learning 0.117s)
             Mean action noise std: 1.99
          Mean value_function loss: 25.5910
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 65.2359
                       Mean reward: 60.40
               Mean episode length: 228.40
    Episode_Reward/reaching_object: 1.0560
    Episode_Reward/rotating_object: 9.7622
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0560
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 6.77s
                      Time elapsed: 00:12:55
                               ETA: 00:44:16

################################################################################
                     [1m Learning iteration 339/1500 [0m                      

                       Computation: 15038 steps/s (collection: 6.373s, learning 0.164s)
             Mean action noise std: 1.99
          Mean value_function loss: 23.4719
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 65.2663
                       Mean reward: 53.29
               Mean episode length: 230.34
    Episode_Reward/reaching_object: 1.0185
    Episode_Reward/rotating_object: 7.5199
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0577
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 6.54s
                      Time elapsed: 00:13:01
                               ETA: 00:44:29

################################################################################
                     [1m Learning iteration 340/1500 [0m                      

                       Computation: 14285 steps/s (collection: 6.758s, learning 0.123s)
             Mean action noise std: 2.00
          Mean value_function loss: 27.3785
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 65.3036
                       Mean reward: 37.61
               Mean episode length: 220.73
    Episode_Reward/reaching_object: 1.0281
    Episode_Reward/rotating_object: 7.3851
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0548
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 6.88s
                      Time elapsed: 00:13:08
                               ETA: 00:44:42

################################################################################
                     [1m Learning iteration 341/1500 [0m                      

                       Computation: 13109 steps/s (collection: 7.294s, learning 0.205s)
             Mean action noise std: 2.00
          Mean value_function loss: 26.3384
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 65.3423
                       Mean reward: 49.11
               Mean episode length: 233.68
    Episode_Reward/reaching_object: 1.0646
    Episode_Reward/rotating_object: 7.7158
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0573
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 7.50s
                      Time elapsed: 00:13:16
                               ETA: 00:44:57

################################################################################
                     [1m Learning iteration 342/1500 [0m                      

                       Computation: 47903 steps/s (collection: 1.941s, learning 0.111s)
             Mean action noise std: 2.00
          Mean value_function loss: 26.5274
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 65.3821
                       Mean reward: 44.80
               Mean episode length: 226.70
    Episode_Reward/reaching_object: 1.0308
    Episode_Reward/rotating_object: 7.9281
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0560
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 2.05s
                      Time elapsed: 00:13:18
                               ETA: 00:44:54

################################################################################
                     [1m Learning iteration 343/1500 [0m                      

                       Computation: 48615 steps/s (collection: 1.931s, learning 0.091s)
             Mean action noise std: 2.00
          Mean value_function loss: 25.5040
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 65.4192
                       Mean reward: 55.60
               Mean episode length: 225.87
    Episode_Reward/reaching_object: 1.0367
    Episode_Reward/rotating_object: 8.6272
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0555
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 2.02s
                      Time elapsed: 00:13:20
                               ETA: 00:44:51

################################################################################
                     [1m Learning iteration 344/1500 [0m                      

                       Computation: 48664 steps/s (collection: 1.918s, learning 0.102s)
             Mean action noise std: 2.01
          Mean value_function loss: 24.5600
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 65.4572
                       Mean reward: 52.18
               Mean episode length: 230.85
    Episode_Reward/reaching_object: 1.0781
    Episode_Reward/rotating_object: 7.5801
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0552
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 2.02s
                      Time elapsed: 00:13:22
                               ETA: 00:44:47

################################################################################
                     [1m Learning iteration 345/1500 [0m                      

                       Computation: 48457 steps/s (collection: 1.926s, learning 0.103s)
             Mean action noise std: 2.01
          Mean value_function loss: 26.5621
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 65.4955
                       Mean reward: 58.65
               Mean episode length: 233.95
    Episode_Reward/reaching_object: 1.0708
    Episode_Reward/rotating_object: 9.4272
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0565
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 2.03s
                      Time elapsed: 00:13:24
                               ETA: 00:44:44

################################################################################
                     [1m Learning iteration 346/1500 [0m                      

                       Computation: 46766 steps/s (collection: 1.986s, learning 0.116s)
             Mean action noise std: 2.01
          Mean value_function loss: 24.7719
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 65.5210
                       Mean reward: 46.28
               Mean episode length: 228.22
    Episode_Reward/reaching_object: 1.0585
    Episode_Reward/rotating_object: 7.7851
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0550
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 2.10s
                      Time elapsed: 00:13:26
                               ETA: 00:44:41

################################################################################
                     [1m Learning iteration 347/1500 [0m                      

                       Computation: 47554 steps/s (collection: 1.953s, learning 0.115s)
             Mean action noise std: 2.01
          Mean value_function loss: 26.4134
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 65.5502
                       Mean reward: 53.63
               Mean episode length: 227.96
    Episode_Reward/reaching_object: 1.0700
    Episode_Reward/rotating_object: 9.9094
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 2.07s
                      Time elapsed: 00:13:28
                               ETA: 00:44:38

################################################################################
                     [1m Learning iteration 348/1500 [0m                      

                       Computation: 48132 steps/s (collection: 1.952s, learning 0.090s)
             Mean action noise std: 2.01
          Mean value_function loss: 27.1994
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 65.5891
                       Mean reward: 61.98
               Mean episode length: 231.50
    Episode_Reward/reaching_object: 1.0686
    Episode_Reward/rotating_object: 9.2314
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0563
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 2.04s
                      Time elapsed: 00:13:30
                               ETA: 00:44:34

################################################################################
                     [1m Learning iteration 349/1500 [0m                      

                       Computation: 48558 steps/s (collection: 1.926s, learning 0.098s)
             Mean action noise std: 2.02
          Mean value_function loss: 30.5971
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 65.6339
                       Mean reward: 45.29
               Mean episode length: 227.90
    Episode_Reward/reaching_object: 1.0318
    Episode_Reward/rotating_object: 7.2088
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0561
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 2.02s
                      Time elapsed: 00:13:32
                               ETA: 00:44:31

################################################################################
                     [1m Learning iteration 350/1500 [0m                      

                       Computation: 48148 steps/s (collection: 1.951s, learning 0.091s)
             Mean action noise std: 2.02
          Mean value_function loss: 28.3894
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 65.6804
                       Mean reward: 41.92
               Mean episode length: 219.28
    Episode_Reward/reaching_object: 1.0433
    Episode_Reward/rotating_object: 8.2613
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 2.04s
                      Time elapsed: 00:13:34
                               ETA: 00:44:28

################################################################################
                     [1m Learning iteration 351/1500 [0m                      

                       Computation: 47335 steps/s (collection: 1.965s, learning 0.112s)
             Mean action noise std: 2.02
          Mean value_function loss: 29.2246
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 65.7127
                       Mean reward: 46.15
               Mean episode length: 230.86
    Episode_Reward/reaching_object: 1.0700
    Episode_Reward/rotating_object: 8.0166
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0559
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 2.08s
                      Time elapsed: 00:13:36
                               ETA: 00:44:25

################################################################################
                     [1m Learning iteration 352/1500 [0m                      

                       Computation: 49197 steps/s (collection: 1.902s, learning 0.096s)
             Mean action noise std: 2.02
          Mean value_function loss: 28.8270
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 65.7481
                       Mean reward: 45.96
               Mean episode length: 219.59
    Episode_Reward/reaching_object: 1.0573
    Episode_Reward/rotating_object: 9.1992
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0528
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 2.00s
                      Time elapsed: 00:13:38
                               ETA: 00:44:21

################################################################################
                     [1m Learning iteration 353/1500 [0m                      

                       Computation: 47594 steps/s (collection: 1.957s, learning 0.108s)
             Mean action noise std: 2.03
          Mean value_function loss: 26.0581
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 65.7765
                       Mean reward: 56.90
               Mean episode length: 214.09
    Episode_Reward/reaching_object: 1.0683
    Episode_Reward/rotating_object: 10.1984
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0541
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 2.07s
                      Time elapsed: 00:13:40
                               ETA: 00:44:18

################################################################################
                     [1m Learning iteration 354/1500 [0m                      

                       Computation: 47453 steps/s (collection: 1.981s, learning 0.091s)
             Mean action noise std: 2.03
          Mean value_function loss: 25.0183
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 65.8059
                       Mean reward: 52.13
               Mean episode length: 221.88
    Episode_Reward/reaching_object: 1.0778
    Episode_Reward/rotating_object: 9.5185
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0542
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 2.07s
                      Time elapsed: 00:13:42
                               ETA: 00:44:15

################################################################################
                     [1m Learning iteration 355/1500 [0m                      

                       Computation: 46420 steps/s (collection: 2.002s, learning 0.116s)
             Mean action noise std: 2.03
          Mean value_function loss: 27.1727
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 65.8358
                       Mean reward: 36.07
               Mean episode length: 226.49
    Episode_Reward/reaching_object: 1.0647
    Episode_Reward/rotating_object: 6.8475
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0555
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 2.12s
                      Time elapsed: 00:13:44
                               ETA: 00:44:12

################################################################################
                     [1m Learning iteration 356/1500 [0m                      

                       Computation: 46422 steps/s (collection: 2.002s, learning 0.115s)
             Mean action noise std: 2.03
          Mean value_function loss: 27.5481
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 65.8716
                       Mean reward: 38.71
               Mean episode length: 220.69
    Episode_Reward/reaching_object: 1.0595
    Episode_Reward/rotating_object: 8.6977
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0552
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 2.12s
                      Time elapsed: 00:13:46
                               ETA: 00:44:09

################################################################################
                     [1m Learning iteration 357/1500 [0m                      

                       Computation: 47351 steps/s (collection: 1.912s, learning 0.164s)
             Mean action noise std: 2.03
          Mean value_function loss: 28.6144
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 65.9061
                       Mean reward: 56.38
               Mean episode length: 217.22
    Episode_Reward/reaching_object: 1.0370
    Episode_Reward/rotating_object: 8.6730
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0534
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 2.08s
                      Time elapsed: 00:13:48
                               ETA: 00:44:06

################################################################################
                     [1m Learning iteration 358/1500 [0m                      

                       Computation: 48738 steps/s (collection: 1.915s, learning 0.102s)
             Mean action noise std: 2.04
          Mean value_function loss: 30.8116
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 65.9302
                       Mean reward: 58.08
               Mean episode length: 221.44
    Episode_Reward/reaching_object: 1.0526
    Episode_Reward/rotating_object: 9.4053
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0534
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 2.02s
                      Time elapsed: 00:13:50
                               ETA: 00:44:03

################################################################################
                     [1m Learning iteration 359/1500 [0m                      

                       Computation: 47691 steps/s (collection: 1.962s, learning 0.099s)
             Mean action noise std: 2.04
          Mean value_function loss: 30.6390
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 65.9611
                       Mean reward: 55.21
               Mean episode length: 208.08
    Episode_Reward/reaching_object: 1.0431
    Episode_Reward/rotating_object: 9.5785
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0532
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 2.06s
                      Time elapsed: 00:13:53
                               ETA: 00:44:00

################################################################################
                     [1m Learning iteration 360/1500 [0m                      

                       Computation: 42950 steps/s (collection: 2.202s, learning 0.087s)
             Mean action noise std: 2.04
          Mean value_function loss: 28.1856
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 65.9864
                       Mean reward: 48.72
               Mean episode length: 225.62
    Episode_Reward/reaching_object: 1.0516
    Episode_Reward/rotating_object: 8.0612
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0539
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 2.29s
                      Time elapsed: 00:13:55
                               ETA: 00:43:57

################################################################################
                     [1m Learning iteration 361/1500 [0m                      

                       Computation: 45298 steps/s (collection: 2.077s, learning 0.093s)
             Mean action noise std: 2.04
          Mean value_function loss: 31.7958
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 66.0219
                       Mean reward: 36.31
               Mean episode length: 229.08
    Episode_Reward/reaching_object: 1.1008
    Episode_Reward/rotating_object: 8.7793
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0545
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 2.17s
                      Time elapsed: 00:13:57
                               ETA: 00:43:55

################################################################################
                     [1m Learning iteration 362/1500 [0m                      

                       Computation: 47146 steps/s (collection: 1.986s, learning 0.099s)
             Mean action noise std: 2.04
          Mean value_function loss: 26.5344
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 66.0582
                       Mean reward: 41.62
               Mean episode length: 218.95
    Episode_Reward/reaching_object: 1.0920
    Episode_Reward/rotating_object: 8.3912
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0533
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 2.09s
                      Time elapsed: 00:13:59
                               ETA: 00:43:52

################################################################################
                     [1m Learning iteration 363/1500 [0m                      

                       Computation: 48479 steps/s (collection: 1.909s, learning 0.119s)
             Mean action noise std: 2.05
          Mean value_function loss: 30.7849
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 66.0856
                       Mean reward: 58.76
               Mean episode length: 212.91
    Episode_Reward/reaching_object: 1.0913
    Episode_Reward/rotating_object: 8.6881
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0533
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 2.03s
                      Time elapsed: 00:14:01
                               ETA: 00:43:48

################################################################################
                     [1m Learning iteration 364/1500 [0m                      

                       Computation: 46504 steps/s (collection: 1.978s, learning 0.136s)
             Mean action noise std: 2.05
          Mean value_function loss: 29.4881
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 66.1173
                       Mean reward: 62.02
               Mean episode length: 218.49
    Episode_Reward/reaching_object: 1.0905
    Episode_Reward/rotating_object: 9.0971
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0537
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 2.11s
                      Time elapsed: 00:14:03
                               ETA: 00:43:46

################################################################################
                     [1m Learning iteration 365/1500 [0m                      

                       Computation: 43429 steps/s (collection: 2.151s, learning 0.112s)
             Mean action noise std: 2.05
          Mean value_function loss: 25.9621
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 66.1529
                       Mean reward: 39.62
               Mean episode length: 220.35
    Episode_Reward/reaching_object: 1.0818
    Episode_Reward/rotating_object: 10.5831
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0529
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 2.26s
                      Time elapsed: 00:14:06
                               ETA: 00:43:43

################################################################################
                     [1m Learning iteration 366/1500 [0m                      

                       Computation: 48009 steps/s (collection: 1.919s, learning 0.129s)
             Mean action noise std: 2.05
          Mean value_function loss: 30.9290
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 66.1883
                       Mean reward: 54.87
               Mean episode length: 219.73
    Episode_Reward/reaching_object: 1.0977
    Episode_Reward/rotating_object: 8.1718
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0531
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 2.05s
                      Time elapsed: 00:14:08
                               ETA: 00:43:40

################################################################################
                     [1m Learning iteration 367/1500 [0m                      

                       Computation: 47459 steps/s (collection: 1.941s, learning 0.130s)
             Mean action noise std: 2.06
          Mean value_function loss: 31.6618
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 66.2277
                       Mean reward: 52.91
               Mean episode length: 223.99
    Episode_Reward/reaching_object: 1.1130
    Episode_Reward/rotating_object: 9.3882
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0537
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 2.07s
                      Time elapsed: 00:14:10
                               ETA: 00:43:37

################################################################################
                     [1m Learning iteration 368/1500 [0m                      

                       Computation: 48475 steps/s (collection: 1.929s, learning 0.099s)
             Mean action noise std: 2.06
          Mean value_function loss: 32.6646
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 66.2658
                       Mean reward: 52.68
               Mean episode length: 214.60
    Episode_Reward/reaching_object: 1.0734
    Episode_Reward/rotating_object: 10.6138
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0521
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 2.03s
                      Time elapsed: 00:14:12
                               ETA: 00:43:34

################################################################################
                     [1m Learning iteration 369/1500 [0m                      

                       Computation: 47876 steps/s (collection: 1.962s, learning 0.092s)
             Mean action noise std: 2.06
          Mean value_function loss: 33.4491
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 66.3005
                       Mean reward: 71.22
               Mean episode length: 222.12
    Episode_Reward/reaching_object: 1.1163
    Episode_Reward/rotating_object: 10.8521
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0523
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 2.05s
                      Time elapsed: 00:14:14
                               ETA: 00:43:31

################################################################################
                     [1m Learning iteration 370/1500 [0m                      

                       Computation: 48304 steps/s (collection: 1.926s, learning 0.109s)
             Mean action noise std: 2.06
          Mean value_function loss: 33.1333
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 66.3343
                       Mean reward: 57.33
               Mean episode length: 202.13
    Episode_Reward/reaching_object: 1.0716
    Episode_Reward/rotating_object: 10.2445
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0501
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 2.04s
                      Time elapsed: 00:14:16
                               ETA: 00:43:27

################################################################################
                     [1m Learning iteration 371/1500 [0m                      

                       Computation: 46454 steps/s (collection: 2.001s, learning 0.116s)
             Mean action noise std: 2.06
          Mean value_function loss: 31.7895
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 66.3580
                       Mean reward: 81.84
               Mean episode length: 225.56
    Episode_Reward/reaching_object: 1.0980
    Episode_Reward/rotating_object: 10.4326
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0506
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 2.12s
                      Time elapsed: 00:14:18
                               ETA: 00:43:25

################################################################################
                     [1m Learning iteration 372/1500 [0m                      

                       Computation: 46959 steps/s (collection: 1.985s, learning 0.108s)
             Mean action noise std: 2.07
          Mean value_function loss: 27.3760
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 66.3959
                       Mean reward: 56.90
               Mean episode length: 214.37
    Episode_Reward/reaching_object: 1.1456
    Episode_Reward/rotating_object: 10.6262
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0505
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 2.09s
                      Time elapsed: 00:14:20
                               ETA: 00:43:22

################################################################################
                     [1m Learning iteration 373/1500 [0m                      

                       Computation: 47702 steps/s (collection: 1.964s, learning 0.097s)
             Mean action noise std: 2.07
          Mean value_function loss: 31.3506
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 66.4233
                       Mean reward: 48.87
               Mean episode length: 221.93
    Episode_Reward/reaching_object: 1.1062
    Episode_Reward/rotating_object: 8.5271
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0518
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 2.06s
                      Time elapsed: 00:14:22
                               ETA: 00:43:19

################################################################################
                     [1m Learning iteration 374/1500 [0m                      

                       Computation: 46985 steps/s (collection: 1.992s, learning 0.100s)
             Mean action noise std: 2.07
          Mean value_function loss: 33.1199
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 66.4518
                       Mean reward: 54.65
               Mean episode length: 212.53
    Episode_Reward/reaching_object: 1.1110
    Episode_Reward/rotating_object: 10.6186
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0505
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 2.09s
                      Time elapsed: 00:14:24
                               ETA: 00:43:16

################################################################################
                     [1m Learning iteration 375/1500 [0m                      

                       Computation: 49595 steps/s (collection: 1.892s, learning 0.090s)
             Mean action noise std: 2.07
          Mean value_function loss: 32.3073
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 66.4808
                       Mean reward: 49.83
               Mean episode length: 208.67
    Episode_Reward/reaching_object: 1.1102
    Episode_Reward/rotating_object: 9.9696
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0505
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 1.98s
                      Time elapsed: 00:14:26
                               ETA: 00:43:12

################################################################################
                     [1m Learning iteration 376/1500 [0m                      

                       Computation: 48065 steps/s (collection: 1.955s, learning 0.090s)
             Mean action noise std: 2.07
          Mean value_function loss: 31.6370
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 66.5101
                       Mean reward: 49.79
               Mean episode length: 217.03
    Episode_Reward/reaching_object: 1.1308
    Episode_Reward/rotating_object: 10.0366
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 2.05s
                      Time elapsed: 00:14:28
                               ETA: 00:43:09

################################################################################
                     [1m Learning iteration 377/1500 [0m                      

                       Computation: 47449 steps/s (collection: 1.969s, learning 0.103s)
             Mean action noise std: 2.08
          Mean value_function loss: 29.9564
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 66.5443
                       Mean reward: 47.64
               Mean episode length: 215.90
    Episode_Reward/reaching_object: 1.1329
    Episode_Reward/rotating_object: 9.0578
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0507
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 2.07s
                      Time elapsed: 00:14:30
                               ETA: 00:43:06

################################################################################
                     [1m Learning iteration 378/1500 [0m                      

                       Computation: 48098 steps/s (collection: 1.946s, learning 0.098s)
             Mean action noise std: 2.08
          Mean value_function loss: 32.8827
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 66.5746
                       Mean reward: 48.78
               Mean episode length: 216.17
    Episode_Reward/reaching_object: 1.1362
    Episode_Reward/rotating_object: 10.2002
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0507
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 2.04s
                      Time elapsed: 00:14:32
                               ETA: 00:43:03

################################################################################
                     [1m Learning iteration 379/1500 [0m                      

                       Computation: 47543 steps/s (collection: 1.958s, learning 0.110s)
             Mean action noise std: 2.08
          Mean value_function loss: 32.7381
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 66.6043
                       Mean reward: 62.43
               Mean episode length: 216.56
    Episode_Reward/reaching_object: 1.1590
    Episode_Reward/rotating_object: 11.5195
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0518
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 2.07s
                      Time elapsed: 00:14:34
                               ETA: 00:43:00

################################################################################
                     [1m Learning iteration 380/1500 [0m                      

                       Computation: 48016 steps/s (collection: 1.958s, learning 0.089s)
             Mean action noise std: 2.08
          Mean value_function loss: 33.6584
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 66.6277
                       Mean reward: 56.23
               Mean episode length: 222.29
    Episode_Reward/reaching_object: 1.1328
    Episode_Reward/rotating_object: 9.7450
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0516
      Episode_Termination/time_out: 12.2083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 2.05s
                      Time elapsed: 00:14:36
                               ETA: 00:42:57

################################################################################
                     [1m Learning iteration 381/1500 [0m                      

                       Computation: 47583 steps/s (collection: 1.945s, learning 0.121s)
             Mean action noise std: 2.09
          Mean value_function loss: 30.5709
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 66.6612
                       Mean reward: 65.59
               Mean episode length: 222.88
    Episode_Reward/reaching_object: 1.1465
    Episode_Reward/rotating_object: 10.2434
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0501
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 2.07s
                      Time elapsed: 00:14:38
                               ETA: 00:42:54

################################################################################
                     [1m Learning iteration 382/1500 [0m                      

                       Computation: 47038 steps/s (collection: 1.978s, learning 0.112s)
             Mean action noise std: 2.09
          Mean value_function loss: 32.6658
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 66.6941
                       Mean reward: 52.69
               Mean episode length: 222.81
    Episode_Reward/reaching_object: 1.1748
    Episode_Reward/rotating_object: 11.3633
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0502
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 2.09s
                      Time elapsed: 00:14:41
                               ETA: 00:42:51

################################################################################
                     [1m Learning iteration 383/1500 [0m                      

                       Computation: 47472 steps/s (collection: 1.968s, learning 0.103s)
             Mean action noise std: 2.09
          Mean value_function loss: 31.8771
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 66.7257
                       Mean reward: 51.99
               Mean episode length: 213.60
    Episode_Reward/reaching_object: 1.1706
    Episode_Reward/rotating_object: 10.5254
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0502
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 2.07s
                      Time elapsed: 00:14:43
                               ETA: 00:42:48

################################################################################
                     [1m Learning iteration 384/1500 [0m                      

                       Computation: 44097 steps/s (collection: 2.059s, learning 0.170s)
             Mean action noise std: 2.09
          Mean value_function loss: 32.5850
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 66.7565
                       Mean reward: 62.85
               Mean episode length: 220.87
    Episode_Reward/reaching_object: 1.1738
    Episode_Reward/rotating_object: 11.4505
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0514
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 2.23s
                      Time elapsed: 00:14:45
                               ETA: 00:42:46

################################################################################
                     [1m Learning iteration 385/1500 [0m                      

                       Computation: 45568 steps/s (collection: 2.069s, learning 0.089s)
             Mean action noise std: 2.09
          Mean value_function loss: 35.8436
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 66.7919
                       Mean reward: 44.95
               Mean episode length: 216.54
    Episode_Reward/reaching_object: 1.1933
    Episode_Reward/rotating_object: 11.6026
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0498
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 2.16s
                      Time elapsed: 00:14:47
                               ETA: 00:42:43

################################################################################
                     [1m Learning iteration 386/1500 [0m                      

                       Computation: 47653 steps/s (collection: 1.941s, learning 0.122s)
             Mean action noise std: 2.10
          Mean value_function loss: 38.9942
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 66.8270
                       Mean reward: 57.58
               Mean episode length: 224.46
    Episode_Reward/reaching_object: 1.1522
    Episode_Reward/rotating_object: 9.1619
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0513
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 2.06s
                      Time elapsed: 00:14:49
                               ETA: 00:42:40

################################################################################
                     [1m Learning iteration 387/1500 [0m                      

                       Computation: 42868 steps/s (collection: 2.202s, learning 0.092s)
             Mean action noise std: 2.10
          Mean value_function loss: 35.6904
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 66.8576
                       Mean reward: 65.08
               Mean episode length: 218.52
    Episode_Reward/reaching_object: 1.2026
    Episode_Reward/rotating_object: 10.8882
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0504
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 2.29s
                      Time elapsed: 00:14:51
                               ETA: 00:42:38

################################################################################
                     [1m Learning iteration 388/1500 [0m                      

                       Computation: 48398 steps/s (collection: 1.939s, learning 0.093s)
             Mean action noise std: 2.10
          Mean value_function loss: 36.4752
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 66.8860
                       Mean reward: 55.75
               Mean episode length: 207.50
    Episode_Reward/reaching_object: 1.1771
    Episode_Reward/rotating_object: 11.2492
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 2.03s
                      Time elapsed: 00:14:53
                               ETA: 00:42:35

################################################################################
                     [1m Learning iteration 389/1500 [0m                      

                       Computation: 46606 steps/s (collection: 1.994s, learning 0.116s)
             Mean action noise std: 2.10
          Mean value_function loss: 36.7754
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 66.9175
                       Mean reward: 57.08
               Mean episode length: 218.81
    Episode_Reward/reaching_object: 1.2038
    Episode_Reward/rotating_object: 8.8155
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0513
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 2.11s
                      Time elapsed: 00:14:55
                               ETA: 00:42:32

################################################################################
                     [1m Learning iteration 390/1500 [0m                      

                       Computation: 46401 steps/s (collection: 2.028s, learning 0.091s)
             Mean action noise std: 2.10
          Mean value_function loss: 39.7315
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 66.9544
                       Mean reward: 77.15
               Mean episode length: 225.86
    Episode_Reward/reaching_object: 1.1965
    Episode_Reward/rotating_object: 11.9342
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0506
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 2.12s
                      Time elapsed: 00:14:58
                               ETA: 00:42:29

################################################################################
                     [1m Learning iteration 391/1500 [0m                      

                       Computation: 46776 steps/s (collection: 1.972s, learning 0.130s)
             Mean action noise std: 2.11
          Mean value_function loss: 40.0948
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 66.9894
                       Mean reward: 71.88
               Mean episode length: 223.60
    Episode_Reward/reaching_object: 1.2281
    Episode_Reward/rotating_object: 12.3014
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0507
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 2.10s
                      Time elapsed: 00:15:00
                               ETA: 00:42:26

################################################################################
                     [1m Learning iteration 392/1500 [0m                      

                       Computation: 47537 steps/s (collection: 1.964s, learning 0.104s)
             Mean action noise std: 2.11
          Mean value_function loss: 36.0858
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 67.0286
                       Mean reward: 64.93
               Mean episode length: 221.32
    Episode_Reward/reaching_object: 1.2259
    Episode_Reward/rotating_object: 12.3414
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 2.07s
                      Time elapsed: 00:15:02
                               ETA: 00:42:23

################################################################################
                     [1m Learning iteration 393/1500 [0m                      

                       Computation: 47770 steps/s (collection: 1.961s, learning 0.097s)
             Mean action noise std: 2.11
          Mean value_function loss: 36.2371
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 67.0591
                       Mean reward: 61.93
               Mean episode length: 223.75
    Episode_Reward/reaching_object: 1.2377
    Episode_Reward/rotating_object: 12.3661
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0505
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 2.06s
                      Time elapsed: 00:15:04
                               ETA: 00:42:20

################################################################################
                     [1m Learning iteration 394/1500 [0m                      

                       Computation: 47427 steps/s (collection: 1.947s, learning 0.126s)
             Mean action noise std: 2.11
          Mean value_function loss: 34.2139
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 67.0957
                       Mean reward: 68.54
               Mean episode length: 211.95
    Episode_Reward/reaching_object: 1.1870
    Episode_Reward/rotating_object: 11.8857
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 2.07s
                      Time elapsed: 00:15:06
                               ETA: 00:42:17

################################################################################
                     [1m Learning iteration 395/1500 [0m                      

                       Computation: 46706 steps/s (collection: 2.008s, learning 0.097s)
             Mean action noise std: 2.12
          Mean value_function loss: 35.4674
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 67.1312
                       Mean reward: 63.50
               Mean episode length: 219.56
    Episode_Reward/reaching_object: 1.2364
    Episode_Reward/rotating_object: 14.1864
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0501
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 2.10s
                      Time elapsed: 00:15:08
                               ETA: 00:42:15

################################################################################
                     [1m Learning iteration 396/1500 [0m                      

                       Computation: 47313 steps/s (collection: 1.969s, learning 0.109s)
             Mean action noise std: 2.12
          Mean value_function loss: 37.0555
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 67.1668
                       Mean reward: 85.48
               Mean episode length: 225.52
    Episode_Reward/reaching_object: 1.2467
    Episode_Reward/rotating_object: 11.6051
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0511
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 2.08s
                      Time elapsed: 00:15:10
                               ETA: 00:42:12

################################################################################
                     [1m Learning iteration 397/1500 [0m                      

                       Computation: 47884 steps/s (collection: 1.961s, learning 0.092s)
             Mean action noise std: 2.12
          Mean value_function loss: 35.3651
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 67.1988
                       Mean reward: 68.61
               Mean episode length: 217.26
    Episode_Reward/reaching_object: 1.2126
    Episode_Reward/rotating_object: 13.3379
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 2.05s
                      Time elapsed: 00:15:12
                               ETA: 00:42:09

################################################################################
                     [1m Learning iteration 398/1500 [0m                      

                       Computation: 47198 steps/s (collection: 1.981s, learning 0.102s)
             Mean action noise std: 2.12
          Mean value_function loss: 41.3847
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 67.2341
                       Mean reward: 79.38
               Mean episode length: 223.42
    Episode_Reward/reaching_object: 1.2050
    Episode_Reward/rotating_object: 11.5087
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0500
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 2.08s
                      Time elapsed: 00:15:14
                               ETA: 00:42:06

################################################################################
                     [1m Learning iteration 399/1500 [0m                      

                       Computation: 47323 steps/s (collection: 1.968s, learning 0.109s)
             Mean action noise std: 2.13
          Mean value_function loss: 34.2905
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 67.2687
                       Mean reward: 50.67
               Mean episode length: 219.80
    Episode_Reward/reaching_object: 1.2170
    Episode_Reward/rotating_object: 13.4108
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0495
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 2.08s
                      Time elapsed: 00:15:16
                               ETA: 00:42:03

################################################################################
                     [1m Learning iteration 400/1500 [0m                      

                       Computation: 46459 steps/s (collection: 1.998s, learning 0.118s)
             Mean action noise std: 2.13
          Mean value_function loss: 38.1881
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 67.3035
                       Mean reward: 77.83
               Mean episode length: 227.92
    Episode_Reward/reaching_object: 1.2344
    Episode_Reward/rotating_object: 12.8777
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0501
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 2.12s
                      Time elapsed: 00:15:18
                               ETA: 00:42:00

################################################################################
                     [1m Learning iteration 401/1500 [0m                      

                       Computation: 47129 steps/s (collection: 1.980s, learning 0.106s)
             Mean action noise std: 2.13
          Mean value_function loss: 41.7728
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 67.3337
                       Mean reward: 65.90
               Mean episode length: 213.73
    Episode_Reward/reaching_object: 1.2062
    Episode_Reward/rotating_object: 11.3215
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 2.09s
                      Time elapsed: 00:15:20
                               ETA: 00:41:57

################################################################################
                     [1m Learning iteration 402/1500 [0m                      

                       Computation: 47438 steps/s (collection: 1.980s, learning 0.092s)
             Mean action noise std: 2.13
          Mean value_function loss: 33.6974
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 67.3692
                       Mean reward: 49.87
               Mean episode length: 219.75
    Episode_Reward/reaching_object: 1.2233
    Episode_Reward/rotating_object: 11.4517
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0502
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 2.07s
                      Time elapsed: 00:15:23
                               ETA: 00:41:54

################################################################################
                     [1m Learning iteration 403/1500 [0m                      

                       Computation: 48028 steps/s (collection: 1.951s, learning 0.096s)
             Mean action noise std: 2.14
          Mean value_function loss: 34.3176
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 67.3984
                       Mean reward: 76.96
               Mean episode length: 224.42
    Episode_Reward/reaching_object: 1.2488
    Episode_Reward/rotating_object: 13.4241
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0494
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 2.05s
                      Time elapsed: 00:15:25
                               ETA: 00:41:51

################################################################################
                     [1m Learning iteration 404/1500 [0m                      

                       Computation: 46596 steps/s (collection: 1.973s, learning 0.137s)
             Mean action noise std: 2.14
          Mean value_function loss: 36.4377
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 67.4299
                       Mean reward: 54.44
               Mean episode length: 220.84
    Episode_Reward/reaching_object: 1.2262
    Episode_Reward/rotating_object: 11.6350
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 2.11s
                      Time elapsed: 00:15:27
                               ETA: 00:41:49

################################################################################
                     [1m Learning iteration 405/1500 [0m                      

                       Computation: 47644 steps/s (collection: 1.965s, learning 0.099s)
             Mean action noise std: 2.14
          Mean value_function loss: 33.2753
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 67.4649
                       Mean reward: 66.48
               Mean episode length: 217.41
    Episode_Reward/reaching_object: 1.2379
    Episode_Reward/rotating_object: 12.1179
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 2.06s
                      Time elapsed: 00:15:29
                               ETA: 00:41:46

################################################################################
                     [1m Learning iteration 406/1500 [0m                      

                       Computation: 47749 steps/s (collection: 1.955s, learning 0.104s)
             Mean action noise std: 2.14
          Mean value_function loss: 39.5316
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 67.4972
                       Mean reward: 66.11
               Mean episode length: 215.61
    Episode_Reward/reaching_object: 1.2961
    Episode_Reward/rotating_object: 12.5983
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0504
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 2.06s
                      Time elapsed: 00:15:31
                               ETA: 00:41:43

################################################################################
                     [1m Learning iteration 407/1500 [0m                      

                       Computation: 47390 steps/s (collection: 1.943s, learning 0.132s)
             Mean action noise std: 2.14
          Mean value_function loss: 40.3066
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 67.5267
                       Mean reward: 61.04
               Mean episode length: 211.49
    Episode_Reward/reaching_object: 1.2247
    Episode_Reward/rotating_object: 13.4321
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0500
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 2.07s
                      Time elapsed: 00:15:33
                               ETA: 00:41:40

################################################################################
                     [1m Learning iteration 408/1500 [0m                      

                       Computation: 46809 steps/s (collection: 1.981s, learning 0.119s)
             Mean action noise std: 2.15
          Mean value_function loss: 36.7221
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 67.5628
                       Mean reward: 93.38
               Mean episode length: 218.88
    Episode_Reward/reaching_object: 1.2558
    Episode_Reward/rotating_object: 14.1578
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 2.10s
                      Time elapsed: 00:15:35
                               ETA: 00:41:37

################################################################################
                     [1m Learning iteration 409/1500 [0m                      

                       Computation: 47611 steps/s (collection: 1.973s, learning 0.092s)
             Mean action noise std: 2.15
          Mean value_function loss: 41.7970
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 67.5944
                       Mean reward: 59.28
               Mean episode length: 226.92
    Episode_Reward/reaching_object: 1.2858
    Episode_Reward/rotating_object: 12.7441
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0506
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 2.06s
                      Time elapsed: 00:15:37
                               ETA: 00:41:34

################################################################################
                     [1m Learning iteration 410/1500 [0m                      

                       Computation: 47578 steps/s (collection: 1.976s, learning 0.090s)
             Mean action noise std: 2.15
          Mean value_function loss: 45.0895
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 67.6210
                       Mean reward: 86.12
               Mean episode length: 223.42
    Episode_Reward/reaching_object: 1.2802
    Episode_Reward/rotating_object: 15.4529
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0498
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 2.07s
                      Time elapsed: 00:15:39
                               ETA: 00:41:32

################################################################################
                     [1m Learning iteration 411/1500 [0m                      

                       Computation: 47411 steps/s (collection: 1.968s, learning 0.106s)
             Mean action noise std: 2.15
          Mean value_function loss: 42.3460
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 67.6466
                       Mean reward: 76.23
               Mean episode length: 210.27
    Episode_Reward/reaching_object: 1.2504
    Episode_Reward/rotating_object: 13.0710
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 2.07s
                      Time elapsed: 00:15:41
                               ETA: 00:41:29

################################################################################
                     [1m Learning iteration 412/1500 [0m                      

                       Computation: 47475 steps/s (collection: 1.978s, learning 0.092s)
             Mean action noise std: 2.15
          Mean value_function loss: 39.5377
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 67.6775
                       Mean reward: 59.06
               Mean episode length: 219.42
    Episode_Reward/reaching_object: 1.2995
    Episode_Reward/rotating_object: 11.8226
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0504
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 2.07s
                      Time elapsed: 00:15:43
                               ETA: 00:41:26

################################################################################
                     [1m Learning iteration 413/1500 [0m                      

                       Computation: 44680 steps/s (collection: 2.022s, learning 0.178s)
             Mean action noise std: 2.16
          Mean value_function loss: 38.9917
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 67.7119
                       Mean reward: 73.76
               Mean episode length: 225.35
    Episode_Reward/reaching_object: 1.2995
    Episode_Reward/rotating_object: 13.9206
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 2.20s
                      Time elapsed: 00:15:45
                               ETA: 00:41:23

################################################################################
                     [1m Learning iteration 414/1500 [0m                      

                       Computation: 45990 steps/s (collection: 2.030s, learning 0.108s)
             Mean action noise std: 2.16
          Mean value_function loss: 37.1484
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 67.7507
                       Mean reward: 70.23
               Mean episode length: 228.29
    Episode_Reward/reaching_object: 1.2802
    Episode_Reward/rotating_object: 12.7415
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0504
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 2.14s
                      Time elapsed: 00:15:48
                               ETA: 00:41:21

################################################################################
                     [1m Learning iteration 415/1500 [0m                      

                       Computation: 46964 steps/s (collection: 1.989s, learning 0.104s)
             Mean action noise std: 2.16
          Mean value_function loss: 42.0240
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 67.7851
                       Mean reward: 92.85
               Mean episode length: 221.67
    Episode_Reward/reaching_object: 1.3213
    Episode_Reward/rotating_object: 17.1680
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0494
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 2.09s
                      Time elapsed: 00:15:50
                               ETA: 00:41:18

################################################################################
                     [1m Learning iteration 416/1500 [0m                      

                       Computation: 45235 steps/s (collection: 2.016s, learning 0.157s)
             Mean action noise std: 2.16
          Mean value_function loss: 36.2626
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 67.8149
                       Mean reward: 83.39
               Mean episode length: 213.23
    Episode_Reward/reaching_object: 1.2938
    Episode_Reward/rotating_object: 13.9270
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 2.17s
                      Time elapsed: 00:15:52
                               ETA: 00:41:15

################################################################################
                     [1m Learning iteration 417/1500 [0m                      

                       Computation: 47544 steps/s (collection: 1.956s, learning 0.112s)
             Mean action noise std: 2.17
          Mean value_function loss: 40.2379
               Mean surrogate loss: -0.0111
                 Mean entropy loss: 67.8473
                       Mean reward: 87.15
               Mean episode length: 224.59
    Episode_Reward/reaching_object: 1.3080
    Episode_Reward/rotating_object: 16.0069
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 2.07s
                      Time elapsed: 00:15:54
                               ETA: 00:41:12

################################################################################
                     [1m Learning iteration 418/1500 [0m                      

                       Computation: 45764 steps/s (collection: 2.014s, learning 0.134s)
             Mean action noise std: 2.17
          Mean value_function loss: 38.7891
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 67.8785
                       Mean reward: 103.07
               Mean episode length: 230.11
    Episode_Reward/reaching_object: 1.2737
    Episode_Reward/rotating_object: 15.5663
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 2.15s
                      Time elapsed: 00:15:56
                               ETA: 00:41:10

################################################################################
                     [1m Learning iteration 419/1500 [0m                      

                       Computation: 46784 steps/s (collection: 2.001s, learning 0.101s)
             Mean action noise std: 2.17
          Mean value_function loss: 39.9312
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 67.9146
                       Mean reward: 75.88
               Mean episode length: 216.15
    Episode_Reward/reaching_object: 1.2804
    Episode_Reward/rotating_object: 13.4468
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 2.10s
                      Time elapsed: 00:15:58
                               ETA: 00:41:07

################################################################################
                     [1m Learning iteration 420/1500 [0m                      

                       Computation: 45160 steps/s (collection: 2.036s, learning 0.141s)
             Mean action noise std: 2.17
          Mean value_function loss: 38.2676
               Mean surrogate loss: -0.0111
                 Mean entropy loss: 67.9518
                       Mean reward: 109.80
               Mean episode length: 224.95
    Episode_Reward/reaching_object: 1.3107
    Episode_Reward/rotating_object: 14.7583
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 2.18s
                      Time elapsed: 00:16:00
                               ETA: 00:41:04

################################################################################
                     [1m Learning iteration 421/1500 [0m                      

                       Computation: 47525 steps/s (collection: 1.977s, learning 0.092s)
             Mean action noise std: 2.18
          Mean value_function loss: 35.7478
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 67.9918
                       Mean reward: 79.57
               Mean episode length: 210.33
    Episode_Reward/reaching_object: 1.2902
    Episode_Reward/rotating_object: 14.5228
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 2.07s
                      Time elapsed: 00:16:02
                               ETA: 00:41:02

################################################################################
                     [1m Learning iteration 422/1500 [0m                      

                       Computation: 47331 steps/s (collection: 1.979s, learning 0.098s)
             Mean action noise std: 2.18
          Mean value_function loss: 36.8538
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 68.0241
                       Mean reward: 106.84
               Mean episode length: 220.25
    Episode_Reward/reaching_object: 1.3427
    Episode_Reward/rotating_object: 15.1551
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0494
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 2.08s
                      Time elapsed: 00:16:05
                               ETA: 00:40:59

################################################################################
                     [1m Learning iteration 423/1500 [0m                      

                       Computation: 47963 steps/s (collection: 1.960s, learning 0.090s)
             Mean action noise std: 2.18
          Mean value_function loss: 37.2910
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 68.0488
                       Mean reward: 74.22
               Mean episode length: 222.85
    Episode_Reward/reaching_object: 1.3276
    Episode_Reward/rotating_object: 13.0822
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 2.05s
                      Time elapsed: 00:16:07
                               ETA: 00:40:56

################################################################################
                     [1m Learning iteration 424/1500 [0m                      

                       Computation: 46854 steps/s (collection: 2.003s, learning 0.095s)
             Mean action noise std: 2.18
          Mean value_function loss: 38.0789
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 68.0852
                       Mean reward: 72.02
               Mean episode length: 212.28
    Episode_Reward/reaching_object: 1.2573
    Episode_Reward/rotating_object: 14.2573
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 2.10s
                      Time elapsed: 00:16:09
                               ETA: 00:40:53

################################################################################
                     [1m Learning iteration 425/1500 [0m                      

                       Computation: 45210 steps/s (collection: 2.037s, learning 0.137s)
             Mean action noise std: 2.19
          Mean value_function loss: 43.7206
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 68.1163
                       Mean reward: 82.71
               Mean episode length: 218.69
    Episode_Reward/reaching_object: 1.2971
    Episode_Reward/rotating_object: 15.1035
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 2.17s
                      Time elapsed: 00:16:11
                               ETA: 00:40:51

################################################################################
                     [1m Learning iteration 426/1500 [0m                      

                       Computation: 44726 steps/s (collection: 2.074s, learning 0.124s)
             Mean action noise std: 2.19
          Mean value_function loss: 44.4922
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 68.1430
                       Mean reward: 83.27
               Mean episode length: 209.84
    Episode_Reward/reaching_object: 1.2987
    Episode_Reward/rotating_object: 14.0243
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 2.20s
                      Time elapsed: 00:16:13
                               ETA: 00:40:48

################################################################################
                     [1m Learning iteration 427/1500 [0m                      

                       Computation: 44006 steps/s (collection: 2.067s, learning 0.167s)
             Mean action noise std: 2.19
          Mean value_function loss: 44.0818
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 68.1755
                       Mean reward: 76.96
               Mean episode length: 213.28
    Episode_Reward/reaching_object: 1.3170
    Episode_Reward/rotating_object: 14.6834
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 2.23s
                      Time elapsed: 00:16:15
                               ETA: 00:40:46

################################################################################
                     [1m Learning iteration 428/1500 [0m                      

                       Computation: 46732 steps/s (collection: 2.011s, learning 0.092s)
             Mean action noise std: 2.19
          Mean value_function loss: 46.0335
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 68.2122
                       Mean reward: 76.68
               Mean episode length: 215.06
    Episode_Reward/reaching_object: 1.3392
    Episode_Reward/rotating_object: 13.1160
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 2.10s
                      Time elapsed: 00:16:17
                               ETA: 00:40:43

################################################################################
                     [1m Learning iteration 429/1500 [0m                      

                       Computation: 47684 steps/s (collection: 1.971s, learning 0.091s)
             Mean action noise std: 2.20
          Mean value_function loss: 45.2892
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 68.2500
                       Mean reward: 73.93
               Mean episode length: 222.80
    Episode_Reward/reaching_object: 1.3817
    Episode_Reward/rotating_object: 14.9956
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 2.06s
                      Time elapsed: 00:16:19
                               ETA: 00:40:40

################################################################################
                     [1m Learning iteration 430/1500 [0m                      

                       Computation: 48181 steps/s (collection: 1.946s, learning 0.094s)
             Mean action noise std: 2.20
          Mean value_function loss: 37.7294
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 68.2822
                       Mean reward: 61.63
               Mean episode length: 192.56
    Episode_Reward/reaching_object: 1.3032
    Episode_Reward/rotating_object: 15.7263
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 2.04s
                      Time elapsed: 00:16:21
                               ETA: 00:40:37

################################################################################
                     [1m Learning iteration 431/1500 [0m                      

                       Computation: 46181 steps/s (collection: 2.027s, learning 0.101s)
             Mean action noise std: 2.20
          Mean value_function loss: 42.0570
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 68.3095
                       Mean reward: 80.14
               Mean episode length: 221.37
    Episode_Reward/reaching_object: 1.3398
    Episode_Reward/rotating_object: 15.8466
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 2.13s
                      Time elapsed: 00:16:24
                               ETA: 00:40:35

################################################################################
                     [1m Learning iteration 432/1500 [0m                      

                       Computation: 47449 steps/s (collection: 1.979s, learning 0.093s)
             Mean action noise std: 2.20
          Mean value_function loss: 38.0795
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 68.3390
                       Mean reward: 91.70
               Mean episode length: 215.67
    Episode_Reward/reaching_object: 1.3046
    Episode_Reward/rotating_object: 15.6484
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 2.07s
                      Time elapsed: 00:16:26
                               ETA: 00:40:32

################################################################################
                     [1m Learning iteration 433/1500 [0m                      

                       Computation: 45082 steps/s (collection: 2.085s, learning 0.096s)
             Mean action noise std: 2.20
          Mean value_function loss: 39.3808
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 68.3735
                       Mean reward: 84.70
               Mean episode length: 221.89
    Episode_Reward/reaching_object: 1.3766
    Episode_Reward/rotating_object: 16.1547
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 2.18s
                      Time elapsed: 00:16:28
                               ETA: 00:40:29

################################################################################
                     [1m Learning iteration 434/1500 [0m                      

                       Computation: 44242 steps/s (collection: 2.057s, learning 0.165s)
             Mean action noise std: 2.21
          Mean value_function loss: 40.6597
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 68.4026
                       Mean reward: 99.09
               Mean episode length: 231.95
    Episode_Reward/reaching_object: 1.3298
    Episode_Reward/rotating_object: 15.1502
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 2.22s
                      Time elapsed: 00:16:30
                               ETA: 00:40:27

################################################################################
                     [1m Learning iteration 435/1500 [0m                      

                       Computation: 46994 steps/s (collection: 1.979s, learning 0.113s)
             Mean action noise std: 2.21
          Mean value_function loss: 39.0763
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 68.4373
                       Mean reward: 98.65
               Mean episode length: 220.02
    Episode_Reward/reaching_object: 1.3129
    Episode_Reward/rotating_object: 17.9016
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 2.09s
                      Time elapsed: 00:16:32
                               ETA: 00:40:24

################################################################################
                     [1m Learning iteration 436/1500 [0m                      

                       Computation: 47095 steps/s (collection: 1.980s, learning 0.107s)
             Mean action noise std: 2.21
          Mean value_function loss: 42.2995
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 68.4784
                       Mean reward: 78.75
               Mean episode length: 219.58
    Episode_Reward/reaching_object: 1.3508
    Episode_Reward/rotating_object: 18.1925
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 2.09s
                      Time elapsed: 00:16:34
                               ETA: 00:40:22

################################################################################
                     [1m Learning iteration 437/1500 [0m                      

                       Computation: 46604 steps/s (collection: 1.999s, learning 0.111s)
             Mean action noise std: 2.21
          Mean value_function loss: 43.4884
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 68.5121
                       Mean reward: 90.77
               Mean episode length: 213.18
    Episode_Reward/reaching_object: 1.3150
    Episode_Reward/rotating_object: 16.7295
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 2.11s
                      Time elapsed: 00:16:36
                               ETA: 00:40:19

################################################################################
                     [1m Learning iteration 438/1500 [0m                      

                       Computation: 47207 steps/s (collection: 1.988s, learning 0.094s)
             Mean action noise std: 2.22
          Mean value_function loss: 40.5858
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 68.5519
                       Mean reward: 102.01
               Mean episode length: 211.44
    Episode_Reward/reaching_object: 1.3230
    Episode_Reward/rotating_object: 18.0213
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 2.08s
                      Time elapsed: 00:16:38
                               ETA: 00:40:16

################################################################################
                     [1m Learning iteration 439/1500 [0m                      

                       Computation: 46503 steps/s (collection: 2.006s, learning 0.108s)
             Mean action noise std: 2.22
          Mean value_function loss: 42.0252
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 68.5821
                       Mean reward: 86.42
               Mean episode length: 212.14
    Episode_Reward/reaching_object: 1.3811
    Episode_Reward/rotating_object: 16.4316
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 2.11s
                      Time elapsed: 00:16:41
                               ETA: 00:40:13

################################################################################
                     [1m Learning iteration 440/1500 [0m                      

                       Computation: 46429 steps/s (collection: 2.027s, learning 0.091s)
             Mean action noise std: 2.22
          Mean value_function loss: 42.6210
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 68.6105
                       Mean reward: 94.97
               Mean episode length: 209.63
    Episode_Reward/reaching_object: 1.3218
    Episode_Reward/rotating_object: 17.5082
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 2.12s
                      Time elapsed: 00:16:43
                               ETA: 00:40:11

################################################################################
                     [1m Learning iteration 441/1500 [0m                      

                       Computation: 47036 steps/s (collection: 1.982s, learning 0.108s)
             Mean action noise std: 2.22
          Mean value_function loss: 40.1615
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 68.6332
                       Mean reward: 101.88
               Mean episode length: 214.29
    Episode_Reward/reaching_object: 1.4056
    Episode_Reward/rotating_object: 17.6983
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 2.09s
                      Time elapsed: 00:16:45
                               ETA: 00:40:08

################################################################################
                     [1m Learning iteration 442/1500 [0m                      

                       Computation: 46774 steps/s (collection: 2.011s, learning 0.090s)
             Mean action noise std: 2.22
          Mean value_function loss: 44.2723
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 68.6540
                       Mean reward: 93.30
               Mean episode length: 216.32
    Episode_Reward/reaching_object: 1.3843
    Episode_Reward/rotating_object: 17.6657
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 2.10s
                      Time elapsed: 00:16:47
                               ETA: 00:40:05

################################################################################
                     [1m Learning iteration 443/1500 [0m                      

                       Computation: 46011 steps/s (collection: 1.992s, learning 0.144s)
             Mean action noise std: 2.23
          Mean value_function loss: 47.5973
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 68.6894
                       Mean reward: 107.36
               Mean episode length: 207.31
    Episode_Reward/reaching_object: 1.3627
    Episode_Reward/rotating_object: 18.4266
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 2.14s
                      Time elapsed: 00:16:49
                               ETA: 00:40:03

################################################################################
                     [1m Learning iteration 444/1500 [0m                      

                       Computation: 46859 steps/s (collection: 1.991s, learning 0.107s)
             Mean action noise std: 2.23
          Mean value_function loss: 47.0003
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 68.7240
                       Mean reward: 99.61
               Mean episode length: 221.62
    Episode_Reward/reaching_object: 1.3729
    Episode_Reward/rotating_object: 17.3316
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 2.10s
                      Time elapsed: 00:16:51
                               ETA: 00:40:00

################################################################################
                     [1m Learning iteration 445/1500 [0m                      

                       Computation: 47862 steps/s (collection: 1.963s, learning 0.091s)
             Mean action noise std: 2.23
          Mean value_function loss: 48.7096
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 68.7572
                       Mean reward: 78.90
               Mean episode length: 214.84
    Episode_Reward/reaching_object: 1.3937
    Episode_Reward/rotating_object: 17.5725
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 2.05s
                      Time elapsed: 00:16:53
                               ETA: 00:39:57

################################################################################
                     [1m Learning iteration 446/1500 [0m                      

                       Computation: 45341 steps/s (collection: 2.035s, learning 0.133s)
             Mean action noise std: 2.23
          Mean value_function loss: 39.6198
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 68.7887
                       Mean reward: 97.15
               Mean episode length: 213.43
    Episode_Reward/reaching_object: 1.3451
    Episode_Reward/rotating_object: 16.9309
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 12.0417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 2.17s
                      Time elapsed: 00:16:55
                               ETA: 00:39:55

################################################################################
                     [1m Learning iteration 447/1500 [0m                      

                       Computation: 46550 steps/s (collection: 2.002s, learning 0.110s)
             Mean action noise std: 2.24
          Mean value_function loss: 42.2335
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 68.8247
                       Mean reward: 76.23
               Mean episode length: 219.30
    Episode_Reward/reaching_object: 1.4117
    Episode_Reward/rotating_object: 15.5987
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 2.11s
                      Time elapsed: 00:16:57
                               ETA: 00:39:52

################################################################################
                     [1m Learning iteration 448/1500 [0m                      

                       Computation: 45535 steps/s (collection: 1.992s, learning 0.167s)
             Mean action noise std: 2.24
          Mean value_function loss: 45.6231
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 68.8657
                       Mean reward: 102.59
               Mean episode length: 224.12
    Episode_Reward/reaching_object: 1.4608
    Episode_Reward/rotating_object: 20.2045
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 2.16s
                      Time elapsed: 00:17:00
                               ETA: 00:39:50

################################################################################
                     [1m Learning iteration 449/1500 [0m                      

                       Computation: 44481 steps/s (collection: 2.051s, learning 0.159s)
             Mean action noise std: 2.24
          Mean value_function loss: 45.5858
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 68.9003
                       Mean reward: 107.73
               Mean episode length: 227.16
    Episode_Reward/reaching_object: 1.4059
    Episode_Reward/rotating_object: 17.6702
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 2.21s
                      Time elapsed: 00:17:02
                               ETA: 00:39:47

################################################################################
                     [1m Learning iteration 450/1500 [0m                      

                       Computation: 47135 steps/s (collection: 1.991s, learning 0.095s)
             Mean action noise std: 2.24
          Mean value_function loss: 47.5329
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 68.9331
                       Mean reward: 106.77
               Mean episode length: 223.65
    Episode_Reward/reaching_object: 1.4693
    Episode_Reward/rotating_object: 20.8774
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 2.09s
                      Time elapsed: 00:17:04
                               ETA: 00:39:44

################################################################################
                     [1m Learning iteration 451/1500 [0m                      

                       Computation: 46241 steps/s (collection: 2.025s, learning 0.101s)
             Mean action noise std: 2.25
          Mean value_function loss: 49.5974
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 68.9691
                       Mean reward: 96.03
               Mean episode length: 211.70
    Episode_Reward/reaching_object: 1.3773
    Episode_Reward/rotating_object: 18.4113
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 2.13s
                      Time elapsed: 00:17:06
                               ETA: 00:39:42

################################################################################
                     [1m Learning iteration 452/1500 [0m                      

                       Computation: 47286 steps/s (collection: 1.980s, learning 0.098s)
             Mean action noise std: 2.25
          Mean value_function loss: 44.8758
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 69.0025
                       Mean reward: 90.95
               Mean episode length: 209.37
    Episode_Reward/reaching_object: 1.3864
    Episode_Reward/rotating_object: 19.9251
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 2.08s
                      Time elapsed: 00:17:08
                               ETA: 00:39:39

################################################################################
                     [1m Learning iteration 453/1500 [0m                      

                       Computation: 47394 steps/s (collection: 1.932s, learning 0.143s)
             Mean action noise std: 2.25
          Mean value_function loss: 45.8871
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 69.0316
                       Mean reward: 108.62
               Mean episode length: 213.96
    Episode_Reward/reaching_object: 1.3928
    Episode_Reward/rotating_object: 17.7162
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 2.07s
                      Time elapsed: 00:17:10
                               ETA: 00:39:36

################################################################################
                     [1m Learning iteration 454/1500 [0m                      

                       Computation: 45440 steps/s (collection: 2.024s, learning 0.140s)
             Mean action noise std: 2.25
          Mean value_function loss: 45.4514
               Mean surrogate loss: -0.0112
                 Mean entropy loss: 69.0597
                       Mean reward: 83.39
               Mean episode length: 212.94
    Episode_Reward/reaching_object: 1.4222
    Episode_Reward/rotating_object: 17.4017
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 2.16s
                      Time elapsed: 00:17:12
                               ETA: 00:39:34

################################################################################
                     [1m Learning iteration 455/1500 [0m                      

                       Computation: 46080 steps/s (collection: 2.022s, learning 0.112s)
             Mean action noise std: 2.26
          Mean value_function loss: 43.8981
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 69.0940
                       Mean reward: 72.70
               Mean episode length: 213.38
    Episode_Reward/reaching_object: 1.3980
    Episode_Reward/rotating_object: 16.8060
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 2.13s
                      Time elapsed: 00:17:14
                               ETA: 00:39:31

################################################################################
                     [1m Learning iteration 456/1500 [0m                      

                       Computation: 46980 steps/s (collection: 2.002s, learning 0.091s)
             Mean action noise std: 2.26
          Mean value_function loss: 46.6739
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 69.1344
                       Mean reward: 91.31
               Mean episode length: 216.58
    Episode_Reward/reaching_object: 1.4038
    Episode_Reward/rotating_object: 20.1741
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 2.09s
                      Time elapsed: 00:17:17
                               ETA: 00:39:29

################################################################################
                     [1m Learning iteration 457/1500 [0m                      

                       Computation: 44392 steps/s (collection: 2.115s, learning 0.099s)
             Mean action noise std: 2.26
          Mean value_function loss: 50.1858
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 69.1642
                       Mean reward: 108.82
               Mean episode length: 217.11
    Episode_Reward/reaching_object: 1.3966
    Episode_Reward/rotating_object: 18.6253
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 2.21s
                      Time elapsed: 00:17:19
                               ETA: 00:39:26

################################################################################
                     [1m Learning iteration 458/1500 [0m                      

                       Computation: 46878 steps/s (collection: 2.007s, learning 0.090s)
             Mean action noise std: 2.26
          Mean value_function loss: 38.8056
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 69.1916
                       Mean reward: 86.42
               Mean episode length: 217.51
    Episode_Reward/reaching_object: 1.4255
    Episode_Reward/rotating_object: 17.5943
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 2.10s
                      Time elapsed: 00:17:21
                               ETA: 00:39:24

################################################################################
                     [1m Learning iteration 459/1500 [0m                      

                       Computation: 44597 steps/s (collection: 2.079s, learning 0.126s)
             Mean action noise std: 2.27
          Mean value_function loss: 46.5052
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 69.2242
                       Mean reward: 138.16
               Mean episode length: 220.21
    Episode_Reward/reaching_object: 1.4087
    Episode_Reward/rotating_object: 21.3164
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0466
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 2.20s
                      Time elapsed: 00:17:23
                               ETA: 00:39:21

################################################################################
                     [1m Learning iteration 460/1500 [0m                      

                       Computation: 43247 steps/s (collection: 2.125s, learning 0.148s)
             Mean action noise std: 2.27
          Mean value_function loss: 44.9276
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 69.2516
                       Mean reward: 94.98
               Mean episode length: 216.92
    Episode_Reward/reaching_object: 1.4063
    Episode_Reward/rotating_object: 18.6841
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 2.27s
                      Time elapsed: 00:17:25
                               ETA: 00:39:19

################################################################################
                     [1m Learning iteration 461/1500 [0m                      

                       Computation: 46628 steps/s (collection: 1.996s, learning 0.112s)
             Mean action noise std: 2.27
          Mean value_function loss: 47.3179
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 69.2815
                       Mean reward: 104.59
               Mean episode length: 222.40
    Episode_Reward/reaching_object: 1.4022
    Episode_Reward/rotating_object: 20.7455
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 2.11s
                      Time elapsed: 00:17:27
                               ETA: 00:39:16

################################################################################
                     [1m Learning iteration 462/1500 [0m                      

                       Computation: 46578 steps/s (collection: 2.016s, learning 0.094s)
             Mean action noise std: 2.27
          Mean value_function loss: 44.6062
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 69.3071
                       Mean reward: 87.52
               Mean episode length: 217.05
    Episode_Reward/reaching_object: 1.4275
    Episode_Reward/rotating_object: 19.2645
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 2.11s
                      Time elapsed: 00:17:30
                               ETA: 00:39:14

################################################################################
                     [1m Learning iteration 463/1500 [0m                      

                       Computation: 47295 steps/s (collection: 1.982s, learning 0.097s)
             Mean action noise std: 2.27
          Mean value_function loss: 44.1150
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 69.3338
                       Mean reward: 103.33
               Mean episode length: 216.12
    Episode_Reward/reaching_object: 1.4329
    Episode_Reward/rotating_object: 19.6006
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 2.08s
                      Time elapsed: 00:17:32
                               ETA: 00:39:11

################################################################################
                     [1m Learning iteration 464/1500 [0m                      

                       Computation: 46826 steps/s (collection: 1.994s, learning 0.106s)
             Mean action noise std: 2.28
          Mean value_function loss: 47.3033
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 69.3695
                       Mean reward: 123.16
               Mean episode length: 217.79
    Episode_Reward/reaching_object: 1.4184
    Episode_Reward/rotating_object: 18.8400
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 2.10s
                      Time elapsed: 00:17:34
                               ETA: 00:39:08

################################################################################
                     [1m Learning iteration 465/1500 [0m                      

                       Computation: 47008 steps/s (collection: 1.998s, learning 0.094s)
             Mean action noise std: 2.28
          Mean value_function loss: 45.6665
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 69.4050
                       Mean reward: 105.80
               Mean episode length: 226.63
    Episode_Reward/reaching_object: 1.4619
    Episode_Reward/rotating_object: 20.1870
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 2.09s
                      Time elapsed: 00:17:36
                               ETA: 00:39:06

################################################################################
                     [1m Learning iteration 466/1500 [0m                      

                       Computation: 47031 steps/s (collection: 1.988s, learning 0.103s)
             Mean action noise std: 2.28
          Mean value_function loss: 49.2996
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 69.4416
                       Mean reward: 122.04
               Mean episode length: 211.17
    Episode_Reward/reaching_object: 1.4225
    Episode_Reward/rotating_object: 19.6200
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 2.09s
                      Time elapsed: 00:17:38
                               ETA: 00:39:03

################################################################################
                     [1m Learning iteration 467/1500 [0m                      

                       Computation: 46719 steps/s (collection: 1.991s, learning 0.113s)
             Mean action noise std: 2.28
          Mean value_function loss: 48.4430
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 69.4732
                       Mean reward: 96.89
               Mean episode length: 218.03
    Episode_Reward/reaching_object: 1.4487
    Episode_Reward/rotating_object: 19.1282
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0472
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 2.10s
                      Time elapsed: 00:17:40
                               ETA: 00:39:00

################################################################################
                     [1m Learning iteration 468/1500 [0m                      

                       Computation: 45359 steps/s (collection: 2.018s, learning 0.150s)
             Mean action noise std: 2.29
          Mean value_function loss: 50.8043
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 69.4969
                       Mean reward: 116.54
               Mean episode length: 211.57
    Episode_Reward/reaching_object: 1.4497
    Episode_Reward/rotating_object: 21.6027
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 2.17s
                      Time elapsed: 00:17:42
                               ETA: 00:38:58

################################################################################
                     [1m Learning iteration 469/1500 [0m                      

                       Computation: 43790 steps/s (collection: 2.123s, learning 0.122s)
             Mean action noise std: 2.29
          Mean value_function loss: 49.5693
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 69.5202
                       Mean reward: 107.07
               Mean episode length: 219.35
    Episode_Reward/reaching_object: 1.4461
    Episode_Reward/rotating_object: 19.8999
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 2.24s
                      Time elapsed: 00:17:44
                               ETA: 00:38:56

################################################################################
                     [1m Learning iteration 470/1500 [0m                      

                       Computation: 45784 steps/s (collection: 2.013s, learning 0.134s)
             Mean action noise std: 2.29
          Mean value_function loss: 49.1119
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 69.5487
                       Mean reward: 94.22
               Mean episode length: 211.48
    Episode_Reward/reaching_object: 1.4562
    Episode_Reward/rotating_object: 19.9726
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0468
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 2.15s
                      Time elapsed: 00:17:47
                               ETA: 00:38:53

################################################################################
                     [1m Learning iteration 471/1500 [0m                      

                       Computation: 43738 steps/s (collection: 2.131s, learning 0.117s)
             Mean action noise std: 2.29
          Mean value_function loss: 53.7997
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 69.5771
                       Mean reward: 112.01
               Mean episode length: 218.91
    Episode_Reward/reaching_object: 1.4306
    Episode_Reward/rotating_object: 19.0346
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 2.25s
                      Time elapsed: 00:17:49
                               ETA: 00:38:51

################################################################################
                     [1m Learning iteration 472/1500 [0m                      

                       Computation: 45183 steps/s (collection: 2.076s, learning 0.099s)
             Mean action noise std: 2.29
          Mean value_function loss: 46.9831
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 69.6039
                       Mean reward: 105.27
               Mean episode length: 218.73
    Episode_Reward/reaching_object: 1.4283
    Episode_Reward/rotating_object: 19.8863
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 2.18s
                      Time elapsed: 00:17:51
                               ETA: 00:38:48

################################################################################
                     [1m Learning iteration 473/1500 [0m                      

                       Computation: 43599 steps/s (collection: 2.116s, learning 0.139s)
             Mean action noise std: 2.30
          Mean value_function loss: 53.6261
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 69.6289
                       Mean reward: 103.41
               Mean episode length: 209.46
    Episode_Reward/reaching_object: 1.4390
    Episode_Reward/rotating_object: 19.7635
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 2.25s
                      Time elapsed: 00:17:53
                               ETA: 00:38:46

################################################################################
                     [1m Learning iteration 474/1500 [0m                      

                       Computation: 45496 steps/s (collection: 2.069s, learning 0.092s)
             Mean action noise std: 2.30
          Mean value_function loss: 48.8979
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 69.6688
                       Mean reward: 121.53
               Mean episode length: 216.82
    Episode_Reward/reaching_object: 1.4159
    Episode_Reward/rotating_object: 22.1969
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 2.16s
                      Time elapsed: 00:17:55
                               ETA: 00:38:44

################################################################################
                     [1m Learning iteration 475/1500 [0m                      

                       Computation: 46323 steps/s (collection: 1.974s, learning 0.148s)
             Mean action noise std: 2.30
          Mean value_function loss: 51.9349
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 69.7006
                       Mean reward: 122.92
               Mean episode length: 216.93
    Episode_Reward/reaching_object: 1.4268
    Episode_Reward/rotating_object: 20.6764
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 2.12s
                      Time elapsed: 00:17:58
                               ETA: 00:38:41

################################################################################
                     [1m Learning iteration 476/1500 [0m                      

                       Computation: 42826 steps/s (collection: 2.166s, learning 0.129s)
             Mean action noise std: 2.30
          Mean value_function loss: 53.3082
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 69.7276
                       Mean reward: 92.99
               Mean episode length: 212.40
    Episode_Reward/reaching_object: 1.4036
    Episode_Reward/rotating_object: 17.9005
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 2.30s
                      Time elapsed: 00:18:00
                               ETA: 00:38:39

################################################################################
                     [1m Learning iteration 477/1500 [0m                      

                       Computation: 46235 steps/s (collection: 2.014s, learning 0.112s)
             Mean action noise std: 2.31
          Mean value_function loss: 53.1515
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 69.7733
                       Mean reward: 117.58
               Mean episode length: 228.26
    Episode_Reward/reaching_object: 1.4595
    Episode_Reward/rotating_object: 20.9611
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 2.13s
                      Time elapsed: 00:18:02
                               ETA: 00:38:36

################################################################################
                     [1m Learning iteration 478/1500 [0m                      

                       Computation: 45538 steps/s (collection: 2.065s, learning 0.094s)
             Mean action noise std: 2.31
          Mean value_function loss: 48.0173
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 69.8130
                       Mean reward: 123.79
               Mean episode length: 225.09
    Episode_Reward/reaching_object: 1.4349
    Episode_Reward/rotating_object: 21.5683
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 2.16s
                      Time elapsed: 00:18:04
                               ETA: 00:38:34

################################################################################
                     [1m Learning iteration 479/1500 [0m                      

                       Computation: 46643 steps/s (collection: 2.001s, learning 0.107s)
             Mean action noise std: 2.31
          Mean value_function loss: 46.2067
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 69.8428
                       Mean reward: 139.62
               Mean episode length: 227.00
    Episode_Reward/reaching_object: 1.4892
    Episode_Reward/rotating_object: 22.8723
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0468
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 2.11s
                      Time elapsed: 00:18:06
                               ETA: 00:38:31

################################################################################
                     [1m Learning iteration 480/1500 [0m                      

                       Computation: 44956 steps/s (collection: 2.064s, learning 0.123s)
             Mean action noise std: 2.32
          Mean value_function loss: 49.2559
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 69.8756
                       Mean reward: 116.38
               Mean episode length: 208.99
    Episode_Reward/reaching_object: 1.4308
    Episode_Reward/rotating_object: 21.7174
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0460
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 2.19s
                      Time elapsed: 00:18:08
                               ETA: 00:38:29

################################################################################
                     [1m Learning iteration 481/1500 [0m                      

                       Computation: 45284 steps/s (collection: 2.038s, learning 0.133s)
             Mean action noise std: 2.32
          Mean value_function loss: 53.4463
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 69.9054
                       Mean reward: 108.90
               Mean episode length: 208.34
    Episode_Reward/reaching_object: 1.4024
    Episode_Reward/rotating_object: 21.6842
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 2.17s
                      Time elapsed: 00:18:11
                               ETA: 00:38:26

################################################################################
                     [1m Learning iteration 482/1500 [0m                      

                       Computation: 46459 steps/s (collection: 2.020s, learning 0.096s)
             Mean action noise std: 2.32
          Mean value_function loss: 51.3790
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 69.9370
                       Mean reward: 124.14
               Mean episode length: 228.04
    Episode_Reward/reaching_object: 1.4717
    Episode_Reward/rotating_object: 22.8467
        Episode_Reward/action_rate: -0.0355
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 2.12s
                      Time elapsed: 00:18:13
                               ETA: 00:38:24

################################################################################
                     [1m Learning iteration 483/1500 [0m                      

                       Computation: 43787 steps/s (collection: 2.146s, learning 0.099s)
             Mean action noise std: 2.32
          Mean value_function loss: 51.3941
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 69.9690
                       Mean reward: 134.60
               Mean episode length: 222.49
    Episode_Reward/reaching_object: 1.4689
    Episode_Reward/rotating_object: 21.5027
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 2.25s
                      Time elapsed: 00:18:15
                               ETA: 00:38:21

################################################################################
                     [1m Learning iteration 484/1500 [0m                      

                       Computation: 46264 steps/s (collection: 2.015s, learning 0.110s)
             Mean action noise std: 2.33
          Mean value_function loss: 47.1445
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 70.0050
                       Mean reward: 124.71
               Mean episode length: 235.49
    Episode_Reward/reaching_object: 1.4682
    Episode_Reward/rotating_object: 20.3651
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 11.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 2.12s
                      Time elapsed: 00:18:17
                               ETA: 00:38:19

################################################################################
                     [1m Learning iteration 485/1500 [0m                      

                       Computation: 45090 steps/s (collection: 2.058s, learning 0.123s)
             Mean action noise std: 2.33
          Mean value_function loss: 48.2814
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 70.0396
                       Mean reward: 140.75
               Mean episode length: 220.42
    Episode_Reward/reaching_object: 1.4879
    Episode_Reward/rotating_object: 22.6784
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 2.18s
                      Time elapsed: 00:18:19
                               ETA: 00:38:16

################################################################################
                     [1m Learning iteration 486/1500 [0m                      

                       Computation: 42958 steps/s (collection: 2.113s, learning 0.176s)
             Mean action noise std: 2.33
          Mean value_function loss: 47.3950
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 70.0721
                       Mean reward: 121.86
               Mean episode length: 224.18
    Episode_Reward/reaching_object: 1.4418
    Episode_Reward/rotating_object: 19.7070
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 2.29s
                      Time elapsed: 00:18:22
                               ETA: 00:38:14

################################################################################
                     [1m Learning iteration 487/1500 [0m                      

                       Computation: 45686 steps/s (collection: 2.029s, learning 0.123s)
             Mean action noise std: 2.33
          Mean value_function loss: 48.0213
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 70.1110
                       Mean reward: 114.10
               Mean episode length: 222.28
    Episode_Reward/reaching_object: 1.4726
    Episode_Reward/rotating_object: 23.3794
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 2.15s
                      Time elapsed: 00:18:24
                               ETA: 00:38:12

################################################################################
                     [1m Learning iteration 488/1500 [0m                      

                       Computation: 47264 steps/s (collection: 1.982s, learning 0.098s)
             Mean action noise std: 2.34
          Mean value_function loss: 52.7787
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 70.1437
                       Mean reward: 105.59
               Mean episode length: 217.63
    Episode_Reward/reaching_object: 1.4546
    Episode_Reward/rotating_object: 19.9889
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 2.08s
                      Time elapsed: 00:18:26
                               ETA: 00:38:09

################################################################################
                     [1m Learning iteration 489/1500 [0m                      

                       Computation: 45821 steps/s (collection: 2.050s, learning 0.096s)
             Mean action noise std: 2.34
          Mean value_function loss: 51.7693
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 70.1797
                       Mean reward: 121.69
               Mean episode length: 228.77
    Episode_Reward/reaching_object: 1.5092
    Episode_Reward/rotating_object: 23.4037
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0468
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 2.15s
                      Time elapsed: 00:18:28
                               ETA: 00:38:07

################################################################################
                     [1m Learning iteration 490/1500 [0m                      

                       Computation: 46806 steps/s (collection: 1.994s, learning 0.106s)
             Mean action noise std: 2.34
          Mean value_function loss: 49.4579
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 70.2072
                       Mean reward: 106.96
               Mean episode length: 218.86
    Episode_Reward/reaching_object: 1.4813
    Episode_Reward/rotating_object: 23.2116
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 2.10s
                      Time elapsed: 00:18:30
                               ETA: 00:38:04

################################################################################
                     [1m Learning iteration 491/1500 [0m                      

                       Computation: 47362 steps/s (collection: 1.975s, learning 0.101s)
             Mean action noise std: 2.34
          Mean value_function loss: 52.9007
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 70.2362
                       Mean reward: 125.84
               Mean episode length: 217.88
    Episode_Reward/reaching_object: 1.4596
    Episode_Reward/rotating_object: 23.4167
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 2.08s
                      Time elapsed: 00:18:32
                               ETA: 00:38:01

################################################################################
                     [1m Learning iteration 492/1500 [0m                      

                       Computation: 44295 steps/s (collection: 2.093s, learning 0.127s)
             Mean action noise std: 2.34
          Mean value_function loss: 51.6055
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 70.2671
                       Mean reward: 98.90
               Mean episode length: 216.40
    Episode_Reward/reaching_object: 1.4835
    Episode_Reward/rotating_object: 25.4988
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 2.22s
                      Time elapsed: 00:18:34
                               ETA: 00:37:59

################################################################################
                     [1m Learning iteration 493/1500 [0m                      

                       Computation: 44498 steps/s (collection: 2.101s, learning 0.108s)
             Mean action noise std: 2.35
          Mean value_function loss: 55.6890
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 70.2912
                       Mean reward: 127.61
               Mean episode length: 222.99
    Episode_Reward/reaching_object: 1.4462
    Episode_Reward/rotating_object: 22.5553
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 2.21s
                      Time elapsed: 00:18:37
                               ETA: 00:37:57

################################################################################
                     [1m Learning iteration 494/1500 [0m                      

                       Computation: 44294 steps/s (collection: 2.118s, learning 0.102s)
             Mean action noise std: 2.35
          Mean value_function loss: 55.9386
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 70.3223
                       Mean reward: 161.41
               Mean episode length: 221.47
    Episode_Reward/reaching_object: 1.4576
    Episode_Reward/rotating_object: 26.1304
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 2.22s
                      Time elapsed: 00:18:39
                               ETA: 00:37:54

################################################################################
                     [1m Learning iteration 495/1500 [0m                      

                       Computation: 47428 steps/s (collection: 1.964s, learning 0.109s)
             Mean action noise std: 2.35
          Mean value_function loss: 56.4331
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 70.3573
                       Mean reward: 104.00
               Mean episode length: 213.31
    Episode_Reward/reaching_object: 1.4601
    Episode_Reward/rotating_object: 22.3994
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 2.07s
                      Time elapsed: 00:18:41
                               ETA: 00:37:52

################################################################################
                     [1m Learning iteration 496/1500 [0m                      

                       Computation: 41416 steps/s (collection: 2.164s, learning 0.210s)
             Mean action noise std: 2.36
          Mean value_function loss: 51.2900
               Mean surrogate loss: -0.0111
                 Mean entropy loss: 70.3973
                       Mean reward: 149.46
               Mean episode length: 221.36
    Episode_Reward/reaching_object: 1.4860
    Episode_Reward/rotating_object: 25.6214
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 2.37s
                      Time elapsed: 00:18:43
                               ETA: 00:37:50

################################################################################
                     [1m Learning iteration 497/1500 [0m                      

                       Computation: 39436 steps/s (collection: 2.243s, learning 0.250s)
             Mean action noise std: 2.36
          Mean value_function loss: 54.8280
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 70.4339
                       Mean reward: 151.25
               Mean episode length: 223.91
    Episode_Reward/reaching_object: 1.4377
    Episode_Reward/rotating_object: 25.8044
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 2.49s
                      Time elapsed: 00:18:46
                               ETA: 00:37:48

################################################################################
                     [1m Learning iteration 498/1500 [0m                      

                       Computation: 43362 steps/s (collection: 2.157s, learning 0.110s)
             Mean action noise std: 2.36
          Mean value_function loss: 53.1306
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 70.4627
                       Mean reward: 121.01
               Mean episode length: 218.58
    Episode_Reward/reaching_object: 1.4791
    Episode_Reward/rotating_object: 24.3004
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 2.27s
                      Time elapsed: 00:18:48
                               ETA: 00:37:45

################################################################################
                     [1m Learning iteration 499/1500 [0m                      

                       Computation: 43752 steps/s (collection: 2.156s, learning 0.091s)
             Mean action noise std: 2.36
          Mean value_function loss: 54.0420
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 70.4916
                       Mean reward: 122.33
               Mean episode length: 223.01
    Episode_Reward/reaching_object: 1.4706
    Episode_Reward/rotating_object: 24.0901
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 2.25s
                      Time elapsed: 00:18:50
                               ETA: 00:37:43

################################################################################
                     [1m Learning iteration 500/1500 [0m                      

                       Computation: 47561 steps/s (collection: 1.965s, learning 0.102s)
             Mean action noise std: 2.36
          Mean value_function loss: 50.2980
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 70.5161
                       Mean reward: 128.33
               Mean episode length: 223.17
    Episode_Reward/reaching_object: 1.4820
    Episode_Reward/rotating_object: 27.5988
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 2.07s
                      Time elapsed: 00:18:52
                               ETA: 00:37:41

################################################################################
                     [1m Learning iteration 501/1500 [0m                      

                       Computation: 45823 steps/s (collection: 2.055s, learning 0.091s)
             Mean action noise std: 2.37
          Mean value_function loss: 50.2508
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 70.5469
                       Mean reward: 142.59
               Mean episode length: 211.90
    Episode_Reward/reaching_object: 1.4541
    Episode_Reward/rotating_object: 22.8950
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 2.15s
                      Time elapsed: 00:18:54
                               ETA: 00:37:38

################################################################################
                     [1m Learning iteration 502/1500 [0m                      

                       Computation: 46892 steps/s (collection: 2.002s, learning 0.094s)
             Mean action noise std: 2.37
          Mean value_function loss: 44.9050
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 70.5903
                       Mean reward: 147.24
               Mean episode length: 218.42
    Episode_Reward/reaching_object: 1.4640
    Episode_Reward/rotating_object: 24.9040
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 2.10s
                      Time elapsed: 00:18:57
                               ETA: 00:37:35

################################################################################
                     [1m Learning iteration 503/1500 [0m                      

                       Computation: 47655 steps/s (collection: 1.955s, learning 0.108s)
             Mean action noise std: 2.37
          Mean value_function loss: 51.9080
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 70.6209
                       Mean reward: 131.93
               Mean episode length: 221.22
    Episode_Reward/reaching_object: 1.4539
    Episode_Reward/rotating_object: 24.8878
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 2.06s
                      Time elapsed: 00:18:59
                               ETA: 00:37:33

################################################################################
                     [1m Learning iteration 504/1500 [0m                      

                       Computation: 46872 steps/s (collection: 1.992s, learning 0.105s)
             Mean action noise std: 2.38
          Mean value_function loss: 52.3007
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 70.6609
                       Mean reward: 117.56
               Mean episode length: 204.60
    Episode_Reward/reaching_object: 1.4165
    Episode_Reward/rotating_object: 25.0990
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 2.10s
                      Time elapsed: 00:19:01
                               ETA: 00:37:30

################################################################################
                     [1m Learning iteration 505/1500 [0m                      

                       Computation: 45880 steps/s (collection: 2.017s, learning 0.126s)
             Mean action noise std: 2.38
          Mean value_function loss: 53.1487
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 70.6951
                       Mean reward: 153.57
               Mean episode length: 226.07
    Episode_Reward/reaching_object: 1.4425
    Episode_Reward/rotating_object: 25.1674
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 2.14s
                      Time elapsed: 00:19:03
                               ETA: 00:37:28

################################################################################
                     [1m Learning iteration 506/1500 [0m                      

                       Computation: 44897 steps/s (collection: 2.071s, learning 0.119s)
             Mean action noise std: 2.38
          Mean value_function loss: 51.2197
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 70.7307
                       Mean reward: 135.66
               Mean episode length: 223.83
    Episode_Reward/reaching_object: 1.5011
    Episode_Reward/rotating_object: 25.6862
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 2.19s
                      Time elapsed: 00:19:05
                               ETA: 00:37:25

################################################################################
                     [1m Learning iteration 507/1500 [0m                      

                       Computation: 42708 steps/s (collection: 2.200s, learning 0.102s)
             Mean action noise std: 2.38
          Mean value_function loss: 49.2308
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 70.7596
                       Mean reward: 135.66
               Mean episode length: 217.09
    Episode_Reward/reaching_object: 1.4881
    Episode_Reward/rotating_object: 24.9339
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 2.30s
                      Time elapsed: 00:19:07
                               ETA: 00:37:23

################################################################################
                     [1m Learning iteration 508/1500 [0m                      

                       Computation: 47735 steps/s (collection: 1.967s, learning 0.092s)
             Mean action noise std: 2.38
          Mean value_function loss: 53.5142
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 70.7855
                       Mean reward: 122.38
               Mean episode length: 217.36
    Episode_Reward/reaching_object: 1.4048
    Episode_Reward/rotating_object: 26.3866
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 2.06s
                      Time elapsed: 00:19:09
                               ETA: 00:37:21

################################################################################
                     [1m Learning iteration 509/1500 [0m                      

                       Computation: 47573 steps/s (collection: 1.954s, learning 0.112s)
             Mean action noise std: 2.39
          Mean value_function loss: 54.4341
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 70.8104
                       Mean reward: 82.09
               Mean episode length: 206.26
    Episode_Reward/reaching_object: 1.3979
    Episode_Reward/rotating_object: 23.3593
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 2.07s
                      Time elapsed: 00:19:11
                               ETA: 00:37:18

################################################################################
                     [1m Learning iteration 510/1500 [0m                      

                       Computation: 47682 steps/s (collection: 1.946s, learning 0.116s)
             Mean action noise std: 2.39
          Mean value_function loss: 53.6366
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 70.8506
                       Mean reward: 131.74
               Mean episode length: 217.99
    Episode_Reward/reaching_object: 1.4161
    Episode_Reward/rotating_object: 24.6043
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 2.06s
                      Time elapsed: 00:19:14
                               ETA: 00:37:15

################################################################################
                     [1m Learning iteration 511/1500 [0m                      

                       Computation: 47145 steps/s (collection: 1.970s, learning 0.115s)
             Mean action noise std: 2.39
          Mean value_function loss: 49.2301
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 70.8903
                       Mean reward: 153.10
               Mean episode length: 219.71
    Episode_Reward/reaching_object: 1.3997
    Episode_Reward/rotating_object: 25.6885
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 2.09s
                      Time elapsed: 00:19:16
                               ETA: 00:37:13

################################################################################
                     [1m Learning iteration 512/1500 [0m                      

                       Computation: 48907 steps/s (collection: 1.915s, learning 0.095s)
             Mean action noise std: 2.40
          Mean value_function loss: 50.9569
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 70.9283
                       Mean reward: 118.43
               Mean episode length: 213.26
    Episode_Reward/reaching_object: 1.4200
    Episode_Reward/rotating_object: 22.0773
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 2.01s
                      Time elapsed: 00:19:18
                               ETA: 00:37:10

################################################################################
                     [1m Learning iteration 513/1500 [0m                      

                       Computation: 46987 steps/s (collection: 1.976s, learning 0.116s)
             Mean action noise std: 2.40
          Mean value_function loss: 49.7110
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 70.9553
                       Mean reward: 129.40
               Mean episode length: 208.42
    Episode_Reward/reaching_object: 1.4338
    Episode_Reward/rotating_object: 25.4918
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 2.09s
                      Time elapsed: 00:19:20
                               ETA: 00:37:07

################################################################################
                     [1m Learning iteration 514/1500 [0m                      

                       Computation: 45736 steps/s (collection: 2.042s, learning 0.108s)
             Mean action noise std: 2.40
          Mean value_function loss: 52.2342
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 70.9899
                       Mean reward: 131.85
               Mean episode length: 219.57
    Episode_Reward/reaching_object: 1.4359
    Episode_Reward/rotating_object: 25.8426
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 2.15s
                      Time elapsed: 00:19:22
                               ETA: 00:37:05

################################################################################
                     [1m Learning iteration 515/1500 [0m                      

                       Computation: 47852 steps/s (collection: 1.954s, learning 0.100s)
             Mean action noise std: 2.40
          Mean value_function loss: 55.2026
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 71.0241
                       Mean reward: 108.38
               Mean episode length: 203.07
    Episode_Reward/reaching_object: 1.4031
    Episode_Reward/rotating_object: 22.5857
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 2.05s
                      Time elapsed: 00:19:24
                               ETA: 00:37:02

################################################################################
                     [1m Learning iteration 516/1500 [0m                      

                       Computation: 47986 steps/s (collection: 1.950s, learning 0.099s)
             Mean action noise std: 2.41
          Mean value_function loss: 52.1329
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 71.0516
                       Mean reward: 151.26
               Mean episode length: 225.02
    Episode_Reward/reaching_object: 1.4001
    Episode_Reward/rotating_object: 23.8255
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 2.05s
                      Time elapsed: 00:19:26
                               ETA: 00:37:00

################################################################################
                     [1m Learning iteration 517/1500 [0m                      

                       Computation: 48715 steps/s (collection: 1.917s, learning 0.101s)
             Mean action noise std: 2.41
          Mean value_function loss: 55.3990
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 71.0798
                       Mean reward: 131.49
               Mean episode length: 206.85
    Episode_Reward/reaching_object: 1.4204
    Episode_Reward/rotating_object: 24.9868
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 2.02s
                      Time elapsed: 00:19:28
                               ETA: 00:36:57

################################################################################
                     [1m Learning iteration 518/1500 [0m                      

                       Computation: 48700 steps/s (collection: 1.926s, learning 0.093s)
             Mean action noise std: 2.41
          Mean value_function loss: 51.5428
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 71.1203
                       Mean reward: 102.26
               Mean episode length: 204.37
    Episode_Reward/reaching_object: 1.4491
    Episode_Reward/rotating_object: 23.4801
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 2.02s
                      Time elapsed: 00:19:30
                               ETA: 00:36:54

################################################################################
                     [1m Learning iteration 519/1500 [0m                      

                       Computation: 48014 steps/s (collection: 1.952s, learning 0.095s)
             Mean action noise std: 2.41
          Mean value_function loss: 45.4527
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 71.1563
                       Mean reward: 130.32
               Mean episode length: 205.40
    Episode_Reward/reaching_object: 1.3503
    Episode_Reward/rotating_object: 23.7174
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 12.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 2.05s
                      Time elapsed: 00:19:32
                               ETA: 00:36:52

################################################################################
                     [1m Learning iteration 520/1500 [0m                      

                       Computation: 48104 steps/s (collection: 1.948s, learning 0.095s)
             Mean action noise std: 2.42
          Mean value_function loss: 41.8829
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 71.1872
                       Mean reward: 115.14
               Mean episode length: 209.89
    Episode_Reward/reaching_object: 1.4333
    Episode_Reward/rotating_object: 23.6621
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 2.04s
                      Time elapsed: 00:19:34
                               ETA: 00:36:49

################################################################################
                     [1m Learning iteration 521/1500 [0m                      

                       Computation: 48600 steps/s (collection: 1.930s, learning 0.092s)
             Mean action noise std: 2.42
          Mean value_function loss: 43.1421
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 71.2238
                       Mean reward: 105.56
               Mean episode length: 214.14
    Episode_Reward/reaching_object: 1.4182
    Episode_Reward/rotating_object: 23.8317
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 2.02s
                      Time elapsed: 00:19:36
                               ETA: 00:36:46

################################################################################
                     [1m Learning iteration 522/1500 [0m                      

                       Computation: 47637 steps/s (collection: 1.969s, learning 0.095s)
             Mean action noise std: 2.42
          Mean value_function loss: 54.0815
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 71.2586
                       Mean reward: 108.25
               Mean episode length: 220.28
    Episode_Reward/reaching_object: 1.4564
    Episode_Reward/rotating_object: 24.3837
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 2.06s
                      Time elapsed: 00:19:38
                               ETA: 00:36:44

################################################################################
                     [1m Learning iteration 523/1500 [0m                      

                       Computation: 45526 steps/s (collection: 2.026s, learning 0.134s)
             Mean action noise std: 2.42
          Mean value_function loss: 51.5500
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 71.2940
                       Mean reward: 138.80
               Mean episode length: 208.67
    Episode_Reward/reaching_object: 1.3903
    Episode_Reward/rotating_object: 24.1562
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 2.16s
                      Time elapsed: 00:19:40
                               ETA: 00:36:41

################################################################################
                     [1m Learning iteration 524/1500 [0m                      

                       Computation: 45508 steps/s (collection: 2.049s, learning 0.111s)
             Mean action noise std: 2.43
          Mean value_function loss: 50.9062
               Mean surrogate loss: -0.0114
                 Mean entropy loss: 71.3222
                       Mean reward: 131.87
               Mean episode length: 228.20
    Episode_Reward/reaching_object: 1.4024
    Episode_Reward/rotating_object: 22.9595
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 2.16s
                      Time elapsed: 00:19:42
                               ETA: 00:36:39

################################################################################
                     [1m Learning iteration 525/1500 [0m                      

                       Computation: 46526 steps/s (collection: 2.010s, learning 0.103s)
             Mean action noise std: 2.43
          Mean value_function loss: 55.4933
               Mean surrogate loss: -0.0113
                 Mean entropy loss: 71.3530
                       Mean reward: 127.33
               Mean episode length: 212.95
    Episode_Reward/reaching_object: 1.3842
    Episode_Reward/rotating_object: 24.9779
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 2.11s
                      Time elapsed: 00:19:45
                               ETA: 00:36:36

################################################################################
                     [1m Learning iteration 526/1500 [0m                      

                       Computation: 45815 steps/s (collection: 2.026s, learning 0.120s)
             Mean action noise std: 2.43
          Mean value_function loss: 54.6954
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 71.3877
                       Mean reward: 137.70
               Mean episode length: 212.89
    Episode_Reward/reaching_object: 1.4375
    Episode_Reward/rotating_object: 25.8812
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 2.15s
                      Time elapsed: 00:19:47
                               ETA: 00:36:34

################################################################################
                     [1m Learning iteration 527/1500 [0m                      

                       Computation: 47512 steps/s (collection: 1.973s, learning 0.096s)
             Mean action noise std: 2.44
          Mean value_function loss: 57.9754
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 71.4252
                       Mean reward: 120.89
               Mean episode length: 206.60
    Episode_Reward/reaching_object: 1.4493
    Episode_Reward/rotating_object: 25.6008
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 2.07s
                      Time elapsed: 00:19:49
                               ETA: 00:36:31

################################################################################
                     [1m Learning iteration 528/1500 [0m                      

                       Computation: 47521 steps/s (collection: 1.967s, learning 0.102s)
             Mean action noise std: 2.44
          Mean value_function loss: 52.3945
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 71.4566
                       Mean reward: 115.00
               Mean episode length: 218.71
    Episode_Reward/reaching_object: 1.4521
    Episode_Reward/rotating_object: 23.5513
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 2.07s
                      Time elapsed: 00:19:51
                               ETA: 00:36:29

################################################################################
                     [1m Learning iteration 529/1500 [0m                      

                       Computation: 45367 steps/s (collection: 2.045s, learning 0.122s)
             Mean action noise std: 2.44
          Mean value_function loss: 55.7379
               Mean surrogate loss: -0.0111
                 Mean entropy loss: 71.4801
                       Mean reward: 116.95
               Mean episode length: 224.88
    Episode_Reward/reaching_object: 1.4524
    Episode_Reward/rotating_object: 25.3119
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 2.17s
                      Time elapsed: 00:19:53
                               ETA: 00:36:26

################################################################################
                     [1m Learning iteration 530/1500 [0m                      

                       Computation: 46385 steps/s (collection: 2.019s, learning 0.101s)
             Mean action noise std: 2.44
          Mean value_function loss: 51.9725
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 71.5165
                       Mean reward: 121.15
               Mean episode length: 214.10
    Episode_Reward/reaching_object: 1.4859
    Episode_Reward/rotating_object: 23.7163
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 2.12s
                      Time elapsed: 00:19:55
                               ETA: 00:36:24

################################################################################
                     [1m Learning iteration 531/1500 [0m                      

                       Computation: 45499 steps/s (collection: 2.066s, learning 0.094s)
             Mean action noise std: 2.45
          Mean value_function loss: 47.4481
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 71.5537
                       Mean reward: 136.56
               Mean episode length: 217.06
    Episode_Reward/reaching_object: 1.4671
    Episode_Reward/rotating_object: 28.1026
        Episode_Reward/action_rate: -0.0384
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 2.16s
                      Time elapsed: 00:19:57
                               ETA: 00:36:21

################################################################################
                     [1m Learning iteration 532/1500 [0m                      

                       Computation: 46902 steps/s (collection: 1.996s, learning 0.100s)
             Mean action noise std: 2.45
          Mean value_function loss: 56.0026
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 71.5858
                       Mean reward: 141.27
               Mean episode length: 214.68
    Episode_Reward/reaching_object: 1.4299
    Episode_Reward/rotating_object: 24.5477
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 2.10s
                      Time elapsed: 00:19:59
                               ETA: 00:36:19

################################################################################
                     [1m Learning iteration 533/1500 [0m                      

                       Computation: 46551 steps/s (collection: 2.023s, learning 0.089s)
             Mean action noise std: 2.45
          Mean value_function loss: 52.8606
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 71.6280
                       Mean reward: 122.07
               Mean episode length: 207.37
    Episode_Reward/reaching_object: 1.4797
    Episode_Reward/rotating_object: 28.2386
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 2.11s
                      Time elapsed: 00:20:02
                               ETA: 00:36:16

################################################################################
                     [1m Learning iteration 534/1500 [0m                      

                       Computation: 48186 steps/s (collection: 1.926s, learning 0.114s)
             Mean action noise std: 2.46
          Mean value_function loss: 56.6447
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 71.6643
                       Mean reward: 136.11
               Mean episode length: 203.20
    Episode_Reward/reaching_object: 1.4659
    Episode_Reward/rotating_object: 26.9559
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 2.04s
                      Time elapsed: 00:20:04
                               ETA: 00:36:14

################################################################################
                     [1m Learning iteration 535/1500 [0m                      

                       Computation: 45119 steps/s (collection: 2.079s, learning 0.100s)
             Mean action noise std: 2.46
          Mean value_function loss: 55.2833
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 71.6986
                       Mean reward: 149.16
               Mean episode length: 212.50
    Episode_Reward/reaching_object: 1.4494
    Episode_Reward/rotating_object: 27.5024
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 2.18s
                      Time elapsed: 00:20:06
                               ETA: 00:36:11

################################################################################
                     [1m Learning iteration 536/1500 [0m                      

                       Computation: 46621 steps/s (collection: 2.003s, learning 0.106s)
             Mean action noise std: 2.46
          Mean value_function loss: 54.3759
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 71.7232
                       Mean reward: 144.72
               Mean episode length: 206.17
    Episode_Reward/reaching_object: 1.4306
    Episode_Reward/rotating_object: 27.7075
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 2.11s
                      Time elapsed: 00:20:08
                               ETA: 00:36:09

################################################################################
                     [1m Learning iteration 537/1500 [0m                      

                       Computation: 42241 steps/s (collection: 2.188s, learning 0.139s)
             Mean action noise std: 2.46
          Mean value_function loss: 52.1701
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 71.7585
                       Mean reward: 139.51
               Mean episode length: 213.86
    Episode_Reward/reaching_object: 1.5006
    Episode_Reward/rotating_object: 26.4273
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 2.33s
                      Time elapsed: 00:20:10
                               ETA: 00:36:07

################################################################################
                     [1m Learning iteration 538/1500 [0m                      

                       Computation: 43589 steps/s (collection: 2.095s, learning 0.161s)
             Mean action noise std: 2.47
          Mean value_function loss: 55.8289
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 71.7925
                       Mean reward: 163.68
               Mean episode length: 218.53
    Episode_Reward/reaching_object: 1.4549
    Episode_Reward/rotating_object: 26.1256
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 2.26s
                      Time elapsed: 00:20:12
                               ETA: 00:36:04

################################################################################
                     [1m Learning iteration 539/1500 [0m                      

                       Computation: 39743 steps/s (collection: 2.358s, learning 0.116s)
             Mean action noise std: 2.47
          Mean value_function loss: 49.6146
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 71.8231
                       Mean reward: 135.96
               Mean episode length: 215.72
    Episode_Reward/reaching_object: 1.4749
    Episode_Reward/rotating_object: 24.2626
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 2.47s
                      Time elapsed: 00:20:15
                               ETA: 00:36:02

################################################################################
                     [1m Learning iteration 540/1500 [0m                      

                       Computation: 46014 steps/s (collection: 1.975s, learning 0.162s)
             Mean action noise std: 2.47
          Mean value_function loss: 50.8702
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 71.8576
                       Mean reward: 133.23
               Mean episode length: 200.91
    Episode_Reward/reaching_object: 1.4156
    Episode_Reward/rotating_object: 26.6916
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 2.14s
                      Time elapsed: 00:20:17
                               ETA: 00:36:00

################################################################################
                     [1m Learning iteration 541/1500 [0m                      

                       Computation: 43459 steps/s (collection: 2.141s, learning 0.121s)
             Mean action noise std: 2.47
          Mean value_function loss: 45.6917
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 71.8963
                       Mean reward: 157.86
               Mean episode length: 206.52
    Episode_Reward/reaching_object: 1.4852
    Episode_Reward/rotating_object: 27.7940
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 2.26s
                      Time elapsed: 00:20:19
                               ETA: 00:35:58

################################################################################
                     [1m Learning iteration 542/1500 [0m                      

                       Computation: 46857 steps/s (collection: 1.980s, learning 0.118s)
             Mean action noise std: 2.48
          Mean value_function loss: 51.6457
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 71.9335
                       Mean reward: 148.46
               Mean episode length: 214.80
    Episode_Reward/reaching_object: 1.4695
    Episode_Reward/rotating_object: 25.3796
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 2.10s
                      Time elapsed: 00:20:21
                               ETA: 00:35:55

################################################################################
                     [1m Learning iteration 543/1500 [0m                      

                       Computation: 48532 steps/s (collection: 1.925s, learning 0.101s)
             Mean action noise std: 2.48
          Mean value_function loss: 51.5574
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 71.9642
                       Mean reward: 164.92
               Mean episode length: 219.33
    Episode_Reward/reaching_object: 1.4588
    Episode_Reward/rotating_object: 28.0822
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 2.03s
                      Time elapsed: 00:20:23
                               ETA: 00:35:53

################################################################################
                     [1m Learning iteration 544/1500 [0m                      

                       Computation: 46173 steps/s (collection: 2.024s, learning 0.105s)
             Mean action noise std: 2.48
          Mean value_function loss: 56.0623
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 71.9952
                       Mean reward: 153.59
               Mean episode length: 227.07
    Episode_Reward/reaching_object: 1.4776
    Episode_Reward/rotating_object: 28.7669
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 2.13s
                      Time elapsed: 00:20:26
                               ETA: 00:35:50

################################################################################
                     [1m Learning iteration 545/1500 [0m                      

                       Computation: 46038 steps/s (collection: 2.027s, learning 0.108s)
             Mean action noise std: 2.48
          Mean value_function loss: 54.7960
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 72.0281
                       Mean reward: 155.94
               Mean episode length: 225.15
    Episode_Reward/reaching_object: 1.5257
    Episode_Reward/rotating_object: 27.2961
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 2.14s
                      Time elapsed: 00:20:28
                               ETA: 00:35:48

################################################################################
                     [1m Learning iteration 546/1500 [0m                      

                       Computation: 45167 steps/s (collection: 2.015s, learning 0.161s)
             Mean action noise std: 2.49
          Mean value_function loss: 54.5289
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 72.0586
                       Mean reward: 124.09
               Mean episode length: 213.92
    Episode_Reward/reaching_object: 1.4604
    Episode_Reward/rotating_object: 27.2976
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 2.18s
                      Time elapsed: 00:20:30
                               ETA: 00:35:45

################################################################################
                     [1m Learning iteration 547/1500 [0m                      

                       Computation: 41597 steps/s (collection: 2.199s, learning 0.164s)
             Mean action noise std: 2.49
          Mean value_function loss: 50.6725
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 72.0944
                       Mean reward: 137.67
               Mean episode length: 218.61
    Episode_Reward/reaching_object: 1.5541
    Episode_Reward/rotating_object: 26.3408
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 2.36s
                      Time elapsed: 00:20:32
                               ETA: 00:35:43

################################################################################
                     [1m Learning iteration 548/1500 [0m                      

                       Computation: 46298 steps/s (collection: 1.980s, learning 0.144s)
             Mean action noise std: 2.49
          Mean value_function loss: 60.8123
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 72.1322
                       Mean reward: 108.84
               Mean episode length: 208.60
    Episode_Reward/reaching_object: 1.4625
    Episode_Reward/rotating_object: 26.4196
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 2.12s
                      Time elapsed: 00:20:34
                               ETA: 00:35:41

################################################################################
                     [1m Learning iteration 549/1500 [0m                      

                       Computation: 42853 steps/s (collection: 2.173s, learning 0.121s)
             Mean action noise std: 2.50
          Mean value_function loss: 53.5696
               Mean surrogate loss: -0.0112
                 Mean entropy loss: 72.1697
                       Mean reward: 132.93
               Mean episode length: 226.98
    Episode_Reward/reaching_object: 1.4916
    Episode_Reward/rotating_object: 27.7728
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 2.29s
                      Time elapsed: 00:20:37
                               ETA: 00:35:39

################################################################################
                     [1m Learning iteration 550/1500 [0m                      

                       Computation: 42710 steps/s (collection: 2.174s, learning 0.127s)
             Mean action noise std: 2.50
          Mean value_function loss: 54.9654
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 72.2069
                       Mean reward: 141.74
               Mean episode length: 219.93
    Episode_Reward/reaching_object: 1.4731
    Episode_Reward/rotating_object: 28.4992
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 2.30s
                      Time elapsed: 00:20:39
                               ETA: 00:35:37

################################################################################
                     [1m Learning iteration 551/1500 [0m                      

                       Computation: 46016 steps/s (collection: 2.027s, learning 0.109s)
             Mean action noise std: 2.50
          Mean value_function loss: 58.7878
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 72.2422
                       Mean reward: 180.34
               Mean episode length: 225.43
    Episode_Reward/reaching_object: 1.5028
    Episode_Reward/rotating_object: 31.4505
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 2.14s
                      Time elapsed: 00:20:41
                               ETA: 00:35:34

################################################################################
                     [1m Learning iteration 552/1500 [0m                      

                       Computation: 46317 steps/s (collection: 2.014s, learning 0.109s)
             Mean action noise std: 2.51
          Mean value_function loss: 54.3768
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 72.2793
                       Mean reward: 141.37
               Mean episode length: 217.69
    Episode_Reward/reaching_object: 1.4944
    Episode_Reward/rotating_object: 29.3342
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 2.12s
                      Time elapsed: 00:20:43
                               ETA: 00:35:32

################################################################################
                     [1m Learning iteration 553/1500 [0m                      

                       Computation: 42299 steps/s (collection: 2.203s, learning 0.121s)
             Mean action noise std: 2.51
          Mean value_function loss: 62.1406
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 72.3103
                       Mean reward: 162.75
               Mean episode length: 218.44
    Episode_Reward/reaching_object: 1.5032
    Episode_Reward/rotating_object: 31.1761
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 2.32s
                      Time elapsed: 00:20:46
                               ETA: 00:35:29

################################################################################
                     [1m Learning iteration 554/1500 [0m                      

                       Computation: 37606 steps/s (collection: 2.422s, learning 0.192s)
             Mean action noise std: 2.51
          Mean value_function loss: 61.3722
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 72.3481
                       Mean reward: 150.69
               Mean episode length: 224.74
    Episode_Reward/reaching_object: 1.5001
    Episode_Reward/rotating_object: 28.3179
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 2.61s
                      Time elapsed: 00:20:48
                               ETA: 00:35:28

################################################################################
                     [1m Learning iteration 555/1500 [0m                      

                       Computation: 35336 steps/s (collection: 2.565s, learning 0.217s)
             Mean action noise std: 2.51
          Mean value_function loss: 59.7410
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 72.3841
                       Mean reward: 168.63
               Mean episode length: 221.25
    Episode_Reward/reaching_object: 1.5265
    Episode_Reward/rotating_object: 29.7076
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 2.78s
                      Time elapsed: 00:20:51
                               ETA: 00:35:27

################################################################################
                     [1m Learning iteration 556/1500 [0m                      

                       Computation: 37682 steps/s (collection: 2.418s, learning 0.191s)
             Mean action noise std: 2.52
          Mean value_function loss: 54.6696
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 72.4112
                       Mean reward: 142.24
               Mean episode length: 219.20
    Episode_Reward/reaching_object: 1.4864
    Episode_Reward/rotating_object: 29.7612
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 2.61s
                      Time elapsed: 00:20:54
                               ETA: 00:35:25

################################################################################
                     [1m Learning iteration 557/1500 [0m                      

                       Computation: 33703 steps/s (collection: 2.689s, learning 0.228s)
             Mean action noise std: 2.52
          Mean value_function loss: 57.0362
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 72.4429
                       Mean reward: 121.78
               Mean episode length: 209.39
    Episode_Reward/reaching_object: 1.4775
    Episode_Reward/rotating_object: 27.0123
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 2.92s
                      Time elapsed: 00:20:56
                               ETA: 00:35:24

################################################################################
                     [1m Learning iteration 558/1500 [0m                      

                       Computation: 33884 steps/s (collection: 2.604s, learning 0.298s)
             Mean action noise std: 2.52
          Mean value_function loss: 59.7240
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 72.4779
                       Mean reward: 166.54
               Mean episode length: 222.85
    Episode_Reward/reaching_object: 1.4585
    Episode_Reward/rotating_object: 29.7583
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 2.90s
                      Time elapsed: 00:20:59
                               ETA: 00:35:23

################################################################################
                     [1m Learning iteration 559/1500 [0m                      

                       Computation: 34504 steps/s (collection: 2.634s, learning 0.215s)
             Mean action noise std: 2.53
          Mean value_function loss: 56.9761
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 72.5267
                       Mean reward: 169.01
               Mean episode length: 219.97
    Episode_Reward/reaching_object: 1.5366
    Episode_Reward/rotating_object: 32.7044
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 2.85s
                      Time elapsed: 00:21:02
                               ETA: 00:35:21

################################################################################
                     [1m Learning iteration 560/1500 [0m                      

                       Computation: 34304 steps/s (collection: 2.543s, learning 0.322s)
             Mean action noise std: 2.53
          Mean value_function loss: 56.2862
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 72.5646
                       Mean reward: 173.09
               Mean episode length: 223.11
    Episode_Reward/reaching_object: 1.5412
    Episode_Reward/rotating_object: 32.3120
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 2.87s
                      Time elapsed: 00:21:05
                               ETA: 00:35:20

################################################################################
                     [1m Learning iteration 561/1500 [0m                      

                       Computation: 34347 steps/s (collection: 2.599s, learning 0.263s)
             Mean action noise std: 2.53
          Mean value_function loss: 60.2409
               Mean surrogate loss: -0.0115
                 Mean entropy loss: 72.6020
                       Mean reward: 155.26
               Mean episode length: 223.45
    Episode_Reward/reaching_object: 1.4793
    Episode_Reward/rotating_object: 30.8119
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 2.86s
                      Time elapsed: 00:21:08
                               ETA: 00:35:19

################################################################################
                     [1m Learning iteration 562/1500 [0m                      

                       Computation: 36746 steps/s (collection: 2.557s, learning 0.118s)
             Mean action noise std: 2.54
          Mean value_function loss: 54.9257
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 72.6364
                       Mean reward: 192.89
               Mean episode length: 220.96
    Episode_Reward/reaching_object: 1.5122
    Episode_Reward/rotating_object: 29.2565
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 2.68s
                      Time elapsed: 00:21:11
                               ETA: 00:35:17

################################################################################
                     [1m Learning iteration 563/1500 [0m                      

                       Computation: 40916 steps/s (collection: 2.276s, learning 0.127s)
             Mean action noise std: 2.54
          Mean value_function loss: 58.3208
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 72.6751
                       Mean reward: 152.35
               Mean episode length: 207.73
    Episode_Reward/reaching_object: 1.4836
    Episode_Reward/rotating_object: 29.5341
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 2.40s
                      Time elapsed: 00:21:13
                               ETA: 00:35:15

################################################################################
                     [1m Learning iteration 564/1500 [0m                      

                       Computation: 40750 steps/s (collection: 2.298s, learning 0.115s)
             Mean action noise std: 2.54
          Mean value_function loss: 55.1506
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 72.7096
                       Mean reward: 135.21
               Mean episode length: 218.11
    Episode_Reward/reaching_object: 1.4872
    Episode_Reward/rotating_object: 29.6152
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 2.41s
                      Time elapsed: 00:21:15
                               ETA: 00:35:13

################################################################################
                     [1m Learning iteration 565/1500 [0m                      

                       Computation: 43698 steps/s (collection: 2.123s, learning 0.127s)
             Mean action noise std: 2.55
          Mean value_function loss: 65.5742
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 72.7554
                       Mean reward: 148.74
               Mean episode length: 217.40
    Episode_Reward/reaching_object: 1.4796
    Episode_Reward/rotating_object: 30.3457
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 2.25s
                      Time elapsed: 00:21:18
                               ETA: 00:35:11

################################################################################
                     [1m Learning iteration 566/1500 [0m                      

                       Computation: 33529 steps/s (collection: 2.632s, learning 0.300s)
             Mean action noise std: 2.55
          Mean value_function loss: 60.8885
               Mean surrogate loss: -0.0115
                 Mean entropy loss: 72.7917
                       Mean reward: 178.25
               Mean episode length: 219.45
    Episode_Reward/reaching_object: 1.4464
    Episode_Reward/rotating_object: 31.3028
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 2.93s
                      Time elapsed: 00:21:21
                               ETA: 00:35:10

################################################################################
                     [1m Learning iteration 567/1500 [0m                      

                       Computation: 24100 steps/s (collection: 3.739s, learning 0.340s)
             Mean action noise std: 2.55
          Mean value_function loss: 63.1899
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 72.8319
                       Mean reward: 134.57
               Mean episode length: 205.92
    Episode_Reward/reaching_object: 1.4450
    Episode_Reward/rotating_object: 29.5768
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 4.08s
                      Time elapsed: 00:21:25
                               ETA: 00:35:11

################################################################################
                     [1m Learning iteration 568/1500 [0m                      

                       Computation: 21162 steps/s (collection: 4.391s, learning 0.254s)
             Mean action noise std: 2.55
          Mean value_function loss: 55.1155
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 72.8668
                       Mean reward: 164.70
               Mean episode length: 227.67
    Episode_Reward/reaching_object: 1.4481
    Episode_Reward/rotating_object: 29.8926
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 4.65s
                      Time elapsed: 00:21:29
                               ETA: 00:35:12

################################################################################
                     [1m Learning iteration 569/1500 [0m                      

                       Computation: 24848 steps/s (collection: 3.710s, learning 0.246s)
             Mean action noise std: 2.56
          Mean value_function loss: 55.0178
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 72.8990
                       Mean reward: 162.89
               Mean episode length: 218.54
    Episode_Reward/reaching_object: 1.4642
    Episode_Reward/rotating_object: 31.8138
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 3.96s
                      Time elapsed: 00:21:33
                               ETA: 00:35:13

################################################################################
                     [1m Learning iteration 570/1500 [0m                      

                       Computation: 22855 steps/s (collection: 4.026s, learning 0.276s)
             Mean action noise std: 2.56
          Mean value_function loss: 55.7867
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 72.9427
                       Mean reward: 133.14
               Mean episode length: 212.61
    Episode_Reward/reaching_object: 1.4443
    Episode_Reward/rotating_object: 31.1579
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 4.30s
                      Time elapsed: 00:21:38
                               ETA: 00:35:14

################################################################################
                     [1m Learning iteration 571/1500 [0m                      

                       Computation: 22055 steps/s (collection: 4.182s, learning 0.275s)
             Mean action noise std: 2.56
          Mean value_function loss: 64.4117
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 72.9821
                       Mean reward: 154.03
               Mean episode length: 213.90
    Episode_Reward/reaching_object: 1.4680
    Episode_Reward/rotating_object: 28.5266
        Episode_Reward/action_rate: -0.0433
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 4.46s
                      Time elapsed: 00:21:42
                               ETA: 00:35:15

################################################################################
                     [1m Learning iteration 572/1500 [0m                      

                       Computation: 23060 steps/s (collection: 3.942s, learning 0.321s)
             Mean action noise std: 2.57
          Mean value_function loss: 65.5237
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 73.0096
                       Mean reward: 162.71
               Mean episode length: 212.40
    Episode_Reward/reaching_object: 1.4728
    Episode_Reward/rotating_object: 30.3436
        Episode_Reward/action_rate: -0.0433
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 4.26s
                      Time elapsed: 00:21:46
                               ETA: 00:35:16

################################################################################
                     [1m Learning iteration 573/1500 [0m                      

                       Computation: 23501 steps/s (collection: 3.938s, learning 0.245s)
             Mean action noise std: 2.57
          Mean value_function loss: 61.7111
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 73.0376
                       Mean reward: 165.42
               Mean episode length: 225.83
    Episode_Reward/reaching_object: 1.4785
    Episode_Reward/rotating_object: 29.0723
        Episode_Reward/action_rate: -0.0436
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 4.18s
                      Time elapsed: 00:21:51
                               ETA: 00:35:17

################################################################################
                     [1m Learning iteration 574/1500 [0m                      

                       Computation: 26104 steps/s (collection: 3.483s, learning 0.283s)
             Mean action noise std: 2.57
          Mean value_function loss: 62.0922
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 73.0749
                       Mean reward: 156.42
               Mean episode length: 218.51
    Episode_Reward/reaching_object: 1.5129
    Episode_Reward/rotating_object: 31.5001
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0460
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 3.77s
                      Time elapsed: 00:21:54
                               ETA: 00:35:17

################################################################################
                     [1m Learning iteration 575/1500 [0m                      

                       Computation: 21849 steps/s (collection: 4.190s, learning 0.310s)
             Mean action noise std: 2.57
          Mean value_function loss: 62.5810
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 73.1081
                       Mean reward: 152.07
               Mean episode length: 223.59
    Episode_Reward/reaching_object: 1.4551
    Episode_Reward/rotating_object: 30.2829
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 4.50s
                      Time elapsed: 00:21:59
                               ETA: 00:35:18

################################################################################
                     [1m Learning iteration 576/1500 [0m                      

                       Computation: 34605 steps/s (collection: 2.747s, learning 0.094s)
             Mean action noise std: 2.58
          Mean value_function loss: 63.0464
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 73.1397
                       Mean reward: 224.16
               Mean episode length: 223.28
    Episode_Reward/reaching_object: 1.4654
    Episode_Reward/rotating_object: 30.6841
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 2.84s
                      Time elapsed: 00:22:02
                               ETA: 00:35:17

################################################################################
                     [1m Learning iteration 577/1500 [0m                      

                       Computation: 45783 steps/s (collection: 2.036s, learning 0.111s)
             Mean action noise std: 2.58
          Mean value_function loss: 66.7138
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 73.1802
                       Mean reward: 119.98
               Mean episode length: 215.42
    Episode_Reward/reaching_object: 1.4541
    Episode_Reward/rotating_object: 28.9907
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 2.15s
                      Time elapsed: 00:22:04
                               ETA: 00:35:14

################################################################################
                     [1m Learning iteration 578/1500 [0m                      

                       Computation: 44357 steps/s (collection: 2.122s, learning 0.095s)
             Mean action noise std: 2.58
          Mean value_function loss: 59.2911
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 73.2110
                       Mean reward: 142.22
               Mean episode length: 212.70
    Episode_Reward/reaching_object: 1.5127
    Episode_Reward/rotating_object: 31.5477
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 2.22s
                      Time elapsed: 00:22:06
                               ETA: 00:35:12

################################################################################
                     [1m Learning iteration 579/1500 [0m                      

                       Computation: 44013 steps/s (collection: 2.054s, learning 0.180s)
             Mean action noise std: 2.59
          Mean value_function loss: 58.5078
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 73.2500
                       Mean reward: 147.28
               Mean episode length: 224.93
    Episode_Reward/reaching_object: 1.5083
    Episode_Reward/rotating_object: 29.9211
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 2.23s
                      Time elapsed: 00:22:08
                               ETA: 00:35:09

################################################################################
                     [1m Learning iteration 580/1500 [0m                      

                       Computation: 45528 steps/s (collection: 2.058s, learning 0.102s)
             Mean action noise std: 2.59
          Mean value_function loss: 60.3571
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 73.2850
                       Mean reward: 148.17
               Mean episode length: 212.58
    Episode_Reward/reaching_object: 1.4890
    Episode_Reward/rotating_object: 30.8639
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 2.16s
                      Time elapsed: 00:22:10
                               ETA: 00:35:07

################################################################################
                     [1m Learning iteration 581/1500 [0m                      

                       Computation: 47769 steps/s (collection: 1.961s, learning 0.097s)
             Mean action noise std: 2.59
          Mean value_function loss: 66.2642
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 73.3197
                       Mean reward: 149.96
               Mean episode length: 217.45
    Episode_Reward/reaching_object: 1.4436
    Episode_Reward/rotating_object: 26.0254
        Episode_Reward/action_rate: -0.0436
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 2.06s
                      Time elapsed: 00:22:12
                               ETA: 00:35:04

################################################################################
                     [1m Learning iteration 582/1500 [0m                      

                       Computation: 47699 steps/s (collection: 1.967s, learning 0.093s)
             Mean action noise std: 2.60
          Mean value_function loss: 56.3398
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 73.3555
                       Mean reward: 167.18
               Mean episode length: 216.47
    Episode_Reward/reaching_object: 1.5023
    Episode_Reward/rotating_object: 30.0796
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 2.06s
                      Time elapsed: 00:22:14
                               ETA: 00:35:02

################################################################################
                     [1m Learning iteration 583/1500 [0m                      

                       Computation: 46129 steps/s (collection: 2.014s, learning 0.117s)
             Mean action noise std: 2.60
          Mean value_function loss: 61.6604
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 73.3993
                       Mean reward: 155.35
               Mean episode length: 215.64
    Episode_Reward/reaching_object: 1.5180
    Episode_Reward/rotating_object: 31.0297
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 2.13s
                      Time elapsed: 00:22:17
                               ETA: 00:34:59

################################################################################
                     [1m Learning iteration 584/1500 [0m                      

                       Computation: 46218 steps/s (collection: 2.005s, learning 0.122s)
             Mean action noise std: 2.60
          Mean value_function loss: 63.2492
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 73.4493
                       Mean reward: 164.21
               Mean episode length: 223.63
    Episode_Reward/reaching_object: 1.4792
    Episode_Reward/rotating_object: 32.3445
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 2.13s
                      Time elapsed: 00:22:19
                               ETA: 00:34:56

################################################################################
                     [1m Learning iteration 585/1500 [0m                      

                       Computation: 45187 steps/s (collection: 2.066s, learning 0.110s)
             Mean action noise std: 2.61
          Mean value_function loss: 61.2703
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 73.4946
                       Mean reward: 180.34
               Mean episode length: 229.39
    Episode_Reward/reaching_object: 1.5183
    Episode_Reward/rotating_object: 35.4249
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 2.18s
                      Time elapsed: 00:22:21
                               ETA: 00:34:54

################################################################################
                     [1m Learning iteration 586/1500 [0m                      

                       Computation: 46495 steps/s (collection: 1.999s, learning 0.115s)
             Mean action noise std: 2.61
          Mean value_function loss: 64.1890
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 73.5380
                       Mean reward: 183.18
               Mean episode length: 213.91
    Episode_Reward/reaching_object: 1.5048
    Episode_Reward/rotating_object: 34.2595
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 2.11s
                      Time elapsed: 00:22:23
                               ETA: 00:34:51

################################################################################
                     [1m Learning iteration 587/1500 [0m                      

                       Computation: 43613 steps/s (collection: 2.047s, learning 0.207s)
             Mean action noise std: 2.62
          Mean value_function loss: 72.4814
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 73.5831
                       Mean reward: 190.20
               Mean episode length: 222.59
    Episode_Reward/reaching_object: 1.4677
    Episode_Reward/rotating_object: 32.2224
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 2.25s
                      Time elapsed: 00:22:25
                               ETA: 00:34:49

################################################################################
                     [1m Learning iteration 588/1500 [0m                      

                       Computation: 38812 steps/s (collection: 2.353s, learning 0.180s)
             Mean action noise std: 2.62
          Mean value_function loss: 69.8878
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 73.6220
                       Mean reward: 139.17
               Mean episode length: 211.18
    Episode_Reward/reaching_object: 1.4495
    Episode_Reward/rotating_object: 31.0878
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 2.53s
                      Time elapsed: 00:22:28
                               ETA: 00:34:47

################################################################################
                     [1m Learning iteration 589/1500 [0m                      

                       Computation: 37247 steps/s (collection: 2.510s, learning 0.130s)
             Mean action noise std: 2.62
          Mean value_function loss: 58.5859
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 73.6577
                       Mean reward: 143.83
               Mean episode length: 212.04
    Episode_Reward/reaching_object: 1.4895
    Episode_Reward/rotating_object: 32.4455
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 2.64s
                      Time elapsed: 00:22:30
                               ETA: 00:34:45

################################################################################
                     [1m Learning iteration 590/1500 [0m                      

                       Computation: 41714 steps/s (collection: 2.193s, learning 0.163s)
             Mean action noise std: 2.63
          Mean value_function loss: 66.9929
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 73.7027
                       Mean reward: 159.73
               Mean episode length: 218.96
    Episode_Reward/reaching_object: 1.4723
    Episode_Reward/rotating_object: 30.5156
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 2.36s
                      Time elapsed: 00:22:33
                               ETA: 00:34:43

################################################################################
                     [1m Learning iteration 591/1500 [0m                      

                       Computation: 44683 steps/s (collection: 2.088s, learning 0.112s)
             Mean action noise std: 2.63
          Mean value_function loss: 64.9537
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 73.7424
                       Mean reward: 161.01
               Mean episode length: 212.09
    Episode_Reward/reaching_object: 1.4662
    Episode_Reward/rotating_object: 31.9510
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 2.20s
                      Time elapsed: 00:22:35
                               ETA: 00:34:41

################################################################################
                     [1m Learning iteration 592/1500 [0m                      

                       Computation: 44451 steps/s (collection: 2.095s, learning 0.117s)
             Mean action noise std: 2.63
          Mean value_function loss: 58.5403
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 73.7807
                       Mean reward: 175.19
               Mean episode length: 225.55
    Episode_Reward/reaching_object: 1.4135
    Episode_Reward/rotating_object: 27.8901
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 2.21s
                      Time elapsed: 00:22:37
                               ETA: 00:34:38

################################################################################
                     [1m Learning iteration 593/1500 [0m                      

                       Computation: 43644 steps/s (collection: 2.140s, learning 0.112s)
             Mean action noise std: 2.64
          Mean value_function loss: 64.1890
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 73.8225
                       Mean reward: 214.49
               Mean episode length: 230.08
    Episode_Reward/reaching_object: 1.4870
    Episode_Reward/rotating_object: 35.4855
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 2.25s
                      Time elapsed: 00:22:39
                               ETA: 00:34:36

################################################################################
                     [1m Learning iteration 594/1500 [0m                      

                       Computation: 45346 steps/s (collection: 2.043s, learning 0.124s)
             Mean action noise std: 2.64
          Mean value_function loss: 56.2799
               Mean surrogate loss: -0.0115
                 Mean entropy loss: 73.8574
                       Mean reward: 138.88
               Mean episode length: 203.33
    Episode_Reward/reaching_object: 1.4536
    Episode_Reward/rotating_object: 29.9218
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 2.17s
                      Time elapsed: 00:22:42
                               ETA: 00:34:34

################################################################################
                     [1m Learning iteration 595/1500 [0m                      

                       Computation: 42989 steps/s (collection: 2.109s, learning 0.178s)
             Mean action noise std: 2.64
          Mean value_function loss: 66.9778
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 73.8985
                       Mean reward: 148.90
               Mean episode length: 219.76
    Episode_Reward/reaching_object: 1.4591
    Episode_Reward/rotating_object: 29.0295
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 2.29s
                      Time elapsed: 00:22:44
                               ETA: 00:34:31

################################################################################
                     [1m Learning iteration 596/1500 [0m                      

                       Computation: 42940 steps/s (collection: 2.177s, learning 0.112s)
             Mean action noise std: 2.65
          Mean value_function loss: 65.7756
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 73.9355
                       Mean reward: 215.70
               Mean episode length: 224.86
    Episode_Reward/reaching_object: 1.5043
    Episode_Reward/rotating_object: 33.4326
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 2.29s
                      Time elapsed: 00:22:46
                               ETA: 00:34:29

################################################################################
                     [1m Learning iteration 597/1500 [0m                      

                       Computation: 42109 steps/s (collection: 2.180s, learning 0.155s)
             Mean action noise std: 2.65
          Mean value_function loss: 68.2332
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 73.9778
                       Mean reward: 187.00
               Mean episode length: 223.53
    Episode_Reward/reaching_object: 1.4941
    Episode_Reward/rotating_object: 33.6984
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 2.33s
                      Time elapsed: 00:22:49
                               ETA: 00:34:27

################################################################################
                     [1m Learning iteration 598/1500 [0m                      

                       Computation: 42685 steps/s (collection: 2.195s, learning 0.108s)
             Mean action noise std: 2.65
          Mean value_function loss: 59.3781
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 74.0264
                       Mean reward: 193.27
               Mean episode length: 223.40
    Episode_Reward/reaching_object: 1.4613
    Episode_Reward/rotating_object: 29.2247
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 2.30s
                      Time elapsed: 00:22:51
                               ETA: 00:34:25

################################################################################
                     [1m Learning iteration 599/1500 [0m                      

                       Computation: 43827 steps/s (collection: 2.090s, learning 0.153s)
             Mean action noise std: 2.66
          Mean value_function loss: 60.5465
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 74.0642
                       Mean reward: 151.22
               Mean episode length: 206.52
    Episode_Reward/reaching_object: 1.4043
    Episode_Reward/rotating_object: 31.0714
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 2.24s
                      Time elapsed: 00:22:53
                               ETA: 00:34:22

################################################################################
                     [1m Learning iteration 600/1500 [0m                      

                       Computation: 40554 steps/s (collection: 2.240s, learning 0.184s)
             Mean action noise std: 2.66
          Mean value_function loss: 57.4676
               Mean surrogate loss: -0.0111
                 Mean entropy loss: 74.0941
                       Mean reward: 197.99
               Mean episode length: 231.10
    Episode_Reward/reaching_object: 1.4834
    Episode_Reward/rotating_object: 33.6617
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 2.42s
                      Time elapsed: 00:22:56
                               ETA: 00:34:20

################################################################################
                     [1m Learning iteration 601/1500 [0m                      

                       Computation: 41646 steps/s (collection: 2.153s, learning 0.208s)
             Mean action noise std: 2.66
          Mean value_function loss: 53.9802
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 74.1201
                       Mean reward: 143.59
               Mean episode length: 209.20
    Episode_Reward/reaching_object: 1.4017
    Episode_Reward/rotating_object: 27.9037
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 2.36s
                      Time elapsed: 00:22:58
                               ETA: 00:34:18

################################################################################
                     [1m Learning iteration 602/1500 [0m                      

                       Computation: 38698 steps/s (collection: 2.377s, learning 0.164s)
             Mean action noise std: 2.67
          Mean value_function loss: 60.9055
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 74.1537
                       Mean reward: 132.08
               Mean episode length: 209.99
    Episode_Reward/reaching_object: 1.4290
    Episode_Reward/rotating_object: 32.8783
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 2.54s
                      Time elapsed: 00:23:00
                               ETA: 00:34:16

################################################################################
                     [1m Learning iteration 603/1500 [0m                      

                       Computation: 40182 steps/s (collection: 2.333s, learning 0.113s)
             Mean action noise std: 2.67
          Mean value_function loss: 67.6312
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 74.2039
                       Mean reward: 169.74
               Mean episode length: 224.86
    Episode_Reward/reaching_object: 1.4486
    Episode_Reward/rotating_object: 31.6414
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 2.45s
                      Time elapsed: 00:23:03
                               ETA: 00:34:14

################################################################################
                     [1m Learning iteration 604/1500 [0m                      

                       Computation: 47508 steps/s (collection: 1.968s, learning 0.102s)
             Mean action noise std: 2.67
          Mean value_function loss: 60.4194
               Mean surrogate loss: -0.0115
                 Mean entropy loss: 74.2376
                       Mean reward: 185.05
               Mean episode length: 218.55
    Episode_Reward/reaching_object: 1.4340
    Episode_Reward/rotating_object: 31.4647
        Episode_Reward/action_rate: -0.0461
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 2.07s
                      Time elapsed: 00:23:05
                               ETA: 00:34:11

################################################################################
                     [1m Learning iteration 605/1500 [0m                      

                       Computation: 49175 steps/s (collection: 1.902s, learning 0.097s)
             Mean action noise std: 2.68
          Mean value_function loss: 72.6703
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 74.2729
                       Mean reward: 167.73
               Mean episode length: 226.81
    Episode_Reward/reaching_object: 1.4314
    Episode_Reward/rotating_object: 30.3234
        Episode_Reward/action_rate: -0.0459
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 2.00s
                      Time elapsed: 00:23:07
                               ETA: 00:34:09

################################################################################
                     [1m Learning iteration 606/1500 [0m                      

                       Computation: 48787 steps/s (collection: 1.917s, learning 0.098s)
             Mean action noise std: 2.68
          Mean value_function loss: 68.3164
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 74.3043
                       Mean reward: 146.70
               Mean episode length: 215.92
    Episode_Reward/reaching_object: 1.4301
    Episode_Reward/rotating_object: 32.5643
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 2.01s
                      Time elapsed: 00:23:09
                               ETA: 00:34:06

################################################################################
                     [1m Learning iteration 607/1500 [0m                      

                       Computation: 48633 steps/s (collection: 1.919s, learning 0.102s)
             Mean action noise std: 2.68
          Mean value_function loss: 65.9216
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 74.3440
                       Mean reward: 150.03
               Mean episode length: 212.54
    Episode_Reward/reaching_object: 1.4020
    Episode_Reward/rotating_object: 30.6424
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 2.02s
                      Time elapsed: 00:23:11
                               ETA: 00:34:03

################################################################################
                     [1m Learning iteration 608/1500 [0m                      

                       Computation: 45227 steps/s (collection: 2.066s, learning 0.108s)
             Mean action noise std: 2.69
          Mean value_function loss: 66.7623
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 74.3786
                       Mean reward: 168.46
               Mean episode length: 209.23
    Episode_Reward/reaching_object: 1.4239
    Episode_Reward/rotating_object: 33.4045
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 2.17s
                      Time elapsed: 00:23:13
                               ETA: 00:34:01

################################################################################
                     [1m Learning iteration 609/1500 [0m                      

                       Computation: 44613 steps/s (collection: 2.103s, learning 0.101s)
             Mean action noise std: 2.69
          Mean value_function loss: 59.7379
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 74.4105
                       Mean reward: 177.03
               Mean episode length: 217.86
    Episode_Reward/reaching_object: 1.4143
    Episode_Reward/rotating_object: 33.0247
        Episode_Reward/action_rate: -0.0461
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 2.20s
                      Time elapsed: 00:23:15
                               ETA: 00:33:58

################################################################################
                     [1m Learning iteration 610/1500 [0m                      

                       Computation: 47146 steps/s (collection: 1.963s, learning 0.122s)
             Mean action noise std: 2.69
          Mean value_function loss: 65.3808
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 74.4415
                       Mean reward: 170.30
               Mean episode length: 217.55
    Episode_Reward/reaching_object: 1.4451
    Episode_Reward/rotating_object: 31.8819
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 2.09s
                      Time elapsed: 00:23:17
                               ETA: 00:33:56

################################################################################
                     [1m Learning iteration 611/1500 [0m                      

                       Computation: 45581 steps/s (collection: 1.954s, learning 0.203s)
             Mean action noise std: 2.69
          Mean value_function loss: 58.7046
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 74.4763
                       Mean reward: 153.32
               Mean episode length: 212.39
    Episode_Reward/reaching_object: 1.4321
    Episode_Reward/rotating_object: 34.2299
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 2.16s
                      Time elapsed: 00:23:20
                               ETA: 00:33:53

################################################################################
                     [1m Learning iteration 612/1500 [0m                      

                       Computation: 41314 steps/s (collection: 2.206s, learning 0.174s)
             Mean action noise std: 2.70
          Mean value_function loss: 50.6603
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 74.5137
                       Mean reward: 208.90
               Mean episode length: 212.15
    Episode_Reward/reaching_object: 1.4332
    Episode_Reward/rotating_object: 36.7950
        Episode_Reward/action_rate: -0.0475
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 2.38s
                      Time elapsed: 00:23:22
                               ETA: 00:33:51

################################################################################
                     [1m Learning iteration 613/1500 [0m                      

                       Computation: 43478 steps/s (collection: 2.121s, learning 0.140s)
             Mean action noise std: 2.70
          Mean value_function loss: 60.0827
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 74.5541
                       Mean reward: 154.81
               Mean episode length: 218.85
    Episode_Reward/reaching_object: 1.4295
    Episode_Reward/rotating_object: 32.5630
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 2.26s
                      Time elapsed: 00:23:24
                               ETA: 00:33:49

################################################################################
                     [1m Learning iteration 614/1500 [0m                      

                       Computation: 44044 steps/s (collection: 2.064s, learning 0.168s)
             Mean action noise std: 2.70
          Mean value_function loss: 54.5522
               Mean surrogate loss: -0.0114
                 Mean entropy loss: 74.5918
                       Mean reward: 191.76
               Mean episode length: 225.33
    Episode_Reward/reaching_object: 1.4689
    Episode_Reward/rotating_object: 36.6886
        Episode_Reward/action_rate: -0.0484
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 2.23s
                      Time elapsed: 00:23:26
                               ETA: 00:33:46

################################################################################
                     [1m Learning iteration 615/1500 [0m                      

                       Computation: 44654 steps/s (collection: 2.101s, learning 0.101s)
             Mean action noise std: 2.71
          Mean value_function loss: 63.3043
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 74.6272
                       Mean reward: 143.03
               Mean episode length: 195.34
    Episode_Reward/reaching_object: 1.4094
    Episode_Reward/rotating_object: 33.5172
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 2.20s
                      Time elapsed: 00:23:29
                               ETA: 00:33:44

################################################################################
                     [1m Learning iteration 616/1500 [0m                      

                       Computation: 43299 steps/s (collection: 2.140s, learning 0.131s)
             Mean action noise std: 2.71
          Mean value_function loss: 59.7969
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 74.6736
                       Mean reward: 144.58
               Mean episode length: 210.25
    Episode_Reward/reaching_object: 1.4035
    Episode_Reward/rotating_object: 33.1370
        Episode_Reward/action_rate: -0.0472
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 2.27s
                      Time elapsed: 00:23:31
                               ETA: 00:33:42

################################################################################
                     [1m Learning iteration 617/1500 [0m                      

                       Computation: 42441 steps/s (collection: 2.174s, learning 0.143s)
             Mean action noise std: 2.71
          Mean value_function loss: 58.8904
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 74.7131
                       Mean reward: 154.73
               Mean episode length: 197.96
    Episode_Reward/reaching_object: 1.3679
    Episode_Reward/rotating_object: 29.6825
        Episode_Reward/action_rate: -0.0459
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 2.32s
                      Time elapsed: 00:23:33
                               ETA: 00:33:39

################################################################################
                     [1m Learning iteration 618/1500 [0m                      

                       Computation: 41974 steps/s (collection: 2.208s, learning 0.134s)
             Mean action noise std: 2.72
          Mean value_function loss: 56.1568
               Mean surrogate loss: -0.0117
                 Mean entropy loss: 74.7551
                       Mean reward: 145.69
               Mean episode length: 208.96
    Episode_Reward/reaching_object: 1.3865
    Episode_Reward/rotating_object: 32.1865
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 2.34s
                      Time elapsed: 00:23:36
                               ETA: 00:33:37

################################################################################
                     [1m Learning iteration 619/1500 [0m                      

                       Computation: 43185 steps/s (collection: 2.123s, learning 0.154s)
             Mean action noise std: 2.72
          Mean value_function loss: 57.9827
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 74.8020
                       Mean reward: 164.18
               Mean episode length: 205.60
    Episode_Reward/reaching_object: 1.3832
    Episode_Reward/rotating_object: 31.2207
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 2.28s
                      Time elapsed: 00:23:38
                               ETA: 00:33:35

################################################################################
                     [1m Learning iteration 620/1500 [0m                      

                       Computation: 43478 steps/s (collection: 2.120s, learning 0.141s)
             Mean action noise std: 2.73
          Mean value_function loss: 64.2302
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 74.8534
                       Mean reward: 178.33
               Mean episode length: 214.74
    Episode_Reward/reaching_object: 1.4210
    Episode_Reward/rotating_object: 34.2015
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 2.26s
                      Time elapsed: 00:23:40
                               ETA: 00:33:33

################################################################################
                     [1m Learning iteration 621/1500 [0m                      

                       Computation: 43306 steps/s (collection: 2.135s, learning 0.135s)
             Mean action noise std: 2.73
          Mean value_function loss: 61.9322
               Mean surrogate loss: -0.0116
                 Mean entropy loss: 74.8864
                       Mean reward: 149.86
               Mean episode length: 207.44
    Episode_Reward/reaching_object: 1.3928
    Episode_Reward/rotating_object: 32.3840
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 2.27s
                      Time elapsed: 00:23:42
                               ETA: 00:33:30

################################################################################
                     [1m Learning iteration 622/1500 [0m                      

                       Computation: 41926 steps/s (collection: 2.173s, learning 0.172s)
             Mean action noise std: 2.73
          Mean value_function loss: 62.3064
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 74.9290
                       Mean reward: 114.45
               Mean episode length: 206.68
    Episode_Reward/reaching_object: 1.3426
    Episode_Reward/rotating_object: 27.7655
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 2.34s
                      Time elapsed: 00:23:45
                               ETA: 00:33:28

################################################################################
                     [1m Learning iteration 623/1500 [0m                      

                       Computation: 44715 steps/s (collection: 2.069s, learning 0.130s)
             Mean action noise std: 2.74
          Mean value_function loss: 62.9553
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 74.9717
                       Mean reward: 172.27
               Mean episode length: 198.03
    Episode_Reward/reaching_object: 1.4259
    Episode_Reward/rotating_object: 31.2806
        Episode_Reward/action_rate: -0.0477
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 2.20s
                      Time elapsed: 00:23:47
                               ETA: 00:33:26

################################################################################
                     [1m Learning iteration 624/1500 [0m                      

                       Computation: 43771 steps/s (collection: 2.104s, learning 0.142s)
             Mean action noise std: 2.74
          Mean value_function loss: 67.2478
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 75.0125
                       Mean reward: 181.69
               Mean episode length: 220.53
    Episode_Reward/reaching_object: 1.4441
    Episode_Reward/rotating_object: 33.9036
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 2.25s
                      Time elapsed: 00:23:49
                               ETA: 00:33:23

################################################################################
                     [1m Learning iteration 625/1500 [0m                      

                       Computation: 44471 steps/s (collection: 2.047s, learning 0.164s)
             Mean action noise std: 2.75
          Mean value_function loss: 70.0813
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 75.0507
                       Mean reward: 181.69
               Mean episode length: 214.03
    Episode_Reward/reaching_object: 1.5051
    Episode_Reward/rotating_object: 34.3532
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 2.21s
                      Time elapsed: 00:23:51
                               ETA: 00:33:21

################################################################################
                     [1m Learning iteration 626/1500 [0m                      

                       Computation: 41024 steps/s (collection: 2.266s, learning 0.130s)
             Mean action noise std: 2.75
          Mean value_function loss: 67.7050
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 75.1037
                       Mean reward: 136.80
               Mean episode length: 207.60
    Episode_Reward/reaching_object: 1.4330
    Episode_Reward/rotating_object: 31.5346
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 2.40s
                      Time elapsed: 00:23:54
                               ETA: 00:33:19

################################################################################
                     [1m Learning iteration 627/1500 [0m                      

                       Computation: 45210 steps/s (collection: 2.022s, learning 0.153s)
             Mean action noise std: 2.75
          Mean value_function loss: 70.5947
               Mean surrogate loss: -0.0112
                 Mean entropy loss: 75.1519
                       Mean reward: 207.06
               Mean episode length: 222.24
    Episode_Reward/reaching_object: 1.4594
    Episode_Reward/rotating_object: 34.6315
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 2.17s
                      Time elapsed: 00:23:56
                               ETA: 00:33:16

################################################################################
                     [1m Learning iteration 628/1500 [0m                      

                       Computation: 44994 steps/s (collection: 2.053s, learning 0.132s)
             Mean action noise std: 2.76
          Mean value_function loss: 60.5700
               Mean surrogate loss: -0.0121
                 Mean entropy loss: 75.1997
                       Mean reward: 182.92
               Mean episode length: 209.99
    Episode_Reward/reaching_object: 1.4126
    Episode_Reward/rotating_object: 33.4003
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 2.18s
                      Time elapsed: 00:23:58
                               ETA: 00:33:14

################################################################################
                     [1m Learning iteration 629/1500 [0m                      

                       Computation: 45810 steps/s (collection: 2.017s, learning 0.129s)
             Mean action noise std: 2.76
          Mean value_function loss: 67.3570
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 75.2427
                       Mean reward: 205.39
               Mean episode length: 220.55
    Episode_Reward/reaching_object: 1.4155
    Episode_Reward/rotating_object: 34.5953
        Episode_Reward/action_rate: -0.0485
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 2.15s
                      Time elapsed: 00:24:00
                               ETA: 00:33:11

################################################################################
                     [1m Learning iteration 630/1500 [0m                      

                       Computation: 45692 steps/s (collection: 2.032s, learning 0.120s)
             Mean action noise std: 2.77
          Mean value_function loss: 64.2504
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 75.2712
                       Mean reward: 183.60
               Mean episode length: 203.73
    Episode_Reward/reaching_object: 1.4473
    Episode_Reward/rotating_object: 35.5701
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 2.15s
                      Time elapsed: 00:24:02
                               ETA: 00:33:09

################################################################################
                     [1m Learning iteration 631/1500 [0m                      

                       Computation: 40670 steps/s (collection: 2.273s, learning 0.144s)
             Mean action noise std: 2.77
          Mean value_function loss: 54.7022
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 75.3105
                       Mean reward: 168.13
               Mean episode length: 224.30
    Episode_Reward/reaching_object: 1.4302
    Episode_Reward/rotating_object: 31.4482
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 2.42s
                      Time elapsed: 00:24:05
                               ETA: 00:33:07

################################################################################
                     [1m Learning iteration 632/1500 [0m                      

                       Computation: 45011 steps/s (collection: 2.049s, learning 0.135s)
             Mean action noise std: 2.77
          Mean value_function loss: 53.0216
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 75.3411
                       Mean reward: 204.16
               Mean episode length: 213.73
    Episode_Reward/reaching_object: 1.4190
    Episode_Reward/rotating_object: 36.5919
        Episode_Reward/action_rate: -0.0493
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 2.18s
                      Time elapsed: 00:24:07
                               ETA: 00:33:04

################################################################################
                     [1m Learning iteration 633/1500 [0m                      

                       Computation: 45134 steps/s (collection: 2.076s, learning 0.102s)
             Mean action noise std: 2.78
          Mean value_function loss: 58.4949
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 75.3792
                       Mean reward: 186.60
               Mean episode length: 216.07
    Episode_Reward/reaching_object: 1.4323
    Episode_Reward/rotating_object: 33.9813
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 2.18s
                      Time elapsed: 00:24:09
                               ETA: 00:33:02

################################################################################
                     [1m Learning iteration 634/1500 [0m                      

                       Computation: 44406 steps/s (collection: 2.054s, learning 0.160s)
             Mean action noise std: 2.78
          Mean value_function loss: 66.4946
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 75.4200
                       Mean reward: 196.42
               Mean episode length: 226.38
    Episode_Reward/reaching_object: 1.4371
    Episode_Reward/rotating_object: 35.8135
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 2.21s
                      Time elapsed: 00:24:11
                               ETA: 00:33:00

################################################################################
                     [1m Learning iteration 635/1500 [0m                      

                       Computation: 44003 steps/s (collection: 2.125s, learning 0.109s)
             Mean action noise std: 2.78
          Mean value_function loss: 59.8345
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 75.4630
                       Mean reward: 190.54
               Mean episode length: 233.12
    Episode_Reward/reaching_object: 1.4281
    Episode_Reward/rotating_object: 31.9867
        Episode_Reward/action_rate: -0.0507
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 2.23s
                      Time elapsed: 00:24:14
                               ETA: 00:32:57

################################################################################
                     [1m Learning iteration 636/1500 [0m                      

                       Computation: 43857 steps/s (collection: 2.141s, learning 0.101s)
             Mean action noise std: 2.79
          Mean value_function loss: 63.5732
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 75.5097
                       Mean reward: 204.25
               Mean episode length: 224.24
    Episode_Reward/reaching_object: 1.4529
    Episode_Reward/rotating_object: 37.6538
        Episode_Reward/action_rate: -0.0515
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 2.24s
                      Time elapsed: 00:24:16
                               ETA: 00:32:55

################################################################################
                     [1m Learning iteration 637/1500 [0m                      

                       Computation: 37943 steps/s (collection: 2.386s, learning 0.205s)
             Mean action noise std: 2.79
          Mean value_function loss: 60.6835
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 75.5612
                       Mean reward: 202.15
               Mean episode length: 223.21
    Episode_Reward/reaching_object: 1.4524
    Episode_Reward/rotating_object: 36.8610
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 2.59s
                      Time elapsed: 00:24:19
                               ETA: 00:32:53

################################################################################
                     [1m Learning iteration 638/1500 [0m                      

                       Computation: 35461 steps/s (collection: 2.618s, learning 0.154s)
             Mean action noise std: 2.80
          Mean value_function loss: 60.6507
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 75.5992
                       Mean reward: 226.62
               Mean episode length: 220.78
    Episode_Reward/reaching_object: 1.4023
    Episode_Reward/rotating_object: 35.6479
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 2.77s
                      Time elapsed: 00:24:21
                               ETA: 00:32:51

################################################################################
                     [1m Learning iteration 639/1500 [0m                      

                       Computation: 44123 steps/s (collection: 2.125s, learning 0.103s)
             Mean action noise std: 2.80
          Mean value_function loss: 65.4052
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 75.6374
                       Mean reward: 164.88
               Mean episode length: 224.41
    Episode_Reward/reaching_object: 1.4349
    Episode_Reward/rotating_object: 32.6787
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 2.23s
                      Time elapsed: 00:24:24
                               ETA: 00:32:49

################################################################################
                     [1m Learning iteration 640/1500 [0m                      

                       Computation: 44380 steps/s (collection: 2.094s, learning 0.121s)
             Mean action noise std: 2.80
          Mean value_function loss: 57.4695
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 75.6805
                       Mean reward: 162.37
               Mean episode length: 221.53
    Episode_Reward/reaching_object: 1.4384
    Episode_Reward/rotating_object: 35.3099
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 2.22s
                      Time elapsed: 00:24:26
                               ETA: 00:32:47

################################################################################
                     [1m Learning iteration 641/1500 [0m                      

                       Computation: 43146 steps/s (collection: 2.160s, learning 0.118s)
             Mean action noise std: 2.81
          Mean value_function loss: 63.8830
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 75.7245
                       Mean reward: 167.58
               Mean episode length: 215.33
    Episode_Reward/reaching_object: 1.3652
    Episode_Reward/rotating_object: 33.6974
        Episode_Reward/action_rate: -0.0495
          Episode_Reward/joint_vel: -0.0460
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 2.28s
                      Time elapsed: 00:24:28
                               ETA: 00:32:44

################################################################################
                     [1m Learning iteration 642/1500 [0m                      

                       Computation: 41593 steps/s (collection: 2.213s, learning 0.151s)
             Mean action noise std: 2.81
          Mean value_function loss: 60.1256
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 75.7668
                       Mean reward: 178.08
               Mean episode length: 220.96
    Episode_Reward/reaching_object: 1.4134
    Episode_Reward/rotating_object: 33.7909
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 2.36s
                      Time elapsed: 00:24:30
                               ETA: 00:32:42

################################################################################
                     [1m Learning iteration 643/1500 [0m                      

                       Computation: 39338 steps/s (collection: 2.368s, learning 0.131s)
             Mean action noise std: 2.81
          Mean value_function loss: 56.3087
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 75.8029
                       Mean reward: 179.94
               Mean episode length: 222.48
    Episode_Reward/reaching_object: 1.4294
    Episode_Reward/rotating_object: 37.3539
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 2.50s
                      Time elapsed: 00:24:33
                               ETA: 00:32:40

################################################################################
                     [1m Learning iteration 644/1500 [0m                      

                       Computation: 41611 steps/s (collection: 2.206s, learning 0.156s)
             Mean action noise std: 2.82
          Mean value_function loss: 56.1988
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 75.8397
                       Mean reward: 196.42
               Mean episode length: 219.43
    Episode_Reward/reaching_object: 1.3935
    Episode_Reward/rotating_object: 33.9647
        Episode_Reward/action_rate: -0.0511
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 2.36s
                      Time elapsed: 00:24:35
                               ETA: 00:32:38

################################################################################
                     [1m Learning iteration 645/1500 [0m                      

                       Computation: 42707 steps/s (collection: 2.142s, learning 0.160s)
             Mean action noise std: 2.82
          Mean value_function loss: 70.2517
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 75.8792
                       Mean reward: 218.70
               Mean episode length: 234.77
    Episode_Reward/reaching_object: 1.4655
    Episode_Reward/rotating_object: 37.8239
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 2.30s
                      Time elapsed: 00:24:38
                               ETA: 00:32:36

################################################################################
                     [1m Learning iteration 646/1500 [0m                      

                       Computation: 47535 steps/s (collection: 1.945s, learning 0.123s)
             Mean action noise std: 2.82
          Mean value_function loss: 66.6704
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 75.9124
                       Mean reward: 162.10
               Mean episode length: 219.31
    Episode_Reward/reaching_object: 1.4387
    Episode_Reward/rotating_object: 36.1614
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 2.07s
                      Time elapsed: 00:24:40
                               ETA: 00:32:33

################################################################################
                     [1m Learning iteration 647/1500 [0m                      

                       Computation: 46163 steps/s (collection: 2.021s, learning 0.108s)
             Mean action noise std: 2.83
          Mean value_function loss: 65.3046
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 75.9494
                       Mean reward: 162.24
               Mean episode length: 216.26
    Episode_Reward/reaching_object: 1.4468
    Episode_Reward/rotating_object: 33.9188
        Episode_Reward/action_rate: -0.0528
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 2.13s
                      Time elapsed: 00:24:42
                               ETA: 00:32:31

################################################################################
                     [1m Learning iteration 648/1500 [0m                      

                       Computation: 39580 steps/s (collection: 2.249s, learning 0.235s)
             Mean action noise std: 2.83
          Mean value_function loss: 66.8997
               Mean surrogate loss: -0.0111
                 Mean entropy loss: 75.9833
                       Mean reward: 186.23
               Mean episode length: 221.15
    Episode_Reward/reaching_object: 1.3738
    Episode_Reward/rotating_object: 32.3144
        Episode_Reward/action_rate: -0.0507
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 2.48s
                      Time elapsed: 00:24:44
                               ETA: 00:32:29

################################################################################
                     [1m Learning iteration 649/1500 [0m                      

                       Computation: 43000 steps/s (collection: 2.116s, learning 0.170s)
             Mean action noise std: 2.84
          Mean value_function loss: 57.2431
               Mean surrogate loss: -0.0111
                 Mean entropy loss: 76.0255
                       Mean reward: 191.30
               Mean episode length: 213.60
    Episode_Reward/reaching_object: 1.4096
    Episode_Reward/rotating_object: 35.9402
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 2.29s
                      Time elapsed: 00:24:47
                               ETA: 00:32:26

################################################################################
                     [1m Learning iteration 650/1500 [0m                      

                       Computation: 42209 steps/s (collection: 2.172s, learning 0.157s)
             Mean action noise std: 2.84
          Mean value_function loss: 67.3479
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 76.0612
                       Mean reward: 219.87
               Mean episode length: 222.03
    Episode_Reward/reaching_object: 1.4437
    Episode_Reward/rotating_object: 37.3021
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 2.33s
                      Time elapsed: 00:24:49
                               ETA: 00:32:24

################################################################################
                     [1m Learning iteration 651/1500 [0m                      

                       Computation: 45888 steps/s (collection: 2.052s, learning 0.090s)
             Mean action noise std: 2.84
          Mean value_function loss: 59.0761
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 76.1002
                       Mean reward: 173.23
               Mean episode length: 207.86
    Episode_Reward/reaching_object: 1.3791
    Episode_Reward/rotating_object: 32.7056
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 2.14s
                      Time elapsed: 00:24:51
                               ETA: 00:32:22

################################################################################
                     [1m Learning iteration 652/1500 [0m                      

                       Computation: 40093 steps/s (collection: 2.291s, learning 0.161s)
             Mean action noise std: 2.85
          Mean value_function loss: 64.4826
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 76.1402
                       Mean reward: 185.23
               Mean episode length: 207.54
    Episode_Reward/reaching_object: 1.3917
    Episode_Reward/rotating_object: 37.6813
        Episode_Reward/action_rate: -0.0517
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 2.45s
                      Time elapsed: 00:24:53
                               ETA: 00:32:20

################################################################################
                     [1m Learning iteration 653/1500 [0m                      

                       Computation: 43394 steps/s (collection: 2.101s, learning 0.164s)
             Mean action noise std: 2.85
          Mean value_function loss: 70.8928
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 76.1816
                       Mean reward: 184.86
               Mean episode length: 208.36
    Episode_Reward/reaching_object: 1.4054
    Episode_Reward/rotating_object: 37.2526
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 2.27s
                      Time elapsed: 00:24:56
                               ETA: 00:32:17

################################################################################
                     [1m Learning iteration 654/1500 [0m                      

                       Computation: 45582 steps/s (collection: 2.046s, learning 0.110s)
             Mean action noise std: 2.85
          Mean value_function loss: 63.3176
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 76.2233
                       Mean reward: 187.23
               Mean episode length: 210.91
    Episode_Reward/reaching_object: 1.4089
    Episode_Reward/rotating_object: 37.2629
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 2.16s
                      Time elapsed: 00:24:58
                               ETA: 00:32:15

################################################################################
                     [1m Learning iteration 655/1500 [0m                      

                       Computation: 43272 steps/s (collection: 2.144s, learning 0.128s)
             Mean action noise std: 2.86
          Mean value_function loss: 62.0698
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 76.2599
                       Mean reward: 157.05
               Mean episode length: 209.70
    Episode_Reward/reaching_object: 1.3560
    Episode_Reward/rotating_object: 32.8547
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 2.27s
                      Time elapsed: 00:25:00
                               ETA: 00:32:12

################################################################################
                     [1m Learning iteration 656/1500 [0m                      

                       Computation: 46712 steps/s (collection: 1.985s, learning 0.120s)
             Mean action noise std: 2.86
          Mean value_function loss: 62.0081
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 76.3006
                       Mean reward: 194.72
               Mean episode length: 223.15
    Episode_Reward/reaching_object: 1.4321
    Episode_Reward/rotating_object: 40.2329
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 2.10s
                      Time elapsed: 00:25:02
                               ETA: 00:32:10

################################################################################
                     [1m Learning iteration 657/1500 [0m                      

                       Computation: 43855 steps/s (collection: 2.127s, learning 0.114s)
             Mean action noise std: 2.87
          Mean value_function loss: 60.4958
               Mean surrogate loss: -0.0114
                 Mean entropy loss: 76.3546
                       Mean reward: 237.85
               Mean episode length: 229.61
    Episode_Reward/reaching_object: 1.4305
    Episode_Reward/rotating_object: 38.7669
        Episode_Reward/action_rate: -0.0535
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 2.24s
                      Time elapsed: 00:25:04
                               ETA: 00:32:08

################################################################################
                     [1m Learning iteration 658/1500 [0m                      

                       Computation: 47509 steps/s (collection: 1.970s, learning 0.100s)
             Mean action noise std: 2.87
          Mean value_function loss: 58.4720
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 76.4092
                       Mean reward: 192.57
               Mean episode length: 232.02
    Episode_Reward/reaching_object: 1.4315
    Episode_Reward/rotating_object: 35.4233
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0468
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 2.07s
                      Time elapsed: 00:25:07
                               ETA: 00:32:05

################################################################################
                     [1m Learning iteration 659/1500 [0m                      

                       Computation: 44970 steps/s (collection: 1.993s, learning 0.193s)
             Mean action noise std: 2.88
          Mean value_function loss: 67.8381
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 76.4475
                       Mean reward: 177.95
               Mean episode length: 202.42
    Episode_Reward/reaching_object: 1.4446
    Episode_Reward/rotating_object: 40.3394
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 2.19s
                      Time elapsed: 00:25:09
                               ETA: 00:32:03

################################################################################
                     [1m Learning iteration 660/1500 [0m                      

                       Computation: 46428 steps/s (collection: 1.963s, learning 0.154s)
             Mean action noise std: 2.88
          Mean value_function loss: 58.9635
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 76.4903
                       Mean reward: 152.82
               Mean episode length: 211.22
    Episode_Reward/reaching_object: 1.4019
    Episode_Reward/rotating_object: 34.0100
        Episode_Reward/action_rate: -0.0529
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 2.12s
                      Time elapsed: 00:25:11
                               ETA: 00:32:00

################################################################################
                     [1m Learning iteration 661/1500 [0m                      

                       Computation: 46844 steps/s (collection: 1.928s, learning 0.171s)
             Mean action noise std: 2.88
          Mean value_function loss: 64.7211
               Mean surrogate loss: -0.0111
                 Mean entropy loss: 76.5388
                       Mean reward: 213.78
               Mean episode length: 219.27
    Episode_Reward/reaching_object: 1.4266
    Episode_Reward/rotating_object: 39.4546
        Episode_Reward/action_rate: -0.0538
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 2.10s
                      Time elapsed: 00:25:13
                               ETA: 00:31:58

################################################################################
                     [1m Learning iteration 662/1500 [0m                      

                       Computation: 45619 steps/s (collection: 2.026s, learning 0.129s)
             Mean action noise std: 2.89
          Mean value_function loss: 66.0032
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 76.5862
                       Mean reward: 163.12
               Mean episode length: 215.75
    Episode_Reward/reaching_object: 1.4032
    Episode_Reward/rotating_object: 34.4269
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 2.15s
                      Time elapsed: 00:25:15
                               ETA: 00:31:55

################################################################################
                     [1m Learning iteration 663/1500 [0m                      

                       Computation: 45970 steps/s (collection: 2.011s, learning 0.127s)
             Mean action noise std: 2.89
          Mean value_function loss: 60.0930
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 76.6209
                       Mean reward: 200.07
               Mean episode length: 228.51
    Episode_Reward/reaching_object: 1.4692
    Episode_Reward/rotating_object: 34.4922
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 2.14s
                      Time elapsed: 00:25:17
                               ETA: 00:31:53

################################################################################
                     [1m Learning iteration 664/1500 [0m                      

                       Computation: 44900 steps/s (collection: 2.017s, learning 0.172s)
             Mean action noise std: 2.90
          Mean value_function loss: 68.6498
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 76.6608
                       Mean reward: 179.27
               Mean episode length: 217.56
    Episode_Reward/reaching_object: 1.4203
    Episode_Reward/rotating_object: 36.8852
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 2.19s
                      Time elapsed: 00:25:19
                               ETA: 00:31:50

################################################################################
                     [1m Learning iteration 665/1500 [0m                      

                       Computation: 44091 steps/s (collection: 2.067s, learning 0.162s)
             Mean action noise std: 2.90
          Mean value_function loss: 62.3487
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 76.7002
                       Mean reward: 193.71
               Mean episode length: 219.10
    Episode_Reward/reaching_object: 1.4392
    Episode_Reward/rotating_object: 39.2100
        Episode_Reward/action_rate: -0.0553
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 2.23s
                      Time elapsed: 00:25:22
                               ETA: 00:31:48

################################################################################
                     [1m Learning iteration 666/1500 [0m                      

                       Computation: 26569 steps/s (collection: 3.561s, learning 0.139s)
             Mean action noise std: 2.90
          Mean value_function loss: 74.0817
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 76.7443
                       Mean reward: 187.32
               Mean episode length: 216.23
    Episode_Reward/reaching_object: 1.4162
    Episode_Reward/rotating_object: 36.8937
        Episode_Reward/action_rate: -0.0544
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 3.70s
                      Time elapsed: 00:25:25
                               ETA: 00:31:47

################################################################################
                     [1m Learning iteration 667/1500 [0m                      

                       Computation: 14071 steps/s (collection: 6.805s, learning 0.181s)
             Mean action noise std: 2.91
          Mean value_function loss: 63.9880
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 76.7807
                       Mean reward: 207.71
               Mean episode length: 223.23
    Episode_Reward/reaching_object: 1.3938
    Episode_Reward/rotating_object: 37.3596
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 6.99s
                      Time elapsed: 00:25:32
                               ETA: 00:31:51

################################################################################
                     [1m Learning iteration 668/1500 [0m                      

                       Computation: 14215 steps/s (collection: 6.777s, learning 0.138s)
             Mean action noise std: 2.91
          Mean value_function loss: 73.6449
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 76.8216
                       Mean reward: 177.97
               Mean episode length: 223.59
    Episode_Reward/reaching_object: 1.4365
    Episode_Reward/rotating_object: 38.6456
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 6.92s
                      Time elapsed: 00:25:39
                               ETA: 00:31:54

################################################################################
                     [1m Learning iteration 669/1500 [0m                      

                       Computation: 13836 steps/s (collection: 6.941s, learning 0.164s)
             Mean action noise std: 2.92
          Mean value_function loss: 72.1507
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 76.8684
                       Mean reward: 171.36
               Mean episode length: 223.15
    Episode_Reward/reaching_object: 1.3966
    Episode_Reward/rotating_object: 35.0539
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 7.10s
                      Time elapsed: 00:25:46
                               ETA: 00:31:58

################################################################################
                     [1m Learning iteration 670/1500 [0m                      

                       Computation: 14803 steps/s (collection: 6.506s, learning 0.135s)
             Mean action noise std: 2.92
          Mean value_function loss: 71.1143
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 76.9063
                       Mean reward: 172.21
               Mean episode length: 212.13
    Episode_Reward/reaching_object: 1.4312
    Episode_Reward/rotating_object: 38.0957
        Episode_Reward/action_rate: -0.0553
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 6.64s
                      Time elapsed: 00:25:53
                               ETA: 00:32:01

################################################################################
                     [1m Learning iteration 671/1500 [0m                      

                       Computation: 14612 steps/s (collection: 6.559s, learning 0.169s)
             Mean action noise std: 2.92
          Mean value_function loss: 68.3440
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 76.9252
                       Mean reward: 203.33
               Mean episode length: 221.36
    Episode_Reward/reaching_object: 1.4214
    Episode_Reward/rotating_object: 36.9768
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 6.73s
                      Time elapsed: 00:26:00
                               ETA: 00:32:04

################################################################################
                     [1m Learning iteration 672/1500 [0m                      

                       Computation: 14795 steps/s (collection: 6.495s, learning 0.150s)
             Mean action noise std: 2.92
          Mean value_function loss: 74.6048
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 76.9511
                       Mean reward: 214.56
               Mean episode length: 222.67
    Episode_Reward/reaching_object: 1.4127
    Episode_Reward/rotating_object: 37.8556
        Episode_Reward/action_rate: -0.0553
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 6.64s
                      Time elapsed: 00:26:06
                               ETA: 00:32:07

################################################################################
                     [1m Learning iteration 673/1500 [0m                      

                       Computation: 14753 steps/s (collection: 6.537s, learning 0.127s)
             Mean action noise std: 2.93
          Mean value_function loss: 81.2589
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 76.9847
                       Mean reward: 158.24
               Mean episode length: 206.23
    Episode_Reward/reaching_object: 1.4049
    Episode_Reward/rotating_object: 37.0930
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 6.66s
                      Time elapsed: 00:26:13
                               ETA: 00:32:10

################################################################################
                     [1m Learning iteration 674/1500 [0m                      

                       Computation: 15221 steps/s (collection: 6.315s, learning 0.144s)
             Mean action noise std: 2.93
          Mean value_function loss: 66.9810
               Mean surrogate loss: -0.0111
                 Mean entropy loss: 77.0150
                       Mean reward: 190.11
               Mean episode length: 216.72
    Episode_Reward/reaching_object: 1.4349
    Episode_Reward/rotating_object: 37.9752
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 6.46s
                      Time elapsed: 00:26:19
                               ETA: 00:32:13

################################################################################
                     [1m Learning iteration 675/1500 [0m                      

                       Computation: 21240 steps/s (collection: 4.465s, learning 0.163s)
             Mean action noise std: 2.93
          Mean value_function loss: 68.6100
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 77.0526
                       Mean reward: 225.25
               Mean episode length: 224.76
    Episode_Reward/reaching_object: 1.4223
    Episode_Reward/rotating_object: 39.8505
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 4.63s
                      Time elapsed: 00:26:24
                               ETA: 00:32:13

################################################################################
                     [1m Learning iteration 676/1500 [0m                      

                       Computation: 44571 steps/s (collection: 2.087s, learning 0.118s)
             Mean action noise std: 2.94
          Mean value_function loss: 65.0249
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 77.0927
                       Mean reward: 195.04
               Mean episode length: 215.19
    Episode_Reward/reaching_object: 1.3935
    Episode_Reward/rotating_object: 36.6374
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 2.21s
                      Time elapsed: 00:26:26
                               ETA: 00:32:11

################################################################################
                     [1m Learning iteration 677/1500 [0m                      

                       Computation: 41942 steps/s (collection: 2.245s, learning 0.099s)
             Mean action noise std: 2.94
          Mean value_function loss: 75.0470
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 77.1308
                       Mean reward: 174.58
               Mean episode length: 212.37
    Episode_Reward/reaching_object: 1.3634
    Episode_Reward/rotating_object: 35.3653
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 2.34s
                      Time elapsed: 00:26:29
                               ETA: 00:32:09

################################################################################
                     [1m Learning iteration 678/1500 [0m                      

                       Computation: 47373 steps/s (collection: 1.972s, learning 0.103s)
             Mean action noise std: 2.94
          Mean value_function loss: 71.3200
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 77.1683
                       Mean reward: 247.75
               Mean episode length: 223.82
    Episode_Reward/reaching_object: 1.4137
    Episode_Reward/rotating_object: 39.8923
        Episode_Reward/action_rate: -0.0561
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 2.08s
                      Time elapsed: 00:26:31
                               ETA: 00:32:06

################################################################################
                     [1m Learning iteration 679/1500 [0m                      

                       Computation: 47831 steps/s (collection: 1.946s, learning 0.110s)
             Mean action noise std: 2.95
          Mean value_function loss: 81.5587
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 77.1946
                       Mean reward: 211.72
               Mean episode length: 222.49
    Episode_Reward/reaching_object: 1.4202
    Episode_Reward/rotating_object: 39.7008
        Episode_Reward/action_rate: -0.0561
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 2.06s
                      Time elapsed: 00:26:33
                               ETA: 00:32:03

################################################################################
                     [1m Learning iteration 680/1500 [0m                      

                       Computation: 47425 steps/s (collection: 1.961s, learning 0.112s)
             Mean action noise std: 2.95
          Mean value_function loss: 75.1617
               Mean surrogate loss: -0.0114
                 Mean entropy loss: 77.2277
                       Mean reward: 181.71
               Mean episode length: 210.54
    Episode_Reward/reaching_object: 1.4144
    Episode_Reward/rotating_object: 39.5088
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 2.07s
                      Time elapsed: 00:26:35
                               ETA: 00:32:01

################################################################################
                     [1m Learning iteration 681/1500 [0m                      

                       Computation: 46712 steps/s (collection: 1.996s, learning 0.108s)
             Mean action noise std: 2.95
          Mean value_function loss: 72.9787
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 77.2657
                       Mean reward: 225.24
               Mean episode length: 218.07
    Episode_Reward/reaching_object: 1.4572
    Episode_Reward/rotating_object: 42.5536
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 2.10s
                      Time elapsed: 00:26:37
                               ETA: 00:31:58

################################################################################
                     [1m Learning iteration 682/1500 [0m                      

                       Computation: 48380 steps/s (collection: 1.923s, learning 0.109s)
             Mean action noise std: 2.96
          Mean value_function loss: 68.6386
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 77.3063
                       Mean reward: 234.85
               Mean episode length: 226.31
    Episode_Reward/reaching_object: 1.4567
    Episode_Reward/rotating_object: 40.4065
        Episode_Reward/action_rate: -0.0569
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 2.03s
                      Time elapsed: 00:26:39
                               ETA: 00:31:55

################################################################################
                     [1m Learning iteration 683/1500 [0m                      

                       Computation: 50283 steps/s (collection: 1.867s, learning 0.088s)
             Mean action noise std: 2.96
          Mean value_function loss: 59.7407
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 77.3361
                       Mean reward: 198.46
               Mean episode length: 208.38
    Episode_Reward/reaching_object: 1.4206
    Episode_Reward/rotating_object: 38.3107
        Episode_Reward/action_rate: -0.0562
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 1.95s
                      Time elapsed: 00:26:41
                               ETA: 00:31:52

################################################################################
                     [1m Learning iteration 684/1500 [0m                      

                       Computation: 48620 steps/s (collection: 1.930s, learning 0.092s)
             Mean action noise std: 2.97
          Mean value_function loss: 64.9997
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 77.3914
                       Mean reward: 233.88
               Mean episode length: 222.33
    Episode_Reward/reaching_object: 1.4056
    Episode_Reward/rotating_object: 41.9769
        Episode_Reward/action_rate: -0.0563
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 2.02s
                      Time elapsed: 00:26:43
                               ETA: 00:31:50

################################################################################
                     [1m Learning iteration 685/1500 [0m                      

                       Computation: 47914 steps/s (collection: 1.947s, learning 0.105s)
             Mean action noise std: 2.97
          Mean value_function loss: 63.8117
               Mean surrogate loss: -0.0111
                 Mean entropy loss: 77.4441
                       Mean reward: 187.86
               Mean episode length: 225.07
    Episode_Reward/reaching_object: 1.4526
    Episode_Reward/rotating_object: 40.2069
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 2.05s
                      Time elapsed: 00:26:45
                               ETA: 00:31:47

################################################################################
                     [1m Learning iteration 686/1500 [0m                      

                       Computation: 46703 steps/s (collection: 1.986s, learning 0.119s)
             Mean action noise std: 2.98
          Mean value_function loss: 69.8536
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 77.4785
                       Mean reward: 204.21
               Mean episode length: 221.16
    Episode_Reward/reaching_object: 1.4320
    Episode_Reward/rotating_object: 41.6781
        Episode_Reward/action_rate: -0.0573
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 2.10s
                      Time elapsed: 00:26:47
                               ETA: 00:31:44

################################################################################
                     [1m Learning iteration 687/1500 [0m                      

                       Computation: 47000 steps/s (collection: 1.998s, learning 0.094s)
             Mean action noise std: 2.98
          Mean value_function loss: 73.6574
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 77.5060
                       Mean reward: 152.85
               Mean episode length: 207.28
    Episode_Reward/reaching_object: 1.4163
    Episode_Reward/rotating_object: 39.3156
        Episode_Reward/action_rate: -0.0568
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 2.09s
                      Time elapsed: 00:26:49
                               ETA: 00:31:42

################################################################################
                     [1m Learning iteration 688/1500 [0m                      

                       Computation: 49390 steps/s (collection: 1.896s, learning 0.094s)
             Mean action noise std: 2.98
          Mean value_function loss: 63.2944
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 77.5249
                       Mean reward: 229.65
               Mean episode length: 221.79
    Episode_Reward/reaching_object: 1.4368
    Episode_Reward/rotating_object: 40.6607
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 1.99s
                      Time elapsed: 00:26:51
                               ETA: 00:31:39

################################################################################
                     [1m Learning iteration 689/1500 [0m                      

                       Computation: 48228 steps/s (collection: 1.946s, learning 0.093s)
             Mean action noise std: 2.98
          Mean value_function loss: 67.9901
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 77.5494
                       Mean reward: 232.04
               Mean episode length: 223.64
    Episode_Reward/reaching_object: 1.4287
    Episode_Reward/rotating_object: 42.6812
        Episode_Reward/action_rate: -0.0581
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 2.04s
                      Time elapsed: 00:26:53
                               ETA: 00:31:36

################################################################################
                     [1m Learning iteration 690/1500 [0m                      

                       Computation: 48189 steps/s (collection: 1.946s, learning 0.094s)
             Mean action noise std: 2.99
          Mean value_function loss: 66.5851
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 77.5871
                       Mean reward: 196.57
               Mean episode length: 221.53
    Episode_Reward/reaching_object: 1.4346
    Episode_Reward/rotating_object: 41.6216
        Episode_Reward/action_rate: -0.0576
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 2.04s
                      Time elapsed: 00:26:55
                               ETA: 00:31:34

################################################################################
                     [1m Learning iteration 691/1500 [0m                      

                       Computation: 48479 steps/s (collection: 1.932s, learning 0.096s)
             Mean action noise std: 2.99
          Mean value_function loss: 67.4269
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 77.6243
                       Mean reward: 200.13
               Mean episode length: 219.39
    Episode_Reward/reaching_object: 1.4235
    Episode_Reward/rotating_object: 41.0242
        Episode_Reward/action_rate: -0.0573
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 2.03s
                      Time elapsed: 00:26:57
                               ETA: 00:31:31

################################################################################
                     [1m Learning iteration 692/1500 [0m                      

                       Computation: 49165 steps/s (collection: 1.903s, learning 0.096s)
             Mean action noise std: 2.99
          Mean value_function loss: 65.3629
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 77.6679
                       Mean reward: 192.72
               Mean episode length: 215.13
    Episode_Reward/reaching_object: 1.4075
    Episode_Reward/rotating_object: 37.2594
        Episode_Reward/action_rate: -0.0569
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 2.00s
                      Time elapsed: 00:26:59
                               ETA: 00:31:28

################################################################################
                     [1m Learning iteration 693/1500 [0m                      

                       Computation: 48672 steps/s (collection: 1.911s, learning 0.109s)
             Mean action noise std: 3.00
          Mean value_function loss: 67.6674
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 77.7198
                       Mean reward: 166.99
               Mean episode length: 219.05
    Episode_Reward/reaching_object: 1.4073
    Episode_Reward/rotating_object: 37.9830
        Episode_Reward/action_rate: -0.0573
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 2.02s
                      Time elapsed: 00:27:01
                               ETA: 00:31:25

################################################################################
                     [1m Learning iteration 694/1500 [0m                      

                       Computation: 48952 steps/s (collection: 1.897s, learning 0.112s)
             Mean action noise std: 3.00
          Mean value_function loss: 78.6573
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 77.7649
                       Mean reward: 200.48
               Mean episode length: 216.58
    Episode_Reward/reaching_object: 1.4247
    Episode_Reward/rotating_object: 40.0320
        Episode_Reward/action_rate: -0.0582
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 2.01s
                      Time elapsed: 00:27:03
                               ETA: 00:31:23

################################################################################
                     [1m Learning iteration 695/1500 [0m                      

                       Computation: 49015 steps/s (collection: 1.895s, learning 0.111s)
             Mean action noise std: 3.01
          Mean value_function loss: 67.9088
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 77.8013
                       Mean reward: 179.36
               Mean episode length: 204.03
    Episode_Reward/reaching_object: 1.4293
    Episode_Reward/rotating_object: 38.2741
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 2.01s
                      Time elapsed: 00:27:05
                               ETA: 00:31:20

################################################################################
                     [1m Learning iteration 696/1500 [0m                      

                       Computation: 48234 steps/s (collection: 1.928s, learning 0.110s)
             Mean action noise std: 3.01
          Mean value_function loss: 68.4439
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 77.8365
                       Mean reward: 194.74
               Mean episode length: 213.78
    Episode_Reward/reaching_object: 1.4096
    Episode_Reward/rotating_object: 38.1133
        Episode_Reward/action_rate: -0.0583
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 2.04s
                      Time elapsed: 00:27:07
                               ETA: 00:31:17

################################################################################
                     [1m Learning iteration 697/1500 [0m                      

                       Computation: 46649 steps/s (collection: 1.998s, learning 0.110s)
             Mean action noise std: 3.02
          Mean value_function loss: 67.3047
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 77.8853
                       Mean reward: 198.70
               Mean episode length: 219.06
    Episode_Reward/reaching_object: 1.4368
    Episode_Reward/rotating_object: 39.8207
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 2.11s
                      Time elapsed: 00:27:10
                               ETA: 00:31:15

################################################################################
                     [1m Learning iteration 698/1500 [0m                      

                       Computation: 48139 steps/s (collection: 1.945s, learning 0.097s)
             Mean action noise std: 3.02
          Mean value_function loss: 70.3688
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 77.9216
                       Mean reward: 185.72
               Mean episode length: 228.61
    Episode_Reward/reaching_object: 1.4134
    Episode_Reward/rotating_object: 36.8665
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 2.04s
                      Time elapsed: 00:27:12
                               ETA: 00:31:12

################################################################################
                     [1m Learning iteration 699/1500 [0m                      

                       Computation: 48252 steps/s (collection: 1.941s, learning 0.097s)
             Mean action noise std: 3.02
          Mean value_function loss: 73.6921
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 77.9570
                       Mean reward: 181.22
               Mean episode length: 210.72
    Episode_Reward/reaching_object: 1.4033
    Episode_Reward/rotating_object: 36.9610
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 2.04s
                      Time elapsed: 00:27:14
                               ETA: 00:31:09

################################################################################
                     [1m Learning iteration 700/1500 [0m                      

                       Computation: 49553 steps/s (collection: 1.883s, learning 0.101s)
             Mean action noise std: 3.03
          Mean value_function loss: 69.8349
               Mean surrogate loss: -0.0113
                 Mean entropy loss: 77.9918
                       Mean reward: 241.98
               Mean episode length: 218.40
    Episode_Reward/reaching_object: 1.4151
    Episode_Reward/rotating_object: 38.6792
        Episode_Reward/action_rate: -0.0589
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 1.98s
                      Time elapsed: 00:27:16
                               ETA: 00:31:07

################################################################################
                     [1m Learning iteration 701/1500 [0m                      

                       Computation: 48451 steps/s (collection: 1.934s, learning 0.095s)
             Mean action noise std: 3.03
          Mean value_function loss: 72.6388
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 78.0242
                       Mean reward: 171.34
               Mean episode length: 218.12
    Episode_Reward/reaching_object: 1.3719
    Episode_Reward/rotating_object: 37.6175
        Episode_Reward/action_rate: -0.0576
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 2.03s
                      Time elapsed: 00:27:18
                               ETA: 00:31:04

################################################################################
                     [1m Learning iteration 702/1500 [0m                      

                       Computation: 48477 steps/s (collection: 1.933s, learning 0.095s)
             Mean action noise std: 3.03
          Mean value_function loss: 75.3487
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 78.0570
                       Mean reward: 213.77
               Mean episode length: 221.35
    Episode_Reward/reaching_object: 1.4393
    Episode_Reward/rotating_object: 38.3648
        Episode_Reward/action_rate: -0.0601
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 2.03s
                      Time elapsed: 00:27:20
                               ETA: 00:31:01

################################################################################
                     [1m Learning iteration 703/1500 [0m                      

                       Computation: 49451 steps/s (collection: 1.889s, learning 0.099s)
             Mean action noise std: 3.04
          Mean value_function loss: 69.8197
               Mean surrogate loss: -0.0114
                 Mean entropy loss: 78.0904
                       Mean reward: 179.35
               Mean episode length: 202.72
    Episode_Reward/reaching_object: 1.3935
    Episode_Reward/rotating_object: 40.1655
        Episode_Reward/action_rate: -0.0585
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 1.99s
                      Time elapsed: 00:27:22
                               ETA: 00:30:59

################################################################################
                     [1m Learning iteration 704/1500 [0m                      

                       Computation: 48781 steps/s (collection: 1.916s, learning 0.099s)
             Mean action noise std: 3.04
          Mean value_function loss: 73.8980
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 78.1204
                       Mean reward: 258.89
               Mean episode length: 231.06
    Episode_Reward/reaching_object: 1.3977
    Episode_Reward/rotating_object: 41.2403
        Episode_Reward/action_rate: -0.0586
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 2.02s
                      Time elapsed: 00:27:24
                               ETA: 00:30:56

################################################################################
                     [1m Learning iteration 705/1500 [0m                      

                       Computation: 48996 steps/s (collection: 1.905s, learning 0.102s)
             Mean action noise std: 3.04
          Mean value_function loss: 78.2419
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 78.1470
                       Mean reward: 171.91
               Mean episode length: 208.77
    Episode_Reward/reaching_object: 1.3489
    Episode_Reward/rotating_object: 35.1901
        Episode_Reward/action_rate: -0.0576
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 2.01s
                      Time elapsed: 00:27:26
                               ETA: 00:30:53

################################################################################
                     [1m Learning iteration 706/1500 [0m                      

                       Computation: 48437 steps/s (collection: 1.930s, learning 0.099s)
             Mean action noise std: 3.05
          Mean value_function loss: 73.8331
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 78.1788
                       Mean reward: 181.04
               Mean episode length: 211.50
    Episode_Reward/reaching_object: 1.4190
    Episode_Reward/rotating_object: 37.3037
        Episode_Reward/action_rate: -0.0603
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 2.03s
                      Time elapsed: 00:27:28
                               ETA: 00:30:50

################################################################################
                     [1m Learning iteration 707/1500 [0m                      

                       Computation: 49430 steps/s (collection: 1.896s, learning 0.093s)
             Mean action noise std: 3.05
          Mean value_function loss: 61.8551
               Mean surrogate loss: -0.0113
                 Mean entropy loss: 78.2172
                       Mean reward: 208.66
               Mean episode length: 220.28
    Episode_Reward/reaching_object: 1.3669
    Episode_Reward/rotating_object: 38.6253
        Episode_Reward/action_rate: -0.0588
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 1.99s
                      Time elapsed: 00:27:30
                               ETA: 00:30:48

################################################################################
                     [1m Learning iteration 708/1500 [0m                      

                       Computation: 48429 steps/s (collection: 1.917s, learning 0.113s)
             Mean action noise std: 3.05
          Mean value_function loss: 69.0180
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 78.2654
                       Mean reward: 184.89
               Mean episode length: 212.34
    Episode_Reward/reaching_object: 1.3902
    Episode_Reward/rotating_object: 39.2011
        Episode_Reward/action_rate: -0.0587
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 2.03s
                      Time elapsed: 00:27:32
                               ETA: 00:30:45

################################################################################
                     [1m Learning iteration 709/1500 [0m                      

                       Computation: 49368 steps/s (collection: 1.889s, learning 0.103s)
             Mean action noise std: 3.06
          Mean value_function loss: 65.4241
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 78.2968
                       Mean reward: 218.25
               Mean episode length: 207.20
    Episode_Reward/reaching_object: 1.3850
    Episode_Reward/rotating_object: 41.0287
        Episode_Reward/action_rate: -0.0588
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 1.99s
                      Time elapsed: 00:27:34
                               ETA: 00:30:42

################################################################################
                     [1m Learning iteration 710/1500 [0m                      

                       Computation: 49079 steps/s (collection: 1.905s, learning 0.098s)
             Mean action noise std: 3.06
          Mean value_function loss: 81.7208
               Mean surrogate loss: -0.0111
                 Mean entropy loss: 78.3300
                       Mean reward: 180.84
               Mean episode length: 213.94
    Episode_Reward/reaching_object: 1.4276
    Episode_Reward/rotating_object: 39.4703
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 2.00s
                      Time elapsed: 00:27:36
                               ETA: 00:30:40

################################################################################
                     [1m Learning iteration 711/1500 [0m                      

                       Computation: 48887 steps/s (collection: 1.897s, learning 0.114s)
             Mean action noise std: 3.07
          Mean value_function loss: 70.5184
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 78.3683
                       Mean reward: 203.33
               Mean episode length: 217.91
    Episode_Reward/reaching_object: 1.4251
    Episode_Reward/rotating_object: 39.4861
        Episode_Reward/action_rate: -0.0598
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 2.01s
                      Time elapsed: 00:27:38
                               ETA: 00:30:37

################################################################################
                     [1m Learning iteration 712/1500 [0m                      

                       Computation: 49674 steps/s (collection: 1.876s, learning 0.103s)
             Mean action noise std: 3.07
          Mean value_function loss: 68.8065
               Mean surrogate loss: -0.0117
                 Mean entropy loss: 78.4134
                       Mean reward: 211.53
               Mean episode length: 210.19
    Episode_Reward/reaching_object: 1.3787
    Episode_Reward/rotating_object: 33.6978
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 1.98s
                      Time elapsed: 00:27:40
                               ETA: 00:30:34

################################################################################
                     [1m Learning iteration 713/1500 [0m                      

                       Computation: 49033 steps/s (collection: 1.909s, learning 0.096s)
             Mean action noise std: 3.07
          Mean value_function loss: 67.8562
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 78.4465
                       Mean reward: 187.79
               Mean episode length: 210.86
    Episode_Reward/reaching_object: 1.4136
    Episode_Reward/rotating_object: 36.6934
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 2.00s
                      Time elapsed: 00:27:42
                               ETA: 00:30:32

################################################################################
                     [1m Learning iteration 714/1500 [0m                      

                       Computation: 48828 steps/s (collection: 1.919s, learning 0.095s)
             Mean action noise std: 3.07
          Mean value_function loss: 73.4553
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 78.4719
                       Mean reward: 245.15
               Mean episode length: 222.64
    Episode_Reward/reaching_object: 1.4601
    Episode_Reward/rotating_object: 42.9867
        Episode_Reward/action_rate: -0.0614
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 2.01s
                      Time elapsed: 00:27:44
                               ETA: 00:30:29

################################################################################
                     [1m Learning iteration 715/1500 [0m                      

                       Computation: 48953 steps/s (collection: 1.914s, learning 0.095s)
             Mean action noise std: 3.08
          Mean value_function loss: 69.6227
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 78.5080
                       Mean reward: 196.92
               Mean episode length: 219.64
    Episode_Reward/reaching_object: 1.4304
    Episode_Reward/rotating_object: 39.2310
        Episode_Reward/action_rate: -0.0609
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 2.01s
                      Time elapsed: 00:27:46
                               ETA: 00:30:26

################################################################################
                     [1m Learning iteration 716/1500 [0m                      

                       Computation: 49005 steps/s (collection: 1.902s, learning 0.104s)
             Mean action noise std: 3.08
          Mean value_function loss: 71.0467
               Mean surrogate loss: -0.0111
                 Mean entropy loss: 78.5502
                       Mean reward: 192.27
               Mean episode length: 219.08
    Episode_Reward/reaching_object: 1.3947
    Episode_Reward/rotating_object: 38.2029
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 2.01s
                      Time elapsed: 00:27:48
                               ETA: 00:30:24

################################################################################
                     [1m Learning iteration 717/1500 [0m                      

                       Computation: 48965 steps/s (collection: 1.908s, learning 0.100s)
             Mean action noise std: 3.09
          Mean value_function loss: 84.9434
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 78.5862
                       Mean reward: 190.59
               Mean episode length: 208.61
    Episode_Reward/reaching_object: 1.3950
    Episode_Reward/rotating_object: 38.8451
        Episode_Reward/action_rate: -0.0603
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 2.01s
                      Time elapsed: 00:27:50
                               ETA: 00:30:21

################################################################################
                     [1m Learning iteration 718/1500 [0m                      

                       Computation: 48968 steps/s (collection: 1.902s, learning 0.105s)
             Mean action noise std: 3.09
          Mean value_function loss: 67.9869
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 78.6375
                       Mean reward: 207.50
               Mean episode length: 221.38
    Episode_Reward/reaching_object: 1.3874
    Episode_Reward/rotating_object: 36.2024
        Episode_Reward/action_rate: -0.0602
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 2.01s
                      Time elapsed: 00:27:52
                               ETA: 00:30:18

################################################################################
                     [1m Learning iteration 719/1500 [0m                      

                       Computation: 47535 steps/s (collection: 1.969s, learning 0.099s)
             Mean action noise std: 3.10
          Mean value_function loss: 68.5573
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 78.6785
                       Mean reward: 223.84
               Mean episode length: 217.59
    Episode_Reward/reaching_object: 1.4278
    Episode_Reward/rotating_object: 40.3579
        Episode_Reward/action_rate: -0.0613
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 2.07s
                      Time elapsed: 00:27:54
                               ETA: 00:30:16

################################################################################
                     [1m Learning iteration 720/1500 [0m                      

                       Computation: 48850 steps/s (collection: 1.919s, learning 0.093s)
             Mean action noise std: 3.10
          Mean value_function loss: 78.0241
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 78.7180
                       Mean reward: 183.81
               Mean episode length: 212.67
    Episode_Reward/reaching_object: 1.3969
    Episode_Reward/rotating_object: 36.9704
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 2.01s
                      Time elapsed: 00:27:56
                               ETA: 00:30:13

################################################################################
                     [1m Learning iteration 721/1500 [0m                      

                       Computation: 49085 steps/s (collection: 1.906s, learning 0.097s)
             Mean action noise std: 3.10
          Mean value_function loss: 74.5294
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 78.7485
                       Mean reward: 178.32
               Mean episode length: 202.20
    Episode_Reward/reaching_object: 1.4438
    Episode_Reward/rotating_object: 41.2146
        Episode_Reward/action_rate: -0.0622
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 2.00s
                      Time elapsed: 00:27:58
                               ETA: 00:30:10

################################################################################
                     [1m Learning iteration 722/1500 [0m                      

                       Computation: 48796 steps/s (collection: 1.913s, learning 0.102s)
             Mean action noise std: 3.11
          Mean value_function loss: 79.6285
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 78.7845
                       Mean reward: 219.63
               Mean episode length: 221.30
    Episode_Reward/reaching_object: 1.4307
    Episode_Reward/rotating_object: 40.6927
        Episode_Reward/action_rate: -0.0614
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 2.01s
                      Time elapsed: 00:28:00
                               ETA: 00:30:08

################################################################################
                     [1m Learning iteration 723/1500 [0m                      

                       Computation: 49143 steps/s (collection: 1.908s, learning 0.092s)
             Mean action noise std: 3.11
          Mean value_function loss: 70.8089
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 78.8196
                       Mean reward: 190.76
               Mean episode length: 201.55
    Episode_Reward/reaching_object: 1.4045
    Episode_Reward/rotating_object: 38.6053
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 2.00s
                      Time elapsed: 00:28:02
                               ETA: 00:30:05

################################################################################
                     [1m Learning iteration 724/1500 [0m                      

                       Computation: 45985 steps/s (collection: 2.031s, learning 0.107s)
             Mean action noise std: 3.11
          Mean value_function loss: 80.9906
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 78.8568
                       Mean reward: 218.93
               Mean episode length: 220.76
    Episode_Reward/reaching_object: 1.4225
    Episode_Reward/rotating_object: 34.9089
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 2.14s
                      Time elapsed: 00:28:04
                               ETA: 00:30:02

################################################################################
                     [1m Learning iteration 725/1500 [0m                      

                       Computation: 49275 steps/s (collection: 1.885s, learning 0.110s)
             Mean action noise std: 3.12
          Mean value_function loss: 79.5231
               Mean surrogate loss: -0.0114
                 Mean entropy loss: 78.8898
                       Mean reward: 200.17
               Mean episode length: 208.26
    Episode_Reward/reaching_object: 1.4478
    Episode_Reward/rotating_object: 39.1898
        Episode_Reward/action_rate: -0.0625
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 1.99s
                      Time elapsed: 00:28:06
                               ETA: 00:30:00

################################################################################
                     [1m Learning iteration 726/1500 [0m                      

                       Computation: 49148 steps/s (collection: 1.901s, learning 0.099s)
             Mean action noise std: 3.12
          Mean value_function loss: 76.8030
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 78.9323
                       Mean reward: 206.53
               Mean episode length: 216.79
    Episode_Reward/reaching_object: 1.3794
    Episode_Reward/rotating_object: 39.8644
        Episode_Reward/action_rate: -0.0609
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 2.00s
                      Time elapsed: 00:28:08
                               ETA: 00:29:57

################################################################################
                     [1m Learning iteration 727/1500 [0m                      

                       Computation: 49774 steps/s (collection: 1.880s, learning 0.095s)
             Mean action noise std: 3.13
          Mean value_function loss: 69.0525
               Mean surrogate loss: -0.0115
                 Mean entropy loss: 78.9717
                       Mean reward: 208.30
               Mean episode length: 224.11
    Episode_Reward/reaching_object: 1.4113
    Episode_Reward/rotating_object: 41.0038
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 1.97s
                      Time elapsed: 00:28:10
                               ETA: 00:29:54

################################################################################
                     [1m Learning iteration 728/1500 [0m                      

                       Computation: 48750 steps/s (collection: 1.910s, learning 0.106s)
             Mean action noise std: 3.13
          Mean value_function loss: 76.2320
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 79.0079
                       Mean reward: 251.47
               Mean episode length: 221.36
    Episode_Reward/reaching_object: 1.4242
    Episode_Reward/rotating_object: 40.2330
        Episode_Reward/action_rate: -0.0629
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 2.02s
                      Time elapsed: 00:28:12
                               ETA: 00:29:52

################################################################################
                     [1m Learning iteration 729/1500 [0m                      

                       Computation: 48384 steps/s (collection: 1.940s, learning 0.092s)
             Mean action noise std: 3.13
          Mean value_function loss: 72.7250
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 79.0342
                       Mean reward: 218.78
               Mean episode length: 210.68
    Episode_Reward/reaching_object: 1.3578
    Episode_Reward/rotating_object: 43.1344
        Episode_Reward/action_rate: -0.0605
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 2.03s
                      Time elapsed: 00:28:14
                               ETA: 00:29:49

################################################################################
                     [1m Learning iteration 730/1500 [0m                      

                       Computation: 48720 steps/s (collection: 1.919s, learning 0.099s)
             Mean action noise std: 3.14
          Mean value_function loss: 66.7489
               Mean surrogate loss: -0.0116
                 Mean entropy loss: 79.0827
                       Mean reward: 178.34
               Mean episode length: 193.76
    Episode_Reward/reaching_object: 1.3669
    Episode_Reward/rotating_object: 38.4949
        Episode_Reward/action_rate: -0.0608
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 2.02s
                      Time elapsed: 00:28:16
                               ETA: 00:29:46

################################################################################
                     [1m Learning iteration 731/1500 [0m                      

                       Computation: 49481 steps/s (collection: 1.896s, learning 0.091s)
             Mean action noise std: 3.14
          Mean value_function loss: 76.0238
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 79.1303
                       Mean reward: 202.50
               Mean episode length: 205.58
    Episode_Reward/reaching_object: 1.4321
    Episode_Reward/rotating_object: 37.2997
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 1.99s
                      Time elapsed: 00:28:18
                               ETA: 00:29:44

################################################################################
                     [1m Learning iteration 732/1500 [0m                      

                       Computation: 49196 steps/s (collection: 1.899s, learning 0.099s)
             Mean action noise std: 3.15
          Mean value_function loss: 73.0539
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 79.1801
                       Mean reward: 225.38
               Mean episode length: 212.11
    Episode_Reward/reaching_object: 1.4247
    Episode_Reward/rotating_object: 40.9249
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 2.00s
                      Time elapsed: 00:28:20
                               ETA: 00:29:41

################################################################################
                     [1m Learning iteration 733/1500 [0m                      

                       Computation: 48054 steps/s (collection: 1.950s, learning 0.096s)
             Mean action noise std: 3.15
          Mean value_function loss: 74.8073
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 79.2230
                       Mean reward: 191.46
               Mean episode length: 205.87
    Episode_Reward/reaching_object: 1.3919
    Episode_Reward/rotating_object: 37.3298
        Episode_Reward/action_rate: -0.0631
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 2.05s
                      Time elapsed: 00:28:22
                               ETA: 00:29:39

################################################################################
                     [1m Learning iteration 734/1500 [0m                      

                       Computation: 48439 steps/s (collection: 1.937s, learning 0.093s)
             Mean action noise std: 3.16
          Mean value_function loss: 67.9915
               Mean surrogate loss: -0.0111
                 Mean entropy loss: 79.2626
                       Mean reward: 165.88
               Mean episode length: 212.68
    Episode_Reward/reaching_object: 1.3993
    Episode_Reward/rotating_object: 37.9015
        Episode_Reward/action_rate: -0.0631
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 2.03s
                      Time elapsed: 00:28:24
                               ETA: 00:29:36

################################################################################
                     [1m Learning iteration 735/1500 [0m                      

                       Computation: 49599 steps/s (collection: 1.890s, learning 0.092s)
             Mean action noise std: 3.16
          Mean value_function loss: 64.2669
               Mean surrogate loss: -0.0115
                 Mean entropy loss: 79.3046
                       Mean reward: 209.48
               Mean episode length: 214.73
    Episode_Reward/reaching_object: 1.4217
    Episode_Reward/rotating_object: 40.3104
        Episode_Reward/action_rate: -0.0635
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 1.98s
                      Time elapsed: 00:28:26
                               ETA: 00:29:33

################################################################################
                     [1m Learning iteration 736/1500 [0m                      

                       Computation: 49204 steps/s (collection: 1.898s, learning 0.100s)
             Mean action noise std: 3.16
          Mean value_function loss: 70.8463
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 79.3453
                       Mean reward: 210.30
               Mean episode length: 218.32
    Episode_Reward/reaching_object: 1.4275
    Episode_Reward/rotating_object: 39.8015
        Episode_Reward/action_rate: -0.0634
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 2.00s
                      Time elapsed: 00:28:28
                               ETA: 00:29:31

################################################################################
                     [1m Learning iteration 737/1500 [0m                      

                       Computation: 49675 steps/s (collection: 1.886s, learning 0.093s)
             Mean action noise std: 3.17
          Mean value_function loss: 70.7532
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 79.3755
                       Mean reward: 232.13
               Mean episode length: 233.99
    Episode_Reward/reaching_object: 1.4675
    Episode_Reward/rotating_object: 43.1688
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 1.98s
                      Time elapsed: 00:28:30
                               ETA: 00:29:28

################################################################################
                     [1m Learning iteration 738/1500 [0m                      

                       Computation: 49677 steps/s (collection: 1.883s, learning 0.096s)
             Mean action noise std: 3.17
          Mean value_function loss: 71.7725
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 79.4161
                       Mean reward: 242.67
               Mean episode length: 223.75
    Episode_Reward/reaching_object: 1.4571
    Episode_Reward/rotating_object: 41.3958
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 1.98s
                      Time elapsed: 00:28:32
                               ETA: 00:29:25

################################################################################
                     [1m Learning iteration 739/1500 [0m                      

                       Computation: 48394 steps/s (collection: 1.938s, learning 0.093s)
             Mean action noise std: 3.18
          Mean value_function loss: 79.8653
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 79.4535
                       Mean reward: 186.93
               Mean episode length: 205.30
    Episode_Reward/reaching_object: 1.3833
    Episode_Reward/rotating_object: 38.7660
        Episode_Reward/action_rate: -0.0625
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 2.03s
                      Time elapsed: 00:28:34
                               ETA: 00:29:23

################################################################################
                     [1m Learning iteration 740/1500 [0m                      

                       Computation: 48443 steps/s (collection: 1.907s, learning 0.122s)
             Mean action noise std: 3.18
          Mean value_function loss: 72.7757
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 79.4946
                       Mean reward: 207.19
               Mean episode length: 217.22
    Episode_Reward/reaching_object: 1.4210
    Episode_Reward/rotating_object: 40.5565
        Episode_Reward/action_rate: -0.0647
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 2.03s
                      Time elapsed: 00:28:36
                               ETA: 00:29:20

################################################################################
                     [1m Learning iteration 741/1500 [0m                      

                       Computation: 48061 steps/s (collection: 1.929s, learning 0.116s)
             Mean action noise std: 3.19
          Mean value_function loss: 75.3799
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 79.5447
                       Mean reward: 226.52
               Mean episode length: 221.49
    Episode_Reward/reaching_object: 1.4420
    Episode_Reward/rotating_object: 42.6141
        Episode_Reward/action_rate: -0.0655
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 2.05s
                      Time elapsed: 00:28:38
                               ETA: 00:29:17

################################################################################
                     [1m Learning iteration 742/1500 [0m                      

                       Computation: 48551 steps/s (collection: 1.921s, learning 0.104s)
             Mean action noise std: 3.19
          Mean value_function loss: 73.5384
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 79.5965
                       Mean reward: 193.00
               Mean episode length: 221.44
    Episode_Reward/reaching_object: 1.4165
    Episode_Reward/rotating_object: 38.1766
        Episode_Reward/action_rate: -0.0644
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 2.02s
                      Time elapsed: 00:28:40
                               ETA: 00:29:15

################################################################################
                     [1m Learning iteration 743/1500 [0m                      

                       Computation: 49693 steps/s (collection: 1.889s, learning 0.089s)
             Mean action noise std: 3.19
          Mean value_function loss: 72.7148
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 79.6256
                       Mean reward: 248.80
               Mean episode length: 211.37
    Episode_Reward/reaching_object: 1.4365
    Episode_Reward/rotating_object: 42.2125
        Episode_Reward/action_rate: -0.0652
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 1.98s
                      Time elapsed: 00:28:42
                               ETA: 00:29:12

################################################################################
                     [1m Learning iteration 744/1500 [0m                      

                       Computation: 49304 steps/s (collection: 1.901s, learning 0.093s)
             Mean action noise std: 3.20
          Mean value_function loss: 78.9133
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 79.6554
                       Mean reward: 223.10
               Mean episode length: 218.32
    Episode_Reward/reaching_object: 1.4231
    Episode_Reward/rotating_object: 43.2888
        Episode_Reward/action_rate: -0.0646
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 1.99s
                      Time elapsed: 00:28:44
                               ETA: 00:29:10

################################################################################
                     [1m Learning iteration 745/1500 [0m                      

                       Computation: 48682 steps/s (collection: 1.929s, learning 0.091s)
             Mean action noise std: 3.20
          Mean value_function loss: 73.2449
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 79.7016
                       Mean reward: 200.46
               Mean episode length: 216.90
    Episode_Reward/reaching_object: 1.4115
    Episode_Reward/rotating_object: 37.7828
        Episode_Reward/action_rate: -0.0643
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 2.02s
                      Time elapsed: 00:28:46
                               ETA: 00:29:07

################################################################################
                     [1m Learning iteration 746/1500 [0m                      

                       Computation: 49388 steps/s (collection: 1.893s, learning 0.098s)
             Mean action noise std: 3.21
          Mean value_function loss: 77.7740
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 79.7394
                       Mean reward: 176.36
               Mean episode length: 214.51
    Episode_Reward/reaching_object: 1.4344
    Episode_Reward/rotating_object: 41.5143
        Episode_Reward/action_rate: -0.0651
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 1.99s
                      Time elapsed: 00:28:48
                               ETA: 00:29:04

################################################################################
                     [1m Learning iteration 747/1500 [0m                      

                       Computation: 48577 steps/s (collection: 1.922s, learning 0.102s)
             Mean action noise std: 3.21
          Mean value_function loss: 69.4232
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 79.7786
                       Mean reward: 181.18
               Mean episode length: 214.48
    Episode_Reward/reaching_object: 1.4165
    Episode_Reward/rotating_object: 41.3199
        Episode_Reward/action_rate: -0.0654
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 2.02s
                      Time elapsed: 00:28:50
                               ETA: 00:29:02

################################################################################
                     [1m Learning iteration 748/1500 [0m                      

                       Computation: 48664 steps/s (collection: 1.928s, learning 0.092s)
             Mean action noise std: 3.22
          Mean value_function loss: 76.8684
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 79.8096
                       Mean reward: 256.76
               Mean episode length: 225.53
    Episode_Reward/reaching_object: 1.4364
    Episode_Reward/rotating_object: 43.7405
        Episode_Reward/action_rate: -0.0666
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 2.02s
                      Time elapsed: 00:28:52
                               ETA: 00:28:59

################################################################################
                     [1m Learning iteration 749/1500 [0m                      

                       Computation: 47029 steps/s (collection: 1.998s, learning 0.093s)
             Mean action noise std: 3.22
          Mean value_function loss: 70.9321
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 79.8507
                       Mean reward: 227.76
               Mean episode length: 226.12
    Episode_Reward/reaching_object: 1.4351
    Episode_Reward/rotating_object: 41.4370
        Episode_Reward/action_rate: -0.0666
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 2.09s
                      Time elapsed: 00:28:54
                               ETA: 00:28:57

################################################################################
                     [1m Learning iteration 750/1500 [0m                      

                       Computation: 48983 steps/s (collection: 1.916s, learning 0.091s)
             Mean action noise std: 3.22
          Mean value_function loss: 67.1075
               Mean surrogate loss: -0.0113
                 Mean entropy loss: 79.8933
                       Mean reward: 235.22
               Mean episode length: 206.68
    Episode_Reward/reaching_object: 1.4039
    Episode_Reward/rotating_object: 41.9880
        Episode_Reward/action_rate: -0.0654
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 2.01s
                      Time elapsed: 00:28:56
                               ETA: 00:28:54

################################################################################
                     [1m Learning iteration 751/1500 [0m                      

                       Computation: 47797 steps/s (collection: 1.965s, learning 0.092s)
             Mean action noise std: 3.23
          Mean value_function loss: 66.9024
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 79.9285
                       Mean reward: 211.14
               Mean episode length: 215.48
    Episode_Reward/reaching_object: 1.4116
    Episode_Reward/rotating_object: 39.3277
        Episode_Reward/action_rate: -0.0665
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 2.06s
                      Time elapsed: 00:28:58
                               ETA: 00:28:51

################################################################################
                     [1m Learning iteration 752/1500 [0m                      

                       Computation: 49179 steps/s (collection: 1.905s, learning 0.094s)
             Mean action noise std: 3.23
          Mean value_function loss: 76.5745
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 79.9736
                       Mean reward: 176.57
               Mean episode length: 197.74
    Episode_Reward/reaching_object: 1.3964
    Episode_Reward/rotating_object: 40.0005
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 2.00s
                      Time elapsed: 00:29:00
                               ETA: 00:28:49

################################################################################
                     [1m Learning iteration 753/1500 [0m                      

                       Computation: 46232 steps/s (collection: 2.002s, learning 0.124s)
             Mean action noise std: 3.24
          Mean value_function loss: 74.6202
               Mean surrogate loss: -0.0118
                 Mean entropy loss: 80.0184
                       Mean reward: 197.85
               Mean episode length: 220.49
    Episode_Reward/reaching_object: 1.4422
    Episode_Reward/rotating_object: 40.5709
        Episode_Reward/action_rate: -0.0685
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 2.13s
                      Time elapsed: 00:29:02
                               ETA: 00:28:46

################################################################################
                     [1m Learning iteration 754/1500 [0m                      

                       Computation: 44894 steps/s (collection: 2.067s, learning 0.123s)
             Mean action noise std: 3.24
          Mean value_function loss: 70.2116
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 80.0652
                       Mean reward: 207.00
               Mean episode length: 213.63
    Episode_Reward/reaching_object: 1.4269
    Episode_Reward/rotating_object: 43.4467
        Episode_Reward/action_rate: -0.0671
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 2.19s
                      Time elapsed: 00:29:05
                               ETA: 00:28:44

################################################################################
                     [1m Learning iteration 755/1500 [0m                      

                       Computation: 47884 steps/s (collection: 1.934s, learning 0.119s)
             Mean action noise std: 3.25
          Mean value_function loss: 70.1860
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 80.1029
                       Mean reward: 226.21
               Mean episode length: 214.92
    Episode_Reward/reaching_object: 1.4165
    Episode_Reward/rotating_object: 44.7050
        Episode_Reward/action_rate: -0.0673
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 2.05s
                      Time elapsed: 00:29:07
                               ETA: 00:28:41

################################################################################
                     [1m Learning iteration 756/1500 [0m                      

                       Computation: 49422 steps/s (collection: 1.870s, learning 0.119s)
             Mean action noise std: 3.25
          Mean value_function loss: 70.1809
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 80.1299
                       Mean reward: 209.04
               Mean episode length: 222.32
    Episode_Reward/reaching_object: 1.4497
    Episode_Reward/rotating_object: 42.0009
        Episode_Reward/action_rate: -0.0688
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 1.99s
                      Time elapsed: 00:29:09
                               ETA: 00:28:39

################################################################################
                     [1m Learning iteration 757/1500 [0m                      

                       Computation: 49044 steps/s (collection: 1.902s, learning 0.103s)
             Mean action noise std: 3.25
          Mean value_function loss: 72.5571
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 80.1581
                       Mean reward: 211.89
               Mean episode length: 212.54
    Episode_Reward/reaching_object: 1.4375
    Episode_Reward/rotating_object: 42.0431
        Episode_Reward/action_rate: -0.0672
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 2.00s
                      Time elapsed: 00:29:11
                               ETA: 00:28:36

################################################################################
                     [1m Learning iteration 758/1500 [0m                      

                       Computation: 48204 steps/s (collection: 1.933s, learning 0.106s)
             Mean action noise std: 3.26
          Mean value_function loss: 81.1247
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 80.1918
                       Mean reward: 225.77
               Mean episode length: 212.45
    Episode_Reward/reaching_object: 1.4170
    Episode_Reward/rotating_object: 40.7323
        Episode_Reward/action_rate: -0.0679
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 2.04s
                      Time elapsed: 00:29:13
                               ETA: 00:28:33

################################################################################
                     [1m Learning iteration 759/1500 [0m                      

                       Computation: 48098 steps/s (collection: 1.943s, learning 0.101s)
             Mean action noise std: 3.26
          Mean value_function loss: 78.5141
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 80.2212
                       Mean reward: 235.62
               Mean episode length: 222.42
    Episode_Reward/reaching_object: 1.3839
    Episode_Reward/rotating_object: 42.3394
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 2.04s
                      Time elapsed: 00:29:15
                               ETA: 00:28:31

################################################################################
                     [1m Learning iteration 760/1500 [0m                      

                       Computation: 49517 steps/s (collection: 1.889s, learning 0.097s)
             Mean action noise std: 3.26
          Mean value_function loss: 74.1450
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 80.2450
                       Mean reward: 218.38
               Mean episode length: 213.77
    Episode_Reward/reaching_object: 1.4772
    Episode_Reward/rotating_object: 43.5989
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 1.99s
                      Time elapsed: 00:29:17
                               ETA: 00:28:28

################################################################################
                     [1m Learning iteration 761/1500 [0m                      

                       Computation: 48684 steps/s (collection: 1.912s, learning 0.107s)
             Mean action noise std: 3.27
          Mean value_function loss: 72.7752
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 80.2801
                       Mean reward: 195.80
               Mean episode length: 220.68
    Episode_Reward/reaching_object: 1.4710
    Episode_Reward/rotating_object: 40.9867
        Episode_Reward/action_rate: -0.0697
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 2.02s
                      Time elapsed: 00:29:19
                               ETA: 00:28:26

################################################################################
                     [1m Learning iteration 762/1500 [0m                      

                       Computation: 49542 steps/s (collection: 1.889s, learning 0.095s)
             Mean action noise std: 3.27
          Mean value_function loss: 76.6265
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 80.3189
                       Mean reward: 240.05
               Mean episode length: 224.13
    Episode_Reward/reaching_object: 1.3994
    Episode_Reward/rotating_object: 41.8462
        Episode_Reward/action_rate: -0.0676
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 1.98s
                      Time elapsed: 00:29:21
                               ETA: 00:28:23

################################################################################
                     [1m Learning iteration 763/1500 [0m                      

                       Computation: 49375 steps/s (collection: 1.899s, learning 0.092s)
             Mean action noise std: 3.27
          Mean value_function loss: 78.6584
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 80.3615
                       Mean reward: 207.81
               Mean episode length: 202.87
    Episode_Reward/reaching_object: 1.3927
    Episode_Reward/rotating_object: 40.1151
        Episode_Reward/action_rate: -0.0665
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 1.99s
                      Time elapsed: 00:29:23
                               ETA: 00:28:20

################################################################################
                     [1m Learning iteration 764/1500 [0m                      

                       Computation: 48804 steps/s (collection: 1.920s, learning 0.094s)
             Mean action noise std: 3.28
          Mean value_function loss: 78.1286
               Mean surrogate loss: -0.0121
                 Mean entropy loss: 80.3954
                       Mean reward: 218.19
               Mean episode length: 208.70
    Episode_Reward/reaching_object: 1.3781
    Episode_Reward/rotating_object: 43.0723
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 2.01s
                      Time elapsed: 00:29:25
                               ETA: 00:28:18

################################################################################
                     [1m Learning iteration 765/1500 [0m                      

                       Computation: 48579 steps/s (collection: 1.928s, learning 0.096s)
             Mean action noise std: 3.28
          Mean value_function loss: 74.0418
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 80.4303
                       Mean reward: 221.59
               Mean episode length: 218.08
    Episode_Reward/reaching_object: 1.4304
    Episode_Reward/rotating_object: 43.1263
        Episode_Reward/action_rate: -0.0686
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 2.02s
                      Time elapsed: 00:29:27
                               ETA: 00:28:15

################################################################################
                     [1m Learning iteration 766/1500 [0m                      

                       Computation: 49226 steps/s (collection: 1.901s, learning 0.096s)
             Mean action noise std: 3.29
          Mean value_function loss: 75.5168
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 80.4675
                       Mean reward: 226.15
               Mean episode length: 217.90
    Episode_Reward/reaching_object: 1.3630
    Episode_Reward/rotating_object: 40.4693
        Episode_Reward/action_rate: -0.0659
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 2.00s
                      Time elapsed: 00:29:29
                               ETA: 00:28:13

################################################################################
                     [1m Learning iteration 767/1500 [0m                      

                       Computation: 48506 steps/s (collection: 1.916s, learning 0.111s)
             Mean action noise std: 3.29
          Mean value_function loss: 76.5728
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 80.5015
                       Mean reward: 244.50
               Mean episode length: 214.74
    Episode_Reward/reaching_object: 1.4180
    Episode_Reward/rotating_object: 45.4199
        Episode_Reward/action_rate: -0.0678
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 2.03s
                      Time elapsed: 00:29:31
                               ETA: 00:28:10

################################################################################
                     [1m Learning iteration 768/1500 [0m                      

                       Computation: 49180 steps/s (collection: 1.901s, learning 0.098s)
             Mean action noise std: 3.29
          Mean value_function loss: 74.5635
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 80.5382
                       Mean reward: 198.20
               Mean episode length: 210.30
    Episode_Reward/reaching_object: 1.4217
    Episode_Reward/rotating_object: 44.6873
        Episode_Reward/action_rate: -0.0683
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 2.00s
                      Time elapsed: 00:29:33
                               ETA: 00:28:07

################################################################################
                     [1m Learning iteration 769/1500 [0m                      

                       Computation: 48955 steps/s (collection: 1.900s, learning 0.108s)
             Mean action noise std: 3.30
          Mean value_function loss: 71.0412
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 80.5810
                       Mean reward: 219.87
               Mean episode length: 204.49
    Episode_Reward/reaching_object: 1.3845
    Episode_Reward/rotating_object: 42.2794
        Episode_Reward/action_rate: -0.0667
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 2.01s
                      Time elapsed: 00:29:35
                               ETA: 00:28:05

################################################################################
                     [1m Learning iteration 770/1500 [0m                      

                       Computation: 48307 steps/s (collection: 1.909s, learning 0.126s)
             Mean action noise std: 3.30
          Mean value_function loss: 74.5269
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 80.6181
                       Mean reward: 220.96
               Mean episode length: 204.06
    Episode_Reward/reaching_object: 1.3977
    Episode_Reward/rotating_object: 44.0545
        Episode_Reward/action_rate: -0.0672
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 2.03s
                      Time elapsed: 00:29:37
                               ETA: 00:28:02

################################################################################
                     [1m Learning iteration 771/1500 [0m                      

                       Computation: 48040 steps/s (collection: 1.899s, learning 0.148s)
             Mean action noise std: 3.31
          Mean value_function loss: 76.5644
               Mean surrogate loss: -0.0112
                 Mean entropy loss: 80.6508
                       Mean reward: 212.71
               Mean episode length: 208.71
    Episode_Reward/reaching_object: 1.3919
    Episode_Reward/rotating_object: 38.9142
        Episode_Reward/action_rate: -0.0673
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 2.05s
                      Time elapsed: 00:29:39
                               ETA: 00:28:00

################################################################################
                     [1m Learning iteration 772/1500 [0m                      

                       Computation: 48024 steps/s (collection: 1.928s, learning 0.119s)
             Mean action noise std: 3.31
          Mean value_function loss: 75.8893
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 80.6938
                       Mean reward: 213.12
               Mean episode length: 224.01
    Episode_Reward/reaching_object: 1.4225
    Episode_Reward/rotating_object: 39.6446
        Episode_Reward/action_rate: -0.0695
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 2.05s
                      Time elapsed: 00:29:41
                               ETA: 00:27:57

################################################################################
                     [1m Learning iteration 773/1500 [0m                      

                       Computation: 48667 steps/s (collection: 1.913s, learning 0.107s)
             Mean action noise std: 3.31
          Mean value_function loss: 78.4582
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 80.7201
                       Mean reward: 202.70
               Mean episode length: 214.31
    Episode_Reward/reaching_object: 1.4182
    Episode_Reward/rotating_object: 42.1547
        Episode_Reward/action_rate: -0.0692
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 2.02s
                      Time elapsed: 00:29:43
                               ETA: 00:27:55

################################################################################
                     [1m Learning iteration 774/1500 [0m                      

                       Computation: 48619 steps/s (collection: 1.916s, learning 0.106s)
             Mean action noise std: 3.32
          Mean value_function loss: 74.9414
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 80.7523
                       Mean reward: 243.00
               Mean episode length: 210.00
    Episode_Reward/reaching_object: 1.3861
    Episode_Reward/rotating_object: 40.9798
        Episode_Reward/action_rate: -0.0679
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 2.02s
                      Time elapsed: 00:29:45
                               ETA: 00:27:52

################################################################################
                     [1m Learning iteration 775/1500 [0m                      

                       Computation: 48442 steps/s (collection: 1.932s, learning 0.097s)
             Mean action noise std: 3.32
          Mean value_function loss: 68.0666
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 80.8034
                       Mean reward: 219.62
               Mean episode length: 212.58
    Episode_Reward/reaching_object: 1.4035
    Episode_Reward/rotating_object: 41.3698
        Episode_Reward/action_rate: -0.0682
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 2.03s
                      Time elapsed: 00:29:47
                               ETA: 00:27:50

################################################################################
                     [1m Learning iteration 776/1500 [0m                      

                       Computation: 48203 steps/s (collection: 1.944s, learning 0.096s)
             Mean action noise std: 3.33
          Mean value_function loss: 72.3461
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 80.8449
                       Mean reward: 206.01
               Mean episode length: 207.25
    Episode_Reward/reaching_object: 1.3827
    Episode_Reward/rotating_object: 38.0960
        Episode_Reward/action_rate: -0.0679
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 2.04s
                      Time elapsed: 00:29:49
                               ETA: 00:27:47

################################################################################
                     [1m Learning iteration 777/1500 [0m                      

                       Computation: 48483 steps/s (collection: 1.926s, learning 0.101s)
             Mean action noise std: 3.33
          Mean value_function loss: 69.0142
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 80.8815
                       Mean reward: 248.23
               Mean episode length: 224.50
    Episode_Reward/reaching_object: 1.4386
    Episode_Reward/rotating_object: 46.6209
        Episode_Reward/action_rate: -0.0694
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 2.03s
                      Time elapsed: 00:29:51
                               ETA: 00:27:44

################################################################################
                     [1m Learning iteration 778/1500 [0m                      

                       Computation: 47160 steps/s (collection: 1.984s, learning 0.100s)
             Mean action noise std: 3.34
          Mean value_function loss: 77.9814
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 80.9221
                       Mean reward: 193.77
               Mean episode length: 217.11
    Episode_Reward/reaching_object: 1.4340
    Episode_Reward/rotating_object: 40.7214
        Episode_Reward/action_rate: -0.0707
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 2.08s
                      Time elapsed: 00:29:53
                               ETA: 00:27:42

################################################################################
                     [1m Learning iteration 779/1500 [0m                      

                       Computation: 46590 steps/s (collection: 1.998s, learning 0.112s)
             Mean action noise std: 3.34
          Mean value_function loss: 73.9888
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 80.9675
                       Mean reward: 212.79
               Mean episode length: 219.03
    Episode_Reward/reaching_object: 1.4344
    Episode_Reward/rotating_object: 43.2484
        Episode_Reward/action_rate: -0.0711
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 2.11s
                      Time elapsed: 00:29:55
                               ETA: 00:27:39

################################################################################
                     [1m Learning iteration 780/1500 [0m                      

                       Computation: 48428 steps/s (collection: 1.928s, learning 0.102s)
             Mean action noise std: 3.35
          Mean value_function loss: 75.2860
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 80.9994
                       Mean reward: 203.67
               Mean episode length: 203.79
    Episode_Reward/reaching_object: 1.4394
    Episode_Reward/rotating_object: 43.4383
        Episode_Reward/action_rate: -0.0704
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 2.03s
                      Time elapsed: 00:29:57
                               ETA: 00:27:37

################################################################################
                     [1m Learning iteration 781/1500 [0m                      

                       Computation: 48787 steps/s (collection: 1.906s, learning 0.109s)
             Mean action noise std: 3.35
          Mean value_function loss: 77.0449
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 81.0264
                       Mean reward: 250.38
               Mean episode length: 229.26
    Episode_Reward/reaching_object: 1.4184
    Episode_Reward/rotating_object: 44.5305
        Episode_Reward/action_rate: -0.0694
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 2.01s
                      Time elapsed: 00:29:59
                               ETA: 00:27:34

################################################################################
                     [1m Learning iteration 782/1500 [0m                      

                       Computation: 48957 steps/s (collection: 1.914s, learning 0.094s)
             Mean action noise std: 3.35
          Mean value_function loss: 76.6346
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 81.0561
                       Mean reward: 215.43
               Mean episode length: 203.30
    Episode_Reward/reaching_object: 1.4234
    Episode_Reward/rotating_object: 43.7475
        Episode_Reward/action_rate: -0.0702
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 2.01s
                      Time elapsed: 00:30:01
                               ETA: 00:27:32

################################################################################
                     [1m Learning iteration 783/1500 [0m                      

                       Computation: 46646 steps/s (collection: 2.005s, learning 0.102s)
             Mean action noise std: 3.36
          Mean value_function loss: 74.2781
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 81.0956
                       Mean reward: 224.94
               Mean episode length: 225.29
    Episode_Reward/reaching_object: 1.4375
    Episode_Reward/rotating_object: 42.8279
        Episode_Reward/action_rate: -0.0713
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 2.11s
                      Time elapsed: 00:30:03
                               ETA: 00:27:29

################################################################################
                     [1m Learning iteration 784/1500 [0m                      

                       Computation: 46899 steps/s (collection: 1.973s, learning 0.123s)
             Mean action noise std: 3.36
          Mean value_function loss: 76.9777
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 81.1377
                       Mean reward: 230.81
               Mean episode length: 212.16
    Episode_Reward/reaching_object: 1.4018
    Episode_Reward/rotating_object: 41.8246
        Episode_Reward/action_rate: -0.0693
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 2.10s
                      Time elapsed: 00:30:06
                               ETA: 00:27:27

################################################################################
                     [1m Learning iteration 785/1500 [0m                      

                       Computation: 48407 steps/s (collection: 1.908s, learning 0.123s)
             Mean action noise std: 3.37
          Mean value_function loss: 67.1917
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 81.1789
                       Mean reward: 213.24
               Mean episode length: 215.17
    Episode_Reward/reaching_object: 1.4193
    Episode_Reward/rotating_object: 41.5493
        Episode_Reward/action_rate: -0.0711
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 2.03s
                      Time elapsed: 00:30:08
                               ETA: 00:27:24

################################################################################
                     [1m Learning iteration 786/1500 [0m                      

                       Computation: 48212 steps/s (collection: 1.920s, learning 0.119s)
             Mean action noise std: 3.37
          Mean value_function loss: 68.6803
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 81.2211
                       Mean reward: 207.49
               Mean episode length: 199.39
    Episode_Reward/reaching_object: 1.3730
    Episode_Reward/rotating_object: 38.9969
        Episode_Reward/action_rate: -0.0690
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 2.04s
                      Time elapsed: 00:30:10
                               ETA: 00:27:22

################################################################################
                     [1m Learning iteration 787/1500 [0m                      

                       Computation: 48591 steps/s (collection: 1.910s, learning 0.113s)
             Mean action noise std: 3.38
          Mean value_function loss: 74.3589
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 81.2695
                       Mean reward: 245.20
               Mean episode length: 209.47
    Episode_Reward/reaching_object: 1.3968
    Episode_Reward/rotating_object: 43.7900
        Episode_Reward/action_rate: -0.0708
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 2.02s
                      Time elapsed: 00:30:12
                               ETA: 00:27:19

################################################################################
                     [1m Learning iteration 788/1500 [0m                      

                       Computation: 48138 steps/s (collection: 1.940s, learning 0.103s)
             Mean action noise std: 3.38
          Mean value_function loss: 75.9073
               Mean surrogate loss: -0.0114
                 Mean entropy loss: 81.3085
                       Mean reward: 240.99
               Mean episode length: 224.54
    Episode_Reward/reaching_object: 1.3912
    Episode_Reward/rotating_object: 41.9178
        Episode_Reward/action_rate: -0.0714
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 2.04s
                      Time elapsed: 00:30:14
                               ETA: 00:27:17

################################################################################
                     [1m Learning iteration 789/1500 [0m                      

                       Computation: 47323 steps/s (collection: 1.974s, learning 0.103s)
             Mean action noise std: 3.38
          Mean value_function loss: 76.0178
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 81.3376
                       Mean reward: 236.89
               Mean episode length: 206.66
    Episode_Reward/reaching_object: 1.4183
    Episode_Reward/rotating_object: 44.0565
        Episode_Reward/action_rate: -0.0724
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 2.08s
                      Time elapsed: 00:30:16
                               ETA: 00:27:14

################################################################################
                     [1m Learning iteration 790/1500 [0m                      

                       Computation: 48282 steps/s (collection: 1.930s, learning 0.106s)
             Mean action noise std: 3.39
          Mean value_function loss: 79.0907
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 81.3681
                       Mean reward: 232.55
               Mean episode length: 212.19
    Episode_Reward/reaching_object: 1.3838
    Episode_Reward/rotating_object: 43.1393
        Episode_Reward/action_rate: -0.0703
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 2.04s
                      Time elapsed: 00:30:18
                               ETA: 00:27:12

################################################################################
                     [1m Learning iteration 791/1500 [0m                      

                       Computation: 47904 steps/s (collection: 1.953s, learning 0.100s)
             Mean action noise std: 3.39
          Mean value_function loss: 78.7410
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 81.4075
                       Mean reward: 190.21
               Mean episode length: 199.61
    Episode_Reward/reaching_object: 1.3513
    Episode_Reward/rotating_object: 39.2398
        Episode_Reward/action_rate: -0.0707
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 2.05s
                      Time elapsed: 00:30:20
                               ETA: 00:27:09

################################################################################
                     [1m Learning iteration 792/1500 [0m                      

                       Computation: 47933 steps/s (collection: 1.954s, learning 0.097s)
             Mean action noise std: 3.39
          Mean value_function loss: 81.6394
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 81.4329
                       Mean reward: 206.83
               Mean episode length: 212.13
    Episode_Reward/reaching_object: 1.3699
    Episode_Reward/rotating_object: 41.0196
        Episode_Reward/action_rate: -0.0704
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 2.05s
                      Time elapsed: 00:30:22
                               ETA: 00:27:07

################################################################################
                     [1m Learning iteration 793/1500 [0m                      

                       Computation: 48259 steps/s (collection: 1.938s, learning 0.099s)
             Mean action noise std: 3.40
          Mean value_function loss: 81.2330
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 81.4614
                       Mean reward: 238.68
               Mean episode length: 216.94
    Episode_Reward/reaching_object: 1.4174
    Episode_Reward/rotating_object: 44.8082
        Episode_Reward/action_rate: -0.0724
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 2.04s
                      Time elapsed: 00:30:24
                               ETA: 00:27:04

################################################################################
                     [1m Learning iteration 794/1500 [0m                      

                       Computation: 46349 steps/s (collection: 2.002s, learning 0.119s)
             Mean action noise std: 3.40
          Mean value_function loss: 76.8810
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 81.4928
                       Mean reward: 239.51
               Mean episode length: 212.29
    Episode_Reward/reaching_object: 1.4080
    Episode_Reward/rotating_object: 42.4443
        Episode_Reward/action_rate: -0.0716
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 2.12s
                      Time elapsed: 00:30:26
                               ETA: 00:27:02

################################################################################
                     [1m Learning iteration 795/1500 [0m                      

                       Computation: 46667 steps/s (collection: 1.994s, learning 0.112s)
             Mean action noise std: 3.41
          Mean value_function loss: 81.4380
               Mean surrogate loss: -0.0114
                 Mean entropy loss: 81.5223
                       Mean reward: 227.45
               Mean episode length: 206.62
    Episode_Reward/reaching_object: 1.3916
    Episode_Reward/rotating_object: 40.6265
        Episode_Reward/action_rate: -0.0717
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 2.11s
                      Time elapsed: 00:30:28
                               ETA: 00:26:59

################################################################################
                     [1m Learning iteration 796/1500 [0m                      

                       Computation: 47341 steps/s (collection: 1.974s, learning 0.102s)
             Mean action noise std: 3.41
          Mean value_function loss: 67.8833
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 81.5535
                       Mean reward: 186.47
               Mean episode length: 202.52
    Episode_Reward/reaching_object: 1.4410
    Episode_Reward/rotating_object: 43.7045
        Episode_Reward/action_rate: -0.0740
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 2.08s
                      Time elapsed: 00:30:30
                               ETA: 00:26:57

################################################################################
                     [1m Learning iteration 797/1500 [0m                      

                       Computation: 47925 steps/s (collection: 1.946s, learning 0.106s)
             Mean action noise std: 3.41
          Mean value_function loss: 67.1262
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 81.5839
                       Mean reward: 214.37
               Mean episode length: 201.62
    Episode_Reward/reaching_object: 1.4050
    Episode_Reward/rotating_object: 42.3113
        Episode_Reward/action_rate: -0.0718
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 2.05s
                      Time elapsed: 00:30:32
                               ETA: 00:26:54

################################################################################
                     [1m Learning iteration 798/1500 [0m                      

                       Computation: 47966 steps/s (collection: 1.949s, learning 0.100s)
             Mean action noise std: 3.42
          Mean value_function loss: 71.6567
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 81.6201
                       Mean reward: 236.74
               Mean episode length: 222.69
    Episode_Reward/reaching_object: 1.4640
    Episode_Reward/rotating_object: 47.1272
        Episode_Reward/action_rate: -0.0747
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 2.05s
                      Time elapsed: 00:30:34
                               ETA: 00:26:52

################################################################################
                     [1m Learning iteration 799/1500 [0m                      

                       Computation: 47568 steps/s (collection: 1.945s, learning 0.122s)
             Mean action noise std: 3.42
          Mean value_function loss: 72.4693
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 81.6668
                       Mean reward: 256.92
               Mean episode length: 223.78
    Episode_Reward/reaching_object: 1.3988
    Episode_Reward/rotating_object: 40.3981
        Episode_Reward/action_rate: -0.0737
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 2.07s
                      Time elapsed: 00:30:36
                               ETA: 00:26:49

################################################################################
                     [1m Learning iteration 800/1500 [0m                      

                       Computation: 48072 steps/s (collection: 1.919s, learning 0.126s)
             Mean action noise std: 3.43
          Mean value_function loss: 71.8351
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 81.7037
                       Mean reward: 228.16
               Mean episode length: 206.48
    Episode_Reward/reaching_object: 1.3679
    Episode_Reward/rotating_object: 42.7294
        Episode_Reward/action_rate: -0.0719
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 2.04s
                      Time elapsed: 00:30:38
                               ETA: 00:26:47

################################################################################
                     [1m Learning iteration 801/1500 [0m                      

                       Computation: 46468 steps/s (collection: 2.002s, learning 0.114s)
             Mean action noise std: 3.43
          Mean value_function loss: 74.0084
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 81.7307
                       Mean reward: 196.61
               Mean episode length: 212.34
    Episode_Reward/reaching_object: 1.3962
    Episode_Reward/rotating_object: 40.2049
        Episode_Reward/action_rate: -0.0733
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 2.12s
                      Time elapsed: 00:30:41
                               ETA: 00:26:44

################################################################################
                     [1m Learning iteration 802/1500 [0m                      

                       Computation: 47067 steps/s (collection: 1.982s, learning 0.107s)
             Mean action noise std: 3.43
          Mean value_function loss: 86.4911
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 81.7629
                       Mean reward: 261.41
               Mean episode length: 219.73
    Episode_Reward/reaching_object: 1.4247
    Episode_Reward/rotating_object: 44.9531
        Episode_Reward/action_rate: -0.0742
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 2.09s
                      Time elapsed: 00:30:43
                               ETA: 00:26:42

################################################################################
                     [1m Learning iteration 803/1500 [0m                      

                       Computation: 47691 steps/s (collection: 1.947s, learning 0.114s)
             Mean action noise std: 3.44
          Mean value_function loss: 83.7995
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 81.8087
                       Mean reward: 235.54
               Mean episode length: 216.26
    Episode_Reward/reaching_object: 1.4275
    Episode_Reward/rotating_object: 43.9515
        Episode_Reward/action_rate: -0.0750
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 2.06s
                      Time elapsed: 00:30:45
                               ETA: 00:26:39

################################################################################
                     [1m Learning iteration 804/1500 [0m                      

                       Computation: 48094 steps/s (collection: 1.938s, learning 0.106s)
             Mean action noise std: 3.44
          Mean value_function loss: 72.2971
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 81.8497
                       Mean reward: 219.45
               Mean episode length: 213.15
    Episode_Reward/reaching_object: 1.3680
    Episode_Reward/rotating_object: 41.2714
        Episode_Reward/action_rate: -0.0724
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 2.04s
                      Time elapsed: 00:30:47
                               ETA: 00:26:37

################################################################################
                     [1m Learning iteration 805/1500 [0m                      

                       Computation: 47181 steps/s (collection: 1.978s, learning 0.105s)
             Mean action noise std: 3.45
          Mean value_function loss: 71.6891
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 81.8801
                       Mean reward: 247.68
               Mean episode length: 211.51
    Episode_Reward/reaching_object: 1.4252
    Episode_Reward/rotating_object: 47.0834
        Episode_Reward/action_rate: -0.0749
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 2.08s
                      Time elapsed: 00:30:49
                               ETA: 00:26:34

################################################################################
                     [1m Learning iteration 806/1500 [0m                      

                       Computation: 47905 steps/s (collection: 1.955s, learning 0.097s)
             Mean action noise std: 3.45
          Mean value_function loss: 76.6715
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 81.9141
                       Mean reward: 239.24
               Mean episode length: 213.76
    Episode_Reward/reaching_object: 1.4142
    Episode_Reward/rotating_object: 44.6870
        Episode_Reward/action_rate: -0.0749
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 2.05s
                      Time elapsed: 00:30:51
                               ETA: 00:26:32

################################################################################
                     [1m Learning iteration 807/1500 [0m                      

                       Computation: 47430 steps/s (collection: 1.978s, learning 0.095s)
             Mean action noise std: 3.45
          Mean value_function loss: 81.5017
               Mean surrogate loss: -0.0113
                 Mean entropy loss: 81.9401
                       Mean reward: 216.83
               Mean episode length: 218.68
    Episode_Reward/reaching_object: 1.4351
    Episode_Reward/rotating_object: 43.7246
        Episode_Reward/action_rate: -0.0763
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 2.07s
                      Time elapsed: 00:30:53
                               ETA: 00:26:29

################################################################################
                     [1m Learning iteration 808/1500 [0m                      

                       Computation: 47962 steps/s (collection: 1.956s, learning 0.094s)
             Mean action noise std: 3.46
          Mean value_function loss: 79.7501
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 81.9724
                       Mean reward: 246.26
               Mean episode length: 225.86
    Episode_Reward/reaching_object: 1.4955
    Episode_Reward/rotating_object: 47.6429
        Episode_Reward/action_rate: -0.0784
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 2.05s
                      Time elapsed: 00:30:55
                               ETA: 00:26:27

################################################################################
                     [1m Learning iteration 809/1500 [0m                      

                       Computation: 47588 steps/s (collection: 1.969s, learning 0.097s)
             Mean action noise std: 3.46
          Mean value_function loss: 85.6646
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 82.0027
                       Mean reward: 181.68
               Mean episode length: 209.84
    Episode_Reward/reaching_object: 1.4512
    Episode_Reward/rotating_object: 42.3984
        Episode_Reward/action_rate: -0.0773
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 2.07s
                      Time elapsed: 00:30:57
                               ETA: 00:26:24

################################################################################
                     [1m Learning iteration 810/1500 [0m                      

                       Computation: 47780 steps/s (collection: 1.961s, learning 0.097s)
             Mean action noise std: 3.47
          Mean value_function loss: 81.5975
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 82.0333
                       Mean reward: 228.44
               Mean episode length: 214.96
    Episode_Reward/reaching_object: 1.4916
    Episode_Reward/rotating_object: 45.9690
        Episode_Reward/action_rate: -0.0787
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 2.06s
                      Time elapsed: 00:30:59
                               ETA: 00:26:22

################################################################################
                     [1m Learning iteration 811/1500 [0m                      

                       Computation: 46107 steps/s (collection: 2.032s, learning 0.101s)
             Mean action noise std: 3.47
          Mean value_function loss: 82.7071
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 82.0643
                       Mean reward: 235.05
               Mean episode length: 216.20
    Episode_Reward/reaching_object: 1.4481
    Episode_Reward/rotating_object: 45.3146
        Episode_Reward/action_rate: -0.0772
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 2.13s
                      Time elapsed: 00:31:01
                               ETA: 00:26:19

################################################################################
                     [1m Learning iteration 812/1500 [0m                      

                       Computation: 45800 steps/s (collection: 2.034s, learning 0.112s)
             Mean action noise std: 3.47
          Mean value_function loss: 88.8112
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 82.0923
                       Mean reward: 254.24
               Mean episode length: 221.21
    Episode_Reward/reaching_object: 1.4304
    Episode_Reward/rotating_object: 42.8197
        Episode_Reward/action_rate: -0.0761
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 2.15s
                      Time elapsed: 00:31:03
                               ETA: 00:26:17

################################################################################
                     [1m Learning iteration 813/1500 [0m                      

                       Computation: 47755 steps/s (collection: 1.960s, learning 0.099s)
             Mean action noise std: 3.47
          Mean value_function loss: 70.5317
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 82.1187
                       Mean reward: 200.59
               Mean episode length: 216.64
    Episode_Reward/reaching_object: 1.4053
    Episode_Reward/rotating_object: 44.2346
        Episode_Reward/action_rate: -0.0757
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 2.06s
                      Time elapsed: 00:31:05
                               ETA: 00:26:14

################################################################################
                     [1m Learning iteration 814/1500 [0m                      

                       Computation: 47256 steps/s (collection: 1.973s, learning 0.108s)
             Mean action noise std: 3.48
          Mean value_function loss: 79.2362
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 82.1525
                       Mean reward: 238.06
               Mean episode length: 214.14
    Episode_Reward/reaching_object: 1.4707
    Episode_Reward/rotating_object: 46.7026
        Episode_Reward/action_rate: -0.0775
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 2.08s
                      Time elapsed: 00:31:08
                               ETA: 00:26:12

################################################################################
                     [1m Learning iteration 815/1500 [0m                      

                       Computation: 47377 steps/s (collection: 1.951s, learning 0.124s)
             Mean action noise std: 3.48
          Mean value_function loss: 76.4890
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 82.1852
                       Mean reward: 213.80
               Mean episode length: 214.53
    Episode_Reward/reaching_object: 1.3976
    Episode_Reward/rotating_object: 43.1755
        Episode_Reward/action_rate: -0.0755
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 2.07s
                      Time elapsed: 00:31:10
                               ETA: 00:26:09

################################################################################
                     [1m Learning iteration 816/1500 [0m                      

                       Computation: 47191 steps/s (collection: 1.971s, learning 0.113s)
             Mean action noise std: 3.49
          Mean value_function loss: 68.5889
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 82.2219
                       Mean reward: 256.29
               Mean episode length: 221.22
    Episode_Reward/reaching_object: 1.4599
    Episode_Reward/rotating_object: 47.7032
        Episode_Reward/action_rate: -0.0770
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 2.08s
                      Time elapsed: 00:31:12
                               ETA: 00:26:07

################################################################################
                     [1m Learning iteration 817/1500 [0m                      

                       Computation: 47081 steps/s (collection: 1.986s, learning 0.102s)
             Mean action noise std: 3.49
          Mean value_function loss: 75.9829
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 82.2616
                       Mean reward: 208.17
               Mean episode length: 212.80
    Episode_Reward/reaching_object: 1.4361
    Episode_Reward/rotating_object: 42.4113
        Episode_Reward/action_rate: -0.0771
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 2.09s
                      Time elapsed: 00:31:14
                               ETA: 00:26:04

################################################################################
                     [1m Learning iteration 818/1500 [0m                      

                       Computation: 47415 steps/s (collection: 1.980s, learning 0.094s)
             Mean action noise std: 3.50
          Mean value_function loss: 78.7556
               Mean surrogate loss: -0.0111
                 Mean entropy loss: 82.2994
                       Mean reward: 260.24
               Mean episode length: 209.86
    Episode_Reward/reaching_object: 1.3980
    Episode_Reward/rotating_object: 44.4245
        Episode_Reward/action_rate: -0.0749
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 2.07s
                      Time elapsed: 00:31:16
                               ETA: 00:26:02

################################################################################
                     [1m Learning iteration 819/1500 [0m                      

                       Computation: 47550 steps/s (collection: 1.961s, learning 0.107s)
             Mean action noise std: 3.50
          Mean value_function loss: 73.8939
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 82.3382
                       Mean reward: 214.04
               Mean episode length: 209.73
    Episode_Reward/reaching_object: 1.3836
    Episode_Reward/rotating_object: 43.8722
        Episode_Reward/action_rate: -0.0753
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 2.07s
                      Time elapsed: 00:31:18
                               ETA: 00:25:59

################################################################################
                     [1m Learning iteration 820/1500 [0m                      

                       Computation: 46924 steps/s (collection: 1.996s, learning 0.099s)
             Mean action noise std: 3.50
          Mean value_function loss: 76.6440
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 82.3603
                       Mean reward: 241.87
               Mean episode length: 208.32
    Episode_Reward/reaching_object: 1.4149
    Episode_Reward/rotating_object: 44.4235
        Episode_Reward/action_rate: -0.0774
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 2.09s
                      Time elapsed: 00:31:20
                               ETA: 00:25:57

################################################################################
                     [1m Learning iteration 821/1500 [0m                      

                       Computation: 47665 steps/s (collection: 1.966s, learning 0.096s)
             Mean action noise std: 3.51
          Mean value_function loss: 76.1593
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 82.3889
                       Mean reward: 292.30
               Mean episode length: 230.35
    Episode_Reward/reaching_object: 1.4591
    Episode_Reward/rotating_object: 48.7153
        Episode_Reward/action_rate: -0.0784
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 2.06s
                      Time elapsed: 00:31:22
                               ETA: 00:25:55

################################################################################
                     [1m Learning iteration 822/1500 [0m                      

                       Computation: 47596 steps/s (collection: 1.959s, learning 0.106s)
             Mean action noise std: 3.51
          Mean value_function loss: 75.6958
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 82.4312
                       Mean reward: 228.31
               Mean episode length: 210.24
    Episode_Reward/reaching_object: 1.3894
    Episode_Reward/rotating_object: 44.0057
        Episode_Reward/action_rate: -0.0756
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 2.07s
                      Time elapsed: 00:31:24
                               ETA: 00:25:52

################################################################################
                     [1m Learning iteration 823/1500 [0m                      

                       Computation: 46678 steps/s (collection: 1.992s, learning 0.114s)
             Mean action noise std: 3.52
          Mean value_function loss: 78.6231
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 82.4669
                       Mean reward: 219.77
               Mean episode length: 222.10
    Episode_Reward/reaching_object: 1.4575
    Episode_Reward/rotating_object: 45.4796
        Episode_Reward/action_rate: -0.0790
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 2.11s
                      Time elapsed: 00:31:26
                               ETA: 00:25:50

################################################################################
                     [1m Learning iteration 824/1500 [0m                      

                       Computation: 46718 steps/s (collection: 1.998s, learning 0.106s)
             Mean action noise std: 3.52
          Mean value_function loss: 76.8407
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 82.4949
                       Mean reward: 267.51
               Mean episode length: 221.34
    Episode_Reward/reaching_object: 1.3984
    Episode_Reward/rotating_object: 44.7371
        Episode_Reward/action_rate: -0.0770
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 2.10s
                      Time elapsed: 00:31:28
                               ETA: 00:25:47

################################################################################
                     [1m Learning iteration 825/1500 [0m                      

                       Computation: 47173 steps/s (collection: 1.982s, learning 0.102s)
             Mean action noise std: 3.52
          Mean value_function loss: 78.5277
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 82.5185
                       Mean reward: 216.63
               Mean episode length: 205.99
    Episode_Reward/reaching_object: 1.3663
    Episode_Reward/rotating_object: 43.7528
        Episode_Reward/action_rate: -0.0763
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 2.08s
                      Time elapsed: 00:31:30
                               ETA: 00:25:45

################################################################################
                     [1m Learning iteration 826/1500 [0m                      

                       Computation: 47432 steps/s (collection: 1.962s, learning 0.110s)
             Mean action noise std: 3.53
          Mean value_function loss: 72.3060
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 82.5494
                       Mean reward: 221.91
               Mean episode length: 218.30
    Episode_Reward/reaching_object: 1.3998
    Episode_Reward/rotating_object: 44.5540
        Episode_Reward/action_rate: -0.0772
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 2.07s
                      Time elapsed: 00:31:32
                               ETA: 00:25:42

################################################################################
                     [1m Learning iteration 827/1500 [0m                      

                       Computation: 47848 steps/s (collection: 1.954s, learning 0.100s)
             Mean action noise std: 3.53
          Mean value_function loss: 82.2382
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 82.5858
                       Mean reward: 229.87
               Mean episode length: 206.97
    Episode_Reward/reaching_object: 1.4004
    Episode_Reward/rotating_object: 46.3804
        Episode_Reward/action_rate: -0.0778
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 2.05s
                      Time elapsed: 00:31:35
                               ETA: 00:25:40

################################################################################
                     [1m Learning iteration 828/1500 [0m                      

                       Computation: 44950 steps/s (collection: 2.048s, learning 0.139s)
             Mean action noise std: 3.53
          Mean value_function loss: 80.1487
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 82.6102
                       Mean reward: 230.93
               Mean episode length: 206.79
    Episode_Reward/reaching_object: 1.4184
    Episode_Reward/rotating_object: 44.1724
        Episode_Reward/action_rate: -0.0789
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 2.19s
                      Time elapsed: 00:31:37
                               ETA: 00:25:37

################################################################################
                     [1m Learning iteration 829/1500 [0m                      

                       Computation: 47977 steps/s (collection: 1.934s, learning 0.115s)
             Mean action noise std: 3.54
          Mean value_function loss: 79.5994
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 82.6352
                       Mean reward: 214.84
               Mean episode length: 208.40
    Episode_Reward/reaching_object: 1.4447
    Episode_Reward/rotating_object: 43.1541
        Episode_Reward/action_rate: -0.0800
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 2.05s
                      Time elapsed: 00:31:39
                               ETA: 00:25:35

################################################################################
                     [1m Learning iteration 830/1500 [0m                      

                       Computation: 46455 steps/s (collection: 1.995s, learning 0.121s)
             Mean action noise std: 3.54
          Mean value_function loss: 87.1220
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 82.6647
                       Mean reward: 239.32
               Mean episode length: 211.21
    Episode_Reward/reaching_object: 1.3576
    Episode_Reward/rotating_object: 42.7193
        Episode_Reward/action_rate: -0.0764
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 2.12s
                      Time elapsed: 00:31:41
                               ETA: 00:25:33

################################################################################
                     [1m Learning iteration 831/1500 [0m                      

                       Computation: 46270 steps/s (collection: 2.008s, learning 0.117s)
             Mean action noise std: 3.54
          Mean value_function loss: 76.2842
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 82.7053
                       Mean reward: 215.14
               Mean episode length: 208.99
    Episode_Reward/reaching_object: 1.4190
    Episode_Reward/rotating_object: 47.2351
        Episode_Reward/action_rate: -0.0782
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 2.12s
                      Time elapsed: 00:31:43
                               ETA: 00:25:30

################################################################################
                     [1m Learning iteration 832/1500 [0m                      

                       Computation: 46972 steps/s (collection: 1.978s, learning 0.115s)
             Mean action noise std: 3.55
          Mean value_function loss: 74.1375
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 82.7328
                       Mean reward: 251.44
               Mean episode length: 218.01
    Episode_Reward/reaching_object: 1.4438
    Episode_Reward/rotating_object: 45.3081
        Episode_Reward/action_rate: -0.0801
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 2.09s
                      Time elapsed: 00:31:45
                               ETA: 00:25:28

################################################################################
                     [1m Learning iteration 833/1500 [0m                      

                       Computation: 46952 steps/s (collection: 1.981s, learning 0.113s)
             Mean action noise std: 3.55
          Mean value_function loss: 76.2275
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 82.7642
                       Mean reward: 249.04
               Mean episode length: 215.85
    Episode_Reward/reaching_object: 1.4589
    Episode_Reward/rotating_object: 46.9015
        Episode_Reward/action_rate: -0.0807
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 2.09s
                      Time elapsed: 00:31:47
                               ETA: 00:25:25

################################################################################
                     [1m Learning iteration 834/1500 [0m                      

                       Computation: 46045 steps/s (collection: 2.009s, learning 0.126s)
             Mean action noise std: 3.56
          Mean value_function loss: 76.1250
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 82.7950
                       Mean reward: 227.00
               Mean episode length: 210.94
    Episode_Reward/reaching_object: 1.4306
    Episode_Reward/rotating_object: 42.7681
        Episode_Reward/action_rate: -0.0794
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 2.13s
                      Time elapsed: 00:31:49
                               ETA: 00:25:23

################################################################################
                     [1m Learning iteration 835/1500 [0m                      

                       Computation: 44574 steps/s (collection: 2.103s, learning 0.103s)
             Mean action noise std: 3.56
          Mean value_function loss: 79.5075
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 82.8254
                       Mean reward: 205.45
               Mean episode length: 204.83
    Episode_Reward/reaching_object: 1.4600
    Episode_Reward/rotating_object: 46.6116
        Episode_Reward/action_rate: -0.0802
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 2.21s
                      Time elapsed: 00:31:52
                               ETA: 00:25:20

################################################################################
                     [1m Learning iteration 836/1500 [0m                      

                       Computation: 46779 steps/s (collection: 2.006s, learning 0.095s)
             Mean action noise std: 3.56
          Mean value_function loss: 80.0845
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 82.8605
                       Mean reward: 210.70
               Mean episode length: 220.90
    Episode_Reward/reaching_object: 1.4276
    Episode_Reward/rotating_object: 43.4076
        Episode_Reward/action_rate: -0.0803
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 2.10s
                      Time elapsed: 00:31:54
                               ETA: 00:25:18

################################################################################
                     [1m Learning iteration 837/1500 [0m                      

                       Computation: 46181 steps/s (collection: 2.032s, learning 0.097s)
             Mean action noise std: 3.57
          Mean value_function loss: 82.3476
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 82.8979
                       Mean reward: 206.95
               Mean episode length: 211.28
    Episode_Reward/reaching_object: 1.4604
    Episode_Reward/rotating_object: 44.4517
        Episode_Reward/action_rate: -0.0808
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 2.13s
                      Time elapsed: 00:31:56
                               ETA: 00:25:16

################################################################################
                     [1m Learning iteration 838/1500 [0m                      

                       Computation: 46152 steps/s (collection: 2.029s, learning 0.101s)
             Mean action noise std: 3.57
          Mean value_function loss: 81.3915
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 82.9267
                       Mean reward: 242.72
               Mean episode length: 221.67
    Episode_Reward/reaching_object: 1.4770
    Episode_Reward/rotating_object: 49.4162
        Episode_Reward/action_rate: -0.0818
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 2.13s
                      Time elapsed: 00:31:58
                               ETA: 00:25:13

################################################################################
                     [1m Learning iteration 839/1500 [0m                      

                       Computation: 45729 steps/s (collection: 2.048s, learning 0.102s)
             Mean action noise std: 3.57
          Mean value_function loss: 66.0636
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 82.9548
                       Mean reward: 204.38
               Mean episode length: 208.61
    Episode_Reward/reaching_object: 1.4399
    Episode_Reward/rotating_object: 44.2318
        Episode_Reward/action_rate: -0.0802
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 2.15s
                      Time elapsed: 00:32:00
                               ETA: 00:25:11

################################################################################
                     [1m Learning iteration 840/1500 [0m                      

                       Computation: 45814 steps/s (collection: 2.045s, learning 0.101s)
             Mean action noise std: 3.58
          Mean value_function loss: 71.6733
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 82.9890
                       Mean reward: 199.21
               Mean episode length: 208.27
    Episode_Reward/reaching_object: 1.3950
    Episode_Reward/rotating_object: 43.9684
        Episode_Reward/action_rate: -0.0791
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 2.15s
                      Time elapsed: 00:32:02
                               ETA: 00:25:08

################################################################################
                     [1m Learning iteration 841/1500 [0m                      

                       Computation: 43849 steps/s (collection: 2.128s, learning 0.114s)
             Mean action noise std: 3.58
          Mean value_function loss: 71.7452
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 83.0292
                       Mean reward: 220.15
               Mean episode length: 209.89
    Episode_Reward/reaching_object: 1.4477
    Episode_Reward/rotating_object: 45.9675
        Episode_Reward/action_rate: -0.0808
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 2.24s
                      Time elapsed: 00:32:04
                               ETA: 00:25:06

################################################################################
                     [1m Learning iteration 842/1500 [0m                      

                       Computation: 46383 steps/s (collection: 2.012s, learning 0.107s)
             Mean action noise std: 3.59
          Mean value_function loss: 75.2504
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 83.0656
                       Mean reward: 228.59
               Mean episode length: 218.32
    Episode_Reward/reaching_object: 1.4646
    Episode_Reward/rotating_object: 48.9782
        Episode_Reward/action_rate: -0.0815
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 2.12s
                      Time elapsed: 00:32:07
                               ETA: 00:25:04

################################################################################
                     [1m Learning iteration 843/1500 [0m                      

                       Computation: 47233 steps/s (collection: 1.970s, learning 0.111s)
             Mean action noise std: 3.59
          Mean value_function loss: 78.0803
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 83.0944
                       Mean reward: 233.67
               Mean episode length: 215.51
    Episode_Reward/reaching_object: 1.4376
    Episode_Reward/rotating_object: 44.5771
        Episode_Reward/action_rate: -0.0813
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 2.08s
                      Time elapsed: 00:32:09
                               ETA: 00:25:01

################################################################################
                     [1m Learning iteration 844/1500 [0m                      

                       Computation: 46724 steps/s (collection: 2.003s, learning 0.101s)
             Mean action noise std: 3.60
          Mean value_function loss: 84.3010
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 83.1317
                       Mean reward: 235.74
               Mean episode length: 211.84
    Episode_Reward/reaching_object: 1.4602
    Episode_Reward/rotating_object: 44.6795
        Episode_Reward/action_rate: -0.0824
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 2.10s
                      Time elapsed: 00:32:11
                               ETA: 00:24:59

################################################################################
                     [1m Learning iteration 845/1500 [0m                      

                       Computation: 45980 steps/s (collection: 2.036s, learning 0.102s)
             Mean action noise std: 3.60
          Mean value_function loss: 79.3778
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 83.1661
                       Mean reward: 236.49
               Mean episode length: 211.36
    Episode_Reward/reaching_object: 1.4247
    Episode_Reward/rotating_object: 48.4096
        Episode_Reward/action_rate: -0.0817
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 2.14s
                      Time elapsed: 00:32:13
                               ETA: 00:24:56

################################################################################
                     [1m Learning iteration 846/1500 [0m                      

                       Computation: 45113 steps/s (collection: 2.060s, learning 0.119s)
             Mean action noise std: 3.60
          Mean value_function loss: 70.2792
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 83.1906
                       Mean reward: 212.85
               Mean episode length: 205.89
    Episode_Reward/reaching_object: 1.4369
    Episode_Reward/rotating_object: 45.8722
        Episode_Reward/action_rate: -0.0816
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 2.18s
                      Time elapsed: 00:32:15
                               ETA: 00:24:54

################################################################################
                     [1m Learning iteration 847/1500 [0m                      

                       Computation: 44527 steps/s (collection: 2.088s, learning 0.120s)
             Mean action noise std: 3.61
          Mean value_function loss: 76.9454
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 83.2191
                       Mean reward: 247.09
               Mean episode length: 218.79
    Episode_Reward/reaching_object: 1.4667
    Episode_Reward/rotating_object: 51.3788
        Episode_Reward/action_rate: -0.0824
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 2.21s
                      Time elapsed: 00:32:17
                               ETA: 00:24:52

################################################################################
                     [1m Learning iteration 848/1500 [0m                      

                       Computation: 46455 steps/s (collection: 2.005s, learning 0.111s)
             Mean action noise std: 3.61
          Mean value_function loss: 76.4531
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 83.2561
                       Mean reward: 238.08
               Mean episode length: 207.75
    Episode_Reward/reaching_object: 1.4392
    Episode_Reward/rotating_object: 46.7417
        Episode_Reward/action_rate: -0.0820
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 2.12s
                      Time elapsed: 00:32:19
                               ETA: 00:24:49

################################################################################
                     [1m Learning iteration 849/1500 [0m                      

                       Computation: 47466 steps/s (collection: 1.962s, learning 0.109s)
             Mean action noise std: 3.61
          Mean value_function loss: 72.0052
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 83.2806
                       Mean reward: 213.89
               Mean episode length: 212.21
    Episode_Reward/reaching_object: 1.4495
    Episode_Reward/rotating_object: 45.6971
        Episode_Reward/action_rate: -0.0824
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 2.07s
                      Time elapsed: 00:32:21
                               ETA: 00:24:47

################################################################################
                     [1m Learning iteration 850/1500 [0m                      

                       Computation: 46427 steps/s (collection: 1.995s, learning 0.122s)
             Mean action noise std: 3.62
          Mean value_function loss: 71.8145
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 83.2979
                       Mean reward: 240.22
               Mean episode length: 210.37
    Episode_Reward/reaching_object: 1.4171
    Episode_Reward/rotating_object: 45.1472
        Episode_Reward/action_rate: -0.0821
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 2.12s
                      Time elapsed: 00:32:24
                               ETA: 00:24:44

################################################################################
                     [1m Learning iteration 851/1500 [0m                      

                       Computation: 45949 steps/s (collection: 2.035s, learning 0.105s)
             Mean action noise std: 3.62
          Mean value_function loss: 87.4023
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 83.3230
                       Mean reward: 273.72
               Mean episode length: 224.49
    Episode_Reward/reaching_object: 1.4423
    Episode_Reward/rotating_object: 45.7229
        Episode_Reward/action_rate: -0.0834
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 2.14s
                      Time elapsed: 00:32:26
                               ETA: 00:24:42

################################################################################
                     [1m Learning iteration 852/1500 [0m                      

                       Computation: 46624 steps/s (collection: 2.004s, learning 0.105s)
             Mean action noise std: 3.62
          Mean value_function loss: 84.5492
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 83.3484
                       Mean reward: 235.54
               Mean episode length: 218.93
    Episode_Reward/reaching_object: 1.4766
    Episode_Reward/rotating_object: 47.4077
        Episode_Reward/action_rate: -0.0850
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 2.11s
                      Time elapsed: 00:32:28
                               ETA: 00:24:40

################################################################################
                     [1m Learning iteration 853/1500 [0m                      

                       Computation: 46448 steps/s (collection: 2.019s, learning 0.097s)
             Mean action noise std: 3.63
          Mean value_function loss: 72.9272
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 83.3776
                       Mean reward: 235.94
               Mean episode length: 221.02
    Episode_Reward/reaching_object: 1.4339
    Episode_Reward/rotating_object: 46.6550
        Episode_Reward/action_rate: -0.0828
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 2.12s
                      Time elapsed: 00:32:30
                               ETA: 00:24:37

################################################################################
                     [1m Learning iteration 854/1500 [0m                      

                       Computation: 46174 steps/s (collection: 2.022s, learning 0.107s)
             Mean action noise std: 3.63
          Mean value_function loss: 75.8783
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 83.4166
                       Mean reward: 262.43
               Mean episode length: 206.26
    Episode_Reward/reaching_object: 1.4246
    Episode_Reward/rotating_object: 47.8499
        Episode_Reward/action_rate: -0.0822
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 2.13s
                      Time elapsed: 00:32:32
                               ETA: 00:24:35

################################################################################
                     [1m Learning iteration 855/1500 [0m                      

                       Computation: 47349 steps/s (collection: 1.970s, learning 0.107s)
             Mean action noise std: 3.63
          Mean value_function loss: 85.4451
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 83.4445
                       Mean reward: 240.96
               Mean episode length: 223.37
    Episode_Reward/reaching_object: 1.4474
    Episode_Reward/rotating_object: 48.5392
        Episode_Reward/action_rate: -0.0844
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 2.08s
                      Time elapsed: 00:32:34
                               ETA: 00:24:32

################################################################################
                     [1m Learning iteration 856/1500 [0m                      

                       Computation: 45370 steps/s (collection: 2.059s, learning 0.108s)
             Mean action noise std: 3.64
          Mean value_function loss: 84.8374
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 83.4673
                       Mean reward: 235.42
               Mean episode length: 204.18
    Episode_Reward/reaching_object: 1.4024
    Episode_Reward/rotating_object: 44.7975
        Episode_Reward/action_rate: -0.0805
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 2.17s
                      Time elapsed: 00:32:36
                               ETA: 00:24:30

################################################################################
                     [1m Learning iteration 857/1500 [0m                      

                       Computation: 43534 steps/s (collection: 2.126s, learning 0.133s)
             Mean action noise std: 3.65
          Mean value_function loss: 78.1376
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 83.5130
                       Mean reward: 261.12
               Mean episode length: 219.04
    Episode_Reward/reaching_object: 1.4254
    Episode_Reward/rotating_object: 48.1367
        Episode_Reward/action_rate: -0.0826
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 2.26s
                      Time elapsed: 00:32:39
                               ETA: 00:24:28

################################################################################
                     [1m Learning iteration 858/1500 [0m                      

                       Computation: 46958 steps/s (collection: 1.982s, learning 0.111s)
             Mean action noise std: 3.65
          Mean value_function loss: 87.5489
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 83.5594
                       Mean reward: 256.21
               Mean episode length: 211.26
    Episode_Reward/reaching_object: 1.4166
    Episode_Reward/rotating_object: 46.3645
        Episode_Reward/action_rate: -0.0824
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 2.09s
                      Time elapsed: 00:32:41
                               ETA: 00:24:25

################################################################################
                     [1m Learning iteration 859/1500 [0m                      

                       Computation: 46558 steps/s (collection: 1.981s, learning 0.131s)
             Mean action noise std: 3.66
          Mean value_function loss: 79.9461
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 83.5991
                       Mean reward: 289.23
               Mean episode length: 222.73
    Episode_Reward/reaching_object: 1.4722
    Episode_Reward/rotating_object: 53.4686
        Episode_Reward/action_rate: -0.0849
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 2.11s
                      Time elapsed: 00:32:43
                               ETA: 00:24:23

################################################################################
                     [1m Learning iteration 860/1500 [0m                      

                       Computation: 46687 steps/s (collection: 2.006s, learning 0.100s)
             Mean action noise std: 3.66
          Mean value_function loss: 76.6924
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 83.6457
                       Mean reward: 260.67
               Mean episode length: 214.39
    Episode_Reward/reaching_object: 1.4787
    Episode_Reward/rotating_object: 48.9188
        Episode_Reward/action_rate: -0.0856
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 2.11s
                      Time elapsed: 00:32:45
                               ETA: 00:24:20

################################################################################
                     [1m Learning iteration 861/1500 [0m                      

                       Computation: 46821 steps/s (collection: 1.991s, learning 0.108s)
             Mean action noise std: 3.66
          Mean value_function loss: 80.8538
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 83.6766
                       Mean reward: 273.08
               Mean episode length: 226.19
    Episode_Reward/reaching_object: 1.4743
    Episode_Reward/rotating_object: 47.9349
        Episode_Reward/action_rate: -0.0863
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 2.10s
                      Time elapsed: 00:32:47
                               ETA: 00:24:18

################################################################################
                     [1m Learning iteration 862/1500 [0m                      

                       Computation: 46712 steps/s (collection: 2.005s, learning 0.100s)
             Mean action noise std: 3.67
          Mean value_function loss: 75.8457
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 83.7047
                       Mean reward: 230.72
               Mean episode length: 220.45
    Episode_Reward/reaching_object: 1.4522
    Episode_Reward/rotating_object: 47.9898
        Episode_Reward/action_rate: -0.0855
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 2.10s
                      Time elapsed: 00:32:49
                               ETA: 00:24:16

################################################################################
                     [1m Learning iteration 863/1500 [0m                      

                       Computation: 46187 steps/s (collection: 2.024s, learning 0.104s)
             Mean action noise std: 3.67
          Mean value_function loss: 73.6635
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 83.7310
                       Mean reward: 297.51
               Mean episode length: 216.28
    Episode_Reward/reaching_object: 1.4563
    Episode_Reward/rotating_object: 49.9579
        Episode_Reward/action_rate: -0.0857
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 2.13s
                      Time elapsed: 00:32:51
                               ETA: 00:24:13

################################################################################
                     [1m Learning iteration 864/1500 [0m                      

                       Computation: 44930 steps/s (collection: 2.082s, learning 0.106s)
             Mean action noise std: 3.67
          Mean value_function loss: 77.2139
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 83.7605
                       Mean reward: 227.89
               Mean episode length: 211.85
    Episode_Reward/reaching_object: 1.3547
    Episode_Reward/rotating_object: 43.8593
        Episode_Reward/action_rate: -0.0799
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 2.19s
                      Time elapsed: 00:32:53
                               ETA: 00:24:11

################################################################################
                     [1m Learning iteration 865/1500 [0m                      

                       Computation: 45299 steps/s (collection: 2.064s, learning 0.106s)
             Mean action noise std: 3.68
          Mean value_function loss: 83.4913
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 83.7950
                       Mean reward: 225.35
               Mean episode length: 199.03
    Episode_Reward/reaching_object: 1.4029
    Episode_Reward/rotating_object: 50.7987
        Episode_Reward/action_rate: -0.0836
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 2.17s
                      Time elapsed: 00:32:56
                               ETA: 00:24:08

################################################################################
                     [1m Learning iteration 866/1500 [0m                      

                       Computation: 46396 steps/s (collection: 2.006s, learning 0.113s)
             Mean action noise std: 3.68
          Mean value_function loss: 95.8935
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 83.8314
                       Mean reward: 301.87
               Mean episode length: 232.42
    Episode_Reward/reaching_object: 1.4424
    Episode_Reward/rotating_object: 48.8623
        Episode_Reward/action_rate: -0.0865
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 2.12s
                      Time elapsed: 00:32:58
                               ETA: 00:24:06

################################################################################
                     [1m Learning iteration 867/1500 [0m                      

                       Computation: 46358 steps/s (collection: 2.015s, learning 0.105s)
             Mean action noise std: 3.69
          Mean value_function loss: 76.3100
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 83.8642
                       Mean reward: 294.49
               Mean episode length: 223.35
    Episode_Reward/reaching_object: 1.4334
    Episode_Reward/rotating_object: 46.4267
        Episode_Reward/action_rate: -0.0855
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 2.12s
                      Time elapsed: 00:33:00
                               ETA: 00:24:04

################################################################################
                     [1m Learning iteration 868/1500 [0m                      

                       Computation: 42844 steps/s (collection: 2.180s, learning 0.115s)
             Mean action noise std: 3.69
          Mean value_function loss: 78.8500
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 83.8836
                       Mean reward: 267.06
               Mean episode length: 218.68
    Episode_Reward/reaching_object: 1.3877
    Episode_Reward/rotating_object: 47.7416
        Episode_Reward/action_rate: -0.0829
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 2.29s
                      Time elapsed: 00:33:02
                               ETA: 00:24:01

################################################################################
                     [1m Learning iteration 869/1500 [0m                      

                       Computation: 44842 steps/s (collection: 2.071s, learning 0.122s)
             Mean action noise std: 3.69
          Mean value_function loss: 78.2899
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 83.9036
                       Mean reward: 230.99
               Mean episode length: 200.62
    Episode_Reward/reaching_object: 1.4252
    Episode_Reward/rotating_object: 50.5240
        Episode_Reward/action_rate: -0.0852
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 2.19s
                      Time elapsed: 00:33:04
                               ETA: 00:23:59

################################################################################
                     [1m Learning iteration 870/1500 [0m                      

                       Computation: 45401 steps/s (collection: 2.065s, learning 0.101s)
             Mean action noise std: 3.69
          Mean value_function loss: 83.4268
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 83.9326
                       Mean reward: 268.03
               Mean episode length: 219.65
    Episode_Reward/reaching_object: 1.4396
    Episode_Reward/rotating_object: 50.7753
        Episode_Reward/action_rate: -0.0859
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 2.17s
                      Time elapsed: 00:33:06
                               ETA: 00:23:57

################################################################################
                     [1m Learning iteration 871/1500 [0m                      

                       Computation: 46601 steps/s (collection: 1.984s, learning 0.126s)
             Mean action noise std: 3.70
          Mean value_function loss: 84.8639
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 83.9562
                       Mean reward: 284.67
               Mean episode length: 215.36
    Episode_Reward/reaching_object: 1.4453
    Episode_Reward/rotating_object: 50.1011
        Episode_Reward/action_rate: -0.0866
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 2.11s
                      Time elapsed: 00:33:09
                               ETA: 00:23:54

################################################################################
                     [1m Learning iteration 872/1500 [0m                      

                       Computation: 45839 steps/s (collection: 2.009s, learning 0.135s)
             Mean action noise std: 3.70
          Mean value_function loss: 79.7519
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 83.9893
                       Mean reward: 217.29
               Mean episode length: 204.22
    Episode_Reward/reaching_object: 1.3876
    Episode_Reward/rotating_object: 44.5332
        Episode_Reward/action_rate: -0.0846
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 2.14s
                      Time elapsed: 00:33:11
                               ETA: 00:23:52

################################################################################
                     [1m Learning iteration 873/1500 [0m                      

                       Computation: 46651 steps/s (collection: 1.989s, learning 0.118s)
             Mean action noise std: 3.71
          Mean value_function loss: 77.8761
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 84.0216
                       Mean reward: 233.30
               Mean episode length: 215.98
    Episode_Reward/reaching_object: 1.3959
    Episode_Reward/rotating_object: 46.0624
        Episode_Reward/action_rate: -0.0854
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 2.11s
                      Time elapsed: 00:33:13
                               ETA: 00:23:49

################################################################################
                     [1m Learning iteration 874/1500 [0m                      

                       Computation: 43071 steps/s (collection: 2.161s, learning 0.121s)
             Mean action noise std: 3.71
          Mean value_function loss: 77.1757
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 84.0548
                       Mean reward: 219.91
               Mean episode length: 197.32
    Episode_Reward/reaching_object: 1.4007
    Episode_Reward/rotating_object: 46.1523
        Episode_Reward/action_rate: -0.0847
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 2.28s
                      Time elapsed: 00:33:15
                               ETA: 00:23:47

################################################################################
                     [1m Learning iteration 875/1500 [0m                      

                       Computation: 44538 steps/s (collection: 2.101s, learning 0.107s)
             Mean action noise std: 3.71
          Mean value_function loss: 88.8820
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 84.0796
                       Mean reward: 249.90
               Mean episode length: 215.66
    Episode_Reward/reaching_object: 1.4113
    Episode_Reward/rotating_object: 47.5684
        Episode_Reward/action_rate: -0.0864
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 2.21s
                      Time elapsed: 00:33:17
                               ETA: 00:23:45

################################################################################
                     [1m Learning iteration 876/1500 [0m                      

                       Computation: 45666 steps/s (collection: 2.040s, learning 0.113s)
             Mean action noise std: 3.72
          Mean value_function loss: 88.6627
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 84.1084
                       Mean reward: 218.64
               Mean episode length: 207.77
    Episode_Reward/reaching_object: 1.4032
    Episode_Reward/rotating_object: 49.3544
        Episode_Reward/action_rate: -0.0859
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 2.15s
                      Time elapsed: 00:33:19
                               ETA: 00:23:43

################################################################################
                     [1m Learning iteration 877/1500 [0m                      

                       Computation: 43256 steps/s (collection: 2.177s, learning 0.096s)
             Mean action noise std: 3.72
          Mean value_function loss: 81.2225
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 84.1492
                       Mean reward: 194.13
               Mean episode length: 192.76
    Episode_Reward/reaching_object: 1.3752
    Episode_Reward/rotating_object: 45.2000
        Episode_Reward/action_rate: -0.0848
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 2.27s
                      Time elapsed: 00:33:22
                               ETA: 00:23:40

################################################################################
                     [1m Learning iteration 878/1500 [0m                      

                       Computation: 46818 steps/s (collection: 1.990s, learning 0.110s)
             Mean action noise std: 3.73
          Mean value_function loss: 79.8753
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 84.1789
                       Mean reward: 237.91
               Mean episode length: 215.93
    Episode_Reward/reaching_object: 1.3906
    Episode_Reward/rotating_object: 46.7069
        Episode_Reward/action_rate: -0.0857
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 2.10s
                      Time elapsed: 00:33:24
                               ETA: 00:23:38

################################################################################
                     [1m Learning iteration 879/1500 [0m                      

                       Computation: 44163 steps/s (collection: 2.097s, learning 0.129s)
             Mean action noise std: 3.73
          Mean value_function loss: 76.2586
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 84.2185
                       Mean reward: 290.75
               Mean episode length: 209.06
    Episode_Reward/reaching_object: 1.4318
    Episode_Reward/rotating_object: 48.8943
        Episode_Reward/action_rate: -0.0876
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 2.23s
                      Time elapsed: 00:33:26
                               ETA: 00:23:35

################################################################################
                     [1m Learning iteration 880/1500 [0m                      

                       Computation: 46046 steps/s (collection: 2.019s, learning 0.116s)
             Mean action noise std: 3.74
          Mean value_function loss: 81.3430
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 84.2557
                       Mean reward: 219.18
               Mean episode length: 203.55
    Episode_Reward/reaching_object: 1.4037
    Episode_Reward/rotating_object: 46.3606
        Episode_Reward/action_rate: -0.0873
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 2.13s
                      Time elapsed: 00:33:28
                               ETA: 00:23:33

################################################################################
                     [1m Learning iteration 881/1500 [0m                      

                       Computation: 41160 steps/s (collection: 2.263s, learning 0.126s)
             Mean action noise std: 3.74
          Mean value_function loss: 76.1543
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 84.2891
                       Mean reward: 259.32
               Mean episode length: 206.02
    Episode_Reward/reaching_object: 1.4118
    Episode_Reward/rotating_object: 49.1617
        Episode_Reward/action_rate: -0.0871
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 2.39s
                      Time elapsed: 00:33:31
                               ETA: 00:23:31

################################################################################
                     [1m Learning iteration 882/1500 [0m                      

                       Computation: 45807 steps/s (collection: 2.031s, learning 0.115s)
             Mean action noise std: 3.75
          Mean value_function loss: 76.4902
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 84.3233
                       Mean reward: 264.30
               Mean episode length: 219.20
    Episode_Reward/reaching_object: 1.4353
    Episode_Reward/rotating_object: 49.6939
        Episode_Reward/action_rate: -0.0892
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 2.15s
                      Time elapsed: 00:33:33
                               ETA: 00:23:29

################################################################################
                     [1m Learning iteration 883/1500 [0m                      

                       Computation: 46679 steps/s (collection: 1.997s, learning 0.109s)
             Mean action noise std: 3.75
          Mean value_function loss: 76.0964
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 84.3622
                       Mean reward: 224.68
               Mean episode length: 207.15
    Episode_Reward/reaching_object: 1.4456
    Episode_Reward/rotating_object: 47.9933
        Episode_Reward/action_rate: -0.0898
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 2.11s
                      Time elapsed: 00:33:35
                               ETA: 00:23:26

################################################################################
                     [1m Learning iteration 884/1500 [0m                      

                       Computation: 47129 steps/s (collection: 1.959s, learning 0.127s)
             Mean action noise std: 3.75
          Mean value_function loss: 78.7160
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 84.4006
                       Mean reward: 257.29
               Mean episode length: 212.11
    Episode_Reward/reaching_object: 1.4712
    Episode_Reward/rotating_object: 50.3437
        Episode_Reward/action_rate: -0.0914
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 2.09s
                      Time elapsed: 00:33:37
                               ETA: 00:23:24

################################################################################
                     [1m Learning iteration 885/1500 [0m                      

                       Computation: 46713 steps/s (collection: 1.968s, learning 0.137s)
             Mean action noise std: 3.76
          Mean value_function loss: 77.5425
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 84.4404
                       Mean reward: 276.98
               Mean episode length: 232.16
    Episode_Reward/reaching_object: 1.3938
    Episode_Reward/rotating_object: 46.9515
        Episode_Reward/action_rate: -0.0887
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 2.10s
                      Time elapsed: 00:33:39
                               ETA: 00:23:21

################################################################################
                     [1m Learning iteration 886/1500 [0m                      

                       Computation: 44368 steps/s (collection: 2.094s, learning 0.122s)
             Mean action noise std: 3.76
          Mean value_function loss: 78.7160
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 84.4862
                       Mean reward: 237.40
               Mean episode length: 210.62
    Episode_Reward/reaching_object: 1.4221
    Episode_Reward/rotating_object: 49.3356
        Episode_Reward/action_rate: -0.0898
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 2.22s
                      Time elapsed: 00:33:41
                               ETA: 00:23:19

################################################################################
                     [1m Learning iteration 887/1500 [0m                      

                       Computation: 46637 steps/s (collection: 2.006s, learning 0.102s)
             Mean action noise std: 3.77
          Mean value_function loss: 85.6538
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 84.5314
                       Mean reward: 259.04
               Mean episode length: 219.10
    Episode_Reward/reaching_object: 1.4034
    Episode_Reward/rotating_object: 48.4983
        Episode_Reward/action_rate: -0.0897
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 2.11s
                      Time elapsed: 00:33:43
                               ETA: 00:23:17

################################################################################
                     [1m Learning iteration 888/1500 [0m                      

                       Computation: 47129 steps/s (collection: 1.988s, learning 0.098s)
             Mean action noise std: 3.78
          Mean value_function loss: 90.3320
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 84.5800
                       Mean reward: 258.14
               Mean episode length: 201.50
    Episode_Reward/reaching_object: 1.4174
    Episode_Reward/rotating_object: 49.4513
        Episode_Reward/action_rate: -0.0887
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 2.09s
                      Time elapsed: 00:33:45
                               ETA: 00:23:14

################################################################################
                     [1m Learning iteration 889/1500 [0m                      

                       Computation: 45472 steps/s (collection: 2.057s, learning 0.105s)
             Mean action noise std: 3.78
          Mean value_function loss: 86.8138
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 84.6242
                       Mean reward: 240.60
               Mean episode length: 209.06
    Episode_Reward/reaching_object: 1.3836
    Episode_Reward/rotating_object: 47.6748
        Episode_Reward/action_rate: -0.0884
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 2.16s
                      Time elapsed: 00:33:48
                               ETA: 00:23:12

################################################################################
                     [1m Learning iteration 890/1500 [0m                      

                       Computation: 45992 steps/s (collection: 2.034s, learning 0.103s)
             Mean action noise std: 3.79
          Mean value_function loss: 78.1178
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 84.6540
                       Mean reward: 271.30
               Mean episode length: 215.41
    Episode_Reward/reaching_object: 1.4298
    Episode_Reward/rotating_object: 49.8833
        Episode_Reward/action_rate: -0.0914
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 2.14s
                      Time elapsed: 00:33:50
                               ETA: 00:23:09

################################################################################
                     [1m Learning iteration 891/1500 [0m                      

                       Computation: 46115 steps/s (collection: 2.021s, learning 0.111s)
             Mean action noise std: 3.79
          Mean value_function loss: 84.5442
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 84.6889
                       Mean reward: 256.91
               Mean episode length: 204.14
    Episode_Reward/reaching_object: 1.3732
    Episode_Reward/rotating_object: 47.9927
        Episode_Reward/action_rate: -0.0884
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 2.13s
                      Time elapsed: 00:33:52
                               ETA: 00:23:07

################################################################################
                     [1m Learning iteration 892/1500 [0m                      

                       Computation: 46121 steps/s (collection: 2.024s, learning 0.107s)
             Mean action noise std: 3.79
          Mean value_function loss: 80.3211
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 84.7167
                       Mean reward: 245.32
               Mean episode length: 207.41
    Episode_Reward/reaching_object: 1.4203
    Episode_Reward/rotating_object: 47.5145
        Episode_Reward/action_rate: -0.0899
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 2.13s
                      Time elapsed: 00:33:54
                               ETA: 00:23:05

################################################################################
                     [1m Learning iteration 893/1500 [0m                      

                       Computation: 46120 steps/s (collection: 2.018s, learning 0.113s)
             Mean action noise std: 3.80
          Mean value_function loss: 84.0292
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 84.7360
                       Mean reward: 257.13
               Mean episode length: 205.48
    Episode_Reward/reaching_object: 1.4002
    Episode_Reward/rotating_object: 47.8202
        Episode_Reward/action_rate: -0.0887
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 2.13s
                      Time elapsed: 00:33:56
                               ETA: 00:23:02

################################################################################
                     [1m Learning iteration 894/1500 [0m                      

                       Computation: 45664 steps/s (collection: 2.047s, learning 0.106s)
             Mean action noise std: 3.80
          Mean value_function loss: 91.4625
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 84.7656
                       Mean reward: 240.24
               Mean episode length: 203.10
    Episode_Reward/reaching_object: 1.3545
    Episode_Reward/rotating_object: 45.0492
        Episode_Reward/action_rate: -0.0866
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 2.15s
                      Time elapsed: 00:33:58
                               ETA: 00:23:00

################################################################################
                     [1m Learning iteration 895/1500 [0m                      

                       Computation: 46873 steps/s (collection: 1.989s, learning 0.108s)
             Mean action noise std: 3.80
          Mean value_function loss: 80.5887
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 84.8021
                       Mean reward: 293.42
               Mean episode length: 216.22
    Episode_Reward/reaching_object: 1.4430
    Episode_Reward/rotating_object: 51.1670
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 2.10s
                      Time elapsed: 00:34:00
                               ETA: 00:22:58

################################################################################
                     [1m Learning iteration 896/1500 [0m                      

                       Computation: 46559 steps/s (collection: 2.003s, learning 0.108s)
             Mean action noise std: 3.81
          Mean value_function loss: 80.4953
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 84.8323
                       Mean reward: 241.08
               Mean episode length: 207.51
    Episode_Reward/reaching_object: 1.4243
    Episode_Reward/rotating_object: 48.3231
        Episode_Reward/action_rate: -0.0909
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 2.11s
                      Time elapsed: 00:34:02
                               ETA: 00:22:55

################################################################################
                     [1m Learning iteration 897/1500 [0m                      

                       Computation: 46232 steps/s (collection: 2.016s, learning 0.110s)
             Mean action noise std: 3.81
          Mean value_function loss: 91.0057
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 84.8535
                       Mean reward: 258.30
               Mean episode length: 220.30
    Episode_Reward/reaching_object: 1.3909
    Episode_Reward/rotating_object: 49.1152
        Episode_Reward/action_rate: -0.0907
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 2.13s
                      Time elapsed: 00:34:05
                               ETA: 00:22:53

################################################################################
                     [1m Learning iteration 898/1500 [0m                      

                       Computation: 46518 steps/s (collection: 2.006s, learning 0.108s)
             Mean action noise std: 3.82
          Mean value_function loss: 83.7375
               Mean surrogate loss: -0.0111
                 Mean entropy loss: 84.8881
                       Mean reward: 240.88
               Mean episode length: 212.65
    Episode_Reward/reaching_object: 1.4140
    Episode_Reward/rotating_object: 47.0371
        Episode_Reward/action_rate: -0.0916
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 2.11s
                      Time elapsed: 00:34:07
                               ETA: 00:22:50

################################################################################
                     [1m Learning iteration 899/1500 [0m                      

                       Computation: 46708 steps/s (collection: 1.993s, learning 0.111s)
             Mean action noise std: 3.82
          Mean value_function loss: 88.2265
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 84.9214
                       Mean reward: 241.14
               Mean episode length: 209.11
    Episode_Reward/reaching_object: 1.4150
    Episode_Reward/rotating_object: 46.7877
        Episode_Reward/action_rate: -0.0926
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 2.10s
                      Time elapsed: 00:34:09
                               ETA: 00:22:48

################################################################################
                     [1m Learning iteration 900/1500 [0m                      

                       Computation: 46807 steps/s (collection: 1.990s, learning 0.110s)
             Mean action noise std: 3.82
          Mean value_function loss: 85.7259
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 84.9475
                       Mean reward: 256.11
               Mean episode length: 216.09
    Episode_Reward/reaching_object: 1.4009
    Episode_Reward/rotating_object: 48.6005
        Episode_Reward/action_rate: -0.0905
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 2.10s
                      Time elapsed: 00:34:11
                               ETA: 00:22:46

################################################################################
                     [1m Learning iteration 901/1500 [0m                      

                       Computation: 45579 steps/s (collection: 2.039s, learning 0.118s)
             Mean action noise std: 3.83
          Mean value_function loss: 88.7578
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 84.9760
                       Mean reward: 270.48
               Mean episode length: 228.80
    Episode_Reward/reaching_object: 1.4494
    Episode_Reward/rotating_object: 48.3431
        Episode_Reward/action_rate: -0.0938
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 2.16s
                      Time elapsed: 00:34:13
                               ETA: 00:22:43

################################################################################
                     [1m Learning iteration 902/1500 [0m                      

                       Computation: 45096 steps/s (collection: 2.076s, learning 0.104s)
             Mean action noise std: 3.83
          Mean value_function loss: 80.1291
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 85.0074
                       Mean reward: 227.86
               Mean episode length: 209.34
    Episode_Reward/reaching_object: 1.4199
    Episode_Reward/rotating_object: 46.9041
        Episode_Reward/action_rate: -0.0929
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 2.18s
                      Time elapsed: 00:34:15
                               ETA: 00:22:41

################################################################################
                     [1m Learning iteration 903/1500 [0m                      

                       Computation: 44913 steps/s (collection: 2.080s, learning 0.109s)
             Mean action noise std: 3.84
          Mean value_function loss: 83.4722
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 85.0363
                       Mean reward: 271.68
               Mean episode length: 218.84
    Episode_Reward/reaching_object: 1.4036
    Episode_Reward/rotating_object: 49.9191
        Episode_Reward/action_rate: -0.0912
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 2.19s
                      Time elapsed: 00:34:17
                               ETA: 00:22:39

################################################################################
                     [1m Learning iteration 904/1500 [0m                      

                       Computation: 46833 steps/s (collection: 1.991s, learning 0.108s)
             Mean action noise std: 3.84
          Mean value_function loss: 80.7954
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 85.0751
                       Mean reward: 241.22
               Mean episode length: 221.31
    Episode_Reward/reaching_object: 1.4067
    Episode_Reward/rotating_object: 50.2039
        Episode_Reward/action_rate: -0.0919
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 2.10s
                      Time elapsed: 00:34:20
                               ETA: 00:22:36

################################################################################
                     [1m Learning iteration 905/1500 [0m                      

                       Computation: 46169 steps/s (collection: 2.026s, learning 0.104s)
             Mean action noise std: 3.85
          Mean value_function loss: 82.1010
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 85.1124
                       Mean reward: 225.91
               Mean episode length: 202.23
    Episode_Reward/reaching_object: 1.3869
    Episode_Reward/rotating_object: 46.1789
        Episode_Reward/action_rate: -0.0918
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 2.13s
                      Time elapsed: 00:34:22
                               ETA: 00:22:34

################################################################################
                     [1m Learning iteration 906/1500 [0m                      

                       Computation: 46295 steps/s (collection: 2.018s, learning 0.106s)
             Mean action noise std: 3.85
          Mean value_function loss: 93.7565
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 85.1464
                       Mean reward: 276.21
               Mean episode length: 217.80
    Episode_Reward/reaching_object: 1.3946
    Episode_Reward/rotating_object: 47.1702
        Episode_Reward/action_rate: -0.0923
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 2.12s
                      Time elapsed: 00:34:24
                               ETA: 00:22:31

################################################################################
                     [1m Learning iteration 907/1500 [0m                      

                       Computation: 45997 steps/s (collection: 2.027s, learning 0.111s)
             Mean action noise std: 3.85
          Mean value_function loss: 91.6312
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 85.1731
                       Mean reward: 249.03
               Mean episode length: 195.19
    Episode_Reward/reaching_object: 1.3504
    Episode_Reward/rotating_object: 47.9237
        Episode_Reward/action_rate: -0.0880
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 2.14s
                      Time elapsed: 00:34:26
                               ETA: 00:22:29

################################################################################
                     [1m Learning iteration 908/1500 [0m                      

                       Computation: 47028 steps/s (collection: 1.984s, learning 0.107s)
             Mean action noise std: 3.86
          Mean value_function loss: 93.1419
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 85.2002
                       Mean reward: 235.44
               Mean episode length: 212.93
    Episode_Reward/reaching_object: 1.3212
    Episode_Reward/rotating_object: 44.1825
        Episode_Reward/action_rate: -0.0884
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 2.09s
                      Time elapsed: 00:34:28
                               ETA: 00:22:27

################################################################################
                     [1m Learning iteration 909/1500 [0m                      

                       Computation: 46763 steps/s (collection: 2.002s, learning 0.100s)
             Mean action noise std: 3.86
          Mean value_function loss: 87.4588
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 85.2356
                       Mean reward: 285.16
               Mean episode length: 221.97
    Episode_Reward/reaching_object: 1.4512
    Episode_Reward/rotating_object: 52.9844
        Episode_Reward/action_rate: -0.0954
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 2.10s
                      Time elapsed: 00:34:30
                               ETA: 00:22:24

################################################################################
                     [1m Learning iteration 910/1500 [0m                      

                       Computation: 46108 steps/s (collection: 2.020s, learning 0.112s)
             Mean action noise std: 3.87
          Mean value_function loss: 91.5878
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 85.2690
                       Mean reward: 250.28
               Mean episode length: 211.20
    Episode_Reward/reaching_object: 1.4056
    Episode_Reward/rotating_object: 47.0014
        Episode_Reward/action_rate: -0.0931
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 2.13s
                      Time elapsed: 00:34:32
                               ETA: 00:22:22

################################################################################
                     [1m Learning iteration 911/1500 [0m                      

                       Computation: 47165 steps/s (collection: 1.979s, learning 0.106s)
             Mean action noise std: 3.87
          Mean value_function loss: 87.9358
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 85.2965
                       Mean reward: 240.39
               Mean episode length: 210.42
    Episode_Reward/reaching_object: 1.4350
    Episode_Reward/rotating_object: 52.1877
        Episode_Reward/action_rate: -0.0944
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 2.08s
                      Time elapsed: 00:34:34
                               ETA: 00:22:20

################################################################################
                     [1m Learning iteration 912/1500 [0m                      

                       Computation: 45749 steps/s (collection: 2.055s, learning 0.094s)
             Mean action noise std: 3.87
          Mean value_function loss: 83.9040
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 85.3193
                       Mean reward: 260.70
               Mean episode length: 219.19
    Episode_Reward/reaching_object: 1.4118
    Episode_Reward/rotating_object: 50.3757
        Episode_Reward/action_rate: -0.0938
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 2.15s
                      Time elapsed: 00:34:37
                               ETA: 00:22:17

################################################################################
                     [1m Learning iteration 913/1500 [0m                      

                       Computation: 47587 steps/s (collection: 1.966s, learning 0.100s)
             Mean action noise std: 3.88
          Mean value_function loss: 81.9605
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 85.3467
                       Mean reward: 287.42
               Mean episode length: 211.72
    Episode_Reward/reaching_object: 1.4465
    Episode_Reward/rotating_object: 48.2238
        Episode_Reward/action_rate: -0.0951
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 2.07s
                      Time elapsed: 00:34:39
                               ETA: 00:22:15

################################################################################
                     [1m Learning iteration 914/1500 [0m                      

                       Computation: 46756 steps/s (collection: 1.989s, learning 0.113s)
             Mean action noise std: 3.88
          Mean value_function loss: 94.9592
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 85.3655
                       Mean reward: 300.76
               Mean episode length: 226.28
    Episode_Reward/reaching_object: 1.4561
    Episode_Reward/rotating_object: 50.7914
        Episode_Reward/action_rate: -0.0958
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 2.10s
                      Time elapsed: 00:34:41
                               ETA: 00:22:12

################################################################################
                     [1m Learning iteration 915/1500 [0m                      

                       Computation: 46986 steps/s (collection: 1.995s, learning 0.097s)
             Mean action noise std: 3.88
          Mean value_function loss: 79.4052
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 85.3887
                       Mean reward: 249.99
               Mean episode length: 212.65
    Episode_Reward/reaching_object: 1.4263
    Episode_Reward/rotating_object: 49.0871
        Episode_Reward/action_rate: -0.0951
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 2.09s
                      Time elapsed: 00:34:43
                               ETA: 00:22:10

################################################################################
                     [1m Learning iteration 916/1500 [0m                      

                       Computation: 45927 steps/s (collection: 2.028s, learning 0.112s)
             Mean action noise std: 3.89
          Mean value_function loss: 84.7528
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 85.4311
                       Mean reward: 231.69
               Mean episode length: 204.24
    Episode_Reward/reaching_object: 1.4353
    Episode_Reward/rotating_object: 49.7498
        Episode_Reward/action_rate: -0.0958
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 2.14s
                      Time elapsed: 00:34:45
                               ETA: 00:22:08

################################################################################
                     [1m Learning iteration 917/1500 [0m                      

                       Computation: 47055 steps/s (collection: 1.980s, learning 0.110s)
             Mean action noise std: 3.89
          Mean value_function loss: 85.4605
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 85.4615
                       Mean reward: 261.43
               Mean episode length: 207.37
    Episode_Reward/reaching_object: 1.4512
    Episode_Reward/rotating_object: 52.4950
        Episode_Reward/action_rate: -0.0960
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 2.09s
                      Time elapsed: 00:34:47
                               ETA: 00:22:05

################################################################################
                     [1m Learning iteration 918/1500 [0m                      

                       Computation: 46502 steps/s (collection: 2.005s, learning 0.109s)
             Mean action noise std: 3.89
          Mean value_function loss: 85.0972
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 85.4897
                       Mean reward: 239.98
               Mean episode length: 198.83
    Episode_Reward/reaching_object: 1.3701
    Episode_Reward/rotating_object: 49.7096
        Episode_Reward/action_rate: -0.0934
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 2.11s
                      Time elapsed: 00:34:49
                               ETA: 00:22:03

################################################################################
                     [1m Learning iteration 919/1500 [0m                      

                       Computation: 42653 steps/s (collection: 2.211s, learning 0.094s)
             Mean action noise std: 3.90
          Mean value_function loss: 83.4339
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 85.5091
                       Mean reward: 268.24
               Mean episode length: 216.43
    Episode_Reward/reaching_object: 1.4037
    Episode_Reward/rotating_object: 49.1471
        Episode_Reward/action_rate: -0.0951
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 2.30s
                      Time elapsed: 00:34:51
                               ETA: 00:22:01

################################################################################
                     [1m Learning iteration 920/1500 [0m                      

                       Computation: 46145 steps/s (collection: 2.032s, learning 0.099s)
             Mean action noise std: 3.90
          Mean value_function loss: 93.7313
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 85.5367
                       Mean reward: 228.43
               Mean episode length: 201.99
    Episode_Reward/reaching_object: 1.3773
    Episode_Reward/rotating_object: 45.6238
        Episode_Reward/action_rate: -0.0939
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 2.13s
                      Time elapsed: 00:34:54
                               ETA: 00:21:58

################################################################################
                     [1m Learning iteration 921/1500 [0m                      

                       Computation: 46751 steps/s (collection: 1.999s, learning 0.104s)
             Mean action noise std: 3.91
          Mean value_function loss: 85.8114
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 85.5686
                       Mean reward: 245.16
               Mean episode length: 208.64
    Episode_Reward/reaching_object: 1.3698
    Episode_Reward/rotating_object: 46.9392
        Episode_Reward/action_rate: -0.0947
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 2.10s
                      Time elapsed: 00:34:56
                               ETA: 00:21:56

################################################################################
                     [1m Learning iteration 922/1500 [0m                      

                       Computation: 45733 steps/s (collection: 2.048s, learning 0.102s)
             Mean action noise std: 3.91
          Mean value_function loss: 79.3772
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 85.6017
                       Mean reward: 268.61
               Mean episode length: 211.73
    Episode_Reward/reaching_object: 1.3965
    Episode_Reward/rotating_object: 49.9166
        Episode_Reward/action_rate: -0.0947
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 2.15s
                      Time elapsed: 00:34:58
                               ETA: 00:21:53

################################################################################
                     [1m Learning iteration 923/1500 [0m                      

                       Computation: 46437 steps/s (collection: 2.016s, learning 0.101s)
             Mean action noise std: 3.91
          Mean value_function loss: 77.0126
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 85.6348
                       Mean reward: 283.96
               Mean episode length: 223.06
    Episode_Reward/reaching_object: 1.4119
    Episode_Reward/rotating_object: 49.5514
        Episode_Reward/action_rate: -0.0966
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 2.12s
                      Time elapsed: 00:35:00
                               ETA: 00:21:51

################################################################################
                     [1m Learning iteration 924/1500 [0m                      

                       Computation: 47353 steps/s (collection: 1.961s, learning 0.115s)
             Mean action noise std: 3.92
          Mean value_function loss: 74.0950
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 85.6723
                       Mean reward: 251.80
               Mean episode length: 218.69
    Episode_Reward/reaching_object: 1.4230
    Episode_Reward/rotating_object: 49.6751
        Episode_Reward/action_rate: -0.0980
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 2.08s
                      Time elapsed: 00:35:02
                               ETA: 00:21:49

################################################################################
                     [1m Learning iteration 925/1500 [0m                      

                       Computation: 47485 steps/s (collection: 1.967s, learning 0.103s)
             Mean action noise std: 3.93
          Mean value_function loss: 79.0421
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 85.7136
                       Mean reward: 251.92
               Mean episode length: 200.04
    Episode_Reward/reaching_object: 1.3618
    Episode_Reward/rotating_object: 49.5611
        Episode_Reward/action_rate: -0.0927
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 2.07s
                      Time elapsed: 00:35:04
                               ETA: 00:21:46

################################################################################
                     [1m Learning iteration 926/1500 [0m                      

                       Computation: 46746 steps/s (collection: 1.991s, learning 0.112s)
             Mean action noise std: 3.93
          Mean value_function loss: 72.7394
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 85.7514
                       Mean reward: 253.12
               Mean episode length: 204.67
    Episode_Reward/reaching_object: 1.3499
    Episode_Reward/rotating_object: 47.8877
        Episode_Reward/action_rate: -0.0942
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 2.10s
                      Time elapsed: 00:35:06
                               ETA: 00:21:44

################################################################################
                     [1m Learning iteration 927/1500 [0m                      

                       Computation: 46743 steps/s (collection: 1.995s, learning 0.109s)
             Mean action noise std: 3.93
          Mean value_function loss: 82.4792
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 85.7794
                       Mean reward: 248.11
               Mean episode length: 200.81
    Episode_Reward/reaching_object: 1.3787
    Episode_Reward/rotating_object: 48.1386
        Episode_Reward/action_rate: -0.0955
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 2.10s
                      Time elapsed: 00:35:08
                               ETA: 00:21:42

################################################################################
                     [1m Learning iteration 928/1500 [0m                      

                       Computation: 46681 steps/s (collection: 1.991s, learning 0.115s)
             Mean action noise std: 3.94
          Mean value_function loss: 78.8077
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 85.8092
                       Mean reward: 246.66
               Mean episode length: 209.76
    Episode_Reward/reaching_object: 1.3301
    Episode_Reward/rotating_object: 45.1065
        Episode_Reward/action_rate: -0.0936
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 2.11s
                      Time elapsed: 00:35:10
                               ETA: 00:21:39

################################################################################
                     [1m Learning iteration 929/1500 [0m                      

                       Computation: 47200 steps/s (collection: 1.981s, learning 0.102s)
             Mean action noise std: 3.94
          Mean value_function loss: 80.3553
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 85.8435
                       Mean reward: 260.84
               Mean episode length: 213.90
    Episode_Reward/reaching_object: 1.4114
    Episode_Reward/rotating_object: 52.7401
        Episode_Reward/action_rate: -0.0982
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 2.08s
                      Time elapsed: 00:35:12
                               ETA: 00:21:37

################################################################################
                     [1m Learning iteration 930/1500 [0m                      

                       Computation: 46483 steps/s (collection: 2.017s, learning 0.098s)
             Mean action noise std: 3.95
          Mean value_function loss: 79.8590
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 85.8753
                       Mean reward: 245.24
               Mean episode length: 201.70
    Episode_Reward/reaching_object: 1.3699
    Episode_Reward/rotating_object: 49.2975
        Episode_Reward/action_rate: -0.0970
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 2.11s
                      Time elapsed: 00:35:15
                               ETA: 00:21:34

################################################################################
                     [1m Learning iteration 931/1500 [0m                      

                       Computation: 46914 steps/s (collection: 1.984s, learning 0.111s)
             Mean action noise std: 3.95
          Mean value_function loss: 88.4158
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 85.9135
                       Mean reward: 296.53
               Mean episode length: 229.54
    Episode_Reward/reaching_object: 1.3791
    Episode_Reward/rotating_object: 50.3562
        Episode_Reward/action_rate: -0.0966
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 2.10s
                      Time elapsed: 00:35:17
                               ETA: 00:21:32

################################################################################
                     [1m Learning iteration 932/1500 [0m                      

                       Computation: 46990 steps/s (collection: 1.987s, learning 0.105s)
             Mean action noise std: 3.95
          Mean value_function loss: 80.5217
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 85.9402
                       Mean reward: 244.96
               Mean episode length: 203.77
    Episode_Reward/reaching_object: 1.3361
    Episode_Reward/rotating_object: 46.7570
        Episode_Reward/action_rate: -0.0948
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 2.09s
                      Time elapsed: 00:35:19
                               ETA: 00:21:30

################################################################################
                     [1m Learning iteration 933/1500 [0m                      

                       Computation: 45963 steps/s (collection: 2.036s, learning 0.103s)
             Mean action noise std: 3.96
          Mean value_function loss: 84.6219
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 85.9703
                       Mean reward: 214.82
               Mean episode length: 205.21
    Episode_Reward/reaching_object: 1.3292
    Episode_Reward/rotating_object: 44.1783
        Episode_Reward/action_rate: -0.0935
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 2.14s
                      Time elapsed: 00:35:21
                               ETA: 00:21:27

################################################################################
                     [1m Learning iteration 934/1500 [0m                      

                       Computation: 45102 steps/s (collection: 2.076s, learning 0.103s)
             Mean action noise std: 3.96
          Mean value_function loss: 87.4299
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 86.0087
                       Mean reward: 250.17
               Mean episode length: 217.36
    Episode_Reward/reaching_object: 1.3524
    Episode_Reward/rotating_object: 47.2262
        Episode_Reward/action_rate: -0.0937
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 2.18s
                      Time elapsed: 00:35:23
                               ETA: 00:21:25

################################################################################
                     [1m Learning iteration 935/1500 [0m                      

                       Computation: 46412 steps/s (collection: 2.007s, learning 0.111s)
             Mean action noise std: 3.97
          Mean value_function loss: 75.8866
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 86.0324
                       Mean reward: 267.10
               Mean episode length: 219.18
    Episode_Reward/reaching_object: 1.4089
    Episode_Reward/rotating_object: 48.9916
        Episode_Reward/action_rate: -0.0995
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 2.12s
                      Time elapsed: 00:35:25
                               ETA: 00:21:23

################################################################################
                     [1m Learning iteration 936/1500 [0m                      

                       Computation: 46296 steps/s (collection: 1.999s, learning 0.125s)
             Mean action noise std: 3.97
          Mean value_function loss: 91.7033
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 86.0524
                       Mean reward: 259.74
               Mean episode length: 213.11
    Episode_Reward/reaching_object: 1.3871
    Episode_Reward/rotating_object: 49.0335
        Episode_Reward/action_rate: -0.0961
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 2.12s
                      Time elapsed: 00:35:27
                               ETA: 00:21:20

################################################################################
                     [1m Learning iteration 937/1500 [0m                      

                       Computation: 47241 steps/s (collection: 1.981s, learning 0.100s)
             Mean action noise std: 3.98
          Mean value_function loss: 84.5305
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 86.0901
                       Mean reward: 245.92
               Mean episode length: 219.70
    Episode_Reward/reaching_object: 1.4386
    Episode_Reward/rotating_object: 49.8366
        Episode_Reward/action_rate: -0.1011
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 2.08s
                      Time elapsed: 00:35:29
                               ETA: 00:21:18

################################################################################
                     [1m Learning iteration 938/1500 [0m                      

                       Computation: 47126 steps/s (collection: 1.975s, learning 0.111s)
             Mean action noise std: 3.98
          Mean value_function loss: 88.5461
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 86.1368
                       Mean reward: 247.60
               Mean episode length: 207.81
    Episode_Reward/reaching_object: 1.4053
    Episode_Reward/rotating_object: 49.5582
        Episode_Reward/action_rate: -0.0985
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 2.09s
                      Time elapsed: 00:35:31
                               ETA: 00:21:16

################################################################################
                     [1m Learning iteration 939/1500 [0m                      

                       Computation: 46547 steps/s (collection: 2.017s, learning 0.095s)
             Mean action noise std: 3.99
          Mean value_function loss: 90.3083
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 86.1855
                       Mean reward: 248.61
               Mean episode length: 212.83
    Episode_Reward/reaching_object: 1.4318
    Episode_Reward/rotating_object: 51.0547
        Episode_Reward/action_rate: -0.1001
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 2.11s
                      Time elapsed: 00:35:34
                               ETA: 00:21:13

################################################################################
                     [1m Learning iteration 940/1500 [0m                      

                       Computation: 45785 steps/s (collection: 2.043s, learning 0.104s)
             Mean action noise std: 3.99
          Mean value_function loss: 82.0605
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 86.2214
                       Mean reward: 284.40
               Mean episode length: 220.26
    Episode_Reward/reaching_object: 1.4044
    Episode_Reward/rotating_object: 50.9004
        Episode_Reward/action_rate: -0.0996
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 2.15s
                      Time elapsed: 00:35:36
                               ETA: 00:21:11

################################################################################
                     [1m Learning iteration 941/1500 [0m                      

                       Computation: 47343 steps/s (collection: 1.979s, learning 0.098s)
             Mean action noise std: 4.00
          Mean value_function loss: 87.6163
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 86.2564
                       Mean reward: 233.19
               Mean episode length: 194.69
    Episode_Reward/reaching_object: 1.3517
    Episode_Reward/rotating_object: 47.1220
        Episode_Reward/action_rate: -0.0961
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 2.08s
                      Time elapsed: 00:35:38
                               ETA: 00:21:08

################################################################################
                     [1m Learning iteration 942/1500 [0m                      

                       Computation: 46700 steps/s (collection: 1.990s, learning 0.115s)
             Mean action noise std: 4.00
          Mean value_function loss: 87.5700
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 86.2861
                       Mean reward: 219.94
               Mean episode length: 199.68
    Episode_Reward/reaching_object: 1.3795
    Episode_Reward/rotating_object: 47.5089
        Episode_Reward/action_rate: -0.0977
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 2.10s
                      Time elapsed: 00:35:40
                               ETA: 00:21:06

################################################################################
                     [1m Learning iteration 943/1500 [0m                      

                       Computation: 45765 steps/s (collection: 2.034s, learning 0.114s)
             Mean action noise std: 4.01
          Mean value_function loss: 79.8742
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 86.3229
                       Mean reward: 308.49
               Mean episode length: 214.59
    Episode_Reward/reaching_object: 1.4394
    Episode_Reward/rotating_object: 55.6892
        Episode_Reward/action_rate: -0.1021
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 2.15s
                      Time elapsed: 00:35:42
                               ETA: 00:21:04

################################################################################
                     [1m Learning iteration 944/1500 [0m                      

                       Computation: 46930 steps/s (collection: 1.976s, learning 0.119s)
             Mean action noise std: 4.01
          Mean value_function loss: 89.0422
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 86.3615
                       Mean reward: 232.00
               Mean episode length: 215.13
    Episode_Reward/reaching_object: 1.3542
    Episode_Reward/rotating_object: 45.8932
        Episode_Reward/action_rate: -0.0987
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 2.09s
                      Time elapsed: 00:35:44
                               ETA: 00:21:01

################################################################################
                     [1m Learning iteration 945/1500 [0m                      

                       Computation: 44055 steps/s (collection: 2.122s, learning 0.109s)
             Mean action noise std: 4.01
          Mean value_function loss: 84.1576
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 86.3897
                       Mean reward: 244.99
               Mean episode length: 196.05
    Episode_Reward/reaching_object: 1.3910
    Episode_Reward/rotating_object: 49.3098
        Episode_Reward/action_rate: -0.0997
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 2.23s
                      Time elapsed: 00:35:46
                               ETA: 00:20:59

################################################################################
                     [1m Learning iteration 946/1500 [0m                      

                       Computation: 43626 steps/s (collection: 2.051s, learning 0.202s)
             Mean action noise std: 4.02
          Mean value_function loss: 86.4898
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 86.4141
                       Mean reward: 249.03
               Mean episode length: 204.26
    Episode_Reward/reaching_object: 1.3698
    Episode_Reward/rotating_object: 50.1712
        Episode_Reward/action_rate: -0.0986
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 2.25s
                      Time elapsed: 00:35:49
                               ETA: 00:20:57

################################################################################
                     [1m Learning iteration 947/1500 [0m                      

                       Computation: 39653 steps/s (collection: 2.338s, learning 0.141s)
             Mean action noise std: 4.02
          Mean value_function loss: 83.8274
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 86.4415
                       Mean reward: 244.39
               Mean episode length: 212.89
    Episode_Reward/reaching_object: 1.4210
    Episode_Reward/rotating_object: 51.9714
        Episode_Reward/action_rate: -0.1025
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 2.48s
                      Time elapsed: 00:35:51
                               ETA: 00:20:55

################################################################################
                     [1m Learning iteration 948/1500 [0m                      

                       Computation: 43344 steps/s (collection: 2.094s, learning 0.174s)
             Mean action noise std: 4.03
          Mean value_function loss: 97.2489
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 86.4734
                       Mean reward: 248.53
               Mean episode length: 202.85
    Episode_Reward/reaching_object: 1.4187
    Episode_Reward/rotating_object: 48.6441
        Episode_Reward/action_rate: -0.1038
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 2.27s
                      Time elapsed: 00:35:53
                               ETA: 00:20:52

################################################################################
                     [1m Learning iteration 949/1500 [0m                      

                       Computation: 42472 steps/s (collection: 2.157s, learning 0.158s)
             Mean action noise std: 4.03
          Mean value_function loss: 90.5503
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 86.5024
                       Mean reward: 224.90
               Mean episode length: 197.07
    Episode_Reward/reaching_object: 1.3805
    Episode_Reward/rotating_object: 47.7548
        Episode_Reward/action_rate: -0.1012
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 2.31s
                      Time elapsed: 00:35:56
                               ETA: 00:20:50

################################################################################
                     [1m Learning iteration 950/1500 [0m                      

                       Computation: 40718 steps/s (collection: 2.264s, learning 0.150s)
             Mean action noise std: 4.03
          Mean value_function loss: 86.2663
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 86.5285
                       Mean reward: 287.42
               Mean episode length: 210.11
    Episode_Reward/reaching_object: 1.4012
    Episode_Reward/rotating_object: 52.6277
        Episode_Reward/action_rate: -0.1013
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 2.41s
                      Time elapsed: 00:35:58
                               ETA: 00:20:48

################################################################################
                     [1m Learning iteration 951/1500 [0m                      

                       Computation: 40140 steps/s (collection: 2.293s, learning 0.156s)
             Mean action noise std: 4.04
          Mean value_function loss: 67.9610
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 86.5602
                       Mean reward: 281.32
               Mean episode length: 212.42
    Episode_Reward/reaching_object: 1.3951
    Episode_Reward/rotating_object: 51.3540
        Episode_Reward/action_rate: -0.1023
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 2.45s
                      Time elapsed: 00:36:01
                               ETA: 00:20:46

################################################################################
                     [1m Learning iteration 952/1500 [0m                      

                       Computation: 43685 steps/s (collection: 2.132s, learning 0.118s)
             Mean action noise std: 4.04
          Mean value_function loss: 79.0842
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 86.5907
                       Mean reward: 272.76
               Mean episode length: 211.78
    Episode_Reward/reaching_object: 1.3426
    Episode_Reward/rotating_object: 50.6761
        Episode_Reward/action_rate: -0.0996
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 2.25s
                      Time elapsed: 00:36:03
                               ETA: 00:20:43

################################################################################
                     [1m Learning iteration 953/1500 [0m                      

                       Computation: 44355 steps/s (collection: 2.097s, learning 0.119s)
             Mean action noise std: 4.05
          Mean value_function loss: 76.9876
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 86.6328
                       Mean reward: 209.18
               Mean episode length: 195.52
    Episode_Reward/reaching_object: 1.3320
    Episode_Reward/rotating_object: 46.0330
        Episode_Reward/action_rate: -0.0996
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 2.22s
                      Time elapsed: 00:36:05
                               ETA: 00:20:41

################################################################################
                     [1m Learning iteration 954/1500 [0m                      

                       Computation: 44280 steps/s (collection: 2.095s, learning 0.125s)
             Mean action noise std: 4.05
          Mean value_function loss: 84.7385
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 86.6682
                       Mean reward: 220.06
               Mean episode length: 207.61
    Episode_Reward/reaching_object: 1.3413
    Episode_Reward/rotating_object: 45.6784
        Episode_Reward/action_rate: -0.1012
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 2.22s
                      Time elapsed: 00:36:07
                               ETA: 00:20:39

################################################################################
                     [1m Learning iteration 955/1500 [0m                      

                       Computation: 44680 steps/s (collection: 2.066s, learning 0.134s)
             Mean action noise std: 4.06
          Mean value_function loss: 81.6405
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 86.6996
                       Mean reward: 314.52
               Mean episode length: 227.05
    Episode_Reward/reaching_object: 1.4018
    Episode_Reward/rotating_object: 54.4048
        Episode_Reward/action_rate: -0.1040
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 2.20s
                      Time elapsed: 00:36:09
                               ETA: 00:20:37

################################################################################
                     [1m Learning iteration 956/1500 [0m                      

                       Computation: 43645 steps/s (collection: 2.079s, learning 0.173s)
             Mean action noise std: 4.06
          Mean value_function loss: 85.2220
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 86.7230
                       Mean reward: 302.22
               Mean episode length: 208.32
    Episode_Reward/reaching_object: 1.3876
    Episode_Reward/rotating_object: 54.4728
        Episode_Reward/action_rate: -0.1031
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 2.25s
                      Time elapsed: 00:36:12
                               ETA: 00:20:34

################################################################################
                     [1m Learning iteration 957/1500 [0m                      

                       Computation: 43404 steps/s (collection: 2.148s, learning 0.117s)
             Mean action noise std: 4.06
          Mean value_function loss: 82.3290
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 86.7498
                       Mean reward: 256.68
               Mean episode length: 210.97
    Episode_Reward/reaching_object: 1.3094
    Episode_Reward/rotating_object: 46.6860
        Episode_Reward/action_rate: -0.0997
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 2.26s
                      Time elapsed: 00:36:14
                               ETA: 00:20:32

################################################################################
                     [1m Learning iteration 958/1500 [0m                      

                       Computation: 39813 steps/s (collection: 2.350s, learning 0.120s)
             Mean action noise std: 4.07
          Mean value_function loss: 89.6766
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 86.7809
                       Mean reward: 260.10
               Mean episode length: 203.90
    Episode_Reward/reaching_object: 1.3732
    Episode_Reward/rotating_object: 51.8064
        Episode_Reward/action_rate: -0.1024
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 2.47s
                      Time elapsed: 00:36:16
                               ETA: 00:20:30

################################################################################
                     [1m Learning iteration 959/1500 [0m                      

                       Computation: 44480 steps/s (collection: 2.103s, learning 0.107s)
             Mean action noise std: 4.07
          Mean value_function loss: 85.7304
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 86.8126
                       Mean reward: 229.35
               Mean episode length: 199.53
    Episode_Reward/reaching_object: 1.3810
    Episode_Reward/rotating_object: 50.0144
        Episode_Reward/action_rate: -0.1030
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 2.21s
                      Time elapsed: 00:36:19
                               ETA: 00:20:28

################################################################################
                     [1m Learning iteration 960/1500 [0m                      

                       Computation: 42083 steps/s (collection: 2.208s, learning 0.128s)
             Mean action noise std: 4.08
          Mean value_function loss: 91.6047
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 86.8388
                       Mean reward: 268.58
               Mean episode length: 221.13
    Episode_Reward/reaching_object: 1.4246
    Episode_Reward/rotating_object: 50.4029
        Episode_Reward/action_rate: -0.1071
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 2.34s
                      Time elapsed: 00:36:21
                               ETA: 00:20:25

################################################################################
                     [1m Learning iteration 961/1500 [0m                      

                       Computation: 41527 steps/s (collection: 2.170s, learning 0.197s)
             Mean action noise std: 4.08
          Mean value_function loss: 86.6857
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 86.8665
                       Mean reward: 301.41
               Mean episode length: 216.09
    Episode_Reward/reaching_object: 1.3300
    Episode_Reward/rotating_object: 48.5888
        Episode_Reward/action_rate: -0.1001
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 2.37s
                      Time elapsed: 00:36:23
                               ETA: 00:20:23

################################################################################
                     [1m Learning iteration 962/1500 [0m                      

                       Computation: 42133 steps/s (collection: 2.164s, learning 0.170s)
             Mean action noise std: 4.09
          Mean value_function loss: 100.4737
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 86.8968
                       Mean reward: 292.07
               Mean episode length: 211.55
    Episode_Reward/reaching_object: 1.3747
    Episode_Reward/rotating_object: 50.7237
        Episode_Reward/action_rate: -0.1023
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 2.33s
                      Time elapsed: 00:36:26
                               ETA: 00:20:21

################################################################################
                     [1m Learning iteration 963/1500 [0m                      

                       Computation: 41799 steps/s (collection: 2.199s, learning 0.153s)
             Mean action noise std: 4.09
          Mean value_function loss: 92.8435
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 86.9229
                       Mean reward: 299.13
               Mean episode length: 207.08
    Episode_Reward/reaching_object: 1.3362
    Episode_Reward/rotating_object: 48.6858
        Episode_Reward/action_rate: -0.1007
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 2.35s
                      Time elapsed: 00:36:28
                               ETA: 00:20:19

################################################################################
                     [1m Learning iteration 964/1500 [0m                      

                       Computation: 41855 steps/s (collection: 2.143s, learning 0.206s)
             Mean action noise std: 4.09
          Mean value_function loss: 92.4607
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 86.9400
                       Mean reward: 268.16
               Mean episode length: 204.37
    Episode_Reward/reaching_object: 1.3683
    Episode_Reward/rotating_object: 48.9706
        Episode_Reward/action_rate: -0.1029
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 2.35s
                      Time elapsed: 00:36:30
                               ETA: 00:20:16

################################################################################
                     [1m Learning iteration 965/1500 [0m                      

                       Computation: 43580 steps/s (collection: 2.084s, learning 0.172s)
             Mean action noise std: 4.09
          Mean value_function loss: 95.4590
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 86.9651
                       Mean reward: 281.84
               Mean episode length: 212.71
    Episode_Reward/reaching_object: 1.3983
    Episode_Reward/rotating_object: 52.6306
        Episode_Reward/action_rate: -0.1048
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 2.26s
                      Time elapsed: 00:36:33
                               ETA: 00:20:14

################################################################################
                     [1m Learning iteration 966/1500 [0m                      

                       Computation: 42963 steps/s (collection: 2.179s, learning 0.109s)
             Mean action noise std: 4.10
          Mean value_function loss: 88.1285
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 86.9899
                       Mean reward: 262.86
               Mean episode length: 205.54
    Episode_Reward/reaching_object: 1.3747
    Episode_Reward/rotating_object: 51.5284
        Episode_Reward/action_rate: -0.1035
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 2.29s
                      Time elapsed: 00:36:35
                               ETA: 00:20:12

################################################################################
                     [1m Learning iteration 967/1500 [0m                      

                       Computation: 44219 steps/s (collection: 2.115s, learning 0.108s)
             Mean action noise std: 4.10
          Mean value_function loss: 76.9034
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 87.0149
                       Mean reward: 272.05
               Mean episode length: 222.91
    Episode_Reward/reaching_object: 1.3788
    Episode_Reward/rotating_object: 52.2391
        Episode_Reward/action_rate: -0.1028
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 2.22s
                      Time elapsed: 00:36:37
                               ETA: 00:20:10

################################################################################
                     [1m Learning iteration 968/1500 [0m                      

                       Computation: 40428 steps/s (collection: 2.291s, learning 0.141s)
             Mean action noise std: 4.11
          Mean value_function loss: 87.2418
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 87.0430
                       Mean reward: 235.09
               Mean episode length: 198.88
    Episode_Reward/reaching_object: 1.3608
    Episode_Reward/rotating_object: 48.4657
        Episode_Reward/action_rate: -0.1020
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 2.43s
                      Time elapsed: 00:36:40
                               ETA: 00:20:07

################################################################################
                     [1m Learning iteration 969/1500 [0m                      

                       Computation: 43329 steps/s (collection: 2.067s, learning 0.201s)
             Mean action noise std: 4.11
          Mean value_function loss: 92.7340
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 87.0717
                       Mean reward: 282.69
               Mean episode length: 205.98
    Episode_Reward/reaching_object: 1.3760
    Episode_Reward/rotating_object: 51.6692
        Episode_Reward/action_rate: -0.1040
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 2.27s
                      Time elapsed: 00:36:42
                               ETA: 00:20:05

################################################################################
                     [1m Learning iteration 970/1500 [0m                      

                       Computation: 40757 steps/s (collection: 2.203s, learning 0.209s)
             Mean action noise std: 4.11
          Mean value_function loss: 86.7679
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 87.0940
                       Mean reward: 282.92
               Mean episode length: 212.49
    Episode_Reward/reaching_object: 1.3968
    Episode_Reward/rotating_object: 53.5254
        Episode_Reward/action_rate: -0.1048
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 2.41s
                      Time elapsed: 00:36:44
                               ETA: 00:20:03

################################################################################
                     [1m Learning iteration 971/1500 [0m                      

                       Computation: 44021 steps/s (collection: 2.088s, learning 0.145s)
             Mean action noise std: 4.12
          Mean value_function loss: 89.5316
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 87.1162
                       Mean reward: 224.61
               Mean episode length: 197.89
    Episode_Reward/reaching_object: 1.3363
    Episode_Reward/rotating_object: 45.8931
        Episode_Reward/action_rate: -0.1021
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 2.23s
                      Time elapsed: 00:36:47
                               ETA: 00:20:01

################################################################################
                     [1m Learning iteration 972/1500 [0m                      

                       Computation: 44159 steps/s (collection: 2.103s, learning 0.123s)
             Mean action noise std: 4.12
          Mean value_function loss: 88.5464
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 87.1408
                       Mean reward: 250.92
               Mean episode length: 200.17
    Episode_Reward/reaching_object: 1.3277
    Episode_Reward/rotating_object: 49.4527
        Episode_Reward/action_rate: -0.1015
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 2.23s
                      Time elapsed: 00:36:49
                               ETA: 00:19:58

################################################################################
                     [1m Learning iteration 973/1500 [0m                      

                       Computation: 42860 steps/s (collection: 2.186s, learning 0.108s)
             Mean action noise std: 4.12
          Mean value_function loss: 85.6485
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 87.1675
                       Mean reward: 237.75
               Mean episode length: 210.95
    Episode_Reward/reaching_object: 1.3641
    Episode_Reward/rotating_object: 48.5921
        Episode_Reward/action_rate: -0.1048
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 2.29s
                      Time elapsed: 00:36:51
                               ETA: 00:19:56

################################################################################
                     [1m Learning iteration 974/1500 [0m                      

                       Computation: 42963 steps/s (collection: 2.133s, learning 0.155s)
             Mean action noise std: 4.13
          Mean value_function loss: 86.3530
               Mean surrogate loss: -0.0116
                 Mean entropy loss: 87.1985
                       Mean reward: 249.73
               Mean episode length: 205.11
    Episode_Reward/reaching_object: 1.3814
    Episode_Reward/rotating_object: 50.0994
        Episode_Reward/action_rate: -0.1060
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 2.29s
                      Time elapsed: 00:36:53
                               ETA: 00:19:54

################################################################################
                     [1m Learning iteration 975/1500 [0m                      

                       Computation: 42056 steps/s (collection: 2.205s, learning 0.132s)
             Mean action noise std: 4.13
          Mean value_function loss: 86.3747
               Mean surrogate loss: -0.0115
                 Mean entropy loss: 87.2409
                       Mean reward: 235.08
               Mean episode length: 205.44
    Episode_Reward/reaching_object: 1.3746
    Episode_Reward/rotating_object: 52.2375
        Episode_Reward/action_rate: -0.1054
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 2.34s
                      Time elapsed: 00:36:56
                               ETA: 00:19:52

################################################################################
                     [1m Learning iteration 976/1500 [0m                      

                       Computation: 42113 steps/s (collection: 2.124s, learning 0.211s)
             Mean action noise std: 4.14
          Mean value_function loss: 91.9330
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 87.2833
                       Mean reward: 229.04
               Mean episode length: 214.33
    Episode_Reward/reaching_object: 1.3252
    Episode_Reward/rotating_object: 44.3473
        Episode_Reward/action_rate: -0.1040
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 2.33s
                      Time elapsed: 00:36:58
                               ETA: 00:19:49

################################################################################
                     [1m Learning iteration 977/1500 [0m                      

                       Computation: 42870 steps/s (collection: 2.160s, learning 0.133s)
             Mean action noise std: 4.14
          Mean value_function loss: 87.6614
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 87.3186
                       Mean reward: 283.97
               Mean episode length: 213.62
    Episode_Reward/reaching_object: 1.3725
    Episode_Reward/rotating_object: 51.4606
        Episode_Reward/action_rate: -0.1043
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 2.29s
                      Time elapsed: 00:37:00
                               ETA: 00:19:47

################################################################################
                     [1m Learning iteration 978/1500 [0m                      

                       Computation: 42973 steps/s (collection: 2.150s, learning 0.138s)
             Mean action noise std: 4.15
          Mean value_function loss: 84.5761
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 87.3549
                       Mean reward: 286.67
               Mean episode length: 215.29
    Episode_Reward/reaching_object: 1.4605
    Episode_Reward/rotating_object: 54.7766
        Episode_Reward/action_rate: -0.1117
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 2.29s
                      Time elapsed: 00:37:03
                               ETA: 00:19:45

################################################################################
                     [1m Learning iteration 979/1500 [0m                      

                       Computation: 44669 steps/s (collection: 2.076s, learning 0.125s)
             Mean action noise std: 4.15
          Mean value_function loss: 92.7395
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 87.3841
                       Mean reward: 250.22
               Mean episode length: 197.74
    Episode_Reward/reaching_object: 1.3682
    Episode_Reward/rotating_object: 50.2204
        Episode_Reward/action_rate: -0.1045
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 2.20s
                      Time elapsed: 00:37:05
                               ETA: 00:19:43

################################################################################
                     [1m Learning iteration 980/1500 [0m                      

                       Computation: 46011 steps/s (collection: 2.023s, learning 0.114s)
             Mean action noise std: 4.16
          Mean value_function loss: 93.2898
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 87.4039
                       Mean reward: 226.05
               Mean episode length: 192.77
    Episode_Reward/reaching_object: 1.4047
    Episode_Reward/rotating_object: 53.5950
        Episode_Reward/action_rate: -0.1069
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 2.14s
                      Time elapsed: 00:37:07
                               ETA: 00:19:40

################################################################################
                     [1m Learning iteration 981/1500 [0m                      

                       Computation: 46499 steps/s (collection: 1.993s, learning 0.121s)
             Mean action noise std: 4.16
          Mean value_function loss: 87.0310
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 87.4231
                       Mean reward: 288.81
               Mean episode length: 217.97
    Episode_Reward/reaching_object: 1.4133
    Episode_Reward/rotating_object: 51.8876
        Episode_Reward/action_rate: -0.1082
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 2.11s
                      Time elapsed: 00:37:09
                               ETA: 00:19:38

################################################################################
                     [1m Learning iteration 982/1500 [0m                      

                       Computation: 45214 steps/s (collection: 2.077s, learning 0.098s)
             Mean action noise std: 4.16
          Mean value_function loss: 82.9320
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 87.4432
                       Mean reward: 240.43
               Mean episode length: 211.30
    Episode_Reward/reaching_object: 1.4102
    Episode_Reward/rotating_object: 51.4017
        Episode_Reward/action_rate: -0.1086
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 2.17s
                      Time elapsed: 00:37:11
                               ETA: 00:19:36

################################################################################
                     [1m Learning iteration 983/1500 [0m                      

                       Computation: 44375 steps/s (collection: 2.103s, learning 0.113s)
             Mean action noise std: 4.16
          Mean value_function loss: 92.2413
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 87.4604
                       Mean reward: 297.49
               Mean episode length: 215.87
    Episode_Reward/reaching_object: 1.4094
    Episode_Reward/rotating_object: 54.5503
        Episode_Reward/action_rate: -0.1072
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 2.22s
                      Time elapsed: 00:37:13
                               ETA: 00:19:33

################################################################################
                     [1m Learning iteration 984/1500 [0m                      

                       Computation: 41327 steps/s (collection: 2.208s, learning 0.171s)
             Mean action noise std: 4.17
          Mean value_function loss: 93.4965
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 87.4814
                       Mean reward: 284.87
               Mean episode length: 216.36
    Episode_Reward/reaching_object: 1.3817
    Episode_Reward/rotating_object: 50.2825
        Episode_Reward/action_rate: -0.1074
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 2.38s
                      Time elapsed: 00:37:16
                               ETA: 00:19:31

################################################################################
                     [1m Learning iteration 985/1500 [0m                      

                       Computation: 43435 steps/s (collection: 2.154s, learning 0.110s)
             Mean action noise std: 4.17
          Mean value_function loss: 93.4069
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 87.5075
                       Mean reward: 268.56
               Mean episode length: 205.74
    Episode_Reward/reaching_object: 1.4301
    Episode_Reward/rotating_object: 56.3363
        Episode_Reward/action_rate: -0.1097
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 2.26s
                      Time elapsed: 00:37:18
                               ETA: 00:19:29

################################################################################
                     [1m Learning iteration 986/1500 [0m                      

                       Computation: 44042 steps/s (collection: 2.093s, learning 0.139s)
             Mean action noise std: 4.17
          Mean value_function loss: 90.2947
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 87.5264
                       Mean reward: 260.43
               Mean episode length: 206.69
    Episode_Reward/reaching_object: 1.3810
    Episode_Reward/rotating_object: 49.6533
        Episode_Reward/action_rate: -0.1082
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 2.23s
                      Time elapsed: 00:37:20
                               ETA: 00:19:26

################################################################################
                     [1m Learning iteration 987/1500 [0m                      

                       Computation: 43633 steps/s (collection: 2.100s, learning 0.153s)
             Mean action noise std: 4.18
          Mean value_function loss: 83.8859
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 87.5429
                       Mean reward: 220.09
               Mean episode length: 207.87
    Episode_Reward/reaching_object: 1.3990
    Episode_Reward/rotating_object: 51.2865
        Episode_Reward/action_rate: -0.1091
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 2.25s
                      Time elapsed: 00:37:23
                               ETA: 00:19:24

################################################################################
                     [1m Learning iteration 988/1500 [0m                      

                       Computation: 41079 steps/s (collection: 2.239s, learning 0.154s)
             Mean action noise std: 4.18
          Mean value_function loss: 88.6025
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 87.5725
                       Mean reward: 230.08
               Mean episode length: 209.42
    Episode_Reward/reaching_object: 1.4570
    Episode_Reward/rotating_object: 54.9959
        Episode_Reward/action_rate: -0.1119
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 2.39s
                      Time elapsed: 00:37:25
                               ETA: 00:19:22

################################################################################
                     [1m Learning iteration 989/1500 [0m                      

                       Computation: 44972 steps/s (collection: 2.064s, learning 0.122s)
             Mean action noise std: 4.19
          Mean value_function loss: 87.4880
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 87.5974
                       Mean reward: 288.13
               Mean episode length: 212.25
    Episode_Reward/reaching_object: 1.4390
    Episode_Reward/rotating_object: 55.0075
        Episode_Reward/action_rate: -0.1114
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 2.19s
                      Time elapsed: 00:37:27
                               ETA: 00:19:20

################################################################################
                     [1m Learning iteration 990/1500 [0m                      

                       Computation: 45237 steps/s (collection: 2.057s, learning 0.117s)
             Mean action noise std: 4.19
          Mean value_function loss: 93.9851
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 87.6265
                       Mean reward: 242.08
               Mean episode length: 207.31
    Episode_Reward/reaching_object: 1.4345
    Episode_Reward/rotating_object: 53.8128
        Episode_Reward/action_rate: -0.1114
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 2.17s
                      Time elapsed: 00:37:29
                               ETA: 00:19:17

################################################################################
                     [1m Learning iteration 991/1500 [0m                      

                       Computation: 44393 steps/s (collection: 2.110s, learning 0.105s)
             Mean action noise std: 4.19
          Mean value_function loss: 85.2461
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 87.6486
                       Mean reward: 271.92
               Mean episode length: 204.31
    Episode_Reward/reaching_object: 1.4113
    Episode_Reward/rotating_object: 52.9265
        Episode_Reward/action_rate: -0.1095
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 2.21s
                      Time elapsed: 00:37:32
                               ETA: 00:19:15

################################################################################
                     [1m Learning iteration 992/1500 [0m                      

                       Computation: 44097 steps/s (collection: 2.085s, learning 0.144s)
             Mean action noise std: 4.19
          Mean value_function loss: 90.1970
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 87.6676
                       Mean reward: 274.38
               Mean episode length: 210.19
    Episode_Reward/reaching_object: 1.4160
    Episode_Reward/rotating_object: 51.5620
        Episode_Reward/action_rate: -0.1110
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 2.23s
                      Time elapsed: 00:37:34
                               ETA: 00:19:13

################################################################################
                     [1m Learning iteration 993/1500 [0m                      

                       Computation: 42344 steps/s (collection: 2.158s, learning 0.164s)
             Mean action noise std: 4.20
          Mean value_function loss: 88.0530
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 87.6837
                       Mean reward: 297.92
               Mean episode length: 217.27
    Episode_Reward/reaching_object: 1.4672
    Episode_Reward/rotating_object: 57.0801
        Episode_Reward/action_rate: -0.1139
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 2.32s
                      Time elapsed: 00:37:36
                               ETA: 00:19:10

################################################################################
                     [1m Learning iteration 994/1500 [0m                      

                       Computation: 47219 steps/s (collection: 1.963s, learning 0.119s)
             Mean action noise std: 4.20
          Mean value_function loss: 85.7283
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 87.7147
                       Mean reward: 313.50
               Mean episode length: 217.31
    Episode_Reward/reaching_object: 1.4773
    Episode_Reward/rotating_object: 58.3757
        Episode_Reward/action_rate: -0.1141
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 2.08s
                      Time elapsed: 00:37:38
                               ETA: 00:19:08

################################################################################
                     [1m Learning iteration 995/1500 [0m                      

                       Computation: 43045 steps/s (collection: 2.096s, learning 0.188s)
             Mean action noise std: 4.21
          Mean value_function loss: 78.4048
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 87.7465
                       Mean reward: 322.41
               Mean episode length: 224.51
    Episode_Reward/reaching_object: 1.4528
    Episode_Reward/rotating_object: 56.7705
        Episode_Reward/action_rate: -0.1132
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 2.28s
                      Time elapsed: 00:37:40
                               ETA: 00:19:06

################################################################################
                     [1m Learning iteration 996/1500 [0m                      

                       Computation: 43293 steps/s (collection: 2.072s, learning 0.199s)
             Mean action noise std: 4.21
          Mean value_function loss: 90.6536
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 87.7804
                       Mean reward: 322.12
               Mean episode length: 224.59
    Episode_Reward/reaching_object: 1.4419
    Episode_Reward/rotating_object: 57.7706
        Episode_Reward/action_rate: -0.1134
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 2.27s
                      Time elapsed: 00:37:43
                               ETA: 00:19:04

################################################################################
                     [1m Learning iteration 997/1500 [0m                      

                       Computation: 44018 steps/s (collection: 2.094s, learning 0.140s)
             Mean action noise std: 4.22
          Mean value_function loss: 85.4851
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 87.8134
                       Mean reward: 257.70
               Mean episode length: 204.45
    Episode_Reward/reaching_object: 1.3717
    Episode_Reward/rotating_object: 53.0922
        Episode_Reward/action_rate: -0.1085
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 2.23s
                      Time elapsed: 00:37:45
                               ETA: 00:19:01

################################################################################
                     [1m Learning iteration 998/1500 [0m                      

                       Computation: 43722 steps/s (collection: 2.088s, learning 0.160s)
             Mean action noise std: 4.22
          Mean value_function loss: 80.7465
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 87.8306
                       Mean reward: 261.92
               Mean episode length: 213.60
    Episode_Reward/reaching_object: 1.4062
    Episode_Reward/rotating_object: 53.3436
        Episode_Reward/action_rate: -0.1110
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 2.25s
                      Time elapsed: 00:37:47
                               ETA: 00:18:59

################################################################################
                     [1m Learning iteration 999/1500 [0m                      

                       Computation: 42459 steps/s (collection: 2.168s, learning 0.148s)
             Mean action noise std: 4.22
          Mean value_function loss: 85.1741
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 87.8540
                       Mean reward: 292.65
               Mean episode length: 216.27
    Episode_Reward/reaching_object: 1.4360
    Episode_Reward/rotating_object: 57.7369
        Episode_Reward/action_rate: -0.1130
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 2.32s
                      Time elapsed: 00:37:49
                               ETA: 00:18:57

################################################################################
                     [1m Learning iteration 1000/1500 [0m                     

                       Computation: 14467 steps/s (collection: 6.625s, learning 0.170s)
             Mean action noise std: 4.23
          Mean value_function loss: 88.1558
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 87.8874
                       Mean reward: 288.54
               Mean episode length: 196.95
    Episode_Reward/reaching_object: 1.4654
    Episode_Reward/rotating_object: 59.8858
        Episode_Reward/action_rate: -0.1139
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 6.79s
                      Time elapsed: 00:37:56
                               ETA: 00:18:57

################################################################################
                     [1m Learning iteration 1001/1500 [0m                     

                       Computation: 14114 steps/s (collection: 6.819s, learning 0.146s)
             Mean action noise std: 4.23
          Mean value_function loss: 87.9282
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 87.9150
                       Mean reward: 302.14
               Mean episode length: 206.30
    Episode_Reward/reaching_object: 1.4208
    Episode_Reward/rotating_object: 57.5963
        Episode_Reward/action_rate: -0.1115
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 6.96s
                      Time elapsed: 00:38:03
                               ETA: 00:18:57

################################################################################
                     [1m Learning iteration 1002/1500 [0m                     

                       Computation: 14226 steps/s (collection: 6.775s, learning 0.135s)
             Mean action noise std: 4.24
          Mean value_function loss: 88.2689
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 87.9496
                       Mean reward: 254.64
               Mean episode length: 209.18
    Episode_Reward/reaching_object: 1.4236
    Episode_Reward/rotating_object: 56.0437
        Episode_Reward/action_rate: -0.1140
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 6.91s
                      Time elapsed: 00:38:10
                               ETA: 00:18:57

################################################################################
                     [1m Learning iteration 1003/1500 [0m                     

                       Computation: 14553 steps/s (collection: 6.636s, learning 0.119s)
             Mean action noise std: 4.24
          Mean value_function loss: 81.6710
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 87.9752
                       Mean reward: 306.28
               Mean episode length: 223.80
    Episode_Reward/reaching_object: 1.4487
    Episode_Reward/rotating_object: 57.3649
        Episode_Reward/action_rate: -0.1152
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 6.75s
                      Time elapsed: 00:38:17
                               ETA: 00:18:57

################################################################################
                     [1m Learning iteration 1004/1500 [0m                     

                       Computation: 14320 steps/s (collection: 6.735s, learning 0.130s)
             Mean action noise std: 4.24
          Mean value_function loss: 85.3770
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 87.9981
                       Mean reward: 280.39
               Mean episode length: 221.66
    Episode_Reward/reaching_object: 1.4225
    Episode_Reward/rotating_object: 52.0926
        Episode_Reward/action_rate: -0.1147
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 6.86s
                      Time elapsed: 00:38:24
                               ETA: 00:18:57

################################################################################
                     [1m Learning iteration 1005/1500 [0m                     

                       Computation: 14320 steps/s (collection: 6.721s, learning 0.144s)
             Mean action noise std: 4.25
          Mean value_function loss: 92.3460
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 88.0229
                       Mean reward: 248.74
               Mean episode length: 217.85
    Episode_Reward/reaching_object: 1.4021
    Episode_Reward/rotating_object: 52.2042
        Episode_Reward/action_rate: -0.1140
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 6.86s
                      Time elapsed: 00:38:31
                               ETA: 00:18:57

################################################################################
                     [1m Learning iteration 1006/1500 [0m                     

                       Computation: 13958 steps/s (collection: 6.923s, learning 0.120s)
             Mean action noise std: 4.25
          Mean value_function loss: 93.7284
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 88.0450
                       Mean reward: 300.04
               Mean episode length: 216.77
    Episode_Reward/reaching_object: 1.4446
    Episode_Reward/rotating_object: 55.8613
        Episode_Reward/action_rate: -0.1160
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 7.04s
                      Time elapsed: 00:38:38
                               ETA: 00:18:57

################################################################################
                     [1m Learning iteration 1007/1500 [0m                     

                       Computation: 14007 steps/s (collection: 6.840s, learning 0.179s)
             Mean action noise std: 4.25
          Mean value_function loss: 97.8798
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 88.0696
                       Mean reward: 332.11
               Mean episode length: 223.09
    Episode_Reward/reaching_object: 1.4303
    Episode_Reward/rotating_object: 57.3034
        Episode_Reward/action_rate: -0.1134
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 7.02s
                      Time elapsed: 00:38:45
                               ETA: 00:18:57

################################################################################
                     [1m Learning iteration 1008/1500 [0m                     

                       Computation: 13189 steps/s (collection: 7.267s, learning 0.186s)
             Mean action noise std: 4.26
          Mean value_function loss: 92.3544
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 88.0872
                       Mean reward: 323.54
               Mean episode length: 215.06
    Episode_Reward/reaching_object: 1.3925
    Episode_Reward/rotating_object: 52.8741
        Episode_Reward/action_rate: -0.1126
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 7.45s
                      Time elapsed: 00:38:52
                               ETA: 00:18:57

################################################################################
                     [1m Learning iteration 1009/1500 [0m                     

                       Computation: 43714 steps/s (collection: 2.123s, learning 0.126s)
             Mean action noise std: 4.26
          Mean value_function loss: 89.8860
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 88.1064
                       Mean reward: 304.10
               Mean episode length: 218.81
    Episode_Reward/reaching_object: 1.4990
    Episode_Reward/rotating_object: 60.6501
        Episode_Reward/action_rate: -0.1180
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 2.25s
                      Time elapsed: 00:38:54
                               ETA: 00:18:55

################################################################################
                     [1m Learning iteration 1010/1500 [0m                     

                       Computation: 44328 steps/s (collection: 2.089s, learning 0.129s)
             Mean action noise std: 4.26
          Mean value_function loss: 92.3153
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 88.1224
                       Mean reward: 301.41
               Mean episode length: 218.91
    Episode_Reward/reaching_object: 1.4302
    Episode_Reward/rotating_object: 56.6486
        Episode_Reward/action_rate: -0.1148
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 2.22s
                      Time elapsed: 00:38:57
                               ETA: 00:18:52

################################################################################
                     [1m Learning iteration 1011/1500 [0m                     

                       Computation: 39768 steps/s (collection: 2.284s, learning 0.188s)
             Mean action noise std: 4.27
          Mean value_function loss: 94.0107
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 88.1451
                       Mean reward: 291.66
               Mean episode length: 218.19
    Episode_Reward/reaching_object: 1.4507
    Episode_Reward/rotating_object: 55.3503
        Episode_Reward/action_rate: -0.1176
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 2.47s
                      Time elapsed: 00:38:59
                               ETA: 00:18:50

################################################################################
                     [1m Learning iteration 1012/1500 [0m                     

                       Computation: 43440 steps/s (collection: 2.145s, learning 0.118s)
             Mean action noise std: 4.27
          Mean value_function loss: 84.4887
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 88.1741
                       Mean reward: 296.52
               Mean episode length: 213.72
    Episode_Reward/reaching_object: 1.3978
    Episode_Reward/rotating_object: 56.0543
        Episode_Reward/action_rate: -0.1123
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 2.26s
                      Time elapsed: 00:39:01
                               ETA: 00:18:48

################################################################################
                     [1m Learning iteration 1013/1500 [0m                     

                       Computation: 48064 steps/s (collection: 1.935s, learning 0.111s)
             Mean action noise std: 4.27
          Mean value_function loss: 77.9287
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 88.2020
                       Mean reward: 319.41
               Mean episode length: 217.82
    Episode_Reward/reaching_object: 1.4970
    Episode_Reward/rotating_object: 60.0416
        Episode_Reward/action_rate: -0.1196
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 2.05s
                      Time elapsed: 00:39:03
                               ETA: 00:18:45

################################################################################
                     [1m Learning iteration 1014/1500 [0m                     

                       Computation: 40966 steps/s (collection: 2.272s, learning 0.128s)
             Mean action noise std: 4.28
          Mean value_function loss: 88.5269
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 88.2248
                       Mean reward: 310.13
               Mean episode length: 209.71
    Episode_Reward/reaching_object: 1.4012
    Episode_Reward/rotating_object: 57.1252
        Episode_Reward/action_rate: -0.1134
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 2.40s
                      Time elapsed: 00:39:06
                               ETA: 00:18:43

################################################################################
                     [1m Learning iteration 1015/1500 [0m                     

                       Computation: 47625 steps/s (collection: 1.967s, learning 0.097s)
             Mean action noise std: 4.28
          Mean value_function loss: 92.3580
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 88.2515
                       Mean reward: 261.25
               Mean episode length: 217.20
    Episode_Reward/reaching_object: 1.4148
    Episode_Reward/rotating_object: 56.3226
        Episode_Reward/action_rate: -0.1152
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 2.06s
                      Time elapsed: 00:39:08
                               ETA: 00:18:41

################################################################################
                     [1m Learning iteration 1016/1500 [0m                     

                       Computation: 41602 steps/s (collection: 2.226s, learning 0.137s)
             Mean action noise std: 4.29
          Mean value_function loss: 92.8046
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 88.2829
                       Mean reward: 296.78
               Mean episode length: 199.30
    Episode_Reward/reaching_object: 1.4391
    Episode_Reward/rotating_object: 58.7503
        Episode_Reward/action_rate: -0.1173
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 2.36s
                      Time elapsed: 00:39:10
                               ETA: 00:18:38

################################################################################
                     [1m Learning iteration 1017/1500 [0m                     

                       Computation: 45240 steps/s (collection: 2.056s, learning 0.117s)
             Mean action noise std: 4.29
          Mean value_function loss: 84.1743
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 88.3131
                       Mean reward: 289.41
               Mean episode length: 215.31
    Episode_Reward/reaching_object: 1.4400
    Episode_Reward/rotating_object: 58.2203
        Episode_Reward/action_rate: -0.1169
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 2.17s
                      Time elapsed: 00:39:12
                               ETA: 00:18:36

################################################################################
                     [1m Learning iteration 1018/1500 [0m                     

                       Computation: 48663 steps/s (collection: 1.927s, learning 0.094s)
             Mean action noise std: 4.29
          Mean value_function loss: 86.5395
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 88.3407
                       Mean reward: 309.90
               Mean episode length: 214.46
    Episode_Reward/reaching_object: 1.3664
    Episode_Reward/rotating_object: 54.8652
        Episode_Reward/action_rate: -0.1129
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 2.02s
                      Time elapsed: 00:39:14
                               ETA: 00:18:33

################################################################################
                     [1m Learning iteration 1019/1500 [0m                     

                       Computation: 49232 steps/s (collection: 1.884s, learning 0.113s)
             Mean action noise std: 4.30
          Mean value_function loss: 79.8502
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 88.3676
                       Mean reward: 242.94
               Mean episode length: 214.69
    Episode_Reward/reaching_object: 1.3452
    Episode_Reward/rotating_object: 50.8326
        Episode_Reward/action_rate: -0.1125
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 2.00s
                      Time elapsed: 00:39:16
                               ETA: 00:18:31

################################################################################
                     [1m Learning iteration 1020/1500 [0m                     

                       Computation: 38160 steps/s (collection: 2.296s, learning 0.280s)
             Mean action noise std: 4.30
          Mean value_function loss: 79.4420
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 88.3960
                       Mean reward: 264.90
               Mean episode length: 208.44
    Episode_Reward/reaching_object: 1.3673
    Episode_Reward/rotating_object: 54.7876
        Episode_Reward/action_rate: -0.1148
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 2.58s
                      Time elapsed: 00:39:19
                               ETA: 00:18:29

################################################################################
                     [1m Learning iteration 1021/1500 [0m                     

                       Computation: 38851 steps/s (collection: 2.399s, learning 0.131s)
             Mean action noise std: 4.31
          Mean value_function loss: 85.5750
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 88.4311
                       Mean reward: 302.59
               Mean episode length: 231.22
    Episode_Reward/reaching_object: 1.4244
    Episode_Reward/rotating_object: 58.9260
        Episode_Reward/action_rate: -0.1184
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 2.53s
                      Time elapsed: 00:39:22
                               ETA: 00:18:27

################################################################################
                     [1m Learning iteration 1022/1500 [0m                     

                       Computation: 46445 steps/s (collection: 2.026s, learning 0.091s)
             Mean action noise std: 4.31
          Mean value_function loss: 85.8318
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 88.4581
                       Mean reward: 302.54
               Mean episode length: 203.29
    Episode_Reward/reaching_object: 1.3606
    Episode_Reward/rotating_object: 57.5893
        Episode_Reward/action_rate: -0.1125
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 2.12s
                      Time elapsed: 00:39:24
                               ETA: 00:18:24

################################################################################
                     [1m Learning iteration 1023/1500 [0m                     

                       Computation: 45351 steps/s (collection: 2.077s, learning 0.091s)
             Mean action noise std: 4.32
          Mean value_function loss: 80.8110
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 88.4857
                       Mean reward: 307.27
               Mean episode length: 224.03
    Episode_Reward/reaching_object: 1.3789
    Episode_Reward/rotating_object: 55.8240
        Episode_Reward/action_rate: -0.1161
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 2.17s
                      Time elapsed: 00:39:26
                               ETA: 00:18:22

################################################################################
                     [1m Learning iteration 1024/1500 [0m                     

                       Computation: 49266 steps/s (collection: 1.895s, learning 0.101s)
             Mean action noise std: 4.32
          Mean value_function loss: 85.4314
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 88.5079
                       Mean reward: 266.74
               Mean episode length: 216.28
    Episode_Reward/reaching_object: 1.4208
    Episode_Reward/rotating_object: 56.2627
        Episode_Reward/action_rate: -0.1182
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 2.00s
                      Time elapsed: 00:39:28
                               ETA: 00:18:19

################################################################################
                     [1m Learning iteration 1025/1500 [0m                     

                       Computation: 49225 steps/s (collection: 1.886s, learning 0.111s)
             Mean action noise std: 4.32
          Mean value_function loss: 91.7945
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 88.5321
                       Mean reward: 289.73
               Mean episode length: 205.05
    Episode_Reward/reaching_object: 1.3789
    Episode_Reward/rotating_object: 58.4355
        Episode_Reward/action_rate: -0.1162
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 2.00s
                      Time elapsed: 00:39:30
                               ETA: 00:18:17

################################################################################
                     [1m Learning iteration 1026/1500 [0m                     

                       Computation: 49664 steps/s (collection: 1.886s, learning 0.093s)
             Mean action noise std: 4.32
          Mean value_function loss: 83.2868
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 88.5522
                       Mean reward: 248.08
               Mean episode length: 206.56
    Episode_Reward/reaching_object: 1.4047
    Episode_Reward/rotating_object: 56.8374
        Episode_Reward/action_rate: -0.1172
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 1.98s
                      Time elapsed: 00:39:32
                               ETA: 00:18:14

################################################################################
                     [1m Learning iteration 1027/1500 [0m                     

                       Computation: 49343 steps/s (collection: 1.870s, learning 0.122s)
             Mean action noise std: 4.33
          Mean value_function loss: 79.5052
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 88.5720
                       Mean reward: 309.93
               Mean episode length: 215.35
    Episode_Reward/reaching_object: 1.4171
    Episode_Reward/rotating_object: 57.5343
        Episode_Reward/action_rate: -0.1185
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 1.99s
                      Time elapsed: 00:39:34
                               ETA: 00:18:12

################################################################################
                     [1m Learning iteration 1028/1500 [0m                     

                       Computation: 45984 steps/s (collection: 2.030s, learning 0.108s)
             Mean action noise std: 4.33
          Mean value_function loss: 75.0571
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 88.5926
                       Mean reward: 304.83
               Mean episode length: 214.04
    Episode_Reward/reaching_object: 1.3996
    Episode_Reward/rotating_object: 56.7539
        Episode_Reward/action_rate: -0.1174
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 2.14s
                      Time elapsed: 00:39:36
                               ETA: 00:18:10

################################################################################
                     [1m Learning iteration 1029/1500 [0m                     

                       Computation: 50717 steps/s (collection: 1.844s, learning 0.094s)
             Mean action noise std: 4.33
          Mean value_function loss: 75.5372
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 88.6105
                       Mean reward: 242.15
               Mean episode length: 205.14
    Episode_Reward/reaching_object: 1.4352
    Episode_Reward/rotating_object: 55.2528
        Episode_Reward/action_rate: -0.1197
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 1.94s
                      Time elapsed: 00:39:38
                               ETA: 00:18:07

################################################################################
                     [1m Learning iteration 1030/1500 [0m                     

                       Computation: 49350 steps/s (collection: 1.893s, learning 0.099s)
             Mean action noise std: 4.34
          Mean value_function loss: 82.3662
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 88.6336
                       Mean reward: 300.22
               Mean episode length: 215.55
    Episode_Reward/reaching_object: 1.4336
    Episode_Reward/rotating_object: 57.2482
        Episode_Reward/action_rate: -0.1206
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 1.99s
                      Time elapsed: 00:39:40
                               ETA: 00:18:05

################################################################################
                     [1m Learning iteration 1031/1500 [0m                     

                       Computation: 50628 steps/s (collection: 1.850s, learning 0.092s)
             Mean action noise std: 4.34
          Mean value_function loss: 85.4256
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 88.6580
                       Mean reward: 288.05
               Mean episode length: 219.39
    Episode_Reward/reaching_object: 1.4860
    Episode_Reward/rotating_object: 57.6836
        Episode_Reward/action_rate: -0.1227
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 1.94s
                      Time elapsed: 00:39:42
                               ETA: 00:18:02

################################################################################
                     [1m Learning iteration 1032/1500 [0m                     

                       Computation: 50848 steps/s (collection: 1.832s, learning 0.101s)
             Mean action noise std: 4.34
          Mean value_function loss: 88.3763
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 88.6819
                       Mean reward: 309.60
               Mean episode length: 211.21
    Episode_Reward/reaching_object: 1.4415
    Episode_Reward/rotating_object: 58.0410
        Episode_Reward/action_rate: -0.1208
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 1.93s
                      Time elapsed: 00:39:44
                               ETA: 00:18:00

################################################################################
                     [1m Learning iteration 1033/1500 [0m                     

                       Computation: 47098 steps/s (collection: 1.992s, learning 0.095s)
             Mean action noise std: 4.35
          Mean value_function loss: 80.0110
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 88.7056
                       Mean reward: 312.05
               Mean episode length: 209.95
    Episode_Reward/reaching_object: 1.4354
    Episode_Reward/rotating_object: 58.2383
        Episode_Reward/action_rate: -0.1203
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 2.09s
                      Time elapsed: 00:39:46
                               ETA: 00:17:57

################################################################################
                     [1m Learning iteration 1034/1500 [0m                     

                       Computation: 50461 steps/s (collection: 1.855s, learning 0.093s)
             Mean action noise std: 4.35
          Mean value_function loss: 86.9345
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 88.7302
                       Mean reward: 281.27
               Mean episode length: 217.18
    Episode_Reward/reaching_object: 1.4738
    Episode_Reward/rotating_object: 59.5614
        Episode_Reward/action_rate: -0.1237
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 1.95s
                      Time elapsed: 00:39:48
                               ETA: 00:17:55

################################################################################
                     [1m Learning iteration 1035/1500 [0m                     

                       Computation: 47506 steps/s (collection: 1.967s, learning 0.102s)
             Mean action noise std: 4.36
          Mean value_function loss: 79.1636
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 88.7541
                       Mean reward: 275.39
               Mean episode length: 211.03
    Episode_Reward/reaching_object: 1.4517
    Episode_Reward/rotating_object: 60.5202
        Episode_Reward/action_rate: -0.1220
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 2.07s
                      Time elapsed: 00:39:50
                               ETA: 00:17:52

################################################################################
                     [1m Learning iteration 1036/1500 [0m                     

                       Computation: 46510 steps/s (collection: 2.023s, learning 0.091s)
             Mean action noise std: 4.36
          Mean value_function loss: 80.3770
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 88.7785
                       Mean reward: 283.75
               Mean episode length: 207.56
    Episode_Reward/reaching_object: 1.4551
    Episode_Reward/rotating_object: 59.8022
        Episode_Reward/action_rate: -0.1218
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 2.11s
                      Time elapsed: 00:39:52
                               ETA: 00:17:50

################################################################################
                     [1m Learning iteration 1037/1500 [0m                     

                       Computation: 49614 steps/s (collection: 1.889s, learning 0.093s)
             Mean action noise std: 4.36
          Mean value_function loss: 86.0171
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 88.7943
                       Mean reward: 298.66
               Mean episode length: 208.60
    Episode_Reward/reaching_object: 1.4341
    Episode_Reward/rotating_object: 56.4034
        Episode_Reward/action_rate: -0.1212
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 1.98s
                      Time elapsed: 00:39:54
                               ETA: 00:17:48

################################################################################
                     [1m Learning iteration 1038/1500 [0m                     

                       Computation: 46689 steps/s (collection: 2.003s, learning 0.102s)
             Mean action noise std: 4.36
          Mean value_function loss: 81.7406
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 88.8110
                       Mean reward: 316.98
               Mean episode length: 221.21
    Episode_Reward/reaching_object: 1.4421
    Episode_Reward/rotating_object: 58.8678
        Episode_Reward/action_rate: -0.1214
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 2.11s
                      Time elapsed: 00:39:56
                               ETA: 00:17:45

################################################################################
                     [1m Learning iteration 1039/1500 [0m                     

                       Computation: 49007 steps/s (collection: 1.894s, learning 0.112s)
             Mean action noise std: 4.37
          Mean value_function loss: 86.2592
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 88.8307
                       Mean reward: 278.61
               Mean episode length: 214.82
    Episode_Reward/reaching_object: 1.4716
    Episode_Reward/rotating_object: 61.0161
        Episode_Reward/action_rate: -0.1250
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 2.01s
                      Time elapsed: 00:39:58
                               ETA: 00:17:43

################################################################################
                     [1m Learning iteration 1040/1500 [0m                     

                       Computation: 50174 steps/s (collection: 1.845s, learning 0.114s)
             Mean action noise std: 4.37
          Mean value_function loss: 83.7255
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 88.8593
                       Mean reward: 285.29
               Mean episode length: 215.71
    Episode_Reward/reaching_object: 1.4831
    Episode_Reward/rotating_object: 60.0104
        Episode_Reward/action_rate: -0.1255
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 1.96s
                      Time elapsed: 00:40:00
                               ETA: 00:17:40

################################################################################
                     [1m Learning iteration 1041/1500 [0m                     

                       Computation: 48752 steps/s (collection: 1.917s, learning 0.100s)
             Mean action noise std: 4.38
          Mean value_function loss: 93.6387
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 88.8822
                       Mean reward: 318.40
               Mean episode length: 227.18
    Episode_Reward/reaching_object: 1.4621
    Episode_Reward/rotating_object: 56.6765
        Episode_Reward/action_rate: -0.1242
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 2.02s
                      Time elapsed: 00:40:02
                               ETA: 00:17:38

################################################################################
                     [1m Learning iteration 1042/1500 [0m                     

                       Computation: 48172 steps/s (collection: 1.940s, learning 0.101s)
             Mean action noise std: 4.38
          Mean value_function loss: 88.4162
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 88.8951
                       Mean reward: 268.65
               Mean episode length: 200.03
    Episode_Reward/reaching_object: 1.4114
    Episode_Reward/rotating_object: 57.3313
        Episode_Reward/action_rate: -0.1204
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 2.04s
                      Time elapsed: 00:40:04
                               ETA: 00:17:35

################################################################################
                     [1m Learning iteration 1043/1500 [0m                     

                       Computation: 49909 steps/s (collection: 1.865s, learning 0.105s)
             Mean action noise std: 4.38
          Mean value_function loss: 91.8931
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 88.9046
                       Mean reward: 287.35
               Mean episode length: 210.13
    Episode_Reward/reaching_object: 1.4175
    Episode_Reward/rotating_object: 54.6823
        Episode_Reward/action_rate: -0.1208
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 1.97s
                      Time elapsed: 00:40:06
                               ETA: 00:17:33

################################################################################
                     [1m Learning iteration 1044/1500 [0m                     

                       Computation: 51042 steps/s (collection: 1.837s, learning 0.089s)
             Mean action noise std: 4.38
          Mean value_function loss: 78.8121
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 88.9168
                       Mean reward: 275.97
               Mean episode length: 212.76
    Episode_Reward/reaching_object: 1.4386
    Episode_Reward/rotating_object: 56.0194
        Episode_Reward/action_rate: -0.1227
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 1.93s
                      Time elapsed: 00:40:08
                               ETA: 00:17:30

################################################################################
                     [1m Learning iteration 1045/1500 [0m                     

                       Computation: 48401 steps/s (collection: 1.935s, learning 0.096s)
             Mean action noise std: 4.39
          Mean value_function loss: 80.3573
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 88.9363
                       Mean reward: 333.20
               Mean episode length: 228.69
    Episode_Reward/reaching_object: 1.4537
    Episode_Reward/rotating_object: 59.8463
        Episode_Reward/action_rate: -0.1230
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 2.03s
                      Time elapsed: 00:40:10
                               ETA: 00:17:28

################################################################################
                     [1m Learning iteration 1046/1500 [0m                     

                       Computation: 47304 steps/s (collection: 1.979s, learning 0.099s)
             Mean action noise std: 4.39
          Mean value_function loss: 79.6977
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 88.9647
                       Mean reward: 291.35
               Mean episode length: 208.47
    Episode_Reward/reaching_object: 1.4815
    Episode_Reward/rotating_object: 61.4425
        Episode_Reward/action_rate: -0.1240
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 2.08s
                      Time elapsed: 00:40:12
                               ETA: 00:17:26

################################################################################
                     [1m Learning iteration 1047/1500 [0m                     

                       Computation: 46997 steps/s (collection: 2.003s, learning 0.089s)
             Mean action noise std: 4.39
          Mean value_function loss: 79.4519
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 88.9948
                       Mean reward: 304.59
               Mean episode length: 217.00
    Episode_Reward/reaching_object: 1.4677
    Episode_Reward/rotating_object: 57.5629
        Episode_Reward/action_rate: -0.1247
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 2.09s
                      Time elapsed: 00:40:14
                               ETA: 00:17:23

################################################################################
                     [1m Learning iteration 1048/1500 [0m                     

                       Computation: 49355 steps/s (collection: 1.899s, learning 0.093s)
             Mean action noise std: 4.40
          Mean value_function loss: 79.2483
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 89.0181
                       Mean reward: 286.89
               Mean episode length: 212.07
    Episode_Reward/reaching_object: 1.4668
    Episode_Reward/rotating_object: 59.8133
        Episode_Reward/action_rate: -0.1253
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 1.99s
                      Time elapsed: 00:40:16
                               ETA: 00:17:21

################################################################################
                     [1m Learning iteration 1049/1500 [0m                     

                       Computation: 49501 steps/s (collection: 1.893s, learning 0.093s)
             Mean action noise std: 4.40
          Mean value_function loss: 83.5355
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 89.0491
                       Mean reward: 332.38
               Mean episode length: 218.45
    Episode_Reward/reaching_object: 1.4437
    Episode_Reward/rotating_object: 60.1614
        Episode_Reward/action_rate: -0.1231
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 1.99s
                      Time elapsed: 00:40:18
                               ETA: 00:17:18

################################################################################
                     [1m Learning iteration 1050/1500 [0m                     

                       Computation: 50868 steps/s (collection: 1.842s, learning 0.091s)
             Mean action noise std: 4.41
          Mean value_function loss: 77.8245
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 89.0807
                       Mean reward: 360.95
               Mean episode length: 225.47
    Episode_Reward/reaching_object: 1.4243
    Episode_Reward/rotating_object: 58.1268
        Episode_Reward/action_rate: -0.1235
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 1.93s
                      Time elapsed: 00:40:20
                               ETA: 00:17:16

################################################################################
                     [1m Learning iteration 1051/1500 [0m                     

                       Computation: 48994 steps/s (collection: 1.910s, learning 0.097s)
             Mean action noise std: 4.41
          Mean value_function loss: 85.8002
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 89.1154
                       Mean reward: 330.79
               Mean episode length: 218.40
    Episode_Reward/reaching_object: 1.4334
    Episode_Reward/rotating_object: 59.7326
        Episode_Reward/action_rate: -0.1243
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 2.01s
                      Time elapsed: 00:40:22
                               ETA: 00:17:13

################################################################################
                     [1m Learning iteration 1052/1500 [0m                     

                       Computation: 50968 steps/s (collection: 1.836s, learning 0.093s)
             Mean action noise std: 4.42
          Mean value_function loss: 86.1498
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 89.1458
                       Mean reward: 314.53
               Mean episode length: 212.02
    Episode_Reward/reaching_object: 1.4222
    Episode_Reward/rotating_object: 60.5586
        Episode_Reward/action_rate: -0.1228
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 1.93s
                      Time elapsed: 00:40:24
                               ETA: 00:17:11

################################################################################
                     [1m Learning iteration 1053/1500 [0m                     

                       Computation: 50466 steps/s (collection: 1.842s, learning 0.106s)
             Mean action noise std: 4.42
          Mean value_function loss: 88.7924
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 89.1654
                       Mean reward: 302.22
               Mean episode length: 213.43
    Episode_Reward/reaching_object: 1.4410
    Episode_Reward/rotating_object: 60.5629
        Episode_Reward/action_rate: -0.1248
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 1.95s
                      Time elapsed: 00:40:26
                               ETA: 00:17:09

################################################################################
                     [1m Learning iteration 1054/1500 [0m                     

                       Computation: 50381 steps/s (collection: 1.839s, learning 0.113s)
             Mean action noise std: 4.42
          Mean value_function loss: 88.6431
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 89.1886
                       Mean reward: 297.75
               Mean episode length: 209.18
    Episode_Reward/reaching_object: 1.3953
    Episode_Reward/rotating_object: 56.3525
        Episode_Reward/action_rate: -0.1216
          Episode_Reward/joint_vel: -0.0353
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 1.95s
                      Time elapsed: 00:40:28
                               ETA: 00:17:06

################################################################################
                     [1m Learning iteration 1055/1500 [0m                     

                       Computation: 49693 steps/s (collection: 1.870s, learning 0.109s)
             Mean action noise std: 4.43
          Mean value_function loss: 96.5597
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 89.2031
                       Mean reward: 290.64
               Mean episode length: 207.92
    Episode_Reward/reaching_object: 1.4098
    Episode_Reward/rotating_object: 55.7138
        Episode_Reward/action_rate: -0.1221
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 1.98s
                      Time elapsed: 00:40:30
                               ETA: 00:17:04

################################################################################
                     [1m Learning iteration 1056/1500 [0m                     

                       Computation: 49849 steps/s (collection: 1.864s, learning 0.108s)
             Mean action noise std: 4.43
          Mean value_function loss: 84.8060
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 89.2282
                       Mean reward: 302.52
               Mean episode length: 212.74
    Episode_Reward/reaching_object: 1.4280
    Episode_Reward/rotating_object: 60.6469
        Episode_Reward/action_rate: -0.1226
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 1.97s
                      Time elapsed: 00:40:32
                               ETA: 00:17:01

################################################################################
                     [1m Learning iteration 1057/1500 [0m                     

                       Computation: 50258 steps/s (collection: 1.857s, learning 0.099s)
             Mean action noise std: 4.43
          Mean value_function loss: 87.9863
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 89.2540
                       Mean reward: 282.15
               Mean episode length: 211.36
    Episode_Reward/reaching_object: 1.4465
    Episode_Reward/rotating_object: 58.6768
        Episode_Reward/action_rate: -0.1265
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 1.96s
                      Time elapsed: 00:40:34
                               ETA: 00:16:59

################################################################################
                     [1m Learning iteration 1058/1500 [0m                     

                       Computation: 49860 steps/s (collection: 1.879s, learning 0.093s)
             Mean action noise std: 4.44
          Mean value_function loss: 78.1635
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 89.2739
                       Mean reward: 326.82
               Mean episode length: 221.45
    Episode_Reward/reaching_object: 1.4630
    Episode_Reward/rotating_object: 61.9627
        Episode_Reward/action_rate: -0.1254
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 1.97s
                      Time elapsed: 00:40:36
                               ETA: 00:16:56

################################################################################
                     [1m Learning iteration 1059/1500 [0m                     

                       Computation: 50223 steps/s (collection: 1.848s, learning 0.109s)
             Mean action noise std: 4.44
          Mean value_function loss: 85.0196
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 89.2914
                       Mean reward: 323.76
               Mean episode length: 210.88
    Episode_Reward/reaching_object: 1.4641
    Episode_Reward/rotating_object: 61.9991
        Episode_Reward/action_rate: -0.1258
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 1.96s
                      Time elapsed: 00:40:38
                               ETA: 00:16:54

################################################################################
                     [1m Learning iteration 1060/1500 [0m                     

                       Computation: 48050 steps/s (collection: 1.955s, learning 0.091s)
             Mean action noise std: 4.44
          Mean value_function loss: 85.4000
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 89.3215
                       Mean reward: 335.65
               Mean episode length: 210.69
    Episode_Reward/reaching_object: 1.4731
    Episode_Reward/rotating_object: 62.6637
        Episode_Reward/action_rate: -0.1264
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 2.05s
                      Time elapsed: 00:40:40
                               ETA: 00:16:51

################################################################################
                     [1m Learning iteration 1061/1500 [0m                     

                       Computation: 50257 steps/s (collection: 1.861s, learning 0.095s)
             Mean action noise std: 4.45
          Mean value_function loss: 79.5568
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 89.3473
                       Mean reward: 345.87
               Mean episode length: 227.64
    Episode_Reward/reaching_object: 1.5012
    Episode_Reward/rotating_object: 64.7014
        Episode_Reward/action_rate: -0.1307
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 1.96s
                      Time elapsed: 00:40:42
                               ETA: 00:16:49

################################################################################
                     [1m Learning iteration 1062/1500 [0m                     

                       Computation: 49107 steps/s (collection: 1.909s, learning 0.093s)
             Mean action noise std: 4.45
          Mean value_function loss: 74.7897
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 89.3680
                       Mean reward: 293.86
               Mean episode length: 209.72
    Episode_Reward/reaching_object: 1.4183
    Episode_Reward/rotating_object: 59.6412
        Episode_Reward/action_rate: -0.1243
          Episode_Reward/joint_vel: -0.0353
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 2.00s
                      Time elapsed: 00:40:44
                               ETA: 00:16:47

################################################################################
                     [1m Learning iteration 1063/1500 [0m                     

                       Computation: 50201 steps/s (collection: 1.845s, learning 0.114s)
             Mean action noise std: 4.45
          Mean value_function loss: 78.9523
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 89.3847
                       Mean reward: 347.49
               Mean episode length: 225.55
    Episode_Reward/reaching_object: 1.4829
    Episode_Reward/rotating_object: 62.3912
        Episode_Reward/action_rate: -0.1292
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 1.96s
                      Time elapsed: 00:40:46
                               ETA: 00:16:44

################################################################################
                     [1m Learning iteration 1064/1500 [0m                     

                       Computation: 50456 steps/s (collection: 1.856s, learning 0.093s)
             Mean action noise std: 4.46
          Mean value_function loss: 87.6787
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 89.4073
                       Mean reward: 316.79
               Mean episode length: 215.67
    Episode_Reward/reaching_object: 1.4283
    Episode_Reward/rotating_object: 62.6442
        Episode_Reward/action_rate: -0.1239
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 1.95s
                      Time elapsed: 00:40:48
                               ETA: 00:16:42

################################################################################
                     [1m Learning iteration 1065/1500 [0m                     

                       Computation: 47744 steps/s (collection: 1.937s, learning 0.122s)
             Mean action noise std: 4.46
          Mean value_function loss: 86.6959
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 89.4365
                       Mean reward: 273.80
               Mean episode length: 219.15
    Episode_Reward/reaching_object: 1.4826
    Episode_Reward/rotating_object: 62.3114
        Episode_Reward/action_rate: -0.1295
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 2.06s
                      Time elapsed: 00:40:50
                               ETA: 00:16:39

################################################################################
                     [1m Learning iteration 1066/1500 [0m                     

                       Computation: 50295 steps/s (collection: 1.851s, learning 0.103s)
             Mean action noise std: 4.47
          Mean value_function loss: 85.8053
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 89.4547
                       Mean reward: 304.50
               Mean episode length: 228.98
    Episode_Reward/reaching_object: 1.4103
    Episode_Reward/rotating_object: 57.8112
        Episode_Reward/action_rate: -0.1264
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 1.95s
                      Time elapsed: 00:40:52
                               ETA: 00:16:37

################################################################################
                     [1m Learning iteration 1067/1500 [0m                     

                       Computation: 48292 steps/s (collection: 1.892s, learning 0.144s)
             Mean action noise std: 4.47
          Mean value_function loss: 91.4883
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 89.4754
                       Mean reward: 288.39
               Mean episode length: 201.58
    Episode_Reward/reaching_object: 1.4365
    Episode_Reward/rotating_object: 61.0737
        Episode_Reward/action_rate: -0.1246
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 2.04s
                      Time elapsed: 00:40:54
                               ETA: 00:16:35

################################################################################
                     [1m Learning iteration 1068/1500 [0m                     

                       Computation: 47193 steps/s (collection: 1.981s, learning 0.102s)
             Mean action noise std: 4.47
          Mean value_function loss: 92.5387
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 89.4964
                       Mean reward: 300.72
               Mean episode length: 221.22
    Episode_Reward/reaching_object: 1.4412
    Episode_Reward/rotating_object: 57.3765
        Episode_Reward/action_rate: -0.1280
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 2.08s
                      Time elapsed: 00:40:56
                               ETA: 00:16:32

################################################################################
                     [1m Learning iteration 1069/1500 [0m                     

                       Computation: 49849 steps/s (collection: 1.854s, learning 0.118s)
             Mean action noise std: 4.48
          Mean value_function loss: 88.1201
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 89.5165
                       Mean reward: 341.30
               Mean episode length: 228.17
    Episode_Reward/reaching_object: 1.5240
    Episode_Reward/rotating_object: 63.9487
        Episode_Reward/action_rate: -0.1325
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 1.97s
                      Time elapsed: 00:40:58
                               ETA: 00:16:30

################################################################################
                     [1m Learning iteration 1070/1500 [0m                     

                       Computation: 45408 steps/s (collection: 2.064s, learning 0.101s)
             Mean action noise std: 4.48
          Mean value_function loss: 100.9619
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 89.5365
                       Mean reward: 284.46
               Mean episode length: 206.45
    Episode_Reward/reaching_object: 1.4192
    Episode_Reward/rotating_object: 56.1946
        Episode_Reward/action_rate: -0.1259
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 2.16s
                      Time elapsed: 00:41:00
                               ETA: 00:16:27

################################################################################
                     [1m Learning iteration 1071/1500 [0m                     

                       Computation: 49676 steps/s (collection: 1.853s, learning 0.126s)
             Mean action noise std: 4.48
          Mean value_function loss: 94.6415
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 89.5585
                       Mean reward: 320.10
               Mean episode length: 211.62
    Episode_Reward/reaching_object: 1.4758
    Episode_Reward/rotating_object: 62.8700
        Episode_Reward/action_rate: -0.1281
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 1.98s
                      Time elapsed: 00:41:02
                               ETA: 00:16:25

################################################################################
                     [1m Learning iteration 1072/1500 [0m                     

                       Computation: 50453 steps/s (collection: 1.859s, learning 0.089s)
             Mean action noise std: 4.49
          Mean value_function loss: 84.6835
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 89.5859
                       Mean reward: 315.78
               Mean episode length: 215.69
    Episode_Reward/reaching_object: 1.5093
    Episode_Reward/rotating_object: 62.4366
        Episode_Reward/action_rate: -0.1313
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 1.95s
                      Time elapsed: 00:41:04
                               ETA: 00:16:22

################################################################################
                     [1m Learning iteration 1073/1500 [0m                     

                       Computation: 50099 steps/s (collection: 1.872s, learning 0.090s)
             Mean action noise std: 4.49
          Mean value_function loss: 76.3076
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 89.6093
                       Mean reward: 340.31
               Mean episode length: 222.37
    Episode_Reward/reaching_object: 1.4710
    Episode_Reward/rotating_object: 61.1976
        Episode_Reward/action_rate: -0.1296
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 1.96s
                      Time elapsed: 00:41:06
                               ETA: 00:16:20

################################################################################
                     [1m Learning iteration 1074/1500 [0m                     

                       Computation: 50644 steps/s (collection: 1.845s, learning 0.096s)
             Mean action noise std: 4.50
          Mean value_function loss: 90.5932
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 89.6352
                       Mean reward: 395.24
               Mean episode length: 228.27
    Episode_Reward/reaching_object: 1.5352
    Episode_Reward/rotating_object: 70.2843
        Episode_Reward/action_rate: -0.1306
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 1.94s
                      Time elapsed: 00:41:08
                               ETA: 00:16:18

################################################################################
                     [1m Learning iteration 1075/1500 [0m                     

                       Computation: 50411 steps/s (collection: 1.856s, learning 0.094s)
             Mean action noise std: 4.50
          Mean value_function loss: 82.6411
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 89.6625
                       Mean reward: 359.93
               Mean episode length: 222.00
    Episode_Reward/reaching_object: 1.5062
    Episode_Reward/rotating_object: 65.7505
        Episode_Reward/action_rate: -0.1299
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 1.95s
                      Time elapsed: 00:41:10
                               ETA: 00:16:15

################################################################################
                     [1m Learning iteration 1076/1500 [0m                     

                       Computation: 49375 steps/s (collection: 1.901s, learning 0.090s)
             Mean action noise std: 4.50
          Mean value_function loss: 92.2190
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 89.6811
                       Mean reward: 328.06
               Mean episode length: 212.87
    Episode_Reward/reaching_object: 1.4723
    Episode_Reward/rotating_object: 63.0689
        Episode_Reward/action_rate: -0.1282
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 1.99s
                      Time elapsed: 00:41:12
                               ETA: 00:16:13

################################################################################
                     [1m Learning iteration 1077/1500 [0m                     

                       Computation: 49117 steps/s (collection: 1.886s, learning 0.115s)
             Mean action noise std: 4.50
          Mean value_function loss: 86.5268
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 89.6947
                       Mean reward: 322.68
               Mean episode length: 217.13
    Episode_Reward/reaching_object: 1.5223
    Episode_Reward/rotating_object: 65.2425
        Episode_Reward/action_rate: -0.1307
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 2.00s
                      Time elapsed: 00:41:14
                               ETA: 00:16:10

################################################################################
                     [1m Learning iteration 1078/1500 [0m                     

                       Computation: 48715 steps/s (collection: 1.916s, learning 0.102s)
             Mean action noise std: 4.51
          Mean value_function loss: 91.3417
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 89.7148
                       Mean reward: 329.19
               Mean episode length: 223.22
    Episode_Reward/reaching_object: 1.4807
    Episode_Reward/rotating_object: 63.6982
        Episode_Reward/action_rate: -0.1300
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 2.02s
                      Time elapsed: 00:41:16
                               ETA: 00:16:08

################################################################################
                     [1m Learning iteration 1079/1500 [0m                     

                       Computation: 49957 steps/s (collection: 1.872s, learning 0.096s)
             Mean action noise std: 4.51
          Mean value_function loss: 89.9503
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 89.7414
                       Mean reward: 307.60
               Mean episode length: 206.42
    Episode_Reward/reaching_object: 1.3944
    Episode_Reward/rotating_object: 58.1746
        Episode_Reward/action_rate: -0.1229
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 1.97s
                      Time elapsed: 00:41:18
                               ETA: 00:16:06

################################################################################
                     [1m Learning iteration 1080/1500 [0m                     

                       Computation: 49270 steps/s (collection: 1.895s, learning 0.100s)
             Mean action noise std: 4.52
          Mean value_function loss: 95.5224
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 89.7702
                       Mean reward: 310.72
               Mean episode length: 213.81
    Episode_Reward/reaching_object: 1.4710
    Episode_Reward/rotating_object: 65.8286
        Episode_Reward/action_rate: -0.1282
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 2.00s
                      Time elapsed: 00:41:20
                               ETA: 00:16:03

################################################################################
                     [1m Learning iteration 1081/1500 [0m                     

                       Computation: 49477 steps/s (collection: 1.881s, learning 0.106s)
             Mean action noise std: 4.52
          Mean value_function loss: 92.3205
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 89.7950
                       Mean reward: 332.21
               Mean episode length: 220.60
    Episode_Reward/reaching_object: 1.4572
    Episode_Reward/rotating_object: 64.5389
        Episode_Reward/action_rate: -0.1273
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 1.99s
                      Time elapsed: 00:41:22
                               ETA: 00:16:01

################################################################################
                     [1m Learning iteration 1082/1500 [0m                     

                       Computation: 50021 steps/s (collection: 1.867s, learning 0.099s)
             Mean action noise std: 4.52
          Mean value_function loss: 90.3840
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 89.8135
                       Mean reward: 326.00
               Mean episode length: 203.82
    Episode_Reward/reaching_object: 1.3875
    Episode_Reward/rotating_object: 59.7918
        Episode_Reward/action_rate: -0.1243
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 1.97s
                      Time elapsed: 00:41:24
                               ETA: 00:15:58

################################################################################
                     [1m Learning iteration 1083/1500 [0m                     

                       Computation: 49027 steps/s (collection: 1.905s, learning 0.100s)
             Mean action noise std: 4.53
          Mean value_function loss: 85.4397
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 89.8359
                       Mean reward: 292.17
               Mean episode length: 202.06
    Episode_Reward/reaching_object: 1.4475
    Episode_Reward/rotating_object: 63.0890
        Episode_Reward/action_rate: -0.1278
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 2.01s
                      Time elapsed: 00:41:26
                               ETA: 00:15:56

################################################################################
                     [1m Learning iteration 1084/1500 [0m                     

                       Computation: 49622 steps/s (collection: 1.885s, learning 0.096s)
             Mean action noise std: 4.53
          Mean value_function loss: 83.5906
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 89.8555
                       Mean reward: 316.13
               Mean episode length: 212.82
    Episode_Reward/reaching_object: 1.4209
    Episode_Reward/rotating_object: 61.0766
        Episode_Reward/action_rate: -0.1273
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 1.98s
                      Time elapsed: 00:41:28
                               ETA: 00:15:53

################################################################################
                     [1m Learning iteration 1085/1500 [0m                     

                       Computation: 50698 steps/s (collection: 1.826s, learning 0.113s)
             Mean action noise std: 4.53
          Mean value_function loss: 79.5351
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 89.8752
                       Mean reward: 350.39
               Mean episode length: 223.21
    Episode_Reward/reaching_object: 1.4953
    Episode_Reward/rotating_object: 67.0293
        Episode_Reward/action_rate: -0.1336
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 1.94s
                      Time elapsed: 00:41:30
                               ETA: 00:15:51

################################################################################
                     [1m Learning iteration 1086/1500 [0m                     

                       Computation: 50203 steps/s (collection: 1.852s, learning 0.106s)
             Mean action noise std: 4.54
          Mean value_function loss: 81.9309
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 89.9094
                       Mean reward: 367.44
               Mean episode length: 230.64
    Episode_Reward/reaching_object: 1.4901
    Episode_Reward/rotating_object: 69.0747
        Episode_Reward/action_rate: -0.1347
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 1.96s
                      Time elapsed: 00:41:31
                               ETA: 00:15:49

################################################################################
                     [1m Learning iteration 1087/1500 [0m                     

                       Computation: 50581 steps/s (collection: 1.849s, learning 0.094s)
             Mean action noise std: 4.55
          Mean value_function loss: 84.8539
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 89.9486
                       Mean reward: 357.65
               Mean episode length: 218.32
    Episode_Reward/reaching_object: 1.4786
    Episode_Reward/rotating_object: 67.0244
        Episode_Reward/action_rate: -0.1328
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 1.94s
                      Time elapsed: 00:41:33
                               ETA: 00:15:46

################################################################################
                     [1m Learning iteration 1088/1500 [0m                     

                       Computation: 49836 steps/s (collection: 1.872s, learning 0.100s)
             Mean action noise std: 4.55
          Mean value_function loss: 82.7993
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 89.9842
                       Mean reward: 318.25
               Mean episode length: 221.04
    Episode_Reward/reaching_object: 1.4454
    Episode_Reward/rotating_object: 60.9241
        Episode_Reward/action_rate: -0.1339
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 1.97s
                      Time elapsed: 00:41:35
                               ETA: 00:15:44

################################################################################
                     [1m Learning iteration 1089/1500 [0m                     

                       Computation: 50665 steps/s (collection: 1.846s, learning 0.094s)
             Mean action noise std: 4.55
          Mean value_function loss: 88.8478
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 90.0079
                       Mean reward: 366.11
               Mean episode length: 217.13
    Episode_Reward/reaching_object: 1.4015
    Episode_Reward/rotating_object: 61.6692
        Episode_Reward/action_rate: -0.1291
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 1.94s
                      Time elapsed: 00:41:37
                               ETA: 00:15:41

################################################################################
                     [1m Learning iteration 1090/1500 [0m                     

                       Computation: 49149 steps/s (collection: 1.908s, learning 0.092s)
             Mean action noise std: 4.56
          Mean value_function loss: 88.4899
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 90.0368
                       Mean reward: 378.58
               Mean episode length: 216.12
    Episode_Reward/reaching_object: 1.4331
    Episode_Reward/rotating_object: 64.8092
        Episode_Reward/action_rate: -0.1305
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 2.00s
                      Time elapsed: 00:41:39
                               ETA: 00:15:39

################################################################################
                     [1m Learning iteration 1091/1500 [0m                     

                       Computation: 50176 steps/s (collection: 1.867s, learning 0.093s)
             Mean action noise std: 4.56
          Mean value_function loss: 94.1181
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 90.0630
                       Mean reward: 363.80
               Mean episode length: 224.90
    Episode_Reward/reaching_object: 1.4732
    Episode_Reward/rotating_object: 67.0796
        Episode_Reward/action_rate: -0.1346
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 1.96s
                      Time elapsed: 00:41:41
                               ETA: 00:15:37

################################################################################
                     [1m Learning iteration 1092/1500 [0m                     

                       Computation: 49495 steps/s (collection: 1.897s, learning 0.089s)
             Mean action noise std: 4.56
          Mean value_function loss: 97.4013
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 90.0817
                       Mean reward: 377.81
               Mean episode length: 216.24
    Episode_Reward/reaching_object: 1.4028
    Episode_Reward/rotating_object: 62.7762
        Episode_Reward/action_rate: -0.1274
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 1.99s
                      Time elapsed: 00:41:43
                               ETA: 00:15:34

################################################################################
                     [1m Learning iteration 1093/1500 [0m                     

                       Computation: 50212 steps/s (collection: 1.865s, learning 0.093s)
             Mean action noise std: 4.57
          Mean value_function loss: 93.5863
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 90.1001
                       Mean reward: 301.69
               Mean episode length: 213.92
    Episode_Reward/reaching_object: 1.4025
    Episode_Reward/rotating_object: 61.5151
        Episode_Reward/action_rate: -0.1300
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 1.96s
                      Time elapsed: 00:41:45
                               ETA: 00:15:32

################################################################################
                     [1m Learning iteration 1094/1500 [0m                     

                       Computation: 49902 steps/s (collection: 1.876s, learning 0.094s)
             Mean action noise std: 4.57
          Mean value_function loss: 95.6543
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 90.1211
                       Mean reward: 296.37
               Mean episode length: 206.46
    Episode_Reward/reaching_object: 1.4574
    Episode_Reward/rotating_object: 61.2560
        Episode_Reward/action_rate: -0.1338
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 1.97s
                      Time elapsed: 00:41:47
                               ETA: 00:15:29

################################################################################
                     [1m Learning iteration 1095/1500 [0m                     

                       Computation: 48644 steps/s (collection: 1.914s, learning 0.107s)
             Mean action noise std: 4.57
          Mean value_function loss: 97.3399
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 90.1382
                       Mean reward: 340.28
               Mean episode length: 208.69
    Episode_Reward/reaching_object: 1.4753
    Episode_Reward/rotating_object: 67.5121
        Episode_Reward/action_rate: -0.1327
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 2.02s
                      Time elapsed: 00:41:49
                               ETA: 00:15:27

################################################################################
                     [1m Learning iteration 1096/1500 [0m                     

                       Computation: 49589 steps/s (collection: 1.882s, learning 0.100s)
             Mean action noise std: 4.58
          Mean value_function loss: 91.4641
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 90.1510
                       Mean reward: 317.42
               Mean episode length: 215.76
    Episode_Reward/reaching_object: 1.4565
    Episode_Reward/rotating_object: 63.4110
        Episode_Reward/action_rate: -0.1330
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 1.98s
                      Time elapsed: 00:41:51
                               ETA: 00:15:25

################################################################################
                     [1m Learning iteration 1097/1500 [0m                     

                       Computation: 49917 steps/s (collection: 1.875s, learning 0.094s)
             Mean action noise std: 4.58
          Mean value_function loss: 89.0804
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 90.1763
                       Mean reward: 333.58
               Mean episode length: 226.11
    Episode_Reward/reaching_object: 1.4620
    Episode_Reward/rotating_object: 62.7848
        Episode_Reward/action_rate: -0.1347
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 1.97s
                      Time elapsed: 00:41:53
                               ETA: 00:15:22

################################################################################
                     [1m Learning iteration 1098/1500 [0m                     

                       Computation: 48093 steps/s (collection: 1.950s, learning 0.095s)
             Mean action noise std: 4.58
          Mean value_function loss: 83.1303
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 90.1963
                       Mean reward: 338.88
               Mean episode length: 216.29
    Episode_Reward/reaching_object: 1.4291
    Episode_Reward/rotating_object: 61.0908
        Episode_Reward/action_rate: -0.1311
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 2.04s
                      Time elapsed: 00:41:55
                               ETA: 00:15:20

################################################################################
                     [1m Learning iteration 1099/1500 [0m                     

                       Computation: 50617 steps/s (collection: 1.848s, learning 0.095s)
             Mean action noise std: 4.59
          Mean value_function loss: 87.1544
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 90.2139
                       Mean reward: 358.37
               Mean episode length: 225.27
    Episode_Reward/reaching_object: 1.4817
    Episode_Reward/rotating_object: 64.3670
        Episode_Reward/action_rate: -0.1357
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 1.94s
                      Time elapsed: 00:41:57
                               ETA: 00:15:17

################################################################################
                     [1m Learning iteration 1100/1500 [0m                     

                       Computation: 49990 steps/s (collection: 1.851s, learning 0.116s)
             Mean action noise std: 4.59
          Mean value_function loss: 79.0806
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 90.2379
                       Mean reward: 340.17
               Mean episode length: 217.62
    Episode_Reward/reaching_object: 1.4660
    Episode_Reward/rotating_object: 63.3525
        Episode_Reward/action_rate: -0.1339
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 1.97s
                      Time elapsed: 00:41:59
                               ETA: 00:15:15

################################################################################
                     [1m Learning iteration 1101/1500 [0m                     

                       Computation: 48970 steps/s (collection: 1.901s, learning 0.107s)
             Mean action noise std: 4.59
          Mean value_function loss: 95.4214
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 90.2608
                       Mean reward: 272.80
               Mean episode length: 193.53
    Episode_Reward/reaching_object: 1.4267
    Episode_Reward/rotating_object: 62.2378
        Episode_Reward/action_rate: -0.1313
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 2.01s
                      Time elapsed: 00:42:01
                               ETA: 00:15:13

################################################################################
                     [1m Learning iteration 1102/1500 [0m                     

                       Computation: 49939 steps/s (collection: 1.861s, learning 0.108s)
             Mean action noise std: 4.60
          Mean value_function loss: 88.5576
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 90.2761
                       Mean reward: 321.79
               Mean episode length: 208.48
    Episode_Reward/reaching_object: 1.4164
    Episode_Reward/rotating_object: 62.3427
        Episode_Reward/action_rate: -0.1306
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 1.97s
                      Time elapsed: 00:42:03
                               ETA: 00:15:10

################################################################################
                     [1m Learning iteration 1103/1500 [0m                     

                       Computation: 42891 steps/s (collection: 2.193s, learning 0.099s)
             Mean action noise std: 4.60
          Mean value_function loss: 90.7486
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 90.2931
                       Mean reward: 346.35
               Mean episode length: 206.96
    Episode_Reward/reaching_object: 1.4361
    Episode_Reward/rotating_object: 62.9553
        Episode_Reward/action_rate: -0.1329
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 2.29s
                      Time elapsed: 00:42:05
                               ETA: 00:15:08

################################################################################
                     [1m Learning iteration 1104/1500 [0m                     

                       Computation: 49140 steps/s (collection: 1.901s, learning 0.099s)
             Mean action noise std: 4.60
          Mean value_function loss: 91.3805
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 90.3164
                       Mean reward: 373.71
               Mean episode length: 225.93
    Episode_Reward/reaching_object: 1.4718
    Episode_Reward/rotating_object: 65.5426
        Episode_Reward/action_rate: -0.1359
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 2.00s
                      Time elapsed: 00:42:07
                               ETA: 00:15:05

################################################################################
                     [1m Learning iteration 1105/1500 [0m                     

                       Computation: 48534 steps/s (collection: 1.927s, learning 0.098s)
             Mean action noise std: 4.61
          Mean value_function loss: 85.0401
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 90.3512
                       Mean reward: 342.68
               Mean episode length: 219.80
    Episode_Reward/reaching_object: 1.5070
    Episode_Reward/rotating_object: 69.6770
        Episode_Reward/action_rate: -0.1367
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 2.03s
                      Time elapsed: 00:42:09
                               ETA: 00:15:03

################################################################################
                     [1m Learning iteration 1106/1500 [0m                     

                       Computation: 49162 steps/s (collection: 1.901s, learning 0.099s)
             Mean action noise std: 4.62
          Mean value_function loss: 89.7096
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 90.3894
                       Mean reward: 350.64
               Mean episode length: 218.97
    Episode_Reward/reaching_object: 1.3873
    Episode_Reward/rotating_object: 61.6360
        Episode_Reward/action_rate: -0.1293
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 2.00s
                      Time elapsed: 00:42:11
                               ETA: 00:15:01

################################################################################
                     [1m Learning iteration 1107/1500 [0m                     

                       Computation: 46068 steps/s (collection: 2.036s, learning 0.098s)
             Mean action noise std: 4.62
          Mean value_function loss: 87.1953
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 90.4238
                       Mean reward: 303.73
               Mean episode length: 215.87
    Episode_Reward/reaching_object: 1.4540
    Episode_Reward/rotating_object: 62.2703
        Episode_Reward/action_rate: -0.1363
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 2.13s
                      Time elapsed: 00:42:14
                               ETA: 00:14:58

################################################################################
                     [1m Learning iteration 1108/1500 [0m                     

                       Computation: 46644 steps/s (collection: 1.994s, learning 0.113s)
             Mean action noise std: 4.63
          Mean value_function loss: 81.8080
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 90.4503
                       Mean reward: 328.66
               Mean episode length: 212.04
    Episode_Reward/reaching_object: 1.4749
    Episode_Reward/rotating_object: 67.8142
        Episode_Reward/action_rate: -0.1368
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 2.11s
                      Time elapsed: 00:42:16
                               ETA: 00:14:56

################################################################################
                     [1m Learning iteration 1109/1500 [0m                     

                       Computation: 47275 steps/s (collection: 1.973s, learning 0.107s)
             Mean action noise std: 4.63
          Mean value_function loss: 77.5589
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 90.4727
                       Mean reward: 329.98
               Mean episode length: 214.27
    Episode_Reward/reaching_object: 1.5241
    Episode_Reward/rotating_object: 69.4147
        Episode_Reward/action_rate: -0.1413
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 2.08s
                      Time elapsed: 00:42:18
                               ETA: 00:14:54

################################################################################
                     [1m Learning iteration 1110/1500 [0m                     

                       Computation: 48606 steps/s (collection: 1.927s, learning 0.096s)
             Mean action noise std: 4.63
          Mean value_function loss: 83.0855
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 90.5049
                       Mean reward: 360.73
               Mean episode length: 224.57
    Episode_Reward/reaching_object: 1.4503
    Episode_Reward/rotating_object: 63.0468
        Episode_Reward/action_rate: -0.1362
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 2.02s
                      Time elapsed: 00:42:20
                               ETA: 00:14:51

################################################################################
                     [1m Learning iteration 1111/1500 [0m                     

                       Computation: 47006 steps/s (collection: 1.958s, learning 0.133s)
             Mean action noise std: 4.64
          Mean value_function loss: 95.7640
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 90.5289
                       Mean reward: 262.44
               Mean episode length: 203.03
    Episode_Reward/reaching_object: 1.4454
    Episode_Reward/rotating_object: 63.5081
        Episode_Reward/action_rate: -0.1375
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 2.09s
                      Time elapsed: 00:42:22
                               ETA: 00:14:49

################################################################################
                     [1m Learning iteration 1112/1500 [0m                     

                       Computation: 46483 steps/s (collection: 1.994s, learning 0.121s)
             Mean action noise std: 4.64
          Mean value_function loss: 94.4668
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 90.5469
                       Mean reward: 337.85
               Mean episode length: 212.39
    Episode_Reward/reaching_object: 1.4569
    Episode_Reward/rotating_object: 65.3503
        Episode_Reward/action_rate: -0.1377
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 2.11s
                      Time elapsed: 00:42:24
                               ETA: 00:14:47

################################################################################
                     [1m Learning iteration 1113/1500 [0m                     

                       Computation: 48711 steps/s (collection: 1.919s, learning 0.099s)
             Mean action noise std: 4.64
          Mean value_function loss: 83.0995
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 90.5672
                       Mean reward: 326.16
               Mean episode length: 213.91
    Episode_Reward/reaching_object: 1.4387
    Episode_Reward/rotating_object: 62.5457
        Episode_Reward/action_rate: -0.1361
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 2.02s
                      Time elapsed: 00:42:26
                               ETA: 00:14:44

################################################################################
                     [1m Learning iteration 1114/1500 [0m                     

                       Computation: 48716 steps/s (collection: 1.888s, learning 0.130s)
             Mean action noise std: 4.65
          Mean value_function loss: 94.3586
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 90.5870
                       Mean reward: 339.81
               Mean episode length: 228.97
    Episode_Reward/reaching_object: 1.4712
    Episode_Reward/rotating_object: 65.3751
        Episode_Reward/action_rate: -0.1397
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 2.02s
                      Time elapsed: 00:42:28
                               ETA: 00:14:42

################################################################################
                     [1m Learning iteration 1115/1500 [0m                     

                       Computation: 49902 steps/s (collection: 1.850s, learning 0.120s)
             Mean action noise std: 4.65
          Mean value_function loss: 91.9212
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 90.6064
                       Mean reward: 321.64
               Mean episode length: 210.73
    Episode_Reward/reaching_object: 1.4787
    Episode_Reward/rotating_object: 66.6057
        Episode_Reward/action_rate: -0.1387
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 1.97s
                      Time elapsed: 00:42:30
                               ETA: 00:14:39

################################################################################
                     [1m Learning iteration 1116/1500 [0m                     

                       Computation: 49241 steps/s (collection: 1.883s, learning 0.114s)
             Mean action noise std: 4.65
          Mean value_function loss: 100.2745
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 90.6220
                       Mean reward: 364.19
               Mean episode length: 229.21
    Episode_Reward/reaching_object: 1.4800
    Episode_Reward/rotating_object: 64.6689
        Episode_Reward/action_rate: -0.1403
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 2.00s
                      Time elapsed: 00:42:32
                               ETA: 00:14:37

################################################################################
                     [1m Learning iteration 1117/1500 [0m                     

                       Computation: 49992 steps/s (collection: 1.859s, learning 0.108s)
             Mean action noise std: 4.66
          Mean value_function loss: 93.3705
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 90.6353
                       Mean reward: 379.37
               Mean episode length: 213.25
    Episode_Reward/reaching_object: 1.4832
    Episode_Reward/rotating_object: 67.6528
        Episode_Reward/action_rate: -0.1389
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 1.97s
                      Time elapsed: 00:42:34
                               ETA: 00:14:35

################################################################################
                     [1m Learning iteration 1118/1500 [0m                     

                       Computation: 51108 steps/s (collection: 1.826s, learning 0.097s)
             Mean action noise std: 4.66
          Mean value_function loss: 81.3776
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 90.6568
                       Mean reward: 349.61
               Mean episode length: 217.95
    Episode_Reward/reaching_object: 1.5135
    Episode_Reward/rotating_object: 65.7273
        Episode_Reward/action_rate: -0.1411
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 1.92s
                      Time elapsed: 00:42:36
                               ETA: 00:14:32

################################################################################
                     [1m Learning iteration 1119/1500 [0m                     

                       Computation: 50319 steps/s (collection: 1.850s, learning 0.104s)
             Mean action noise std: 4.66
          Mean value_function loss: 80.1144
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 90.6774
                       Mean reward: 366.87
               Mean episode length: 227.71
    Episode_Reward/reaching_object: 1.4862
    Episode_Reward/rotating_object: 64.6146
        Episode_Reward/action_rate: -0.1415
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 1.95s
                      Time elapsed: 00:42:38
                               ETA: 00:14:30

################################################################################
                     [1m Learning iteration 1120/1500 [0m                     

                       Computation: 49849 steps/s (collection: 1.882s, learning 0.090s)
             Mean action noise std: 4.67
          Mean value_function loss: 91.6551
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 90.6977
                       Mean reward: 355.88
               Mean episode length: 213.79
    Episode_Reward/reaching_object: 1.4944
    Episode_Reward/rotating_object: 68.5621
        Episode_Reward/action_rate: -0.1409
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 1.97s
                      Time elapsed: 00:42:40
                               ETA: 00:14:27

################################################################################
                     [1m Learning iteration 1121/1500 [0m                     

                       Computation: 48837 steps/s (collection: 1.903s, learning 0.110s)
             Mean action noise std: 4.67
          Mean value_function loss: 88.5786
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 90.7238
                       Mean reward: 289.08
               Mean episode length: 213.14
    Episode_Reward/reaching_object: 1.4857
    Episode_Reward/rotating_object: 67.3100
        Episode_Reward/action_rate: -0.1400
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 2.01s
                      Time elapsed: 00:42:42
                               ETA: 00:14:25

################################################################################
                     [1m Learning iteration 1122/1500 [0m                     

                       Computation: 47225 steps/s (collection: 1.985s, learning 0.097s)
             Mean action noise std: 4.68
          Mean value_function loss: 74.6974
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 90.7479
                       Mean reward: 384.50
               Mean episode length: 222.38
    Episode_Reward/reaching_object: 1.5226
    Episode_Reward/rotating_object: 71.3199
        Episode_Reward/action_rate: -0.1422
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 2.08s
                      Time elapsed: 00:42:44
                               ETA: 00:14:23

################################################################################
                     [1m Learning iteration 1123/1500 [0m                     

                       Computation: 49233 steps/s (collection: 1.898s, learning 0.099s)
             Mean action noise std: 4.68
          Mean value_function loss: 78.0302
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 90.7632
                       Mean reward: 335.46
               Mean episode length: 214.84
    Episode_Reward/reaching_object: 1.4826
    Episode_Reward/rotating_object: 66.7170
        Episode_Reward/action_rate: -0.1417
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 2.00s
                      Time elapsed: 00:42:46
                               ETA: 00:14:20

################################################################################
                     [1m Learning iteration 1124/1500 [0m                     

                       Computation: 48168 steps/s (collection: 1.933s, learning 0.108s)
             Mean action noise std: 4.68
          Mean value_function loss: 82.8671
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 90.7798
                       Mean reward: 335.21
               Mean episode length: 223.92
    Episode_Reward/reaching_object: 1.4774
    Episode_Reward/rotating_object: 63.9818
        Episode_Reward/action_rate: -0.1416
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 2.04s
                      Time elapsed: 00:42:48
                               ETA: 00:14:18

################################################################################
                     [1m Learning iteration 1125/1500 [0m                     

                       Computation: 47679 steps/s (collection: 1.954s, learning 0.108s)
             Mean action noise std: 4.68
          Mean value_function loss: 91.5877
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 90.8056
                       Mean reward: 404.03
               Mean episode length: 218.81
    Episode_Reward/reaching_object: 1.5145
    Episode_Reward/rotating_object: 69.8619
        Episode_Reward/action_rate: -0.1417
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 2.06s
                      Time elapsed: 00:42:50
                               ETA: 00:14:16

################################################################################
                     [1m Learning iteration 1126/1500 [0m                     

                       Computation: 48464 steps/s (collection: 1.935s, learning 0.093s)
             Mean action noise std: 4.69
          Mean value_function loss: 97.7736
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 90.8253
                       Mean reward: 319.49
               Mean episode length: 216.37
    Episode_Reward/reaching_object: 1.4877
    Episode_Reward/rotating_object: 67.1717
        Episode_Reward/action_rate: -0.1407
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 2.03s
                      Time elapsed: 00:42:52
                               ETA: 00:14:13

################################################################################
                     [1m Learning iteration 1127/1500 [0m                     

                       Computation: 49420 steps/s (collection: 1.888s, learning 0.101s)
             Mean action noise std: 4.69
          Mean value_function loss: 87.4449
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 90.8449
                       Mean reward: 347.73
               Mean episode length: 226.40
    Episode_Reward/reaching_object: 1.4849
    Episode_Reward/rotating_object: 65.9180
        Episode_Reward/action_rate: -0.1418
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 1.99s
                      Time elapsed: 00:42:54
                               ETA: 00:14:11

################################################################################
                     [1m Learning iteration 1128/1500 [0m                     

                       Computation: 50271 steps/s (collection: 1.866s, learning 0.089s)
             Mean action noise std: 4.69
          Mean value_function loss: 94.2060
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 90.8608
                       Mean reward: 352.25
               Mean episode length: 211.24
    Episode_Reward/reaching_object: 1.4747
    Episode_Reward/rotating_object: 66.4292
        Episode_Reward/action_rate: -0.1377
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 1.96s
                      Time elapsed: 00:42:56
                               ETA: 00:14:08

################################################################################
                     [1m Learning iteration 1129/1500 [0m                     

                       Computation: 48578 steps/s (collection: 1.897s, learning 0.127s)
             Mean action noise std: 4.70
          Mean value_function loss: 82.6966
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 90.8744
                       Mean reward: 342.36
               Mean episode length: 228.16
    Episode_Reward/reaching_object: 1.5351
    Episode_Reward/rotating_object: 69.4812
        Episode_Reward/action_rate: -0.1458
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 2.02s
                      Time elapsed: 00:42:58
                               ETA: 00:14:06

################################################################################
                     [1m Learning iteration 1130/1500 [0m                     

                       Computation: 47371 steps/s (collection: 1.965s, learning 0.110s)
             Mean action noise std: 4.70
          Mean value_function loss: 83.4681
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 90.8885
                       Mean reward: 323.08
               Mean episode length: 205.91
    Episode_Reward/reaching_object: 1.4842
    Episode_Reward/rotating_object: 66.8811
        Episode_Reward/action_rate: -0.1398
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 2.08s
                      Time elapsed: 00:43:00
                               ETA: 00:14:04

################################################################################
                     [1m Learning iteration 1131/1500 [0m                     

                       Computation: 49864 steps/s (collection: 1.862s, learning 0.110s)
             Mean action noise std: 4.70
          Mean value_function loss: 92.9471
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 90.9060
                       Mean reward: 370.41
               Mean episode length: 230.19
    Episode_Reward/reaching_object: 1.5211
    Episode_Reward/rotating_object: 68.2339
        Episode_Reward/action_rate: -0.1448
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 1.97s
                      Time elapsed: 00:43:02
                               ETA: 00:14:01

################################################################################
                     [1m Learning iteration 1132/1500 [0m                     

                       Computation: 50254 steps/s (collection: 1.856s, learning 0.101s)
             Mean action noise std: 4.71
          Mean value_function loss: 88.6242
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 90.9222
                       Mean reward: 335.83
               Mean episode length: 200.96
    Episode_Reward/reaching_object: 1.5067
    Episode_Reward/rotating_object: 68.4595
        Episode_Reward/action_rate: -0.1431
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 1.96s
                      Time elapsed: 00:43:04
                               ETA: 00:13:59

################################################################################
                     [1m Learning iteration 1133/1500 [0m                     

                       Computation: 49938 steps/s (collection: 1.863s, learning 0.105s)
             Mean action noise std: 4.71
          Mean value_function loss: 91.7003
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 90.9426
                       Mean reward: 349.92
               Mean episode length: 216.82
    Episode_Reward/reaching_object: 1.5588
    Episode_Reward/rotating_object: 73.1228
        Episode_Reward/action_rate: -0.1458
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 1.97s
                      Time elapsed: 00:43:06
                               ETA: 00:13:57

################################################################################
                     [1m Learning iteration 1134/1500 [0m                     

                       Computation: 48691 steps/s (collection: 1.920s, learning 0.099s)
             Mean action noise std: 4.71
          Mean value_function loss: 83.9825
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 90.9615
                       Mean reward: 346.13
               Mean episode length: 217.08
    Episode_Reward/reaching_object: 1.5131
    Episode_Reward/rotating_object: 68.3421
        Episode_Reward/action_rate: -0.1438
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 2.02s
                      Time elapsed: 00:43:08
                               ETA: 00:13:54

################################################################################
                     [1m Learning iteration 1135/1500 [0m                     

                       Computation: 49601 steps/s (collection: 1.890s, learning 0.092s)
             Mean action noise std: 4.72
          Mean value_function loss: 83.3473
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 90.9830
                       Mean reward: 333.67
               Mean episode length: 224.84
    Episode_Reward/reaching_object: 1.4747
    Episode_Reward/rotating_object: 66.6140
        Episode_Reward/action_rate: -0.1417
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 1.98s
                      Time elapsed: 00:43:10
                               ETA: 00:13:52

################################################################################
                     [1m Learning iteration 1136/1500 [0m                     

                       Computation: 50120 steps/s (collection: 1.867s, learning 0.094s)
             Mean action noise std: 4.72
          Mean value_function loss: 86.0936
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 91.0117
                       Mean reward: 338.93
               Mean episode length: 210.41
    Episode_Reward/reaching_object: 1.5243
    Episode_Reward/rotating_object: 69.4758
        Episode_Reward/action_rate: -0.1445
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 1.96s
                      Time elapsed: 00:43:12
                               ETA: 00:13:49

################################################################################
                     [1m Learning iteration 1137/1500 [0m                     

                       Computation: 49736 steps/s (collection: 1.881s, learning 0.095s)
             Mean action noise std: 4.72
          Mean value_function loss: 91.2276
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 91.0318
                       Mean reward: 343.50
               Mean episode length: 224.89
    Episode_Reward/reaching_object: 1.5302
    Episode_Reward/rotating_object: 70.7020
        Episode_Reward/action_rate: -0.1446
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 1.98s
                      Time elapsed: 00:43:14
                               ETA: 00:13:47

################################################################################
                     [1m Learning iteration 1138/1500 [0m                     

                       Computation: 49709 steps/s (collection: 1.889s, learning 0.089s)
             Mean action noise std: 4.73
          Mean value_function loss: 85.4585
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 91.0480
                       Mean reward: 340.96
               Mean episode length: 207.71
    Episode_Reward/reaching_object: 1.5317
    Episode_Reward/rotating_object: 70.6961
        Episode_Reward/action_rate: -0.1463
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 1.98s
                      Time elapsed: 00:43:16
                               ETA: 00:13:45

################################################################################
                     [1m Learning iteration 1139/1500 [0m                     

                       Computation: 49052 steps/s (collection: 1.901s, learning 0.103s)
             Mean action noise std: 4.73
          Mean value_function loss: 90.5190
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 91.0639
                       Mean reward: 397.71
               Mean episode length: 225.79
    Episode_Reward/reaching_object: 1.4885
    Episode_Reward/rotating_object: 67.2098
        Episode_Reward/action_rate: -0.1422
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 2.00s
                      Time elapsed: 00:43:18
                               ETA: 00:13:42

################################################################################
                     [1m Learning iteration 1140/1500 [0m                     

                       Computation: 48790 steps/s (collection: 1.925s, learning 0.090s)
             Mean action noise std: 4.74
          Mean value_function loss: 86.5470
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 91.0873
                       Mean reward: 376.05
               Mean episode length: 225.46
    Episode_Reward/reaching_object: 1.4869
    Episode_Reward/rotating_object: 68.9967
        Episode_Reward/action_rate: -0.1424
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 2.01s
                      Time elapsed: 00:43:20
                               ETA: 00:13:40

################################################################################
                     [1m Learning iteration 1141/1500 [0m                     

                       Computation: 42837 steps/s (collection: 2.139s, learning 0.156s)
             Mean action noise std: 4.74
          Mean value_function loss: 88.7837
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 91.1193
                       Mean reward: 317.82
               Mean episode length: 207.04
    Episode_Reward/reaching_object: 1.5279
    Episode_Reward/rotating_object: 71.5473
        Episode_Reward/action_rate: -0.1468
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 2.29s
                      Time elapsed: 00:43:22
                               ETA: 00:13:38

################################################################################
                     [1m Learning iteration 1142/1500 [0m                     

                       Computation: 40362 steps/s (collection: 2.305s, learning 0.130s)
             Mean action noise std: 4.74
          Mean value_function loss: 89.3877
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 91.1432
                       Mean reward: 385.55
               Mean episode length: 225.19
    Episode_Reward/reaching_object: 1.4799
    Episode_Reward/rotating_object: 65.4770
        Episode_Reward/action_rate: -0.1442
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 2.44s
                      Time elapsed: 00:43:25
                               ETA: 00:13:35

################################################################################
                     [1m Learning iteration 1143/1500 [0m                     

                       Computation: 44467 steps/s (collection: 2.103s, learning 0.108s)
             Mean action noise std: 4.75
          Mean value_function loss: 88.5369
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 91.1686
                       Mean reward: 349.11
               Mean episode length: 216.10
    Episode_Reward/reaching_object: 1.4730
    Episode_Reward/rotating_object: 64.9198
        Episode_Reward/action_rate: -0.1419
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 2.21s
                      Time elapsed: 00:43:27
                               ETA: 00:13:33

################################################################################
                     [1m Learning iteration 1144/1500 [0m                     

                       Computation: 45206 steps/s (collection: 2.055s, learning 0.120s)
             Mean action noise std: 4.75
          Mean value_function loss: 84.0962
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 91.1937
                       Mean reward: 381.81
               Mean episode length: 228.46
    Episode_Reward/reaching_object: 1.5396
    Episode_Reward/rotating_object: 71.0035
        Episode_Reward/action_rate: -0.1496
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 2.17s
                      Time elapsed: 00:43:29
                               ETA: 00:13:31

################################################################################
                     [1m Learning iteration 1145/1500 [0m                     

                       Computation: 45186 steps/s (collection: 2.042s, learning 0.134s)
             Mean action noise std: 4.75
          Mean value_function loss: 88.2426
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 91.2103
                       Mean reward: 354.01
               Mean episode length: 214.23
    Episode_Reward/reaching_object: 1.4878
    Episode_Reward/rotating_object: 67.0017
        Episode_Reward/action_rate: -0.1453
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 2.18s
                      Time elapsed: 00:43:31
                               ETA: 00:13:29

################################################################################
                     [1m Learning iteration 1146/1500 [0m                     

                       Computation: 41319 steps/s (collection: 2.132s, learning 0.247s)
             Mean action noise std: 4.76
          Mean value_function loss: 95.6439
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 91.2255
                       Mean reward: 349.90
               Mean episode length: 220.97
    Episode_Reward/reaching_object: 1.5192
    Episode_Reward/rotating_object: 69.5190
        Episode_Reward/action_rate: -0.1471
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 2.38s
                      Time elapsed: 00:43:34
                               ETA: 00:13:26

################################################################################
                     [1m Learning iteration 1147/1500 [0m                     

                       Computation: 46588 steps/s (collection: 1.990s, learning 0.120s)
             Mean action noise std: 4.76
          Mean value_function loss: 86.6675
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 91.2515
                       Mean reward: 334.51
               Mean episode length: 208.83
    Episode_Reward/reaching_object: 1.4847
    Episode_Reward/rotating_object: 67.2686
        Episode_Reward/action_rate: -0.1452
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 2.11s
                      Time elapsed: 00:43:36
                               ETA: 00:13:24

################################################################################
                     [1m Learning iteration 1148/1500 [0m                     

                       Computation: 44943 steps/s (collection: 2.081s, learning 0.106s)
             Mean action noise std: 4.77
          Mean value_function loss: 80.2108
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 91.2788
                       Mean reward: 339.08
               Mean episode length: 208.99
    Episode_Reward/reaching_object: 1.4827
    Episode_Reward/rotating_object: 67.3103
        Episode_Reward/action_rate: -0.1448
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 2.19s
                      Time elapsed: 00:43:38
                               ETA: 00:13:22

################################################################################
                     [1m Learning iteration 1149/1500 [0m                     

                       Computation: 41431 steps/s (collection: 2.245s, learning 0.128s)
             Mean action noise std: 4.77
          Mean value_function loss: 98.1700
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 91.3023
                       Mean reward: 384.75
               Mean episode length: 217.83
    Episode_Reward/reaching_object: 1.4388
    Episode_Reward/rotating_object: 66.2405
        Episode_Reward/action_rate: -0.1398
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 2.37s
                      Time elapsed: 00:43:40
                               ETA: 00:13:19

################################################################################
                     [1m Learning iteration 1150/1500 [0m                     

                       Computation: 46929 steps/s (collection: 1.970s, learning 0.125s)
             Mean action noise std: 4.77
          Mean value_function loss: 80.6839
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 91.3192
                       Mean reward: 392.31
               Mean episode length: 223.52
    Episode_Reward/reaching_object: 1.4809
    Episode_Reward/rotating_object: 69.8219
        Episode_Reward/action_rate: -0.1442
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 2.09s
                      Time elapsed: 00:43:42
                               ETA: 00:13:17

################################################################################
                     [1m Learning iteration 1151/1500 [0m                     

                       Computation: 46809 steps/s (collection: 1.985s, learning 0.115s)
             Mean action noise std: 4.78
          Mean value_function loss: 87.3483
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 91.3440
                       Mean reward: 330.99
               Mean episode length: 210.66
    Episode_Reward/reaching_object: 1.4620
    Episode_Reward/rotating_object: 68.6884
        Episode_Reward/action_rate: -0.1437
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 2.10s
                      Time elapsed: 00:43:44
                               ETA: 00:13:15

################################################################################
                     [1m Learning iteration 1152/1500 [0m                     

                       Computation: 45404 steps/s (collection: 2.013s, learning 0.152s)
             Mean action noise std: 4.78
          Mean value_function loss: 85.4266
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 91.3748
                       Mean reward: 378.66
               Mean episode length: 217.09
    Episode_Reward/reaching_object: 1.5092
    Episode_Reward/rotating_object: 71.8681
        Episode_Reward/action_rate: -0.1479
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 2.17s
                      Time elapsed: 00:43:47
                               ETA: 00:13:12

################################################################################
                     [1m Learning iteration 1153/1500 [0m                     

                       Computation: 45128 steps/s (collection: 2.067s, learning 0.112s)
             Mean action noise std: 4.79
          Mean value_function loss: 86.3775
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 91.4018
                       Mean reward: 344.80
               Mean episode length: 218.25
    Episode_Reward/reaching_object: 1.4611
    Episode_Reward/rotating_object: 66.2931
        Episode_Reward/action_rate: -0.1442
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 2.18s
                      Time elapsed: 00:43:49
                               ETA: 00:13:10

################################################################################
                     [1m Learning iteration 1154/1500 [0m                     

                       Computation: 47642 steps/s (collection: 1.947s, learning 0.116s)
             Mean action noise std: 4.79
          Mean value_function loss: 90.2105
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 91.4247
                       Mean reward: 290.20
               Mean episode length: 201.07
    Episode_Reward/reaching_object: 1.4288
    Episode_Reward/rotating_object: 66.6667
        Episode_Reward/action_rate: -0.1414
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 2.06s
                      Time elapsed: 00:43:51
                               ETA: 00:13:08

################################################################################
                     [1m Learning iteration 1155/1500 [0m                     

                       Computation: 45456 steps/s (collection: 2.032s, learning 0.131s)
             Mean action noise std: 4.79
          Mean value_function loss: 89.3663
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 91.4468
                       Mean reward: 332.19
               Mean episode length: 222.45
    Episode_Reward/reaching_object: 1.4552
    Episode_Reward/rotating_object: 66.9431
        Episode_Reward/action_rate: -0.1439
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 2.16s
                      Time elapsed: 00:43:53
                               ETA: 00:13:05

################################################################################
                     [1m Learning iteration 1156/1500 [0m                     

                       Computation: 44417 steps/s (collection: 2.096s, learning 0.118s)
             Mean action noise std: 4.79
          Mean value_function loss: 90.3870
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 91.4585
                       Mean reward: 385.06
               Mean episode length: 224.99
    Episode_Reward/reaching_object: 1.5199
    Episode_Reward/rotating_object: 70.9230
        Episode_Reward/action_rate: -0.1479
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 2.21s
                      Time elapsed: 00:43:55
                               ETA: 00:13:03

################################################################################
                     [1m Learning iteration 1157/1500 [0m                     

                       Computation: 46790 steps/s (collection: 1.961s, learning 0.140s)
             Mean action noise std: 4.80
          Mean value_function loss: 88.5649
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 91.4714
                       Mean reward: 374.82
               Mean episode length: 215.70
    Episode_Reward/reaching_object: 1.4722
    Episode_Reward/rotating_object: 70.2589
        Episode_Reward/action_rate: -0.1443
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 2.10s
                      Time elapsed: 00:43:57
                               ETA: 00:13:01

################################################################################
                     [1m Learning iteration 1158/1500 [0m                     

                       Computation: 46013 steps/s (collection: 1.979s, learning 0.157s)
             Mean action noise std: 4.80
          Mean value_function loss: 88.4191
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 91.4848
                       Mean reward: 324.65
               Mean episode length: 215.69
    Episode_Reward/reaching_object: 1.4488
    Episode_Reward/rotating_object: 68.0067
        Episode_Reward/action_rate: -0.1441
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 2.14s
                      Time elapsed: 00:43:59
                               ETA: 00:12:59

################################################################################
                     [1m Learning iteration 1159/1500 [0m                     

                       Computation: 48003 steps/s (collection: 1.952s, learning 0.096s)
             Mean action noise std: 4.80
          Mean value_function loss: 87.9461
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 91.5029
                       Mean reward: 367.10
               Mean episode length: 218.00
    Episode_Reward/reaching_object: 1.5091
    Episode_Reward/rotating_object: 71.0974
        Episode_Reward/action_rate: -0.1475
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 2.05s
                      Time elapsed: 00:44:02
                               ETA: 00:12:56

################################################################################
                     [1m Learning iteration 1160/1500 [0m                     

                       Computation: 43966 steps/s (collection: 2.113s, learning 0.123s)
             Mean action noise std: 4.81
          Mean value_function loss: 86.5874
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 91.5202
                       Mean reward: 378.09
               Mean episode length: 217.38
    Episode_Reward/reaching_object: 1.5217
    Episode_Reward/rotating_object: 72.3768
        Episode_Reward/action_rate: -0.1495
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 2.24s
                      Time elapsed: 00:44:04
                               ETA: 00:12:54

################################################################################
                     [1m Learning iteration 1161/1500 [0m                     

                       Computation: 45244 steps/s (collection: 2.064s, learning 0.109s)
             Mean action noise std: 4.81
          Mean value_function loss: 86.3369
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 91.5375
                       Mean reward: 411.50
               Mean episode length: 228.76
    Episode_Reward/reaching_object: 1.5659
    Episode_Reward/rotating_object: 75.1001
        Episode_Reward/action_rate: -0.1524
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 2.17s
                      Time elapsed: 00:44:06
                               ETA: 00:12:52

################################################################################
                     [1m Learning iteration 1162/1500 [0m                     

                       Computation: 46121 steps/s (collection: 1.962s, learning 0.169s)
             Mean action noise std: 4.81
          Mean value_function loss: 89.2583
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 91.5579
                       Mean reward: 344.97
               Mean episode length: 212.19
    Episode_Reward/reaching_object: 1.4727
    Episode_Reward/rotating_object: 67.6917
        Episode_Reward/action_rate: -0.1464
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 2.13s
                      Time elapsed: 00:44:08
                               ETA: 00:12:49

################################################################################
                     [1m Learning iteration 1163/1500 [0m                     

                       Computation: 46975 steps/s (collection: 1.940s, learning 0.153s)
             Mean action noise std: 4.82
          Mean value_function loss: 96.5630
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 91.5834
                       Mean reward: 326.78
               Mean episode length: 213.06
    Episode_Reward/reaching_object: 1.4766
    Episode_Reward/rotating_object: 67.5916
        Episode_Reward/action_rate: -0.1471
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 2.09s
                      Time elapsed: 00:44:10
                               ETA: 00:12:47

################################################################################
                     [1m Learning iteration 1164/1500 [0m                     

                       Computation: 46182 steps/s (collection: 1.952s, learning 0.176s)
             Mean action noise std: 4.83
          Mean value_function loss: 95.5808
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 91.6179
                       Mean reward: 371.91
               Mean episode length: 229.74
    Episode_Reward/reaching_object: 1.5551
    Episode_Reward/rotating_object: 73.6548
        Episode_Reward/action_rate: -0.1539
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 2.13s
                      Time elapsed: 00:44:12
                               ETA: 00:12:45

################################################################################
                     [1m Learning iteration 1165/1500 [0m                     

                       Computation: 43532 steps/s (collection: 2.100s, learning 0.159s)
             Mean action noise std: 4.83
          Mean value_function loss: 96.2777
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 91.6454
                       Mean reward: 342.76
               Mean episode length: 219.42
    Episode_Reward/reaching_object: 1.5465
    Episode_Reward/rotating_object: 72.3859
        Episode_Reward/action_rate: -0.1508
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 2.26s
                      Time elapsed: 00:44:15
                               ETA: 00:12:42

################################################################################
                     [1m Learning iteration 1166/1500 [0m                     

                       Computation: 46021 steps/s (collection: 1.979s, learning 0.157s)
             Mean action noise std: 4.83
          Mean value_function loss: 88.8755
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 91.6598
                       Mean reward: 356.26
               Mean episode length: 218.32
    Episode_Reward/reaching_object: 1.5674
    Episode_Reward/rotating_object: 74.5435
        Episode_Reward/action_rate: -0.1517
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 2.14s
                      Time elapsed: 00:44:17
                               ETA: 00:12:40

################################################################################
                     [1m Learning iteration 1167/1500 [0m                     

                       Computation: 46345 steps/s (collection: 1.998s, learning 0.123s)
             Mean action noise std: 4.84
          Mean value_function loss: 86.2343
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 91.6789
                       Mean reward: 398.41
               Mean episode length: 207.42
    Episode_Reward/reaching_object: 1.6078
    Episode_Reward/rotating_object: 79.5097
        Episode_Reward/action_rate: -0.1543
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 2.12s
                      Time elapsed: 00:44:19
                               ETA: 00:12:38

################################################################################
                     [1m Learning iteration 1168/1500 [0m                     

                       Computation: 47387 steps/s (collection: 1.942s, learning 0.133s)
             Mean action noise std: 4.84
          Mean value_function loss: 87.0603
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 91.7032
                       Mean reward: 371.14
               Mean episode length: 215.54
    Episode_Reward/reaching_object: 1.5373
    Episode_Reward/rotating_object: 72.9032
        Episode_Reward/action_rate: -0.1489
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 2.07s
                      Time elapsed: 00:44:21
                               ETA: 00:12:35

################################################################################
                     [1m Learning iteration 1169/1500 [0m                     

                       Computation: 45996 steps/s (collection: 2.012s, learning 0.126s)
             Mean action noise std: 4.84
          Mean value_function loss: 96.0034
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 91.7208
                       Mean reward: 318.72
               Mean episode length: 209.38
    Episode_Reward/reaching_object: 1.4906
    Episode_Reward/rotating_object: 66.5644
        Episode_Reward/action_rate: -0.1490
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 2.14s
                      Time elapsed: 00:44:23
                               ETA: 00:12:33

################################################################################
                     [1m Learning iteration 1170/1500 [0m                     

                       Computation: 46679 steps/s (collection: 1.983s, learning 0.123s)
             Mean action noise std: 4.85
          Mean value_function loss: 86.6774
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 91.7397
                       Mean reward: 369.22
               Mean episode length: 214.79
    Episode_Reward/reaching_object: 1.4652
    Episode_Reward/rotating_object: 70.2940
        Episode_Reward/action_rate: -0.1440
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 2.11s
                      Time elapsed: 00:44:25
                               ETA: 00:12:31

################################################################################
                     [1m Learning iteration 1171/1500 [0m                     

                       Computation: 47440 steps/s (collection: 1.961s, learning 0.112s)
             Mean action noise std: 4.85
          Mean value_function loss: 89.0098
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 91.7576
                       Mean reward: 374.72
               Mean episode length: 228.56
    Episode_Reward/reaching_object: 1.5554
    Episode_Reward/rotating_object: 73.3387
        Episode_Reward/action_rate: -0.1541
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 2.07s
                      Time elapsed: 00:44:27
                               ETA: 00:12:28

################################################################################
                     [1m Learning iteration 1172/1500 [0m                     

                       Computation: 46630 steps/s (collection: 2.005s, learning 0.103s)
             Mean action noise std: 4.85
          Mean value_function loss: 76.4028
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 91.7699
                       Mean reward: 379.90
               Mean episode length: 231.85
    Episode_Reward/reaching_object: 1.5148
    Episode_Reward/rotating_object: 68.9538
        Episode_Reward/action_rate: -0.1512
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 2.11s
                      Time elapsed: 00:44:29
                               ETA: 00:12:26

################################################################################
                     [1m Learning iteration 1173/1500 [0m                     

                       Computation: 45626 steps/s (collection: 1.994s, learning 0.160s)
             Mean action noise std: 4.86
          Mean value_function loss: 87.4468
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 91.7873
                       Mean reward: 396.32
               Mean episode length: 226.56
    Episode_Reward/reaching_object: 1.5692
    Episode_Reward/rotating_object: 74.2828
        Episode_Reward/action_rate: -0.1541
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 2.15s
                      Time elapsed: 00:44:31
                               ETA: 00:12:24

################################################################################
                     [1m Learning iteration 1174/1500 [0m                     

                       Computation: 44503 steps/s (collection: 2.019s, learning 0.190s)
             Mean action noise std: 4.86
          Mean value_function loss: 80.4227
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 91.8126
                       Mean reward: 371.49
               Mean episode length: 225.39
    Episode_Reward/reaching_object: 1.6058
    Episode_Reward/rotating_object: 74.5730
        Episode_Reward/action_rate: -0.1587
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 2.21s
                      Time elapsed: 00:44:34
                               ETA: 00:12:21

################################################################################
                     [1m Learning iteration 1175/1500 [0m                     

                       Computation: 46099 steps/s (collection: 1.999s, learning 0.134s)
             Mean action noise std: 4.87
          Mean value_function loss: 92.4186
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 91.8499
                       Mean reward: 323.48
               Mean episode length: 208.65
    Episode_Reward/reaching_object: 1.5215
    Episode_Reward/rotating_object: 67.5996
        Episode_Reward/action_rate: -0.1530
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 2.13s
                      Time elapsed: 00:44:36
                               ETA: 00:12:19

################################################################################
                     [1m Learning iteration 1176/1500 [0m                     

                       Computation: 46456 steps/s (collection: 1.985s, learning 0.131s)
             Mean action noise std: 4.87
          Mean value_function loss: 81.3969
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 91.8778
                       Mean reward: 399.11
               Mean episode length: 221.59
    Episode_Reward/reaching_object: 1.5672
    Episode_Reward/rotating_object: 74.0249
        Episode_Reward/action_rate: -0.1557
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 2.12s
                      Time elapsed: 00:44:38
                               ETA: 00:12:17

################################################################################
                     [1m Learning iteration 1177/1500 [0m                     

                       Computation: 44841 steps/s (collection: 2.085s, learning 0.108s)
             Mean action noise std: 4.87
          Mean value_function loss: 92.8725
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 91.8985
                       Mean reward: 346.05
               Mean episode length: 216.30
    Episode_Reward/reaching_object: 1.5628
    Episode_Reward/rotating_object: 74.8348
        Episode_Reward/action_rate: -0.1531
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 2.19s
                      Time elapsed: 00:44:40
                               ETA: 00:12:14

################################################################################
                     [1m Learning iteration 1178/1500 [0m                     

                       Computation: 44134 steps/s (collection: 2.079s, learning 0.148s)
             Mean action noise std: 4.88
          Mean value_function loss: 86.1734
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 91.9201
                       Mean reward: 367.30
               Mean episode length: 218.36
    Episode_Reward/reaching_object: 1.4969
    Episode_Reward/rotating_object: 69.8368
        Episode_Reward/action_rate: -0.1504
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 2.23s
                      Time elapsed: 00:44:42
                               ETA: 00:12:12

################################################################################
                     [1m Learning iteration 1179/1500 [0m                     

                       Computation: 46342 steps/s (collection: 1.950s, learning 0.171s)
             Mean action noise std: 4.88
          Mean value_function loss: 86.8678
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 91.9378
                       Mean reward: 383.65
               Mean episode length: 213.66
    Episode_Reward/reaching_object: 1.5550
    Episode_Reward/rotating_object: 75.6457
        Episode_Reward/action_rate: -0.1530
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 2.12s
                      Time elapsed: 00:44:44
                               ETA: 00:12:10

################################################################################
                     [1m Learning iteration 1180/1500 [0m                     

                       Computation: 48081 steps/s (collection: 1.940s, learning 0.104s)
             Mean action noise std: 4.88
          Mean value_function loss: 88.1736
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 91.9483
                       Mean reward: 335.35
               Mean episode length: 216.42
    Episode_Reward/reaching_object: 1.5491
    Episode_Reward/rotating_object: 72.4322
        Episode_Reward/action_rate: -0.1551
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 2.04s
                      Time elapsed: 00:44:46
                               ETA: 00:12:08

################################################################################
                     [1m Learning iteration 1181/1500 [0m                     

                       Computation: 47442 steps/s (collection: 1.971s, learning 0.101s)
             Mean action noise std: 4.89
          Mean value_function loss: 87.5579
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 91.9624
                       Mean reward: 403.09
               Mean episode length: 225.07
    Episode_Reward/reaching_object: 1.5421
    Episode_Reward/rotating_object: 71.7690
        Episode_Reward/action_rate: -0.1585
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 2.07s
                      Time elapsed: 00:44:49
                               ETA: 00:12:05

################################################################################
                     [1m Learning iteration 1182/1500 [0m                     

                       Computation: 46006 steps/s (collection: 1.980s, learning 0.157s)
             Mean action noise std: 4.89
          Mean value_function loss: 86.4944
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 91.9794
                       Mean reward: 418.56
               Mean episode length: 221.96
    Episode_Reward/reaching_object: 1.5719
    Episode_Reward/rotating_object: 74.8412
        Episode_Reward/action_rate: -0.1567
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 2.14s
                      Time elapsed: 00:44:51
                               ETA: 00:12:03

################################################################################
                     [1m Learning iteration 1183/1500 [0m                     

                       Computation: 47177 steps/s (collection: 1.953s, learning 0.131s)
             Mean action noise std: 4.89
          Mean value_function loss: 86.9544
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 92.0003
                       Mean reward: 355.85
               Mean episode length: 224.65
    Episode_Reward/reaching_object: 1.5514
    Episode_Reward/rotating_object: 74.2119
        Episode_Reward/action_rate: -0.1557
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 2.08s
                      Time elapsed: 00:44:53
                               ETA: 00:12:01

################################################################################
                     [1m Learning iteration 1184/1500 [0m                     

                       Computation: 41731 steps/s (collection: 2.229s, learning 0.127s)
             Mean action noise std: 4.90
          Mean value_function loss: 84.1819
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 92.0215
                       Mean reward: 395.18
               Mean episode length: 226.48
    Episode_Reward/reaching_object: 1.5301
    Episode_Reward/rotating_object: 70.0417
        Episode_Reward/action_rate: -0.1557
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 2.36s
                      Time elapsed: 00:44:55
                               ETA: 00:11:58

################################################################################
                     [1m Learning iteration 1185/1500 [0m                     

                       Computation: 41359 steps/s (collection: 2.211s, learning 0.166s)
             Mean action noise std: 4.90
          Mean value_function loss: 82.6712
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 92.0395
                       Mean reward: 419.23
               Mean episode length: 228.94
    Episode_Reward/reaching_object: 1.5928
    Episode_Reward/rotating_object: 77.1903
        Episode_Reward/action_rate: -0.1586
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 2.38s
                      Time elapsed: 00:44:58
                               ETA: 00:11:56

################################################################################
                     [1m Learning iteration 1186/1500 [0m                     

                       Computation: 49745 steps/s (collection: 1.883s, learning 0.094s)
             Mean action noise std: 4.90
          Mean value_function loss: 97.8297
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 92.0622
                       Mean reward: 344.52
               Mean episode length: 211.11
    Episode_Reward/reaching_object: 1.5593
    Episode_Reward/rotating_object: 74.3261
        Episode_Reward/action_rate: -0.1559
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 1.98s
                      Time elapsed: 00:44:59
                               ETA: 00:11:54

################################################################################
                     [1m Learning iteration 1187/1500 [0m                     

                       Computation: 47864 steps/s (collection: 1.930s, learning 0.123s)
             Mean action noise std: 4.91
          Mean value_function loss: 90.8226
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 92.0916
                       Mean reward: 377.87
               Mean episode length: 216.04
    Episode_Reward/reaching_object: 1.5351
    Episode_Reward/rotating_object: 71.6178
        Episode_Reward/action_rate: -0.1555
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 2.05s
                      Time elapsed: 00:45:02
                               ETA: 00:11:51

################################################################################
                     [1m Learning iteration 1188/1500 [0m                     

                       Computation: 43879 steps/s (collection: 2.053s, learning 0.187s)
             Mean action noise std: 4.91
          Mean value_function loss: 83.1614
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 92.1166
                       Mean reward: 374.06
               Mean episode length: 228.57
    Episode_Reward/reaching_object: 1.5880
    Episode_Reward/rotating_object: 75.8652
        Episode_Reward/action_rate: -0.1594
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 2.24s
                      Time elapsed: 00:45:04
                               ETA: 00:11:49

################################################################################
                     [1m Learning iteration 1189/1500 [0m                     

                       Computation: 46973 steps/s (collection: 1.970s, learning 0.123s)
             Mean action noise std: 4.92
          Mean value_function loss: 87.6013
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 92.1400
                       Mean reward: 367.78
               Mean episode length: 227.14
    Episode_Reward/reaching_object: 1.6117
    Episode_Reward/rotating_object: 79.5375
        Episode_Reward/action_rate: -0.1587
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 2.09s
                      Time elapsed: 00:45:06
                               ETA: 00:11:47

################################################################################
                     [1m Learning iteration 1190/1500 [0m                     

                       Computation: 47530 steps/s (collection: 1.958s, learning 0.110s)
             Mean action noise std: 4.92
          Mean value_function loss: 87.5615
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 92.1548
                       Mean reward: 355.59
               Mean episode length: 217.16
    Episode_Reward/reaching_object: 1.5613
    Episode_Reward/rotating_object: 72.6647
        Episode_Reward/action_rate: -0.1584
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 2.07s
                      Time elapsed: 00:45:08
                               ETA: 00:11:44

################################################################################
                     [1m Learning iteration 1191/1500 [0m                     

                       Computation: 47371 steps/s (collection: 1.957s, learning 0.118s)
             Mean action noise std: 4.92
          Mean value_function loss: 87.6768
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 92.1696
                       Mean reward: 356.13
               Mean episode length: 222.87
    Episode_Reward/reaching_object: 1.5733
    Episode_Reward/rotating_object: 74.1914
        Episode_Reward/action_rate: -0.1591
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 2.08s
                      Time elapsed: 00:45:10
                               ETA: 00:11:42

################################################################################
                     [1m Learning iteration 1192/1500 [0m                     

                       Computation: 48335 steps/s (collection: 1.916s, learning 0.118s)
             Mean action noise std: 4.93
          Mean value_function loss: 83.0762
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 92.1897
                       Mean reward: 442.27
               Mean episode length: 232.34
    Episode_Reward/reaching_object: 1.5310
    Episode_Reward/rotating_object: 71.9934
        Episode_Reward/action_rate: -0.1565
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 2.03s
                      Time elapsed: 00:45:12
                               ETA: 00:11:40

################################################################################
                     [1m Learning iteration 1193/1500 [0m                     

                       Computation: 46516 steps/s (collection: 1.988s, learning 0.126s)
             Mean action noise std: 4.93
          Mean value_function loss: 81.8638
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 92.2089
                       Mean reward: 357.82
               Mean episode length: 226.92
    Episode_Reward/reaching_object: 1.6449
    Episode_Reward/rotating_object: 77.0811
        Episode_Reward/action_rate: -0.1633
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 2.11s
                      Time elapsed: 00:45:14
                               ETA: 00:11:37

################################################################################
                     [1m Learning iteration 1194/1500 [0m                     

                       Computation: 45985 steps/s (collection: 2.013s, learning 0.125s)
             Mean action noise std: 4.93
          Mean value_function loss: 82.0595
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 92.2332
                       Mean reward: 375.49
               Mean episode length: 212.91
    Episode_Reward/reaching_object: 1.5735
    Episode_Reward/rotating_object: 74.6544
        Episode_Reward/action_rate: -0.1599
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 2.14s
                      Time elapsed: 00:45:16
                               ETA: 00:11:35

################################################################################
                     [1m Learning iteration 1195/1500 [0m                     

                       Computation: 40638 steps/s (collection: 2.221s, learning 0.198s)
             Mean action noise std: 4.94
          Mean value_function loss: 84.3321
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 92.2573
                       Mean reward: 393.73
               Mean episode length: 220.90
    Episode_Reward/reaching_object: 1.5417
    Episode_Reward/rotating_object: 71.2582
        Episode_Reward/action_rate: -0.1590
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 2.42s
                      Time elapsed: 00:45:19
                               ETA: 00:11:33

################################################################################
                     [1m Learning iteration 1196/1500 [0m                     

                       Computation: 44890 steps/s (collection: 2.052s, learning 0.138s)
             Mean action noise std: 4.94
          Mean value_function loss: 76.8892
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 92.2781
                       Mean reward: 380.90
               Mean episode length: 218.64
    Episode_Reward/reaching_object: 1.5712
    Episode_Reward/rotating_object: 75.1783
        Episode_Reward/action_rate: -0.1605
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 2.19s
                      Time elapsed: 00:45:21
                               ETA: 00:11:31

################################################################################
                     [1m Learning iteration 1197/1500 [0m                     

                       Computation: 43873 steps/s (collection: 2.108s, learning 0.133s)
             Mean action noise std: 4.95
          Mean value_function loss: 85.8871
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 92.2991
                       Mean reward: 340.22
               Mean episode length: 209.86
    Episode_Reward/reaching_object: 1.5749
    Episode_Reward/rotating_object: 73.7288
        Episode_Reward/action_rate: -0.1614
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 2.24s
                      Time elapsed: 00:45:23
                               ETA: 00:11:28

################################################################################
                     [1m Learning iteration 1198/1500 [0m                     

                       Computation: 45444 steps/s (collection: 2.041s, learning 0.122s)
             Mean action noise std: 4.95
          Mean value_function loss: 93.1038
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 92.3235
                       Mean reward: 353.83
               Mean episode length: 217.20
    Episode_Reward/reaching_object: 1.5168
    Episode_Reward/rotating_object: 70.3252
        Episode_Reward/action_rate: -0.1573
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 2.16s
                      Time elapsed: 00:45:25
                               ETA: 00:11:26

################################################################################
                     [1m Learning iteration 1199/1500 [0m                     

                       Computation: 48198 steps/s (collection: 1.902s, learning 0.138s)
             Mean action noise std: 4.96
          Mean value_function loss: 84.5905
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 92.3517
                       Mean reward: 365.45
               Mean episode length: 219.71
    Episode_Reward/reaching_object: 1.5527
    Episode_Reward/rotating_object: 75.1991
        Episode_Reward/action_rate: -0.1604
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 2.04s
                      Time elapsed: 00:45:27
                               ETA: 00:11:24

################################################################################
                     [1m Learning iteration 1200/1500 [0m                     

                       Computation: 47987 steps/s (collection: 1.917s, learning 0.131s)
             Mean action noise std: 4.96
          Mean value_function loss: 84.9938
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 92.3758
                       Mean reward: 382.35
               Mean episode length: 216.67
    Episode_Reward/reaching_object: 1.5768
    Episode_Reward/rotating_object: 74.8689
        Episode_Reward/action_rate: -0.1635
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 2.05s
                      Time elapsed: 00:45:29
                               ETA: 00:11:21

################################################################################
                     [1m Learning iteration 1201/1500 [0m                     

                       Computation: 43911 steps/s (collection: 2.066s, learning 0.173s)
             Mean action noise std: 4.96
          Mean value_function loss: 79.2326
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 92.3957
                       Mean reward: 380.55
               Mean episode length: 226.09
    Episode_Reward/reaching_object: 1.5567
    Episode_Reward/rotating_object: 73.0980
        Episode_Reward/action_rate: -0.1623
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 2.24s
                      Time elapsed: 00:45:32
                               ETA: 00:11:19

################################################################################
                     [1m Learning iteration 1202/1500 [0m                     

                       Computation: 47057 steps/s (collection: 1.959s, learning 0.130s)
             Mean action noise std: 4.96
          Mean value_function loss: 90.6270
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 92.4098
                       Mean reward: 336.11
               Mean episode length: 214.07
    Episode_Reward/reaching_object: 1.5769
    Episode_Reward/rotating_object: 72.9032
        Episode_Reward/action_rate: -0.1620
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 2.09s
                      Time elapsed: 00:45:34
                               ETA: 00:11:17

################################################################################
                     [1m Learning iteration 1203/1500 [0m                     

                       Computation: 48667 steps/s (collection: 1.920s, learning 0.100s)
             Mean action noise std: 4.97
          Mean value_function loss: 87.9420
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 92.4185
                       Mean reward: 378.07
               Mean episode length: 224.88
    Episode_Reward/reaching_object: 1.5823
    Episode_Reward/rotating_object: 75.4135
        Episode_Reward/action_rate: -0.1623
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 2.02s
                      Time elapsed: 00:45:36
                               ETA: 00:11:14

################################################################################
                     [1m Learning iteration 1204/1500 [0m                     

                       Computation: 42583 steps/s (collection: 2.155s, learning 0.154s)
             Mean action noise std: 4.97
          Mean value_function loss: 78.6877
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 92.4399
                       Mean reward: 353.42
               Mean episode length: 218.58
    Episode_Reward/reaching_object: 1.6031
    Episode_Reward/rotating_object: 78.2235
        Episode_Reward/action_rate: -0.1651
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 2.31s
                      Time elapsed: 00:45:38
                               ETA: 00:11:12

################################################################################
                     [1m Learning iteration 1205/1500 [0m                     

                       Computation: 45115 steps/s (collection: 2.032s, learning 0.147s)
             Mean action noise std: 4.98
          Mean value_function loss: 82.3947
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 92.4628
                       Mean reward: 356.71
               Mean episode length: 215.13
    Episode_Reward/reaching_object: 1.5627
    Episode_Reward/rotating_object: 73.0279
        Episode_Reward/action_rate: -0.1639
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 2.18s
                      Time elapsed: 00:45:40
                               ETA: 00:11:10

################################################################################
                     [1m Learning iteration 1206/1500 [0m                     

                       Computation: 46649 steps/s (collection: 1.932s, learning 0.175s)
             Mean action noise std: 4.98
          Mean value_function loss: 88.8946
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 92.4823
                       Mean reward: 392.91
               Mean episode length: 226.66
    Episode_Reward/reaching_object: 1.6030
    Episode_Reward/rotating_object: 79.0302
        Episode_Reward/action_rate: -0.1656
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 2.11s
                      Time elapsed: 00:45:42
                               ETA: 00:11:08

################################################################################
                     [1m Learning iteration 1207/1500 [0m                     

                       Computation: 43501 steps/s (collection: 2.130s, learning 0.130s)
             Mean action noise std: 4.98
          Mean value_function loss: 85.2990
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 92.4991
                       Mean reward: 359.10
               Mean episode length: 225.73
    Episode_Reward/reaching_object: 1.5665
    Episode_Reward/rotating_object: 73.8259
        Episode_Reward/action_rate: -0.1637
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 2.26s
                      Time elapsed: 00:45:45
                               ETA: 00:11:05

################################################################################
                     [1m Learning iteration 1208/1500 [0m                     

                       Computation: 47465 steps/s (collection: 1.957s, learning 0.114s)
             Mean action noise std: 4.99
          Mean value_function loss: 90.3695
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 92.5215
                       Mean reward: 323.27
               Mean episode length: 199.57
    Episode_Reward/reaching_object: 1.5250
    Episode_Reward/rotating_object: 71.2354
        Episode_Reward/action_rate: -0.1609
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 2.07s
                      Time elapsed: 00:45:47
                               ETA: 00:11:03

################################################################################
                     [1m Learning iteration 1209/1500 [0m                     

                       Computation: 44669 steps/s (collection: 1.993s, learning 0.208s)
             Mean action noise std: 4.99
          Mean value_function loss: 88.9495
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 92.5451
                       Mean reward: 349.74
               Mean episode length: 220.01
    Episode_Reward/reaching_object: 1.5379
    Episode_Reward/rotating_object: 72.3774
        Episode_Reward/action_rate: -0.1628
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 2.20s
                      Time elapsed: 00:45:49
                               ETA: 00:11:01

################################################################################
                     [1m Learning iteration 1210/1500 [0m                     

                       Computation: 45939 steps/s (collection: 1.979s, learning 0.161s)
             Mean action noise std: 4.99
          Mean value_function loss: 80.8770
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 92.5639
                       Mean reward: 380.23
               Mean episode length: 223.89
    Episode_Reward/reaching_object: 1.5911
    Episode_Reward/rotating_object: 76.0279
        Episode_Reward/action_rate: -0.1662
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 2.14s
                      Time elapsed: 00:45:51
                               ETA: 00:10:58

################################################################################
                     [1m Learning iteration 1211/1500 [0m                     

                       Computation: 45789 steps/s (collection: 2.022s, learning 0.125s)
             Mean action noise std: 5.00
          Mean value_function loss: 82.4955
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 92.5734
                       Mean reward: 384.85
               Mean episode length: 211.04
    Episode_Reward/reaching_object: 1.5352
    Episode_Reward/rotating_object: 71.5375
        Episode_Reward/action_rate: -0.1619
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 2.15s
                      Time elapsed: 00:45:53
                               ETA: 00:10:56

################################################################################
                     [1m Learning iteration 1212/1500 [0m                     

                       Computation: 45805 steps/s (collection: 2.028s, learning 0.118s)
             Mean action noise std: 5.00
          Mean value_function loss: 83.7320
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 92.5853
                       Mean reward: 338.75
               Mean episode length: 218.52
    Episode_Reward/reaching_object: 1.5866
    Episode_Reward/rotating_object: 76.9201
        Episode_Reward/action_rate: -0.1657
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 2.15s
                      Time elapsed: 00:45:55
                               ETA: 00:10:54

################################################################################
                     [1m Learning iteration 1213/1500 [0m                     

                       Computation: 46263 steps/s (collection: 1.995s, learning 0.130s)
             Mean action noise std: 5.00
          Mean value_function loss: 84.7651
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 92.6015
                       Mean reward: 416.89
               Mean episode length: 224.66
    Episode_Reward/reaching_object: 1.5783
    Episode_Reward/rotating_object: 76.8534
        Episode_Reward/action_rate: -0.1632
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 2.12s
                      Time elapsed: 00:45:57
                               ETA: 00:10:51

################################################################################
                     [1m Learning iteration 1214/1500 [0m                     

                       Computation: 41662 steps/s (collection: 2.223s, learning 0.136s)
             Mean action noise std: 5.00
          Mean value_function loss: 82.0060
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 92.6158
                       Mean reward: 367.52
               Mean episode length: 209.04
    Episode_Reward/reaching_object: 1.6099
    Episode_Reward/rotating_object: 76.6149
        Episode_Reward/action_rate: -0.1671
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 2.36s
                      Time elapsed: 00:46:00
                               ETA: 00:10:49

################################################################################
                     [1m Learning iteration 1215/1500 [0m                     

                       Computation: 43418 steps/s (collection: 2.075s, learning 0.189s)
             Mean action noise std: 5.01
          Mean value_function loss: 77.7250
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 92.6352
                       Mean reward: 382.50
               Mean episode length: 228.56
    Episode_Reward/reaching_object: 1.5930
    Episode_Reward/rotating_object: 76.5585
        Episode_Reward/action_rate: -0.1637
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 2.26s
                      Time elapsed: 00:46:02
                               ETA: 00:10:47

################################################################################
                     [1m Learning iteration 1216/1500 [0m                     

                       Computation: 45240 steps/s (collection: 2.043s, learning 0.130s)
             Mean action noise std: 5.01
          Mean value_function loss: 81.7991
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 92.6545
                       Mean reward: 441.90
               Mean episode length: 217.91
    Episode_Reward/reaching_object: 1.6013
    Episode_Reward/rotating_object: 79.0029
        Episode_Reward/action_rate: -0.1659
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 2.17s
                      Time elapsed: 00:46:04
                               ETA: 00:10:45

################################################################################
                     [1m Learning iteration 1217/1500 [0m                     

                       Computation: 46361 steps/s (collection: 2.008s, learning 0.112s)
             Mean action noise std: 5.01
          Mean value_function loss: 83.7082
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 92.6668
                       Mean reward: 326.16
               Mean episode length: 206.34
    Episode_Reward/reaching_object: 1.5383
    Episode_Reward/rotating_object: 70.9104
        Episode_Reward/action_rate: -0.1625
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 2.12s
                      Time elapsed: 00:46:06
                               ETA: 00:10:42

################################################################################
                     [1m Learning iteration 1218/1500 [0m                     

                       Computation: 43819 steps/s (collection: 2.095s, learning 0.149s)
             Mean action noise std: 5.02
          Mean value_function loss: 75.5378
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 92.6842
                       Mean reward: 381.73
               Mean episode length: 227.85
    Episode_Reward/reaching_object: 1.6211
    Episode_Reward/rotating_object: 78.3125
        Episode_Reward/action_rate: -0.1702
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 2.24s
                      Time elapsed: 00:46:09
                               ETA: 00:10:40

################################################################################
                     [1m Learning iteration 1219/1500 [0m                     

                       Computation: 45809 steps/s (collection: 2.009s, learning 0.137s)
             Mean action noise std: 5.02
          Mean value_function loss: 88.9399
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 92.7097
                       Mean reward: 367.97
               Mean episode length: 217.01
    Episode_Reward/reaching_object: 1.5554
    Episode_Reward/rotating_object: 75.1952
        Episode_Reward/action_rate: -0.1642
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 2.15s
                      Time elapsed: 00:46:11
                               ETA: 00:10:38

################################################################################
                     [1m Learning iteration 1220/1500 [0m                     

                       Computation: 47514 steps/s (collection: 1.971s, learning 0.098s)
             Mean action noise std: 5.03
          Mean value_function loss: 85.3820
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 92.7283
                       Mean reward: 378.26
               Mean episode length: 221.51
    Episode_Reward/reaching_object: 1.5469
    Episode_Reward/rotating_object: 75.4816
        Episode_Reward/action_rate: -0.1634
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 2.07s
                      Time elapsed: 00:46:13
                               ETA: 00:10:35

################################################################################
                     [1m Learning iteration 1221/1500 [0m                     

                       Computation: 46548 steps/s (collection: 1.967s, learning 0.145s)
             Mean action noise std: 5.03
          Mean value_function loss: 81.7409
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 92.7460
                       Mean reward: 419.56
               Mean episode length: 218.07
    Episode_Reward/reaching_object: 1.5932
    Episode_Reward/rotating_object: 79.1077
        Episode_Reward/action_rate: -0.1654
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 2.11s
                      Time elapsed: 00:46:15
                               ETA: 00:10:33

################################################################################
                     [1m Learning iteration 1222/1500 [0m                     

                       Computation: 47353 steps/s (collection: 1.917s, learning 0.159s)
             Mean action noise std: 5.03
          Mean value_function loss: 83.5868
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 92.7657
                       Mean reward: 368.62
               Mean episode length: 217.05
    Episode_Reward/reaching_object: 1.5928
    Episode_Reward/rotating_object: 78.3001
        Episode_Reward/action_rate: -0.1672
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 2.08s
                      Time elapsed: 00:46:17
                               ETA: 00:10:31

################################################################################
                     [1m Learning iteration 1223/1500 [0m                     

                       Computation: 49408 steps/s (collection: 1.879s, learning 0.111s)
             Mean action noise std: 5.04
          Mean value_function loss: 87.8229
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 92.7852
                       Mean reward: 353.53
               Mean episode length: 224.39
    Episode_Reward/reaching_object: 1.5662
    Episode_Reward/rotating_object: 73.8050
        Episode_Reward/action_rate: -0.1670
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 1.99s
                      Time elapsed: 00:46:19
                               ETA: 00:10:29

################################################################################
                     [1m Learning iteration 1224/1500 [0m                     

                       Computation: 47336 steps/s (collection: 1.960s, learning 0.117s)
             Mean action noise std: 5.04
          Mean value_function loss: 81.8956
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 92.7990
                       Mean reward: 383.24
               Mean episode length: 221.01
    Episode_Reward/reaching_object: 1.6013
    Episode_Reward/rotating_object: 78.1859
        Episode_Reward/action_rate: -0.1688
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 2.08s
                      Time elapsed: 00:46:21
                               ETA: 00:10:26

################################################################################
                     [1m Learning iteration 1225/1500 [0m                     

                       Computation: 48193 steps/s (collection: 1.903s, learning 0.137s)
             Mean action noise std: 5.04
          Mean value_function loss: 80.3853
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 92.8079
                       Mean reward: 432.80
               Mean episode length: 236.01
    Episode_Reward/reaching_object: 1.5927
    Episode_Reward/rotating_object: 74.3913
        Episode_Reward/action_rate: -0.1698
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 2.04s
                      Time elapsed: 00:46:23
                               ETA: 00:10:24

################################################################################
                     [1m Learning iteration 1226/1500 [0m                     

                       Computation: 47232 steps/s (collection: 1.951s, learning 0.131s)
             Mean action noise std: 5.04
          Mean value_function loss: 83.0454
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 92.8261
                       Mean reward: 379.72
               Mean episode length: 220.86
    Episode_Reward/reaching_object: 1.5958
    Episode_Reward/rotating_object: 79.0245
        Episode_Reward/action_rate: -0.1689
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 2.08s
                      Time elapsed: 00:46:25
                               ETA: 00:10:22

################################################################################
                     [1m Learning iteration 1227/1500 [0m                     

                       Computation: 47387 steps/s (collection: 1.934s, learning 0.140s)
             Mean action noise std: 5.05
          Mean value_function loss: 86.5269
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 92.8534
                       Mean reward: 396.02
               Mean episode length: 222.62
    Episode_Reward/reaching_object: 1.5668
    Episode_Reward/rotating_object: 75.8346
        Episode_Reward/action_rate: -0.1664
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 2.07s
                      Time elapsed: 00:46:27
                               ETA: 00:10:19

################################################################################
                     [1m Learning iteration 1228/1500 [0m                     

                       Computation: 47685 steps/s (collection: 1.896s, learning 0.166s)
             Mean action noise std: 5.05
          Mean value_function loss: 84.5972
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 92.8719
                       Mean reward: 363.66
               Mean episode length: 222.94
    Episode_Reward/reaching_object: 1.5754
    Episode_Reward/rotating_object: 77.6347
        Episode_Reward/action_rate: -0.1664
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 2.06s
                      Time elapsed: 00:46:29
                               ETA: 00:10:17

################################################################################
                     [1m Learning iteration 1229/1500 [0m                     

                       Computation: 46982 steps/s (collection: 1.999s, learning 0.094s)
             Mean action noise std: 5.05
          Mean value_function loss: 85.1542
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 92.8857
                       Mean reward: 403.06
               Mean episode length: 221.22
    Episode_Reward/reaching_object: 1.5999
    Episode_Reward/rotating_object: 79.7732
        Episode_Reward/action_rate: -0.1687
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 2.09s
                      Time elapsed: 00:46:31
                               ETA: 00:10:15

################################################################################
                     [1m Learning iteration 1230/1500 [0m                     

                       Computation: 44279 steps/s (collection: 2.092s, learning 0.128s)
             Mean action noise std: 5.06
          Mean value_function loss: 84.8704
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 92.8941
                       Mean reward: 431.21
               Mean episode length: 222.88
    Episode_Reward/reaching_object: 1.5967
    Episode_Reward/rotating_object: 79.5568
        Episode_Reward/action_rate: -0.1678
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 2.22s
                      Time elapsed: 00:46:34
                               ETA: 00:10:12

################################################################################
                     [1m Learning iteration 1231/1500 [0m                     

                       Computation: 47401 steps/s (collection: 1.940s, learning 0.134s)
             Mean action noise std: 5.06
          Mean value_function loss: 84.5668
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 92.9117
                       Mean reward: 400.70
               Mean episode length: 223.04
    Episode_Reward/reaching_object: 1.5801
    Episode_Reward/rotating_object: 80.5724
        Episode_Reward/action_rate: -0.1684
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 2.07s
                      Time elapsed: 00:46:36
                               ETA: 00:10:10

################################################################################
                     [1m Learning iteration 1232/1500 [0m                     

                       Computation: 43717 steps/s (collection: 2.018s, learning 0.231s)
             Mean action noise std: 5.06
          Mean value_function loss: 83.6212
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 92.9268
                       Mean reward: 402.73
               Mean episode length: 214.54
    Episode_Reward/reaching_object: 1.5934
    Episode_Reward/rotating_object: 78.0159
        Episode_Reward/action_rate: -0.1693
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 2.25s
                      Time elapsed: 00:46:38
                               ETA: 00:10:08

################################################################################
                     [1m Learning iteration 1233/1500 [0m                     

                       Computation: 47304 steps/s (collection: 1.977s, learning 0.101s)
             Mean action noise std: 5.07
          Mean value_function loss: 84.2931
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 92.9421
                       Mean reward: 393.26
               Mean episode length: 230.14
    Episode_Reward/reaching_object: 1.5604
    Episode_Reward/rotating_object: 75.5130
        Episode_Reward/action_rate: -0.1688
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 2.08s
                      Time elapsed: 00:46:40
                               ETA: 00:10:05

################################################################################
                     [1m Learning iteration 1234/1500 [0m                     

                       Computation: 47794 steps/s (collection: 1.925s, learning 0.132s)
             Mean action noise std: 5.07
          Mean value_function loss: 84.2523
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 92.9527
                       Mean reward: 323.44
               Mean episode length: 211.29
    Episode_Reward/reaching_object: 1.5428
    Episode_Reward/rotating_object: 73.4911
        Episode_Reward/action_rate: -0.1669
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 2.06s
                      Time elapsed: 00:46:42
                               ETA: 00:10:03

################################################################################
                     [1m Learning iteration 1235/1500 [0m                     

                       Computation: 46174 steps/s (collection: 2.008s, learning 0.121s)
             Mean action noise std: 5.07
          Mean value_function loss: 79.1597
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 92.9655
                       Mean reward: 389.85
               Mean episode length: 219.94
    Episode_Reward/reaching_object: 1.5820
    Episode_Reward/rotating_object: 77.3851
        Episode_Reward/action_rate: -0.1708
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 2.13s
                      Time elapsed: 00:46:44
                               ETA: 00:10:01

################################################################################
                     [1m Learning iteration 1236/1500 [0m                     

                       Computation: 46301 steps/s (collection: 2.025s, learning 0.098s)
             Mean action noise std: 5.08
          Mean value_function loss: 79.2854
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 92.9850
                       Mean reward: 406.95
               Mean episode length: 223.82
    Episode_Reward/reaching_object: 1.5559
    Episode_Reward/rotating_object: 77.4614
        Episode_Reward/action_rate: -0.1682
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 2.12s
                      Time elapsed: 00:46:46
                               ETA: 00:09:59

################################################################################
                     [1m Learning iteration 1237/1500 [0m                     

                       Computation: 44740 steps/s (collection: 2.051s, learning 0.147s)
             Mean action noise std: 5.08
          Mean value_function loss: 82.8420
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 93.0010
                       Mean reward: 440.37
               Mean episode length: 223.40
    Episode_Reward/reaching_object: 1.5906
    Episode_Reward/rotating_object: 79.5764
        Episode_Reward/action_rate: -0.1697
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 2.20s
                      Time elapsed: 00:46:49
                               ETA: 00:09:56

################################################################################
                     [1m Learning iteration 1238/1500 [0m                     

                       Computation: 45985 steps/s (collection: 2.024s, learning 0.114s)
             Mean action noise std: 5.08
          Mean value_function loss: 81.7827
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 93.0223
                       Mean reward: 399.50
               Mean episode length: 216.64
    Episode_Reward/reaching_object: 1.5674
    Episode_Reward/rotating_object: 77.9072
        Episode_Reward/action_rate: -0.1679
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 2.14s
                      Time elapsed: 00:46:51
                               ETA: 00:09:54

################################################################################
                     [1m Learning iteration 1239/1500 [0m                     

                       Computation: 46112 steps/s (collection: 2.020s, learning 0.112s)
             Mean action noise std: 5.09
          Mean value_function loss: 83.9175
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 93.0412
                       Mean reward: 397.95
               Mean episode length: 207.93
    Episode_Reward/reaching_object: 1.5728
    Episode_Reward/rotating_object: 79.1953
        Episode_Reward/action_rate: -0.1689
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 2.13s
                      Time elapsed: 00:46:53
                               ETA: 00:09:52

################################################################################
                     [1m Learning iteration 1240/1500 [0m                     

                       Computation: 44653 steps/s (collection: 2.028s, learning 0.174s)
             Mean action noise std: 5.09
          Mean value_function loss: 85.9815
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 93.0550
                       Mean reward: 359.46
               Mean episode length: 212.03
    Episode_Reward/reaching_object: 1.5900
    Episode_Reward/rotating_object: 77.9450
        Episode_Reward/action_rate: -0.1722
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 2.20s
                      Time elapsed: 00:46:55
                               ETA: 00:09:49

################################################################################
                     [1m Learning iteration 1241/1500 [0m                     

                       Computation: 43364 steps/s (collection: 2.069s, learning 0.198s)
             Mean action noise std: 5.09
          Mean value_function loss: 81.2564
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 93.0763
                       Mean reward: 415.40
               Mean episode length: 227.77
    Episode_Reward/reaching_object: 1.5680
    Episode_Reward/rotating_object: 78.9096
        Episode_Reward/action_rate: -0.1689
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 2.27s
                      Time elapsed: 00:46:57
                               ETA: 00:09:47

################################################################################
                     [1m Learning iteration 1242/1500 [0m                     

                       Computation: 41541 steps/s (collection: 2.210s, learning 0.156s)
             Mean action noise std: 5.09
          Mean value_function loss: 79.1994
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 93.0898
                       Mean reward: 411.28
               Mean episode length: 232.13
    Episode_Reward/reaching_object: 1.5837
    Episode_Reward/rotating_object: 77.8258
        Episode_Reward/action_rate: -0.1720
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 2.37s
                      Time elapsed: 00:47:00
                               ETA: 00:09:45

################################################################################
                     [1m Learning iteration 1243/1500 [0m                     

                       Computation: 43017 steps/s (collection: 2.135s, learning 0.150s)
             Mean action noise std: 5.10
          Mean value_function loss: 78.7560
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 93.1034
                       Mean reward: 406.66
               Mean episode length: 225.18
    Episode_Reward/reaching_object: 1.5733
    Episode_Reward/rotating_object: 78.6178
        Episode_Reward/action_rate: -0.1702
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 2.29s
                      Time elapsed: 00:47:02
                               ETA: 00:09:43

################################################################################
                     [1m Learning iteration 1244/1500 [0m                     

                       Computation: 46729 steps/s (collection: 1.994s, learning 0.110s)
             Mean action noise std: 5.10
          Mean value_function loss: 85.6226
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 93.1260
                       Mean reward: 383.16
               Mean episode length: 214.83
    Episode_Reward/reaching_object: 1.5812
    Episode_Reward/rotating_object: 78.9733
        Episode_Reward/action_rate: -0.1724
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 2.10s
                      Time elapsed: 00:47:04
                               ETA: 00:09:40

################################################################################
                     [1m Learning iteration 1245/1500 [0m                     

                       Computation: 46335 steps/s (collection: 2.006s, learning 0.116s)
             Mean action noise std: 5.11
          Mean value_function loss: 86.0085
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 93.1495
                       Mean reward: 443.93
               Mean episode length: 229.63
    Episode_Reward/reaching_object: 1.5264
    Episode_Reward/rotating_object: 76.7360
        Episode_Reward/action_rate: -0.1664
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 2.12s
                      Time elapsed: 00:47:06
                               ETA: 00:09:38

################################################################################
                     [1m Learning iteration 1246/1500 [0m                     

                       Computation: 43300 steps/s (collection: 2.138s, learning 0.132s)
             Mean action noise std: 5.11
          Mean value_function loss: 78.2840
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 93.1652
                       Mean reward: 447.94
               Mean episode length: 226.05
    Episode_Reward/reaching_object: 1.6220
    Episode_Reward/rotating_object: 82.3844
        Episode_Reward/action_rate: -0.1761
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 2.27s
                      Time elapsed: 00:47:08
                               ETA: 00:09:36

################################################################################
                     [1m Learning iteration 1247/1500 [0m                     

                       Computation: 41753 steps/s (collection: 2.131s, learning 0.223s)
             Mean action noise std: 5.11
          Mean value_function loss: 85.4577
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 93.1880
                       Mean reward: 393.29
               Mean episode length: 231.64
    Episode_Reward/reaching_object: 1.5935
    Episode_Reward/rotating_object: 79.6072
        Episode_Reward/action_rate: -0.1734
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 2.35s
                      Time elapsed: 00:47:11
                               ETA: 00:09:33

################################################################################
                     [1m Learning iteration 1248/1500 [0m                     

                       Computation: 38707 steps/s (collection: 2.320s, learning 0.220s)
             Mean action noise std: 5.12
          Mean value_function loss: 85.3135
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 93.2080
                       Mean reward: 378.27
               Mean episode length: 228.78
    Episode_Reward/reaching_object: 1.6122
    Episode_Reward/rotating_object: 80.9365
        Episode_Reward/action_rate: -0.1752
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 2.54s
                      Time elapsed: 00:47:13
                               ETA: 00:09:31

################################################################################
                     [1m Learning iteration 1249/1500 [0m                     

                       Computation: 47253 steps/s (collection: 1.988s, learning 0.093s)
             Mean action noise std: 5.12
          Mean value_function loss: 88.6954
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 93.2232
                       Mean reward: 416.04
               Mean episode length: 222.21
    Episode_Reward/reaching_object: 1.5945
    Episode_Reward/rotating_object: 81.4198
        Episode_Reward/action_rate: -0.1726
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 2.08s
                      Time elapsed: 00:47:15
                               ETA: 00:09:29

################################################################################
                     [1m Learning iteration 1250/1500 [0m                     

                       Computation: 44554 steps/s (collection: 2.067s, learning 0.139s)
             Mean action noise std: 5.12
          Mean value_function loss: 83.6975
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 93.2414
                       Mean reward: 412.41
               Mean episode length: 226.96
    Episode_Reward/reaching_object: 1.5611
    Episode_Reward/rotating_object: 77.1268
        Episode_Reward/action_rate: -0.1719
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 2.21s
                      Time elapsed: 00:47:18
                               ETA: 00:09:27

################################################################################
                     [1m Learning iteration 1251/1500 [0m                     

                       Computation: 45520 steps/s (collection: 1.978s, learning 0.181s)
             Mean action noise std: 5.13
          Mean value_function loss: 80.3626
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 93.2603
                       Mean reward: 396.57
               Mean episode length: 228.02
    Episode_Reward/reaching_object: 1.6309
    Episode_Reward/rotating_object: 82.5126
        Episode_Reward/action_rate: -0.1765
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 2.16s
                      Time elapsed: 00:47:20
                               ETA: 00:09:24

################################################################################
                     [1m Learning iteration 1252/1500 [0m                     

                       Computation: 43848 steps/s (collection: 2.143s, learning 0.099s)
             Mean action noise std: 5.13
          Mean value_function loss: 77.0217
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 93.2804
                       Mean reward: 425.37
               Mean episode length: 226.52
    Episode_Reward/reaching_object: 1.6506
    Episode_Reward/rotating_object: 85.0740
        Episode_Reward/action_rate: -0.1786
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 2.24s
                      Time elapsed: 00:47:22
                               ETA: 00:09:22

################################################################################
                     [1m Learning iteration 1253/1500 [0m                     

                       Computation: 45358 steps/s (collection: 1.984s, learning 0.183s)
             Mean action noise std: 5.13
          Mean value_function loss: 80.4350
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 93.3001
                       Mean reward: 380.66
               Mean episode length: 232.40
    Episode_Reward/reaching_object: 1.5897
    Episode_Reward/rotating_object: 77.6069
        Episode_Reward/action_rate: -0.1762
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 2.17s
                      Time elapsed: 00:47:24
                               ETA: 00:09:20

################################################################################
                     [1m Learning iteration 1254/1500 [0m                     

                       Computation: 45423 steps/s (collection: 1.996s, learning 0.168s)
             Mean action noise std: 5.14
          Mean value_function loss: 85.3961
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 93.3182
                       Mean reward: 435.75
               Mean episode length: 236.47
    Episode_Reward/reaching_object: 1.6026
    Episode_Reward/rotating_object: 80.7426
        Episode_Reward/action_rate: -0.1762
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 2.16s
                      Time elapsed: 00:47:26
                               ETA: 00:09:18

################################################################################
                     [1m Learning iteration 1255/1500 [0m                     

                       Computation: 44908 steps/s (collection: 2.054s, learning 0.135s)
             Mean action noise std: 5.14
          Mean value_function loss: 83.3820
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 93.3344
                       Mean reward: 407.70
               Mean episode length: 230.47
    Episode_Reward/reaching_object: 1.5923
    Episode_Reward/rotating_object: 77.5319
        Episode_Reward/action_rate: -0.1763
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 2.19s
                      Time elapsed: 00:47:29
                               ETA: 00:09:15

################################################################################
                     [1m Learning iteration 1256/1500 [0m                     

                       Computation: 44601 steps/s (collection: 2.025s, learning 0.179s)
             Mean action noise std: 5.14
          Mean value_function loss: 83.0301
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 93.3478
                       Mean reward: 426.32
               Mean episode length: 225.69
    Episode_Reward/reaching_object: 1.6075
    Episode_Reward/rotating_object: 79.7797
        Episode_Reward/action_rate: -0.1778
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 2.20s
                      Time elapsed: 00:47:31
                               ETA: 00:09:13

################################################################################
                     [1m Learning iteration 1257/1500 [0m                     

                       Computation: 44535 steps/s (collection: 2.070s, learning 0.137s)
             Mean action noise std: 5.15
          Mean value_function loss: 85.4026
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 93.3659
                       Mean reward: 383.10
               Mean episode length: 221.14
    Episode_Reward/reaching_object: 1.5542
    Episode_Reward/rotating_object: 78.2362
        Episode_Reward/action_rate: -0.1742
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 2.21s
                      Time elapsed: 00:47:33
                               ETA: 00:09:11

################################################################################
                     [1m Learning iteration 1258/1500 [0m                     

                       Computation: 46590 steps/s (collection: 1.950s, learning 0.160s)
             Mean action noise std: 5.15
          Mean value_function loss: 91.6654
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 93.3883
                       Mean reward: 386.50
               Mean episode length: 226.97
    Episode_Reward/reaching_object: 1.6578
    Episode_Reward/rotating_object: 83.2858
        Episode_Reward/action_rate: -0.1796
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 2.11s
                      Time elapsed: 00:47:35
                               ETA: 00:09:08

################################################################################
                     [1m Learning iteration 1259/1500 [0m                     

                       Computation: 42692 steps/s (collection: 2.161s, learning 0.141s)
             Mean action noise std: 5.15
          Mean value_function loss: 85.3913
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 93.4082
                       Mean reward: 403.03
               Mean episode length: 223.47
    Episode_Reward/reaching_object: 1.6165
    Episode_Reward/rotating_object: 80.4081
        Episode_Reward/action_rate: -0.1786
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 2.30s
                      Time elapsed: 00:47:37
                               ETA: 00:09:06

################################################################################
                     [1m Learning iteration 1260/1500 [0m                     

                       Computation: 46001 steps/s (collection: 1.978s, learning 0.159s)
             Mean action noise std: 5.16
          Mean value_function loss: 80.7394
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 93.4300
                       Mean reward: 419.46
               Mean episode length: 228.27
    Episode_Reward/reaching_object: 1.6086
    Episode_Reward/rotating_object: 80.3521
        Episode_Reward/action_rate: -0.1782
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 2.14s
                      Time elapsed: 00:47:39
                               ETA: 00:09:04

################################################################################
                     [1m Learning iteration 1261/1500 [0m                     

                       Computation: 43074 steps/s (collection: 2.107s, learning 0.175s)
             Mean action noise std: 5.16
          Mean value_function loss: 91.7684
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 93.4500
                       Mean reward: 382.95
               Mean episode length: 212.29
    Episode_Reward/reaching_object: 1.5254
    Episode_Reward/rotating_object: 76.8444
        Episode_Reward/action_rate: -0.1674
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 2.28s
                      Time elapsed: 00:47:42
                               ETA: 00:09:02

################################################################################
                     [1m Learning iteration 1262/1500 [0m                     

                       Computation: 42901 steps/s (collection: 2.100s, learning 0.191s)
             Mean action noise std: 5.16
          Mean value_function loss: 89.8124
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 93.4637
                       Mean reward: 396.97
               Mean episode length: 219.62
    Episode_Reward/reaching_object: 1.6121
    Episode_Reward/rotating_object: 79.1903
        Episode_Reward/action_rate: -0.1777
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 2.29s
                      Time elapsed: 00:47:44
                               ETA: 00:08:59

################################################################################
                     [1m Learning iteration 1263/1500 [0m                     

                       Computation: 44684 steps/s (collection: 2.047s, learning 0.153s)
             Mean action noise std: 5.17
          Mean value_function loss: 86.0087
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 93.4853
                       Mean reward: 407.37
               Mean episode length: 226.73
    Episode_Reward/reaching_object: 1.5801
    Episode_Reward/rotating_object: 77.8239
        Episode_Reward/action_rate: -0.1760
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 2.20s
                      Time elapsed: 00:47:46
                               ETA: 00:08:57

################################################################################
                     [1m Learning iteration 1264/1500 [0m                     

                       Computation: 44331 steps/s (collection: 2.073s, learning 0.144s)
             Mean action noise std: 5.17
          Mean value_function loss: 88.3677
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 93.5062
                       Mean reward: 364.01
               Mean episode length: 208.34
    Episode_Reward/reaching_object: 1.5925
    Episode_Reward/rotating_object: 76.2425
        Episode_Reward/action_rate: -0.1759
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 2.22s
                      Time elapsed: 00:47:48
                               ETA: 00:08:55

################################################################################
                     [1m Learning iteration 1265/1500 [0m                     

                       Computation: 47170 steps/s (collection: 1.963s, learning 0.121s)
             Mean action noise std: 5.18
          Mean value_function loss: 90.1079
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 93.5293
                       Mean reward: 364.11
               Mean episode length: 216.05
    Episode_Reward/reaching_object: 1.5664
    Episode_Reward/rotating_object: 77.2527
        Episode_Reward/action_rate: -0.1746
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 2.08s
                      Time elapsed: 00:47:51
                               ETA: 00:08:52

################################################################################
                     [1m Learning iteration 1266/1500 [0m                     

                       Computation: 46946 steps/s (collection: 1.919s, learning 0.175s)
             Mean action noise std: 5.18
          Mean value_function loss: 84.4834
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 93.5481
                       Mean reward: 364.07
               Mean episode length: 210.99
    Episode_Reward/reaching_object: 1.5268
    Episode_Reward/rotating_object: 74.5287
        Episode_Reward/action_rate: -0.1704
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 2.09s
                      Time elapsed: 00:47:53
                               ETA: 00:08:50

################################################################################
                     [1m Learning iteration 1267/1500 [0m                     

                       Computation: 46352 steps/s (collection: 2.013s, learning 0.107s)
             Mean action noise std: 5.18
          Mean value_function loss: 76.3930
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 93.5686
                       Mean reward: 415.85
               Mean episode length: 229.56
    Episode_Reward/reaching_object: 1.6024
    Episode_Reward/rotating_object: 78.2130
        Episode_Reward/action_rate: -0.1782
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 2.12s
                      Time elapsed: 00:47:55
                               ETA: 00:08:48

################################################################################
                     [1m Learning iteration 1268/1500 [0m                     

                       Computation: 43207 steps/s (collection: 2.128s, learning 0.148s)
             Mean action noise std: 5.19
          Mean value_function loss: 77.2098
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 93.6044
                       Mean reward: 472.27
               Mean episode length: 235.86
    Episode_Reward/reaching_object: 1.6353
    Episode_Reward/rotating_object: 81.7623
        Episode_Reward/action_rate: -0.1816
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 2.28s
                      Time elapsed: 00:47:57
                               ETA: 00:08:46

################################################################################
                     [1m Learning iteration 1269/1500 [0m                     

                       Computation: 44717 steps/s (collection: 1.990s, learning 0.208s)
             Mean action noise std: 5.19
          Mean value_function loss: 87.3791
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 93.6228
                       Mean reward: 354.55
               Mean episode length: 210.04
    Episode_Reward/reaching_object: 1.5543
    Episode_Reward/rotating_object: 75.2276
        Episode_Reward/action_rate: -0.1759
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 2.20s
                      Time elapsed: 00:47:59
                               ETA: 00:08:43

################################################################################
                     [1m Learning iteration 1270/1500 [0m                     

                       Computation: 46652 steps/s (collection: 1.983s, learning 0.124s)
             Mean action noise std: 5.19
          Mean value_function loss: 78.4185
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 93.6396
                       Mean reward: 366.80
               Mean episode length: 230.93
    Episode_Reward/reaching_object: 1.5781
    Episode_Reward/rotating_object: 76.5262
        Episode_Reward/action_rate: -0.1785
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 2.11s
                      Time elapsed: 00:48:01
                               ETA: 00:08:41

################################################################################
                     [1m Learning iteration 1271/1500 [0m                     

                       Computation: 46514 steps/s (collection: 1.972s, learning 0.141s)
             Mean action noise std: 5.20
          Mean value_function loss: 83.4998
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 93.6556
                       Mean reward: 461.90
               Mean episode length: 237.54
    Episode_Reward/reaching_object: 1.6866
    Episode_Reward/rotating_object: 85.1033
        Episode_Reward/action_rate: -0.1863
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 2.11s
                      Time elapsed: 00:48:03
                               ETA: 00:08:39

################################################################################
                     [1m Learning iteration 1272/1500 [0m                     

                       Computation: 47544 steps/s (collection: 1.927s, learning 0.141s)
             Mean action noise std: 5.20
          Mean value_function loss: 84.6087
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 93.6677
                       Mean reward: 392.66
               Mean episode length: 219.00
    Episode_Reward/reaching_object: 1.5792
    Episode_Reward/rotating_object: 80.4827
        Episode_Reward/action_rate: -0.1779
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 2.07s
                      Time elapsed: 00:48:06
                               ETA: 00:08:36

################################################################################
                     [1m Learning iteration 1273/1500 [0m                     

                       Computation: 43969 steps/s (collection: 2.051s, learning 0.185s)
             Mean action noise std: 5.20
          Mean value_function loss: 90.8685
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 93.6818
                       Mean reward: 371.16
               Mean episode length: 219.11
    Episode_Reward/reaching_object: 1.5802
    Episode_Reward/rotating_object: 79.6643
        Episode_Reward/action_rate: -0.1777
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 2.24s
                      Time elapsed: 00:48:08
                               ETA: 00:08:34

################################################################################
                     [1m Learning iteration 1274/1500 [0m                     

                       Computation: 45448 steps/s (collection: 2.013s, learning 0.150s)
             Mean action noise std: 5.20
          Mean value_function loss: 85.6388
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 93.6966
                       Mean reward: 396.67
               Mean episode length: 223.69
    Episode_Reward/reaching_object: 1.6013
    Episode_Reward/rotating_object: 79.3278
        Episode_Reward/action_rate: -0.1816
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 2.16s
                      Time elapsed: 00:48:10
                               ETA: 00:08:32

################################################################################
                     [1m Learning iteration 1275/1500 [0m                     

                       Computation: 41394 steps/s (collection: 2.184s, learning 0.191s)
             Mean action noise std: 5.21
          Mean value_function loss: 86.1927
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 93.7181
                       Mean reward: 402.37
               Mean episode length: 230.80
    Episode_Reward/reaching_object: 1.6113
    Episode_Reward/rotating_object: 78.3082
        Episode_Reward/action_rate: -0.1831
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 2.37s
                      Time elapsed: 00:48:12
                               ETA: 00:08:30

################################################################################
                     [1m Learning iteration 1276/1500 [0m                     

                       Computation: 43542 steps/s (collection: 2.094s, learning 0.164s)
             Mean action noise std: 5.21
          Mean value_function loss: 84.1156
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 93.7377
                       Mean reward: 399.20
               Mean episode length: 229.38
    Episode_Reward/reaching_object: 1.5800
    Episode_Reward/rotating_object: 78.4265
        Episode_Reward/action_rate: -0.1799
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 2.26s
                      Time elapsed: 00:48:15
                               ETA: 00:08:27

################################################################################
                     [1m Learning iteration 1277/1500 [0m                     

                       Computation: 41142 steps/s (collection: 2.139s, learning 0.251s)
             Mean action noise std: 5.21
          Mean value_function loss: 83.0663
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 93.7493
                       Mean reward: 397.18
               Mean episode length: 217.48
    Episode_Reward/reaching_object: 1.6127
    Episode_Reward/rotating_object: 82.1368
        Episode_Reward/action_rate: -0.1799
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 2.39s
                      Time elapsed: 00:48:17
                               ETA: 00:08:25

################################################################################
                     [1m Learning iteration 1278/1500 [0m                     

                       Computation: 43649 steps/s (collection: 2.078s, learning 0.174s)
             Mean action noise std: 5.22
          Mean value_function loss: 79.7220
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 93.7616
                       Mean reward: 383.86
               Mean episode length: 221.62
    Episode_Reward/reaching_object: 1.6029
    Episode_Reward/rotating_object: 79.3209
        Episode_Reward/action_rate: -0.1820
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 2.25s
                      Time elapsed: 00:48:19
                               ETA: 00:08:23

################################################################################
                     [1m Learning iteration 1279/1500 [0m                     

                       Computation: 43662 steps/s (collection: 2.021s, learning 0.230s)
             Mean action noise std: 5.22
          Mean value_function loss: 77.5004
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 93.7794
                       Mean reward: 374.17
               Mean episode length: 222.38
    Episode_Reward/reaching_object: 1.5821
    Episode_Reward/rotating_object: 76.2157
        Episode_Reward/action_rate: -0.1813
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 2.25s
                      Time elapsed: 00:48:21
                               ETA: 00:08:21

################################################################################
                     [1m Learning iteration 1280/1500 [0m                     

                       Computation: 42629 steps/s (collection: 2.178s, learning 0.128s)
             Mean action noise std: 5.23
          Mean value_function loss: 73.8212
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 93.8037
                       Mean reward: 415.92
               Mean episode length: 229.48
    Episode_Reward/reaching_object: 1.6386
    Episode_Reward/rotating_object: 83.7109
        Episode_Reward/action_rate: -0.1854
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 2.31s
                      Time elapsed: 00:48:24
                               ETA: 00:08:18

################################################################################
                     [1m Learning iteration 1281/1500 [0m                     

                       Computation: 46014 steps/s (collection: 1.984s, learning 0.152s)
             Mean action noise std: 5.23
          Mean value_function loss: 84.5006
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 93.8219
                       Mean reward: 404.51
               Mean episode length: 228.86
    Episode_Reward/reaching_object: 1.5619
    Episode_Reward/rotating_object: 77.9444
        Episode_Reward/action_rate: -0.1788
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 2.14s
                      Time elapsed: 00:48:26
                               ETA: 00:08:16

################################################################################
                     [1m Learning iteration 1282/1500 [0m                     

                       Computation: 43548 steps/s (collection: 2.070s, learning 0.187s)
             Mean action noise std: 5.23
          Mean value_function loss: 84.6308
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 93.8416
                       Mean reward: 376.45
               Mean episode length: 221.29
    Episode_Reward/reaching_object: 1.6098
    Episode_Reward/rotating_object: 83.9103
        Episode_Reward/action_rate: -0.1830
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 2.26s
                      Time elapsed: 00:48:28
                               ETA: 00:08:14

################################################################################
                     [1m Learning iteration 1283/1500 [0m                     

                       Computation: 46821 steps/s (collection: 1.990s, learning 0.109s)
             Mean action noise std: 5.23
          Mean value_function loss: 80.7980
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 93.8545
                       Mean reward: 395.79
               Mean episode length: 225.90
    Episode_Reward/reaching_object: 1.5474
    Episode_Reward/rotating_object: 74.6425
        Episode_Reward/action_rate: -0.1803
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 2.10s
                      Time elapsed: 00:48:30
                               ETA: 00:08:11

################################################################################
                     [1m Learning iteration 1284/1500 [0m                     

                       Computation: 43676 steps/s (collection: 2.134s, learning 0.117s)
             Mean action noise std: 5.24
          Mean value_function loss: 83.2143
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 93.8650
                       Mean reward: 419.78
               Mean episode length: 226.71
    Episode_Reward/reaching_object: 1.5967
    Episode_Reward/rotating_object: 80.9224
        Episode_Reward/action_rate: -0.1829
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 2.25s
                      Time elapsed: 00:48:33
                               ETA: 00:08:09

################################################################################
                     [1m Learning iteration 1285/1500 [0m                     

                       Computation: 48057 steps/s (collection: 1.936s, learning 0.110s)
             Mean action noise std: 5.24
          Mean value_function loss: 82.0742
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 93.8823
                       Mean reward: 394.55
               Mean episode length: 207.93
    Episode_Reward/reaching_object: 1.5772
    Episode_Reward/rotating_object: 81.6659
        Episode_Reward/action_rate: -0.1822
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 2.05s
                      Time elapsed: 00:48:35
                               ETA: 00:08:07

################################################################################
                     [1m Learning iteration 1286/1500 [0m                     

                       Computation: 37616 steps/s (collection: 2.389s, learning 0.225s)
             Mean action noise std: 5.25
          Mean value_function loss: 89.9837
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 93.9090
                       Mean reward: 384.32
               Mean episode length: 220.67
    Episode_Reward/reaching_object: 1.6036
    Episode_Reward/rotating_object: 83.8297
        Episode_Reward/action_rate: -0.1843
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 2.61s
                      Time elapsed: 00:48:37
                               ETA: 00:08:05

################################################################################
                     [1m Learning iteration 1287/1500 [0m                     

                       Computation: 45557 steps/s (collection: 2.042s, learning 0.116s)
             Mean action noise std: 5.25
          Mean value_function loss: 77.3945
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 93.9282
                       Mean reward: 447.88
               Mean episode length: 227.74
    Episode_Reward/reaching_object: 1.5743
    Episode_Reward/rotating_object: 79.2560
        Episode_Reward/action_rate: -0.1816
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 2.16s
                      Time elapsed: 00:48:39
                               ETA: 00:08:02

################################################################################
                     [1m Learning iteration 1288/1500 [0m                     

                       Computation: 42753 steps/s (collection: 2.103s, learning 0.197s)
             Mean action noise std: 5.25
          Mean value_function loss: 81.9916
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 93.9454
                       Mean reward: 431.92
               Mean episode length: 232.06
    Episode_Reward/reaching_object: 1.6457
    Episode_Reward/rotating_object: 85.2095
        Episode_Reward/action_rate: -0.1874
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 2.30s
                      Time elapsed: 00:48:42
                               ETA: 00:08:00

################################################################################
                     [1m Learning iteration 1289/1500 [0m                     

                       Computation: 42812 steps/s (collection: 2.159s, learning 0.138s)
             Mean action noise std: 5.25
          Mean value_function loss: 77.3832
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 93.9576
                       Mean reward: 379.70
               Mean episode length: 209.92
    Episode_Reward/reaching_object: 1.5474
    Episode_Reward/rotating_object: 79.4825
        Episode_Reward/action_rate: -0.1785
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 2.30s
                      Time elapsed: 00:48:44
                               ETA: 00:07:58

################################################################################
                     [1m Learning iteration 1290/1500 [0m                     

                       Computation: 43293 steps/s (collection: 2.159s, learning 0.112s)
             Mean action noise std: 5.26
          Mean value_function loss: 82.9174
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 93.9694
                       Mean reward: 411.48
               Mean episode length: 218.76
    Episode_Reward/reaching_object: 1.5834
    Episode_Reward/rotating_object: 80.7017
        Episode_Reward/action_rate: -0.1819
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 2.27s
                      Time elapsed: 00:48:46
                               ETA: 00:07:56

################################################################################
                     [1m Learning iteration 1291/1500 [0m                     

                       Computation: 40521 steps/s (collection: 2.287s, learning 0.139s)
             Mean action noise std: 5.26
          Mean value_function loss: 87.7271
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 93.9913
                       Mean reward: 417.96
               Mean episode length: 233.29
    Episode_Reward/reaching_object: 1.6254
    Episode_Reward/rotating_object: 82.8005
        Episode_Reward/action_rate: -0.1865
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 2.43s
                      Time elapsed: 00:48:49
                               ETA: 00:07:53

################################################################################
                     [1m Learning iteration 1292/1500 [0m                     

                       Computation: 46045 steps/s (collection: 1.997s, learning 0.138s)
             Mean action noise std: 5.27
          Mean value_function loss: 87.8532
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 94.0095
                       Mean reward: 442.37
               Mean episode length: 224.82
    Episode_Reward/reaching_object: 1.6108
    Episode_Reward/rotating_object: 82.3500
        Episode_Reward/action_rate: -0.1839
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 2.13s
                      Time elapsed: 00:48:51
                               ETA: 00:07:51

################################################################################
                     [1m Learning iteration 1293/1500 [0m                     

                       Computation: 42100 steps/s (collection: 2.207s, learning 0.128s)
             Mean action noise std: 5.27
          Mean value_function loss: 83.7708
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 94.0276
                       Mean reward: 420.91
               Mean episode length: 224.16
    Episode_Reward/reaching_object: 1.5719
    Episode_Reward/rotating_object: 79.3450
        Episode_Reward/action_rate: -0.1819
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 2.33s
                      Time elapsed: 00:48:53
                               ETA: 00:07:49

################################################################################
                     [1m Learning iteration 1294/1500 [0m                     

                       Computation: 43802 steps/s (collection: 2.019s, learning 0.225s)
             Mean action noise std: 5.27
          Mean value_function loss: 87.8576
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 94.0488
                       Mean reward: 436.95
               Mean episode length: 236.58
    Episode_Reward/reaching_object: 1.6173
    Episode_Reward/rotating_object: 85.3249
        Episode_Reward/action_rate: -0.1850
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 2.24s
                      Time elapsed: 00:48:55
                               ETA: 00:07:47

################################################################################
                     [1m Learning iteration 1295/1500 [0m                     

                       Computation: 44128 steps/s (collection: 2.119s, learning 0.109s)
             Mean action noise std: 5.28
          Mean value_function loss: 81.6244
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 94.0689
                       Mean reward: 413.93
               Mean episode length: 216.04
    Episode_Reward/reaching_object: 1.5925
    Episode_Reward/rotating_object: 80.4785
        Episode_Reward/action_rate: -0.1842
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 2.23s
                      Time elapsed: 00:48:58
                               ETA: 00:07:44

################################################################################
                     [1m Learning iteration 1296/1500 [0m                     

                       Computation: 43586 steps/s (collection: 2.110s, learning 0.146s)
             Mean action noise std: 5.28
          Mean value_function loss: 80.5558
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 94.0824
                       Mean reward: 413.34
               Mean episode length: 231.28
    Episode_Reward/reaching_object: 1.6003
    Episode_Reward/rotating_object: 80.7747
        Episode_Reward/action_rate: -0.1847
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 2.26s
                      Time elapsed: 00:49:00
                               ETA: 00:07:42

################################################################################
                     [1m Learning iteration 1297/1500 [0m                     

                       Computation: 41254 steps/s (collection: 2.258s, learning 0.125s)
             Mean action noise std: 5.28
          Mean value_function loss: 78.9013
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 94.0981
                       Mean reward: 453.05
               Mean episode length: 240.65
    Episode_Reward/reaching_object: 1.6026
    Episode_Reward/rotating_object: 83.0654
        Episode_Reward/action_rate: -0.1861
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 2.38s
                      Time elapsed: 00:49:02
                               ETA: 00:07:40

################################################################################
                     [1m Learning iteration 1298/1500 [0m                     

                       Computation: 46448 steps/s (collection: 2.015s, learning 0.101s)
             Mean action noise std: 5.29
          Mean value_function loss: 64.5475
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 94.1162
                       Mean reward: 402.26
               Mean episode length: 233.68
    Episode_Reward/reaching_object: 1.6406
    Episode_Reward/rotating_object: 82.5197
        Episode_Reward/action_rate: -0.1901
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 2.12s
                      Time elapsed: 00:49:04
                               ETA: 00:07:37

################################################################################
                     [1m Learning iteration 1299/1500 [0m                     

                       Computation: 47577 steps/s (collection: 1.946s, learning 0.121s)
             Mean action noise std: 5.29
          Mean value_function loss: 73.8302
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 94.1406
                       Mean reward: 397.58
               Mean episode length: 221.93
    Episode_Reward/reaching_object: 1.6053
    Episode_Reward/rotating_object: 82.7334
        Episode_Reward/action_rate: -0.1871
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 2.07s
                      Time elapsed: 00:49:06
                               ETA: 00:07:35

################################################################################
                     [1m Learning iteration 1300/1500 [0m                     

                       Computation: 46920 steps/s (collection: 1.968s, learning 0.127s)
             Mean action noise std: 5.29
          Mean value_function loss: 84.0702
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 94.1548
                       Mean reward: 379.76
               Mean episode length: 222.38
    Episode_Reward/reaching_object: 1.5938
    Episode_Reward/rotating_object: 83.3060
        Episode_Reward/action_rate: -0.1837
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 2.10s
                      Time elapsed: 00:49:08
                               ETA: 00:07:33

################################################################################
                     [1m Learning iteration 1301/1500 [0m                     

                       Computation: 45130 steps/s (collection: 2.043s, learning 0.135s)
             Mean action noise std: 5.30
          Mean value_function loss: 89.4781
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 94.1674
                       Mean reward: 483.45
               Mean episode length: 239.60
    Episode_Reward/reaching_object: 1.6584
    Episode_Reward/rotating_object: 86.3616
        Episode_Reward/action_rate: -0.1900
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 2.18s
                      Time elapsed: 00:49:11
                               ETA: 00:07:31

################################################################################
                     [1m Learning iteration 1302/1500 [0m                     

                       Computation: 44116 steps/s (collection: 2.114s, learning 0.114s)
             Mean action noise std: 5.30
          Mean value_function loss: 90.1601
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 94.1836
                       Mean reward: 414.77
               Mean episode length: 228.87
    Episode_Reward/reaching_object: 1.6348
    Episode_Reward/rotating_object: 83.1112
        Episode_Reward/action_rate: -0.1875
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 2.23s
                      Time elapsed: 00:49:13
                               ETA: 00:07:28

################################################################################
                     [1m Learning iteration 1303/1500 [0m                     

                       Computation: 45502 steps/s (collection: 2.059s, learning 0.102s)
             Mean action noise std: 5.30
          Mean value_function loss: 84.8975
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 94.2010
                       Mean reward: 453.92
               Mean episode length: 236.03
    Episode_Reward/reaching_object: 1.6291
    Episode_Reward/rotating_object: 82.3884
        Episode_Reward/action_rate: -0.1879
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 2.16s
                      Time elapsed: 00:49:15
                               ETA: 00:07:26

################################################################################
                     [1m Learning iteration 1304/1500 [0m                     

                       Computation: 46508 steps/s (collection: 2.005s, learning 0.109s)
             Mean action noise std: 5.31
          Mean value_function loss: 80.4258
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 94.2208
                       Mean reward: 394.55
               Mean episode length: 221.31
    Episode_Reward/reaching_object: 1.6335
    Episode_Reward/rotating_object: 85.5046
        Episode_Reward/action_rate: -0.1867
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 2.11s
                      Time elapsed: 00:49:17
                               ETA: 00:07:24

################################################################################
                     [1m Learning iteration 1305/1500 [0m                     

                       Computation: 47554 steps/s (collection: 1.958s, learning 0.109s)
             Mean action noise std: 5.31
          Mean value_function loss: 79.5681
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 94.2353
                       Mean reward: 404.14
               Mean episode length: 218.88
    Episode_Reward/reaching_object: 1.6095
    Episode_Reward/rotating_object: 81.8023
        Episode_Reward/action_rate: -0.1865
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 2.07s
                      Time elapsed: 00:49:19
                               ETA: 00:07:21

################################################################################
                     [1m Learning iteration 1306/1500 [0m                     

                       Computation: 45878 steps/s (collection: 2.021s, learning 0.122s)
             Mean action noise std: 5.31
          Mean value_function loss: 90.2432
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 94.2536
                       Mean reward: 417.11
               Mean episode length: 229.93
    Episode_Reward/reaching_object: 1.5923
    Episode_Reward/rotating_object: 80.7844
        Episode_Reward/action_rate: -0.1835
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 2.14s
                      Time elapsed: 00:49:21
                               ETA: 00:07:19

################################################################################
                     [1m Learning iteration 1307/1500 [0m                     

                       Computation: 43526 steps/s (collection: 2.158s, learning 0.101s)
             Mean action noise std: 5.32
          Mean value_function loss: 80.0310
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 94.2787
                       Mean reward: 370.81
               Mean episode length: 222.06
    Episode_Reward/reaching_object: 1.5264
    Episode_Reward/rotating_object: 74.9826
        Episode_Reward/action_rate: -0.1824
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 2.26s
                      Time elapsed: 00:49:24
                               ETA: 00:07:17

################################################################################
                     [1m Learning iteration 1308/1500 [0m                     

                       Computation: 48222 steps/s (collection: 1.934s, learning 0.104s)
             Mean action noise std: 5.32
          Mean value_function loss: 79.7728
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 94.2981
                       Mean reward: 400.61
               Mean episode length: 224.34
    Episode_Reward/reaching_object: 1.6264
    Episode_Reward/rotating_object: 82.7090
        Episode_Reward/action_rate: -0.1906
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 2.04s
                      Time elapsed: 00:49:26
                               ETA: 00:07:15

################################################################################
                     [1m Learning iteration 1309/1500 [0m                     

                       Computation: 47945 steps/s (collection: 1.949s, learning 0.101s)
             Mean action noise std: 5.32
          Mean value_function loss: 73.8544
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 94.3174
                       Mean reward: 451.25
               Mean episode length: 223.09
    Episode_Reward/reaching_object: 1.6432
    Episode_Reward/rotating_object: 86.2615
        Episode_Reward/action_rate: -0.1898
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 2.05s
                      Time elapsed: 00:49:28
                               ETA: 00:07:12

################################################################################
                     [1m Learning iteration 1310/1500 [0m                     

                       Computation: 47773 steps/s (collection: 1.953s, learning 0.105s)
             Mean action noise std: 5.33
          Mean value_function loss: 73.0277
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 94.3287
                       Mean reward: 422.64
               Mean episode length: 221.69
    Episode_Reward/reaching_object: 1.6121
    Episode_Reward/rotating_object: 84.1241
        Episode_Reward/action_rate: -0.1881
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 2.06s
                      Time elapsed: 00:49:30
                               ETA: 00:07:10

################################################################################
                     [1m Learning iteration 1311/1500 [0m                     

                       Computation: 47862 steps/s (collection: 1.942s, learning 0.112s)
             Mean action noise std: 5.33
          Mean value_function loss: 77.6325
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 94.3382
                       Mean reward: 415.24
               Mean episode length: 224.69
    Episode_Reward/reaching_object: 1.6525
    Episode_Reward/rotating_object: 86.3940
        Episode_Reward/action_rate: -0.1917
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 2.05s
                      Time elapsed: 00:49:32
                               ETA: 00:07:08

################################################################################
                     [1m Learning iteration 1312/1500 [0m                     

                       Computation: 47830 steps/s (collection: 1.953s, learning 0.102s)
             Mean action noise std: 5.33
          Mean value_function loss: 79.8884
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 94.3528
                       Mean reward: 445.74
               Mean episode length: 226.29
    Episode_Reward/reaching_object: 1.5961
    Episode_Reward/rotating_object: 81.8969
        Episode_Reward/action_rate: -0.1884
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 2.06s
                      Time elapsed: 00:49:34
                               ETA: 00:07:05

################################################################################
                     [1m Learning iteration 1313/1500 [0m                     

                       Computation: 47441 steps/s (collection: 1.960s, learning 0.112s)
             Mean action noise std: 5.33
          Mean value_function loss: 84.4033
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 94.3669
                       Mean reward: 389.74
               Mean episode length: 226.34
    Episode_Reward/reaching_object: 1.6362
    Episode_Reward/rotating_object: 82.0820
        Episode_Reward/action_rate: -0.1913
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 2.07s
                      Time elapsed: 00:49:36
                               ETA: 00:07:03

################################################################################
                     [1m Learning iteration 1314/1500 [0m                     

                       Computation: 43516 steps/s (collection: 2.146s, learning 0.113s)
             Mean action noise std: 5.34
          Mean value_function loss: 77.8012
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 94.3854
                       Mean reward: 428.76
               Mean episode length: 230.96
    Episode_Reward/reaching_object: 1.6260
    Episode_Reward/rotating_object: 83.3259
        Episode_Reward/action_rate: -0.1896
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 2.26s
                      Time elapsed: 00:49:38
                               ETA: 00:07:01

################################################################################
                     [1m Learning iteration 1315/1500 [0m                     

                       Computation: 45246 steps/s (collection: 2.052s, learning 0.121s)
             Mean action noise std: 5.34
          Mean value_function loss: 87.8677
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 94.4066
                       Mean reward: 447.48
               Mean episode length: 227.33
    Episode_Reward/reaching_object: 1.5934
    Episode_Reward/rotating_object: 82.8735
        Episode_Reward/action_rate: -0.1854
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 2.17s
                      Time elapsed: 00:49:40
                               ETA: 00:06:59

################################################################################
                     [1m Learning iteration 1316/1500 [0m                     

                       Computation: 45284 steps/s (collection: 2.055s, learning 0.116s)
             Mean action noise std: 5.34
          Mean value_function loss: 88.1560
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 94.4157
                       Mean reward: 449.86
               Mean episode length: 226.49
    Episode_Reward/reaching_object: 1.6094
    Episode_Reward/rotating_object: 82.1685
        Episode_Reward/action_rate: -0.1888
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 2.17s
                      Time elapsed: 00:49:43
                               ETA: 00:06:56

################################################################################
                     [1m Learning iteration 1317/1500 [0m                     

                       Computation: 46334 steps/s (collection: 1.985s, learning 0.137s)
             Mean action noise std: 5.34
          Mean value_function loss: 85.5985
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 94.4262
                       Mean reward: 379.41
               Mean episode length: 218.31
    Episode_Reward/reaching_object: 1.6187
    Episode_Reward/rotating_object: 82.3522
        Episode_Reward/action_rate: -0.1880
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 2.12s
                      Time elapsed: 00:49:45
                               ETA: 00:06:54

################################################################################
                     [1m Learning iteration 1318/1500 [0m                     

                       Computation: 42082 steps/s (collection: 2.195s, learning 0.141s)
             Mean action noise std: 5.35
          Mean value_function loss: 79.3893
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 94.4417
                       Mean reward: 442.53
               Mean episode length: 224.48
    Episode_Reward/reaching_object: 1.6054
    Episode_Reward/rotating_object: 84.6980
        Episode_Reward/action_rate: -0.1873
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 2.34s
                      Time elapsed: 00:49:47
                               ETA: 00:06:52

################################################################################
                     [1m Learning iteration 1319/1500 [0m                     

                       Computation: 45965 steps/s (collection: 2.030s, learning 0.108s)
             Mean action noise std: 5.35
          Mean value_function loss: 81.2952
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 94.4577
                       Mean reward: 402.48
               Mean episode length: 222.35
    Episode_Reward/reaching_object: 1.6015
    Episode_Reward/rotating_object: 79.7827
        Episode_Reward/action_rate: -0.1913
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 2.14s
                      Time elapsed: 00:49:49
                               ETA: 00:06:49

################################################################################
                     [1m Learning iteration 1320/1500 [0m                     

                       Computation: 48056 steps/s (collection: 1.943s, learning 0.102s)
             Mean action noise std: 5.35
          Mean value_function loss: 70.2242
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 94.4735
                       Mean reward: 456.12
               Mean episode length: 235.25
    Episode_Reward/reaching_object: 1.6589
    Episode_Reward/rotating_object: 86.6062
        Episode_Reward/action_rate: -0.1939
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 2.05s
                      Time elapsed: 00:49:51
                               ETA: 00:06:47

################################################################################
                     [1m Learning iteration 1321/1500 [0m                     

                       Computation: 48059 steps/s (collection: 1.943s, learning 0.102s)
             Mean action noise std: 5.36
          Mean value_function loss: 76.0141
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 94.4881
                       Mean reward: 443.30
               Mean episode length: 216.84
    Episode_Reward/reaching_object: 1.6370
    Episode_Reward/rotating_object: 85.6860
        Episode_Reward/action_rate: -0.1930
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 2.05s
                      Time elapsed: 00:49:53
                               ETA: 00:06:45

################################################################################
                     [1m Learning iteration 1322/1500 [0m                     

                       Computation: 46446 steps/s (collection: 1.987s, learning 0.130s)
             Mean action noise std: 5.36
          Mean value_function loss: 78.9483
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 94.5084
                       Mean reward: 475.85
               Mean episode length: 231.96
    Episode_Reward/reaching_object: 1.6826
    Episode_Reward/rotating_object: 89.2096
        Episode_Reward/action_rate: -0.1967
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 2.12s
                      Time elapsed: 00:49:55
                               ETA: 00:06:43

################################################################################
                     [1m Learning iteration 1323/1500 [0m                     

                       Computation: 48192 steps/s (collection: 1.930s, learning 0.110s)
             Mean action noise std: 5.36
          Mean value_function loss: 73.0265
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 94.5233
                       Mean reward: 411.18
               Mean episode length: 226.26
    Episode_Reward/reaching_object: 1.6475
    Episode_Reward/rotating_object: 85.1729
        Episode_Reward/action_rate: -0.1944
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 2.04s
                      Time elapsed: 00:49:57
                               ETA: 00:06:40

################################################################################
                     [1m Learning iteration 1324/1500 [0m                     

                       Computation: 46906 steps/s (collection: 1.973s, learning 0.123s)
             Mean action noise std: 5.36
          Mean value_function loss: 78.2486
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 94.5294
                       Mean reward: 444.83
               Mean episode length: 237.17
    Episode_Reward/reaching_object: 1.6259
    Episode_Reward/rotating_object: 84.3065
        Episode_Reward/action_rate: -0.1949
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 2.10s
                      Time elapsed: 00:49:59
                               ETA: 00:06:38

################################################################################
                     [1m Learning iteration 1325/1500 [0m                     

                       Computation: 46918 steps/s (collection: 1.993s, learning 0.102s)
             Mean action noise std: 5.37
          Mean value_function loss: 81.8456
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 94.5425
                       Mean reward: 462.79
               Mean episode length: 228.74
    Episode_Reward/reaching_object: 1.6251
    Episode_Reward/rotating_object: 84.6231
        Episode_Reward/action_rate: -0.1915
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 2.10s
                      Time elapsed: 00:50:02
                               ETA: 00:06:36

################################################################################
                     [1m Learning iteration 1326/1500 [0m                     

                       Computation: 44493 steps/s (collection: 2.111s, learning 0.098s)
             Mean action noise std: 5.37
          Mean value_function loss: 76.2657
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 94.5563
                       Mean reward: 473.65
               Mean episode length: 233.88
    Episode_Reward/reaching_object: 1.6334
    Episode_Reward/rotating_object: 84.2111
        Episode_Reward/action_rate: -0.1947
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 2.21s
                      Time elapsed: 00:50:04
                               ETA: 00:06:33

################################################################################
                     [1m Learning iteration 1327/1500 [0m                     

                       Computation: 47600 steps/s (collection: 1.956s, learning 0.109s)
             Mean action noise std: 5.37
          Mean value_function loss: 81.0968
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 94.5724
                       Mean reward: 404.75
               Mean episode length: 228.75
    Episode_Reward/reaching_object: 1.5877
    Episode_Reward/rotating_object: 81.8288
        Episode_Reward/action_rate: -0.1901
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 2.07s
                      Time elapsed: 00:50:06
                               ETA: 00:06:31

################################################################################
                     [1m Learning iteration 1328/1500 [0m                     

                       Computation: 46145 steps/s (collection: 2.023s, learning 0.107s)
             Mean action noise std: 5.38
          Mean value_function loss: 87.4807
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 94.5919
                       Mean reward: 497.88
               Mean episode length: 236.00
    Episode_Reward/reaching_object: 1.6555
    Episode_Reward/rotating_object: 88.7565
        Episode_Reward/action_rate: -0.1950
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 2.13s
                      Time elapsed: 00:50:08
                               ETA: 00:06:29

################################################################################
                     [1m Learning iteration 1329/1500 [0m                     

                       Computation: 47079 steps/s (collection: 1.986s, learning 0.102s)
             Mean action noise std: 5.38
          Mean value_function loss: 73.1659
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 94.6131
                       Mean reward: 433.13
               Mean episode length: 226.77
    Episode_Reward/reaching_object: 1.5883
    Episode_Reward/rotating_object: 83.4827
        Episode_Reward/action_rate: -0.1899
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 2.09s
                      Time elapsed: 00:50:10
                               ETA: 00:06:27

################################################################################
                     [1m Learning iteration 1330/1500 [0m                     

                       Computation: 47158 steps/s (collection: 1.986s, learning 0.098s)
             Mean action noise std: 5.39
          Mean value_function loss: 80.2521
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 94.6319
                       Mean reward: 478.57
               Mean episode length: 230.25
    Episode_Reward/reaching_object: 1.6412
    Episode_Reward/rotating_object: 88.4853
        Episode_Reward/action_rate: -0.1941
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 2.08s
                      Time elapsed: 00:50:12
                               ETA: 00:06:24

################################################################################
                     [1m Learning iteration 1331/1500 [0m                     

                       Computation: 46760 steps/s (collection: 1.984s, learning 0.119s)
             Mean action noise std: 5.39
          Mean value_function loss: 75.2618
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 94.6479
                       Mean reward: 450.13
               Mean episode length: 232.21
    Episode_Reward/reaching_object: 1.6759
    Episode_Reward/rotating_object: 90.0711
        Episode_Reward/action_rate: -0.1976
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 2.10s
                      Time elapsed: 00:50:14
                               ETA: 00:06:22

################################################################################
                     [1m Learning iteration 1332/1500 [0m                     

                       Computation: 48162 steps/s (collection: 1.936s, learning 0.106s)
             Mean action noise std: 5.39
          Mean value_function loss: 73.7571
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 94.6668
                       Mean reward: 425.72
               Mean episode length: 230.83
    Episode_Reward/reaching_object: 1.6383
    Episode_Reward/rotating_object: 83.9910
        Episode_Reward/action_rate: -0.1979
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 2.04s
                      Time elapsed: 00:50:16
                               ETA: 00:06:20

################################################################################
                     [1m Learning iteration 1333/1500 [0m                     

                       Computation: 19964 steps/s (collection: 4.800s, learning 0.124s)
             Mean action noise std: 5.40
          Mean value_function loss: 82.2920
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 94.6845
                       Mean reward: 438.44
               Mean episode length: 220.27
    Episode_Reward/reaching_object: 1.6334
    Episode_Reward/rotating_object: 87.3818
        Episode_Reward/action_rate: -0.1949
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 4.92s
                      Time elapsed: 00:50:21
                               ETA: 00:06:18

################################################################################
                     [1m Learning iteration 1334/1500 [0m                     

                       Computation: 15128 steps/s (collection: 6.380s, learning 0.118s)
             Mean action noise std: 5.40
          Mean value_function loss: 79.8813
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 94.7023
                       Mean reward: 447.63
               Mean episode length: 226.59
    Episode_Reward/reaching_object: 1.6130
    Episode_Reward/rotating_object: 85.0920
        Episode_Reward/action_rate: -0.1930
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 6.50s
                      Time elapsed: 00:50:28
                               ETA: 00:06:16

################################################################################
                     [1m Learning iteration 1335/1500 [0m                     

                       Computation: 14974 steps/s (collection: 6.432s, learning 0.133s)
             Mean action noise std: 5.40
          Mean value_function loss: 77.2009
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 94.7193
                       Mean reward: 426.09
               Mean episode length: 213.23
    Episode_Reward/reaching_object: 1.6126
    Episode_Reward/rotating_object: 87.2373
        Episode_Reward/action_rate: -0.1932
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 6.56s
                      Time elapsed: 00:50:34
                               ETA: 00:06:14

################################################################################
                     [1m Learning iteration 1336/1500 [0m                     

                       Computation: 14637 steps/s (collection: 6.598s, learning 0.118s)
             Mean action noise std: 5.41
          Mean value_function loss: 79.1524
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 94.7363
                       Mean reward: 443.40
               Mean episode length: 222.32
    Episode_Reward/reaching_object: 1.6665
    Episode_Reward/rotating_object: 89.7540
        Episode_Reward/action_rate: -0.1993
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 6.72s
                      Time elapsed: 00:50:41
                               ETA: 00:06:13

################################################################################
                     [1m Learning iteration 1337/1500 [0m                     

                       Computation: 14805 steps/s (collection: 6.506s, learning 0.134s)
             Mean action noise std: 5.41
          Mean value_function loss: 81.9571
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 94.7531
                       Mean reward: 454.09
               Mean episode length: 225.06
    Episode_Reward/reaching_object: 1.6540
    Episode_Reward/rotating_object: 88.0653
        Episode_Reward/action_rate: -0.1968
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 6.64s
                      Time elapsed: 00:50:48
                               ETA: 00:06:11

################################################################################
                     [1m Learning iteration 1338/1500 [0m                     

                       Computation: 15223 steps/s (collection: 6.322s, learning 0.135s)
             Mean action noise std: 5.41
          Mean value_function loss: 86.8602
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 94.7658
                       Mean reward: 440.81
               Mean episode length: 231.27
    Episode_Reward/reaching_object: 1.7110
    Episode_Reward/rotating_object: 91.6969
        Episode_Reward/action_rate: -0.2021
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 6.46s
                      Time elapsed: 00:50:54
                               ETA: 00:06:09

################################################################################
                     [1m Learning iteration 1339/1500 [0m                     

                       Computation: 14869 steps/s (collection: 6.489s, learning 0.122s)
             Mean action noise std: 5.42
          Mean value_function loss: 77.9150
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 94.7781
                       Mean reward: 482.30
               Mean episode length: 227.29
    Episode_Reward/reaching_object: 1.6244
    Episode_Reward/rotating_object: 85.6389
        Episode_Reward/action_rate: -0.1943
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 6.61s
                      Time elapsed: 00:51:01
                               ETA: 00:06:07

################################################################################
                     [1m Learning iteration 1340/1500 [0m                     

                       Computation: 14840 steps/s (collection: 6.482s, learning 0.142s)
             Mean action noise std: 5.42
          Mean value_function loss: 77.6170
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 94.8007
                       Mean reward: 467.93
               Mean episode length: 227.89
    Episode_Reward/reaching_object: 1.6354
    Episode_Reward/rotating_object: 87.0922
        Episode_Reward/action_rate: -0.1961
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 6.62s
                      Time elapsed: 00:51:07
                               ETA: 00:06:06

################################################################################
                     [1m Learning iteration 1341/1500 [0m                     

                       Computation: 13860 steps/s (collection: 6.982s, learning 0.110s)
             Mean action noise std: 5.42
          Mean value_function loss: 81.4668
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 94.8205
                       Mean reward: 426.96
               Mean episode length: 228.08
    Episode_Reward/reaching_object: 1.6775
    Episode_Reward/rotating_object: 87.8745
        Episode_Reward/action_rate: -0.2008
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 7.09s
                      Time elapsed: 00:51:14
                               ETA: 00:06:04

################################################################################
                     [1m Learning iteration 1342/1500 [0m                     

                       Computation: 49831 steps/s (collection: 1.879s, learning 0.094s)
             Mean action noise std: 5.43
          Mean value_function loss: 76.3681
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 94.8327
                       Mean reward: 430.75
               Mean episode length: 231.22
    Episode_Reward/reaching_object: 1.6600
    Episode_Reward/rotating_object: 87.8871
        Episode_Reward/action_rate: -0.1972
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 1.97s
                      Time elapsed: 00:51:16
                               ETA: 00:06:01

################################################################################
                     [1m Learning iteration 1343/1500 [0m                     

                       Computation: 50152 steps/s (collection: 1.858s, learning 0.102s)
             Mean action noise std: 5.43
          Mean value_function loss: 73.6637
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 94.8459
                       Mean reward: 401.78
               Mean episode length: 232.54
    Episode_Reward/reaching_object: 1.6362
    Episode_Reward/rotating_object: 86.3580
        Episode_Reward/action_rate: -0.1966
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 1.96s
                      Time elapsed: 00:51:18
                               ETA: 00:05:59

################################################################################
                     [1m Learning iteration 1344/1500 [0m                     

                       Computation: 50465 steps/s (collection: 1.839s, learning 0.109s)
             Mean action noise std: 5.43
          Mean value_function loss: 77.0837
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 94.8690
                       Mean reward: 449.25
               Mean episode length: 230.06
    Episode_Reward/reaching_object: 1.6733
    Episode_Reward/rotating_object: 85.3239
        Episode_Reward/action_rate: -0.1991
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 1.95s
                      Time elapsed: 00:51:20
                               ETA: 00:05:57

################################################################################
                     [1m Learning iteration 1345/1500 [0m                     

                       Computation: 49256 steps/s (collection: 1.880s, learning 0.116s)
             Mean action noise std: 5.44
          Mean value_function loss: 78.1072
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 94.8889
                       Mean reward: 472.39
               Mean episode length: 238.56
    Episode_Reward/reaching_object: 1.6575
    Episode_Reward/rotating_object: 87.9034
        Episode_Reward/action_rate: -0.1982
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 2.00s
                      Time elapsed: 00:51:22
                               ETA: 00:05:55

################################################################################
                     [1m Learning iteration 1346/1500 [0m                     

                       Computation: 49909 steps/s (collection: 1.855s, learning 0.115s)
             Mean action noise std: 5.44
          Mean value_function loss: 91.8874
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 94.9101
                       Mean reward: 452.17
               Mean episode length: 232.85
    Episode_Reward/reaching_object: 1.6417
    Episode_Reward/rotating_object: 83.8180
        Episode_Reward/action_rate: -0.1990
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 1.97s
                      Time elapsed: 00:51:24
                               ETA: 00:05:52

################################################################################
                     [1m Learning iteration 1347/1500 [0m                     

                       Computation: 49246 steps/s (collection: 1.883s, learning 0.114s)
             Mean action noise std: 5.44
          Mean value_function loss: 85.3030
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 94.9227
                       Mean reward: 458.94
               Mean episode length: 228.74
    Episode_Reward/reaching_object: 1.6562
    Episode_Reward/rotating_object: 89.1500
        Episode_Reward/action_rate: -0.1992
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 2.00s
                      Time elapsed: 00:51:26
                               ETA: 00:05:50

################################################################################
                     [1m Learning iteration 1348/1500 [0m                     

                       Computation: 51404 steps/s (collection: 1.823s, learning 0.089s)
             Mean action noise std: 5.45
          Mean value_function loss: 83.0036
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 94.9404
                       Mean reward: 457.66
               Mean episode length: 226.93
    Episode_Reward/reaching_object: 1.6827
    Episode_Reward/rotating_object: 90.9752
        Episode_Reward/action_rate: -0.1996
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 1.91s
                      Time elapsed: 00:51:28
                               ETA: 00:05:48

################################################################################
                     [1m Learning iteration 1349/1500 [0m                     

                       Computation: 50230 steps/s (collection: 1.844s, learning 0.113s)
             Mean action noise std: 5.45
          Mean value_function loss: 85.4141
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 94.9539
                       Mean reward: 472.67
               Mean episode length: 231.96
    Episode_Reward/reaching_object: 1.6332
    Episode_Reward/rotating_object: 85.9187
        Episode_Reward/action_rate: -0.1965
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 1.96s
                      Time elapsed: 00:51:30
                               ETA: 00:05:45

################################################################################
                     [1m Learning iteration 1350/1500 [0m                     

                       Computation: 41788 steps/s (collection: 2.241s, learning 0.111s)
             Mean action noise std: 5.45
          Mean value_function loss: 77.9841
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 94.9653
                       Mean reward: 456.86
               Mean episode length: 231.13
    Episode_Reward/reaching_object: 1.6749
    Episode_Reward/rotating_object: 88.8222
        Episode_Reward/action_rate: -0.2000
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 2.35s
                      Time elapsed: 00:51:32
                               ETA: 00:05:43

################################################################################
                     [1m Learning iteration 1351/1500 [0m                     

                       Computation: 48563 steps/s (collection: 1.923s, learning 0.101s)
             Mean action noise std: 5.46
          Mean value_function loss: 73.5788
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 94.9756
                       Mean reward: 449.71
               Mean episode length: 228.25
    Episode_Reward/reaching_object: 1.6766
    Episode_Reward/rotating_object: 87.7931
        Episode_Reward/action_rate: -0.2028
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 2.02s
                      Time elapsed: 00:51:35
                               ETA: 00:05:41

################################################################################
                     [1m Learning iteration 1352/1500 [0m                     

                       Computation: 49142 steps/s (collection: 1.900s, learning 0.101s)
             Mean action noise std: 5.46
          Mean value_function loss: 70.4850
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 94.9902
                       Mean reward: 445.23
               Mean episode length: 230.95
    Episode_Reward/reaching_object: 1.6337
    Episode_Reward/rotating_object: 84.1542
        Episode_Reward/action_rate: -0.1982
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 2.00s
                      Time elapsed: 00:51:37
                               ETA: 00:05:38

################################################################################
                     [1m Learning iteration 1353/1500 [0m                     

                       Computation: 50403 steps/s (collection: 1.858s, learning 0.092s)
             Mean action noise std: 5.46
          Mean value_function loss: 80.7778
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 95.0064
                       Mean reward: 437.53
               Mean episode length: 228.70
    Episode_Reward/reaching_object: 1.6671
    Episode_Reward/rotating_object: 86.5231
        Episode_Reward/action_rate: -0.2029
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 1.95s
                      Time elapsed: 00:51:38
                               ETA: 00:05:36

################################################################################
                     [1m Learning iteration 1354/1500 [0m                     

                       Computation: 52693 steps/s (collection: 1.773s, learning 0.093s)
             Mean action noise std: 5.47
          Mean value_function loss: 73.8871
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 95.0263
                       Mean reward: 432.51
               Mean episode length: 236.10
    Episode_Reward/reaching_object: 1.7060
    Episode_Reward/rotating_object: 89.2396
        Episode_Reward/action_rate: -0.2064
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 1.87s
                      Time elapsed: 00:51:40
                               ETA: 00:05:34

################################################################################
                     [1m Learning iteration 1355/1500 [0m                     

                       Computation: 52168 steps/s (collection: 1.777s, learning 0.108s)
             Mean action noise std: 5.47
          Mean value_function loss: 78.5797
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 95.0468
                       Mean reward: 418.68
               Mean episode length: 228.37
    Episode_Reward/reaching_object: 1.6408
    Episode_Reward/rotating_object: 86.1882
        Episode_Reward/action_rate: -0.2013
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 1.88s
                      Time elapsed: 00:51:42
                               ETA: 00:05:31

################################################################################
                     [1m Learning iteration 1356/1500 [0m                     

                       Computation: 52871 steps/s (collection: 1.769s, learning 0.091s)
             Mean action noise std: 5.47
          Mean value_function loss: 71.3884
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 95.0626
                       Mean reward: 420.04
               Mean episode length: 220.98
    Episode_Reward/reaching_object: 1.6422
    Episode_Reward/rotating_object: 84.1523
        Episode_Reward/action_rate: -0.2017
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 18.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 1.86s
                      Time elapsed: 00:51:44
                               ETA: 00:05:29

################################################################################
                     [1m Learning iteration 1357/1500 [0m                     

                       Computation: 50637 steps/s (collection: 1.834s, learning 0.107s)
             Mean action noise std: 5.47
          Mean value_function loss: 83.7216
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 95.0779
                       Mean reward: 400.51
               Mean episode length: 229.13
    Episode_Reward/reaching_object: 1.6128
    Episode_Reward/rotating_object: 85.2971
        Episode_Reward/action_rate: -0.1985
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 1.94s
                      Time elapsed: 00:51:46
                               ETA: 00:05:27

################################################################################
                     [1m Learning iteration 1358/1500 [0m                     

                       Computation: 51090 steps/s (collection: 1.829s, learning 0.096s)
             Mean action noise std: 5.48
          Mean value_function loss: 81.7567
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 95.0900
                       Mean reward: 421.92
               Mean episode length: 216.77
    Episode_Reward/reaching_object: 1.6283
    Episode_Reward/rotating_object: 88.6304
        Episode_Reward/action_rate: -0.1977
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 1.92s
                      Time elapsed: 00:51:48
                               ETA: 00:05:24

################################################################################
                     [1m Learning iteration 1359/1500 [0m                     

                       Computation: 51920 steps/s (collection: 1.797s, learning 0.097s)
             Mean action noise std: 5.48
          Mean value_function loss: 80.6671
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 95.1094
                       Mean reward: 451.10
               Mean episode length: 223.54
    Episode_Reward/reaching_object: 1.6046
    Episode_Reward/rotating_object: 85.9536
        Episode_Reward/action_rate: -0.1973
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 1.89s
                      Time elapsed: 00:51:50
                               ETA: 00:05:22

################################################################################
                     [1m Learning iteration 1360/1500 [0m                     

                       Computation: 51994 steps/s (collection: 1.779s, learning 0.112s)
             Mean action noise std: 5.49
          Mean value_function loss: 78.1643
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 95.1249
                       Mean reward: 400.36
               Mean episode length: 228.93
    Episode_Reward/reaching_object: 1.6392
    Episode_Reward/rotating_object: 88.2236
        Episode_Reward/action_rate: -0.2023
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 1.89s
                      Time elapsed: 00:51:52
                               ETA: 00:05:20

################################################################################
                     [1m Learning iteration 1361/1500 [0m                     

                       Computation: 51670 steps/s (collection: 1.800s, learning 0.102s)
             Mean action noise std: 5.49
          Mean value_function loss: 77.3772
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 95.1401
                       Mean reward: 449.39
               Mean episode length: 227.56
    Episode_Reward/reaching_object: 1.6132
    Episode_Reward/rotating_object: 85.2650
        Episode_Reward/action_rate: -0.1981
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 1.90s
                      Time elapsed: 00:51:54
                               ETA: 00:05:17

################################################################################
                     [1m Learning iteration 1362/1500 [0m                     

                       Computation: 51646 steps/s (collection: 1.790s, learning 0.113s)
             Mean action noise std: 5.49
          Mean value_function loss: 77.9824
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 95.1546
                       Mean reward: 462.36
               Mean episode length: 228.00
    Episode_Reward/reaching_object: 1.6587
    Episode_Reward/rotating_object: 89.7880
        Episode_Reward/action_rate: -0.2011
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 1.90s
                      Time elapsed: 00:51:56
                               ETA: 00:05:15

################################################################################
                     [1m Learning iteration 1363/1500 [0m                     

                       Computation: 48524 steps/s (collection: 1.921s, learning 0.105s)
             Mean action noise std: 5.50
          Mean value_function loss: 78.1923
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 95.1779
                       Mean reward: 451.54
               Mean episode length: 233.78
    Episode_Reward/reaching_object: 1.6912
    Episode_Reward/rotating_object: 91.3081
        Episode_Reward/action_rate: -0.2084
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 2.03s
                      Time elapsed: 00:51:58
                               ETA: 00:05:13

################################################################################
                     [1m Learning iteration 1364/1500 [0m                     

                       Computation: 51366 steps/s (collection: 1.823s, learning 0.091s)
             Mean action noise std: 5.50
          Mean value_function loss: 75.3960
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 95.1947
                       Mean reward: 467.08
               Mean episode length: 235.90
    Episode_Reward/reaching_object: 1.6512
    Episode_Reward/rotating_object: 89.5035
        Episode_Reward/action_rate: -0.2025
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 1.91s
                      Time elapsed: 00:51:59
                               ETA: 00:05:10

################################################################################
                     [1m Learning iteration 1365/1500 [0m                     

                       Computation: 50997 steps/s (collection: 1.834s, learning 0.094s)
             Mean action noise std: 5.50
          Mean value_function loss: 76.3941
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 95.2057
                       Mean reward: 427.21
               Mean episode length: 233.65
    Episode_Reward/reaching_object: 1.6263
    Episode_Reward/rotating_object: 85.3449
        Episode_Reward/action_rate: -0.2023
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 1.93s
                      Time elapsed: 00:52:01
                               ETA: 00:05:08

################################################################################
                     [1m Learning iteration 1366/1500 [0m                     

                       Computation: 52122 steps/s (collection: 1.797s, learning 0.089s)
             Mean action noise std: 5.50
          Mean value_function loss: 80.6383
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 95.2199
                       Mean reward: 414.61
               Mean episode length: 220.50
    Episode_Reward/reaching_object: 1.6245
    Episode_Reward/rotating_object: 85.1548
        Episode_Reward/action_rate: -0.2029
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 1.89s
                      Time elapsed: 00:52:03
                               ETA: 00:05:06

################################################################################
                     [1m Learning iteration 1367/1500 [0m                     

                       Computation: 52244 steps/s (collection: 1.793s, learning 0.089s)
             Mean action noise std: 5.51
          Mean value_function loss: 79.5198
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 95.2451
                       Mean reward: 420.88
               Mean episode length: 220.68
    Episode_Reward/reaching_object: 1.6598
    Episode_Reward/rotating_object: 92.0953
        Episode_Reward/action_rate: -0.2033
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 1.88s
                      Time elapsed: 00:52:05
                               ETA: 00:05:03

################################################################################
                     [1m Learning iteration 1368/1500 [0m                     

                       Computation: 52503 steps/s (collection: 1.778s, learning 0.094s)
             Mean action noise std: 5.51
          Mean value_function loss: 78.5186
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 95.2669
                       Mean reward: 458.38
               Mean episode length: 224.92
    Episode_Reward/reaching_object: 1.5925
    Episode_Reward/rotating_object: 86.4853
        Episode_Reward/action_rate: -0.1989
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 1.87s
                      Time elapsed: 00:52:07
                               ETA: 00:05:01

################################################################################
                     [1m Learning iteration 1369/1500 [0m                     

                       Computation: 51956 steps/s (collection: 1.796s, learning 0.096s)
             Mean action noise std: 5.52
          Mean value_function loss: 81.2953
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 95.2822
                       Mean reward: 447.29
               Mean episode length: 222.28
    Episode_Reward/reaching_object: 1.6397
    Episode_Reward/rotating_object: 90.3111
        Episode_Reward/action_rate: -0.2028
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 1.89s
                      Time elapsed: 00:52:09
                               ETA: 00:04:59

################################################################################
                     [1m Learning iteration 1370/1500 [0m                     

                       Computation: 52331 steps/s (collection: 1.779s, learning 0.099s)
             Mean action noise std: 5.52
          Mean value_function loss: 83.6404
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 95.3028
                       Mean reward: 413.02
               Mean episode length: 225.49
    Episode_Reward/reaching_object: 1.5960
    Episode_Reward/rotating_object: 87.2288
        Episode_Reward/action_rate: -0.1987
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 1.88s
                      Time elapsed: 00:52:11
                               ETA: 00:04:56

################################################################################
                     [1m Learning iteration 1371/1500 [0m                     

                       Computation: 51535 steps/s (collection: 1.805s, learning 0.102s)
             Mean action noise std: 5.52
          Mean value_function loss: 81.7933
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 95.3228
                       Mean reward: 460.82
               Mean episode length: 233.24
    Episode_Reward/reaching_object: 1.6307
    Episode_Reward/rotating_object: 87.8515
        Episode_Reward/action_rate: -0.2042
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 1.91s
                      Time elapsed: 00:52:13
                               ETA: 00:04:54

################################################################################
                     [1m Learning iteration 1372/1500 [0m                     

                       Computation: 52058 steps/s (collection: 1.787s, learning 0.101s)
             Mean action noise std: 5.53
          Mean value_function loss: 74.7618
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 95.3459
                       Mean reward: 465.45
               Mean episode length: 236.61
    Episode_Reward/reaching_object: 1.6685
    Episode_Reward/rotating_object: 89.8310
        Episode_Reward/action_rate: -0.2077
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 1.89s
                      Time elapsed: 00:52:15
                               ETA: 00:04:52

################################################################################
                     [1m Learning iteration 1373/1500 [0m                     

                       Computation: 51531 steps/s (collection: 1.818s, learning 0.090s)
             Mean action noise std: 5.53
          Mean value_function loss: 73.1246
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 95.3671
                       Mean reward: 472.82
               Mean episode length: 225.30
    Episode_Reward/reaching_object: 1.6139
    Episode_Reward/rotating_object: 87.2060
        Episode_Reward/action_rate: -0.2039
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 1.91s
                      Time elapsed: 00:52:17
                               ETA: 00:04:49

################################################################################
                     [1m Learning iteration 1374/1500 [0m                     

                       Computation: 51721 steps/s (collection: 1.811s, learning 0.090s)
             Mean action noise std: 5.53
          Mean value_function loss: 80.8891
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 95.3837
                       Mean reward: 469.49
               Mean episode length: 230.02
    Episode_Reward/reaching_object: 1.6740
    Episode_Reward/rotating_object: 92.2446
        Episode_Reward/action_rate: -0.2069
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 1.90s
                      Time elapsed: 00:52:18
                               ETA: 00:04:47

################################################################################
                     [1m Learning iteration 1375/1500 [0m                     

                       Computation: 51946 steps/s (collection: 1.801s, learning 0.091s)
             Mean action noise std: 5.54
          Mean value_function loss: 77.3809
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 95.4047
                       Mean reward: 451.69
               Mean episode length: 226.62
    Episode_Reward/reaching_object: 1.6098
    Episode_Reward/rotating_object: 87.2246
        Episode_Reward/action_rate: -0.2016
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 1.89s
                      Time elapsed: 00:52:20
                               ETA: 00:04:45

################################################################################
                     [1m Learning iteration 1376/1500 [0m                     

                       Computation: 51645 steps/s (collection: 1.792s, learning 0.111s)
             Mean action noise std: 5.54
          Mean value_function loss: 88.9829
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 95.4292
                       Mean reward: 442.15
               Mean episode length: 228.00
    Episode_Reward/reaching_object: 1.6251
    Episode_Reward/rotating_object: 90.9270
        Episode_Reward/action_rate: -0.2017
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 1.90s
                      Time elapsed: 00:52:22
                               ETA: 00:04:43

################################################################################
                     [1m Learning iteration 1377/1500 [0m                     

                       Computation: 51485 steps/s (collection: 1.793s, learning 0.116s)
             Mean action noise std: 5.55
          Mean value_function loss: 75.4288
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 95.4484
                       Mean reward: 431.36
               Mean episode length: 229.04
    Episode_Reward/reaching_object: 1.6201
    Episode_Reward/rotating_object: 85.6711
        Episode_Reward/action_rate: -0.2054
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 1.91s
                      Time elapsed: 00:52:24
                               ETA: 00:04:40

################################################################################
                     [1m Learning iteration 1378/1500 [0m                     

                       Computation: 48661 steps/s (collection: 1.877s, learning 0.144s)
             Mean action noise std: 5.55
          Mean value_function loss: 85.4471
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 95.4673
                       Mean reward: 480.90
               Mean episode length: 228.86
    Episode_Reward/reaching_object: 1.5945
    Episode_Reward/rotating_object: 85.6136
        Episode_Reward/action_rate: -0.2013
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 2.02s
                      Time elapsed: 00:52:26
                               ETA: 00:04:38

################################################################################
                     [1m Learning iteration 1379/1500 [0m                     

                       Computation: 51316 steps/s (collection: 1.823s, learning 0.093s)
             Mean action noise std: 5.55
          Mean value_function loss: 84.6292
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 95.4750
                       Mean reward: 476.93
               Mean episode length: 220.39
    Episode_Reward/reaching_object: 1.6378
    Episode_Reward/rotating_object: 90.6395
        Episode_Reward/action_rate: -0.2027
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 1.92s
                      Time elapsed: 00:52:28
                               ETA: 00:04:36

################################################################################
                     [1m Learning iteration 1380/1500 [0m                     

                       Computation: 51612 steps/s (collection: 1.811s, learning 0.094s)
             Mean action noise std: 5.55
          Mean value_function loss: 93.1648
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 95.4823
                       Mean reward: 455.32
               Mean episode length: 228.16
    Episode_Reward/reaching_object: 1.6270
    Episode_Reward/rotating_object: 85.7371
        Episode_Reward/action_rate: -0.2039
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 1.90s
                      Time elapsed: 00:52:30
                               ETA: 00:04:33

################################################################################
                     [1m Learning iteration 1381/1500 [0m                     

                       Computation: 51748 steps/s (collection: 1.800s, learning 0.100s)
             Mean action noise std: 5.56
          Mean value_function loss: 88.6604
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 95.4913
                       Mean reward: 394.24
               Mean episode length: 213.72
    Episode_Reward/reaching_object: 1.5961
    Episode_Reward/rotating_object: 85.4579
        Episode_Reward/action_rate: -0.2008
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 1.90s
                      Time elapsed: 00:52:32
                               ETA: 00:04:31

################################################################################
                     [1m Learning iteration 1382/1500 [0m                     

                       Computation: 51443 steps/s (collection: 1.814s, learning 0.097s)
             Mean action noise std: 5.56
          Mean value_function loss: 79.0183
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 95.5074
                       Mean reward: 419.21
               Mean episode length: 219.45
    Episode_Reward/reaching_object: 1.6346
    Episode_Reward/rotating_object: 86.5614
        Episode_Reward/action_rate: -0.2066
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 1.91s
                      Time elapsed: 00:52:34
                               ETA: 00:04:29

################################################################################
                     [1m Learning iteration 1383/1500 [0m                     

                       Computation: 51264 steps/s (collection: 1.824s, learning 0.094s)
             Mean action noise std: 5.56
          Mean value_function loss: 69.5811
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 95.5322
                       Mean reward: 457.07
               Mean episode length: 231.20
    Episode_Reward/reaching_object: 1.6576
    Episode_Reward/rotating_object: 87.6460
        Episode_Reward/action_rate: -0.2076
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 1.92s
                      Time elapsed: 00:52:36
                               ETA: 00:04:26

################################################################################
                     [1m Learning iteration 1384/1500 [0m                     

                       Computation: 51232 steps/s (collection: 1.820s, learning 0.098s)
             Mean action noise std: 5.57
          Mean value_function loss: 80.1383
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 95.5507
                       Mean reward: 428.89
               Mean episode length: 217.62
    Episode_Reward/reaching_object: 1.5992
    Episode_Reward/rotating_object: 87.7477
        Episode_Reward/action_rate: -0.2012
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 1.92s
                      Time elapsed: 00:52:38
                               ETA: 00:04:24

################################################################################
                     [1m Learning iteration 1385/1500 [0m                     

                       Computation: 50954 steps/s (collection: 1.830s, learning 0.100s)
             Mean action noise std: 5.57
          Mean value_function loss: 74.4174
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 95.5750
                       Mean reward: 488.28
               Mean episode length: 230.81
    Episode_Reward/reaching_object: 1.6414
    Episode_Reward/rotating_object: 86.7546
        Episode_Reward/action_rate: -0.2092
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 1.93s
                      Time elapsed: 00:52:40
                               ETA: 00:04:22

################################################################################
                     [1m Learning iteration 1386/1500 [0m                     

                       Computation: 52083 steps/s (collection: 1.789s, learning 0.098s)
             Mean action noise std: 5.58
          Mean value_function loss: 76.2070
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 95.6001
                       Mean reward: 438.32
               Mean episode length: 227.24
    Episode_Reward/reaching_object: 1.6113
    Episode_Reward/rotating_object: 83.6377
        Episode_Reward/action_rate: -0.2064
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 1.89s
                      Time elapsed: 00:52:41
                               ETA: 00:04:19

################################################################################
                     [1m Learning iteration 1387/1500 [0m                     

                       Computation: 52537 steps/s (collection: 1.778s, learning 0.094s)
             Mean action noise std: 5.58
          Mean value_function loss: 76.4757
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 95.6180
                       Mean reward: 467.39
               Mean episode length: 224.96
    Episode_Reward/reaching_object: 1.6644
    Episode_Reward/rotating_object: 88.6113
        Episode_Reward/action_rate: -0.2121
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 1.87s
                      Time elapsed: 00:52:43
                               ETA: 00:04:17

################################################################################
                     [1m Learning iteration 1388/1500 [0m                     

                       Computation: 51778 steps/s (collection: 1.801s, learning 0.098s)
             Mean action noise std: 5.58
          Mean value_function loss: 79.3402
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 95.6392
                       Mean reward: 441.09
               Mean episode length: 215.53
    Episode_Reward/reaching_object: 1.5996
    Episode_Reward/rotating_object: 85.9578
        Episode_Reward/action_rate: -0.2018
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 1.90s
                      Time elapsed: 00:52:45
                               ETA: 00:04:15

################################################################################
                     [1m Learning iteration 1389/1500 [0m                     

                       Computation: 51987 steps/s (collection: 1.794s, learning 0.097s)
             Mean action noise std: 5.59
          Mean value_function loss: 73.0562
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 95.6577
                       Mean reward: 454.40
               Mean episode length: 229.12
    Episode_Reward/reaching_object: 1.6662
    Episode_Reward/rotating_object: 90.0513
        Episode_Reward/action_rate: -0.2105
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 1.89s
                      Time elapsed: 00:52:47
                               ETA: 00:04:12

################################################################################
                     [1m Learning iteration 1390/1500 [0m                     

                       Computation: 51222 steps/s (collection: 1.827s, learning 0.092s)
             Mean action noise std: 5.59
          Mean value_function loss: 83.6258
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 95.6737
                       Mean reward: 452.94
               Mean episode length: 228.36
    Episode_Reward/reaching_object: 1.6549
    Episode_Reward/rotating_object: 87.8621
        Episode_Reward/action_rate: -0.2106
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 1.92s
                      Time elapsed: 00:52:49
                               ETA: 00:04:10

################################################################################
                     [1m Learning iteration 1391/1500 [0m                     

                       Computation: 51149 steps/s (collection: 1.823s, learning 0.099s)
             Mean action noise std: 5.59
          Mean value_function loss: 82.1967
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 95.6961
                       Mean reward: 452.33
               Mean episode length: 227.11
    Episode_Reward/reaching_object: 1.6449
    Episode_Reward/rotating_object: 88.3686
        Episode_Reward/action_rate: -0.2096
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 1.92s
                      Time elapsed: 00:52:51
                               ETA: 00:04:08

################################################################################
                     [1m Learning iteration 1392/1500 [0m                     

                       Computation: 51115 steps/s (collection: 1.805s, learning 0.119s)
             Mean action noise std: 5.60
          Mean value_function loss: 80.9066
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 95.7085
                       Mean reward: 445.20
               Mean episode length: 223.59
    Episode_Reward/reaching_object: 1.6363
    Episode_Reward/rotating_object: 88.8278
        Episode_Reward/action_rate: -0.2084
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 1.92s
                      Time elapsed: 00:52:53
                               ETA: 00:04:06

################################################################################
                     [1m Learning iteration 1393/1500 [0m                     

                       Computation: 51951 steps/s (collection: 1.792s, learning 0.101s)
             Mean action noise std: 5.60
          Mean value_function loss: 78.6700
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 95.7179
                       Mean reward: 451.99
               Mean episode length: 224.13
    Episode_Reward/reaching_object: 1.6048
    Episode_Reward/rotating_object: 86.4590
        Episode_Reward/action_rate: -0.2043
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 1.89s
                      Time elapsed: 00:52:55
                               ETA: 00:04:03

################################################################################
                     [1m Learning iteration 1394/1500 [0m                     

                       Computation: 49478 steps/s (collection: 1.878s, learning 0.109s)
             Mean action noise std: 5.60
          Mean value_function loss: 77.4128
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 95.7300
                       Mean reward: 467.73
               Mean episode length: 231.50
    Episode_Reward/reaching_object: 1.6803
    Episode_Reward/rotating_object: 91.6525
        Episode_Reward/action_rate: -0.2127
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 1.99s
                      Time elapsed: 00:52:57
                               ETA: 00:04:01

################################################################################
                     [1m Learning iteration 1395/1500 [0m                     

                       Computation: 51013 steps/s (collection: 1.829s, learning 0.098s)
             Mean action noise std: 5.60
          Mean value_function loss: 73.5235
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 95.7364
                       Mean reward: 479.41
               Mean episode length: 228.44
    Episode_Reward/reaching_object: 1.6897
    Episode_Reward/rotating_object: 93.3574
        Episode_Reward/action_rate: -0.2128
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 1.93s
                      Time elapsed: 00:52:59
                               ETA: 00:03:59

################################################################################
                     [1m Learning iteration 1396/1500 [0m                     

                       Computation: 49758 steps/s (collection: 1.874s, learning 0.102s)
             Mean action noise std: 5.61
          Mean value_function loss: 82.0780
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 95.7482
                       Mean reward: 477.26
               Mean episode length: 229.35
    Episode_Reward/reaching_object: 1.6620
    Episode_Reward/rotating_object: 93.3526
        Episode_Reward/action_rate: -0.2091
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 1.98s
                      Time elapsed: 00:53:01
                               ETA: 00:03:56

################################################################################
                     [1m Learning iteration 1397/1500 [0m                     

                       Computation: 50228 steps/s (collection: 1.864s, learning 0.093s)
             Mean action noise std: 5.61
          Mean value_function loss: 75.0782
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 95.7643
                       Mean reward: 455.00
               Mean episode length: 231.48
    Episode_Reward/reaching_object: 1.6765
    Episode_Reward/rotating_object: 92.3340
        Episode_Reward/action_rate: -0.2121
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 1.96s
                      Time elapsed: 00:53:03
                               ETA: 00:03:54

################################################################################
                     [1m Learning iteration 1398/1500 [0m                     

                       Computation: 51720 steps/s (collection: 1.802s, learning 0.099s)
             Mean action noise std: 5.62
          Mean value_function loss: 82.0852
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 95.7825
                       Mean reward: 429.84
               Mean episode length: 214.41
    Episode_Reward/reaching_object: 1.6503
    Episode_Reward/rotating_object: 88.9987
        Episode_Reward/action_rate: -0.2092
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 1.90s
                      Time elapsed: 00:53:04
                               ETA: 00:03:52

################################################################################
                     [1m Learning iteration 1399/1500 [0m                     

                       Computation: 49539 steps/s (collection: 1.889s, learning 0.095s)
             Mean action noise std: 5.62
          Mean value_function loss: 82.4026
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 95.8061
                       Mean reward: 436.01
               Mean episode length: 236.32
    Episode_Reward/reaching_object: 1.6625
    Episode_Reward/rotating_object: 88.7973
        Episode_Reward/action_rate: -0.2131
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 1.98s
                      Time elapsed: 00:53:06
                               ETA: 00:03:49

################################################################################
                     [1m Learning iteration 1400/1500 [0m                     

                       Computation: 51269 steps/s (collection: 1.819s, learning 0.098s)
             Mean action noise std: 5.62
          Mean value_function loss: 83.7234
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 95.8236
                       Mean reward: 457.55
               Mean episode length: 229.63
    Episode_Reward/reaching_object: 1.6590
    Episode_Reward/rotating_object: 87.8583
        Episode_Reward/action_rate: -0.2112
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 1.92s
                      Time elapsed: 00:53:08
                               ETA: 00:03:47

################################################################################
                     [1m Learning iteration 1401/1500 [0m                     

                       Computation: 51472 steps/s (collection: 1.814s, learning 0.096s)
             Mean action noise std: 5.63
          Mean value_function loss: 83.7411
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 95.8462
                       Mean reward: 471.17
               Mean episode length: 222.10
    Episode_Reward/reaching_object: 1.6568
    Episode_Reward/rotating_object: 90.7390
        Episode_Reward/action_rate: -0.2107
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 1.91s
                      Time elapsed: 00:53:10
                               ETA: 00:03:45

################################################################################
                     [1m Learning iteration 1402/1500 [0m                     

                       Computation: 52282 steps/s (collection: 1.789s, learning 0.091s)
             Mean action noise std: 5.63
          Mean value_function loss: 74.4113
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 95.8668
                       Mean reward: 444.71
               Mean episode length: 220.96
    Episode_Reward/reaching_object: 1.7033
    Episode_Reward/rotating_object: 94.4515
        Episode_Reward/action_rate: -0.2143
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 1.88s
                      Time elapsed: 00:53:12
                               ETA: 00:03:43

################################################################################
                     [1m Learning iteration 1403/1500 [0m                     

                       Computation: 51391 steps/s (collection: 1.816s, learning 0.097s)
             Mean action noise std: 5.63
          Mean value_function loss: 81.4309
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 95.8789
                       Mean reward: 454.73
               Mean episode length: 227.24
    Episode_Reward/reaching_object: 1.6037
    Episode_Reward/rotating_object: 90.3967
        Episode_Reward/action_rate: -0.2043
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 1.91s
                      Time elapsed: 00:53:14
                               ETA: 00:03:40

################################################################################
                     [1m Learning iteration 1404/1500 [0m                     

                       Computation: 51108 steps/s (collection: 1.828s, learning 0.096s)
             Mean action noise std: 5.64
          Mean value_function loss: 74.7801
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 95.8938
                       Mean reward: 445.98
               Mean episode length: 227.28
    Episode_Reward/reaching_object: 1.6579
    Episode_Reward/rotating_object: 90.7917
        Episode_Reward/action_rate: -0.2126
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 1.92s
                      Time elapsed: 00:53:16
                               ETA: 00:03:38

################################################################################
                     [1m Learning iteration 1405/1500 [0m                     

                       Computation: 51969 steps/s (collection: 1.798s, learning 0.094s)
             Mean action noise std: 5.64
          Mean value_function loss: 82.8724
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 95.9138
                       Mean reward: 447.55
               Mean episode length: 230.32
    Episode_Reward/reaching_object: 1.5931
    Episode_Reward/rotating_object: 83.7567
        Episode_Reward/action_rate: -0.2076
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 1.89s
                      Time elapsed: 00:53:18
                               ETA: 00:03:36

################################################################################
                     [1m Learning iteration 1406/1500 [0m                     

                       Computation: 51457 steps/s (collection: 1.812s, learning 0.098s)
             Mean action noise std: 5.65
          Mean value_function loss: 74.1757
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 95.9383
                       Mean reward: 421.40
               Mean episode length: 218.69
    Episode_Reward/reaching_object: 1.6788
    Episode_Reward/rotating_object: 91.5594
        Episode_Reward/action_rate: -0.2159
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 1.91s
                      Time elapsed: 00:53:20
                               ETA: 00:03:33

################################################################################
                     [1m Learning iteration 1407/1500 [0m                     

                       Computation: 51231 steps/s (collection: 1.831s, learning 0.088s)
             Mean action noise std: 5.65
          Mean value_function loss: 71.8477
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 95.9587
                       Mean reward: 455.34
               Mean episode length: 228.65
    Episode_Reward/reaching_object: 1.6462
    Episode_Reward/rotating_object: 89.7947
        Episode_Reward/action_rate: -0.2127
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 1.92s
                      Time elapsed: 00:53:22
                               ETA: 00:03:31

################################################################################
                     [1m Learning iteration 1408/1500 [0m                     

                       Computation: 49972 steps/s (collection: 1.850s, learning 0.118s)
             Mean action noise std: 5.65
          Mean value_function loss: 75.5686
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 95.9721
                       Mean reward: 467.87
               Mean episode length: 235.08
    Episode_Reward/reaching_object: 1.6342
    Episode_Reward/rotating_object: 86.8690
        Episode_Reward/action_rate: -0.2131
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 1.97s
                      Time elapsed: 00:53:24
                               ETA: 00:03:29

################################################################################
                     [1m Learning iteration 1409/1500 [0m                     

                       Computation: 49884 steps/s (collection: 1.851s, learning 0.120s)
             Mean action noise std: 5.66
          Mean value_function loss: 85.0123
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 95.9915
                       Mean reward: 452.11
               Mean episode length: 237.88
    Episode_Reward/reaching_object: 1.6329
    Episode_Reward/rotating_object: 87.0323
        Episode_Reward/action_rate: -0.2125
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 1.97s
                      Time elapsed: 00:53:26
                               ETA: 00:03:26

################################################################################
                     [1m Learning iteration 1410/1500 [0m                     

                       Computation: 49577 steps/s (collection: 1.872s, learning 0.111s)
             Mean action noise std: 5.66
          Mean value_function loss: 80.1803
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 96.0029
                       Mean reward: 451.27
               Mean episode length: 233.48
    Episode_Reward/reaching_object: 1.6783
    Episode_Reward/rotating_object: 89.7489
        Episode_Reward/action_rate: -0.2172
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 1.98s
                      Time elapsed: 00:53:28
                               ETA: 00:03:24

################################################################################
                     [1m Learning iteration 1411/1500 [0m                     

                       Computation: 50836 steps/s (collection: 1.837s, learning 0.097s)
             Mean action noise std: 5.66
          Mean value_function loss: 89.1365
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 96.0125
                       Mean reward: 459.62
               Mean episode length: 226.78
    Episode_Reward/reaching_object: 1.6401
    Episode_Reward/rotating_object: 89.8127
        Episode_Reward/action_rate: -0.2106
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 1.93s
                      Time elapsed: 00:53:30
                               ETA: 00:03:22

################################################################################
                     [1m Learning iteration 1412/1500 [0m                     

                       Computation: 48753 steps/s (collection: 1.905s, learning 0.112s)
             Mean action noise std: 5.66
          Mean value_function loss: 83.2914
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 96.0225
                       Mean reward: 473.31
               Mean episode length: 217.31
    Episode_Reward/reaching_object: 1.6440
    Episode_Reward/rotating_object: 89.7598
        Episode_Reward/action_rate: -0.2104
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 2.02s
                      Time elapsed: 00:53:32
                               ETA: 00:03:20

################################################################################
                     [1m Learning iteration 1413/1500 [0m                     

                       Computation: 50730 steps/s (collection: 1.838s, learning 0.100s)
             Mean action noise std: 5.67
          Mean value_function loss: 86.7212
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 96.0358
                       Mean reward: 390.43
               Mean episode length: 225.00
    Episode_Reward/reaching_object: 1.6195
    Episode_Reward/rotating_object: 84.8188
        Episode_Reward/action_rate: -0.2110
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 1.94s
                      Time elapsed: 00:53:34
                               ETA: 00:03:17

################################################################################
                     [1m Learning iteration 1414/1500 [0m                     

                       Computation: 48393 steps/s (collection: 1.921s, learning 0.111s)
             Mean action noise std: 5.67
          Mean value_function loss: 74.4490
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 96.0492
                       Mean reward: 434.00
               Mean episode length: 218.82
    Episode_Reward/reaching_object: 1.6709
    Episode_Reward/rotating_object: 90.5230
        Episode_Reward/action_rate: -0.2156
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 2.03s
                      Time elapsed: 00:53:36
                               ETA: 00:03:15

################################################################################
                     [1m Learning iteration 1415/1500 [0m                     

                       Computation: 50515 steps/s (collection: 1.848s, learning 0.098s)
             Mean action noise std: 5.67
          Mean value_function loss: 74.3137
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 96.0629
                       Mean reward: 419.04
               Mean episode length: 216.97
    Episode_Reward/reaching_object: 1.6782
    Episode_Reward/rotating_object: 90.6750
        Episode_Reward/action_rate: -0.2164
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 1.95s
                      Time elapsed: 00:53:38
                               ETA: 00:03:13

################################################################################
                     [1m Learning iteration 1416/1500 [0m                     

                       Computation: 51064 steps/s (collection: 1.829s, learning 0.097s)
             Mean action noise std: 5.68
          Mean value_function loss: 68.0203
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 96.0814
                       Mean reward: 478.35
               Mean episode length: 230.55
    Episode_Reward/reaching_object: 1.7069
    Episode_Reward/rotating_object: 93.5711
        Episode_Reward/action_rate: -0.2178
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 1.93s
                      Time elapsed: 00:53:39
                               ETA: 00:03:10

################################################################################
                     [1m Learning iteration 1417/1500 [0m                     

                       Computation: 49995 steps/s (collection: 1.870s, learning 0.096s)
             Mean action noise std: 5.68
          Mean value_function loss: 78.8690
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 96.0961
                       Mean reward: 486.15
               Mean episode length: 230.73
    Episode_Reward/reaching_object: 1.7132
    Episode_Reward/rotating_object: 94.7442
        Episode_Reward/action_rate: -0.2217
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 1.97s
                      Time elapsed: 00:53:41
                               ETA: 00:03:08

################################################################################
                     [1m Learning iteration 1418/1500 [0m                     

                       Computation: 50040 steps/s (collection: 1.868s, learning 0.097s)
             Mean action noise std: 5.68
          Mean value_function loss: 71.1462
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 96.1151
                       Mean reward: 470.25
               Mean episode length: 228.43
    Episode_Reward/reaching_object: 1.6522
    Episode_Reward/rotating_object: 90.0644
        Episode_Reward/action_rate: -0.2136
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 1.96s
                      Time elapsed: 00:53:43
                               ETA: 00:03:06

################################################################################
                     [1m Learning iteration 1419/1500 [0m                     

                       Computation: 50349 steps/s (collection: 1.858s, learning 0.094s)
             Mean action noise std: 5.69
          Mean value_function loss: 81.2564
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 96.1321
                       Mean reward: 480.60
               Mean episode length: 217.98
    Episode_Reward/reaching_object: 1.6796
    Episode_Reward/rotating_object: 95.3533
        Episode_Reward/action_rate: -0.2161
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 1.95s
                      Time elapsed: 00:53:45
                               ETA: 00:03:04

################################################################################
                     [1m Learning iteration 1420/1500 [0m                     

                       Computation: 50825 steps/s (collection: 1.839s, learning 0.096s)
             Mean action noise std: 5.69
          Mean value_function loss: 82.6356
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 96.1413
                       Mean reward: 424.31
               Mean episode length: 225.25
    Episode_Reward/reaching_object: 1.7077
    Episode_Reward/rotating_object: 92.2125
        Episode_Reward/action_rate: -0.2209
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 1.93s
                      Time elapsed: 00:53:47
                               ETA: 00:03:01

################################################################################
                     [1m Learning iteration 1421/1500 [0m                     

                       Computation: 50413 steps/s (collection: 1.851s, learning 0.099s)
             Mean action noise std: 5.69
          Mean value_function loss: 79.9053
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 96.1522
                       Mean reward: 448.38
               Mean episode length: 219.63
    Episode_Reward/reaching_object: 1.6514
    Episode_Reward/rotating_object: 88.3125
        Episode_Reward/action_rate: -0.2166
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 1.95s
                      Time elapsed: 00:53:49
                               ETA: 00:02:59

################################################################################
                     [1m Learning iteration 1422/1500 [0m                     

                       Computation: 50844 steps/s (collection: 1.837s, learning 0.096s)
             Mean action noise std: 5.70
          Mean value_function loss: 74.7880
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 96.1637
                       Mean reward: 464.36
               Mean episode length: 227.44
    Episode_Reward/reaching_object: 1.7035
    Episode_Reward/rotating_object: 91.0683
        Episode_Reward/action_rate: -0.2216
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 1.93s
                      Time elapsed: 00:53:51
                               ETA: 00:02:57

################################################################################
                     [1m Learning iteration 1423/1500 [0m                     

                       Computation: 50363 steps/s (collection: 1.841s, learning 0.111s)
             Mean action noise std: 5.70
          Mean value_function loss: 87.0026
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 96.1813
                       Mean reward: 428.37
               Mean episode length: 222.91
    Episode_Reward/reaching_object: 1.6583
    Episode_Reward/rotating_object: 89.7594
        Episode_Reward/action_rate: -0.2169
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 1.95s
                      Time elapsed: 00:53:53
                               ETA: 00:02:54

################################################################################
                     [1m Learning iteration 1424/1500 [0m                     

                       Computation: 50782 steps/s (collection: 1.824s, learning 0.112s)
             Mean action noise std: 5.70
          Mean value_function loss: 85.2266
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 96.2050
                       Mean reward: 446.39
               Mean episode length: 214.08
    Episode_Reward/reaching_object: 1.6037
    Episode_Reward/rotating_object: 88.7277
        Episode_Reward/action_rate: -0.2104
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 1.94s
                      Time elapsed: 00:53:55
                               ETA: 00:02:52

################################################################################
                     [1m Learning iteration 1425/1500 [0m                     

                       Computation: 50722 steps/s (collection: 1.826s, learning 0.112s)
             Mean action noise std: 5.71
          Mean value_function loss: 73.7868
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 96.2244
                       Mean reward: 474.20
               Mean episode length: 235.26
    Episode_Reward/reaching_object: 1.6841
    Episode_Reward/rotating_object: 92.3286
        Episode_Reward/action_rate: -0.2199
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 1.94s
                      Time elapsed: 00:53:57
                               ETA: 00:02:50

################################################################################
                     [1m Learning iteration 1426/1500 [0m                     

                       Computation: 48972 steps/s (collection: 1.907s, learning 0.100s)
             Mean action noise std: 5.71
          Mean value_function loss: 68.4055
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 96.2457
                       Mean reward: 431.38
               Mean episode length: 219.47
    Episode_Reward/reaching_object: 1.6807
    Episode_Reward/rotating_object: 92.3596
        Episode_Reward/action_rate: -0.2203
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 2.01s
                      Time elapsed: 00:53:59
                               ETA: 00:02:47

################################################################################
                     [1m Learning iteration 1427/1500 [0m                     

                       Computation: 50400 steps/s (collection: 1.856s, learning 0.095s)
             Mean action noise std: 5.72
          Mean value_function loss: 63.4181
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 96.2683
                       Mean reward: 463.86
               Mean episode length: 233.83
    Episode_Reward/reaching_object: 1.7009
    Episode_Reward/rotating_object: 94.2210
        Episode_Reward/action_rate: -0.2240
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 1.95s
                      Time elapsed: 00:54:01
                               ETA: 00:02:45

################################################################################
                     [1m Learning iteration 1428/1500 [0m                     

                       Computation: 50414 steps/s (collection: 1.855s, learning 0.095s)
             Mean action noise std: 5.72
          Mean value_function loss: 72.9072
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 96.2765
                       Mean reward: 457.56
               Mean episode length: 232.57
    Episode_Reward/reaching_object: 1.6852
    Episode_Reward/rotating_object: 94.6309
        Episode_Reward/action_rate: -0.2220
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 1.95s
                      Time elapsed: 00:54:03
                               ETA: 00:02:43

################################################################################
                     [1m Learning iteration 1429/1500 [0m                     

                       Computation: 51650 steps/s (collection: 1.811s, learning 0.092s)
             Mean action noise std: 5.72
          Mean value_function loss: 75.6020
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 96.2860
                       Mean reward: 451.04
               Mean episode length: 224.18
    Episode_Reward/reaching_object: 1.6679
    Episode_Reward/rotating_object: 91.7186
        Episode_Reward/action_rate: -0.2189
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 1.90s
                      Time elapsed: 00:54:05
                               ETA: 00:02:41

################################################################################
                     [1m Learning iteration 1430/1500 [0m                     

                       Computation: 49198 steps/s (collection: 1.902s, learning 0.097s)
             Mean action noise std: 5.73
          Mean value_function loss: 73.7370
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 96.3072
                       Mean reward: 466.38
               Mean episode length: 230.09
    Episode_Reward/reaching_object: 1.6745
    Episode_Reward/rotating_object: 92.4622
        Episode_Reward/action_rate: -0.2217
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 2.00s
                      Time elapsed: 00:54:07
                               ETA: 00:02:38

################################################################################
                     [1m Learning iteration 1431/1500 [0m                     

                       Computation: 49802 steps/s (collection: 1.860s, learning 0.114s)
             Mean action noise std: 5.73
          Mean value_function loss: 73.3644
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 96.3199
                       Mean reward: 494.33
               Mean episode length: 222.62
    Episode_Reward/reaching_object: 1.7166
    Episode_Reward/rotating_object: 96.0055
        Episode_Reward/action_rate: -0.2253
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 1.97s
                      Time elapsed: 00:54:09
                               ETA: 00:02:36

################################################################################
                     [1m Learning iteration 1432/1500 [0m                     

                       Computation: 51535 steps/s (collection: 1.808s, learning 0.099s)
             Mean action noise std: 5.73
          Mean value_function loss: 71.3373
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 96.3291
                       Mean reward: 504.97
               Mean episode length: 235.30
    Episode_Reward/reaching_object: 1.7100
    Episode_Reward/rotating_object: 95.2427
        Episode_Reward/action_rate: -0.2234
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 1.91s
                      Time elapsed: 00:54:11
                               ETA: 00:02:34

################################################################################
                     [1m Learning iteration 1433/1500 [0m                     

                       Computation: 50601 steps/s (collection: 1.844s, learning 0.099s)
             Mean action noise std: 5.73
          Mean value_function loss: 74.0616
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 96.3378
                       Mean reward: 493.79
               Mean episode length: 230.15
    Episode_Reward/reaching_object: 1.7012
    Episode_Reward/rotating_object: 94.8275
        Episode_Reward/action_rate: -0.2232
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 1.94s
                      Time elapsed: 00:54:13
                               ETA: 00:02:31

################################################################################
                     [1m Learning iteration 1434/1500 [0m                     

                       Computation: 50687 steps/s (collection: 1.838s, learning 0.101s)
             Mean action noise std: 5.73
          Mean value_function loss: 86.4400
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 96.3495
                       Mean reward: 503.40
               Mean episode length: 230.53
    Episode_Reward/reaching_object: 1.6847
    Episode_Reward/rotating_object: 94.4027
        Episode_Reward/action_rate: -0.2210
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 1.94s
                      Time elapsed: 00:54:15
                               ETA: 00:02:29

################################################################################
                     [1m Learning iteration 1435/1500 [0m                     

                       Computation: 51445 steps/s (collection: 1.820s, learning 0.091s)
             Mean action noise std: 5.74
          Mean value_function loss: 72.6185
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 96.3674
                       Mean reward: 496.47
               Mean episode length: 234.63
    Episode_Reward/reaching_object: 1.6591
    Episode_Reward/rotating_object: 91.7589
        Episode_Reward/action_rate: -0.2186
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 1.91s
                      Time elapsed: 00:54:16
                               ETA: 00:02:27

################################################################################
                     [1m Learning iteration 1436/1500 [0m                     

                       Computation: 51094 steps/s (collection: 1.828s, learning 0.096s)
             Mean action noise std: 5.74
          Mean value_function loss: 70.5895
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 96.3891
                       Mean reward: 453.38
               Mean episode length: 226.87
    Episode_Reward/reaching_object: 1.6958
    Episode_Reward/rotating_object: 92.6768
        Episode_Reward/action_rate: -0.2256
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 1.92s
                      Time elapsed: 00:54:18
                               ETA: 00:02:25

################################################################################
                     [1m Learning iteration 1437/1500 [0m                     

                       Computation: 49642 steps/s (collection: 1.871s, learning 0.109s)
             Mean action noise std: 5.75
          Mean value_function loss: 75.4124
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 96.4007
                       Mean reward: 483.16
               Mean episode length: 226.18
    Episode_Reward/reaching_object: 1.6871
    Episode_Reward/rotating_object: 93.0023
        Episode_Reward/action_rate: -0.2222
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 1.98s
                      Time elapsed: 00:54:20
                               ETA: 00:02:22

################################################################################
                     [1m Learning iteration 1438/1500 [0m                     

                       Computation: 48736 steps/s (collection: 1.920s, learning 0.097s)
             Mean action noise std: 5.75
          Mean value_function loss: 79.3907
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 96.4139
                       Mean reward: 481.20
               Mean episode length: 226.99
    Episode_Reward/reaching_object: 1.6879
    Episode_Reward/rotating_object: 92.8457
        Episode_Reward/action_rate: -0.2253
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 2.02s
                      Time elapsed: 00:54:22
                               ETA: 00:02:20

################################################################################
                     [1m Learning iteration 1439/1500 [0m                     

                       Computation: 50899 steps/s (collection: 1.840s, learning 0.091s)
             Mean action noise std: 5.75
          Mean value_function loss: 71.6996
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 96.4229
                       Mean reward: 498.10
               Mean episode length: 239.15
    Episode_Reward/reaching_object: 1.7071
    Episode_Reward/rotating_object: 94.0719
        Episode_Reward/action_rate: -0.2253
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 1.93s
                      Time elapsed: 00:54:24
                               ETA: 00:02:18

################################################################################
                     [1m Learning iteration 1440/1500 [0m                     

                       Computation: 51324 steps/s (collection: 1.812s, learning 0.103s)
             Mean action noise std: 5.75
          Mean value_function loss: 77.2370
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 96.4326
                       Mean reward: 445.63
               Mean episode length: 217.64
    Episode_Reward/reaching_object: 1.7135
    Episode_Reward/rotating_object: 96.4546
        Episode_Reward/action_rate: -0.2251
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 1.92s
                      Time elapsed: 00:54:26
                               ETA: 00:02:16

################################################################################
                     [1m Learning iteration 1441/1500 [0m                     

                       Computation: 51229 steps/s (collection: 1.813s, learning 0.105s)
             Mean action noise std: 5.76
          Mean value_function loss: 77.5403
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 96.4544
                       Mean reward: 514.81
               Mean episode length: 235.72
    Episode_Reward/reaching_object: 1.7500
    Episode_Reward/rotating_object: 99.6860
        Episode_Reward/action_rate: -0.2284
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 1.92s
                      Time elapsed: 00:54:28
                               ETA: 00:02:13

################################################################################
                     [1m Learning iteration 1442/1500 [0m                     

                       Computation: 51107 steps/s (collection: 1.828s, learning 0.095s)
             Mean action noise std: 5.76
          Mean value_function loss: 64.8540
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 96.4767
                       Mean reward: 451.01
               Mean episode length: 222.39
    Episode_Reward/reaching_object: 1.6666
    Episode_Reward/rotating_object: 90.8500
        Episode_Reward/action_rate: -0.2211
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 1.92s
                      Time elapsed: 00:54:30
                               ETA: 00:02:11

################################################################################
                     [1m Learning iteration 1443/1500 [0m                     

                       Computation: 51207 steps/s (collection: 1.827s, learning 0.093s)
             Mean action noise std: 5.76
          Mean value_function loss: 72.0208
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 96.4956
                       Mean reward: 448.74
               Mean episode length: 219.38
    Episode_Reward/reaching_object: 1.6962
    Episode_Reward/rotating_object: 92.4211
        Episode_Reward/action_rate: -0.2258
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 1.92s
                      Time elapsed: 00:54:32
                               ETA: 00:02:09

################################################################################
                     [1m Learning iteration 1444/1500 [0m                     

                       Computation: 50847 steps/s (collection: 1.836s, learning 0.097s)
             Mean action noise std: 5.77
          Mean value_function loss: 74.3896
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 96.5069
                       Mean reward: 439.07
               Mean episode length: 221.35
    Episode_Reward/reaching_object: 1.6720
    Episode_Reward/rotating_object: 91.9393
        Episode_Reward/action_rate: -0.2230
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 1.93s
                      Time elapsed: 00:54:34
                               ETA: 00:02:06

################################################################################
                     [1m Learning iteration 1445/1500 [0m                     

                       Computation: 51051 steps/s (collection: 1.830s, learning 0.096s)
             Mean action noise std: 5.77
          Mean value_function loss: 76.5726
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 96.5243
                       Mean reward: 474.40
               Mean episode length: 231.34
    Episode_Reward/reaching_object: 1.6837
    Episode_Reward/rotating_object: 94.3296
        Episode_Reward/action_rate: -0.2252
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 1.93s
                      Time elapsed: 00:54:36
                               ETA: 00:02:04

################################################################################
                     [1m Learning iteration 1446/1500 [0m                     

                       Computation: 50841 steps/s (collection: 1.841s, learning 0.093s)
             Mean action noise std: 5.77
          Mean value_function loss: 75.7462
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 96.5396
                       Mean reward: 451.60
               Mean episode length: 217.42
    Episode_Reward/reaching_object: 1.6681
    Episode_Reward/rotating_object: 92.9031
        Episode_Reward/action_rate: -0.2237
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 1.93s
                      Time elapsed: 00:54:38
                               ETA: 00:02:02

################################################################################
                     [1m Learning iteration 1447/1500 [0m                     

                       Computation: 50527 steps/s (collection: 1.850s, learning 0.096s)
             Mean action noise std: 5.78
          Mean value_function loss: 70.4571
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 96.5503
                       Mean reward: 455.85
               Mean episode length: 227.03
    Episode_Reward/reaching_object: 1.6686
    Episode_Reward/rotating_object: 92.0784
        Episode_Reward/action_rate: -0.2266
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 1.95s
                      Time elapsed: 00:54:40
                               ETA: 00:02:00

################################################################################
                     [1m Learning iteration 1448/1500 [0m                     

                       Computation: 50387 steps/s (collection: 1.836s, learning 0.115s)
             Mean action noise std: 5.78
          Mean value_function loss: 74.5714
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 96.5635
                       Mean reward: 471.80
               Mean episode length: 225.93
    Episode_Reward/reaching_object: 1.6845
    Episode_Reward/rotating_object: 95.0546
        Episode_Reward/action_rate: -0.2258
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 1.95s
                      Time elapsed: 00:54:42
                               ETA: 00:01:57

################################################################################
                     [1m Learning iteration 1449/1500 [0m                     

                       Computation: 50618 steps/s (collection: 1.831s, learning 0.111s)
             Mean action noise std: 5.78
          Mean value_function loss: 61.5782
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 96.5831
                       Mean reward: 507.92
               Mean episode length: 235.43
    Episode_Reward/reaching_object: 1.7342
    Episode_Reward/rotating_object: 97.4486
        Episode_Reward/action_rate: -0.2324
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 1.94s
                      Time elapsed: 00:54:44
                               ETA: 00:01:55

################################################################################
                     [1m Learning iteration 1450/1500 [0m                     

                       Computation: 49945 steps/s (collection: 1.861s, learning 0.108s)
             Mean action noise std: 5.78
          Mean value_function loss: 72.2240
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 96.5995
                       Mean reward: 442.62
               Mean episode length: 225.42
    Episode_Reward/reaching_object: 1.6884
    Episode_Reward/rotating_object: 95.8198
        Episode_Reward/action_rate: -0.2269
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 1.97s
                      Time elapsed: 00:54:46
                               ETA: 00:01:53

################################################################################
                     [1m Learning iteration 1451/1500 [0m                     

                       Computation: 49208 steps/s (collection: 1.894s, learning 0.104s)
             Mean action noise std: 5.79
          Mean value_function loss: 77.9270
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 96.6056
                       Mean reward: 478.83
               Mean episode length: 227.32
    Episode_Reward/reaching_object: 1.6853
    Episode_Reward/rotating_object: 92.1405
        Episode_Reward/action_rate: -0.2273
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 2.00s
                      Time elapsed: 00:54:48
                               ETA: 00:01:50

################################################################################
                     [1m Learning iteration 1452/1500 [0m                     

                       Computation: 50213 steps/s (collection: 1.862s, learning 0.096s)
             Mean action noise std: 5.79
          Mean value_function loss: 80.2364
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 96.6233
                       Mean reward: 477.51
               Mean episode length: 220.50
    Episode_Reward/reaching_object: 1.6638
    Episode_Reward/rotating_object: 92.3435
        Episode_Reward/action_rate: -0.2250
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 1.96s
                      Time elapsed: 00:54:50
                               ETA: 00:01:48

################################################################################
                     [1m Learning iteration 1453/1500 [0m                     

                       Computation: 49530 steps/s (collection: 1.882s, learning 0.103s)
             Mean action noise std: 5.79
          Mean value_function loss: 75.2248
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 96.6391
                       Mean reward: 478.46
               Mean episode length: 226.76
    Episode_Reward/reaching_object: 1.7481
    Episode_Reward/rotating_object: 99.0503
        Episode_Reward/action_rate: -0.2306
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 1.98s
                      Time elapsed: 00:54:52
                               ETA: 00:01:46

################################################################################
                     [1m Learning iteration 1454/1500 [0m                     

                       Computation: 49778 steps/s (collection: 1.867s, learning 0.108s)
             Mean action noise std: 5.80
          Mean value_function loss: 72.6367
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 96.6431
                       Mean reward: 511.80
               Mean episode length: 236.67
    Episode_Reward/reaching_object: 1.7594
    Episode_Reward/rotating_object: 97.4631
        Episode_Reward/action_rate: -0.2325
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 1.97s
                      Time elapsed: 00:54:54
                               ETA: 00:01:44

################################################################################
                     [1m Learning iteration 1455/1500 [0m                     

                       Computation: 48667 steps/s (collection: 1.910s, learning 0.110s)
             Mean action noise std: 5.80
          Mean value_function loss: 80.1275
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 96.6511
                       Mean reward: 489.06
               Mean episode length: 232.45
    Episode_Reward/reaching_object: 1.7163
    Episode_Reward/rotating_object: 96.1136
        Episode_Reward/action_rate: -0.2283
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 2.02s
                      Time elapsed: 00:54:56
                               ETA: 00:01:41

################################################################################
                     [1m Learning iteration 1456/1500 [0m                     

                       Computation: 45983 steps/s (collection: 2.021s, learning 0.116s)
             Mean action noise std: 5.80
          Mean value_function loss: 67.5916
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 96.6596
                       Mean reward: 504.78
               Mean episode length: 234.88
    Episode_Reward/reaching_object: 1.7247
    Episode_Reward/rotating_object: 92.9645
        Episode_Reward/action_rate: -0.2313
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 2.14s
                      Time elapsed: 00:54:58
                               ETA: 00:01:39

################################################################################
                     [1m Learning iteration 1457/1500 [0m                     

                       Computation: 47564 steps/s (collection: 1.936s, learning 0.131s)
             Mean action noise std: 5.80
          Mean value_function loss: 70.8056
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 96.6735
                       Mean reward: 500.64
               Mean episode length: 235.71
    Episode_Reward/reaching_object: 1.7563
    Episode_Reward/rotating_object: 97.6063
        Episode_Reward/action_rate: -0.2327
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 2.07s
                      Time elapsed: 00:55:00
                               ETA: 00:01:37

################################################################################
                     [1m Learning iteration 1458/1500 [0m                     

                       Computation: 48472 steps/s (collection: 1.921s, learning 0.107s)
             Mean action noise std: 5.81
          Mean value_function loss: 63.9785
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 96.6820
                       Mean reward: 497.20
               Mean episode length: 238.79
    Episode_Reward/reaching_object: 1.7309
    Episode_Reward/rotating_object: 94.3991
        Episode_Reward/action_rate: -0.2335
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 2.03s
                      Time elapsed: 00:55:02
                               ETA: 00:01:35

################################################################################
                     [1m Learning iteration 1459/1500 [0m                     

                       Computation: 47883 steps/s (collection: 1.959s, learning 0.094s)
             Mean action noise std: 5.81
          Mean value_function loss: 66.2817
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 96.6919
                       Mean reward: 476.32
               Mean episode length: 240.56
    Episode_Reward/reaching_object: 1.7328
    Episode_Reward/rotating_object: 95.0667
        Episode_Reward/action_rate: -0.2315
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 2.05s
                      Time elapsed: 00:55:04
                               ETA: 00:01:32

################################################################################
                     [1m Learning iteration 1460/1500 [0m                     

                       Computation: 45707 steps/s (collection: 2.055s, learning 0.096s)
             Mean action noise std: 5.81
          Mean value_function loss: 64.7378
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 96.7068
                       Mean reward: 533.16
               Mean episode length: 239.85
    Episode_Reward/reaching_object: 1.7427
    Episode_Reward/rotating_object: 95.8163
        Episode_Reward/action_rate: -0.2351
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 2.15s
                      Time elapsed: 00:55:06
                               ETA: 00:01:30

################################################################################
                     [1m Learning iteration 1461/1500 [0m                     

                       Computation: 49363 steps/s (collection: 1.872s, learning 0.120s)
             Mean action noise std: 5.82
          Mean value_function loss: 76.3205
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 96.7255
                       Mean reward: 516.32
               Mean episode length: 233.13
    Episode_Reward/reaching_object: 1.7469
    Episode_Reward/rotating_object: 98.5573
        Episode_Reward/action_rate: -0.2337
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 1.99s
                      Time elapsed: 00:55:08
                               ETA: 00:01:28

################################################################################
                     [1m Learning iteration 1462/1500 [0m                     

                       Computation: 46091 steps/s (collection: 1.988s, learning 0.145s)
             Mean action noise std: 5.82
          Mean value_function loss: 71.8526
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 96.7455
                       Mean reward: 469.51
               Mean episode length: 231.64
    Episode_Reward/reaching_object: 1.7080
    Episode_Reward/rotating_object: 94.8949
        Episode_Reward/action_rate: -0.2312
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 2.13s
                      Time elapsed: 00:55:10
                               ETA: 00:01:25

################################################################################
                     [1m Learning iteration 1463/1500 [0m                     

                       Computation: 47162 steps/s (collection: 1.966s, learning 0.119s)
             Mean action noise std: 5.82
          Mean value_function loss: 67.1237
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 96.7597
                       Mean reward: 495.03
               Mean episode length: 232.33
    Episode_Reward/reaching_object: 1.7459
    Episode_Reward/rotating_object: 98.2189
        Episode_Reward/action_rate: -0.2339
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 2.08s
                      Time elapsed: 00:55:12
                               ETA: 00:01:23

################################################################################
                     [1m Learning iteration 1464/1500 [0m                     

                       Computation: 47836 steps/s (collection: 1.955s, learning 0.100s)
             Mean action noise std: 5.82
          Mean value_function loss: 72.0247
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 96.7677
                       Mean reward: 456.20
               Mean episode length: 226.06
    Episode_Reward/reaching_object: 1.7281
    Episode_Reward/rotating_object: 94.7063
        Episode_Reward/action_rate: -0.2342
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 18.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 2.05s
                      Time elapsed: 00:55:14
                               ETA: 00:01:21

################################################################################
                     [1m Learning iteration 1465/1500 [0m                     

                       Computation: 47765 steps/s (collection: 1.962s, learning 0.096s)
             Mean action noise std: 5.83
          Mean value_function loss: 81.9435
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 96.7816
                       Mean reward: 498.77
               Mean episode length: 230.75
    Episode_Reward/reaching_object: 1.7466
    Episode_Reward/rotating_object: 99.6551
        Episode_Reward/action_rate: -0.2317
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 2.06s
                      Time elapsed: 00:55:16
                               ETA: 00:01:19

################################################################################
                     [1m Learning iteration 1466/1500 [0m                     

                       Computation: 48932 steps/s (collection: 1.913s, learning 0.096s)
             Mean action noise std: 5.83
          Mean value_function loss: 68.7919
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 96.7974
                       Mean reward: 513.52
               Mean episode length: 241.85
    Episode_Reward/reaching_object: 1.7362
    Episode_Reward/rotating_object: 94.7963
        Episode_Reward/action_rate: -0.2356
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 2.01s
                      Time elapsed: 00:55:18
                               ETA: 00:01:16

################################################################################
                     [1m Learning iteration 1467/1500 [0m                     

                       Computation: 44953 steps/s (collection: 2.074s, learning 0.113s)
             Mean action noise std: 5.83
          Mean value_function loss: 76.4414
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 96.8110
                       Mean reward: 454.09
               Mean episode length: 231.19
    Episode_Reward/reaching_object: 1.7347
    Episode_Reward/rotating_object: 97.0447
        Episode_Reward/action_rate: -0.2329
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 2.19s
                      Time elapsed: 00:55:20
                               ETA: 00:01:14

################################################################################
                     [1m Learning iteration 1468/1500 [0m                     

                       Computation: 50066 steps/s (collection: 1.862s, learning 0.101s)
             Mean action noise std: 5.84
          Mean value_function loss: 75.8958
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 96.8288
                       Mean reward: 470.99
               Mean episode length: 231.32
    Episode_Reward/reaching_object: 1.7018
    Episode_Reward/rotating_object: 93.8665
        Episode_Reward/action_rate: -0.2307
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 1.96s
                      Time elapsed: 00:55:22
                               ETA: 00:01:12

################################################################################
                     [1m Learning iteration 1469/1500 [0m                     

                       Computation: 48004 steps/s (collection: 1.930s, learning 0.118s)
             Mean action noise std: 5.84
          Mean value_function loss: 64.4356
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 96.8462
                       Mean reward: 452.49
               Mean episode length: 233.16
    Episode_Reward/reaching_object: 1.7637
    Episode_Reward/rotating_object: 97.0331
        Episode_Reward/action_rate: -0.2368
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 2.05s
                      Time elapsed: 00:55:24
                               ETA: 00:01:10

################################################################################
                     [1m Learning iteration 1470/1500 [0m                     

                       Computation: 48876 steps/s (collection: 1.888s, learning 0.124s)
             Mean action noise std: 5.84
          Mean value_function loss: 65.3728
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 96.8596
                       Mean reward: 491.07
               Mean episode length: 237.68
    Episode_Reward/reaching_object: 1.7373
    Episode_Reward/rotating_object: 96.0385
        Episode_Reward/action_rate: -0.2360
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 2.01s
                      Time elapsed: 00:55:27
                               ETA: 00:01:07

################################################################################
                     [1m Learning iteration 1471/1500 [0m                     

                       Computation: 49013 steps/s (collection: 1.891s, learning 0.114s)
             Mean action noise std: 5.85
          Mean value_function loss: 65.6059
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 96.8784
                       Mean reward: 481.77
               Mean episode length: 233.18
    Episode_Reward/reaching_object: 1.7741
    Episode_Reward/rotating_object: 99.5726
        Episode_Reward/action_rate: -0.2370
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 2.01s
                      Time elapsed: 00:55:29
                               ETA: 00:01:05

################################################################################
                     [1m Learning iteration 1472/1500 [0m                     

                       Computation: 47470 steps/s (collection: 1.977s, learning 0.094s)
             Mean action noise std: 5.85
          Mean value_function loss: 78.0922
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 96.8970
                       Mean reward: 510.44
               Mean episode length: 237.13
    Episode_Reward/reaching_object: 1.7565
    Episode_Reward/rotating_object: 99.2377
        Episode_Reward/action_rate: -0.2362
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 2.07s
                      Time elapsed: 00:55:31
                               ETA: 00:01:03

################################################################################
                     [1m Learning iteration 1473/1500 [0m                     

                       Computation: 50017 steps/s (collection: 1.865s, learning 0.100s)
             Mean action noise std: 5.85
          Mean value_function loss: 73.0648
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 96.9186
                       Mean reward: 528.50
               Mean episode length: 241.13
    Episode_Reward/reaching_object: 1.7438
    Episode_Reward/rotating_object: 98.1270
        Episode_Reward/action_rate: -0.2368
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 1.97s
                      Time elapsed: 00:55:33
                               ETA: 00:01:01

################################################################################
                     [1m Learning iteration 1474/1500 [0m                     

                       Computation: 48814 steps/s (collection: 1.901s, learning 0.113s)
             Mean action noise std: 5.86
          Mean value_function loss: 74.9626
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 96.9296
                       Mean reward: 515.80
               Mean episode length: 241.18
    Episode_Reward/reaching_object: 1.7399
    Episode_Reward/rotating_object: 99.5240
        Episode_Reward/action_rate: -0.2339
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 2.01s
                      Time elapsed: 00:55:35
                               ETA: 00:00:58

################################################################################
                     [1m Learning iteration 1475/1500 [0m                     

                       Computation: 46762 steps/s (collection: 1.925s, learning 0.177s)
             Mean action noise std: 5.86
          Mean value_function loss: 67.1726
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 96.9383
                       Mean reward: 505.50
               Mean episode length: 237.09
    Episode_Reward/reaching_object: 1.8178
    Episode_Reward/rotating_object: 105.6108
        Episode_Reward/action_rate: -0.2443
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 2.10s
                      Time elapsed: 00:55:37
                               ETA: 00:00:56

################################################################################
                     [1m Learning iteration 1476/1500 [0m                     

                       Computation: 42354 steps/s (collection: 2.136s, learning 0.185s)
             Mean action noise std: 5.86
          Mean value_function loss: 80.4048
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 96.9499
                       Mean reward: 548.45
               Mean episode length: 244.03
    Episode_Reward/reaching_object: 1.7628
    Episode_Reward/rotating_object: 101.4369
        Episode_Reward/action_rate: -0.2388
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 2.32s
                      Time elapsed: 00:55:39
                               ETA: 00:00:54

################################################################################
                     [1m Learning iteration 1477/1500 [0m                     

                       Computation: 45437 steps/s (collection: 1.995s, learning 0.169s)
             Mean action noise std: 5.86
          Mean value_function loss: 87.6700
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 96.9590
                       Mean reward: 501.17
               Mean episode length: 230.88
    Episode_Reward/reaching_object: 1.7629
    Episode_Reward/rotating_object: 99.6041
        Episode_Reward/action_rate: -0.2381
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 2.16s
                      Time elapsed: 00:55:41
                               ETA: 00:00:52

################################################################################
                     [1m Learning iteration 1478/1500 [0m                     

                       Computation: 43922 steps/s (collection: 2.069s, learning 0.169s)
             Mean action noise std: 5.87
          Mean value_function loss: 68.5413
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 96.9695
                       Mean reward: 489.75
               Mean episode length: 236.69
    Episode_Reward/reaching_object: 1.7317
    Episode_Reward/rotating_object: 96.1155
        Episode_Reward/action_rate: -0.2355
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 2.24s
                      Time elapsed: 00:55:43
                               ETA: 00:00:49

################################################################################
                     [1m Learning iteration 1479/1500 [0m                     

                       Computation: 41534 steps/s (collection: 2.163s, learning 0.204s)
             Mean action noise std: 5.87
          Mean value_function loss: 72.6443
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 96.9827
                       Mean reward: 542.24
               Mean episode length: 240.13
    Episode_Reward/reaching_object: 1.7631
    Episode_Reward/rotating_object: 99.6813
        Episode_Reward/action_rate: -0.2384
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 2.37s
                      Time elapsed: 00:55:46
                               ETA: 00:00:47

################################################################################
                     [1m Learning iteration 1480/1500 [0m                     

                       Computation: 42053 steps/s (collection: 2.163s, learning 0.175s)
             Mean action noise std: 5.87
          Mean value_function loss: 67.7724
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 96.9851
                       Mean reward: 450.46
               Mean episode length: 235.40
    Episode_Reward/reaching_object: 1.7405
    Episode_Reward/rotating_object: 96.6576
        Episode_Reward/action_rate: -0.2408
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 2.34s
                      Time elapsed: 00:55:48
                               ETA: 00:00:45

################################################################################
                     [1m Learning iteration 1481/1500 [0m                     

                       Computation: 43436 steps/s (collection: 2.096s, learning 0.167s)
             Mean action noise std: 5.87
          Mean value_function loss: 71.1202
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 96.9911
                       Mean reward: 466.85
               Mean episode length: 235.67
    Episode_Reward/reaching_object: 1.7650
    Episode_Reward/rotating_object: 102.3581
        Episode_Reward/action_rate: -0.2398
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 2.26s
                      Time elapsed: 00:55:50
                               ETA: 00:00:42

################################################################################
                     [1m Learning iteration 1482/1500 [0m                     

                       Computation: 45807 steps/s (collection: 2.004s, learning 0.142s)
             Mean action noise std: 5.88
          Mean value_function loss: 73.6550
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 97.0049
                       Mean reward: 484.44
               Mean episode length: 234.37
    Episode_Reward/reaching_object: 1.6701
    Episode_Reward/rotating_object: 92.0479
        Episode_Reward/action_rate: -0.2351
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 2.15s
                      Time elapsed: 00:55:52
                               ETA: 00:00:40

################################################################################
                     [1m Learning iteration 1483/1500 [0m                     

                       Computation: 45388 steps/s (collection: 2.010s, learning 0.156s)
             Mean action noise std: 5.88
          Mean value_function loss: 70.1581
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 97.0238
                       Mean reward: 470.35
               Mean episode length: 231.47
    Episode_Reward/reaching_object: 1.7443
    Episode_Reward/rotating_object: 99.7384
        Episode_Reward/action_rate: -0.2407
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 2.17s
                      Time elapsed: 00:55:55
                               ETA: 00:00:38

################################################################################
                     [1m Learning iteration 1484/1500 [0m                     

                       Computation: 42784 steps/s (collection: 2.111s, learning 0.187s)
             Mean action noise std: 5.88
          Mean value_function loss: 71.5302
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 97.0451
                       Mean reward: 511.97
               Mean episode length: 235.84
    Episode_Reward/reaching_object: 1.6921
    Episode_Reward/rotating_object: 95.6730
        Episode_Reward/action_rate: -0.2361
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 2.30s
                      Time elapsed: 00:55:57
                               ETA: 00:00:36

################################################################################
                     [1m Learning iteration 1485/1500 [0m                     

                       Computation: 43994 steps/s (collection: 2.005s, learning 0.229s)
             Mean action noise std: 5.89
          Mean value_function loss: 70.9184
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 97.0546
                       Mean reward: 506.89
               Mean episode length: 232.99
    Episode_Reward/reaching_object: 1.7381
    Episode_Reward/rotating_object: 99.6663
        Episode_Reward/action_rate: -0.2382
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 2.23s
                      Time elapsed: 00:55:59
                               ETA: 00:00:33

################################################################################
                     [1m Learning iteration 1486/1500 [0m                     

                       Computation: 46339 steps/s (collection: 1.974s, learning 0.147s)
             Mean action noise std: 5.89
          Mean value_function loss: 76.7963
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 97.0649
                       Mean reward: 495.87
               Mean episode length: 237.90
    Episode_Reward/reaching_object: 1.7587
    Episode_Reward/rotating_object: 100.2237
        Episode_Reward/action_rate: -0.2423
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 2.12s
                      Time elapsed: 00:56:01
                               ETA: 00:00:31

################################################################################
                     [1m Learning iteration 1487/1500 [0m                     

                       Computation: 45640 steps/s (collection: 2.008s, learning 0.146s)
             Mean action noise std: 5.89
          Mean value_function loss: 73.2329
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 97.0851
                       Mean reward: 463.94
               Mean episode length: 221.42
    Episode_Reward/reaching_object: 1.6393
    Episode_Reward/rotating_object: 94.4517
        Episode_Reward/action_rate: -0.2299
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 2.15s
                      Time elapsed: 00:56:03
                               ETA: 00:00:29

################################################################################
                     [1m Learning iteration 1488/1500 [0m                     

                       Computation: 44872 steps/s (collection: 2.054s, learning 0.137s)
             Mean action noise std: 5.90
          Mean value_function loss: 65.3301
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 97.1013
                       Mean reward: 497.46
               Mean episode length: 238.60
    Episode_Reward/reaching_object: 1.7459
    Episode_Reward/rotating_object: 103.3951
        Episode_Reward/action_rate: -0.2426
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 2.19s
                      Time elapsed: 00:56:06
                               ETA: 00:00:27

################################################################################
                     [1m Learning iteration 1489/1500 [0m                     

                       Computation: 44308 steps/s (collection: 2.071s, learning 0.148s)
             Mean action noise std: 5.90
          Mean value_function loss: 66.5920
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 97.1176
                       Mean reward: 476.24
               Mean episode length: 238.82
    Episode_Reward/reaching_object: 1.6992
    Episode_Reward/rotating_object: 96.4029
        Episode_Reward/action_rate: -0.2383
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 2.22s
                      Time elapsed: 00:56:08
                               ETA: 00:00:24

################################################################################
                     [1m Learning iteration 1490/1500 [0m                     

                       Computation: 46194 steps/s (collection: 1.999s, learning 0.129s)
             Mean action noise std: 5.90
          Mean value_function loss: 74.0007
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 97.1305
                       Mean reward: 523.52
               Mean episode length: 234.33
    Episode_Reward/reaching_object: 1.7406
    Episode_Reward/rotating_object: 102.7336
        Episode_Reward/action_rate: -0.2414
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 2.13s
                      Time elapsed: 00:56:10
                               ETA: 00:00:22

################################################################################
                     [1m Learning iteration 1491/1500 [0m                     

                       Computation: 45723 steps/s (collection: 2.000s, learning 0.150s)
             Mean action noise std: 5.90
          Mean value_function loss: 67.5808
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 97.1400
                       Mean reward: 525.03
               Mean episode length: 233.11
    Episode_Reward/reaching_object: 1.7159
    Episode_Reward/rotating_object: 95.9546
        Episode_Reward/action_rate: -0.2394
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 2.15s
                      Time elapsed: 00:56:12
                               ETA: 00:00:20

################################################################################
                     [1m Learning iteration 1492/1500 [0m                     

                       Computation: 45622 steps/s (collection: 2.017s, learning 0.138s)
             Mean action noise std: 5.91
          Mean value_function loss: 76.1110
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 97.1466
                       Mean reward: 506.22
               Mean episode length: 237.07
    Episode_Reward/reaching_object: 1.7585
    Episode_Reward/rotating_object: 101.2565
        Episode_Reward/action_rate: -0.2437
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 2.15s
                      Time elapsed: 00:56:14
                               ETA: 00:00:18

################################################################################
                     [1m Learning iteration 1493/1500 [0m                     

                       Computation: 42837 steps/s (collection: 2.137s, learning 0.158s)
             Mean action noise std: 5.91
          Mean value_function loss: 77.5228
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 97.1543
                       Mean reward: 523.01
               Mean episode length: 235.76
    Episode_Reward/reaching_object: 1.7275
    Episode_Reward/rotating_object: 97.9647
        Episode_Reward/action_rate: -0.2407
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 2.29s
                      Time elapsed: 00:56:17
                               ETA: 00:00:15

################################################################################
                     [1m Learning iteration 1494/1500 [0m                     

                       Computation: 45175 steps/s (collection: 2.064s, learning 0.112s)
             Mean action noise std: 5.91
          Mean value_function loss: 70.9637
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 97.1608
                       Mean reward: 489.73
               Mean episode length: 239.44
    Episode_Reward/reaching_object: 1.7542
    Episode_Reward/rotating_object: 99.5570
        Episode_Reward/action_rate: -0.2430
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 2.18s
                      Time elapsed: 00:56:19
                               ETA: 00:00:13

################################################################################
                     [1m Learning iteration 1495/1500 [0m                     

                       Computation: 46252 steps/s (collection: 1.972s, learning 0.153s)
             Mean action noise std: 5.91
          Mean value_function loss: 70.5447
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 97.1710
                       Mean reward: 493.23
               Mean episode length: 235.36
    Episode_Reward/reaching_object: 1.7503
    Episode_Reward/rotating_object: 99.9005
        Episode_Reward/action_rate: -0.2428
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 18.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 2.13s
                      Time elapsed: 00:56:21
                               ETA: 00:00:11

################################################################################
                     [1m Learning iteration 1496/1500 [0m                     

                       Computation: 44019 steps/s (collection: 2.054s, learning 0.179s)
             Mean action noise std: 5.92
          Mean value_function loss: 73.1720
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 97.1853
                       Mean reward: 450.49
               Mean episode length: 230.07
    Episode_Reward/reaching_object: 1.7867
    Episode_Reward/rotating_object: 102.7437
        Episode_Reward/action_rate: -0.2463
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 2.23s
                      Time elapsed: 00:56:23
                               ETA: 00:00:09

################################################################################
                     [1m Learning iteration 1497/1500 [0m                     

                       Computation: 45550 steps/s (collection: 2.022s, learning 0.137s)
             Mean action noise std: 5.92
          Mean value_function loss: 70.8423
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 97.1973
                       Mean reward: 488.92
               Mean episode length: 229.73
    Episode_Reward/reaching_object: 1.7165
    Episode_Reward/rotating_object: 96.6784
        Episode_Reward/action_rate: -0.2406
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 2.16s
                      Time elapsed: 00:56:25
                               ETA: 00:00:06

################################################################################
                     [1m Learning iteration 1498/1500 [0m                     

                       Computation: 46366 steps/s (collection: 1.959s, learning 0.161s)
             Mean action noise std: 5.92
          Mean value_function loss: 64.0556
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 97.2107
                       Mean reward: 508.66
               Mean episode length: 236.51
    Episode_Reward/reaching_object: 1.7932
    Episode_Reward/rotating_object: 103.0317
        Episode_Reward/action_rate: -0.2489
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 2.12s
                      Time elapsed: 00:56:27
                               ETA: 00:00:04

################################################################################
                     [1m Learning iteration 1499/1500 [0m                     

                       Computation: 45167 steps/s (collection: 1.998s, learning 0.179s)
             Mean action noise std: 5.93
          Mean value_function loss: 70.9619
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 97.2250
                       Mean reward: 493.21
               Mean episode length: 244.33
    Episode_Reward/reaching_object: 1.7428
    Episode_Reward/rotating_object: 98.3034
        Episode_Reward/action_rate: -0.2450
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 2.18s
                      Time elapsed: 00:56:30
                               ETA: 00:00:02

