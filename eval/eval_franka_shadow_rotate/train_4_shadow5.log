################################################################################
                      [1m Learning iteration 0/1500 [0m                       

                       Computation: 10842 steps/s (collection: 8.802s, learning 0.265s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0036
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 44.0403
                       Mean reward: 0.00
               Mean episode length: 21.94
    Episode_Reward/reaching_object: 0.0011
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0003
          Episode_Reward/joint_vel: -0.0004
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 9.07s
                      Time elapsed: 00:00:09
                               ETA: 03:46:40

################################################################################
                      [1m Learning iteration 1/1500 [0m                       

                       Computation: 14695 steps/s (collection: 6.559s, learning 0.130s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0004
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 44.1711
                       Mean reward: 0.01
               Mean episode length: 45.00
    Episode_Reward/reaching_object: 0.0031
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0009
          Episode_Reward/joint_vel: -0.0013
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 6.69s
                      Time elapsed: 00:00:15
                               ETA: 03:16:49

################################################################################
                      [1m Learning iteration 2/1500 [0m                       

                       Computation: 15444 steps/s (collection: 6.253s, learning 0.112s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 44.2561
                       Mean reward: 0.01
               Mean episode length: 69.37
    Episode_Reward/reaching_object: 0.0049
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0015
          Episode_Reward/joint_vel: -0.0022
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 6.36s
                      Time elapsed: 00:00:22
                               ETA: 03:04:05

################################################################################
                      [1m Learning iteration 3/1500 [0m                       

                       Computation: 14929 steps/s (collection: 6.379s, learning 0.206s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 44.2779
                       Mean reward: 0.01
               Mean episode length: 93.77
    Episode_Reward/reaching_object: 0.0072
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0021
          Episode_Reward/joint_vel: -0.0031
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 6.58s
                      Time elapsed: 00:00:28
                               ETA: 02:59:03

################################################################################
                      [1m Learning iteration 4/1500 [0m                       

                       Computation: 14547 steps/s (collection: 6.586s, learning 0.172s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 44.2647
                       Mean reward: 0.01
               Mean episode length: 117.34
    Episode_Reward/reaching_object: 0.0093
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0027
          Episode_Reward/joint_vel: -0.0040
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 6.76s
                      Time elapsed: 00:00:35
                               ETA: 02:56:50

################################################################################
                      [1m Learning iteration 5/1500 [0m                       

                       Computation: 14156 steps/s (collection: 6.810s, learning 0.134s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 44.2719
                       Mean reward: 0.02
               Mean episode length: 141.43
    Episode_Reward/reaching_object: 0.0117
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0034
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 6.94s
                      Time elapsed: 00:00:42
                               ETA: 02:56:06

################################################################################
                      [1m Learning iteration 6/1500 [0m                       

                       Computation: 14175 steps/s (collection: 6.781s, learning 0.154s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 44.2688
                       Mean reward: 0.03
               Mean episode length: 165.01
    Episode_Reward/reaching_object: 0.0155
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0040
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 6.93s
                      Time elapsed: 00:00:49
                               ETA: 02:55:30

################################################################################
                      [1m Learning iteration 7/1500 [0m                       

                       Computation: 14251 steps/s (collection: 6.758s, learning 0.140s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 44.2803
                       Mean reward: 0.05
               Mean episode length: 189.52
    Episode_Reward/reaching_object: 0.0187
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 6.90s
                      Time elapsed: 00:00:56
                               ETA: 02:54:55

################################################################################
                      [1m Learning iteration 8/1500 [0m                       

                       Computation: 17805 steps/s (collection: 5.412s, learning 0.108s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 44.3016
                       Mean reward: 0.07
               Mean episode length: 213.81
    Episode_Reward/reaching_object: 0.0245
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 5.52s
                      Time elapsed: 00:01:01
                               ETA: 02:50:38

################################################################################
                      [1m Learning iteration 9/1500 [0m                       

                       Computation: 54845 steps/s (collection: 1.689s, learning 0.103s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 44.3383
                       Mean reward: 0.08
               Mean episode length: 237.09
    Episode_Reward/reaching_object: 0.0299
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 1.79s
                      Time elapsed: 00:01:03
                               ETA: 02:37:55

################################################################################
                      [1m Learning iteration 10/1500 [0m                      

                       Computation: 57694 steps/s (collection: 1.603s, learning 0.101s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 44.3701
                       Mean reward: 0.12
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0347
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 1.70s
                      Time elapsed: 00:01:05
                               ETA: 02:27:19

################################################################################
                      [1m Learning iteration 11/1500 [0m                      

                       Computation: 56574 steps/s (collection: 1.614s, learning 0.123s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 44.4541
                       Mean reward: 0.14
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0431
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 1.74s
                      Time elapsed: 00:01:06
                               ETA: 02:18:32

################################################################################
                      [1m Learning iteration 12/1500 [0m                      

                       Computation: 53244 steps/s (collection: 1.723s, learning 0.124s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0003
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 44.4789
                       Mean reward: 0.19
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0539
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 1.85s
                      Time elapsed: 00:01:08
                               ETA: 02:11:19

################################################################################
                      [1m Learning iteration 13/1500 [0m                      

                       Computation: 52759 steps/s (collection: 1.738s, learning 0.126s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0005
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 44.5321
                       Mean reward: 0.28
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0665
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 1.86s
                      Time elapsed: 00:01:10
                               ETA: 02:05:09

################################################################################
                      [1m Learning iteration 14/1500 [0m                      

                       Computation: 55097 steps/s (collection: 1.684s, learning 0.100s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0009
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 44.6293
                       Mean reward: 0.41
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0868
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 1.78s
                      Time elapsed: 00:01:12
                               ETA: 01:59:41

################################################################################
                      [1m Learning iteration 15/1500 [0m                      

                       Computation: 51889 steps/s (collection: 1.800s, learning 0.095s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0016
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 44.7081
                       Mean reward: 0.53
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.1134
    Episode_Reward/rotating_object: 0.0002
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 1.89s
                      Time elapsed: 00:01:14
                               ETA: 01:55:03

################################################################################
                      [1m Learning iteration 16/1500 [0m                      

                       Computation: 50828 steps/s (collection: 1.828s, learning 0.106s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0023
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 44.7805
                       Mean reward: 0.78
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.1570
    Episode_Reward/rotating_object: 0.0001
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 1.93s
                      Time elapsed: 00:01:16
                               ETA: 01:51:01

################################################################################
                      [1m Learning iteration 17/1500 [0m                      

                       Computation: 53136 steps/s (collection: 1.755s, learning 0.095s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0035
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 44.8607
                       Mean reward: 0.96
               Mean episode length: 249.95
    Episode_Reward/reaching_object: 0.1829
    Episode_Reward/rotating_object: 0.0008
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 1.85s
                      Time elapsed: 00:01:18
                               ETA: 01:47:20

################################################################################
                      [1m Learning iteration 18/1500 [0m                      

                       Computation: 52813 steps/s (collection: 1.757s, learning 0.105s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0049
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 44.9689
                       Mean reward: 1.22
               Mean episode length: 248.60
    Episode_Reward/reaching_object: 0.2321
    Episode_Reward/rotating_object: 0.0003
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 1.86s
                      Time elapsed: 00:01:20
                               ETA: 01:44:02

################################################################################
                      [1m Learning iteration 19/1500 [0m                      

                       Computation: 51696 steps/s (collection: 1.753s, learning 0.149s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0084
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 45.0352
                       Mean reward: 1.46
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 0.3008
    Episode_Reward/rotating_object: 0.0024
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 1.90s
                      Time elapsed: 00:01:21
                               ETA: 01:41:06

################################################################################
                      [1m Learning iteration 20/1500 [0m                      

                       Computation: 50206 steps/s (collection: 1.839s, learning 0.119s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0147
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 45.1154
                       Mean reward: 1.73
               Mean episode length: 243.51
    Episode_Reward/reaching_object: 0.3433
    Episode_Reward/rotating_object: 0.0020
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 1.96s
                      Time elapsed: 00:01:23
                               ETA: 01:38:32

################################################################################
                      [1m Learning iteration 21/1500 [0m                      

                       Computation: 51303 steps/s (collection: 1.817s, learning 0.099s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0226
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 45.1916
                       Mean reward: 2.00
               Mean episode length: 238.28
    Episode_Reward/reaching_object: 0.3923
    Episode_Reward/rotating_object: 0.0068
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 1.92s
                      Time elapsed: 00:01:25
                               ETA: 01:36:08

################################################################################
                      [1m Learning iteration 22/1500 [0m                      

                       Computation: 51623 steps/s (collection: 1.808s, learning 0.096s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0122
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 45.2775
                       Mean reward: 2.25
               Mean episode length: 234.89
    Episode_Reward/reaching_object: 0.4388
    Episode_Reward/rotating_object: 0.0111
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 11.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.7500
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 1.90s
                      Time elapsed: 00:01:27
                               ETA: 01:33:56

################################################################################
                      [1m Learning iteration 23/1500 [0m                      

                       Computation: 50591 steps/s (collection: 1.833s, learning 0.110s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0143
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 45.3676
                       Mean reward: 2.33
               Mean episode length: 231.67
    Episode_Reward/reaching_object: 0.4619
    Episode_Reward/rotating_object: 0.0140
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 7.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 1.94s
                      Time elapsed: 00:01:29
                               ETA: 01:31:57

################################################################################
                      [1m Learning iteration 24/1500 [0m                      

                       Computation: 49947 steps/s (collection: 1.877s, learning 0.092s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0164
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 45.4785
                       Mean reward: 2.42
               Mean episode length: 225.87
    Episode_Reward/reaching_object: 0.5019
    Episode_Reward/rotating_object: 0.0161
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 6.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 1.97s
                      Time elapsed: 00:01:31
                               ETA: 01:30:09

################################################################################
                      [1m Learning iteration 25/1500 [0m                      

                       Computation: 49032 steps/s (collection: 1.882s, learning 0.123s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0222
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 45.5875
                       Mean reward: 2.69
               Mean episode length: 215.10
    Episode_Reward/reaching_object: 0.5009
    Episode_Reward/rotating_object: 0.0179
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 4.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 2.00s
                      Time elapsed: 00:01:33
                               ETA: 01:28:31

################################################################################
                      [1m Learning iteration 26/1500 [0m                      

                       Computation: 46996 steps/s (collection: 1.981s, learning 0.111s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0329
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 45.7056
                       Mean reward: 2.55
               Mean episode length: 207.23
    Episode_Reward/reaching_object: 0.5191
    Episode_Reward/rotating_object: 0.0186
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 2.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 19.6250
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 2.09s
                      Time elapsed: 00:01:35
                               ETA: 01:27:05

################################################################################
                      [1m Learning iteration 27/1500 [0m                      

                       Computation: 48918 steps/s (collection: 1.896s, learning 0.114s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0404
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 45.8445
                       Mean reward: 2.67
               Mean episode length: 197.35
    Episode_Reward/reaching_object: 0.5327
    Episode_Reward/rotating_object: 0.0420
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 2.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 20.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 2.01s
                      Time elapsed: 00:01:37
                               ETA: 01:25:41

################################################################################
                      [1m Learning iteration 28/1500 [0m                      

                       Computation: 47809 steps/s (collection: 1.943s, learning 0.113s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.0434
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 45.9830
                       Mean reward: 3.03
               Mean episode length: 193.80
    Episode_Reward/reaching_object: 0.5414
    Episode_Reward/rotating_object: 0.0565
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 1.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 21.2500
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 2.06s
                      Time elapsed: 00:01:39
                               ETA: 01:24:24

################################################################################
                      [1m Learning iteration 29/1500 [0m                      

                       Computation: 48827 steps/s (collection: 1.889s, learning 0.125s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.1205
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 46.0949
                       Mean reward: 3.01
               Mean episode length: 199.41
    Episode_Reward/reaching_object: 0.5577
    Episode_Reward/rotating_object: 0.0366
        Episode_Reward/action_rate: -0.0055
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 1.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 19.2917
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 2.01s
                      Time elapsed: 00:01:41
                               ETA: 01:23:11

################################################################################
                      [1m Learning iteration 30/1500 [0m                      

                       Computation: 47821 steps/s (collection: 1.934s, learning 0.122s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.1222
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 46.1627
                       Mean reward: 3.20
               Mean episode length: 196.76
    Episode_Reward/reaching_object: 0.5753
    Episode_Reward/rotating_object: 0.0461
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 1.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 2.06s
                      Time elapsed: 00:01:43
                               ETA: 01:22:04

################################################################################
                      [1m Learning iteration 31/1500 [0m                      

                       Computation: 48790 steps/s (collection: 1.895s, learning 0.120s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.1203
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 46.3467
                       Mean reward: 3.44
               Mean episode length: 199.43
    Episode_Reward/reaching_object: 0.6506
    Episode_Reward/rotating_object: 0.1016
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 2.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 2.01s
                      Time elapsed: 00:01:45
                               ETA: 01:20:59

################################################################################
                      [1m Learning iteration 32/1500 [0m                      

                       Computation: 47578 steps/s (collection: 1.941s, learning 0.126s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.3111
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 46.5100
                       Mean reward: 5.37
               Mean episode length: 212.04
    Episode_Reward/reaching_object: 0.7270
    Episode_Reward/rotating_object: 0.1490
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 3.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 2.07s
                      Time elapsed: 00:01:47
                               ETA: 01:20:01

################################################################################
                      [1m Learning iteration 33/1500 [0m                      

                       Computation: 48362 steps/s (collection: 1.912s, learning 0.121s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.5239
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 46.7183
                       Mean reward: 5.10
               Mean episode length: 215.29
    Episode_Reward/reaching_object: 0.7861
    Episode_Reward/rotating_object: 0.2873
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 5.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 2.03s
                      Time elapsed: 00:01:49
                               ETA: 01:19:04

################################################################################
                      [1m Learning iteration 34/1500 [0m                      

                       Computation: 45913 steps/s (collection: 2.012s, learning 0.129s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.6743
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 46.8566
                       Mean reward: 7.83
               Mean episode length: 220.79
    Episode_Reward/reaching_object: 0.8597
    Episode_Reward/rotating_object: 0.4268
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 6.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.4583
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 2.14s
                      Time elapsed: 00:01:52
                               ETA: 01:18:15

################################################################################
                      [1m Learning iteration 35/1500 [0m                      

                       Computation: 42250 steps/s (collection: 2.212s, learning 0.114s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.5594
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 47.0060
                       Mean reward: 7.19
               Mean episode length: 226.42
    Episode_Reward/reaching_object: 0.9319
    Episode_Reward/rotating_object: 0.3368
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 9.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 2.33s
                      Time elapsed: 00:01:54
                               ETA: 01:17:36

################################################################################
                      [1m Learning iteration 36/1500 [0m                      

                       Computation: 44800 steps/s (collection: 2.074s, learning 0.121s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.5970
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 47.2346
                       Mean reward: 9.16
               Mean episode length: 233.67
    Episode_Reward/reaching_object: 0.9663
    Episode_Reward/rotating_object: 0.4312
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 11.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 2.19s
                      Time elapsed: 00:01:56
                               ETA: 01:16:54

################################################################################
                      [1m Learning iteration 37/1500 [0m                      

                       Computation: 43624 steps/s (collection: 2.141s, learning 0.112s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.5147
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 47.4087
                       Mean reward: 8.21
               Mean episode length: 243.64
    Episode_Reward/reaching_object: 1.0411
    Episode_Reward/rotating_object: 0.5534
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 2.25s
                      Time elapsed: 00:01:58
                               ETA: 01:16:16

################################################################################
                      [1m Learning iteration 38/1500 [0m                      

                       Computation: 47589 steps/s (collection: 1.970s, learning 0.096s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.3643
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 47.5430
                       Mean reward: 7.56
               Mean episode length: 243.69
    Episode_Reward/reaching_object: 1.0655
    Episode_Reward/rotating_object: 0.6111
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 2.07s
                      Time elapsed: 00:02:00
                               ETA: 01:15:33

################################################################################
                      [1m Learning iteration 39/1500 [0m                      

                       Computation: 47170 steps/s (collection: 1.965s, learning 0.119s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.4183
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 47.7108
                       Mean reward: 7.75
               Mean episode length: 244.01
    Episode_Reward/reaching_object: 1.0557
    Episode_Reward/rotating_object: 0.4282
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 2.08s
                      Time elapsed: 00:02:03
                               ETA: 01:14:53

################################################################################
                      [1m Learning iteration 40/1500 [0m                      

                       Computation: 47493 steps/s (collection: 1.974s, learning 0.096s)
             Mean action noise std: 1.14
          Mean value_function loss: 0.6052
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 47.8927
                       Mean reward: 6.94
               Mean episode length: 247.96
    Episode_Reward/reaching_object: 1.0931
    Episode_Reward/rotating_object: 0.6286
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 2.07s
                      Time elapsed: 00:02:05
                               ETA: 01:14:14

################################################################################
                      [1m Learning iteration 41/1500 [0m                      

                       Computation: 47068 steps/s (collection: 1.970s, learning 0.118s)
             Mean action noise std: 1.15
          Mean value_function loss: 0.5191
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 48.1252
                       Mean reward: 7.32
               Mean episode length: 246.18
    Episode_Reward/reaching_object: 1.0953
    Episode_Reward/rotating_object: 0.5704
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 2.09s
                      Time elapsed: 00:02:07
                               ETA: 01:13:38

################################################################################
                      [1m Learning iteration 42/1500 [0m                      

                       Computation: 45210 steps/s (collection: 2.056s, learning 0.119s)
             Mean action noise std: 1.15
          Mean value_function loss: 0.6107
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 48.2766
                       Mean reward: 7.19
               Mean episode length: 240.04
    Episode_Reward/reaching_object: 1.0429
    Episode_Reward/rotating_object: 0.4200
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 2.17s
                      Time elapsed: 00:02:09
                               ETA: 01:13:06

################################################################################
                      [1m Learning iteration 43/1500 [0m                      

                       Computation: 45134 steps/s (collection: 2.066s, learning 0.112s)
             Mean action noise std: 1.16
          Mean value_function loss: 0.9082
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 48.4052
                       Mean reward: 7.86
               Mean episode length: 246.89
    Episode_Reward/reaching_object: 1.0708
    Episode_Reward/rotating_object: 0.5524
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 12.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 2.18s
                      Time elapsed: 00:02:11
                               ETA: 01:12:35

################################################################################
                      [1m Learning iteration 44/1500 [0m                      

                       Computation: 41167 steps/s (collection: 2.272s, learning 0.116s)
             Mean action noise std: 1.16
          Mean value_function loss: 0.8395
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 48.5702
                       Mean reward: 12.30
               Mean episode length: 241.69
    Episode_Reward/reaching_object: 1.0966
    Episode_Reward/rotating_object: 0.6711
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 2.39s
                      Time elapsed: 00:02:13
                               ETA: 01:12:13

################################################################################
                      [1m Learning iteration 45/1500 [0m                      

                       Computation: 46794 steps/s (collection: 2.007s, learning 0.094s)
             Mean action noise std: 1.17
          Mean value_function loss: 0.9777
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 48.7339
                       Mean reward: 8.38
               Mean episode length: 241.38
    Episode_Reward/reaching_object: 1.1385
    Episode_Reward/rotating_object: 0.5509
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 2.10s
                      Time elapsed: 00:02:16
                               ETA: 01:11:42

################################################################################
                      [1m Learning iteration 46/1500 [0m                      

                       Computation: 47363 steps/s (collection: 1.973s, learning 0.102s)
             Mean action noise std: 1.17
          Mean value_function loss: 1.0052
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 48.8657
                       Mean reward: 9.74
               Mean episode length: 244.52
    Episode_Reward/reaching_object: 1.1031
    Episode_Reward/rotating_object: 0.9126
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 2.08s
                      Time elapsed: 00:02:18
                               ETA: 01:11:12

################################################################################
                      [1m Learning iteration 47/1500 [0m                      

                       Computation: 46138 steps/s (collection: 2.018s, learning 0.113s)
             Mean action noise std: 1.18
          Mean value_function loss: 0.9504
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 49.0419
                       Mean reward: 11.42
               Mean episode length: 244.02
    Episode_Reward/reaching_object: 1.1458
    Episode_Reward/rotating_object: 1.1376
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 2.13s
                      Time elapsed: 00:02:20
                               ETA: 01:10:45

################################################################################
                      [1m Learning iteration 48/1500 [0m                      

                       Computation: 47164 steps/s (collection: 1.969s, learning 0.115s)
             Mean action noise std: 1.18
          Mean value_function loss: 1.1085
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 49.1424
                       Mean reward: 9.17
               Mean episode length: 243.48
    Episode_Reward/reaching_object: 1.2068
    Episode_Reward/rotating_object: 0.7816
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 2.08s
                      Time elapsed: 00:02:22
                               ETA: 01:10:17

################################################################################
                      [1m Learning iteration 49/1500 [0m                      

                       Computation: 47307 steps/s (collection: 1.970s, learning 0.108s)
             Mean action noise std: 1.19
          Mean value_function loss: 1.5502
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 49.2518
                       Mean reward: 11.30
               Mean episode length: 245.26
    Episode_Reward/reaching_object: 1.1823
    Episode_Reward/rotating_object: 0.7808
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 2.08s
                      Time elapsed: 00:02:24
                               ETA: 01:09:50

################################################################################
                      [1m Learning iteration 50/1500 [0m                      

                       Computation: 47249 steps/s (collection: 1.969s, learning 0.112s)
             Mean action noise std: 1.19
          Mean value_function loss: 1.7437
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 49.3841
                       Mean reward: 10.74
               Mean episode length: 246.77
    Episode_Reward/reaching_object: 1.2164
    Episode_Reward/rotating_object: 0.9153
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 2.08s
                      Time elapsed: 00:02:26
                               ETA: 01:09:24

################################################################################
                      [1m Learning iteration 51/1500 [0m                      

                       Computation: 46011 steps/s (collection: 2.030s, learning 0.106s)
             Mean action noise std: 1.20
          Mean value_function loss: 0.9727
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 49.4951
                       Mean reward: 11.82
               Mean episode length: 242.21
    Episode_Reward/reaching_object: 1.2064
    Episode_Reward/rotating_object: 1.3462
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 2.14s
                      Time elapsed: 00:02:28
                               ETA: 01:09:01

################################################################################
                      [1m Learning iteration 52/1500 [0m                      

                       Computation: 47336 steps/s (collection: 1.977s, learning 0.100s)
             Mean action noise std: 1.20
          Mean value_function loss: 1.3397
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 49.6665
                       Mean reward: 13.81
               Mean episode length: 243.69
    Episode_Reward/reaching_object: 1.2227
    Episode_Reward/rotating_object: 1.1946
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 2.08s
                      Time elapsed: 00:02:30
                               ETA: 01:08:36

################################################################################
                      [1m Learning iteration 53/1500 [0m                      

                       Computation: 45563 steps/s (collection: 2.057s, learning 0.100s)
             Mean action noise std: 1.21
          Mean value_function loss: 1.3501
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 49.8009
                       Mean reward: 14.32
               Mean episode length: 244.30
    Episode_Reward/reaching_object: 1.2741
    Episode_Reward/rotating_object: 1.5151
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 2.16s
                      Time elapsed: 00:02:32
                               ETA: 01:08:15

################################################################################
                      [1m Learning iteration 54/1500 [0m                      

                       Computation: 45854 steps/s (collection: 2.056s, learning 0.088s)
             Mean action noise std: 1.21
          Mean value_function loss: 1.6650
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 49.9420
                       Mean reward: 11.63
               Mean episode length: 247.12
    Episode_Reward/reaching_object: 1.2547
    Episode_Reward/rotating_object: 0.8198
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 2.14s
                      Time elapsed: 00:02:34
                               ETA: 01:07:54

################################################################################
                      [1m Learning iteration 55/1500 [0m                      

                       Computation: 47850 steps/s (collection: 1.949s, learning 0.105s)
             Mean action noise std: 1.22
          Mean value_function loss: 2.2179
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 50.0624
                       Mean reward: 14.53
               Mean episode length: 242.96
    Episode_Reward/reaching_object: 1.2511
    Episode_Reward/rotating_object: 1.3488
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 2.05s
                      Time elapsed: 00:02:37
                               ETA: 01:07:32

################################################################################
                      [1m Learning iteration 56/1500 [0m                      

                       Computation: 42267 steps/s (collection: 2.212s, learning 0.114s)
             Mean action noise std: 1.22
          Mean value_function loss: 1.7440
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 50.1758
                       Mean reward: 14.37
               Mean episode length: 246.84
    Episode_Reward/reaching_object: 1.2474
    Episode_Reward/rotating_object: 1.2137
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 2.33s
                      Time elapsed: 00:02:39
                               ETA: 01:07:17

################################################################################
                      [1m Learning iteration 57/1500 [0m                      

                       Computation: 46989 steps/s (collection: 1.987s, learning 0.105s)
             Mean action noise std: 1.23
          Mean value_function loss: 1.9287
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 50.2358
                       Mean reward: 12.79
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 1.2954
    Episode_Reward/rotating_object: 1.4079
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 2.09s
                      Time elapsed: 00:02:41
                               ETA: 01:06:57

################################################################################
                      [1m Learning iteration 58/1500 [0m                      

                       Computation: 46001 steps/s (collection: 2.041s, learning 0.096s)
             Mean action noise std: 1.23
          Mean value_function loss: 2.1428
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 50.3763
                       Mean reward: 14.82
               Mean episode length: 248.54
    Episode_Reward/reaching_object: 1.2703
    Episode_Reward/rotating_object: 1.1970
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 2.14s
                      Time elapsed: 00:02:43
                               ETA: 01:06:38

################################################################################
                      [1m Learning iteration 59/1500 [0m                      

                       Computation: 44283 steps/s (collection: 2.113s, learning 0.107s)
             Mean action noise std: 1.24
          Mean value_function loss: 1.9294
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 50.5144
                       Mean reward: 9.47
               Mean episode length: 246.48
    Episode_Reward/reaching_object: 1.2636
    Episode_Reward/rotating_object: 1.7253
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 2.22s
                      Time elapsed: 00:02:45
                               ETA: 01:06:22

################################################################################
                      [1m Learning iteration 60/1500 [0m                      

                       Computation: 47990 steps/s (collection: 1.939s, learning 0.110s)
             Mean action noise std: 1.24
          Mean value_function loss: 1.8284
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 50.6016
                       Mean reward: 8.37
               Mean episode length: 248.51
    Episode_Reward/reaching_object: 1.2970
    Episode_Reward/rotating_object: 1.2538
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 2.05s
                      Time elapsed: 00:02:47
                               ETA: 01:06:02

################################################################################
                      [1m Learning iteration 61/1500 [0m                      

                       Computation: 44002 steps/s (collection: 2.102s, learning 0.132s)
             Mean action noise std: 1.24
          Mean value_function loss: 1.7702
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 50.7070
                       Mean reward: 9.00
               Mean episode length: 248.69
    Episode_Reward/reaching_object: 1.2520
    Episode_Reward/rotating_object: 1.2311
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 2.23s
                      Time elapsed: 00:02:50
                               ETA: 01:05:48

################################################################################
                      [1m Learning iteration 62/1500 [0m                      

                       Computation: 46120 steps/s (collection: 2.038s, learning 0.094s)
             Mean action noise std: 1.25
          Mean value_function loss: 1.3719
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 50.7918
                       Mean reward: 18.50
               Mean episode length: 248.52
    Episode_Reward/reaching_object: 1.3102
    Episode_Reward/rotating_object: 1.5798
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 2.13s
                      Time elapsed: 00:02:52
                               ETA: 01:05:31

################################################################################
                      [1m Learning iteration 63/1500 [0m                      

                       Computation: 46101 steps/s (collection: 2.024s, learning 0.109s)
             Mean action noise std: 1.25
          Mean value_function loss: 1.5541
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 50.8903
                       Mean reward: 17.45
               Mean episode length: 248.29
    Episode_Reward/reaching_object: 1.2821
    Episode_Reward/rotating_object: 1.4120
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 2.13s
                      Time elapsed: 00:02:54
                               ETA: 01:05:15

################################################################################
                      [1m Learning iteration 64/1500 [0m                      

                       Computation: 42017 steps/s (collection: 2.239s, learning 0.101s)
             Mean action noise std: 1.25
          Mean value_function loss: 1.8230
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 50.9569
                       Mean reward: 14.00
               Mean episode length: 249.70
    Episode_Reward/reaching_object: 1.2847
    Episode_Reward/rotating_object: 1.6541
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 2.34s
                      Time elapsed: 00:02:56
                               ETA: 01:05:03

################################################################################
                      [1m Learning iteration 65/1500 [0m                      

                       Computation: 46896 steps/s (collection: 1.998s, learning 0.099s)
             Mean action noise std: 1.26
          Mean value_function loss: 2.0604
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 51.0091
                       Mean reward: 12.33
               Mean episode length: 248.43
    Episode_Reward/reaching_object: 1.2882
    Episode_Reward/rotating_object: 1.7722
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 2.10s
                      Time elapsed: 00:02:58
                               ETA: 01:04:47

################################################################################
                      [1m Learning iteration 66/1500 [0m                      

                       Computation: 41884 steps/s (collection: 2.238s, learning 0.109s)
             Mean action noise std: 1.26
          Mean value_function loss: 1.8710
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 51.0777
                       Mean reward: 11.47
               Mean episode length: 249.50
    Episode_Reward/reaching_object: 1.3389
    Episode_Reward/rotating_object: 1.2950
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 2.35s
                      Time elapsed: 00:03:01
                               ETA: 01:04:37

################################################################################
                      [1m Learning iteration 67/1500 [0m                      

                       Computation: 45494 steps/s (collection: 2.060s, learning 0.101s)
             Mean action noise std: 1.26
          Mean value_function loss: 1.9728
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 51.1927
                       Mean reward: 13.77
               Mean episode length: 248.58
    Episode_Reward/reaching_object: 1.3472
    Episode_Reward/rotating_object: 1.5916
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 2.16s
                      Time elapsed: 00:03:03
                               ETA: 01:04:23

################################################################################
                      [1m Learning iteration 68/1500 [0m                      

                       Computation: 45552 steps/s (collection: 2.050s, learning 0.108s)
             Mean action noise std: 1.27
          Mean value_function loss: 1.6983
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 51.2888
                       Mean reward: 14.97
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 1.3247
    Episode_Reward/rotating_object: 1.5333
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 2.16s
                      Time elapsed: 00:03:05
                               ETA: 01:04:09

################################################################################
                      [1m Learning iteration 69/1500 [0m                      

                       Computation: 45799 steps/s (collection: 2.019s, learning 0.127s)
             Mean action noise std: 1.27
          Mean value_function loss: 1.6032
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 51.4338
                       Mean reward: 15.14
               Mean episode length: 249.46
    Episode_Reward/reaching_object: 1.3342
    Episode_Reward/rotating_object: 1.6317
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 18.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 2.15s
                      Time elapsed: 00:03:07
                               ETA: 01:03:55

################################################################################
                      [1m Learning iteration 70/1500 [0m                      

                       Computation: 45868 steps/s (collection: 2.025s, learning 0.118s)
             Mean action noise std: 1.28
          Mean value_function loss: 2.0034
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 51.5159
                       Mean reward: 14.57
               Mean episode length: 249.33
    Episode_Reward/reaching_object: 1.2985
    Episode_Reward/rotating_object: 1.5940
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 2.14s
                      Time elapsed: 00:03:09
                               ETA: 01:03:41

################################################################################
                      [1m Learning iteration 71/1500 [0m                      

                       Computation: 45757 steps/s (collection: 2.037s, learning 0.111s)
             Mean action noise std: 1.28
          Mean value_function loss: 2.1142
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 51.6483
                       Mean reward: 17.34
               Mean episode length: 247.27
    Episode_Reward/reaching_object: 1.3152
    Episode_Reward/rotating_object: 1.7719
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 2.15s
                      Time elapsed: 00:03:11
                               ETA: 01:03:28

################################################################################
                      [1m Learning iteration 72/1500 [0m                      

                       Computation: 46759 steps/s (collection: 2.008s, learning 0.094s)
             Mean action noise std: 1.29
          Mean value_function loss: 2.3129
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 51.7464
                       Mean reward: 19.18
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 1.2908
    Episode_Reward/rotating_object: 1.6740
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 2.10s
                      Time elapsed: 00:03:14
                               ETA: 01:03:15

################################################################################
                      [1m Learning iteration 73/1500 [0m                      

                       Computation: 46662 steps/s (collection: 1.997s, learning 0.110s)
             Mean action noise std: 1.29
          Mean value_function loss: 2.4299
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 51.8319
                       Mean reward: 12.27
               Mean episode length: 249.84
    Episode_Reward/reaching_object: 1.3104
    Episode_Reward/rotating_object: 1.4187
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 2.11s
                      Time elapsed: 00:03:16
                               ETA: 01:03:01

################################################################################
                      [1m Learning iteration 74/1500 [0m                      

                       Computation: 47329 steps/s (collection: 1.973s, learning 0.104s)
             Mean action noise std: 1.29
          Mean value_function loss: 2.5294
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 51.9252
                       Mean reward: 15.94
               Mean episode length: 241.31
    Episode_Reward/reaching_object: 1.2685
    Episode_Reward/rotating_object: 1.5775
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 2.08s
                      Time elapsed: 00:03:18
                               ETA: 01:02:48

################################################################################
                      [1m Learning iteration 75/1500 [0m                      

                       Computation: 43333 steps/s (collection: 2.173s, learning 0.096s)
             Mean action noise std: 1.30
          Mean value_function loss: 2.8870
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.0396
                       Mean reward: 22.44
               Mean episode length: 244.24
    Episode_Reward/reaching_object: 1.2716
    Episode_Reward/rotating_object: 1.7948
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 2.27s
                      Time elapsed: 00:03:20
                               ETA: 01:02:38

################################################################################
                      [1m Learning iteration 76/1500 [0m                      

                       Computation: 46580 steps/s (collection: 2.013s, learning 0.097s)
             Mean action noise std: 1.30
          Mean value_function loss: 2.5551
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.1345
                       Mean reward: 11.61
               Mean episode length: 241.65
    Episode_Reward/reaching_object: 1.2570
    Episode_Reward/rotating_object: 1.7175
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 2.11s
                      Time elapsed: 00:03:22
                               ETA: 01:02:26

################################################################################
                      [1m Learning iteration 77/1500 [0m                      

                       Computation: 44983 steps/s (collection: 2.091s, learning 0.094s)
             Mean action noise std: 1.31
          Mean value_function loss: 2.7877
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 52.1999
                       Mean reward: 16.04
               Mean episode length: 241.00
    Episode_Reward/reaching_object: 1.2444
    Episode_Reward/rotating_object: 2.0043
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 2.19s
                      Time elapsed: 00:03:24
                               ETA: 01:02:15

################################################################################
                      [1m Learning iteration 78/1500 [0m                      

                       Computation: 43314 steps/s (collection: 2.168s, learning 0.101s)
             Mean action noise std: 1.31
          Mean value_function loss: 2.7232
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 52.3040
                       Mean reward: 17.79
               Mean episode length: 238.32
    Episode_Reward/reaching_object: 1.2615
    Episode_Reward/rotating_object: 1.8870
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 2.27s
                      Time elapsed: 00:03:27
                               ETA: 01:02:06

################################################################################
                      [1m Learning iteration 79/1500 [0m                      

                       Computation: 46481 steps/s (collection: 2.020s, learning 0.095s)
             Mean action noise std: 1.32
          Mean value_function loss: 2.6039
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 52.4169
                       Mean reward: 17.43
               Mean episode length: 246.72
    Episode_Reward/reaching_object: 1.2648
    Episode_Reward/rotating_object: 1.8146
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 2.11s
                      Time elapsed: 00:03:29
                               ETA: 01:01:54

################################################################################
                      [1m Learning iteration 80/1500 [0m                      

                       Computation: 45632 steps/s (collection: 2.060s, learning 0.095s)
             Mean action noise std: 1.32
          Mean value_function loss: 2.7277
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.5145
                       Mean reward: 11.77
               Mean episode length: 242.89
    Episode_Reward/reaching_object: 1.2814
    Episode_Reward/rotating_object: 1.9152
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 2.15s
                      Time elapsed: 00:03:31
                               ETA: 01:01:44

################################################################################
                      [1m Learning iteration 81/1500 [0m                      

                       Computation: 47222 steps/s (collection: 1.977s, learning 0.105s)
             Mean action noise std: 1.32
          Mean value_function loss: 2.9276
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 52.5672
                       Mean reward: 17.00
               Mean episode length: 244.55
    Episode_Reward/reaching_object: 1.2758
    Episode_Reward/rotating_object: 1.9938
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 2.08s
                      Time elapsed: 00:03:33
                               ETA: 01:01:32

################################################################################
                      [1m Learning iteration 82/1500 [0m                      

                       Computation: 47496 steps/s (collection: 1.963s, learning 0.107s)
             Mean action noise std: 1.33
          Mean value_function loss: 3.2977
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 52.6694
                       Mean reward: 14.11
               Mean episode length: 241.59
    Episode_Reward/reaching_object: 1.2910
    Episode_Reward/rotating_object: 2.0607
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 2.07s
                      Time elapsed: 00:03:35
                               ETA: 01:01:20

################################################################################
                      [1m Learning iteration 83/1500 [0m                      

                       Computation: 47138 steps/s (collection: 1.978s, learning 0.108s)
             Mean action noise std: 1.33
          Mean value_function loss: 2.9445
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 52.7737
                       Mean reward: 16.16
               Mean episode length: 243.67
    Episode_Reward/reaching_object: 1.2581
    Episode_Reward/rotating_object: 2.3942
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 2.09s
                      Time elapsed: 00:03:37
                               ETA: 01:01:09

################################################################################
                      [1m Learning iteration 84/1500 [0m                      

                       Computation: 47973 steps/s (collection: 1.956s, learning 0.093s)
             Mean action noise std: 1.33
          Mean value_function loss: 3.3553
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 52.8553
                       Mean reward: 13.69
               Mean episode length: 243.52
    Episode_Reward/reaching_object: 1.2957
    Episode_Reward/rotating_object: 2.4505
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 2.05s
                      Time elapsed: 00:03:39
                               ETA: 01:00:57

################################################################################
                      [1m Learning iteration 85/1500 [0m                      

                       Computation: 47536 steps/s (collection: 1.949s, learning 0.119s)
             Mean action noise std: 1.34
          Mean value_function loss: 2.9231
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.9415
                       Mean reward: 23.32
               Mean episode length: 240.10
    Episode_Reward/reaching_object: 1.2645
    Episode_Reward/rotating_object: 2.5281
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 2.07s
                      Time elapsed: 00:03:41
                               ETA: 01:00:46

################################################################################
                      [1m Learning iteration 86/1500 [0m                      

                       Computation: 47275 steps/s (collection: 1.982s, learning 0.097s)
             Mean action noise std: 1.34
          Mean value_function loss: 3.0246
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.0478
                       Mean reward: 18.62
               Mean episode length: 244.01
    Episode_Reward/reaching_object: 1.2389
    Episode_Reward/rotating_object: 2.5856
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 2.08s
                      Time elapsed: 00:03:43
                               ETA: 01:00:36

################################################################################
                      [1m Learning iteration 87/1500 [0m                      

                       Computation: 47650 steps/s (collection: 1.961s, learning 0.102s)
             Mean action noise std: 1.35
          Mean value_function loss: 3.1680
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.1278
                       Mean reward: 13.01
               Mean episode length: 243.69
    Episode_Reward/reaching_object: 1.2772
    Episode_Reward/rotating_object: 2.0244
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 2.06s
                      Time elapsed: 00:03:45
                               ETA: 01:00:25

################################################################################
                      [1m Learning iteration 88/1500 [0m                      

                       Computation: 47492 steps/s (collection: 1.969s, learning 0.101s)
             Mean action noise std: 1.35
          Mean value_function loss: 2.9636
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 53.2371
                       Mean reward: 17.66
               Mean episode length: 245.90
    Episode_Reward/reaching_object: 1.2766
    Episode_Reward/rotating_object: 1.9921
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 2.07s
                      Time elapsed: 00:03:47
                               ETA: 01:00:15

################################################################################
                      [1m Learning iteration 89/1500 [0m                      

                       Computation: 46797 steps/s (collection: 2.006s, learning 0.094s)
             Mean action noise std: 1.35
          Mean value_function loss: 2.7305
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 53.3294
                       Mean reward: 21.93
               Mean episode length: 244.41
    Episode_Reward/reaching_object: 1.2753
    Episode_Reward/rotating_object: 2.6138
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 2.10s
                      Time elapsed: 00:03:49
                               ETA: 01:00:05

################################################################################
                      [1m Learning iteration 90/1500 [0m                      

                       Computation: 47748 steps/s (collection: 1.968s, learning 0.091s)
             Mean action noise std: 1.36
          Mean value_function loss: 2.8085
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 53.4088
                       Mean reward: 17.43
               Mean episode length: 239.60
    Episode_Reward/reaching_object: 1.2475
    Episode_Reward/rotating_object: 2.1048
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 2.06s
                      Time elapsed: 00:03:52
                               ETA: 00:59:55

################################################################################
                      [1m Learning iteration 91/1500 [0m                      

                       Computation: 46437 steps/s (collection: 2.022s, learning 0.095s)
             Mean action noise std: 1.36
          Mean value_function loss: 2.8930
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 53.5289
                       Mean reward: 15.68
               Mean episode length: 245.51
    Episode_Reward/reaching_object: 1.2570
    Episode_Reward/rotating_object: 2.4227
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 2.12s
                      Time elapsed: 00:03:54
                               ETA: 00:59:45

################################################################################
                      [1m Learning iteration 92/1500 [0m                      

                       Computation: 42302 steps/s (collection: 2.222s, learning 0.102s)
             Mean action noise std: 1.37
          Mean value_function loss: 3.6126
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 53.6238
                       Mean reward: 16.53
               Mean episode length: 245.21
    Episode_Reward/reaching_object: 1.2618
    Episode_Reward/rotating_object: 2.2565
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 2.32s
                      Time elapsed: 00:03:56
                               ETA: 00:59:39

################################################################################
                      [1m Learning iteration 93/1500 [0m                      

                       Computation: 45867 steps/s (collection: 2.043s, learning 0.100s)
             Mean action noise std: 1.37
          Mean value_function loss: 3.1088
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 53.7288
                       Mean reward: 19.15
               Mean episode length: 246.73
    Episode_Reward/reaching_object: 1.2728
    Episode_Reward/rotating_object: 2.2941
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 2.14s
                      Time elapsed: 00:03:58
                               ETA: 00:59:31

################################################################################
                      [1m Learning iteration 94/1500 [0m                      

                       Computation: 47292 steps/s (collection: 1.985s, learning 0.094s)
             Mean action noise std: 1.38
          Mean value_function loss: 3.3699
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.8244
                       Mean reward: 21.87
               Mean episode length: 245.79
    Episode_Reward/reaching_object: 1.2665
    Episode_Reward/rotating_object: 2.9760
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 2.08s
                      Time elapsed: 00:04:00
                               ETA: 00:59:22

################################################################################
                      [1m Learning iteration 95/1500 [0m                      

                       Computation: 47429 steps/s (collection: 1.984s, learning 0.089s)
             Mean action noise std: 1.38
          Mean value_function loss: 3.1403
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 53.9061
                       Mean reward: 16.31
               Mean episode length: 238.21
    Episode_Reward/reaching_object: 1.2572
    Episode_Reward/rotating_object: 2.1657
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 2.07s
                      Time elapsed: 00:04:02
                               ETA: 00:59:12

################################################################################
                      [1m Learning iteration 96/1500 [0m                      

                       Computation: 45264 steps/s (collection: 2.071s, learning 0.101s)
             Mean action noise std: 1.39
          Mean value_function loss: 3.2677
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 54.0359
                       Mean reward: 14.56
               Mean episode length: 247.29
    Episode_Reward/reaching_object: 1.2376
    Episode_Reward/rotating_object: 2.1928
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 2.17s
                      Time elapsed: 00:04:04
                               ETA: 00:59:05

################################################################################
                      [1m Learning iteration 97/1500 [0m                      

                       Computation: 46910 steps/s (collection: 1.980s, learning 0.116s)
             Mean action noise std: 1.39
          Mean value_function loss: 3.1760
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 54.1380
                       Mean reward: 24.01
               Mean episode length: 243.93
    Episode_Reward/reaching_object: 1.2662
    Episode_Reward/rotating_object: 2.6188
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 2.10s
                      Time elapsed: 00:04:07
                               ETA: 00:58:56

################################################################################
                      [1m Learning iteration 98/1500 [0m                      

                       Computation: 46992 steps/s (collection: 1.965s, learning 0.127s)
             Mean action noise std: 1.39
          Mean value_function loss: 3.6491
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 54.2252
                       Mean reward: 14.06
               Mean episode length: 245.17
    Episode_Reward/reaching_object: 1.2611
    Episode_Reward/rotating_object: 2.1798
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 2.09s
                      Time elapsed: 00:04:09
                               ETA: 00:58:47

################################################################################
                      [1m Learning iteration 99/1500 [0m                      

                       Computation: 47673 steps/s (collection: 1.950s, learning 0.112s)
             Mean action noise std: 1.40
          Mean value_function loss: 4.2861
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 54.3324
                       Mean reward: 19.18
               Mean episode length: 245.33
    Episode_Reward/reaching_object: 1.2765
    Episode_Reward/rotating_object: 2.2810
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 2.06s
                      Time elapsed: 00:04:11
                               ETA: 00:58:39

################################################################################
                     [1m Learning iteration 100/1500 [0m                      

                       Computation: 48003 steps/s (collection: 1.947s, learning 0.101s)
             Mean action noise std: 1.40
          Mean value_function loss: 4.2287
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 54.4032
                       Mean reward: 20.12
               Mean episode length: 244.31
    Episode_Reward/reaching_object: 1.2542
    Episode_Reward/rotating_object: 2.3465
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 2.05s
                      Time elapsed: 00:04:13
                               ETA: 00:58:30

################################################################################
                     [1m Learning iteration 101/1500 [0m                      

                       Computation: 46953 steps/s (collection: 1.994s, learning 0.099s)
             Mean action noise std: 1.41
          Mean value_function loss: 3.9149
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 54.5125
                       Mean reward: 19.21
               Mean episode length: 246.26
    Episode_Reward/reaching_object: 1.2745
    Episode_Reward/rotating_object: 2.6995
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 2.09s
                      Time elapsed: 00:04:15
                               ETA: 00:58:21

################################################################################
                     [1m Learning iteration 102/1500 [0m                      

                       Computation: 43636 steps/s (collection: 2.144s, learning 0.109s)
             Mean action noise std: 1.41
          Mean value_function loss: 3.5561
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 54.6275
                       Mean reward: 21.94
               Mean episode length: 244.93
    Episode_Reward/reaching_object: 1.2841
    Episode_Reward/rotating_object: 3.4294
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 2.25s
                      Time elapsed: 00:04:17
                               ETA: 00:58:15

################################################################################
                     [1m Learning iteration 103/1500 [0m                      

                       Computation: 47327 steps/s (collection: 1.981s, learning 0.097s)
             Mean action noise std: 1.42
          Mean value_function loss: 3.7370
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 54.7165
                       Mean reward: 24.11
               Mean episode length: 244.50
    Episode_Reward/reaching_object: 1.2723
    Episode_Reward/rotating_object: 3.5471
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 2.08s
                      Time elapsed: 00:04:19
                               ETA: 00:58:07

################################################################################
                     [1m Learning iteration 104/1500 [0m                      

                       Computation: 47637 steps/s (collection: 1.970s, learning 0.094s)
             Mean action noise std: 1.42
          Mean value_function loss: 4.0476
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 54.8332
                       Mean reward: 15.65
               Mean episode length: 246.61
    Episode_Reward/reaching_object: 1.2801
    Episode_Reward/rotating_object: 2.0919
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 2.06s
                      Time elapsed: 00:04:21
                               ETA: 00:57:59

################################################################################
                     [1m Learning iteration 105/1500 [0m                      

                       Computation: 46275 steps/s (collection: 2.016s, learning 0.108s)
             Mean action noise std: 1.43
          Mean value_function loss: 3.6535
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 54.9507
                       Mean reward: 16.93
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 1.2440
    Episode_Reward/rotating_object: 2.2275
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 2.12s
                      Time elapsed: 00:04:23
                               ETA: 00:57:52

################################################################################
                     [1m Learning iteration 106/1500 [0m                      

                       Computation: 46723 steps/s (collection: 2.008s, learning 0.096s)
             Mean action noise std: 1.43
          Mean value_function loss: 5.6407
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 55.0346
                       Mean reward: 20.96
               Mean episode length: 240.58
    Episode_Reward/reaching_object: 1.2526
    Episode_Reward/rotating_object: 2.7646
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 2.10s
                      Time elapsed: 00:04:25
                               ETA: 00:57:44

################################################################################
                     [1m Learning iteration 107/1500 [0m                      

                       Computation: 46657 steps/s (collection: 2.001s, learning 0.106s)
             Mean action noise std: 1.43
          Mean value_function loss: 4.7668
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 55.0910
                       Mean reward: 16.13
               Mean episode length: 241.83
    Episode_Reward/reaching_object: 1.2540
    Episode_Reward/rotating_object: 2.9361
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 2.11s
                      Time elapsed: 00:04:28
                               ETA: 00:57:37

################################################################################
                     [1m Learning iteration 108/1500 [0m                      

                       Computation: 46277 steps/s (collection: 2.023s, learning 0.101s)
             Mean action noise std: 1.44
          Mean value_function loss: 4.6495
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 55.1657
                       Mean reward: 21.96
               Mean episode length: 241.28
    Episode_Reward/reaching_object: 1.2472
    Episode_Reward/rotating_object: 2.6253
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 2.12s
                      Time elapsed: 00:04:30
                               ETA: 00:57:30

################################################################################
                     [1m Learning iteration 109/1500 [0m                      

                       Computation: 47305 steps/s (collection: 1.978s, learning 0.101s)
             Mean action noise std: 1.44
          Mean value_function loss: 3.2906
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 55.2182
                       Mean reward: 13.97
               Mean episode length: 244.61
    Episode_Reward/reaching_object: 1.2437
    Episode_Reward/rotating_object: 2.1917
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 2.08s
                      Time elapsed: 00:04:32
                               ETA: 00:57:22

################################################################################
                     [1m Learning iteration 110/1500 [0m                      

                       Computation: 45402 steps/s (collection: 2.073s, learning 0.093s)
             Mean action noise std: 1.44
          Mean value_function loss: 3.9945
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 55.3152
                       Mean reward: 15.27
               Mean episode length: 243.71
    Episode_Reward/reaching_object: 1.2164
    Episode_Reward/rotating_object: 2.4196
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 2.17s
                      Time elapsed: 00:04:34
                               ETA: 00:57:16

################################################################################
                     [1m Learning iteration 111/1500 [0m                      

                       Computation: 47110 steps/s (collection: 1.986s, learning 0.101s)
             Mean action noise std: 1.45
          Mean value_function loss: 4.3516
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 55.4120
                       Mean reward: 24.61
               Mean episode length: 246.77
    Episode_Reward/reaching_object: 1.2393
    Episode_Reward/rotating_object: 2.6514
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 2.09s
                      Time elapsed: 00:04:36
                               ETA: 00:57:09

################################################################################
                     [1m Learning iteration 112/1500 [0m                      

                       Computation: 44015 steps/s (collection: 2.114s, learning 0.120s)
             Mean action noise std: 1.45
          Mean value_function loss: 4.0173
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 55.4922
                       Mean reward: 19.34
               Mean episode length: 241.66
    Episode_Reward/reaching_object: 1.2617
    Episode_Reward/rotating_object: 2.7459
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 2.23s
                      Time elapsed: 00:04:38
                               ETA: 00:57:03

################################################################################
                     [1m Learning iteration 113/1500 [0m                      

                       Computation: 47356 steps/s (collection: 1.969s, learning 0.107s)
             Mean action noise std: 1.45
          Mean value_function loss: 3.8716
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 55.5399
                       Mean reward: 17.50
               Mean episode length: 242.60
    Episode_Reward/reaching_object: 1.2391
    Episode_Reward/rotating_object: 3.2242
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 2.08s
                      Time elapsed: 00:04:40
                               ETA: 00:56:56

################################################################################
                     [1m Learning iteration 114/1500 [0m                      

                       Computation: 46189 steps/s (collection: 2.010s, learning 0.118s)
             Mean action noise std: 1.46
          Mean value_function loss: 4.1755
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 55.6268
                       Mean reward: 20.96
               Mean episode length: 243.93
    Episode_Reward/reaching_object: 1.2306
    Episode_Reward/rotating_object: 2.6383
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 2.13s
                      Time elapsed: 00:04:42
                               ETA: 00:56:50

################################################################################
                     [1m Learning iteration 115/1500 [0m                      

                       Computation: 44551 steps/s (collection: 2.109s, learning 0.097s)
             Mean action noise std: 1.46
          Mean value_function loss: 4.4432
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.6765
                       Mean reward: 11.64
               Mean episode length: 240.04
    Episode_Reward/reaching_object: 1.2190
    Episode_Reward/rotating_object: 2.2847
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 2.21s
                      Time elapsed: 00:04:45
                               ETA: 00:56:44

################################################################################
                     [1m Learning iteration 116/1500 [0m                      

                       Computation: 47023 steps/s (collection: 1.985s, learning 0.105s)
             Mean action noise std: 1.46
          Mean value_function loss: 4.8827
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 55.7372
                       Mean reward: 16.66
               Mean episode length: 245.15
    Episode_Reward/reaching_object: 1.2225
    Episode_Reward/rotating_object: 1.9357
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 2.09s
                      Time elapsed: 00:04:47
                               ETA: 00:56:37

################################################################################
                     [1m Learning iteration 117/1500 [0m                      

                       Computation: 46607 steps/s (collection: 2.002s, learning 0.107s)
             Mean action noise std: 1.47
          Mean value_function loss: 5.0289
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 55.8223
                       Mean reward: 25.12
               Mean episode length: 244.85
    Episode_Reward/reaching_object: 1.2291
    Episode_Reward/rotating_object: 2.5610
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 2.11s
                      Time elapsed: 00:04:49
                               ETA: 00:56:31

################################################################################
                     [1m Learning iteration 118/1500 [0m                      

                       Computation: 45861 steps/s (collection: 2.021s, learning 0.122s)
             Mean action noise std: 1.47
          Mean value_function loss: 5.4155
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 55.8839
                       Mean reward: 15.28
               Mean episode length: 245.14
    Episode_Reward/reaching_object: 1.2397
    Episode_Reward/rotating_object: 2.4738
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 2.14s
                      Time elapsed: 00:04:51
                               ETA: 00:56:25

################################################################################
                     [1m Learning iteration 119/1500 [0m                      

                       Computation: 47147 steps/s (collection: 1.983s, learning 0.102s)
             Mean action noise std: 1.47
          Mean value_function loss: 5.0660
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 55.9595
                       Mean reward: 17.92
               Mean episode length: 242.06
    Episode_Reward/reaching_object: 1.2542
    Episode_Reward/rotating_object: 2.1533
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 2.09s
                      Time elapsed: 00:04:53
                               ETA: 00:56:18

################################################################################
                     [1m Learning iteration 120/1500 [0m                      

                       Computation: 47108 steps/s (collection: 1.994s, learning 0.093s)
             Mean action noise std: 1.48
          Mean value_function loss: 5.6001
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 56.0093
                       Mean reward: 17.24
               Mean episode length: 243.59
    Episode_Reward/reaching_object: 1.2546
    Episode_Reward/rotating_object: 2.9208
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 2.09s
                      Time elapsed: 00:04:55
                               ETA: 00:56:12

################################################################################
                     [1m Learning iteration 121/1500 [0m                      

                       Computation: 46825 steps/s (collection: 1.993s, learning 0.106s)
             Mean action noise std: 1.48
          Mean value_function loss: 5.3616
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 56.0911
                       Mean reward: 18.47
               Mean episode length: 242.73
    Episode_Reward/reaching_object: 1.2431
    Episode_Reward/rotating_object: 2.8777
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 2.10s
                      Time elapsed: 00:04:57
                               ETA: 00:56:05

################################################################################
                     [1m Learning iteration 122/1500 [0m                      

                       Computation: 42786 steps/s (collection: 2.202s, learning 0.095s)
             Mean action noise std: 1.48
          Mean value_function loss: 5.5455
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 56.1542
                       Mean reward: 18.25
               Mean episode length: 233.31
    Episode_Reward/reaching_object: 1.2405
    Episode_Reward/rotating_object: 3.1102
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 2.30s
                      Time elapsed: 00:05:00
                               ETA: 00:56:01

################################################################################
                     [1m Learning iteration 123/1500 [0m                      

                       Computation: 46981 steps/s (collection: 1.998s, learning 0.094s)
             Mean action noise std: 1.49
          Mean value_function loss: 5.7870
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 56.2264
                       Mean reward: 22.84
               Mean episode length: 240.02
    Episode_Reward/reaching_object: 1.2040
    Episode_Reward/rotating_object: 2.9469
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 2.09s
                      Time elapsed: 00:05:02
                               ETA: 00:55:55

################################################################################
                     [1m Learning iteration 124/1500 [0m                      

                       Computation: 46890 steps/s (collection: 2.002s, learning 0.094s)
             Mean action noise std: 1.49
          Mean value_function loss: 5.7487
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 56.2695
                       Mean reward: 16.49
               Mean episode length: 246.38
    Episode_Reward/reaching_object: 1.2365
    Episode_Reward/rotating_object: 2.6182
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 2.10s
                      Time elapsed: 00:05:04
                               ETA: 00:55:49

################################################################################
                     [1m Learning iteration 125/1500 [0m                      

                       Computation: 47036 steps/s (collection: 2.000s, learning 0.090s)
             Mean action noise std: 1.49
          Mean value_function loss: 6.7717
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 56.3454
                       Mean reward: 24.86
               Mean episode length: 243.43
    Episode_Reward/reaching_object: 1.2004
    Episode_Reward/rotating_object: 2.9817
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 2.09s
                      Time elapsed: 00:05:06
                               ETA: 00:55:42

################################################################################
                     [1m Learning iteration 126/1500 [0m                      

                       Computation: 46631 steps/s (collection: 1.994s, learning 0.115s)
             Mean action noise std: 1.49
          Mean value_function loss: 6.0989
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 56.3863
                       Mean reward: 32.00
               Mean episode length: 242.54
    Episode_Reward/reaching_object: 1.2273
    Episode_Reward/rotating_object: 3.4581
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 2.11s
                      Time elapsed: 00:05:08
                               ETA: 00:55:37

################################################################################
                     [1m Learning iteration 127/1500 [0m                      

                       Computation: 46890 steps/s (collection: 1.988s, learning 0.109s)
             Mean action noise std: 1.50
          Mean value_function loss: 5.3641
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 56.4193
                       Mean reward: 23.84
               Mean episode length: 240.77
    Episode_Reward/reaching_object: 1.2271
    Episode_Reward/rotating_object: 3.3301
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 2.10s
                      Time elapsed: 00:05:10
                               ETA: 00:55:31

################################################################################
                     [1m Learning iteration 128/1500 [0m                      

                       Computation: 45834 steps/s (collection: 2.026s, learning 0.119s)
             Mean action noise std: 1.50
          Mean value_function loss: 5.6988
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 56.4616
                       Mean reward: 20.82
               Mean episode length: 240.89
    Episode_Reward/reaching_object: 1.1680
    Episode_Reward/rotating_object: 2.9224
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 2.14s
                      Time elapsed: 00:05:12
                               ETA: 00:55:25

################################################################################
                     [1m Learning iteration 129/1500 [0m                      

                       Computation: 44718 steps/s (collection: 2.085s, learning 0.114s)
             Mean action noise std: 1.50
          Mean value_function loss: 6.0625
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 56.5135
                       Mean reward: 18.99
               Mean episode length: 242.51
    Episode_Reward/reaching_object: 1.2006
    Episode_Reward/rotating_object: 2.8701
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 2.20s
                      Time elapsed: 00:05:14
                               ETA: 00:55:20

################################################################################
                     [1m Learning iteration 130/1500 [0m                      

                       Computation: 47062 steps/s (collection: 1.977s, learning 0.112s)
             Mean action noise std: 1.50
          Mean value_function loss: 5.4823
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 56.5916
                       Mean reward: 26.04
               Mean episode length: 240.86
    Episode_Reward/reaching_object: 1.2049
    Episode_Reward/rotating_object: 3.0955
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 2.09s
                      Time elapsed: 00:05:16
                               ETA: 00:55:14

################################################################################
                     [1m Learning iteration 131/1500 [0m                      

                       Computation: 45645 steps/s (collection: 2.059s, learning 0.095s)
             Mean action noise std: 1.51
          Mean value_function loss: 6.0642
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 56.6502
                       Mean reward: 16.43
               Mean episode length: 236.40
    Episode_Reward/reaching_object: 1.1962
    Episode_Reward/rotating_object: 3.4091
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 2.15s
                      Time elapsed: 00:05:19
                               ETA: 00:55:09

################################################################################
                     [1m Learning iteration 132/1500 [0m                      

                       Computation: 44765 steps/s (collection: 2.102s, learning 0.093s)
             Mean action noise std: 1.51
          Mean value_function loss: 6.6538
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 56.6995
                       Mean reward: 23.83
               Mean episode length: 239.02
    Episode_Reward/reaching_object: 1.1833
    Episode_Reward/rotating_object: 2.5670
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 2.20s
                      Time elapsed: 00:05:21
                               ETA: 00:55:05

################################################################################
                     [1m Learning iteration 133/1500 [0m                      

                       Computation: 47652 steps/s (collection: 1.969s, learning 0.094s)
             Mean action noise std: 1.51
          Mean value_function loss: 7.1879
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 56.7882
                       Mean reward: 20.64
               Mean episode length: 236.68
    Episode_Reward/reaching_object: 1.1967
    Episode_Reward/rotating_object: 3.2845
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 2.06s
                      Time elapsed: 00:05:23
                               ETA: 00:54:59

################################################################################
                     [1m Learning iteration 134/1500 [0m                      

                       Computation: 46866 steps/s (collection: 2.007s, learning 0.091s)
             Mean action noise std: 1.52
          Mean value_function loss: 8.1978
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 56.8619
                       Mean reward: 27.95
               Mean episode length: 238.44
    Episode_Reward/reaching_object: 1.1734
    Episode_Reward/rotating_object: 3.3083
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 2.10s
                      Time elapsed: 00:05:25
                               ETA: 00:54:53

################################################################################
                     [1m Learning iteration 135/1500 [0m                      

                       Computation: 46317 steps/s (collection: 2.027s, learning 0.095s)
             Mean action noise std: 1.52
          Mean value_function loss: 7.0351
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 56.9422
                       Mean reward: 15.85
               Mean episode length: 239.58
    Episode_Reward/reaching_object: 1.1867
    Episode_Reward/rotating_object: 2.5399
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 2.12s
                      Time elapsed: 00:05:27
                               ETA: 00:54:48

################################################################################
                     [1m Learning iteration 136/1500 [0m                      

                       Computation: 44458 steps/s (collection: 2.074s, learning 0.138s)
             Mean action noise std: 1.52
          Mean value_function loss: 7.9642
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 57.0062
                       Mean reward: 24.49
               Mean episode length: 239.30
    Episode_Reward/reaching_object: 1.1718
    Episode_Reward/rotating_object: 3.2463
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 2.21s
                      Time elapsed: 00:05:29
                               ETA: 00:54:43

################################################################################
                     [1m Learning iteration 137/1500 [0m                      

                       Computation: 46675 steps/s (collection: 2.008s, learning 0.099s)
             Mean action noise std: 1.53
          Mean value_function loss: 7.6148
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 57.0522
                       Mean reward: 23.46
               Mean episode length: 234.34
    Episode_Reward/reaching_object: 1.1634
    Episode_Reward/rotating_object: 3.7815
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 12.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 2.11s
                      Time elapsed: 00:05:31
                               ETA: 00:54:38

################################################################################
                     [1m Learning iteration 138/1500 [0m                      

                       Computation: 46926 steps/s (collection: 1.998s, learning 0.097s)
             Mean action noise std: 1.53
          Mean value_function loss: 7.2294
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 57.1278
                       Mean reward: 18.35
               Mean episode length: 234.85
    Episode_Reward/reaching_object: 1.1712
    Episode_Reward/rotating_object: 3.2957
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 2.09s
                      Time elapsed: 00:05:34
                               ETA: 00:54:32

################################################################################
                     [1m Learning iteration 139/1500 [0m                      

                       Computation: 47675 steps/s (collection: 1.967s, learning 0.095s)
             Mean action noise std: 1.54
          Mean value_function loss: 7.7330
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 57.2234
                       Mean reward: 20.35
               Mean episode length: 239.39
    Episode_Reward/reaching_object: 1.1816
    Episode_Reward/rotating_object: 3.7151
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 2.06s
                      Time elapsed: 00:05:36
                               ETA: 00:54:27

################################################################################
                     [1m Learning iteration 140/1500 [0m                      

                       Computation: 47337 steps/s (collection: 1.961s, learning 0.116s)
             Mean action noise std: 1.54
          Mean value_function loss: 6.9244
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 57.2980
                       Mean reward: 23.91
               Mean episode length: 232.07
    Episode_Reward/reaching_object: 1.1555
    Episode_Reward/rotating_object: 3.3334
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 2.08s
                      Time elapsed: 00:05:38
                               ETA: 00:54:21

################################################################################
                     [1m Learning iteration 141/1500 [0m                      

                       Computation: 47477 steps/s (collection: 1.971s, learning 0.100s)
             Mean action noise std: 1.54
          Mean value_function loss: 6.4156
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 57.3423
                       Mean reward: 20.43
               Mean episode length: 234.93
    Episode_Reward/reaching_object: 1.1949
    Episode_Reward/rotating_object: 3.1101
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 2.07s
                      Time elapsed: 00:05:40
                               ETA: 00:54:16

################################################################################
                     [1m Learning iteration 142/1500 [0m                      

                       Computation: 47431 steps/s (collection: 1.958s, learning 0.115s)
             Mean action noise std: 1.55
          Mean value_function loss: 8.4981
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 57.4230
                       Mean reward: 20.25
               Mean episode length: 234.28
    Episode_Reward/reaching_object: 1.1746
    Episode_Reward/rotating_object: 3.6478
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 2.07s
                      Time elapsed: 00:05:42
                               ETA: 00:54:10

################################################################################
                     [1m Learning iteration 143/1500 [0m                      

                       Computation: 46923 steps/s (collection: 1.990s, learning 0.105s)
             Mean action noise std: 1.55
          Mean value_function loss: 7.8311
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 57.5019
                       Mean reward: 27.49
               Mean episode length: 236.76
    Episode_Reward/reaching_object: 1.1630
    Episode_Reward/rotating_object: 4.0094
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 2.09s
                      Time elapsed: 00:05:44
                               ETA: 00:54:05

################################################################################
                     [1m Learning iteration 144/1500 [0m                      

                       Computation: 47597 steps/s (collection: 1.963s, learning 0.103s)
             Mean action noise std: 1.55
          Mean value_function loss: 8.2728
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 57.5740
                       Mean reward: 26.28
               Mean episode length: 234.24
    Episode_Reward/reaching_object: 1.1802
    Episode_Reward/rotating_object: 4.0274
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 2.07s
                      Time elapsed: 00:05:46
                               ETA: 00:54:00

################################################################################
                     [1m Learning iteration 145/1500 [0m                      

                       Computation: 47498 steps/s (collection: 1.965s, learning 0.105s)
             Mean action noise std: 1.56
          Mean value_function loss: 8.6583
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 57.6252
                       Mean reward: 18.14
               Mean episode length: 232.18
    Episode_Reward/reaching_object: 1.1539
    Episode_Reward/rotating_object: 3.2219
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 11.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 2.07s
                      Time elapsed: 00:05:48
                               ETA: 00:53:54

################################################################################
                     [1m Learning iteration 146/1500 [0m                      

                       Computation: 47637 steps/s (collection: 1.965s, learning 0.099s)
             Mean action noise std: 1.56
          Mean value_function loss: 8.0663
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 57.6879
                       Mean reward: 20.88
               Mean episode length: 235.17
    Episode_Reward/reaching_object: 1.1559
    Episode_Reward/rotating_object: 3.3358
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 2.06s
                      Time elapsed: 00:05:50
                               ETA: 00:53:49

################################################################################
                     [1m Learning iteration 147/1500 [0m                      

                       Computation: 47159 steps/s (collection: 1.978s, learning 0.107s)
             Mean action noise std: 1.56
          Mean value_function loss: 8.1359
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 57.7535
                       Mean reward: 24.05
               Mean episode length: 231.63
    Episode_Reward/reaching_object: 1.1590
    Episode_Reward/rotating_object: 3.9370
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 2.08s
                      Time elapsed: 00:05:52
                               ETA: 00:53:44

################################################################################
                     [1m Learning iteration 148/1500 [0m                      

                       Computation: 46781 steps/s (collection: 1.993s, learning 0.108s)
             Mean action noise std: 1.57
          Mean value_function loss: 9.9482
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 57.8342
                       Mean reward: 20.83
               Mean episode length: 234.04
    Episode_Reward/reaching_object: 1.1660
    Episode_Reward/rotating_object: 3.3362
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 2.10s
                      Time elapsed: 00:05:54
                               ETA: 00:53:39

################################################################################
                     [1m Learning iteration 149/1500 [0m                      

                       Computation: 46981 steps/s (collection: 1.979s, learning 0.113s)
             Mean action noise std: 1.57
          Mean value_function loss: 9.0575
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 57.9115
                       Mean reward: 22.75
               Mean episode length: 237.49
    Episode_Reward/reaching_object: 1.1833
    Episode_Reward/rotating_object: 3.6072
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 2.09s
                      Time elapsed: 00:05:56
                               ETA: 00:53:34

################################################################################
                     [1m Learning iteration 150/1500 [0m                      

                       Computation: 47839 steps/s (collection: 1.962s, learning 0.093s)
             Mean action noise std: 1.57
          Mean value_function loss: 10.4008
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 57.9761
                       Mean reward: 23.35
               Mean episode length: 241.65
    Episode_Reward/reaching_object: 1.2167
    Episode_Reward/rotating_object: 4.5140
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 2.05s
                      Time elapsed: 00:05:58
                               ETA: 00:53:28

################################################################################
                     [1m Learning iteration 151/1500 [0m                      

                       Computation: 45993 steps/s (collection: 2.019s, learning 0.119s)
             Mean action noise std: 1.58
          Mean value_function loss: 10.4764
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 58.0289
                       Mean reward: 16.58
               Mean episode length: 236.44
    Episode_Reward/reaching_object: 1.1825
    Episode_Reward/rotating_object: 2.9008
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 2.14s
                      Time elapsed: 00:06:01
                               ETA: 00:53:24

################################################################################
                     [1m Learning iteration 152/1500 [0m                      

                       Computation: 47172 steps/s (collection: 1.986s, learning 0.098s)
             Mean action noise std: 1.58
          Mean value_function loss: 9.6790
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 58.0800
                       Mean reward: 20.49
               Mean episode length: 235.30
    Episode_Reward/reaching_object: 1.1848
    Episode_Reward/rotating_object: 3.8586
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 2.08s
                      Time elapsed: 00:06:03
                               ETA: 00:53:19

################################################################################
                     [1m Learning iteration 153/1500 [0m                      

                       Computation: 45746 steps/s (collection: 2.047s, learning 0.102s)
             Mean action noise std: 1.58
          Mean value_function loss: 8.7538
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 58.1453
                       Mean reward: 18.60
               Mean episode length: 238.57
    Episode_Reward/reaching_object: 1.1983
    Episode_Reward/rotating_object: 4.1032
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 2.15s
                      Time elapsed: 00:06:05
                               ETA: 00:53:15

################################################################################
                     [1m Learning iteration 154/1500 [0m                      

                       Computation: 44757 steps/s (collection: 2.096s, learning 0.101s)
             Mean action noise std: 1.58
          Mean value_function loss: 10.0503
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 58.1988
                       Mean reward: 21.93
               Mean episode length: 231.30
    Episode_Reward/reaching_object: 1.1567
    Episode_Reward/rotating_object: 3.8735
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 2.20s
                      Time elapsed: 00:06:07
                               ETA: 00:53:11

################################################################################
                     [1m Learning iteration 155/1500 [0m                      

                       Computation: 44381 steps/s (collection: 2.113s, learning 0.102s)
             Mean action noise std: 1.59
          Mean value_function loss: 10.3262
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 58.2698
                       Mean reward: 28.89
               Mean episode length: 237.12
    Episode_Reward/reaching_object: 1.1448
    Episode_Reward/rotating_object: 4.3036
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 2.21s
                      Time elapsed: 00:06:09
                               ETA: 00:53:07

################################################################################
                     [1m Learning iteration 156/1500 [0m                      

                       Computation: 46750 steps/s (collection: 1.984s, learning 0.119s)
             Mean action noise std: 1.59
          Mean value_function loss: 11.3222
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 58.3301
                       Mean reward: 22.82
               Mean episode length: 230.56
    Episode_Reward/reaching_object: 1.1442
    Episode_Reward/rotating_object: 4.6023
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 2.10s
                      Time elapsed: 00:06:11
                               ETA: 00:53:02

################################################################################
                     [1m Learning iteration 157/1500 [0m                      

                       Computation: 47573 steps/s (collection: 1.948s, learning 0.119s)
             Mean action noise std: 1.59
          Mean value_function loss: 10.4536
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 58.3695
                       Mean reward: 27.99
               Mean episode length: 233.32
    Episode_Reward/reaching_object: 1.1559
    Episode_Reward/rotating_object: 4.6311
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 2.07s
                      Time elapsed: 00:06:13
                               ETA: 00:52:57

################################################################################
                     [1m Learning iteration 158/1500 [0m                      

                       Computation: 47547 steps/s (collection: 1.974s, learning 0.093s)
             Mean action noise std: 1.60
          Mean value_function loss: 10.9720
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 58.4247
                       Mean reward: 22.83
               Mean episode length: 234.32
    Episode_Reward/reaching_object: 1.1610
    Episode_Reward/rotating_object: 3.9318
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 2.07s
                      Time elapsed: 00:06:15
                               ETA: 00:52:53

################################################################################
                     [1m Learning iteration 159/1500 [0m                      

                       Computation: 46853 steps/s (collection: 2.007s, learning 0.091s)
             Mean action noise std: 1.60
          Mean value_function loss: 10.6615
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 58.4912
                       Mean reward: 20.38
               Mean episode length: 234.73
    Episode_Reward/reaching_object: 1.1223
    Episode_Reward/rotating_object: 4.2516
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 2.10s
                      Time elapsed: 00:06:18
                               ETA: 00:52:48

################################################################################
                     [1m Learning iteration 160/1500 [0m                      

                       Computation: 45141 steps/s (collection: 2.080s, learning 0.097s)
             Mean action noise std: 1.60
          Mean value_function loss: 10.7493
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 58.5644
                       Mean reward: 32.10
               Mean episode length: 235.28
    Episode_Reward/reaching_object: 1.1607
    Episode_Reward/rotating_object: 4.1401
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 2.18s
                      Time elapsed: 00:06:20
                               ETA: 00:52:44

################################################################################
                     [1m Learning iteration 161/1500 [0m                      

                       Computation: 46151 steps/s (collection: 2.032s, learning 0.098s)
             Mean action noise std: 1.61
          Mean value_function loss: 11.7860
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 58.6238
                       Mean reward: 23.70
               Mean episode length: 235.59
    Episode_Reward/reaching_object: 1.1331
    Episode_Reward/rotating_object: 4.0998
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 2.13s
                      Time elapsed: 00:06:22
                               ETA: 00:52:40

################################################################################
                     [1m Learning iteration 162/1500 [0m                      

                       Computation: 44361 steps/s (collection: 2.086s, learning 0.130s)
             Mean action noise std: 1.61
          Mean value_function loss: 12.5249
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 58.6663
                       Mean reward: 29.92
               Mean episode length: 230.96
    Episode_Reward/reaching_object: 1.1298
    Episode_Reward/rotating_object: 4.4835
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 2.22s
                      Time elapsed: 00:06:24
                               ETA: 00:52:36

################################################################################
                     [1m Learning iteration 163/1500 [0m                      

                       Computation: 45753 steps/s (collection: 2.033s, learning 0.116s)
             Mean action noise std: 1.61
          Mean value_function loss: 9.9134
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 58.7057
                       Mean reward: 30.86
               Mean episode length: 234.59
    Episode_Reward/reaching_object: 1.1414
    Episode_Reward/rotating_object: 4.4009
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 2.15s
                      Time elapsed: 00:06:26
                               ETA: 00:52:32

################################################################################
                     [1m Learning iteration 164/1500 [0m                      

                       Computation: 46761 steps/s (collection: 1.988s, learning 0.115s)
             Mean action noise std: 1.61
          Mean value_function loss: 13.1244
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 58.7701
                       Mean reward: 27.27
               Mean episode length: 233.28
    Episode_Reward/reaching_object: 1.1601
    Episode_Reward/rotating_object: 4.6703
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 2.10s
                      Time elapsed: 00:06:28
                               ETA: 00:52:28

################################################################################
                     [1m Learning iteration 165/1500 [0m                      

                       Computation: 47384 steps/s (collection: 1.977s, learning 0.098s)
             Mean action noise std: 1.62
          Mean value_function loss: 12.7853
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 58.8234
                       Mean reward: 31.38
               Mean episode length: 234.20
    Episode_Reward/reaching_object: 1.1147
    Episode_Reward/rotating_object: 5.5023
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 2.07s
                      Time elapsed: 00:06:30
                               ETA: 00:52:23

################################################################################
                     [1m Learning iteration 166/1500 [0m                      

                       Computation: 46091 steps/s (collection: 2.030s, learning 0.103s)
             Mean action noise std: 1.62
          Mean value_function loss: 14.1798
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 58.8864
                       Mean reward: 27.60
               Mean episode length: 238.76
    Episode_Reward/reaching_object: 1.0942
    Episode_Reward/rotating_object: 4.3715
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 2.13s
                      Time elapsed: 00:06:33
                               ETA: 00:52:19

################################################################################
                     [1m Learning iteration 167/1500 [0m                      

                       Computation: 48076 steps/s (collection: 1.954s, learning 0.091s)
             Mean action noise std: 1.62
          Mean value_function loss: 12.3376
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 58.9284
                       Mean reward: 26.66
               Mean episode length: 231.92
    Episode_Reward/reaching_object: 1.1231
    Episode_Reward/rotating_object: 3.4188
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 2.04s
                      Time elapsed: 00:06:35
                               ETA: 00:52:14

################################################################################
                     [1m Learning iteration 168/1500 [0m                      

                       Computation: 46778 steps/s (collection: 1.995s, learning 0.107s)
             Mean action noise std: 1.62
          Mean value_function loss: 13.7754
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 58.9688
                       Mean reward: 31.98
               Mean episode length: 231.92
    Episode_Reward/reaching_object: 1.1185
    Episode_Reward/rotating_object: 4.2344
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 2.10s
                      Time elapsed: 00:06:37
                               ETA: 00:52:10

################################################################################
                     [1m Learning iteration 169/1500 [0m                      

                       Computation: 47573 steps/s (collection: 1.953s, learning 0.114s)
             Mean action noise std: 1.63
          Mean value_function loss: 14.5300
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 59.0139
                       Mean reward: 40.88
               Mean episode length: 235.92
    Episode_Reward/reaching_object: 1.1214
    Episode_Reward/rotating_object: 5.4701
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 2.07s
                      Time elapsed: 00:06:39
                               ETA: 00:52:05

################################################################################
                     [1m Learning iteration 170/1500 [0m                      

                       Computation: 46587 steps/s (collection: 1.994s, learning 0.117s)
             Mean action noise std: 1.63
          Mean value_function loss: 12.4575
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 59.0518
                       Mean reward: 35.73
               Mean episode length: 237.42
    Episode_Reward/reaching_object: 1.1605
    Episode_Reward/rotating_object: 5.8026
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 2.11s
                      Time elapsed: 00:06:41
                               ETA: 00:52:01

################################################################################
                     [1m Learning iteration 171/1500 [0m                      

                       Computation: 47280 steps/s (collection: 1.967s, learning 0.112s)
             Mean action noise std: 1.63
          Mean value_function loss: 13.8197
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 59.1202
                       Mean reward: 34.21
               Mean episode length: 238.43
    Episode_Reward/reaching_object: 1.0954
    Episode_Reward/rotating_object: 4.1153
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 2.08s
                      Time elapsed: 00:06:43
                               ETA: 00:51:57

################################################################################
                     [1m Learning iteration 172/1500 [0m                      

                       Computation: 48009 steps/s (collection: 1.954s, learning 0.094s)
             Mean action noise std: 1.64
          Mean value_function loss: 15.3501
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 59.1718
                       Mean reward: 20.78
               Mean episode length: 229.57
    Episode_Reward/reaching_object: 1.0977
    Episode_Reward/rotating_object: 4.7183
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 2.05s
                      Time elapsed: 00:06:45
                               ETA: 00:51:52

################################################################################
                     [1m Learning iteration 173/1500 [0m                      

                       Computation: 46757 steps/s (collection: 2.000s, learning 0.102s)
             Mean action noise std: 1.64
          Mean value_function loss: 14.6152
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 59.2344
                       Mean reward: 34.13
               Mean episode length: 224.78
    Episode_Reward/reaching_object: 1.0705
    Episode_Reward/rotating_object: 4.4800
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 2.10s
                      Time elapsed: 00:06:47
                               ETA: 00:51:48

################################################################################
                     [1m Learning iteration 174/1500 [0m                      

                       Computation: 45912 steps/s (collection: 2.044s, learning 0.097s)
             Mean action noise std: 1.64
          Mean value_function loss: 15.1546
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 59.2903
                       Mean reward: 34.27
               Mean episode length: 236.37
    Episode_Reward/reaching_object: 1.1072
    Episode_Reward/rotating_object: 5.8289
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 2.14s
                      Time elapsed: 00:06:49
                               ETA: 00:51:44

################################################################################
                     [1m Learning iteration 175/1500 [0m                      

                       Computation: 46761 steps/s (collection: 2.002s, learning 0.101s)
             Mean action noise std: 1.64
          Mean value_function loss: 13.6830
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 59.3475
                       Mean reward: 32.06
               Mean episode length: 240.36
    Episode_Reward/reaching_object: 1.1217
    Episode_Reward/rotating_object: 5.7449
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 2.10s
                      Time elapsed: 00:06:51
                               ETA: 00:51:40

################################################################################
                     [1m Learning iteration 176/1500 [0m                      

                       Computation: 46858 steps/s (collection: 2.002s, learning 0.096s)
             Mean action noise std: 1.65
          Mean value_function loss: 12.9737
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 59.4088
                       Mean reward: 39.66
               Mean episode length: 238.93
    Episode_Reward/reaching_object: 1.0892
    Episode_Reward/rotating_object: 4.6169
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 2.10s
                      Time elapsed: 00:06:53
                               ETA: 00:51:36

################################################################################
                     [1m Learning iteration 177/1500 [0m                      

                       Computation: 47666 steps/s (collection: 1.971s, learning 0.092s)
             Mean action noise std: 1.65
          Mean value_function loss: 12.7772
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 59.4541
                       Mean reward: 31.74
               Mean episode length: 234.66
    Episode_Reward/reaching_object: 1.1188
    Episode_Reward/rotating_object: 4.6471
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 2.06s
                      Time elapsed: 00:06:55
                               ETA: 00:51:31

################################################################################
                     [1m Learning iteration 178/1500 [0m                      

                       Computation: 47319 steps/s (collection: 1.976s, learning 0.101s)
             Mean action noise std: 1.65
          Mean value_function loss: 14.1436
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 59.5145
                       Mean reward: 16.13
               Mean episode length: 228.35
    Episode_Reward/reaching_object: 1.0816
    Episode_Reward/rotating_object: 4.1037
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 2.08s
                      Time elapsed: 00:06:58
                               ETA: 00:51:27

################################################################################
                     [1m Learning iteration 179/1500 [0m                      

                       Computation: 45371 steps/s (collection: 2.075s, learning 0.092s)
             Mean action noise std: 1.66
          Mean value_function loss: 17.5826
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 59.5857
                       Mean reward: 27.56
               Mean episode length: 235.48
    Episode_Reward/reaching_object: 1.1192
    Episode_Reward/rotating_object: 4.9231
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 2.17s
                      Time elapsed: 00:07:00
                               ETA: 00:51:23

################################################################################
                     [1m Learning iteration 180/1500 [0m                      

                       Computation: 47409 steps/s (collection: 1.982s, learning 0.092s)
             Mean action noise std: 1.66
          Mean value_function loss: 13.6752
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 59.6448
                       Mean reward: 31.53
               Mean episode length: 231.28
    Episode_Reward/reaching_object: 1.1011
    Episode_Reward/rotating_object: 5.2183
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 2.07s
                      Time elapsed: 00:07:02
                               ETA: 00:51:19

################################################################################
                     [1m Learning iteration 181/1500 [0m                      

                       Computation: 47651 steps/s (collection: 1.975s, learning 0.088s)
             Mean action noise std: 1.66
          Mean value_function loss: 15.0280
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 59.6877
                       Mean reward: 26.03
               Mean episode length: 238.22
    Episode_Reward/reaching_object: 1.1027
    Episode_Reward/rotating_object: 5.1452
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 2.06s
                      Time elapsed: 00:07:04
                               ETA: 00:51:15

################################################################################
                     [1m Learning iteration 182/1500 [0m                      

                       Computation: 47416 steps/s (collection: 1.975s, learning 0.099s)
             Mean action noise std: 1.67
          Mean value_function loss: 16.4290
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 59.7557
                       Mean reward: 27.40
               Mean episode length: 237.48
    Episode_Reward/reaching_object: 1.1039
    Episode_Reward/rotating_object: 5.1021
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 2.07s
                      Time elapsed: 00:07:06
                               ETA: 00:51:11

################################################################################
                     [1m Learning iteration 183/1500 [0m                      

                       Computation: 45802 steps/s (collection: 2.048s, learning 0.098s)
             Mean action noise std: 1.67
          Mean value_function loss: 13.7784
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 59.8084
                       Mean reward: 26.31
               Mean episode length: 230.47
    Episode_Reward/reaching_object: 1.0702
    Episode_Reward/rotating_object: 5.6117
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 2.15s
                      Time elapsed: 00:07:08
                               ETA: 00:51:07

################################################################################
                     [1m Learning iteration 184/1500 [0m                      

                       Computation: 44110 steps/s (collection: 2.121s, learning 0.108s)
             Mean action noise std: 1.67
          Mean value_function loss: 14.4008
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 59.8648
                       Mean reward: 23.42
               Mean episode length: 233.79
    Episode_Reward/reaching_object: 1.1193
    Episode_Reward/rotating_object: 5.4802
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 2.23s
                      Time elapsed: 00:07:10
                               ETA: 00:51:04

################################################################################
                     [1m Learning iteration 185/1500 [0m                      

                       Computation: 47064 steps/s (collection: 1.974s, learning 0.115s)
             Mean action noise std: 1.68
          Mean value_function loss: 16.5751
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 59.9134
                       Mean reward: 38.82
               Mean episode length: 234.25
    Episode_Reward/reaching_object: 1.0620
    Episode_Reward/rotating_object: 5.2775
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 2.09s
                      Time elapsed: 00:07:12
                               ETA: 00:51:00

################################################################################
                     [1m Learning iteration 186/1500 [0m                      

                       Computation: 46601 steps/s (collection: 1.992s, learning 0.117s)
             Mean action noise std: 1.68
          Mean value_function loss: 18.3952
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 59.9665
                       Mean reward: 33.23
               Mean episode length: 229.18
    Episode_Reward/reaching_object: 1.0595
    Episode_Reward/rotating_object: 4.9968
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 2.11s
                      Time elapsed: 00:07:15
                               ETA: 00:50:56

################################################################################
                     [1m Learning iteration 187/1500 [0m                      

                       Computation: 46951 steps/s (collection: 1.974s, learning 0.120s)
             Mean action noise std: 1.68
          Mean value_function loss: 16.5543
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 59.9979
                       Mean reward: 26.73
               Mean episode length: 228.70
    Episode_Reward/reaching_object: 1.0677
    Episode_Reward/rotating_object: 4.7660
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 2.09s
                      Time elapsed: 00:07:17
                               ETA: 00:50:52

################################################################################
                     [1m Learning iteration 188/1500 [0m                      

                       Computation: 47657 steps/s (collection: 1.955s, learning 0.108s)
             Mean action noise std: 1.68
          Mean value_function loss: 18.6205
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 60.0530
                       Mean reward: 27.57
               Mean episode length: 227.03
    Episode_Reward/reaching_object: 1.1015
    Episode_Reward/rotating_object: 6.1582
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 2.06s
                      Time elapsed: 00:07:19
                               ETA: 00:50:48

################################################################################
                     [1m Learning iteration 189/1500 [0m                      

                       Computation: 42006 steps/s (collection: 2.217s, learning 0.124s)
             Mean action noise std: 1.69
          Mean value_function loss: 19.3903
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 60.1157
                       Mean reward: 32.19
               Mean episode length: 229.69
    Episode_Reward/reaching_object: 1.0540
    Episode_Reward/rotating_object: 5.8777
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 2.34s
                      Time elapsed: 00:07:21
                               ETA: 00:50:46

################################################################################
                     [1m Learning iteration 190/1500 [0m                      

                       Computation: 43387 steps/s (collection: 2.164s, learning 0.102s)
             Mean action noise std: 1.69
          Mean value_function loss: 19.7714
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 60.1589
                       Mean reward: 29.23
               Mean episode length: 229.23
    Episode_Reward/reaching_object: 1.0333
    Episode_Reward/rotating_object: 5.4001
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 2.27s
                      Time elapsed: 00:07:23
                               ETA: 00:50:43

################################################################################
                     [1m Learning iteration 191/1500 [0m                      

                       Computation: 44862 steps/s (collection: 2.094s, learning 0.098s)
             Mean action noise std: 1.69
          Mean value_function loss: 18.7061
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 60.2178
                       Mean reward: 36.54
               Mean episode length: 234.46
    Episode_Reward/reaching_object: 1.0753
    Episode_Reward/rotating_object: 4.9087
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 2.19s
                      Time elapsed: 00:07:25
                               ETA: 00:50:40

################################################################################
                     [1m Learning iteration 192/1500 [0m                      

                       Computation: 46729 steps/s (collection: 2.005s, learning 0.099s)
             Mean action noise std: 1.70
          Mean value_function loss: 20.1092
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 60.2877
                       Mean reward: 27.11
               Mean episode length: 233.08
    Episode_Reward/reaching_object: 1.1047
    Episode_Reward/rotating_object: 4.6790
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 2.10s
                      Time elapsed: 00:07:28
                               ETA: 00:50:36

################################################################################
                     [1m Learning iteration 193/1500 [0m                      

                       Computation: 45808 steps/s (collection: 2.025s, learning 0.121s)
             Mean action noise std: 1.70
          Mean value_function loss: 20.2360
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 60.3466
                       Mean reward: 34.09
               Mean episode length: 230.31
    Episode_Reward/reaching_object: 1.0759
    Episode_Reward/rotating_object: 5.5153
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 2.15s
                      Time elapsed: 00:07:30
                               ETA: 00:50:33

################################################################################
                     [1m Learning iteration 194/1500 [0m                      

                       Computation: 45912 steps/s (collection: 2.026s, learning 0.116s)
             Mean action noise std: 1.70
          Mean value_function loss: 20.2570
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 60.4027
                       Mean reward: 25.49
               Mean episode length: 229.14
    Episode_Reward/reaching_object: 1.0382
    Episode_Reward/rotating_object: 5.5647
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 2.14s
                      Time elapsed: 00:07:32
                               ETA: 00:50:29

################################################################################
                     [1m Learning iteration 195/1500 [0m                      

                       Computation: 46314 steps/s (collection: 2.006s, learning 0.116s)
             Mean action noise std: 1.70
          Mean value_function loss: 20.0587
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 60.4512
                       Mean reward: 38.39
               Mean episode length: 230.42
    Episode_Reward/reaching_object: 1.0633
    Episode_Reward/rotating_object: 7.3938
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 2.12s
                      Time elapsed: 00:07:34
                               ETA: 00:50:25

################################################################################
                     [1m Learning iteration 196/1500 [0m                      

                       Computation: 45854 steps/s (collection: 2.021s, learning 0.123s)
             Mean action noise std: 1.71
          Mean value_function loss: 21.7022
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 60.4892
                       Mean reward: 36.11
               Mean episode length: 223.08
    Episode_Reward/reaching_object: 1.0627
    Episode_Reward/rotating_object: 6.8477
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 12.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 2.14s
                      Time elapsed: 00:07:36
                               ETA: 00:50:22

################################################################################
                     [1m Learning iteration 197/1500 [0m                      

                       Computation: 45044 steps/s (collection: 2.061s, learning 0.122s)
             Mean action noise std: 1.71
          Mean value_function loss: 23.9225
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 60.5462
                       Mean reward: 32.60
               Mean episode length: 223.45
    Episode_Reward/reaching_object: 1.0652
    Episode_Reward/rotating_object: 6.7876
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 2.18s
                      Time elapsed: 00:07:38
                               ETA: 00:50:19

################################################################################
                     [1m Learning iteration 198/1500 [0m                      

                       Computation: 45439 steps/s (collection: 2.050s, learning 0.114s)
             Mean action noise std: 1.71
          Mean value_function loss: 22.2777
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 60.6029
                       Mean reward: 33.79
               Mean episode length: 226.80
    Episode_Reward/reaching_object: 1.0988
    Episode_Reward/rotating_object: 6.0384
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 2.16s
                      Time elapsed: 00:07:40
                               ETA: 00:50:15

################################################################################
                     [1m Learning iteration 199/1500 [0m                      

                       Computation: 46525 steps/s (collection: 2.009s, learning 0.104s)
             Mean action noise std: 1.72
          Mean value_function loss: 23.0718
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 60.6791
                       Mean reward: 42.62
               Mean episode length: 233.80
    Episode_Reward/reaching_object: 1.1016
    Episode_Reward/rotating_object: 6.2375
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 2.11s
                      Time elapsed: 00:07:43
                               ETA: 00:50:12

################################################################################
                     [1m Learning iteration 200/1500 [0m                      

                       Computation: 46661 steps/s (collection: 2.017s, learning 0.090s)
             Mean action noise std: 1.72
          Mean value_function loss: 21.0198
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 60.7422
                       Mean reward: 36.16
               Mean episode length: 230.47
    Episode_Reward/reaching_object: 1.0619
    Episode_Reward/rotating_object: 6.3714
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 2.11s
                      Time elapsed: 00:07:45
                               ETA: 00:50:08

################################################################################
                     [1m Learning iteration 201/1500 [0m                      

                       Computation: 41215 steps/s (collection: 2.221s, learning 0.165s)
             Mean action noise std: 1.72
          Mean value_function loss: 19.8259
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 60.8052
                       Mean reward: 35.71
               Mean episode length: 227.17
    Episode_Reward/reaching_object: 1.1040
    Episode_Reward/rotating_object: 6.7349
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 2.39s
                      Time elapsed: 00:07:47
                               ETA: 00:50:06

################################################################################
                     [1m Learning iteration 202/1500 [0m                      

                       Computation: 45701 steps/s (collection: 2.042s, learning 0.109s)
             Mean action noise std: 1.73
          Mean value_function loss: 22.5502
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 60.8641
                       Mean reward: 26.20
               Mean episode length: 225.98
    Episode_Reward/reaching_object: 1.0404
    Episode_Reward/rotating_object: 5.0179
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 2.15s
                      Time elapsed: 00:07:49
                               ETA: 00:50:03

################################################################################
                     [1m Learning iteration 203/1500 [0m                      

                       Computation: 46585 steps/s (collection: 2.005s, learning 0.105s)
             Mean action noise std: 1.73
          Mean value_function loss: 21.3143
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 60.9307
                       Mean reward: 26.30
               Mean episode length: 223.52
    Episode_Reward/reaching_object: 1.0569
    Episode_Reward/rotating_object: 5.6161
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 2.11s
                      Time elapsed: 00:07:51
                               ETA: 00:49:59

################################################################################
                     [1m Learning iteration 204/1500 [0m                      

                       Computation: 48359 steps/s (collection: 1.935s, learning 0.097s)
             Mean action noise std: 1.74
          Mean value_function loss: 23.9335
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 60.9934
                       Mean reward: 55.39
               Mean episode length: 236.70
    Episode_Reward/reaching_object: 1.0759
    Episode_Reward/rotating_object: 6.5554
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 2.03s
                      Time elapsed: 00:07:53
                               ETA: 00:49:55

################################################################################
                     [1m Learning iteration 205/1500 [0m                      

                       Computation: 46599 steps/s (collection: 2.009s, learning 0.101s)
             Mean action noise std: 1.74
          Mean value_function loss: 21.8575
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 61.0451
                       Mean reward: 47.28
               Mean episode length: 230.46
    Episode_Reward/reaching_object: 1.0548
    Episode_Reward/rotating_object: 7.3046
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 2.11s
                      Time elapsed: 00:07:55
                               ETA: 00:49:52

################################################################################
                     [1m Learning iteration 206/1500 [0m                      

                       Computation: 46649 steps/s (collection: 1.992s, learning 0.116s)
             Mean action noise std: 1.74
          Mean value_function loss: 23.3919
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 61.1006
                       Mean reward: 32.75
               Mean episode length: 230.19
    Episode_Reward/reaching_object: 1.0663
    Episode_Reward/rotating_object: 5.6216
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 2.11s
                      Time elapsed: 00:07:58
                               ETA: 00:49:48

################################################################################
                     [1m Learning iteration 207/1500 [0m                      

                       Computation: 46463 steps/s (collection: 1.992s, learning 0.124s)
             Mean action noise std: 1.74
          Mean value_function loss: 21.3379
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 61.1528
                       Mean reward: 55.54
               Mean episode length: 235.58
    Episode_Reward/reaching_object: 1.1038
    Episode_Reward/rotating_object: 8.7905
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 2.12s
                      Time elapsed: 00:08:00
                               ETA: 00:49:45

################################################################################
                     [1m Learning iteration 208/1500 [0m                      

                       Computation: 43452 steps/s (collection: 2.121s, learning 0.141s)
             Mean action noise std: 1.75
          Mean value_function loss: 23.1189
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 61.1998
                       Mean reward: 33.26
               Mean episode length: 238.14
    Episode_Reward/reaching_object: 1.0836
    Episode_Reward/rotating_object: 5.7927
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 2.26s
                      Time elapsed: 00:08:02
                               ETA: 00:49:42

################################################################################
                     [1m Learning iteration 209/1500 [0m                      

                       Computation: 46345 steps/s (collection: 2.019s, learning 0.102s)
             Mean action noise std: 1.75
          Mean value_function loss: 23.2938
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 61.2594
                       Mean reward: 39.38
               Mean episode length: 236.14
    Episode_Reward/reaching_object: 1.0800
    Episode_Reward/rotating_object: 7.7459
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 2.12s
                      Time elapsed: 00:08:04
                               ETA: 00:49:39

################################################################################
                     [1m Learning iteration 210/1500 [0m                      

                       Computation: 46521 steps/s (collection: 2.013s, learning 0.101s)
             Mean action noise std: 1.75
          Mean value_function loss: 20.7207
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 61.3119
                       Mean reward: 36.15
               Mean episode length: 233.53
    Episode_Reward/reaching_object: 1.0622
    Episode_Reward/rotating_object: 6.9436
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 2.11s
                      Time elapsed: 00:08:06
                               ETA: 00:49:35

################################################################################
                     [1m Learning iteration 211/1500 [0m                      

                       Computation: 46926 steps/s (collection: 2.003s, learning 0.092s)
             Mean action noise std: 1.76
          Mean value_function loss: 21.5221
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 61.3773
                       Mean reward: 45.88
               Mean episode length: 240.22
    Episode_Reward/reaching_object: 1.0858
    Episode_Reward/rotating_object: 7.1139
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 2.09s
                      Time elapsed: 00:08:08
                               ETA: 00:49:31

################################################################################
                     [1m Learning iteration 212/1500 [0m                      

                       Computation: 47016 steps/s (collection: 1.981s, learning 0.109s)
             Mean action noise std: 1.76
          Mean value_function loss: 19.2359
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 61.4408
                       Mean reward: 40.67
               Mean episode length: 242.19
    Episode_Reward/reaching_object: 1.0581
    Episode_Reward/rotating_object: 7.1378
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 2.09s
                      Time elapsed: 00:08:10
                               ETA: 00:49:28

################################################################################
                     [1m Learning iteration 213/1500 [0m                      

                       Computation: 46258 steps/s (collection: 2.003s, learning 0.122s)
             Mean action noise std: 1.76
          Mean value_function loss: 21.6711
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 61.5045
                       Mean reward: 43.72
               Mean episode length: 231.29
    Episode_Reward/reaching_object: 1.0949
    Episode_Reward/rotating_object: 7.1819
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 2.13s
                      Time elapsed: 00:08:13
                               ETA: 00:49:24

################################################################################
                     [1m Learning iteration 214/1500 [0m                      

                       Computation: 46145 steps/s (collection: 2.013s, learning 0.117s)
             Mean action noise std: 1.77
          Mean value_function loss: 24.2298
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 61.5802
                       Mean reward: 39.52
               Mean episode length: 237.97
    Episode_Reward/reaching_object: 1.1002
    Episode_Reward/rotating_object: 8.5018
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 2.13s
                      Time elapsed: 00:08:15
                               ETA: 00:49:21

################################################################################
                     [1m Learning iteration 215/1500 [0m                      

                       Computation: 47488 steps/s (collection: 1.971s, learning 0.100s)
             Mean action noise std: 1.77
          Mean value_function loss: 26.1111
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 61.6316
                       Mean reward: 45.49
               Mean episode length: 229.32
    Episode_Reward/reaching_object: 1.0932
    Episode_Reward/rotating_object: 7.2744
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 2.07s
                      Time elapsed: 00:08:17
                               ETA: 00:49:17

################################################################################
                     [1m Learning iteration 216/1500 [0m                      

                       Computation: 46423 steps/s (collection: 2.001s, learning 0.117s)
             Mean action noise std: 1.78
          Mean value_function loss: 24.7458
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 61.6955
                       Mean reward: 50.57
               Mean episode length: 228.74
    Episode_Reward/reaching_object: 1.0881
    Episode_Reward/rotating_object: 7.8697
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 2.12s
                      Time elapsed: 00:08:19
                               ETA: 00:49:14

################################################################################
                     [1m Learning iteration 217/1500 [0m                      

                       Computation: 46662 steps/s (collection: 1.968s, learning 0.139s)
             Mean action noise std: 1.78
          Mean value_function loss: 24.9464
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 61.7467
                       Mean reward: 33.39
               Mean episode length: 229.12
    Episode_Reward/reaching_object: 1.0709
    Episode_Reward/rotating_object: 6.4589
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 2.11s
                      Time elapsed: 00:08:21
                               ETA: 00:49:11

################################################################################
                     [1m Learning iteration 218/1500 [0m                      

                       Computation: 41157 steps/s (collection: 2.297s, learning 0.091s)
             Mean action noise std: 1.78
          Mean value_function loss: 29.2461
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 61.7859
                       Mean reward: 28.77
               Mean episode length: 235.82
    Episode_Reward/reaching_object: 1.0906
    Episode_Reward/rotating_object: 5.5241
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 2.39s
                      Time elapsed: 00:08:23
                               ETA: 00:49:09

################################################################################
                     [1m Learning iteration 219/1500 [0m                      

                       Computation: 46541 steps/s (collection: 2.014s, learning 0.098s)
             Mean action noise std: 1.78
          Mean value_function loss: 27.1935
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 61.8287
                       Mean reward: 42.55
               Mean episode length: 230.71
    Episode_Reward/reaching_object: 1.0880
    Episode_Reward/rotating_object: 7.7881
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 2.11s
                      Time elapsed: 00:08:25
                               ETA: 00:49:05

################################################################################
                     [1m Learning iteration 220/1500 [0m                      

                       Computation: 47309 steps/s (collection: 1.985s, learning 0.093s)
             Mean action noise std: 1.79
          Mean value_function loss: 29.8419
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 61.8775
                       Mean reward: 54.04
               Mean episode length: 237.72
    Episode_Reward/reaching_object: 1.1053
    Episode_Reward/rotating_object: 7.9301
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 2.08s
                      Time elapsed: 00:08:28
                               ETA: 00:49:02

################################################################################
                     [1m Learning iteration 221/1500 [0m                      

                       Computation: 46746 steps/s (collection: 2.007s, learning 0.096s)
             Mean action noise std: 1.79
          Mean value_function loss: 30.2639
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 61.9286
                       Mean reward: 55.61
               Mean episode length: 241.15
    Episode_Reward/reaching_object: 1.1164
    Episode_Reward/rotating_object: 8.6894
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 2.10s
                      Time elapsed: 00:08:30
                               ETA: 00:48:58

################################################################################
                     [1m Learning iteration 222/1500 [0m                      

                       Computation: 41481 steps/s (collection: 2.217s, learning 0.153s)
             Mean action noise std: 1.79
          Mean value_function loss: 27.8017
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 61.9740
                       Mean reward: 58.76
               Mean episode length: 242.24
    Episode_Reward/reaching_object: 1.1435
    Episode_Reward/rotating_object: 9.7130
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 2.37s
                      Time elapsed: 00:08:32
                               ETA: 00:48:56

################################################################################
                     [1m Learning iteration 223/1500 [0m                      

                       Computation: 41533 steps/s (collection: 2.233s, learning 0.134s)
             Mean action noise std: 1.79
          Mean value_function loss: 29.8943
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 62.0193
                       Mean reward: 45.27
               Mean episode length: 241.74
    Episode_Reward/reaching_object: 1.1292
    Episode_Reward/rotating_object: 9.6600
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 2.37s
                      Time elapsed: 00:08:34
                               ETA: 00:48:55

################################################################################
                     [1m Learning iteration 224/1500 [0m                      

                       Computation: 41421 steps/s (collection: 2.212s, learning 0.162s)
             Mean action noise std: 1.80
          Mean value_function loss: 30.9314
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 62.0688
                       Mean reward: 63.91
               Mean episode length: 239.08
    Episode_Reward/reaching_object: 1.1187
    Episode_Reward/rotating_object: 8.3809
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 2.37s
                      Time elapsed: 00:08:37
                               ETA: 00:48:53

################################################################################
                     [1m Learning iteration 225/1500 [0m                      

                       Computation: 40888 steps/s (collection: 2.288s, learning 0.117s)
             Mean action noise std: 1.80
          Mean value_function loss: 28.9946
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 62.1203
                       Mean reward: 49.90
               Mean episode length: 240.43
    Episode_Reward/reaching_object: 1.1705
    Episode_Reward/rotating_object: 10.6632
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 2.40s
                      Time elapsed: 00:08:39
                               ETA: 00:48:51

################################################################################
                     [1m Learning iteration 226/1500 [0m                      

                       Computation: 44121 steps/s (collection: 2.110s, learning 0.118s)
             Mean action noise std: 1.80
          Mean value_function loss: 29.9940
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 62.1704
                       Mean reward: 32.99
               Mean episode length: 238.55
    Episode_Reward/reaching_object: 1.1070
    Episode_Reward/rotating_object: 8.1590
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 2.23s
                      Time elapsed: 00:08:41
                               ETA: 00:48:48

################################################################################
                     [1m Learning iteration 227/1500 [0m                      

                       Computation: 41599 steps/s (collection: 2.262s, learning 0.102s)
             Mean action noise std: 1.81
          Mean value_function loss: 31.3838
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 62.2245
                       Mean reward: 41.68
               Mean episode length: 229.40
    Episode_Reward/reaching_object: 1.1092
    Episode_Reward/rotating_object: 8.2365
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 2.36s
                      Time elapsed: 00:08:44
                               ETA: 00:48:46

################################################################################
                     [1m Learning iteration 228/1500 [0m                      

                       Computation: 45594 steps/s (collection: 2.034s, learning 0.122s)
             Mean action noise std: 1.81
          Mean value_function loss: 30.3362
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 62.2703
                       Mean reward: 48.79
               Mean episode length: 235.60
    Episode_Reward/reaching_object: 1.1070
    Episode_Reward/rotating_object: 8.8123
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 2.16s
                      Time elapsed: 00:08:46
                               ETA: 00:48:43

################################################################################
                     [1m Learning iteration 229/1500 [0m                      

                       Computation: 45222 steps/s (collection: 2.036s, learning 0.138s)
             Mean action noise std: 1.81
          Mean value_function loss: 28.3561
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 62.3240
                       Mean reward: 43.37
               Mean episode length: 234.34
    Episode_Reward/reaching_object: 1.1149
    Episode_Reward/rotating_object: 8.5379
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 2.17s
                      Time elapsed: 00:08:48
                               ETA: 00:48:40

################################################################################
                     [1m Learning iteration 230/1500 [0m                      

                       Computation: 45009 steps/s (collection: 2.067s, learning 0.117s)
             Mean action noise std: 1.82
          Mean value_function loss: 30.9563
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 62.3760
                       Mean reward: 50.15
               Mean episode length: 233.08
    Episode_Reward/reaching_object: 1.1171
    Episode_Reward/rotating_object: 8.7923
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 2.18s
                      Time elapsed: 00:08:50
                               ETA: 00:48:37

################################################################################
                     [1m Learning iteration 231/1500 [0m                      

                       Computation: 45133 steps/s (collection: 2.038s, learning 0.141s)
             Mean action noise std: 1.82
          Mean value_function loss: 34.2855
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 62.4284
                       Mean reward: 41.62
               Mean episode length: 220.33
    Episode_Reward/reaching_object: 1.1082
    Episode_Reward/rotating_object: 8.9584
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 2.18s
                      Time elapsed: 00:08:52
                               ETA: 00:48:34

################################################################################
                     [1m Learning iteration 232/1500 [0m                      

                       Computation: 45244 steps/s (collection: 2.068s, learning 0.105s)
             Mean action noise std: 1.82
          Mean value_function loss: 31.4034
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 62.4699
                       Mean reward: 60.93
               Mean episode length: 231.73
    Episode_Reward/reaching_object: 1.0902
    Episode_Reward/rotating_object: 7.9398
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 2.17s
                      Time elapsed: 00:08:55
                               ETA: 00:48:31

################################################################################
                     [1m Learning iteration 233/1500 [0m                      

                       Computation: 45218 steps/s (collection: 2.032s, learning 0.142s)
             Mean action noise std: 1.82
          Mean value_function loss: 32.9072
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 62.5120
                       Mean reward: 53.52
               Mean episode length: 226.94
    Episode_Reward/reaching_object: 1.0956
    Episode_Reward/rotating_object: 9.3047
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 2.17s
                      Time elapsed: 00:08:57
                               ETA: 00:48:28

################################################################################
                     [1m Learning iteration 234/1500 [0m                      

                       Computation: 44356 steps/s (collection: 2.078s, learning 0.139s)
             Mean action noise std: 1.83
          Mean value_function loss: 33.7360
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 62.5645
                       Mean reward: 44.72
               Mean episode length: 232.52
    Episode_Reward/reaching_object: 1.0988
    Episode_Reward/rotating_object: 8.0837
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 2.22s
                      Time elapsed: 00:08:59
                               ETA: 00:48:26

################################################################################
                     [1m Learning iteration 235/1500 [0m                      

                       Computation: 45216 steps/s (collection: 2.049s, learning 0.125s)
             Mean action noise std: 1.83
          Mean value_function loss: 29.6362
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 62.6114
                       Mean reward: 64.57
               Mean episode length: 232.49
    Episode_Reward/reaching_object: 1.1115
    Episode_Reward/rotating_object: 9.0712
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 2.17s
                      Time elapsed: 00:09:01
                               ETA: 00:48:23

################################################################################
                     [1m Learning iteration 236/1500 [0m                      

                       Computation: 46568 steps/s (collection: 1.993s, learning 0.118s)
             Mean action noise std: 1.83
          Mean value_function loss: 31.5048
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 62.6650
                       Mean reward: 47.74
               Mean episode length: 228.92
    Episode_Reward/reaching_object: 1.1040
    Episode_Reward/rotating_object: 10.3882
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 2.11s
                      Time elapsed: 00:09:03
                               ETA: 00:48:20

################################################################################
                     [1m Learning iteration 237/1500 [0m                      

                       Computation: 46310 steps/s (collection: 2.024s, learning 0.099s)
             Mean action noise std: 1.84
          Mean value_function loss: 31.8944
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 62.7127
                       Mean reward: 53.54
               Mean episode length: 233.54
    Episode_Reward/reaching_object: 1.1089
    Episode_Reward/rotating_object: 9.9583
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 2.12s
                      Time elapsed: 00:09:05
                               ETA: 00:48:16

################################################################################
                     [1m Learning iteration 238/1500 [0m                      

                       Computation: 46245 steps/s (collection: 2.029s, learning 0.097s)
             Mean action noise std: 1.84
          Mean value_function loss: 33.0802
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 62.7747
                       Mean reward: 71.81
               Mean episode length: 227.35
    Episode_Reward/reaching_object: 1.0863
    Episode_Reward/rotating_object: 9.8778
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 2.13s
                      Time elapsed: 00:09:08
                               ETA: 00:48:13

################################################################################
                     [1m Learning iteration 239/1500 [0m                      

                       Computation: 45058 steps/s (collection: 2.062s, learning 0.120s)
             Mean action noise std: 1.84
          Mean value_function loss: 36.9085
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 62.8269
                       Mean reward: 49.95
               Mean episode length: 230.33
    Episode_Reward/reaching_object: 1.0638
    Episode_Reward/rotating_object: 7.8339
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 2.18s
                      Time elapsed: 00:09:10
                               ETA: 00:48:10

################################################################################
                     [1m Learning iteration 240/1500 [0m                      

                       Computation: 44220 steps/s (collection: 2.061s, learning 0.162s)
             Mean action noise std: 1.85
          Mean value_function loss: 43.3377
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 62.8750
                       Mean reward: 56.71
               Mean episode length: 232.87
    Episode_Reward/reaching_object: 1.1055
    Episode_Reward/rotating_object: 9.4613
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 2.22s
                      Time elapsed: 00:09:12
                               ETA: 00:48:08

################################################################################
                     [1m Learning iteration 241/1500 [0m                      

                       Computation: 44168 steps/s (collection: 2.102s, learning 0.124s)
             Mean action noise std: 1.85
          Mean value_function loss: 42.0274
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 62.9241
                       Mean reward: 55.00
               Mean episode length: 225.26
    Episode_Reward/reaching_object: 1.0929
    Episode_Reward/rotating_object: 8.9874
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 2.23s
                      Time elapsed: 00:09:14
                               ETA: 00:48:05

################################################################################
                     [1m Learning iteration 242/1500 [0m                      

                       Computation: 43356 steps/s (collection: 2.128s, learning 0.139s)
             Mean action noise std: 1.85
          Mean value_function loss: 41.7500
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 62.9719
                       Mean reward: 66.15
               Mean episode length: 230.90
    Episode_Reward/reaching_object: 1.1268
    Episode_Reward/rotating_object: 10.6935
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 2.27s
                      Time elapsed: 00:09:16
                               ETA: 00:48:03

################################################################################
                     [1m Learning iteration 243/1500 [0m                      

                       Computation: 43107 steps/s (collection: 2.115s, learning 0.166s)
             Mean action noise std: 1.85
          Mean value_function loss: 38.7747
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 63.0167
                       Mean reward: 60.62
               Mean episode length: 229.51
    Episode_Reward/reaching_object: 1.1213
    Episode_Reward/rotating_object: 9.4840
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 2.28s
                      Time elapsed: 00:09:19
                               ETA: 00:48:00

################################################################################
                     [1m Learning iteration 244/1500 [0m                      

                       Computation: 40277 steps/s (collection: 2.258s, learning 0.183s)
             Mean action noise std: 1.86
          Mean value_function loss: 40.7746
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 63.0649
                       Mean reward: 63.88
               Mean episode length: 231.67
    Episode_Reward/reaching_object: 1.1072
    Episode_Reward/rotating_object: 10.9055
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 2.44s
                      Time elapsed: 00:09:21
                               ETA: 00:47:59

################################################################################
                     [1m Learning iteration 245/1500 [0m                      

                       Computation: 43028 steps/s (collection: 2.136s, learning 0.149s)
             Mean action noise std: 1.86
          Mean value_function loss: 43.6774
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 63.1154
                       Mean reward: 45.80
               Mean episode length: 224.21
    Episode_Reward/reaching_object: 1.0803
    Episode_Reward/rotating_object: 9.7313
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 2.28s
                      Time elapsed: 00:09:23
                               ETA: 00:47:56

################################################################################
                     [1m Learning iteration 246/1500 [0m                      

                       Computation: 45481 steps/s (collection: 2.051s, learning 0.110s)
             Mean action noise std: 1.86
          Mean value_function loss: 41.0007
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 63.1617
                       Mean reward: 46.88
               Mean episode length: 230.14
    Episode_Reward/reaching_object: 1.1306
    Episode_Reward/rotating_object: 10.2306
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 2.16s
                      Time elapsed: 00:09:26
                               ETA: 00:47:53

################################################################################
                     [1m Learning iteration 247/1500 [0m                      

                       Computation: 46090 steps/s (collection: 2.036s, learning 0.097s)
             Mean action noise std: 1.87
          Mean value_function loss: 43.3726
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 63.2140
                       Mean reward: 64.73
               Mean episode length: 233.28
    Episode_Reward/reaching_object: 1.1262
    Episode_Reward/rotating_object: 10.8613
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 2.13s
                      Time elapsed: 00:09:28
                               ETA: 00:47:50

################################################################################
                     [1m Learning iteration 248/1500 [0m                      

                       Computation: 46317 steps/s (collection: 2.016s, learning 0.107s)
             Mean action noise std: 1.87
          Mean value_function loss: 44.5933
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 63.2692
                       Mean reward: 71.81
               Mean episode length: 231.27
    Episode_Reward/reaching_object: 1.1304
    Episode_Reward/rotating_object: 11.9454
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 2.12s
                      Time elapsed: 00:09:30
                               ETA: 00:47:47

################################################################################
                     [1m Learning iteration 249/1500 [0m                      

                       Computation: 44360 steps/s (collection: 2.108s, learning 0.108s)
             Mean action noise std: 1.87
          Mean value_function loss: 44.8087
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 63.3271
                       Mean reward: 71.78
               Mean episode length: 232.15
    Episode_Reward/reaching_object: 1.1497
    Episode_Reward/rotating_object: 13.1237
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 2.22s
                      Time elapsed: 00:09:32
                               ETA: 00:47:44

################################################################################
                     [1m Learning iteration 250/1500 [0m                      

                       Computation: 45118 steps/s (collection: 2.057s, learning 0.122s)
             Mean action noise std: 1.87
          Mean value_function loss: 40.5196
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 63.3747
                       Mean reward: 67.80
               Mean episode length: 239.23
    Episode_Reward/reaching_object: 1.1548
    Episode_Reward/rotating_object: 11.2919
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 2.18s
                      Time elapsed: 00:09:34
                               ETA: 00:47:42

################################################################################
                     [1m Learning iteration 251/1500 [0m                      

                       Computation: 44272 steps/s (collection: 2.108s, learning 0.113s)
             Mean action noise std: 1.88
          Mean value_function loss: 46.3320
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 63.4095
                       Mean reward: 73.09
               Mean episode length: 226.21
    Episode_Reward/reaching_object: 1.1307
    Episode_Reward/rotating_object: 12.9587
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 2.22s
                      Time elapsed: 00:09:36
                               ETA: 00:47:39

################################################################################
                     [1m Learning iteration 252/1500 [0m                      

                       Computation: 45641 steps/s (collection: 2.055s, learning 0.099s)
             Mean action noise std: 1.88
          Mean value_function loss: 39.2748
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 63.4416
                       Mean reward: 84.93
               Mean episode length: 233.65
    Episode_Reward/reaching_object: 1.1491
    Episode_Reward/rotating_object: 12.9481
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 2.15s
                      Time elapsed: 00:09:39
                               ETA: 00:47:36

################################################################################
                     [1m Learning iteration 253/1500 [0m                      

                       Computation: 46135 steps/s (collection: 2.032s, learning 0.099s)
             Mean action noise std: 1.88
          Mean value_function loss: 42.4256
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 63.4829
                       Mean reward: 58.84
               Mean episode length: 227.32
    Episode_Reward/reaching_object: 1.1508
    Episode_Reward/rotating_object: 11.6954
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 2.13s
                      Time elapsed: 00:09:41
                               ETA: 00:47:33

################################################################################
                     [1m Learning iteration 254/1500 [0m                      

                       Computation: 45001 steps/s (collection: 2.086s, learning 0.099s)
             Mean action noise std: 1.88
          Mean value_function loss: 43.0727
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 63.5238
                       Mean reward: 77.52
               Mean episode length: 231.10
    Episode_Reward/reaching_object: 1.1627
    Episode_Reward/rotating_object: 13.1842
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 2.18s
                      Time elapsed: 00:09:43
                               ETA: 00:47:30

################################################################################
                     [1m Learning iteration 255/1500 [0m                      

                       Computation: 46057 steps/s (collection: 2.038s, learning 0.096s)
             Mean action noise std: 1.89
          Mean value_function loss: 53.7215
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 63.5591
                       Mean reward: 78.39
               Mean episode length: 233.84
    Episode_Reward/reaching_object: 1.1703
    Episode_Reward/rotating_object: 14.7922
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 2.13s
                      Time elapsed: 00:09:45
                               ETA: 00:47:27

################################################################################
                     [1m Learning iteration 256/1500 [0m                      

                       Computation: 45175 steps/s (collection: 2.053s, learning 0.123s)
             Mean action noise std: 1.89
          Mean value_function loss: 46.8731
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 63.6004
                       Mean reward: 69.49
               Mean episode length: 237.14
    Episode_Reward/reaching_object: 1.1690
    Episode_Reward/rotating_object: 12.3762
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 2.18s
                      Time elapsed: 00:09:47
                               ETA: 00:47:24

################################################################################
                     [1m Learning iteration 257/1500 [0m                      

                       Computation: 45428 steps/s (collection: 2.066s, learning 0.098s)
             Mean action noise std: 1.89
          Mean value_function loss: 44.4323
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 63.6511
                       Mean reward: 80.89
               Mean episode length: 231.18
    Episode_Reward/reaching_object: 1.1546
    Episode_Reward/rotating_object: 14.8313
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 2.16s
                      Time elapsed: 00:09:49
                               ETA: 00:47:21

################################################################################
                     [1m Learning iteration 258/1500 [0m                      

                       Computation: 45456 steps/s (collection: 2.067s, learning 0.096s)
             Mean action noise std: 1.89
          Mean value_function loss: 42.5875
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 63.6941
                       Mean reward: 67.01
               Mean episode length: 226.47
    Episode_Reward/reaching_object: 1.1271
    Episode_Reward/rotating_object: 13.1604
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 2.16s
                      Time elapsed: 00:09:52
                               ETA: 00:47:19

################################################################################
                     [1m Learning iteration 259/1500 [0m                      

                       Computation: 45653 steps/s (collection: 2.058s, learning 0.096s)
             Mean action noise std: 1.90
          Mean value_function loss: 38.9369
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 63.7441
                       Mean reward: 68.46
               Mean episode length: 210.96
    Episode_Reward/reaching_object: 1.1101
    Episode_Reward/rotating_object: 13.1118
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 2.15s
                      Time elapsed: 00:09:54
                               ETA: 00:47:16

################################################################################
                     [1m Learning iteration 260/1500 [0m                      

                       Computation: 45261 steps/s (collection: 2.073s, learning 0.099s)
             Mean action noise std: 1.90
          Mean value_function loss: 39.4650
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 63.7907
                       Mean reward: 70.23
               Mean episode length: 216.17
    Episode_Reward/reaching_object: 1.1214
    Episode_Reward/rotating_object: 13.8187
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 2.17s
                      Time elapsed: 00:09:56
                               ETA: 00:47:13

################################################################################
                     [1m Learning iteration 261/1500 [0m                      

                       Computation: 45653 steps/s (collection: 2.043s, learning 0.111s)
             Mean action noise std: 1.90
          Mean value_function loss: 46.1000
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 63.8330
                       Mean reward: 69.98
               Mean episode length: 226.86
    Episode_Reward/reaching_object: 1.1136
    Episode_Reward/rotating_object: 12.5066
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 2.15s
                      Time elapsed: 00:09:58
                               ETA: 00:47:10

################################################################################
                     [1m Learning iteration 262/1500 [0m                      

                       Computation: 44501 steps/s (collection: 2.058s, learning 0.151s)
             Mean action noise std: 1.90
          Mean value_function loss: 47.0611
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 63.8690
                       Mean reward: 64.18
               Mean episode length: 215.60
    Episode_Reward/reaching_object: 1.1270
    Episode_Reward/rotating_object: 14.5464
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 2.21s
                      Time elapsed: 00:10:00
                               ETA: 00:47:07

################################################################################
                     [1m Learning iteration 263/1500 [0m                      

                       Computation: 42079 steps/s (collection: 2.202s, learning 0.134s)
             Mean action noise std: 1.91
          Mean value_function loss: 43.7872
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 63.9106
                       Mean reward: 82.93
               Mean episode length: 219.53
    Episode_Reward/reaching_object: 1.1730
    Episode_Reward/rotating_object: 14.5932
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 2.34s
                      Time elapsed: 00:10:03
                               ETA: 00:47:05

################################################################################
                     [1m Learning iteration 264/1500 [0m                      

                       Computation: 37832 steps/s (collection: 2.400s, learning 0.199s)
             Mean action noise std: 1.91
          Mean value_function loss: 45.4299
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 63.9537
                       Mean reward: 57.37
               Mean episode length: 214.21
    Episode_Reward/reaching_object: 1.1379
    Episode_Reward/rotating_object: 13.6520
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 2.60s
                      Time elapsed: 00:10:05
                               ETA: 00:47:04

################################################################################
                     [1m Learning iteration 265/1500 [0m                      

                       Computation: 40032 steps/s (collection: 2.332s, learning 0.124s)
             Mean action noise std: 1.91
          Mean value_function loss: 48.7471
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 63.9994
                       Mean reward: 53.97
               Mean episode length: 215.48
    Episode_Reward/reaching_object: 1.1334
    Episode_Reward/rotating_object: 11.1997
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 2.46s
                      Time elapsed: 00:10:08
                               ETA: 00:47:03

################################################################################
                     [1m Learning iteration 266/1500 [0m                      

                       Computation: 37889 steps/s (collection: 2.396s, learning 0.199s)
             Mean action noise std: 1.92
          Mean value_function loss: 49.3778
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 64.0404
                       Mean reward: 94.04
               Mean episode length: 226.97
    Episode_Reward/reaching_object: 1.1783
    Episode_Reward/rotating_object: 14.3281
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 11.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 2.59s
                      Time elapsed: 00:10:10
                               ETA: 00:47:02

################################################################################
                     [1m Learning iteration 267/1500 [0m                      

                       Computation: 41271 steps/s (collection: 2.236s, learning 0.146s)
             Mean action noise std: 1.92
          Mean value_function loss: 43.4884
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 64.0777
                       Mean reward: 91.66
               Mean episode length: 219.23
    Episode_Reward/reaching_object: 1.1563
    Episode_Reward/rotating_object: 15.6397
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 2.38s
                      Time elapsed: 00:10:13
                               ETA: 00:47:00

################################################################################
                     [1m Learning iteration 268/1500 [0m                      

                       Computation: 41814 steps/s (collection: 2.233s, learning 0.118s)
             Mean action noise std: 1.92
          Mean value_function loss: 48.8146
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 64.1152
                       Mean reward: 63.07
               Mean episode length: 220.43
    Episode_Reward/reaching_object: 1.1884
    Episode_Reward/rotating_object: 13.8097
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 2.35s
                      Time elapsed: 00:10:15
                               ETA: 00:46:58

################################################################################
                     [1m Learning iteration 269/1500 [0m                      

                       Computation: 41027 steps/s (collection: 2.185s, learning 0.211s)
             Mean action noise std: 1.92
          Mean value_function loss: 43.9326
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 64.1506
                       Mean reward: 70.24
               Mean episode length: 224.32
    Episode_Reward/reaching_object: 1.1317
    Episode_Reward/rotating_object: 13.4699
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 2.40s
                      Time elapsed: 00:10:17
                               ETA: 00:46:56

################################################################################
                     [1m Learning iteration 270/1500 [0m                      

                       Computation: 40571 steps/s (collection: 2.254s, learning 0.169s)
             Mean action noise std: 1.92
          Mean value_function loss: 42.5428
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 64.1819
                       Mean reward: 63.69
               Mean episode length: 222.06
    Episode_Reward/reaching_object: 1.1480
    Episode_Reward/rotating_object: 12.4591
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 2.42s
                      Time elapsed: 00:10:20
                               ETA: 00:46:55

################################################################################
                     [1m Learning iteration 271/1500 [0m                      

                       Computation: 40262 steps/s (collection: 2.270s, learning 0.171s)
             Mean action noise std: 1.93
          Mean value_function loss: 48.0408
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 64.2208
                       Mean reward: 112.25
               Mean episode length: 222.44
    Episode_Reward/reaching_object: 1.1534
    Episode_Reward/rotating_object: 17.0991
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 2.44s
                      Time elapsed: 00:10:22
                               ETA: 00:46:53

################################################################################
                     [1m Learning iteration 272/1500 [0m                      

                       Computation: 42226 steps/s (collection: 2.183s, learning 0.145s)
             Mean action noise std: 1.93
          Mean value_function loss: 48.7531
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 64.2599
                       Mean reward: 105.13
               Mean episode length: 235.79
    Episode_Reward/reaching_object: 1.1883
    Episode_Reward/rotating_object: 16.8098
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 2.33s
                      Time elapsed: 00:10:25
                               ETA: 00:46:51

################################################################################
                     [1m Learning iteration 273/1500 [0m                      

                       Computation: 39050 steps/s (collection: 2.381s, learning 0.137s)
             Mean action noise std: 1.93
          Mean value_function loss: 43.9103
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 64.3041
                       Mean reward: 76.66
               Mean episode length: 221.46
    Episode_Reward/reaching_object: 1.1787
    Episode_Reward/rotating_object: 15.5004
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 2.52s
                      Time elapsed: 00:10:27
                               ETA: 00:46:50

################################################################################
                     [1m Learning iteration 274/1500 [0m                      

                       Computation: 40178 steps/s (collection: 2.250s, learning 0.197s)
             Mean action noise std: 1.94
          Mean value_function loss: 44.4347
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 64.3480
                       Mean reward: 96.87
               Mean episode length: 228.75
    Episode_Reward/reaching_object: 1.1732
    Episode_Reward/rotating_object: 15.7597
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 2.45s
                      Time elapsed: 00:10:30
                               ETA: 00:46:48

################################################################################
                     [1m Learning iteration 275/1500 [0m                      

                       Computation: 41888 steps/s (collection: 2.205s, learning 0.142s)
             Mean action noise std: 1.94
          Mean value_function loss: 51.4442
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 64.3876
                       Mean reward: 84.35
               Mean episode length: 213.93
    Episode_Reward/reaching_object: 1.1639
    Episode_Reward/rotating_object: 15.0040
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 2.35s
                      Time elapsed: 00:10:32
                               ETA: 00:46:46

################################################################################
                     [1m Learning iteration 276/1500 [0m                      

                       Computation: 41424 steps/s (collection: 2.237s, learning 0.136s)
             Mean action noise std: 1.94
          Mean value_function loss: 52.6182
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 64.4248
                       Mean reward: 93.25
               Mean episode length: 220.09
    Episode_Reward/reaching_object: 1.1468
    Episode_Reward/rotating_object: 16.0844
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 2.37s
                      Time elapsed: 00:10:34
                               ETA: 00:46:44

################################################################################
                     [1m Learning iteration 277/1500 [0m                      

                       Computation: 41906 steps/s (collection: 2.217s, learning 0.129s)
             Mean action noise std: 1.94
          Mean value_function loss: 56.2104
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 64.4586
                       Mean reward: 97.28
               Mean episode length: 220.24
    Episode_Reward/reaching_object: 1.1372
    Episode_Reward/rotating_object: 15.7577
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 2.35s
                      Time elapsed: 00:10:37
                               ETA: 00:46:42

################################################################################
                     [1m Learning iteration 278/1500 [0m                      

                       Computation: 38924 steps/s (collection: 2.351s, learning 0.174s)
             Mean action noise std: 1.95
          Mean value_function loss: 60.5334
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 64.5021
                       Mean reward: 95.83
               Mean episode length: 222.87
    Episode_Reward/reaching_object: 1.1801
    Episode_Reward/rotating_object: 15.0950
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 2.53s
                      Time elapsed: 00:10:39
                               ETA: 00:46:41

################################################################################
                     [1m Learning iteration 279/1500 [0m                      

                       Computation: 41550 steps/s (collection: 2.229s, learning 0.137s)
             Mean action noise std: 1.95
          Mean value_function loss: 60.2882
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 64.5484
                       Mean reward: 83.58
               Mean episode length: 226.97
    Episode_Reward/reaching_object: 1.1792
    Episode_Reward/rotating_object: 15.4933
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 2.37s
                      Time elapsed: 00:10:41
                               ETA: 00:46:39

################################################################################
                     [1m Learning iteration 280/1500 [0m                      

                       Computation: 42080 steps/s (collection: 2.225s, learning 0.111s)
             Mean action noise std: 1.95
          Mean value_function loss: 62.5304
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 64.5804
                       Mean reward: 73.08
               Mean episode length: 219.44
    Episode_Reward/reaching_object: 1.1860
    Episode_Reward/rotating_object: 17.0339
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 2.34s
                      Time elapsed: 00:10:44
                               ETA: 00:46:37

################################################################################
                     [1m Learning iteration 281/1500 [0m                      

                       Computation: 40880 steps/s (collection: 2.290s, learning 0.115s)
             Mean action noise std: 1.95
          Mean value_function loss: 61.2107
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 64.6157
                       Mean reward: 81.22
               Mean episode length: 223.66
    Episode_Reward/reaching_object: 1.2242
    Episode_Reward/rotating_object: 18.1694
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 2.40s
                      Time elapsed: 00:10:46
                               ETA: 00:46:35

################################################################################
                     [1m Learning iteration 282/1500 [0m                      

                       Computation: 42261 steps/s (collection: 2.183s, learning 0.143s)
             Mean action noise std: 1.96
          Mean value_function loss: 64.8247
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 64.6599
                       Mean reward: 98.82
               Mean episode length: 235.37
    Episode_Reward/reaching_object: 1.2406
    Episode_Reward/rotating_object: 20.5557
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 2.33s
                      Time elapsed: 00:10:49
                               ETA: 00:46:33

################################################################################
                     [1m Learning iteration 283/1500 [0m                      

                       Computation: 41902 steps/s (collection: 2.210s, learning 0.136s)
             Mean action noise std: 1.96
          Mean value_function loss: 64.5090
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 64.7052
                       Mean reward: 101.14
               Mean episode length: 220.03
    Episode_Reward/reaching_object: 1.2027
    Episode_Reward/rotating_object: 20.0146
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 2.35s
                      Time elapsed: 00:10:51
                               ETA: 00:46:31

################################################################################
                     [1m Learning iteration 284/1500 [0m                      

                       Computation: 42343 steps/s (collection: 2.148s, learning 0.173s)
             Mean action noise std: 1.96
          Mean value_function loss: 60.2753
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 64.7404
                       Mean reward: 127.02
               Mean episode length: 226.45
    Episode_Reward/reaching_object: 1.2132
    Episode_Reward/rotating_object: 22.8147
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 2.32s
                      Time elapsed: 00:10:53
                               ETA: 00:46:29

################################################################################
                     [1m Learning iteration 285/1500 [0m                      

                       Computation: 40556 steps/s (collection: 2.272s, learning 0.152s)
             Mean action noise std: 1.96
          Mean value_function loss: 51.6200
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 64.7713
                       Mean reward: 95.73
               Mean episode length: 221.20
    Episode_Reward/reaching_object: 1.2039
    Episode_Reward/rotating_object: 19.2770
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 2.42s
                      Time elapsed: 00:10:56
                               ETA: 00:46:27

################################################################################
                     [1m Learning iteration 286/1500 [0m                      

                       Computation: 43158 steps/s (collection: 2.135s, learning 0.143s)
             Mean action noise std: 1.96
          Mean value_function loss: 63.7035
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 64.8062
                       Mean reward: 98.97
               Mean episode length: 224.22
    Episode_Reward/reaching_object: 1.2291
    Episode_Reward/rotating_object: 19.1358
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 2.28s
                      Time elapsed: 00:10:58
                               ETA: 00:46:24

################################################################################
                     [1m Learning iteration 287/1500 [0m                      

                       Computation: 42837 steps/s (collection: 2.172s, learning 0.123s)
             Mean action noise std: 1.97
          Mean value_function loss: 68.4058
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 64.8451
                       Mean reward: 110.19
               Mean episode length: 216.02
    Episode_Reward/reaching_object: 1.1955
    Episode_Reward/rotating_object: 17.0144
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 2.29s
                      Time elapsed: 00:11:00
                               ETA: 00:46:22

################################################################################
                     [1m Learning iteration 288/1500 [0m                      

                       Computation: 41172 steps/s (collection: 2.204s, learning 0.184s)
             Mean action noise std: 1.97
          Mean value_function loss: 61.8256
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 64.8753
                       Mean reward: 98.80
               Mean episode length: 232.03
    Episode_Reward/reaching_object: 1.2386
    Episode_Reward/rotating_object: 20.0459
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 2.39s
                      Time elapsed: 00:11:03
                               ETA: 00:46:20

################################################################################
                     [1m Learning iteration 289/1500 [0m                      

                       Computation: 39503 steps/s (collection: 2.347s, learning 0.141s)
             Mean action noise std: 1.97
          Mean value_function loss: 62.5336
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 64.9103
                       Mean reward: 109.05
               Mean episode length: 231.37
    Episode_Reward/reaching_object: 1.2321
    Episode_Reward/rotating_object: 20.6705
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 2.49s
                      Time elapsed: 00:11:05
                               ETA: 00:46:19

################################################################################
                     [1m Learning iteration 290/1500 [0m                      

                       Computation: 41787 steps/s (collection: 2.174s, learning 0.178s)
             Mean action noise std: 1.97
          Mean value_function loss: 71.4673
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 64.9386
                       Mean reward: 111.95
               Mean episode length: 229.97
    Episode_Reward/reaching_object: 1.2252
    Episode_Reward/rotating_object: 19.7338
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 2.35s
                      Time elapsed: 00:11:07
                               ETA: 00:46:17

################################################################################
                     [1m Learning iteration 291/1500 [0m                      

                       Computation: 41800 steps/s (collection: 2.199s, learning 0.153s)
             Mean action noise std: 1.97
          Mean value_function loss: 64.2415
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 64.9643
                       Mean reward: 133.92
               Mean episode length: 223.05
    Episode_Reward/reaching_object: 1.2358
    Episode_Reward/rotating_object: 23.9691
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 2.35s
                      Time elapsed: 00:11:10
                               ETA: 00:46:15

################################################################################
                     [1m Learning iteration 292/1500 [0m                      

                       Computation: 41224 steps/s (collection: 2.240s, learning 0.144s)
             Mean action noise std: 1.98
          Mean value_function loss: 69.4385
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 64.9961
                       Mean reward: 102.73
               Mean episode length: 214.27
    Episode_Reward/reaching_object: 1.1864
    Episode_Reward/rotating_object: 20.8661
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 2.38s
                      Time elapsed: 00:11:12
                               ETA: 00:46:13

################################################################################
                     [1m Learning iteration 293/1500 [0m                      

                       Computation: 42142 steps/s (collection: 2.147s, learning 0.186s)
             Mean action noise std: 1.98
          Mean value_function loss: 77.5748
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 65.0292
                       Mean reward: 109.74
               Mean episode length: 227.51
    Episode_Reward/reaching_object: 1.2266
    Episode_Reward/rotating_object: 19.7564
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 2.33s
                      Time elapsed: 00:11:14
                               ETA: 00:46:11

################################################################################
                     [1m Learning iteration 294/1500 [0m                      

                       Computation: 42997 steps/s (collection: 2.150s, learning 0.137s)
             Mean action noise std: 1.98
          Mean value_function loss: 79.8952
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 65.0559
                       Mean reward: 135.22
               Mean episode length: 228.49
    Episode_Reward/reaching_object: 1.2362
    Episode_Reward/rotating_object: 22.6714
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0472
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 2.29s
                      Time elapsed: 00:11:17
                               ETA: 00:46:08

################################################################################
                     [1m Learning iteration 295/1500 [0m                      

                       Computation: 42754 steps/s (collection: 2.189s, learning 0.111s)
             Mean action noise std: 1.98
          Mean value_function loss: 79.8347
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 65.0874
                       Mean reward: 111.99
               Mean episode length: 224.09
    Episode_Reward/reaching_object: 1.2496
    Episode_Reward/rotating_object: 24.1647
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 2.30s
                      Time elapsed: 00:11:19
                               ETA: 00:46:06

################################################################################
                     [1m Learning iteration 296/1500 [0m                      

                       Computation: 43061 steps/s (collection: 2.172s, learning 0.111s)
             Mean action noise std: 1.98
          Mean value_function loss: 82.9579
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 65.1215
                       Mean reward: 115.60
               Mean episode length: 218.65
    Episode_Reward/reaching_object: 1.2604
    Episode_Reward/rotating_object: 23.5644
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 2.28s
                      Time elapsed: 00:11:21
                               ETA: 00:46:04

################################################################################
                     [1m Learning iteration 297/1500 [0m                      

                       Computation: 42515 steps/s (collection: 2.204s, learning 0.109s)
             Mean action noise std: 1.99
          Mean value_function loss: 75.4339
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 65.1508
                       Mean reward: 127.59
               Mean episode length: 225.44
    Episode_Reward/reaching_object: 1.2707
    Episode_Reward/rotating_object: 24.2588
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 2.31s
                      Time elapsed: 00:11:24
                               ETA: 00:46:01

################################################################################
                     [1m Learning iteration 298/1500 [0m                      

                       Computation: 41261 steps/s (collection: 2.237s, learning 0.145s)
             Mean action noise std: 1.99
          Mean value_function loss: 83.0747
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 65.1797
                       Mean reward: 113.82
               Mean episode length: 220.33
    Episode_Reward/reaching_object: 1.2447
    Episode_Reward/rotating_object: 23.6670
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 2.38s
                      Time elapsed: 00:11:26
                               ETA: 00:45:59

################################################################################
                     [1m Learning iteration 299/1500 [0m                      

                       Computation: 42873 steps/s (collection: 2.164s, learning 0.129s)
             Mean action noise std: 1.99
          Mean value_function loss: 77.9261
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 65.2120
                       Mean reward: 151.84
               Mean episode length: 231.49
    Episode_Reward/reaching_object: 1.2705
    Episode_Reward/rotating_object: 24.8126
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 2.29s
                      Time elapsed: 00:11:28
                               ETA: 00:45:57

################################################################################
                     [1m Learning iteration 300/1500 [0m                      

                       Computation: 41551 steps/s (collection: 2.233s, learning 0.133s)
             Mean action noise std: 1.99
          Mean value_function loss: 79.9449
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 65.2476
                       Mean reward: 125.73
               Mean episode length: 215.34
    Episode_Reward/reaching_object: 1.2391
    Episode_Reward/rotating_object: 24.2795
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 2.37s
                      Time elapsed: 00:11:31
                               ETA: 00:45:55

################################################################################
                     [1m Learning iteration 301/1500 [0m                      

                       Computation: 40182 steps/s (collection: 2.308s, learning 0.139s)
             Mean action noise std: 1.99
          Mean value_function loss: 85.9105
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 65.2792
                       Mean reward: 137.33
               Mean episode length: 235.98
    Episode_Reward/reaching_object: 1.2985
    Episode_Reward/rotating_object: 26.1903
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 2.45s
                      Time elapsed: 00:11:33
                               ETA: 00:45:53

################################################################################
                     [1m Learning iteration 302/1500 [0m                      

                       Computation: 40690 steps/s (collection: 2.271s, learning 0.145s)
             Mean action noise std: 2.00
          Mean value_function loss: 71.9053
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 65.3127
                       Mean reward: 169.27
               Mean episode length: 233.31
    Episode_Reward/reaching_object: 1.2685
    Episode_Reward/rotating_object: 26.3094
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 2.42s
                      Time elapsed: 00:11:36
                               ETA: 00:45:52

################################################################################
                     [1m Learning iteration 303/1500 [0m                      

                       Computation: 39225 steps/s (collection: 2.385s, learning 0.121s)
             Mean action noise std: 2.00
          Mean value_function loss: 72.5023
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 65.3411
                       Mean reward: 124.08
               Mean episode length: 208.41
    Episode_Reward/reaching_object: 1.2584
    Episode_Reward/rotating_object: 26.4799
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 2.51s
                      Time elapsed: 00:11:38
                               ETA: 00:45:50

################################################################################
                     [1m Learning iteration 304/1500 [0m                      

                       Computation: 42640 steps/s (collection: 2.203s, learning 0.103s)
             Mean action noise std: 2.00
          Mean value_function loss: 66.8728
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 65.3679
                       Mean reward: 156.41
               Mean episode length: 218.44
    Episode_Reward/reaching_object: 1.2679
    Episode_Reward/rotating_object: 28.1878
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0468
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 2.31s
                      Time elapsed: 00:11:40
                               ETA: 00:45:48

################################################################################
                     [1m Learning iteration 305/1500 [0m                      

                       Computation: 41453 steps/s (collection: 2.247s, learning 0.125s)
             Mean action noise std: 2.00
          Mean value_function loss: 62.2817
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 65.3973
                       Mean reward: 140.33
               Mean episode length: 232.49
    Episode_Reward/reaching_object: 1.2407
    Episode_Reward/rotating_object: 27.9666
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0472
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 2.37s
                      Time elapsed: 00:11:43
                               ETA: 00:45:46

################################################################################
                     [1m Learning iteration 306/1500 [0m                      

                       Computation: 42955 steps/s (collection: 2.163s, learning 0.126s)
             Mean action noise std: 2.00
          Mean value_function loss: 64.1216
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 65.4326
                       Mean reward: 143.62
               Mean episode length: 220.51
    Episode_Reward/reaching_object: 1.2461
    Episode_Reward/rotating_object: 26.0901
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 2.29s
                      Time elapsed: 00:11:45
                               ETA: 00:45:44

################################################################################
                     [1m Learning iteration 307/1500 [0m                      

                       Computation: 43595 steps/s (collection: 2.124s, learning 0.131s)
             Mean action noise std: 2.01
          Mean value_function loss: 63.3255
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 65.4606
                       Mean reward: 132.17
               Mean episode length: 227.21
    Episode_Reward/reaching_object: 1.2966
    Episode_Reward/rotating_object: 29.1337
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 2.25s
                      Time elapsed: 00:11:47
                               ETA: 00:45:41

################################################################################
                     [1m Learning iteration 308/1500 [0m                      

                       Computation: 42456 steps/s (collection: 2.195s, learning 0.121s)
             Mean action noise std: 2.01
          Mean value_function loss: 65.9561
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 65.4850
                       Mean reward: 160.93
               Mean episode length: 229.20
    Episode_Reward/reaching_object: 1.2333
    Episode_Reward/rotating_object: 29.8418
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 2.32s
                      Time elapsed: 00:11:50
                               ETA: 00:45:39

################################################################################
                     [1m Learning iteration 309/1500 [0m                      

                       Computation: 41013 steps/s (collection: 2.257s, learning 0.140s)
             Mean action noise std: 2.01
          Mean value_function loss: 68.1679
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 65.5068
                       Mean reward: 119.24
               Mean episode length: 212.51
    Episode_Reward/reaching_object: 1.2701
    Episode_Reward/rotating_object: 28.3479
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 2.40s
                      Time elapsed: 00:11:52
                               ETA: 00:45:37

################################################################################
                     [1m Learning iteration 310/1500 [0m                      

                       Computation: 42430 steps/s (collection: 2.210s, learning 0.107s)
             Mean action noise std: 2.01
          Mean value_function loss: 71.0090
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 65.5281
                       Mean reward: 172.94
               Mean episode length: 216.73
    Episode_Reward/reaching_object: 1.2363
    Episode_Reward/rotating_object: 28.1154
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 2.32s
                      Time elapsed: 00:11:54
                               ETA: 00:45:35

################################################################################
                     [1m Learning iteration 311/1500 [0m                      

                       Computation: 42016 steps/s (collection: 2.226s, learning 0.114s)
             Mean action noise std: 2.01
          Mean value_function loss: 81.4911
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 65.5574
                       Mean reward: 164.02
               Mean episode length: 222.63
    Episode_Reward/reaching_object: 1.2581
    Episode_Reward/rotating_object: 30.6560
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 2.34s
                      Time elapsed: 00:11:57
                               ETA: 00:45:33

################################################################################
                     [1m Learning iteration 312/1500 [0m                      

                       Computation: 42497 steps/s (collection: 2.194s, learning 0.120s)
             Mean action noise std: 2.01
          Mean value_function loss: 71.6529
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 65.5863
                       Mean reward: 154.24
               Mean episode length: 217.07
    Episode_Reward/reaching_object: 1.2417
    Episode_Reward/rotating_object: 30.5720
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 2.31s
                      Time elapsed: 00:11:59
                               ETA: 00:45:30

################################################################################
                     [1m Learning iteration 313/1500 [0m                      

                       Computation: 42720 steps/s (collection: 2.180s, learning 0.121s)
             Mean action noise std: 2.02
          Mean value_function loss: 72.2967
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 65.6136
                       Mean reward: 135.10
               Mean episode length: 225.65
    Episode_Reward/reaching_object: 1.2316
    Episode_Reward/rotating_object: 30.9019
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 2.30s
                      Time elapsed: 00:12:01
                               ETA: 00:45:28

################################################################################
                     [1m Learning iteration 314/1500 [0m                      

                       Computation: 45547 steps/s (collection: 2.064s, learning 0.095s)
             Mean action noise std: 2.02
          Mean value_function loss: 67.6605
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 65.6332
                       Mean reward: 170.65
               Mean episode length: 218.20
    Episode_Reward/reaching_object: 1.2601
    Episode_Reward/rotating_object: 30.9919
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 2.16s
                      Time elapsed: 00:12:03
                               ETA: 00:45:25

################################################################################
                     [1m Learning iteration 315/1500 [0m                      

                       Computation: 41449 steps/s (collection: 2.240s, learning 0.132s)
             Mean action noise std: 2.02
          Mean value_function loss: 76.5445
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 65.6531
                       Mean reward: 192.47
               Mean episode length: 226.25
    Episode_Reward/reaching_object: 1.2935
    Episode_Reward/rotating_object: 32.5193
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 2.37s
                      Time elapsed: 00:12:06
                               ETA: 00:45:23

################################################################################
                     [1m Learning iteration 316/1500 [0m                      

                       Computation: 44381 steps/s (collection: 2.101s, learning 0.114s)
             Mean action noise std: 2.02
          Mean value_function loss: 80.9823
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 65.6816
                       Mean reward: 171.03
               Mean episode length: 223.76
    Episode_Reward/reaching_object: 1.2488
    Episode_Reward/rotating_object: 30.7701
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 2.21s
                      Time elapsed: 00:12:08
                               ETA: 00:45:21

################################################################################
                     [1m Learning iteration 317/1500 [0m                      

                       Computation: 42371 steps/s (collection: 2.172s, learning 0.148s)
             Mean action noise std: 2.02
          Mean value_function loss: 90.9768
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 65.7163
                       Mean reward: 160.33
               Mean episode length: 213.37
    Episode_Reward/reaching_object: 1.2263
    Episode_Reward/rotating_object: 30.5388
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0472
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 2.32s
                      Time elapsed: 00:12:10
                               ETA: 00:45:18

################################################################################
                     [1m Learning iteration 318/1500 [0m                      

                       Computation: 43017 steps/s (collection: 2.178s, learning 0.107s)
             Mean action noise std: 2.03
          Mean value_function loss: 94.8196
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 65.7382
                       Mean reward: 180.12
               Mean episode length: 223.25
    Episode_Reward/reaching_object: 1.2974
    Episode_Reward/rotating_object: 34.6525
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 2.29s
                      Time elapsed: 00:12:13
                               ETA: 00:45:16

################################################################################
                     [1m Learning iteration 319/1500 [0m                      

                       Computation: 43968 steps/s (collection: 2.110s, learning 0.126s)
             Mean action noise std: 2.03
          Mean value_function loss: 96.0536
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 65.7639
                       Mean reward: 200.98
               Mean episode length: 223.30
    Episode_Reward/reaching_object: 1.2457
    Episode_Reward/rotating_object: 34.1011
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 2.24s
                      Time elapsed: 00:12:15
                               ETA: 00:45:13

################################################################################
                     [1m Learning iteration 320/1500 [0m                      

                       Computation: 42166 steps/s (collection: 2.225s, learning 0.107s)
             Mean action noise std: 2.03
          Mean value_function loss: 90.8086
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 65.7855
                       Mean reward: 177.46
               Mean episode length: 220.39
    Episode_Reward/reaching_object: 1.2453
    Episode_Reward/rotating_object: 32.3293
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 2.33s
                      Time elapsed: 00:12:17
                               ETA: 00:45:11

################################################################################
                     [1m Learning iteration 321/1500 [0m                      

                       Computation: 44111 steps/s (collection: 2.130s, learning 0.099s)
             Mean action noise std: 2.03
          Mean value_function loss: 91.0806
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 65.8138
                       Mean reward: 169.66
               Mean episode length: 229.66
    Episode_Reward/reaching_object: 1.3090
    Episode_Reward/rotating_object: 33.4724
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 2.23s
                      Time elapsed: 00:12:19
                               ETA: 00:45:09

################################################################################
                     [1m Learning iteration 322/1500 [0m                      

                       Computation: 42008 steps/s (collection: 2.183s, learning 0.157s)
             Mean action noise std: 2.03
          Mean value_function loss: 87.8732
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 65.8438
                       Mean reward: 170.58
               Mean episode length: 222.75
    Episode_Reward/reaching_object: 1.2853
    Episode_Reward/rotating_object: 33.9693
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 2.34s
                      Time elapsed: 00:12:22
                               ETA: 00:45:07

################################################################################
                     [1m Learning iteration 323/1500 [0m                      

                       Computation: 44937 steps/s (collection: 2.091s, learning 0.097s)
             Mean action noise std: 2.03
          Mean value_function loss: 95.3447
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 65.8706
                       Mean reward: 192.76
               Mean episode length: 219.16
    Episode_Reward/reaching_object: 1.2731
    Episode_Reward/rotating_object: 34.4671
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 2.19s
                      Time elapsed: 00:12:24
                               ETA: 00:45:04

################################################################################
                     [1m Learning iteration 324/1500 [0m                      

                       Computation: 42610 steps/s (collection: 2.178s, learning 0.129s)
             Mean action noise std: 2.04
          Mean value_function loss: 84.8539
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 65.8894
                       Mean reward: 201.10
               Mean episode length: 221.96
    Episode_Reward/reaching_object: 1.3035
    Episode_Reward/rotating_object: 34.1536
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 2.31s
                      Time elapsed: 00:12:26
                               ETA: 00:45:02

################################################################################
                     [1m Learning iteration 325/1500 [0m                      

                       Computation: 44768 steps/s (collection: 2.080s, learning 0.116s)
             Mean action noise std: 2.04
          Mean value_function loss: 86.4389
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 65.9133
                       Mean reward: 202.39
               Mean episode length: 225.60
    Episode_Reward/reaching_object: 1.3292
    Episode_Reward/rotating_object: 38.6749
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 2.20s
                      Time elapsed: 00:12:28
                               ETA: 00:44:59

################################################################################
                     [1m Learning iteration 326/1500 [0m                      

                       Computation: 43446 steps/s (collection: 2.100s, learning 0.163s)
             Mean action noise std: 2.04
          Mean value_function loss: 84.8902
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 65.9393
                       Mean reward: 157.80
               Mean episode length: 215.62
    Episode_Reward/reaching_object: 1.2595
    Episode_Reward/rotating_object: 34.3016
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0472
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 2.26s
                      Time elapsed: 00:12:31
                               ETA: 00:44:57

################################################################################
                     [1m Learning iteration 327/1500 [0m                      

                       Computation: 43974 steps/s (collection: 2.130s, learning 0.105s)
             Mean action noise std: 2.04
          Mean value_function loss: 94.9390
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 65.9592
                       Mean reward: 224.68
               Mean episode length: 233.28
    Episode_Reward/reaching_object: 1.3056
    Episode_Reward/rotating_object: 35.5976
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 2.24s
                      Time elapsed: 00:12:33
                               ETA: 00:44:54

################################################################################
                     [1m Learning iteration 328/1500 [0m                      

                       Computation: 44469 steps/s (collection: 2.090s, learning 0.121s)
             Mean action noise std: 2.04
          Mean value_function loss: 106.2089
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 65.9775
                       Mean reward: 181.40
               Mean episode length: 205.57
    Episode_Reward/reaching_object: 1.2430
    Episode_Reward/rotating_object: 35.6379
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 2.21s
                      Time elapsed: 00:12:35
                               ETA: 00:44:51

################################################################################
                     [1m Learning iteration 329/1500 [0m                      

                       Computation: 43111 steps/s (collection: 2.160s, learning 0.120s)
             Mean action noise std: 2.04
          Mean value_function loss: 97.2295
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 65.9993
                       Mean reward: 221.48
               Mean episode length: 230.44
    Episode_Reward/reaching_object: 1.3158
    Episode_Reward/rotating_object: 40.4629
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 2.28s
                      Time elapsed: 00:12:37
                               ETA: 00:44:49

################################################################################
                     [1m Learning iteration 330/1500 [0m                      

                       Computation: 44144 steps/s (collection: 2.087s, learning 0.140s)
             Mean action noise std: 2.04
          Mean value_function loss: 96.2401
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 66.0150
                       Mean reward: 205.48
               Mean episode length: 230.61
    Episode_Reward/reaching_object: 1.3228
    Episode_Reward/rotating_object: 41.0078
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 2.23s
                      Time elapsed: 00:12:40
                               ETA: 00:44:47

################################################################################
                     [1m Learning iteration 331/1500 [0m                      

                       Computation: 43049 steps/s (collection: 2.179s, learning 0.105s)
             Mean action noise std: 2.04
          Mean value_function loss: 96.8923
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 66.0304
                       Mean reward: 172.87
               Mean episode length: 225.05
    Episode_Reward/reaching_object: 1.3153
    Episode_Reward/rotating_object: 37.1505
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 2.28s
                      Time elapsed: 00:12:42
                               ETA: 00:44:44

################################################################################
                     [1m Learning iteration 332/1500 [0m                      

                       Computation: 43865 steps/s (collection: 2.134s, learning 0.108s)
             Mean action noise std: 2.05
          Mean value_function loss: 96.0513
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 66.0464
                       Mean reward: 212.56
               Mean episode length: 216.55
    Episode_Reward/reaching_object: 1.2946
    Episode_Reward/rotating_object: 38.6112
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 2.24s
                      Time elapsed: 00:12:44
                               ETA: 00:44:42

################################################################################
                     [1m Learning iteration 333/1500 [0m                      

                       Computation: 18906 steps/s (collection: 5.080s, learning 0.119s)
             Mean action noise std: 2.05
          Mean value_function loss: 96.0312
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 66.0730
                       Mean reward: 198.01
               Mean episode length: 220.70
    Episode_Reward/reaching_object: 1.3336
    Episode_Reward/rotating_object: 41.2121
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 5.20s
                      Time elapsed: 00:12:49
                               ETA: 00:44:50

################################################################################
                     [1m Learning iteration 334/1500 [0m                      

                       Computation: 13998 steps/s (collection: 6.894s, learning 0.128s)
             Mean action noise std: 2.05
          Mean value_function loss: 97.6641
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 66.0972
                       Mean reward: 181.42
               Mean episode length: 221.04
    Episode_Reward/reaching_object: 1.3187
    Episode_Reward/rotating_object: 40.7652
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0494
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 7.02s
                      Time elapsed: 00:12:56
                               ETA: 00:45:04

################################################################################
                     [1m Learning iteration 335/1500 [0m                      

                       Computation: 14109 steps/s (collection: 6.845s, learning 0.123s)
             Mean action noise std: 2.05
          Mean value_function loss: 86.4848
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 66.1177
                       Mean reward: 175.68
               Mean episode length: 222.20
    Episode_Reward/reaching_object: 1.3313
    Episode_Reward/rotating_object: 39.1078
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 6.97s
                      Time elapsed: 00:13:03
                               ETA: 00:45:17

################################################################################
                     [1m Learning iteration 336/1500 [0m                      

                       Computation: 14113 steps/s (collection: 6.813s, learning 0.152s)
             Mean action noise std: 2.05
          Mean value_function loss: 77.8726
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 66.1371
                       Mean reward: 162.62
               Mean episode length: 213.04
    Episode_Reward/reaching_object: 1.2990
    Episode_Reward/rotating_object: 37.3989
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 6.97s
                      Time elapsed: 00:13:10
                               ETA: 00:45:31

################################################################################
                     [1m Learning iteration 337/1500 [0m                      

                       Computation: 14366 steps/s (collection: 6.720s, learning 0.123s)
             Mean action noise std: 2.05
          Mean value_function loss: 75.0566
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 66.1569
                       Mean reward: 231.37
               Mean episode length: 228.49
    Episode_Reward/reaching_object: 1.3547
    Episode_Reward/rotating_object: 41.1501
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 6.84s
                      Time elapsed: 00:13:17
                               ETA: 00:45:44

################################################################################
                     [1m Learning iteration 338/1500 [0m                      

                       Computation: 13993 steps/s (collection: 6.883s, learning 0.141s)
             Mean action noise std: 2.05
          Mean value_function loss: 87.3288
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 66.1778
                       Mean reward: 194.06
               Mean episode length: 227.34
    Episode_Reward/reaching_object: 1.3303
    Episode_Reward/rotating_object: 38.6997
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 7.02s
                      Time elapsed: 00:13:24
                               ETA: 00:45:58

################################################################################
                     [1m Learning iteration 339/1500 [0m                      

                       Computation: 14436 steps/s (collection: 6.637s, learning 0.172s)
             Mean action noise std: 2.06
          Mean value_function loss: 85.7635
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 66.2010
                       Mean reward: 197.86
               Mean episode length: 225.04
    Episode_Reward/reaching_object: 1.3365
    Episode_Reward/rotating_object: 39.0531
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 6.81s
                      Time elapsed: 00:13:31
                               ETA: 00:46:11

################################################################################
                     [1m Learning iteration 340/1500 [0m                      

                       Computation: 14243 steps/s (collection: 6.775s, learning 0.126s)
             Mean action noise std: 2.06
          Mean value_function loss: 82.0270
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 66.2200
                       Mean reward: 200.69
               Mean episode length: 222.92
    Episode_Reward/reaching_object: 1.3215
    Episode_Reward/rotating_object: 38.0706
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 6.90s
                      Time elapsed: 00:13:38
                               ETA: 00:46:24

################################################################################
                     [1m Learning iteration 341/1500 [0m                      

                       Computation: 12703 steps/s (collection: 7.642s, learning 0.097s)
             Mean action noise std: 2.06
          Mean value_function loss: 80.8677
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 66.2355
                       Mean reward: 193.13
               Mean episode length: 218.28
    Episode_Reward/reaching_object: 1.3174
    Episode_Reward/rotating_object: 37.5831
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 7.74s
                      Time elapsed: 00:13:46
                               ETA: 00:46:39

################################################################################
                     [1m Learning iteration 342/1500 [0m                      

                       Computation: 47093 steps/s (collection: 1.994s, learning 0.093s)
             Mean action noise std: 2.06
          Mean value_function loss: 83.5956
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 66.2575
                       Mean reward: 202.95
               Mean episode length: 221.98
    Episode_Reward/reaching_object: 1.3402
    Episode_Reward/rotating_object: 40.0021
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0502
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 2.09s
                      Time elapsed: 00:13:48
                               ETA: 00:46:36

################################################################################
                     [1m Learning iteration 343/1500 [0m                      

                       Computation: 45698 steps/s (collection: 2.046s, learning 0.106s)
             Mean action noise std: 2.06
          Mean value_function loss: 91.0040
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 66.2762
                       Mean reward: 197.43
               Mean episode length: 218.68
    Episode_Reward/reaching_object: 1.3019
    Episode_Reward/rotating_object: 35.3017
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 2.15s
                      Time elapsed: 00:13:50
                               ETA: 00:46:32

################################################################################
                     [1m Learning iteration 344/1500 [0m                      

                       Computation: 46485 steps/s (collection: 1.998s, learning 0.117s)
             Mean action noise std: 2.06
          Mean value_function loss: 92.1740
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 66.2937
                       Mean reward: 213.11
               Mean episode length: 224.26
    Episode_Reward/reaching_object: 1.2939
    Episode_Reward/rotating_object: 38.1918
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 2.11s
                      Time elapsed: 00:13:52
                               ETA: 00:46:29

################################################################################
                     [1m Learning iteration 345/1500 [0m                      

                       Computation: 47018 steps/s (collection: 1.987s, learning 0.104s)
             Mean action noise std: 2.06
          Mean value_function loss: 98.7278
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 66.3112
                       Mean reward: 193.68
               Mean episode length: 225.13
    Episode_Reward/reaching_object: 1.3237
    Episode_Reward/rotating_object: 39.8307
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 2.09s
                      Time elapsed: 00:13:54
                               ETA: 00:46:26

################################################################################
                     [1m Learning iteration 346/1500 [0m                      

                       Computation: 46247 steps/s (collection: 1.983s, learning 0.142s)
             Mean action noise std: 2.07
          Mean value_function loss: 93.3297
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 66.3295
                       Mean reward: 194.52
               Mean episode length: 217.10
    Episode_Reward/reaching_object: 1.3170
    Episode_Reward/rotating_object: 37.6256
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 2.13s
                      Time elapsed: 00:13:56
                               ETA: 00:46:22

################################################################################
                     [1m Learning iteration 347/1500 [0m                      

                       Computation: 45855 steps/s (collection: 2.039s, learning 0.105s)
             Mean action noise std: 2.07
          Mean value_function loss: 103.3859
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 66.3482
                       Mean reward: 260.92
               Mean episode length: 232.56
    Episode_Reward/reaching_object: 1.3437
    Episode_Reward/rotating_object: 42.2123
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 2.14s
                      Time elapsed: 00:13:58
                               ETA: 00:46:19

################################################################################
                     [1m Learning iteration 348/1500 [0m                      

                       Computation: 47875 steps/s (collection: 1.925s, learning 0.128s)
             Mean action noise std: 2.07
          Mean value_function loss: 99.0849
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 66.3719
                       Mean reward: 207.03
               Mean episode length: 219.60
    Episode_Reward/reaching_object: 1.2927
    Episode_Reward/rotating_object: 38.6685
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 2.05s
                      Time elapsed: 00:14:00
                               ETA: 00:46:15

################################################################################
                     [1m Learning iteration 349/1500 [0m                      

                       Computation: 47492 steps/s (collection: 1.955s, learning 0.115s)
             Mean action noise std: 2.07
          Mean value_function loss: 103.5168
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 66.3923
                       Mean reward: 220.37
               Mean episode length: 225.08
    Episode_Reward/reaching_object: 1.3481
    Episode_Reward/rotating_object: 40.2278
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 2.07s
                      Time elapsed: 00:14:03
                               ETA: 00:46:12

################################################################################
                     [1m Learning iteration 350/1500 [0m                      

                       Computation: 47182 steps/s (collection: 1.984s, learning 0.099s)
             Mean action noise std: 2.07
          Mean value_function loss: 98.4547
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 66.4093
                       Mean reward: 242.40
               Mean episode length: 229.20
    Episode_Reward/reaching_object: 1.3446
    Episode_Reward/rotating_object: 41.4700
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 2.08s
                      Time elapsed: 00:14:05
                               ETA: 00:46:08

################################################################################
                     [1m Learning iteration 351/1500 [0m                      

                       Computation: 45825 steps/s (collection: 2.050s, learning 0.096s)
             Mean action noise std: 2.07
          Mean value_function loss: 87.7819
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 66.4211
                       Mean reward: 219.90
               Mean episode length: 222.18
    Episode_Reward/reaching_object: 1.3527
    Episode_Reward/rotating_object: 44.6397
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 2.15s
                      Time elapsed: 00:14:07
                               ETA: 00:46:05

################################################################################
                     [1m Learning iteration 352/1500 [0m                      

                       Computation: 47908 steps/s (collection: 1.952s, learning 0.100s)
             Mean action noise std: 2.07
          Mean value_function loss: 85.6483
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 66.4320
                       Mean reward: 183.84
               Mean episode length: 226.02
    Episode_Reward/reaching_object: 1.3513
    Episode_Reward/rotating_object: 43.2578
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 2.05s
                      Time elapsed: 00:14:09
                               ETA: 00:46:01

################################################################################
                     [1m Learning iteration 353/1500 [0m                      

                       Computation: 48371 steps/s (collection: 1.939s, learning 0.093s)
             Mean action noise std: 2.07
          Mean value_function loss: 89.9493
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 66.4469
                       Mean reward: 178.96
               Mean episode length: 208.08
    Episode_Reward/reaching_object: 1.3170
    Episode_Reward/rotating_object: 39.0102
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 2.03s
                      Time elapsed: 00:14:11
                               ETA: 00:45:58

################################################################################
                     [1m Learning iteration 354/1500 [0m                      

                       Computation: 46228 steps/s (collection: 2.029s, learning 0.097s)
             Mean action noise std: 2.07
          Mean value_function loss: 93.2445
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 66.4572
                       Mean reward: 243.79
               Mean episode length: 228.45
    Episode_Reward/reaching_object: 1.3541
    Episode_Reward/rotating_object: 45.0013
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 2.13s
                      Time elapsed: 00:14:13
                               ETA: 00:45:55

################################################################################
                     [1m Learning iteration 355/1500 [0m                      

                       Computation: 46124 steps/s (collection: 2.009s, learning 0.123s)
             Mean action noise std: 2.08
          Mean value_function loss: 92.3619
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 66.4726
                       Mean reward: 226.73
               Mean episode length: 227.76
    Episode_Reward/reaching_object: 1.3511
    Episode_Reward/rotating_object: 45.6770
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 2.13s
                      Time elapsed: 00:14:15
                               ETA: 00:45:51

################################################################################
                     [1m Learning iteration 356/1500 [0m                      

                       Computation: 45775 steps/s (collection: 2.057s, learning 0.091s)
             Mean action noise std: 2.08
          Mean value_function loss: 83.2919
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 66.4924
                       Mean reward: 188.96
               Mean episode length: 215.11
    Episode_Reward/reaching_object: 1.3212
    Episode_Reward/rotating_object: 39.9602
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 2.15s
                      Time elapsed: 00:14:17
                               ETA: 00:45:48

################################################################################
                     [1m Learning iteration 357/1500 [0m                      

                       Computation: 47350 steps/s (collection: 1.967s, learning 0.109s)
             Mean action noise std: 2.08
          Mean value_function loss: 80.8527
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 66.5090
                       Mean reward: 235.46
               Mean episode length: 224.93
    Episode_Reward/reaching_object: 1.3593
    Episode_Reward/rotating_object: 44.4737
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 2.08s
                      Time elapsed: 00:14:19
                               ETA: 00:45:45

################################################################################
                     [1m Learning iteration 358/1500 [0m                      

                       Computation: 46214 steps/s (collection: 2.008s, learning 0.120s)
             Mean action noise std: 2.08
          Mean value_function loss: 74.5671
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 66.5260
                       Mean reward: 222.18
               Mean episode length: 226.34
    Episode_Reward/reaching_object: 1.3586
    Episode_Reward/rotating_object: 43.1387
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 2.13s
                      Time elapsed: 00:14:21
                               ETA: 00:45:41

################################################################################
                     [1m Learning iteration 359/1500 [0m                      

                       Computation: 46641 steps/s (collection: 1.983s, learning 0.125s)
             Mean action noise std: 2.08
          Mean value_function loss: 83.1745
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 66.5416
                       Mean reward: 229.85
               Mean episode length: 224.61
    Episode_Reward/reaching_object: 1.3503
    Episode_Reward/rotating_object: 44.0304
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 2.11s
                      Time elapsed: 00:14:24
                               ETA: 00:45:38

################################################################################
                     [1m Learning iteration 360/1500 [0m                      

                       Computation: 40448 steps/s (collection: 2.302s, learning 0.128s)
             Mean action noise std: 2.08
          Mean value_function loss: 84.8480
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 66.5601
                       Mean reward: 203.28
               Mean episode length: 219.58
    Episode_Reward/reaching_object: 1.3374
    Episode_Reward/rotating_object: 43.6427
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 2.43s
                      Time elapsed: 00:14:26
                               ETA: 00:45:36

################################################################################
                     [1m Learning iteration 361/1500 [0m                      

                       Computation: 44274 steps/s (collection: 2.031s, learning 0.189s)
             Mean action noise std: 2.08
          Mean value_function loss: 86.6038
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 66.5762
                       Mean reward: 229.46
               Mean episode length: 229.98
    Episode_Reward/reaching_object: 1.3707
    Episode_Reward/rotating_object: 46.7721
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 2.22s
                      Time elapsed: 00:14:28
                               ETA: 00:45:33

################################################################################
                     [1m Learning iteration 362/1500 [0m                      

                       Computation: 45815 steps/s (collection: 2.008s, learning 0.138s)
             Mean action noise std: 2.08
          Mean value_function loss: 90.8845
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 66.5956
                       Mean reward: 243.25
               Mean episode length: 227.13
    Episode_Reward/reaching_object: 1.3309
    Episode_Reward/rotating_object: 43.6872
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 2.15s
                      Time elapsed: 00:14:30
                               ETA: 00:45:30

################################################################################
                     [1m Learning iteration 363/1500 [0m                      

                       Computation: 46135 steps/s (collection: 2.019s, learning 0.112s)
             Mean action noise std: 2.09
          Mean value_function loss: 97.4036
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 66.6152
                       Mean reward: 204.08
               Mean episode length: 230.87
    Episode_Reward/reaching_object: 1.3365
    Episode_Reward/rotating_object: 43.2164
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 2.13s
                      Time elapsed: 00:14:32
                               ETA: 00:45:26

################################################################################
                     [1m Learning iteration 364/1500 [0m                      

                       Computation: 45211 steps/s (collection: 2.036s, learning 0.138s)
             Mean action noise std: 2.09
          Mean value_function loss: 104.5251
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 66.6316
                       Mean reward: 250.09
               Mean episode length: 228.38
    Episode_Reward/reaching_object: 1.3243
    Episode_Reward/rotating_object: 43.5847
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 2.17s
                      Time elapsed: 00:14:35
                               ETA: 00:45:23

################################################################################
                     [1m Learning iteration 365/1500 [0m                      

                       Computation: 46328 steps/s (collection: 2.022s, learning 0.099s)
             Mean action noise std: 2.09
          Mean value_function loss: 103.6212
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 66.6488
                       Mean reward: 217.97
               Mean episode length: 229.25
    Episode_Reward/reaching_object: 1.3194
    Episode_Reward/rotating_object: 38.3617
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 2.12s
                      Time elapsed: 00:14:37
                               ETA: 00:45:20

################################################################################
                     [1m Learning iteration 366/1500 [0m                      

                       Computation: 46329 steps/s (collection: 1.999s, learning 0.123s)
             Mean action noise std: 2.09
          Mean value_function loss: 100.5771
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 66.6672
                       Mean reward: 215.90
               Mean episode length: 222.53
    Episode_Reward/reaching_object: 1.3212
    Episode_Reward/rotating_object: 43.0289
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0466
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 2.12s
                      Time elapsed: 00:14:39
                               ETA: 00:45:17

################################################################################
                     [1m Learning iteration 367/1500 [0m                      

                       Computation: 46720 steps/s (collection: 2.007s, learning 0.097s)
             Mean action noise std: 2.09
          Mean value_function loss: 94.8804
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 66.6797
                       Mean reward: 220.78
               Mean episode length: 222.32
    Episode_Reward/reaching_object: 1.3347
    Episode_Reward/rotating_object: 41.3697
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 2.10s
                      Time elapsed: 00:14:41
                               ETA: 00:45:13

################################################################################
                     [1m Learning iteration 368/1500 [0m                      

                       Computation: 46419 steps/s (collection: 2.002s, learning 0.116s)
             Mean action noise std: 2.09
          Mean value_function loss: 101.8040
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 66.6954
                       Mean reward: 270.56
               Mean episode length: 223.98
    Episode_Reward/reaching_object: 1.3625
    Episode_Reward/rotating_object: 48.3531
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 2.12s
                      Time elapsed: 00:14:43
                               ETA: 00:45:10

################################################################################
                     [1m Learning iteration 369/1500 [0m                      

                       Computation: 46641 steps/s (collection: 2.007s, learning 0.100s)
             Mean action noise std: 2.09
          Mean value_function loss: 105.5654
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 66.7151
                       Mean reward: 288.05
               Mean episode length: 235.20
    Episode_Reward/reaching_object: 1.3696
    Episode_Reward/rotating_object: 46.2849
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 2.11s
                      Time elapsed: 00:14:45
                               ETA: 00:45:07

################################################################################
                     [1m Learning iteration 370/1500 [0m                      

                       Computation: 46393 steps/s (collection: 1.977s, learning 0.142s)
             Mean action noise std: 2.09
          Mean value_function loss: 108.4551
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 66.7380
                       Mean reward: 264.02
               Mean episode length: 226.43
    Episode_Reward/reaching_object: 1.3721
    Episode_Reward/rotating_object: 46.9016
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 2.12s
                      Time elapsed: 00:14:47
                               ETA: 00:45:04

################################################################################
                     [1m Learning iteration 371/1500 [0m                      

                       Computation: 46386 steps/s (collection: 2.004s, learning 0.116s)
             Mean action noise std: 2.10
          Mean value_function loss: 108.9775
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 66.7591
                       Mean reward: 233.25
               Mean episode length: 224.02
    Episode_Reward/reaching_object: 1.3265
    Episode_Reward/rotating_object: 41.8029
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 2.12s
                      Time elapsed: 00:14:49
                               ETA: 00:45:00

################################################################################
                     [1m Learning iteration 372/1500 [0m                      

                       Computation: 46337 steps/s (collection: 1.975s, learning 0.147s)
             Mean action noise std: 2.10
          Mean value_function loss: 81.9327
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 66.7796
                       Mean reward: 239.23
               Mean episode length: 233.05
    Episode_Reward/reaching_object: 1.3692
    Episode_Reward/rotating_object: 43.4560
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 2.12s
                      Time elapsed: 00:14:52
                               ETA: 00:44:57

################################################################################
                     [1m Learning iteration 373/1500 [0m                      

                       Computation: 47269 steps/s (collection: 1.989s, learning 0.091s)
             Mean action noise std: 2.10
          Mean value_function loss: 86.5415
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 66.7890
                       Mean reward: 230.66
               Mean episode length: 219.41
    Episode_Reward/reaching_object: 1.3851
    Episode_Reward/rotating_object: 45.8091
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 2.08s
                      Time elapsed: 00:14:54
                               ETA: 00:44:54

################################################################################
                     [1m Learning iteration 374/1500 [0m                      

                       Computation: 47079 steps/s (collection: 1.977s, learning 0.111s)
             Mean action noise std: 2.10
          Mean value_function loss: 109.5366
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 66.7993
                       Mean reward: 224.90
               Mean episode length: 216.95
    Episode_Reward/reaching_object: 1.3445
    Episode_Reward/rotating_object: 45.5733
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 2.09s
                      Time elapsed: 00:14:56
                               ETA: 00:44:51

################################################################################
                     [1m Learning iteration 375/1500 [0m                      

                       Computation: 45971 steps/s (collection: 2.027s, learning 0.111s)
             Mean action noise std: 2.10
          Mean value_function loss: 105.0385
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 66.8172
                       Mean reward: 257.04
               Mean episode length: 223.66
    Episode_Reward/reaching_object: 1.3526
    Episode_Reward/rotating_object: 47.3040
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 2.14s
                      Time elapsed: 00:14:58
                               ETA: 00:44:47

################################################################################
                     [1m Learning iteration 376/1500 [0m                      

                       Computation: 46972 steps/s (collection: 1.984s, learning 0.108s)
             Mean action noise std: 2.10
          Mean value_function loss: 106.6816
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 66.8344
                       Mean reward: 245.37
               Mean episode length: 232.83
    Episode_Reward/reaching_object: 1.3575
    Episode_Reward/rotating_object: 47.2002
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 2.09s
                      Time elapsed: 00:15:00
                               ETA: 00:44:44

################################################################################
                     [1m Learning iteration 377/1500 [0m                      

                       Computation: 46753 steps/s (collection: 2.010s, learning 0.093s)
             Mean action noise std: 2.10
          Mean value_function loss: 109.7674
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 66.8490
                       Mean reward: 276.43
               Mean episode length: 224.27
    Episode_Reward/reaching_object: 1.3571
    Episode_Reward/rotating_object: 51.4641
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 2.10s
                      Time elapsed: 00:15:02
                               ETA: 00:44:41

################################################################################
                     [1m Learning iteration 378/1500 [0m                      

                       Computation: 45516 steps/s (collection: 2.051s, learning 0.109s)
             Mean action noise std: 2.10
          Mean value_function loss: 108.0519
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 66.8649
                       Mean reward: 257.16
               Mean episode length: 219.66
    Episode_Reward/reaching_object: 1.3671
    Episode_Reward/rotating_object: 51.9559
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 2.16s
                      Time elapsed: 00:15:04
                               ETA: 00:44:38

################################################################################
                     [1m Learning iteration 379/1500 [0m                      

                       Computation: 45987 steps/s (collection: 2.026s, learning 0.112s)
             Mean action noise std: 2.10
          Mean value_function loss: 94.5734
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 66.8823
                       Mean reward: 273.67
               Mean episode length: 228.65
    Episode_Reward/reaching_object: 1.3759
    Episode_Reward/rotating_object: 50.3805
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 2.14s
                      Time elapsed: 00:15:06
                               ETA: 00:44:35

################################################################################
                     [1m Learning iteration 380/1500 [0m                      

                       Computation: 45919 steps/s (collection: 1.975s, learning 0.166s)
             Mean action noise std: 2.11
          Mean value_function loss: 87.3259
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 66.8986
                       Mean reward: 215.45
               Mean episode length: 211.70
    Episode_Reward/reaching_object: 1.3601
    Episode_Reward/rotating_object: 49.8055
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 2.14s
                      Time elapsed: 00:15:09
                               ETA: 00:44:32

################################################################################
                     [1m Learning iteration 381/1500 [0m                      

                       Computation: 45211 steps/s (collection: 2.019s, learning 0.156s)
             Mean action noise std: 2.11
          Mean value_function loss: 87.5426
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 66.9142
                       Mean reward: 227.35
               Mean episode length: 210.13
    Episode_Reward/reaching_object: 1.3513
    Episode_Reward/rotating_object: 48.4597
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 2.17s
                      Time elapsed: 00:15:11
                               ETA: 00:44:29

################################################################################
                     [1m Learning iteration 382/1500 [0m                      

                       Computation: 46125 steps/s (collection: 2.035s, learning 0.096s)
             Mean action noise std: 2.11
          Mean value_function loss: 90.5509
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 66.9281
                       Mean reward: 253.54
               Mean episode length: 230.55
    Episode_Reward/reaching_object: 1.3783
    Episode_Reward/rotating_object: 49.7011
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0494
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 2.13s
                      Time elapsed: 00:15:13
                               ETA: 00:44:26

################################################################################
                     [1m Learning iteration 383/1500 [0m                      

                       Computation: 46129 steps/s (collection: 2.038s, learning 0.093s)
             Mean action noise std: 2.11
          Mean value_function loss: 79.5923
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 66.9417
                       Mean reward: 236.39
               Mean episode length: 227.83
    Episode_Reward/reaching_object: 1.3492
    Episode_Reward/rotating_object: 48.7561
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 2.13s
                      Time elapsed: 00:15:15
                               ETA: 00:44:22

################################################################################
                     [1m Learning iteration 384/1500 [0m                      

                       Computation: 42192 steps/s (collection: 2.191s, learning 0.139s)
             Mean action noise std: 2.11
          Mean value_function loss: 80.8299
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 66.9596
                       Mean reward: 238.43
               Mean episode length: 212.19
    Episode_Reward/reaching_object: 1.3727
    Episode_Reward/rotating_object: 50.2152
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 2.33s
                      Time elapsed: 00:15:17
                               ETA: 00:44:20

################################################################################
                     [1m Learning iteration 385/1500 [0m                      

                       Computation: 46689 steps/s (collection: 2.011s, learning 0.094s)
             Mean action noise std: 2.11
          Mean value_function loss: 93.0637
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 66.9800
                       Mean reward: 295.49
               Mean episode length: 225.17
    Episode_Reward/reaching_object: 1.3937
    Episode_Reward/rotating_object: 55.4510
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0503
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 2.11s
                      Time elapsed: 00:15:19
                               ETA: 00:44:17

################################################################################
                     [1m Learning iteration 386/1500 [0m                      

                       Computation: 42347 steps/s (collection: 2.161s, learning 0.160s)
             Mean action noise std: 2.11
          Mean value_function loss: 109.1176
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 66.9954
                       Mean reward: 243.84
               Mean episode length: 214.89
    Episode_Reward/reaching_object: 1.3710
    Episode_Reward/rotating_object: 53.2608
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 2.32s
                      Time elapsed: 00:15:22
                               ETA: 00:44:14

################################################################################
                     [1m Learning iteration 387/1500 [0m                      

                       Computation: 46343 steps/s (collection: 1.983s, learning 0.138s)
             Mean action noise std: 2.11
          Mean value_function loss: 101.1161
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 67.0099
                       Mean reward: 277.44
               Mean episode length: 229.44
    Episode_Reward/reaching_object: 1.3786
    Episode_Reward/rotating_object: 48.8254
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 2.12s
                      Time elapsed: 00:15:24
                               ETA: 00:44:11

################################################################################
                     [1m Learning iteration 388/1500 [0m                      

                       Computation: 45384 steps/s (collection: 2.051s, learning 0.115s)
             Mean action noise std: 2.11
          Mean value_function loss: 98.4534
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 67.0240
                       Mean reward: 240.40
               Mean episode length: 223.32
    Episode_Reward/reaching_object: 1.3569
    Episode_Reward/rotating_object: 49.2032
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 2.17s
                      Time elapsed: 00:15:26
                               ETA: 00:44:08

################################################################################
                     [1m Learning iteration 389/1500 [0m                      

                       Computation: 45835 steps/s (collection: 2.040s, learning 0.105s)
             Mean action noise std: 2.12
          Mean value_function loss: 105.6704
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 67.0409
                       Mean reward: 225.79
               Mean episode length: 216.90
    Episode_Reward/reaching_object: 1.3824
    Episode_Reward/rotating_object: 49.7539
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 2.14s
                      Time elapsed: 00:15:28
                               ETA: 00:44:05

################################################################################
                     [1m Learning iteration 390/1500 [0m                      

                       Computation: 43853 steps/s (collection: 2.069s, learning 0.172s)
             Mean action noise std: 2.12
          Mean value_function loss: 112.7292
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 67.0605
                       Mean reward: 290.35
               Mean episode length: 223.16
    Episode_Reward/reaching_object: 1.3687
    Episode_Reward/rotating_object: 56.8323
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 2.24s
                      Time elapsed: 00:15:30
                               ETA: 00:44:02

################################################################################
                     [1m Learning iteration 391/1500 [0m                      

                       Computation: 45238 steps/s (collection: 2.025s, learning 0.148s)
             Mean action noise std: 2.12
          Mean value_function loss: 119.7956
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 67.0740
                       Mean reward: 309.31
               Mean episode length: 230.23
    Episode_Reward/reaching_object: 1.3779
    Episode_Reward/rotating_object: 57.7695
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 2.17s
                      Time elapsed: 00:15:33
                               ETA: 00:43:59

################################################################################
                     [1m Learning iteration 392/1500 [0m                      

                       Computation: 46183 steps/s (collection: 2.014s, learning 0.114s)
             Mean action noise std: 2.12
          Mean value_function loss: 116.8661
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 67.0882
                       Mean reward: 301.82
               Mean episode length: 230.64
    Episode_Reward/reaching_object: 1.3739
    Episode_Reward/rotating_object: 53.8164
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0494
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 2.13s
                      Time elapsed: 00:15:35
                               ETA: 00:43:56

################################################################################
                     [1m Learning iteration 393/1500 [0m                      

                       Computation: 46011 steps/s (collection: 1.989s, learning 0.147s)
             Mean action noise std: 2.12
          Mean value_function loss: 130.8714
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 67.1102
                       Mean reward: 278.69
               Mean episode length: 218.86
    Episode_Reward/reaching_object: 1.3490
    Episode_Reward/rotating_object: 55.3612
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 2.14s
                      Time elapsed: 00:15:37
                               ETA: 00:43:53

################################################################################
                     [1m Learning iteration 394/1500 [0m                      

                       Computation: 47332 steps/s (collection: 1.987s, learning 0.090s)
             Mean action noise std: 2.12
          Mean value_function loss: 130.4710
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 67.1280
                       Mean reward: 264.37
               Mean episode length: 221.29
    Episode_Reward/reaching_object: 1.3784
    Episode_Reward/rotating_object: 55.3271
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0495
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 2.08s
                      Time elapsed: 00:15:39
                               ETA: 00:43:50

################################################################################
                     [1m Learning iteration 395/1500 [0m                      

                       Computation: 46698 steps/s (collection: 2.011s, learning 0.094s)
             Mean action noise std: 2.12
          Mean value_function loss: 129.3401
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 67.1407
                       Mean reward: 255.11
               Mean episode length: 221.79
    Episode_Reward/reaching_object: 1.3823
    Episode_Reward/rotating_object: 54.3894
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0495
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 2.11s
                      Time elapsed: 00:15:41
                               ETA: 00:43:47

################################################################################
                     [1m Learning iteration 396/1500 [0m                      

                       Computation: 47048 steps/s (collection: 2.000s, learning 0.089s)
             Mean action noise std: 2.12
          Mean value_function loss: 138.6038
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 67.1531
                       Mean reward: 304.49
               Mean episode length: 223.18
    Episode_Reward/reaching_object: 1.3937
    Episode_Reward/rotating_object: 57.4161
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 2.09s
                      Time elapsed: 00:15:43
                               ETA: 00:43:43

################################################################################
                     [1m Learning iteration 397/1500 [0m                      

                       Computation: 46366 steps/s (collection: 2.020s, learning 0.101s)
             Mean action noise std: 2.12
          Mean value_function loss: 146.2325
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 67.1624
                       Mean reward: 334.97
               Mean episode length: 226.02
    Episode_Reward/reaching_object: 1.3783
    Episode_Reward/rotating_object: 56.8845
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 2.12s
                      Time elapsed: 00:15:45
                               ETA: 00:43:40

################################################################################
                     [1m Learning iteration 398/1500 [0m                      

                       Computation: 46552 steps/s (collection: 2.006s, learning 0.106s)
             Mean action noise std: 2.12
          Mean value_function loss: 138.9739
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 67.1717
                       Mean reward: 287.23
               Mean episode length: 221.27
    Episode_Reward/reaching_object: 1.3887
    Episode_Reward/rotating_object: 56.6094
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 2.11s
                      Time elapsed: 00:15:47
                               ETA: 00:43:37

################################################################################
                     [1m Learning iteration 399/1500 [0m                      

                       Computation: 44929 steps/s (collection: 2.030s, learning 0.158s)
             Mean action noise std: 2.13
          Mean value_function loss: 123.8283
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 67.1831
                       Mean reward: 290.91
               Mean episode length: 222.68
    Episode_Reward/reaching_object: 1.3964
    Episode_Reward/rotating_object: 57.9965
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 2.19s
                      Time elapsed: 00:15:50
                               ETA: 00:43:34

################################################################################
                     [1m Learning iteration 400/1500 [0m                      

                       Computation: 45574 steps/s (collection: 2.061s, learning 0.096s)
             Mean action noise std: 2.13
          Mean value_function loss: 122.5815
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 67.1993
                       Mean reward: 324.32
               Mean episode length: 224.20
    Episode_Reward/reaching_object: 1.3947
    Episode_Reward/rotating_object: 57.4178
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 2.16s
                      Time elapsed: 00:15:52
                               ETA: 00:43:31

################################################################################
                     [1m Learning iteration 401/1500 [0m                      

                       Computation: 46185 steps/s (collection: 2.023s, learning 0.105s)
             Mean action noise std: 2.13
          Mean value_function loss: 111.4769
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 67.2126
                       Mean reward: 276.10
               Mean episode length: 229.27
    Episode_Reward/reaching_object: 1.4193
    Episode_Reward/rotating_object: 55.9599
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 2.13s
                      Time elapsed: 00:15:54
                               ETA: 00:43:28

################################################################################
                     [1m Learning iteration 402/1500 [0m                      

                       Computation: 45163 steps/s (collection: 2.081s, learning 0.096s)
             Mean action noise std: 2.13
          Mean value_function loss: 108.2229
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 67.2309
                       Mean reward: 311.49
               Mean episode length: 224.69
    Episode_Reward/reaching_object: 1.4256
    Episode_Reward/rotating_object: 61.6781
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 2.18s
                      Time elapsed: 00:15:56
                               ETA: 00:43:25

################################################################################
                     [1m Learning iteration 403/1500 [0m                      

                       Computation: 45999 steps/s (collection: 2.032s, learning 0.105s)
             Mean action noise std: 2.13
          Mean value_function loss: 123.1016
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 67.2479
                       Mean reward: 303.26
               Mean episode length: 226.31
    Episode_Reward/reaching_object: 1.3837
    Episode_Reward/rotating_object: 53.8000
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 2.14s
                      Time elapsed: 00:15:58
                               ETA: 00:43:22

################################################################################
                     [1m Learning iteration 404/1500 [0m                      

                       Computation: 47685 steps/s (collection: 1.969s, learning 0.093s)
             Mean action noise std: 2.13
          Mean value_function loss: 112.3031
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 67.2588
                       Mean reward: 286.21
               Mean episode length: 218.05
    Episode_Reward/reaching_object: 1.3960
    Episode_Reward/rotating_object: 58.9559
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 2.06s
                      Time elapsed: 00:16:00
                               ETA: 00:43:19

################################################################################
                     [1m Learning iteration 405/1500 [0m                      

                       Computation: 47710 steps/s (collection: 1.961s, learning 0.100s)
             Mean action noise std: 2.13
          Mean value_function loss: 105.3512
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 67.2731
                       Mean reward: 354.45
               Mean episode length: 240.31
    Episode_Reward/reaching_object: 1.4579
    Episode_Reward/rotating_object: 64.9402
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 2.06s
                      Time elapsed: 00:16:02
                               ETA: 00:43:16

################################################################################
                     [1m Learning iteration 406/1500 [0m                      

                       Computation: 46217 steps/s (collection: 2.031s, learning 0.096s)
             Mean action noise std: 2.13
          Mean value_function loss: 97.7311
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 67.2883
                       Mean reward: 329.58
               Mean episode length: 227.03
    Episode_Reward/reaching_object: 1.4194
    Episode_Reward/rotating_object: 62.5088
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 2.13s
                      Time elapsed: 00:16:04
                               ETA: 00:43:13

################################################################################
                     [1m Learning iteration 407/1500 [0m                      

                       Computation: 45777 steps/s (collection: 2.032s, learning 0.115s)
             Mean action noise std: 2.13
          Mean value_function loss: 94.9540
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 67.2954
                       Mean reward: 321.91
               Mean episode length: 233.75
    Episode_Reward/reaching_object: 1.4155
    Episode_Reward/rotating_object: 62.2088
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 2.15s
                      Time elapsed: 00:16:06
                               ETA: 00:43:10

################################################################################
                     [1m Learning iteration 408/1500 [0m                      

                       Computation: 45757 steps/s (collection: 2.036s, learning 0.112s)
             Mean action noise std: 2.13
          Mean value_function loss: 103.6011
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 67.3074
                       Mean reward: 348.20
               Mean episode length: 236.83
    Episode_Reward/reaching_object: 1.4198
    Episode_Reward/rotating_object: 60.3318
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 2.15s
                      Time elapsed: 00:16:09
                               ETA: 00:43:07

################################################################################
                     [1m Learning iteration 409/1500 [0m                      

                       Computation: 46342 steps/s (collection: 2.004s, learning 0.118s)
             Mean action noise std: 2.14
          Mean value_function loss: 113.8153
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 67.3202
                       Mean reward: 308.71
               Mean episode length: 230.39
    Episode_Reward/reaching_object: 1.4586
    Episode_Reward/rotating_object: 63.2587
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0498
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 2.12s
                      Time elapsed: 00:16:11
                               ETA: 00:43:04

################################################################################
                     [1m Learning iteration 410/1500 [0m                      

                       Computation: 46347 steps/s (collection: 2.019s, learning 0.102s)
             Mean action noise std: 2.14
          Mean value_function loss: 128.9612
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 67.3294
                       Mean reward: 323.95
               Mean episode length: 225.58
    Episode_Reward/reaching_object: 1.4268
    Episode_Reward/rotating_object: 61.5898
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 2.12s
                      Time elapsed: 00:16:13
                               ETA: 00:43:01

################################################################################
                     [1m Learning iteration 411/1500 [0m                      

                       Computation: 46139 steps/s (collection: 1.997s, learning 0.134s)
             Mean action noise std: 2.14
          Mean value_function loss: 122.8077
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 67.3401
                       Mean reward: 333.97
               Mean episode length: 238.49
    Episode_Reward/reaching_object: 1.4624
    Episode_Reward/rotating_object: 63.8772
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0507
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 2.13s
                      Time elapsed: 00:16:15
                               ETA: 00:42:58

################################################################################
                     [1m Learning iteration 412/1500 [0m                      

                       Computation: 44913 steps/s (collection: 2.078s, learning 0.111s)
             Mean action noise std: 2.14
          Mean value_function loss: 116.3466
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 67.3528
                       Mean reward: 317.13
               Mean episode length: 223.25
    Episode_Reward/reaching_object: 1.4026
    Episode_Reward/rotating_object: 63.3344
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 2.19s
                      Time elapsed: 00:16:17
                               ETA: 00:42:55

################################################################################
                     [1m Learning iteration 413/1500 [0m                      

                       Computation: 46489 steps/s (collection: 2.005s, learning 0.110s)
             Mean action noise std: 2.14
          Mean value_function loss: 107.2127
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 67.3675
                       Mean reward: 334.36
               Mean episode length: 242.61
    Episode_Reward/reaching_object: 1.4367
    Episode_Reward/rotating_object: 61.3341
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0500
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 2.11s
                      Time elapsed: 00:16:19
                               ETA: 00:42:52

################################################################################
                     [1m Learning iteration 414/1500 [0m                      

                       Computation: 46479 steps/s (collection: 2.016s, learning 0.099s)
             Mean action noise std: 2.14
          Mean value_function loss: 110.9593
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 67.3852
                       Mean reward: 328.32
               Mean episode length: 229.26
    Episode_Reward/reaching_object: 1.4137
    Episode_Reward/rotating_object: 66.9677
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 2.11s
                      Time elapsed: 00:16:21
                               ETA: 00:42:49

################################################################################
                     [1m Learning iteration 415/1500 [0m                      

                       Computation: 46686 steps/s (collection: 2.017s, learning 0.089s)
             Mean action noise std: 2.14
          Mean value_function loss: 115.3578
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 67.4049
                       Mean reward: 374.09
               Mean episode length: 237.70
    Episode_Reward/reaching_object: 1.4541
    Episode_Reward/rotating_object: 68.0679
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 2.11s
                      Time elapsed: 00:16:24
                               ETA: 00:42:46

################################################################################
                     [1m Learning iteration 416/1500 [0m                      

                       Computation: 45130 steps/s (collection: 2.027s, learning 0.151s)
             Mean action noise std: 2.14
          Mean value_function loss: 116.2254
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 67.4212
                       Mean reward: 310.31
               Mean episode length: 228.22
    Episode_Reward/reaching_object: 1.4047
    Episode_Reward/rotating_object: 64.3411
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 2.18s
                      Time elapsed: 00:16:26
                               ETA: 00:42:43

################################################################################
                     [1m Learning iteration 417/1500 [0m                      

                       Computation: 45390 steps/s (collection: 2.055s, learning 0.111s)
             Mean action noise std: 2.14
          Mean value_function loss: 120.7435
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 67.4381
                       Mean reward: 321.69
               Mean episode length: 215.14
    Episode_Reward/reaching_object: 1.4135
    Episode_Reward/rotating_object: 63.1509
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 2.17s
                      Time elapsed: 00:16:28
                               ETA: 00:42:40

################################################################################
                     [1m Learning iteration 418/1500 [0m                      

                       Computation: 43974 steps/s (collection: 2.058s, learning 0.178s)
             Mean action noise std: 2.14
          Mean value_function loss: 128.0168
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 67.4483
                       Mean reward: 313.91
               Mean episode length: 216.86
    Episode_Reward/reaching_object: 1.3988
    Episode_Reward/rotating_object: 64.5500
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 2.24s
                      Time elapsed: 00:16:30
                               ETA: 00:42:38

################################################################################
                     [1m Learning iteration 419/1500 [0m                      

                       Computation: 43979 steps/s (collection: 2.121s, learning 0.114s)
             Mean action noise std: 2.15
          Mean value_function loss: 116.4583
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 67.4546
                       Mean reward: 309.07
               Mean episode length: 226.31
    Episode_Reward/reaching_object: 1.4334
    Episode_Reward/rotating_object: 64.3019
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 2.24s
                      Time elapsed: 00:16:32
                               ETA: 00:42:35

################################################################################
                     [1m Learning iteration 420/1500 [0m                      

                       Computation: 46066 steps/s (collection: 2.040s, learning 0.094s)
             Mean action noise std: 2.15
          Mean value_function loss: 123.0393
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 67.4641
                       Mean reward: 320.33
               Mean episode length: 224.09
    Episode_Reward/reaching_object: 1.4126
    Episode_Reward/rotating_object: 65.2625
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 2.13s
                      Time elapsed: 00:16:34
                               ETA: 00:42:32

################################################################################
                     [1m Learning iteration 421/1500 [0m                      

                       Computation: 44577 steps/s (collection: 2.113s, learning 0.092s)
             Mean action noise std: 2.15
          Mean value_function loss: 125.3122
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 67.4771
                       Mean reward: 334.39
               Mean episode length: 212.64
    Episode_Reward/reaching_object: 1.3935
    Episode_Reward/rotating_object: 61.3052
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 2.21s
                      Time elapsed: 00:16:37
                               ETA: 00:42:29

################################################################################
                     [1m Learning iteration 422/1500 [0m                      

                       Computation: 44720 steps/s (collection: 2.090s, learning 0.109s)
             Mean action noise std: 2.15
          Mean value_function loss: 119.9583
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 67.4937
                       Mean reward: 359.29
               Mean episode length: 224.19
    Episode_Reward/reaching_object: 1.4227
    Episode_Reward/rotating_object: 65.8713
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 2.20s
                      Time elapsed: 00:16:39
                               ETA: 00:42:26

################################################################################
                     [1m Learning iteration 423/1500 [0m                      

                       Computation: 44485 steps/s (collection: 2.111s, learning 0.099s)
             Mean action noise std: 2.15
          Mean value_function loss: 131.4806
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 67.5090
                       Mean reward: 327.22
               Mean episode length: 225.74
    Episode_Reward/reaching_object: 1.4234
    Episode_Reward/rotating_object: 64.9252
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 2.21s
                      Time elapsed: 00:16:41
                               ETA: 00:42:24

################################################################################
                     [1m Learning iteration 424/1500 [0m                      

                       Computation: 44979 steps/s (collection: 2.095s, learning 0.090s)
             Mean action noise std: 2.15
          Mean value_function loss: 126.0250
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 67.5234
                       Mean reward: 369.24
               Mean episode length: 229.95
    Episode_Reward/reaching_object: 1.4284
    Episode_Reward/rotating_object: 66.6989
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 2.19s
                      Time elapsed: 00:16:43
                               ETA: 00:42:21

################################################################################
                     [1m Learning iteration 425/1500 [0m                      

                       Computation: 46317 steps/s (collection: 2.031s, learning 0.091s)
             Mean action noise std: 2.15
          Mean value_function loss: 131.2055
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 67.5378
                       Mean reward: 371.50
               Mean episode length: 230.85
    Episode_Reward/reaching_object: 1.4464
    Episode_Reward/rotating_object: 67.5498
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 2.12s
                      Time elapsed: 00:16:45
                               ETA: 00:42:18

################################################################################
                     [1m Learning iteration 426/1500 [0m                      

                       Computation: 44998 steps/s (collection: 2.096s, learning 0.089s)
             Mean action noise std: 2.15
          Mean value_function loss: 129.5527
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 67.5488
                       Mean reward: 324.30
               Mean episode length: 232.91
    Episode_Reward/reaching_object: 1.4728
    Episode_Reward/rotating_object: 70.3678
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 2.18s
                      Time elapsed: 00:16:48
                               ETA: 00:42:15

################################################################################
                     [1m Learning iteration 427/1500 [0m                      

                       Computation: 45178 steps/s (collection: 2.036s, learning 0.140s)
             Mean action noise std: 2.15
          Mean value_function loss: 117.5518
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 67.5630
                       Mean reward: 331.83
               Mean episode length: 226.79
    Episode_Reward/reaching_object: 1.4619
    Episode_Reward/rotating_object: 65.6303
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 2.18s
                      Time elapsed: 00:16:50
                               ETA: 00:42:12

################################################################################
                     [1m Learning iteration 428/1500 [0m                      

                       Computation: 42058 steps/s (collection: 2.215s, learning 0.123s)
             Mean action noise std: 2.15
          Mean value_function loss: 112.9827
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 67.5749
                       Mean reward: 318.21
               Mean episode length: 220.73
    Episode_Reward/reaching_object: 1.4291
    Episode_Reward/rotating_object: 65.5624
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 2.34s
                      Time elapsed: 00:16:52
                               ETA: 00:42:10

################################################################################
                     [1m Learning iteration 429/1500 [0m                      

                       Computation: 45364 steps/s (collection: 2.062s, learning 0.105s)
             Mean action noise std: 2.16
          Mean value_function loss: 100.7125
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 67.5921
                       Mean reward: 384.05
               Mean episode length: 229.68
    Episode_Reward/reaching_object: 1.4633
    Episode_Reward/rotating_object: 69.9825
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 2.17s
                      Time elapsed: 00:16:54
                               ETA: 00:42:07

################################################################################
                     [1m Learning iteration 430/1500 [0m                      

                       Computation: 44361 steps/s (collection: 2.100s, learning 0.116s)
             Mean action noise std: 2.16
          Mean value_function loss: 115.4630
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 67.6135
                       Mean reward: 375.22
               Mean episode length: 236.49
    Episode_Reward/reaching_object: 1.4830
    Episode_Reward/rotating_object: 72.3023
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0504
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 2.22s
                      Time elapsed: 00:16:56
                               ETA: 00:42:04

################################################################################
                     [1m Learning iteration 431/1500 [0m                      

                       Computation: 44838 steps/s (collection: 2.079s, learning 0.114s)
             Mean action noise std: 2.16
          Mean value_function loss: 127.9593
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 67.6260
                       Mean reward: 372.41
               Mean episode length: 226.15
    Episode_Reward/reaching_object: 1.4514
    Episode_Reward/rotating_object: 69.9404
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0494
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 2.19s
                      Time elapsed: 00:16:59
                               ETA: 00:42:02

################################################################################
                     [1m Learning iteration 432/1500 [0m                      

                       Computation: 44986 steps/s (collection: 2.075s, learning 0.110s)
             Mean action noise std: 2.16
          Mean value_function loss: 114.8976
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 67.6397
                       Mean reward: 384.73
               Mean episode length: 233.52
    Episode_Reward/reaching_object: 1.4899
    Episode_Reward/rotating_object: 71.7856
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0498
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 2.19s
                      Time elapsed: 00:17:01
                               ETA: 00:41:59

################################################################################
                     [1m Learning iteration 433/1500 [0m                      

                       Computation: 45331 steps/s (collection: 2.007s, learning 0.162s)
             Mean action noise std: 2.16
          Mean value_function loss: 113.4743
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 67.6496
                       Mean reward: 334.01
               Mean episode length: 219.59
    Episode_Reward/reaching_object: 1.4251
    Episode_Reward/rotating_object: 67.8877
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 2.17s
                      Time elapsed: 00:17:03
                               ETA: 00:41:56

################################################################################
                     [1m Learning iteration 434/1500 [0m                      

                       Computation: 44526 steps/s (collection: 2.093s, learning 0.115s)
             Mean action noise std: 2.16
          Mean value_function loss: 115.1076
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 67.6570
                       Mean reward: 358.39
               Mean episode length: 230.80
    Episode_Reward/reaching_object: 1.4695
    Episode_Reward/rotating_object: 72.7797
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 2.21s
                      Time elapsed: 00:17:05
                               ETA: 00:41:53

################################################################################
                     [1m Learning iteration 435/1500 [0m                      

                       Computation: 45521 steps/s (collection: 2.067s, learning 0.092s)
             Mean action noise std: 2.16
          Mean value_function loss: 106.2618
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 67.6681
                       Mean reward: 344.77
               Mean episode length: 227.80
    Episode_Reward/reaching_object: 1.4348
    Episode_Reward/rotating_object: 71.1882
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 2.16s
                      Time elapsed: 00:17:07
                               ETA: 00:41:50

################################################################################
                     [1m Learning iteration 436/1500 [0m                      

                       Computation: 45117 steps/s (collection: 2.078s, learning 0.101s)
             Mean action noise std: 2.16
          Mean value_function loss: 109.3610
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 67.6806
                       Mean reward: 384.45
               Mean episode length: 228.86
    Episode_Reward/reaching_object: 1.4492
    Episode_Reward/rotating_object: 68.6927
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 2.18s
                      Time elapsed: 00:17:10
                               ETA: 00:41:48

################################################################################
                     [1m Learning iteration 437/1500 [0m                      

                       Computation: 46372 steps/s (collection: 2.029s, learning 0.091s)
             Mean action noise std: 2.16
          Mean value_function loss: 115.2106
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 67.6934
                       Mean reward: 335.98
               Mean episode length: 227.01
    Episode_Reward/reaching_object: 1.4364
    Episode_Reward/rotating_object: 68.0714
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 2.12s
                      Time elapsed: 00:17:12
                               ETA: 00:41:45

################################################################################
                     [1m Learning iteration 438/1500 [0m                      

                       Computation: 46531 steps/s (collection: 2.015s, learning 0.098s)
             Mean action noise std: 2.16
          Mean value_function loss: 116.8673
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 67.7084
                       Mean reward: 317.69
               Mean episode length: 215.09
    Episode_Reward/reaching_object: 1.4162
    Episode_Reward/rotating_object: 69.2678
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 2.11s
                      Time elapsed: 00:17:14
                               ETA: 00:41:42

################################################################################
                     [1m Learning iteration 439/1500 [0m                      

                       Computation: 46433 steps/s (collection: 2.022s, learning 0.095s)
             Mean action noise std: 2.16
          Mean value_function loss: 106.2264
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 67.7162
                       Mean reward: 395.60
               Mean episode length: 233.50
    Episode_Reward/reaching_object: 1.4506
    Episode_Reward/rotating_object: 70.3559
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0495
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 2.12s
                      Time elapsed: 00:17:16
                               ETA: 00:41:39

################################################################################
                     [1m Learning iteration 440/1500 [0m                      

                       Computation: 44293 steps/s (collection: 2.082s, learning 0.137s)
             Mean action noise std: 2.17
          Mean value_function loss: 117.7222
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 67.7301
                       Mean reward: 346.68
               Mean episode length: 226.18
    Episode_Reward/reaching_object: 1.4471
    Episode_Reward/rotating_object: 69.1655
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 2.22s
                      Time elapsed: 00:17:18
                               ETA: 00:41:36

################################################################################
                     [1m Learning iteration 441/1500 [0m                      

                       Computation: 42298 steps/s (collection: 2.182s, learning 0.142s)
             Mean action noise std: 2.17
          Mean value_function loss: 128.2187
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 67.7444
                       Mean reward: 344.83
               Mean episode length: 236.17
    Episode_Reward/reaching_object: 1.4942
    Episode_Reward/rotating_object: 69.7239
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0501
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 2.32s
                      Time elapsed: 00:17:20
                               ETA: 00:41:34

################################################################################
                     [1m Learning iteration 442/1500 [0m                      

                       Computation: 45738 steps/s (collection: 2.052s, learning 0.097s)
             Mean action noise std: 2.17
          Mean value_function loss: 124.5613
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 67.7569
                       Mean reward: 345.82
               Mean episode length: 215.41
    Episode_Reward/reaching_object: 1.4473
    Episode_Reward/rotating_object: 70.1037
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 2.15s
                      Time elapsed: 00:17:23
                               ETA: 00:41:31

################################################################################
                     [1m Learning iteration 443/1500 [0m                      

                       Computation: 44566 steps/s (collection: 2.100s, learning 0.106s)
             Mean action noise std: 2.17
          Mean value_function loss: 117.8378
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 67.7677
                       Mean reward: 392.27
               Mean episode length: 244.64
    Episode_Reward/reaching_object: 1.4841
    Episode_Reward/rotating_object: 72.7265
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 2.21s
                      Time elapsed: 00:17:25
                               ETA: 00:41:28

################################################################################
                     [1m Learning iteration 444/1500 [0m                      

                       Computation: 45470 steps/s (collection: 2.014s, learning 0.148s)
             Mean action noise std: 2.17
          Mean value_function loss: 120.3781
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 67.7751
                       Mean reward: 329.31
               Mean episode length: 216.59
    Episode_Reward/reaching_object: 1.4463
    Episode_Reward/rotating_object: 72.8739
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 2.16s
                      Time elapsed: 00:17:27
                               ETA: 00:41:25

################################################################################
                     [1m Learning iteration 445/1500 [0m                      

                       Computation: 43501 steps/s (collection: 2.085s, learning 0.175s)
             Mean action noise std: 2.17
          Mean value_function loss: 120.6785
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 67.7881
                       Mean reward: 357.16
               Mean episode length: 224.45
    Episode_Reward/reaching_object: 1.4766
    Episode_Reward/rotating_object: 72.6550
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 2.26s
                      Time elapsed: 00:17:29
                               ETA: 00:41:23

################################################################################
                     [1m Learning iteration 446/1500 [0m                      

                       Computation: 44561 steps/s (collection: 2.092s, learning 0.114s)
             Mean action noise std: 2.17
          Mean value_function loss: 117.7278
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 67.7989
                       Mean reward: 349.55
               Mean episode length: 220.21
    Episode_Reward/reaching_object: 1.4597
    Episode_Reward/rotating_object: 73.8719
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 2.21s
                      Time elapsed: 00:17:31
                               ETA: 00:41:20

################################################################################
                     [1m Learning iteration 447/1500 [0m                      

                       Computation: 44632 steps/s (collection: 2.082s, learning 0.120s)
             Mean action noise std: 2.17
          Mean value_function loss: 115.0432
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 67.8081
                       Mean reward: 381.53
               Mean episode length: 223.31
    Episode_Reward/reaching_object: 1.4849
    Episode_Reward/rotating_object: 74.2206
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 2.20s
                      Time elapsed: 00:17:34
                               ETA: 00:41:17

################################################################################
                     [1m Learning iteration 448/1500 [0m                      

                       Computation: 42654 steps/s (collection: 2.211s, learning 0.094s)
             Mean action noise std: 2.17
          Mean value_function loss: 111.4943
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 67.8157
                       Mean reward: 400.13
               Mean episode length: 229.59
    Episode_Reward/reaching_object: 1.4706
    Episode_Reward/rotating_object: 72.3190
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 2.30s
                      Time elapsed: 00:17:36
                               ETA: 00:41:15

################################################################################
                     [1m Learning iteration 449/1500 [0m                      

                       Computation: 43494 steps/s (collection: 2.077s, learning 0.183s)
             Mean action noise std: 2.17
          Mean value_function loss: 115.8368
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 67.8275
                       Mean reward: 363.62
               Mean episode length: 227.24
    Episode_Reward/reaching_object: 1.4991
    Episode_Reward/rotating_object: 74.1595
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 2.26s
                      Time elapsed: 00:17:38
                               ETA: 00:41:12

################################################################################
                     [1m Learning iteration 450/1500 [0m                      

                       Computation: 44750 steps/s (collection: 2.083s, learning 0.114s)
             Mean action noise std: 2.17
          Mean value_function loss: 107.3670
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 67.8435
                       Mean reward: 344.05
               Mean episode length: 215.18
    Episode_Reward/reaching_object: 1.4557
    Episode_Reward/rotating_object: 72.9873
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 2.20s
                      Time elapsed: 00:17:40
                               ETA: 00:41:10

################################################################################
                     [1m Learning iteration 451/1500 [0m                      

                       Computation: 43090 steps/s (collection: 2.138s, learning 0.144s)
             Mean action noise std: 2.18
          Mean value_function loss: 100.3802
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 67.8542
                       Mean reward: 390.67
               Mean episode length: 223.48
    Episode_Reward/reaching_object: 1.4552
    Episode_Reward/rotating_object: 74.4943
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 2.28s
                      Time elapsed: 00:17:43
                               ETA: 00:41:07

################################################################################
                     [1m Learning iteration 452/1500 [0m                      

                       Computation: 43511 steps/s (collection: 2.132s, learning 0.128s)
             Mean action noise std: 2.18
          Mean value_function loss: 114.4791
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 67.8664
                       Mean reward: 408.73
               Mean episode length: 234.55
    Episode_Reward/reaching_object: 1.5035
    Episode_Reward/rotating_object: 79.2672
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 2.26s
                      Time elapsed: 00:17:45
                               ETA: 00:41:04

################################################################################
                     [1m Learning iteration 453/1500 [0m                      

                       Computation: 42885 steps/s (collection: 2.194s, learning 0.098s)
             Mean action noise std: 2.18
          Mean value_function loss: 122.4526
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 67.8832
                       Mean reward: 378.43
               Mean episode length: 223.14
    Episode_Reward/reaching_object: 1.4794
    Episode_Reward/rotating_object: 76.4469
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 2.29s
                      Time elapsed: 00:17:47
                               ETA: 00:41:02

################################################################################
                     [1m Learning iteration 454/1500 [0m                      

                       Computation: 45085 steps/s (collection: 2.088s, learning 0.092s)
             Mean action noise std: 2.18
          Mean value_function loss: 113.0060
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 67.8983
                       Mean reward: 374.51
               Mean episode length: 215.18
    Episode_Reward/reaching_object: 1.4287
    Episode_Reward/rotating_object: 74.4450
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 2.18s
                      Time elapsed: 00:17:49
                               ETA: 00:40:59

################################################################################
                     [1m Learning iteration 455/1500 [0m                      

                       Computation: 45551 steps/s (collection: 2.055s, learning 0.103s)
             Mean action noise std: 2.18
          Mean value_function loss: 116.1997
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 67.9034
                       Mean reward: 315.04
               Mean episode length: 213.80
    Episode_Reward/reaching_object: 1.4090
    Episode_Reward/rotating_object: 68.0679
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 2.16s
                      Time elapsed: 00:17:52
                               ETA: 00:40:56

################################################################################
                     [1m Learning iteration 456/1500 [0m                      

                       Computation: 44735 steps/s (collection: 2.093s, learning 0.104s)
             Mean action noise std: 2.18
          Mean value_function loss: 123.2488
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 67.9096
                       Mean reward: 399.83
               Mean episode length: 221.36
    Episode_Reward/reaching_object: 1.4750
    Episode_Reward/rotating_object: 78.5430
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 2.20s
                      Time elapsed: 00:17:54
                               ETA: 00:40:54

################################################################################
                     [1m Learning iteration 457/1500 [0m                      

                       Computation: 39872 steps/s (collection: 2.328s, learning 0.137s)
             Mean action noise std: 2.18
          Mean value_function loss: 126.1347
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 67.9250
                       Mean reward: 364.94
               Mean episode length: 222.10
    Episode_Reward/reaching_object: 1.4454
    Episode_Reward/rotating_object: 72.4149
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 2.47s
                      Time elapsed: 00:17:56
                               ETA: 00:40:52

################################################################################
                     [1m Learning iteration 458/1500 [0m                      

                       Computation: 43116 steps/s (collection: 2.190s, learning 0.090s)
             Mean action noise std: 2.18
          Mean value_function loss: 129.8900
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 67.9405
                       Mean reward: 344.88
               Mean episode length: 209.37
    Episode_Reward/reaching_object: 1.4382
    Episode_Reward/rotating_object: 73.7853
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 2.28s
                      Time elapsed: 00:17:59
                               ETA: 00:40:49

################################################################################
                     [1m Learning iteration 459/1500 [0m                      

                       Computation: 44426 steps/s (collection: 2.108s, learning 0.105s)
             Mean action noise std: 2.18
          Mean value_function loss: 128.4092
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 67.9510
                       Mean reward: 365.84
               Mean episode length: 216.75
    Episode_Reward/reaching_object: 1.4599
    Episode_Reward/rotating_object: 74.6492
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 2.21s
                      Time elapsed: 00:18:01
                               ETA: 00:40:46

################################################################################
                     [1m Learning iteration 460/1500 [0m                      

                       Computation: 41121 steps/s (collection: 2.251s, learning 0.139s)
             Mean action noise std: 2.18
          Mean value_function loss: 126.4662
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 67.9619
                       Mean reward: 421.33
               Mean episode length: 237.95
    Episode_Reward/reaching_object: 1.5081
    Episode_Reward/rotating_object: 78.3354
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0494
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 2.39s
                      Time elapsed: 00:18:03
                               ETA: 00:40:44

################################################################################
                     [1m Learning iteration 461/1500 [0m                      

                       Computation: 40744 steps/s (collection: 2.228s, learning 0.185s)
             Mean action noise std: 2.18
          Mean value_function loss: 130.1312
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 67.9706
                       Mean reward: 381.68
               Mean episode length: 228.11
    Episode_Reward/reaching_object: 1.5048
    Episode_Reward/rotating_object: 79.0458
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 2.41s
                      Time elapsed: 00:18:06
                               ETA: 00:40:42

################################################################################
                     [1m Learning iteration 462/1500 [0m                      

                       Computation: 44675 steps/s (collection: 2.061s, learning 0.140s)
             Mean action noise std: 2.19
          Mean value_function loss: 119.2964
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 67.9826
                       Mean reward: 415.35
               Mean episode length: 232.99
    Episode_Reward/reaching_object: 1.4983
    Episode_Reward/rotating_object: 79.9790
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 2.20s
                      Time elapsed: 00:18:08
                               ETA: 00:40:39

################################################################################
                     [1m Learning iteration 463/1500 [0m                      

                       Computation: 44361 steps/s (collection: 2.107s, learning 0.109s)
             Mean action noise std: 2.19
          Mean value_function loss: 131.5636
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 67.9934
                       Mean reward: 406.26
               Mean episode length: 232.66
    Episode_Reward/reaching_object: 1.4775
    Episode_Reward/rotating_object: 74.0100
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 2.22s
                      Time elapsed: 00:18:10
                               ETA: 00:40:37

################################################################################
                     [1m Learning iteration 464/1500 [0m                      

                       Computation: 43305 steps/s (collection: 2.123s, learning 0.147s)
             Mean action noise std: 2.19
          Mean value_function loss: 126.3517
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 68.0077
                       Mean reward: 384.62
               Mean episode length: 219.91
    Episode_Reward/reaching_object: 1.4867
    Episode_Reward/rotating_object: 77.5045
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 2.27s
                      Time elapsed: 00:18:12
                               ETA: 00:40:34

################################################################################
                     [1m Learning iteration 465/1500 [0m                      

                       Computation: 45617 steps/s (collection: 2.057s, learning 0.098s)
             Mean action noise std: 2.19
          Mean value_function loss: 125.3958
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 68.0220
                       Mean reward: 388.45
               Mean episode length: 224.06
    Episode_Reward/reaching_object: 1.4785
    Episode_Reward/rotating_object: 74.5786
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 2.15s
                      Time elapsed: 00:18:14
                               ETA: 00:40:31

################################################################################
                     [1m Learning iteration 466/1500 [0m                      

                       Computation: 42447 steps/s (collection: 2.206s, learning 0.110s)
             Mean action noise std: 2.19
          Mean value_function loss: 122.2560
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 68.0350
                       Mean reward: 388.13
               Mean episode length: 221.65
    Episode_Reward/reaching_object: 1.5104
    Episode_Reward/rotating_object: 80.5219
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 2.32s
                      Time elapsed: 00:18:17
                               ETA: 00:40:29

################################################################################
                     [1m Learning iteration 467/1500 [0m                      

                       Computation: 45050 steps/s (collection: 2.073s, learning 0.109s)
             Mean action noise std: 2.19
          Mean value_function loss: 102.7265
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 68.0505
                       Mean reward: 412.29
               Mean episode length: 220.05
    Episode_Reward/reaching_object: 1.5234
    Episode_Reward/rotating_object: 81.6900
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 2.18s
                      Time elapsed: 00:18:19
                               ETA: 00:40:26

################################################################################
                     [1m Learning iteration 468/1500 [0m                      

                       Computation: 41630 steps/s (collection: 2.212s, learning 0.149s)
             Mean action noise std: 2.19
          Mean value_function loss: 97.4910
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 68.0672
                       Mean reward: 373.82
               Mean episode length: 222.64
    Episode_Reward/reaching_object: 1.4771
    Episode_Reward/rotating_object: 77.9238
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 2.36s
                      Time elapsed: 00:18:21
                               ETA: 00:40:24

################################################################################
                     [1m Learning iteration 469/1500 [0m                      

                       Computation: 43041 steps/s (collection: 2.174s, learning 0.110s)
             Mean action noise std: 2.19
          Mean value_function loss: 110.2051
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 68.0778
                       Mean reward: 405.83
               Mean episode length: 229.24
    Episode_Reward/reaching_object: 1.5071
    Episode_Reward/rotating_object: 82.8874
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 2.28s
                      Time elapsed: 00:18:24
                               ETA: 00:40:21

################################################################################
                     [1m Learning iteration 470/1500 [0m                      

                       Computation: 43088 steps/s (collection: 2.183s, learning 0.098s)
             Mean action noise std: 2.19
          Mean value_function loss: 112.5315
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 68.0895
                       Mean reward: 402.97
               Mean episode length: 229.34
    Episode_Reward/reaching_object: 1.5078
    Episode_Reward/rotating_object: 79.9136
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 2.28s
                      Time elapsed: 00:18:26
                               ETA: 00:40:19

################################################################################
                     [1m Learning iteration 471/1500 [0m                      

                       Computation: 44735 steps/s (collection: 2.104s, learning 0.093s)
             Mean action noise std: 2.19
          Mean value_function loss: 104.5251
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 68.0995
                       Mean reward: 447.24
               Mean episode length: 239.98
    Episode_Reward/reaching_object: 1.5183
    Episode_Reward/rotating_object: 81.1832
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0494
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 2.20s
                      Time elapsed: 00:18:28
                               ETA: 00:40:16

################################################################################
                     [1m Learning iteration 472/1500 [0m                      

                       Computation: 41249 steps/s (collection: 2.227s, learning 0.157s)
             Mean action noise std: 2.19
          Mean value_function loss: 117.1400
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 68.1060
                       Mean reward: 457.23
               Mean episode length: 238.72
    Episode_Reward/reaching_object: 1.5246
    Episode_Reward/rotating_object: 83.3970
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 2.38s
                      Time elapsed: 00:18:30
                               ETA: 00:40:14

################################################################################
                     [1m Learning iteration 473/1500 [0m                      

                       Computation: 43902 steps/s (collection: 2.128s, learning 0.111s)
             Mean action noise std: 2.20
          Mean value_function loss: 111.8250
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 68.1156
                       Mean reward: 423.47
               Mean episode length: 232.99
    Episode_Reward/reaching_object: 1.5147
    Episode_Reward/rotating_object: 80.6930
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 2.24s
                      Time elapsed: 00:18:33
                               ETA: 00:40:11

################################################################################
                     [1m Learning iteration 474/1500 [0m                      

                       Computation: 44878 steps/s (collection: 2.076s, learning 0.114s)
             Mean action noise std: 2.20
          Mean value_function loss: 107.1201
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 68.1273
                       Mean reward: 431.74
               Mean episode length: 239.54
    Episode_Reward/reaching_object: 1.5173
    Episode_Reward/rotating_object: 81.1686
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 2.19s
                      Time elapsed: 00:18:35
                               ETA: 00:40:09

################################################################################
                     [1m Learning iteration 475/1500 [0m                      

                       Computation: 46308 steps/s (collection: 2.031s, learning 0.092s)
             Mean action noise std: 2.20
          Mean value_function loss: 122.9872
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 68.1396
                       Mean reward: 417.86
               Mean episode length: 228.48
    Episode_Reward/reaching_object: 1.5042
    Episode_Reward/rotating_object: 80.5531
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 2.12s
                      Time elapsed: 00:18:37
                               ETA: 00:40:06

################################################################################
                     [1m Learning iteration 476/1500 [0m                      

                       Computation: 45680 steps/s (collection: 2.029s, learning 0.123s)
             Mean action noise std: 2.20
          Mean value_function loss: 113.8829
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 68.1515
                       Mean reward: 417.77
               Mean episode length: 229.31
    Episode_Reward/reaching_object: 1.5259
    Episode_Reward/rotating_object: 80.5997
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 2.15s
                      Time elapsed: 00:18:39
                               ETA: 00:40:03

################################################################################
                     [1m Learning iteration 477/1500 [0m                      

                       Computation: 46032 steps/s (collection: 2.040s, learning 0.095s)
             Mean action noise std: 2.20
          Mean value_function loss: 105.1572
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 68.1651
                       Mean reward: 401.63
               Mean episode length: 224.08
    Episode_Reward/reaching_object: 1.5258
    Episode_Reward/rotating_object: 83.7008
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 2.14s
                      Time elapsed: 00:18:41
                               ETA: 00:40:00

################################################################################
                     [1m Learning iteration 478/1500 [0m                      

                       Computation: 44733 steps/s (collection: 2.074s, learning 0.124s)
             Mean action noise std: 2.20
          Mean value_function loss: 114.5358
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 68.1788
                       Mean reward: 390.77
               Mean episode length: 235.95
    Episode_Reward/reaching_object: 1.4875
    Episode_Reward/rotating_object: 77.1059
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 2.20s
                      Time elapsed: 00:18:43
                               ETA: 00:39:58

################################################################################
                     [1m Learning iteration 479/1500 [0m                      

                       Computation: 42967 steps/s (collection: 2.194s, learning 0.094s)
             Mean action noise std: 2.20
          Mean value_function loss: 110.5675
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 68.1934
                       Mean reward: 432.42
               Mean episode length: 229.10
    Episode_Reward/reaching_object: 1.4746
    Episode_Reward/rotating_object: 80.4022
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 2.29s
                      Time elapsed: 00:18:46
                               ETA: 00:39:55

################################################################################
                     [1m Learning iteration 480/1500 [0m                      

                       Computation: 44214 steps/s (collection: 2.123s, learning 0.100s)
             Mean action noise std: 2.20
          Mean value_function loss: 111.1875
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 68.2070
                       Mean reward: 398.79
               Mean episode length: 220.40
    Episode_Reward/reaching_object: 1.4795
    Episode_Reward/rotating_object: 80.2829
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 2.22s
                      Time elapsed: 00:18:48
                               ETA: 00:39:52

################################################################################
                     [1m Learning iteration 481/1500 [0m                      

                       Computation: 45518 steps/s (collection: 2.058s, learning 0.102s)
             Mean action noise std: 2.20
          Mean value_function loss: 115.3486
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 68.2210
                       Mean reward: 406.14
               Mean episode length: 226.32
    Episode_Reward/reaching_object: 1.5198
    Episode_Reward/rotating_object: 83.6443
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 2.16s
                      Time elapsed: 00:18:50
                               ETA: 00:39:50

################################################################################
                     [1m Learning iteration 482/1500 [0m                      

                       Computation: 44253 steps/s (collection: 2.104s, learning 0.117s)
             Mean action noise std: 2.20
          Mean value_function loss: 119.7664
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 68.2309
                       Mean reward: 423.88
               Mean episode length: 227.42
    Episode_Reward/reaching_object: 1.4816
    Episode_Reward/rotating_object: 82.9175
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 2.22s
                      Time elapsed: 00:18:52
                               ETA: 00:39:47

################################################################################
                     [1m Learning iteration 483/1500 [0m                      

                       Computation: 42533 steps/s (collection: 2.182s, learning 0.130s)
             Mean action noise std: 2.21
          Mean value_function loss: 112.2540
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 68.2454
                       Mean reward: 412.70
               Mean episode length: 232.03
    Episode_Reward/reaching_object: 1.5297
    Episode_Reward/rotating_object: 82.5275
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 2.31s
                      Time elapsed: 00:18:55
                               ETA: 00:39:45

################################################################################
                     [1m Learning iteration 484/1500 [0m                      

                       Computation: 44182 steps/s (collection: 2.117s, learning 0.108s)
             Mean action noise std: 2.21
          Mean value_function loss: 109.6124
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 68.2606
                       Mean reward: 391.46
               Mean episode length: 233.85
    Episode_Reward/reaching_object: 1.5032
    Episode_Reward/rotating_object: 82.5349
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 2.22s
                      Time elapsed: 00:18:57
                               ETA: 00:39:42

################################################################################
                     [1m Learning iteration 485/1500 [0m                      

                       Computation: 45443 steps/s (collection: 2.057s, learning 0.107s)
             Mean action noise std: 2.21
          Mean value_function loss: 109.2357
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 68.2713
                       Mean reward: 420.08
               Mean episode length: 234.31
    Episode_Reward/reaching_object: 1.5012
    Episode_Reward/rotating_object: 81.0850
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 2.16s
                      Time elapsed: 00:18:59
                               ETA: 00:39:39

################################################################################
                     [1m Learning iteration 486/1500 [0m                      

                       Computation: 46170 steps/s (collection: 2.034s, learning 0.095s)
             Mean action noise std: 2.21
          Mean value_function loss: 104.9579
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 68.2841
                       Mean reward: 474.87
               Mean episode length: 234.47
    Episode_Reward/reaching_object: 1.5012
    Episode_Reward/rotating_object: 85.1152
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 2.13s
                      Time elapsed: 00:19:01
                               ETA: 00:39:37

################################################################################
                     [1m Learning iteration 487/1500 [0m                      

                       Computation: 46507 steps/s (collection: 2.022s, learning 0.092s)
             Mean action noise std: 2.21
          Mean value_function loss: 103.0085
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 68.2999
                       Mean reward: 451.56
               Mean episode length: 239.10
    Episode_Reward/reaching_object: 1.5270
    Episode_Reward/rotating_object: 87.9693
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 2.11s
                      Time elapsed: 00:19:03
                               ETA: 00:39:34

################################################################################
                     [1m Learning iteration 488/1500 [0m                      

                       Computation: 45272 steps/s (collection: 2.039s, learning 0.132s)
             Mean action noise std: 2.21
          Mean value_function loss: 95.4530
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 68.3177
                       Mean reward: 408.67
               Mean episode length: 223.26
    Episode_Reward/reaching_object: 1.4850
    Episode_Reward/rotating_object: 82.9793
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 2.17s
                      Time elapsed: 00:19:05
                               ETA: 00:39:31

################################################################################
                     [1m Learning iteration 489/1500 [0m                      

                       Computation: 44390 steps/s (collection: 2.079s, learning 0.135s)
             Mean action noise std: 2.21
          Mean value_function loss: 106.7337
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 68.3344
                       Mean reward: 470.00
               Mean episode length: 235.41
    Episode_Reward/reaching_object: 1.5313
    Episode_Reward/rotating_object: 86.6636
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 2.21s
                      Time elapsed: 00:19:08
                               ETA: 00:39:28

################################################################################
                     [1m Learning iteration 490/1500 [0m                      

                       Computation: 41832 steps/s (collection: 2.221s, learning 0.129s)
             Mean action noise std: 2.21
          Mean value_function loss: 115.8103
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 68.3450
                       Mean reward: 459.66
               Mean episode length: 234.13
    Episode_Reward/reaching_object: 1.4973
    Episode_Reward/rotating_object: 85.1697
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 2.35s
                      Time elapsed: 00:19:10
                               ETA: 00:39:26

################################################################################
                     [1m Learning iteration 491/1500 [0m                      

                       Computation: 46469 steps/s (collection: 2.023s, learning 0.093s)
             Mean action noise std: 2.21
          Mean value_function loss: 104.8166
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 68.3546
                       Mean reward: 460.00
               Mean episode length: 230.36
    Episode_Reward/reaching_object: 1.5228
    Episode_Reward/rotating_object: 86.8561
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 2.12s
                      Time elapsed: 00:19:12
                               ETA: 00:39:23

################################################################################
                     [1m Learning iteration 492/1500 [0m                      

                       Computation: 44681 steps/s (collection: 2.111s, learning 0.089s)
             Mean action noise std: 2.22
          Mean value_function loss: 111.9635
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 68.3748
                       Mean reward: 394.80
               Mean episode length: 223.42
    Episode_Reward/reaching_object: 1.5022
    Episode_Reward/rotating_object: 83.0018
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 2.20s
                      Time elapsed: 00:19:14
                               ETA: 00:39:21

################################################################################
                     [1m Learning iteration 493/1500 [0m                      

                       Computation: 44766 steps/s (collection: 2.063s, learning 0.133s)
             Mean action noise std: 2.22
          Mean value_function loss: 105.0372
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 68.3890
                       Mean reward: 452.49
               Mean episode length: 228.39
    Episode_Reward/reaching_object: 1.5044
    Episode_Reward/rotating_object: 87.3544
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 2.20s
                      Time elapsed: 00:19:17
                               ETA: 00:39:18

################################################################################
                     [1m Learning iteration 494/1500 [0m                      

                       Computation: 42277 steps/s (collection: 2.101s, learning 0.224s)
             Mean action noise std: 2.22
          Mean value_function loss: 116.2200
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 68.4012
                       Mean reward: 422.12
               Mean episode length: 229.03
    Episode_Reward/reaching_object: 1.4944
    Episode_Reward/rotating_object: 85.2242
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 2.33s
                      Time elapsed: 00:19:19
                               ETA: 00:39:16

################################################################################
                     [1m Learning iteration 495/1500 [0m                      

                       Computation: 45326 steps/s (collection: 2.072s, learning 0.097s)
             Mean action noise std: 2.22
          Mean value_function loss: 127.9180
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 68.4181
                       Mean reward: 406.85
               Mean episode length: 225.59
    Episode_Reward/reaching_object: 1.5077
    Episode_Reward/rotating_object: 84.3590
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 2.17s
                      Time elapsed: 00:19:21
                               ETA: 00:39:13

################################################################################
                     [1m Learning iteration 496/1500 [0m                      

                       Computation: 45969 steps/s (collection: 2.045s, learning 0.093s)
             Mean action noise std: 2.22
          Mean value_function loss: 108.6408
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 68.4340
                       Mean reward: 425.14
               Mean episode length: 222.56
    Episode_Reward/reaching_object: 1.4970
    Episode_Reward/rotating_object: 83.8475
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 2.14s
                      Time elapsed: 00:19:23
                               ETA: 00:39:10

################################################################################
                     [1m Learning iteration 497/1500 [0m                      

                       Computation: 43583 steps/s (collection: 2.156s, learning 0.100s)
             Mean action noise std: 2.22
          Mean value_function loss: 105.8634
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 68.4493
                       Mean reward: 446.69
               Mean episode length: 229.37
    Episode_Reward/reaching_object: 1.5034
    Episode_Reward/rotating_object: 84.9388
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 2.26s
                      Time elapsed: 00:19:25
                               ETA: 00:39:08

################################################################################
                     [1m Learning iteration 498/1500 [0m                      

                       Computation: 43255 steps/s (collection: 2.095s, learning 0.178s)
             Mean action noise std: 2.22
          Mean value_function loss: 102.2514
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 68.4678
                       Mean reward: 412.35
               Mean episode length: 232.47
    Episode_Reward/reaching_object: 1.5245
    Episode_Reward/rotating_object: 88.1150
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 2.27s
                      Time elapsed: 00:19:28
                               ETA: 00:39:05

################################################################################
                     [1m Learning iteration 499/1500 [0m                      

                       Computation: 42498 steps/s (collection: 2.225s, learning 0.088s)
             Mean action noise std: 2.22
          Mean value_function loss: 103.6539
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 68.4839
                       Mean reward: 458.79
               Mean episode length: 232.19
    Episode_Reward/reaching_object: 1.5245
    Episode_Reward/rotating_object: 88.0264
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0495
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 2.31s
                      Time elapsed: 00:19:30
                               ETA: 00:39:03

################################################################################
                     [1m Learning iteration 500/1500 [0m                      

                       Computation: 45847 steps/s (collection: 2.047s, learning 0.098s)
             Mean action noise std: 2.23
          Mean value_function loss: 93.4529
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 68.4971
                       Mean reward: 487.21
               Mean episode length: 236.17
    Episode_Reward/reaching_object: 1.5460
    Episode_Reward/rotating_object: 92.0091
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 2.14s
                      Time elapsed: 00:19:32
                               ETA: 00:39:00

################################################################################
                     [1m Learning iteration 501/1500 [0m                      

                       Computation: 44016 steps/s (collection: 2.136s, learning 0.097s)
             Mean action noise std: 2.23
          Mean value_function loss: 96.9537
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 68.5061
                       Mean reward: 429.27
               Mean episode length: 225.85
    Episode_Reward/reaching_object: 1.5171
    Episode_Reward/rotating_object: 90.7259
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 2.23s
                      Time elapsed: 00:19:34
                               ETA: 00:38:58

################################################################################
                     [1m Learning iteration 502/1500 [0m                      

                       Computation: 43595 steps/s (collection: 2.105s, learning 0.150s)
             Mean action noise std: 2.23
          Mean value_function loss: 93.2778
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 68.5224
                       Mean reward: 473.71
               Mean episode length: 238.96
    Episode_Reward/reaching_object: 1.5203
    Episode_Reward/rotating_object: 89.6752
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 2.25s
                      Time elapsed: 00:19:37
                               ETA: 00:38:55

################################################################################
                     [1m Learning iteration 503/1500 [0m                      

                       Computation: 44267 steps/s (collection: 2.090s, learning 0.131s)
             Mean action noise std: 2.23
          Mean value_function loss: 95.2246
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 68.5343
                       Mean reward: 404.15
               Mean episode length: 222.68
    Episode_Reward/reaching_object: 1.4933
    Episode_Reward/rotating_object: 85.6179
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 2.22s
                      Time elapsed: 00:19:39
                               ETA: 00:38:52

################################################################################
                     [1m Learning iteration 504/1500 [0m                      

                       Computation: 44847 steps/s (collection: 2.069s, learning 0.123s)
             Mean action noise std: 2.23
          Mean value_function loss: 96.9243
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 68.5430
                       Mean reward: 429.15
               Mean episode length: 226.26
    Episode_Reward/reaching_object: 1.5093
    Episode_Reward/rotating_object: 89.4349
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 2.19s
                      Time elapsed: 00:19:41
                               ETA: 00:38:50

################################################################################
                     [1m Learning iteration 505/1500 [0m                      

                       Computation: 44432 steps/s (collection: 2.093s, learning 0.120s)
             Mean action noise std: 2.23
          Mean value_function loss: 110.7350
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 68.5529
                       Mean reward: 445.49
               Mean episode length: 228.87
    Episode_Reward/reaching_object: 1.5299
    Episode_Reward/rotating_object: 88.7595
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0494
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 2.21s
                      Time elapsed: 00:19:43
                               ETA: 00:38:47

################################################################################
                     [1m Learning iteration 506/1500 [0m                      

                       Computation: 43212 steps/s (collection: 2.153s, learning 0.122s)
             Mean action noise std: 2.23
          Mean value_function loss: 124.2037
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 68.5678
                       Mean reward: 413.30
               Mean episode length: 222.20
    Episode_Reward/reaching_object: 1.4877
    Episode_Reward/rotating_object: 87.7657
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 2.27s
                      Time elapsed: 00:19:46
                               ETA: 00:38:45

################################################################################
                     [1m Learning iteration 507/1500 [0m                      

                       Computation: 43639 steps/s (collection: 2.141s, learning 0.112s)
             Mean action noise std: 2.23
          Mean value_function loss: 105.5377
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 68.5886
                       Mean reward: 463.55
               Mean episode length: 237.25
    Episode_Reward/reaching_object: 1.4948
    Episode_Reward/rotating_object: 88.9318
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 2.25s
                      Time elapsed: 00:19:48
                               ETA: 00:38:42

################################################################################
                     [1m Learning iteration 508/1500 [0m                      

                       Computation: 43333 steps/s (collection: 2.162s, learning 0.106s)
             Mean action noise std: 2.23
          Mean value_function loss: 103.4741
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 68.6079
                       Mean reward: 447.32
               Mean episode length: 234.58
    Episode_Reward/reaching_object: 1.5047
    Episode_Reward/rotating_object: 86.5382
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 2.27s
                      Time elapsed: 00:19:50
                               ETA: 00:38:40

################################################################################
                     [1m Learning iteration 509/1500 [0m                      

                       Computation: 44975 steps/s (collection: 2.095s, learning 0.091s)
             Mean action noise std: 2.24
          Mean value_function loss: 94.7880
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 68.6222
                       Mean reward: 470.82
               Mean episode length: 232.63
    Episode_Reward/reaching_object: 1.5216
    Episode_Reward/rotating_object: 88.7084
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 2.19s
                      Time elapsed: 00:19:52
                               ETA: 00:38:37

################################################################################
                     [1m Learning iteration 510/1500 [0m                      

                       Computation: 42896 steps/s (collection: 2.145s, learning 0.147s)
             Mean action noise std: 2.24
          Mean value_function loss: 92.9131
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 68.6417
                       Mean reward: 472.79
               Mean episode length: 232.91
    Episode_Reward/reaching_object: 1.5126
    Episode_Reward/rotating_object: 88.7152
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 2.29s
                      Time elapsed: 00:19:55
                               ETA: 00:38:35

################################################################################
                     [1m Learning iteration 511/1500 [0m                      

                       Computation: 41891 steps/s (collection: 2.173s, learning 0.174s)
             Mean action noise std: 2.24
          Mean value_function loss: 100.4756
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 68.6673
                       Mean reward: 473.04
               Mean episode length: 228.49
    Episode_Reward/reaching_object: 1.4774
    Episode_Reward/rotating_object: 87.5765
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 2.35s
                      Time elapsed: 00:19:57
                               ETA: 00:38:32

################################################################################
                     [1m Learning iteration 512/1500 [0m                      

                       Computation: 43554 steps/s (collection: 2.165s, learning 0.092s)
             Mean action noise std: 2.24
          Mean value_function loss: 107.1630
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 68.6843
                       Mean reward: 431.78
               Mean episode length: 226.99
    Episode_Reward/reaching_object: 1.4793
    Episode_Reward/rotating_object: 87.5891
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 2.26s
                      Time elapsed: 00:19:59
                               ETA: 00:38:30

################################################################################
                     [1m Learning iteration 513/1500 [0m                      

                       Computation: 44951 steps/s (collection: 2.095s, learning 0.092s)
             Mean action noise std: 2.24
          Mean value_function loss: 117.1073
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 68.7026
                       Mean reward: 457.66
               Mean episode length: 228.98
    Episode_Reward/reaching_object: 1.5025
    Episode_Reward/rotating_object: 89.8803
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0468
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 2.19s
                      Time elapsed: 00:20:01
                               ETA: 00:38:27

################################################################################
                     [1m Learning iteration 514/1500 [0m                      

                       Computation: 44876 steps/s (collection: 2.101s, learning 0.090s)
             Mean action noise std: 2.24
          Mean value_function loss: 137.4783
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 68.7140
                       Mean reward: 436.30
               Mean episode length: 228.44
    Episode_Reward/reaching_object: 1.5268
    Episode_Reward/rotating_object: 91.1812
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 2.19s
                      Time elapsed: 00:20:04
                               ETA: 00:38:25

################################################################################
                     [1m Learning iteration 515/1500 [0m                      

                       Computation: 44252 steps/s (collection: 2.069s, learning 0.153s)
             Mean action noise std: 2.24
          Mean value_function loss: 155.3861
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 68.7242
                       Mean reward: 464.06
               Mean episode length: 228.72
    Episode_Reward/reaching_object: 1.5142
    Episode_Reward/rotating_object: 89.4416
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 2.22s
                      Time elapsed: 00:20:06
                               ETA: 00:38:22

################################################################################
                     [1m Learning iteration 516/1500 [0m                      

                       Computation: 44212 steps/s (collection: 2.095s, learning 0.128s)
             Mean action noise std: 2.24
          Mean value_function loss: 129.4392
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 68.7341
                       Mean reward: 473.29
               Mean episode length: 226.24
    Episode_Reward/reaching_object: 1.5249
    Episode_Reward/rotating_object: 91.1583
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 2.22s
                      Time elapsed: 00:20:08
                               ETA: 00:38:20

################################################################################
                     [1m Learning iteration 517/1500 [0m                      

                       Computation: 41186 steps/s (collection: 2.248s, learning 0.139s)
             Mean action noise std: 2.25
          Mean value_function loss: 117.3821
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 68.7431
                       Mean reward: 436.17
               Mean episode length: 215.88
    Episode_Reward/reaching_object: 1.5016
    Episode_Reward/rotating_object: 91.4088
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 2.39s
                      Time elapsed: 00:20:10
                               ETA: 00:38:17

################################################################################
                     [1m Learning iteration 518/1500 [0m                      

                       Computation: 43632 steps/s (collection: 2.145s, learning 0.108s)
             Mean action noise std: 2.25
          Mean value_function loss: 110.0916
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 68.7521
                       Mean reward: 457.69
               Mean episode length: 227.67
    Episode_Reward/reaching_object: 1.5332
    Episode_Reward/rotating_object: 92.9519
        Episode_Reward/action_rate: -0.0355
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 2.25s
                      Time elapsed: 00:20:13
                               ETA: 00:38:15

################################################################################
                     [1m Learning iteration 519/1500 [0m                      

                       Computation: 43471 steps/s (collection: 2.152s, learning 0.110s)
             Mean action noise std: 2.25
          Mean value_function loss: 111.3430
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 68.7618
                       Mean reward: 482.89
               Mean episode length: 235.59
    Episode_Reward/reaching_object: 1.5628
    Episode_Reward/rotating_object: 95.1666
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 2.26s
                      Time elapsed: 00:20:15
                               ETA: 00:38:12

################################################################################
                     [1m Learning iteration 520/1500 [0m                      

                       Computation: 43090 steps/s (collection: 2.148s, learning 0.134s)
             Mean action noise std: 2.25
          Mean value_function loss: 121.1610
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 68.7705
                       Mean reward: 438.70
               Mean episode length: 213.59
    Episode_Reward/reaching_object: 1.5170
    Episode_Reward/rotating_object: 91.7831
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 2.28s
                      Time elapsed: 00:20:17
                               ETA: 00:38:10

################################################################################
                     [1m Learning iteration 521/1500 [0m                      

                       Computation: 42402 steps/s (collection: 2.171s, learning 0.147s)
             Mean action noise std: 2.25
          Mean value_function loss: 106.7430
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 68.7826
                       Mean reward: 454.77
               Mean episode length: 227.29
    Episode_Reward/reaching_object: 1.5040
    Episode_Reward/rotating_object: 91.9533
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 2.32s
                      Time elapsed: 00:20:19
                               ETA: 00:38:07

################################################################################
                     [1m Learning iteration 522/1500 [0m                      

                       Computation: 44960 steps/s (collection: 2.097s, learning 0.089s)
             Mean action noise std: 2.25
          Mean value_function loss: 112.1510
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 68.7914
                       Mean reward: 488.76
               Mean episode length: 237.47
    Episode_Reward/reaching_object: 1.5655
    Episode_Reward/rotating_object: 95.7904
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 2.19s
                      Time elapsed: 00:20:22
                               ETA: 00:38:05

################################################################################
                     [1m Learning iteration 523/1500 [0m                      

                       Computation: 43955 steps/s (collection: 2.074s, learning 0.162s)
             Mean action noise std: 2.25
          Mean value_function loss: 115.1006
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 68.8011
                       Mean reward: 500.32
               Mean episode length: 237.88
    Episode_Reward/reaching_object: 1.5225
    Episode_Reward/rotating_object: 93.9011
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 2.24s
                      Time elapsed: 00:20:24
                               ETA: 00:38:02

################################################################################
                     [1m Learning iteration 524/1500 [0m                      

                       Computation: 44620 steps/s (collection: 2.093s, learning 0.110s)
             Mean action noise std: 2.25
          Mean value_function loss: 110.3600
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 68.8175
                       Mean reward: 489.23
               Mean episode length: 236.92
    Episode_Reward/reaching_object: 1.5183
    Episode_Reward/rotating_object: 94.0013
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 2.20s
                      Time elapsed: 00:20:26
                               ETA: 00:38:00

################################################################################
                     [1m Learning iteration 525/1500 [0m                      

                       Computation: 45396 steps/s (collection: 2.064s, learning 0.101s)
             Mean action noise std: 2.25
          Mean value_function loss: 102.0505
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 68.8332
                       Mean reward: 474.51
               Mean episode length: 230.69
    Episode_Reward/reaching_object: 1.5387
    Episode_Reward/rotating_object: 93.2107
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 2.17s
                      Time elapsed: 00:20:28
                               ETA: 00:37:57

################################################################################
                     [1m Learning iteration 526/1500 [0m                      

                       Computation: 44321 steps/s (collection: 2.119s, learning 0.099s)
             Mean action noise std: 2.25
          Mean value_function loss: 107.9454
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 68.8498
                       Mean reward: 505.20
               Mean episode length: 240.93
    Episode_Reward/reaching_object: 1.5429
    Episode_Reward/rotating_object: 95.2272
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 2.22s
                      Time elapsed: 00:20:30
                               ETA: 00:37:55

################################################################################
                     [1m Learning iteration 527/1500 [0m                      

                       Computation: 45419 steps/s (collection: 2.065s, learning 0.100s)
             Mean action noise std: 2.26
          Mean value_function loss: 116.5805
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 68.8657
                       Mean reward: 450.79
               Mean episode length: 232.72
    Episode_Reward/reaching_object: 1.5356
    Episode_Reward/rotating_object: 93.5662
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 2.16s
                      Time elapsed: 00:20:33
                               ETA: 00:37:52

################################################################################
                     [1m Learning iteration 528/1500 [0m                      

                       Computation: 43721 steps/s (collection: 2.096s, learning 0.153s)
             Mean action noise std: 2.26
          Mean value_function loss: 105.9033
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 68.8807
                       Mean reward: 515.89
               Mean episode length: 241.63
    Episode_Reward/reaching_object: 1.5582
    Episode_Reward/rotating_object: 94.6489
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 2.25s
                      Time elapsed: 00:20:35
                               ETA: 00:37:49

################################################################################
                     [1m Learning iteration 529/1500 [0m                      

                       Computation: 44114 steps/s (collection: 2.128s, learning 0.101s)
             Mean action noise std: 2.26
          Mean value_function loss: 99.6617
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 68.8939
                       Mean reward: 491.65
               Mean episode length: 235.44
    Episode_Reward/reaching_object: 1.5490
    Episode_Reward/rotating_object: 92.8135
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 2.23s
                      Time elapsed: 00:20:37
                               ETA: 00:37:47

################################################################################
                     [1m Learning iteration 530/1500 [0m                      

                       Computation: 37579 steps/s (collection: 2.478s, learning 0.138s)
             Mean action noise std: 2.26
          Mean value_function loss: 115.4338
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 68.9044
                       Mean reward: 494.13
               Mean episode length: 237.93
    Episode_Reward/reaching_object: 1.5577
    Episode_Reward/rotating_object: 97.6928
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 2.62s
                      Time elapsed: 00:20:40
                               ETA: 00:37:45

################################################################################
                     [1m Learning iteration 531/1500 [0m                      

                       Computation: 42131 steps/s (collection: 2.195s, learning 0.139s)
             Mean action noise std: 2.26
          Mean value_function loss: 120.9208
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 68.9141
                       Mean reward: 529.22
               Mean episode length: 235.05
    Episode_Reward/reaching_object: 1.5009
    Episode_Reward/rotating_object: 94.1494
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 2.33s
                      Time elapsed: 00:20:42
                               ETA: 00:37:43

################################################################################
                     [1m Learning iteration 532/1500 [0m                      

                       Computation: 43985 steps/s (collection: 2.136s, learning 0.099s)
             Mean action noise std: 2.26
          Mean value_function loss: 113.7885
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 68.9260
                       Mean reward: 486.20
               Mean episode length: 233.96
    Episode_Reward/reaching_object: 1.5464
    Episode_Reward/rotating_object: 94.0057
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 2.23s
                      Time elapsed: 00:20:44
                               ETA: 00:37:40

################################################################################
                     [1m Learning iteration 533/1500 [0m                      

                       Computation: 44681 steps/s (collection: 2.102s, learning 0.098s)
             Mean action noise std: 2.26
          Mean value_function loss: 122.2408
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 68.9405
                       Mean reward: 443.45
               Mean episode length: 216.10
    Episode_Reward/reaching_object: 1.4894
    Episode_Reward/rotating_object: 91.0926
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 2.20s
                      Time elapsed: 00:20:46
                               ETA: 00:37:38

################################################################################
                     [1m Learning iteration 534/1500 [0m                      

                       Computation: 44111 steps/s (collection: 2.127s, learning 0.102s)
             Mean action noise std: 2.26
          Mean value_function loss: 126.3953
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 68.9606
                       Mean reward: 469.93
               Mean episode length: 228.50
    Episode_Reward/reaching_object: 1.5050
    Episode_Reward/rotating_object: 93.4375
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 2.23s
                      Time elapsed: 00:20:49
                               ETA: 00:37:35

################################################################################
                     [1m Learning iteration 535/1500 [0m                      

                       Computation: 41400 steps/s (collection: 2.210s, learning 0.165s)
             Mean action noise std: 2.27
          Mean value_function loss: 127.6294
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 68.9788
                       Mean reward: 459.32
               Mean episode length: 229.10
    Episode_Reward/reaching_object: 1.5678
    Episode_Reward/rotating_object: 96.7302
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0466
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 2.37s
                      Time elapsed: 00:20:51
                               ETA: 00:37:33

################################################################################
                     [1m Learning iteration 536/1500 [0m                      

                       Computation: 43897 steps/s (collection: 2.141s, learning 0.099s)
             Mean action noise std: 2.27
          Mean value_function loss: 135.9737
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 68.9974
                       Mean reward: 486.70
               Mean episode length: 225.88
    Episode_Reward/reaching_object: 1.5326
    Episode_Reward/rotating_object: 91.9218
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 2.24s
                      Time elapsed: 00:20:53
                               ETA: 00:37:30

################################################################################
                     [1m Learning iteration 537/1500 [0m                      

                       Computation: 43794 steps/s (collection: 2.146s, learning 0.099s)
             Mean action noise std: 2.27
          Mean value_function loss: 128.4741
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 69.0192
                       Mean reward: 479.48
               Mean episode length: 227.16
    Episode_Reward/reaching_object: 1.5256
    Episode_Reward/rotating_object: 93.6660
        Episode_Reward/action_rate: -0.0355
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 2.24s
                      Time elapsed: 00:20:56
                               ETA: 00:37:28

################################################################################
                     [1m Learning iteration 538/1500 [0m                      

                       Computation: 44507 steps/s (collection: 2.112s, learning 0.097s)
             Mean action noise std: 2.27
          Mean value_function loss: 115.2218
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 69.0314
                       Mean reward: 509.58
               Mean episode length: 228.09
    Episode_Reward/reaching_object: 1.5495
    Episode_Reward/rotating_object: 97.6803
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 2.21s
                      Time elapsed: 00:20:58
                               ETA: 00:37:25

################################################################################
                     [1m Learning iteration 539/1500 [0m                      

                       Computation: 41840 steps/s (collection: 2.184s, learning 0.166s)
             Mean action noise std: 2.27
          Mean value_function loss: 126.1847
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 69.0409
                       Mean reward: 464.36
               Mean episode length: 226.70
    Episode_Reward/reaching_object: 1.5586
    Episode_Reward/rotating_object: 94.4698
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 2.35s
                      Time elapsed: 00:21:00
                               ETA: 00:37:23

################################################################################
                     [1m Learning iteration 540/1500 [0m                      

                       Computation: 42152 steps/s (collection: 2.236s, learning 0.097s)
             Mean action noise std: 2.27
          Mean value_function loss: 126.5916
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 69.0555
                       Mean reward: 450.99
               Mean episode length: 216.49
    Episode_Reward/reaching_object: 1.5324
    Episode_Reward/rotating_object: 91.9589
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 2.33s
                      Time elapsed: 00:21:02
                               ETA: 00:37:21

################################################################################
                     [1m Learning iteration 541/1500 [0m                      

                       Computation: 41451 steps/s (collection: 2.256s, learning 0.116s)
             Mean action noise std: 2.27
          Mean value_function loss: 112.5318
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 69.0817
                       Mean reward: 491.68
               Mean episode length: 226.87
    Episode_Reward/reaching_object: 1.5438
    Episode_Reward/rotating_object: 96.1360
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 2.37s
                      Time elapsed: 00:21:05
                               ETA: 00:37:18

################################################################################
                     [1m Learning iteration 542/1500 [0m                      

                       Computation: 43406 steps/s (collection: 2.148s, learning 0.117s)
             Mean action noise std: 2.27
          Mean value_function loss: 115.9369
               Mean surrogate loss: 0.0014
                 Mean entropy loss: 69.0950
                       Mean reward: 425.23
               Mean episode length: 218.80
    Episode_Reward/reaching_object: 1.5286
    Episode_Reward/rotating_object: 94.5981
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 2.26s
                      Time elapsed: 00:21:07
                               ETA: 00:37:16

################################################################################
                     [1m Learning iteration 543/1500 [0m                      

                       Computation: 40504 steps/s (collection: 2.288s, learning 0.139s)
             Mean action noise std: 2.27
          Mean value_function loss: 118.0202
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 69.0980
                       Mean reward: 458.36
               Mean episode length: 227.69
    Episode_Reward/reaching_object: 1.5408
    Episode_Reward/rotating_object: 95.9846
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 2.43s
                      Time elapsed: 00:21:10
                               ETA: 00:37:14

################################################################################
                     [1m Learning iteration 544/1500 [0m                      

                       Computation: 42356 steps/s (collection: 2.210s, learning 0.111s)
             Mean action noise std: 2.28
          Mean value_function loss: 114.4806
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 69.1050
                       Mean reward: 485.82
               Mean episode length: 225.64
    Episode_Reward/reaching_object: 1.5477
    Episode_Reward/rotating_object: 97.3188
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 2.32s
                      Time elapsed: 00:21:12
                               ETA: 00:37:11

################################################################################
                     [1m Learning iteration 545/1500 [0m                      

                       Computation: 44685 steps/s (collection: 2.100s, learning 0.100s)
             Mean action noise std: 2.28
          Mean value_function loss: 108.6322
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 69.1166
                       Mean reward: 516.51
               Mean episode length: 232.39
    Episode_Reward/reaching_object: 1.5682
    Episode_Reward/rotating_object: 103.3198
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 2.20s
                      Time elapsed: 00:21:14
                               ETA: 00:37:09

################################################################################
                     [1m Learning iteration 546/1500 [0m                      

                       Computation: 43386 steps/s (collection: 2.170s, learning 0.096s)
             Mean action noise std: 2.28
          Mean value_function loss: 116.2139
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 69.1328
                       Mean reward: 506.48
               Mean episode length: 237.93
    Episode_Reward/reaching_object: 1.6003
    Episode_Reward/rotating_object: 100.8512
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 2.27s
                      Time elapsed: 00:21:16
                               ETA: 00:37:06

################################################################################
                     [1m Learning iteration 547/1500 [0m                      

                       Computation: 43363 steps/s (collection: 2.160s, learning 0.107s)
             Mean action noise std: 2.28
          Mean value_function loss: 119.1135
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 69.1488
                       Mean reward: 507.33
               Mean episode length: 231.95
    Episode_Reward/reaching_object: 1.5468
    Episode_Reward/rotating_object: 94.4499
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 2.27s
                      Time elapsed: 00:21:19
                               ETA: 00:37:04

################################################################################
                     [1m Learning iteration 548/1500 [0m                      

                       Computation: 43377 steps/s (collection: 2.159s, learning 0.108s)
             Mean action noise std: 2.28
          Mean value_function loss: 122.0493
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 69.1651
                       Mean reward: 489.81
               Mean episode length: 226.51
    Episode_Reward/reaching_object: 1.5401
    Episode_Reward/rotating_object: 98.8396
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 2.27s
                      Time elapsed: 00:21:21
                               ETA: 00:37:01

################################################################################
                     [1m Learning iteration 549/1500 [0m                      

                       Computation: 42239 steps/s (collection: 2.151s, learning 0.177s)
             Mean action noise std: 2.28
          Mean value_function loss: 119.2277
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 69.1813
                       Mean reward: 505.47
               Mean episode length: 224.66
    Episode_Reward/reaching_object: 1.4867
    Episode_Reward/rotating_object: 92.7669
        Episode_Reward/action_rate: -0.0355
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 2.33s
                      Time elapsed: 00:21:23
                               ETA: 00:36:59

################################################################################
                     [1m Learning iteration 550/1500 [0m                      

                       Computation: 41847 steps/s (collection: 2.255s, learning 0.094s)
             Mean action noise std: 2.28
          Mean value_function loss: 124.6093
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 69.2028
                       Mean reward: 481.87
               Mean episode length: 224.76
    Episode_Reward/reaching_object: 1.5150
    Episode_Reward/rotating_object: 96.6855
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 2.35s
                      Time elapsed: 00:21:26
                               ETA: 00:36:57

################################################################################
                     [1m Learning iteration 551/1500 [0m                      

                       Computation: 42291 steps/s (collection: 2.201s, learning 0.124s)
             Mean action noise std: 2.29
          Mean value_function loss: 117.6768
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 69.2174
                       Mean reward: 456.61
               Mean episode length: 215.36
    Episode_Reward/reaching_object: 1.5436
    Episode_Reward/rotating_object: 96.0393
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 2.32s
                      Time elapsed: 00:21:28
                               ETA: 00:36:54

################################################################################
                     [1m Learning iteration 552/1500 [0m                      

                       Computation: 39509 steps/s (collection: 2.382s, learning 0.106s)
             Mean action noise std: 2.29
          Mean value_function loss: 133.0107
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 69.2357
                       Mean reward: 468.28
               Mean episode length: 220.55
    Episode_Reward/reaching_object: 1.5280
    Episode_Reward/rotating_object: 95.6101
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 2.49s
                      Time elapsed: 00:21:30
                               ETA: 00:36:52

################################################################################
                     [1m Learning iteration 553/1500 [0m                      

                       Computation: 43105 steps/s (collection: 2.174s, learning 0.107s)
             Mean action noise std: 2.29
          Mean value_function loss: 122.3066
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 69.2554
                       Mean reward: 510.30
               Mean episode length: 231.71
    Episode_Reward/reaching_object: 1.5825
    Episode_Reward/rotating_object: 99.7416
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 2.28s
                      Time elapsed: 00:21:33
                               ETA: 00:36:50

################################################################################
                     [1m Learning iteration 554/1500 [0m                      

                       Computation: 42894 steps/s (collection: 2.196s, learning 0.096s)
             Mean action noise std: 2.29
          Mean value_function loss: 108.4837
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 69.2742
                       Mean reward: 506.45
               Mean episode length: 225.18
    Episode_Reward/reaching_object: 1.5532
    Episode_Reward/rotating_object: 100.6784
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 2.29s
                      Time elapsed: 00:21:35
                               ETA: 00:36:48

################################################################################
                     [1m Learning iteration 555/1500 [0m                      

                       Computation: 41341 steps/s (collection: 2.190s, learning 0.188s)
             Mean action noise std: 2.29
          Mean value_function loss: 109.2089
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 69.2910
                       Mean reward: 427.02
               Mean episode length: 208.76
    Episode_Reward/reaching_object: 1.5394
    Episode_Reward/rotating_object: 94.7030
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 2.38s
                      Time elapsed: 00:21:37
                               ETA: 00:36:45

################################################################################
                     [1m Learning iteration 556/1500 [0m                      

                       Computation: 41461 steps/s (collection: 2.275s, learning 0.096s)
             Mean action noise std: 2.29
          Mean value_function loss: 108.0647
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 69.3153
                       Mean reward: 475.39
               Mean episode length: 233.56
    Episode_Reward/reaching_object: 1.5556
    Episode_Reward/rotating_object: 97.8762
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 2.37s
                      Time elapsed: 00:21:40
                               ETA: 00:36:43

################################################################################
                     [1m Learning iteration 557/1500 [0m                      

                       Computation: 42196 steps/s (collection: 2.213s, learning 0.117s)
             Mean action noise std: 2.29
          Mean value_function loss: 113.4673
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 69.3361
                       Mean reward: 490.74
               Mean episode length: 224.97
    Episode_Reward/reaching_object: 1.5700
    Episode_Reward/rotating_object: 100.2547
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 2.33s
                      Time elapsed: 00:21:42
                               ETA: 00:36:41

################################################################################
                     [1m Learning iteration 558/1500 [0m                      

                       Computation: 40588 steps/s (collection: 2.274s, learning 0.148s)
             Mean action noise std: 2.30
          Mean value_function loss: 115.3258
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 69.3566
                       Mean reward: 527.28
               Mean episode length: 228.53
    Episode_Reward/reaching_object: 1.5482
    Episode_Reward/rotating_object: 99.6138
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 2.42s
                      Time elapsed: 00:21:44
                               ETA: 00:36:38

################################################################################
                     [1m Learning iteration 559/1500 [0m                      

                       Computation: 41059 steps/s (collection: 2.278s, learning 0.116s)
             Mean action noise std: 2.30
          Mean value_function loss: 116.8650
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 69.3752
                       Mean reward: 491.81
               Mean episode length: 227.22
    Episode_Reward/reaching_object: 1.5405
    Episode_Reward/rotating_object: 96.0352
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 2.39s
                      Time elapsed: 00:21:47
                               ETA: 00:36:36

################################################################################
                     [1m Learning iteration 560/1500 [0m                      

                       Computation: 42483 steps/s (collection: 2.180s, learning 0.134s)
             Mean action noise std: 2.30
          Mean value_function loss: 115.4367
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 69.3861
                       Mean reward: 450.76
               Mean episode length: 215.98
    Episode_Reward/reaching_object: 1.5510
    Episode_Reward/rotating_object: 98.6646
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 2.31s
                      Time elapsed: 00:21:49
                               ETA: 00:36:34

################################################################################
                     [1m Learning iteration 561/1500 [0m                      

                       Computation: 41106 steps/s (collection: 2.192s, learning 0.200s)
             Mean action noise std: 2.30
          Mean value_function loss: 115.4624
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 69.4082
                       Mean reward: 516.01
               Mean episode length: 227.77
    Episode_Reward/reaching_object: 1.5358
    Episode_Reward/rotating_object: 98.7406
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 2.39s
                      Time elapsed: 00:21:52
                               ETA: 00:36:32

################################################################################
                     [1m Learning iteration 562/1500 [0m                      

                       Computation: 38151 steps/s (collection: 2.438s, learning 0.139s)
             Mean action noise std: 2.30
          Mean value_function loss: 105.3816
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 69.4292
                       Mean reward: 501.89
               Mean episode length: 222.24
    Episode_Reward/reaching_object: 1.5751
    Episode_Reward/rotating_object: 103.1712
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 2.58s
                      Time elapsed: 00:21:54
                               ETA: 00:36:30

################################################################################
                     [1m Learning iteration 563/1500 [0m                      

                       Computation: 42416 steps/s (collection: 2.193s, learning 0.124s)
             Mean action noise std: 2.30
          Mean value_function loss: 103.3443
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 69.4485
                       Mean reward: 490.38
               Mean episode length: 222.21
    Episode_Reward/reaching_object: 1.5454
    Episode_Reward/rotating_object: 94.9297
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 2.32s
                      Time elapsed: 00:21:56
                               ETA: 00:36:27

################################################################################
                     [1m Learning iteration 564/1500 [0m                      

                       Computation: 42297 steps/s (collection: 2.221s, learning 0.103s)
             Mean action noise std: 2.31
          Mean value_function loss: 90.7649
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 69.4630
                       Mean reward: 504.51
               Mean episode length: 232.84
    Episode_Reward/reaching_object: 1.4976
    Episode_Reward/rotating_object: 95.4316
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 2.32s
                      Time elapsed: 00:21:59
                               ETA: 00:36:25

################################################################################
                     [1m Learning iteration 565/1500 [0m                      

                       Computation: 41428 steps/s (collection: 2.242s, learning 0.131s)
             Mean action noise std: 2.31
          Mean value_function loss: 96.2743
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 69.4804
                       Mean reward: 513.60
               Mean episode length: 226.85
    Episode_Reward/reaching_object: 1.5580
    Episode_Reward/rotating_object: 100.9106
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 2.37s
                      Time elapsed: 00:22:01
                               ETA: 00:36:23

################################################################################
                     [1m Learning iteration 566/1500 [0m                      

                       Computation: 43186 steps/s (collection: 2.169s, learning 0.108s)
             Mean action noise std: 2.31
          Mean value_function loss: 90.5035
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 69.5028
                       Mean reward: 508.63
               Mean episode length: 231.03
    Episode_Reward/reaching_object: 1.5380
    Episode_Reward/rotating_object: 98.1272
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 2.28s
                      Time elapsed: 00:22:03
                               ETA: 00:36:20

################################################################################
                     [1m Learning iteration 567/1500 [0m                      

                       Computation: 42202 steps/s (collection: 2.228s, learning 0.101s)
             Mean action noise std: 2.31
          Mean value_function loss: 88.5740
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 69.5197
                       Mean reward: 537.06
               Mean episode length: 236.91
    Episode_Reward/reaching_object: 1.5801
    Episode_Reward/rotating_object: 104.3354
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 2.33s
                      Time elapsed: 00:22:06
                               ETA: 00:36:18

################################################################################
                     [1m Learning iteration 568/1500 [0m                      

                       Computation: 42169 steps/s (collection: 2.219s, learning 0.112s)
             Mean action noise std: 2.31
          Mean value_function loss: 91.4290
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 69.5372
                       Mean reward: 524.55
               Mean episode length: 232.11
    Episode_Reward/reaching_object: 1.5490
    Episode_Reward/rotating_object: 102.2600
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 2.33s
                      Time elapsed: 00:22:08
                               ETA: 00:36:16

################################################################################
                     [1m Learning iteration 569/1500 [0m                      

                       Computation: 41821 steps/s (collection: 2.195s, learning 0.155s)
             Mean action noise std: 2.31
          Mean value_function loss: 83.0436
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 69.5597
                       Mean reward: 553.39
               Mean episode length: 233.65
    Episode_Reward/reaching_object: 1.5590
    Episode_Reward/rotating_object: 105.4646
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 2.35s
                      Time elapsed: 00:22:10
                               ETA: 00:36:13

################################################################################
                     [1m Learning iteration 570/1500 [0m                      

                       Computation: 42759 steps/s (collection: 2.190s, learning 0.109s)
             Mean action noise std: 2.32
          Mean value_function loss: 92.8099
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 69.5862
                       Mean reward: 549.53
               Mean episode length: 240.78
    Episode_Reward/reaching_object: 1.5580
    Episode_Reward/rotating_object: 104.1497
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 2.30s
                      Time elapsed: 00:22:13
                               ETA: 00:36:11

################################################################################
                     [1m Learning iteration 571/1500 [0m                      

                       Computation: 41666 steps/s (collection: 2.252s, learning 0.107s)
             Mean action noise std: 2.32
          Mean value_function loss: 101.5117
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 69.6142
                       Mean reward: 532.13
               Mean episode length: 232.38
    Episode_Reward/reaching_object: 1.5021
    Episode_Reward/rotating_object: 100.0603
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 2.36s
                      Time elapsed: 00:22:15
                               ETA: 00:36:09

################################################################################
                     [1m Learning iteration 572/1500 [0m                      

                       Computation: 42756 steps/s (collection: 2.161s, learning 0.138s)
             Mean action noise std: 2.32
          Mean value_function loss: 106.1165
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 69.6365
                       Mean reward: 495.57
               Mean episode length: 221.89
    Episode_Reward/reaching_object: 1.5308
    Episode_Reward/rotating_object: 101.7619
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 2.30s
                      Time elapsed: 00:22:17
                               ETA: 00:36:06

################################################################################
                     [1m Learning iteration 573/1500 [0m                      

                       Computation: 41118 steps/s (collection: 2.262s, learning 0.129s)
             Mean action noise std: 2.32
          Mean value_function loss: 108.7139
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 69.6565
                       Mean reward: 509.95
               Mean episode length: 222.68
    Episode_Reward/reaching_object: 1.5010
    Episode_Reward/rotating_object: 97.0473
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 2.39s
                      Time elapsed: 00:22:20
                               ETA: 00:36:04

################################################################################
                     [1m Learning iteration 574/1500 [0m                      

                       Computation: 43050 steps/s (collection: 2.182s, learning 0.101s)
             Mean action noise std: 2.32
          Mean value_function loss: 106.8942
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 69.6810
                       Mean reward: 463.01
               Mean episode length: 210.87
    Episode_Reward/reaching_object: 1.4967
    Episode_Reward/rotating_object: 99.7375
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 2.28s
                      Time elapsed: 00:22:22
                               ETA: 00:36:02

################################################################################
                     [1m Learning iteration 575/1500 [0m                      

                       Computation: 41780 steps/s (collection: 2.199s, learning 0.154s)
             Mean action noise std: 2.32
          Mean value_function loss: 93.0508
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 69.6964
                       Mean reward: 497.83
               Mean episode length: 235.39
    Episode_Reward/reaching_object: 1.5594
    Episode_Reward/rotating_object: 100.8502
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 2.35s
                      Time elapsed: 00:22:24
                               ETA: 00:35:59

################################################################################
                     [1m Learning iteration 576/1500 [0m                      

                       Computation: 42772 steps/s (collection: 2.195s, learning 0.103s)
             Mean action noise std: 2.33
          Mean value_function loss: 102.8570
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 69.7150
                       Mean reward: 528.91
               Mean episode length: 232.19
    Episode_Reward/reaching_object: 1.5535
    Episode_Reward/rotating_object: 101.9464
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 2.30s
                      Time elapsed: 00:22:27
                               ETA: 00:35:57

################################################################################
                     [1m Learning iteration 577/1500 [0m                      

                       Computation: 40159 steps/s (collection: 2.301s, learning 0.147s)
             Mean action noise std: 2.33
          Mean value_function loss: 110.1855
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 69.7327
                       Mean reward: 564.97
               Mean episode length: 237.40
    Episode_Reward/reaching_object: 1.5420
    Episode_Reward/rotating_object: 100.8208
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 2.45s
                      Time elapsed: 00:22:29
                               ETA: 00:35:55

################################################################################
                     [1m Learning iteration 578/1500 [0m                      

                       Computation: 42716 steps/s (collection: 2.189s, learning 0.113s)
             Mean action noise std: 2.33
          Mean value_function loss: 115.2169
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 69.7513
                       Mean reward: 506.18
               Mean episode length: 223.45
    Episode_Reward/reaching_object: 1.5414
    Episode_Reward/rotating_object: 101.5481
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 2.30s
                      Time elapsed: 00:22:31
                               ETA: 00:35:52

################################################################################
                     [1m Learning iteration 579/1500 [0m                      

                       Computation: 43166 steps/s (collection: 2.175s, learning 0.103s)
             Mean action noise std: 2.33
          Mean value_function loss: 108.8898
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 69.7596
                       Mean reward: 527.11
               Mean episode length: 229.92
    Episode_Reward/reaching_object: 1.5388
    Episode_Reward/rotating_object: 103.0048
        Episode_Reward/action_rate: -0.0384
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 2.28s
                      Time elapsed: 00:22:34
                               ETA: 00:35:50

################################################################################
                     [1m Learning iteration 580/1500 [0m                      

                       Computation: 42188 steps/s (collection: 2.214s, learning 0.116s)
             Mean action noise std: 2.33
          Mean value_function loss: 111.9658
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 69.7740
                       Mean reward: 507.40
               Mean episode length: 226.52
    Episode_Reward/reaching_object: 1.5590
    Episode_Reward/rotating_object: 100.1605
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 2.33s
                      Time elapsed: 00:22:36
                               ETA: 00:35:48

################################################################################
                     [1m Learning iteration 581/1500 [0m                      

                       Computation: 41884 steps/s (collection: 2.201s, learning 0.146s)
             Mean action noise std: 2.33
          Mean value_function loss: 120.0300
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 69.7911
                       Mean reward: 506.11
               Mean episode length: 223.60
    Episode_Reward/reaching_object: 1.5049
    Episode_Reward/rotating_object: 97.2237
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 2.35s
                      Time elapsed: 00:22:38
                               ETA: 00:35:45

################################################################################
                     [1m Learning iteration 582/1500 [0m                      

                       Computation: 43276 steps/s (collection: 2.178s, learning 0.094s)
             Mean action noise std: 2.33
          Mean value_function loss: 103.5251
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 69.8048
                       Mean reward: 499.35
               Mean episode length: 224.52
    Episode_Reward/reaching_object: 1.5138
    Episode_Reward/rotating_object: 100.6454
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 2.27s
                      Time elapsed: 00:22:41
                               ETA: 00:35:43

################################################################################
                     [1m Learning iteration 583/1500 [0m                      

                       Computation: 41804 steps/s (collection: 2.202s, learning 0.150s)
             Mean action noise std: 2.34
          Mean value_function loss: 106.7899
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 69.8207
                       Mean reward: 561.84
               Mean episode length: 227.82
    Episode_Reward/reaching_object: 1.5841
    Episode_Reward/rotating_object: 106.6190
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 2.35s
                      Time elapsed: 00:22:43
                               ETA: 00:35:40

################################################################################
                     [1m Learning iteration 584/1500 [0m                      

                       Computation: 42272 steps/s (collection: 2.183s, learning 0.142s)
             Mean action noise std: 2.34
          Mean value_function loss: 102.4259
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 69.8357
                       Mean reward: 508.97
               Mean episode length: 224.37
    Episode_Reward/reaching_object: 1.5730
    Episode_Reward/rotating_object: 103.9844
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 2.33s
                      Time elapsed: 00:22:45
                               ETA: 00:35:38

################################################################################
                     [1m Learning iteration 585/1500 [0m                      

                       Computation: 41705 steps/s (collection: 2.232s, learning 0.126s)
             Mean action noise std: 2.34
          Mean value_function loss: 100.9203
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 69.8426
                       Mean reward: 494.26
               Mean episode length: 216.75
    Episode_Reward/reaching_object: 1.5451
    Episode_Reward/rotating_object: 104.3810
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 2.36s
                      Time elapsed: 00:22:48
                               ETA: 00:35:36

################################################################################
                     [1m Learning iteration 586/1500 [0m                      

                       Computation: 42464 steps/s (collection: 2.211s, learning 0.104s)
             Mean action noise std: 2.34
          Mean value_function loss: 108.3559
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 69.8573
                       Mean reward: 511.79
               Mean episode length: 227.34
    Episode_Reward/reaching_object: 1.5825
    Episode_Reward/rotating_object: 103.5473
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0466
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 2.31s
                      Time elapsed: 00:22:50
                               ETA: 00:35:33

################################################################################
                     [1m Learning iteration 587/1500 [0m                      

                       Computation: 41529 steps/s (collection: 2.202s, learning 0.165s)
             Mean action noise std: 2.34
          Mean value_function loss: 118.8015
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 69.8827
                       Mean reward: 515.50
               Mean episode length: 222.83
    Episode_Reward/reaching_object: 1.5504
    Episode_Reward/rotating_object: 102.1584
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 2.37s
                      Time elapsed: 00:22:52
                               ETA: 00:35:31

################################################################################
                     [1m Learning iteration 588/1500 [0m                      

                       Computation: 42305 steps/s (collection: 2.194s, learning 0.130s)
             Mean action noise std: 2.34
          Mean value_function loss: 109.1439
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 69.9107
                       Mean reward: 532.41
               Mean episode length: 228.77
    Episode_Reward/reaching_object: 1.5659
    Episode_Reward/rotating_object: 107.4847
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 2.32s
                      Time elapsed: 00:22:55
                               ETA: 00:35:29

################################################################################
                     [1m Learning iteration 589/1500 [0m                      

                       Computation: 42130 steps/s (collection: 2.232s, learning 0.101s)
             Mean action noise std: 2.34
          Mean value_function loss: 115.3485
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 69.9268
                       Mean reward: 548.07
               Mean episode length: 234.50
    Episode_Reward/reaching_object: 1.5588
    Episode_Reward/rotating_object: 103.4303
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 2.33s
                      Time elapsed: 00:22:57
                               ETA: 00:35:26

################################################################################
                     [1m Learning iteration 590/1500 [0m                      

                       Computation: 41259 steps/s (collection: 2.206s, learning 0.177s)
             Mean action noise std: 2.35
          Mean value_function loss: 117.3742
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 69.9542
                       Mean reward: 487.32
               Mean episode length: 222.99
    Episode_Reward/reaching_object: 1.5383
    Episode_Reward/rotating_object: 100.7337
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 2.38s
                      Time elapsed: 00:22:59
                               ETA: 00:35:24

################################################################################
                     [1m Learning iteration 591/1500 [0m                      

                       Computation: 42725 steps/s (collection: 2.190s, learning 0.111s)
             Mean action noise std: 2.35
          Mean value_function loss: 112.2536
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 69.9784
                       Mean reward: 566.50
               Mean episode length: 231.73
    Episode_Reward/reaching_object: 1.5540
    Episode_Reward/rotating_object: 106.1996
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 2.30s
                      Time elapsed: 00:23:02
                               ETA: 00:35:22

################################################################################
                     [1m Learning iteration 592/1500 [0m                      

                       Computation: 43635 steps/s (collection: 2.154s, learning 0.099s)
             Mean action noise std: 2.35
          Mean value_function loss: 113.7564
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 69.9943
                       Mean reward: 512.22
               Mean episode length: 229.04
    Episode_Reward/reaching_object: 1.5530
    Episode_Reward/rotating_object: 104.3646
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 2.25s
                      Time elapsed: 00:23:04
                               ETA: 00:35:19

################################################################################
                     [1m Learning iteration 593/1500 [0m                      

                       Computation: 43460 steps/s (collection: 2.147s, learning 0.115s)
             Mean action noise std: 2.35
          Mean value_function loss: 107.6359
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 70.0098
                       Mean reward: 544.10
               Mean episode length: 231.20
    Episode_Reward/reaching_object: 1.5469
    Episode_Reward/rotating_object: 104.2457
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 2.26s
                      Time elapsed: 00:23:06
                               ETA: 00:35:17

################################################################################
                     [1m Learning iteration 594/1500 [0m                      

                       Computation: 41223 steps/s (collection: 2.252s, learning 0.133s)
             Mean action noise std: 2.35
          Mean value_function loss: 112.7398
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 70.0303
                       Mean reward: 459.16
               Mean episode length: 211.69
    Episode_Reward/reaching_object: 1.5040
    Episode_Reward/rotating_object: 98.0192
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 2.38s
                      Time elapsed: 00:23:09
                               ETA: 00:35:15

################################################################################
                     [1m Learning iteration 595/1500 [0m                      

                       Computation: 42007 steps/s (collection: 2.234s, learning 0.107s)
             Mean action noise std: 2.35
          Mean value_function loss: 115.5575
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 70.0544
                       Mean reward: 513.29
               Mean episode length: 225.82
    Episode_Reward/reaching_object: 1.5162
    Episode_Reward/rotating_object: 99.2692
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 2.34s
                      Time elapsed: 00:23:11
                               ETA: 00:35:12

################################################################################
                     [1m Learning iteration 596/1500 [0m                      

                       Computation: 40993 steps/s (collection: 2.215s, learning 0.183s)
             Mean action noise std: 2.36
          Mean value_function loss: 117.6973
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 70.0705
                       Mean reward: 487.76
               Mean episode length: 224.85
    Episode_Reward/reaching_object: 1.5228
    Episode_Reward/rotating_object: 98.8393
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 2.40s
                      Time elapsed: 00:23:13
                               ETA: 00:35:10

################################################################################
                     [1m Learning iteration 597/1500 [0m                      

                       Computation: 41958 steps/s (collection: 2.212s, learning 0.131s)
             Mean action noise std: 2.36
          Mean value_function loss: 106.5854
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 70.0921
                       Mean reward: 511.24
               Mean episode length: 222.80
    Episode_Reward/reaching_object: 1.5184
    Episode_Reward/rotating_object: 100.4535
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 2.34s
                      Time elapsed: 00:23:16
                               ETA: 00:35:08

################################################################################
                     [1m Learning iteration 598/1500 [0m                      

                       Computation: 43845 steps/s (collection: 2.143s, learning 0.099s)
             Mean action noise std: 2.36
          Mean value_function loss: 97.6270
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 70.1131
                       Mean reward: 518.73
               Mean episode length: 219.28
    Episode_Reward/reaching_object: 1.5503
    Episode_Reward/rotating_object: 104.8276
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 2.24s
                      Time elapsed: 00:23:18
                               ETA: 00:35:05

################################################################################
                     [1m Learning iteration 599/1500 [0m                      

                       Computation: 43180 steps/s (collection: 2.156s, learning 0.121s)
             Mean action noise std: 2.36
          Mean value_function loss: 111.1068
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 70.1295
                       Mean reward: 537.39
               Mean episode length: 223.91
    Episode_Reward/reaching_object: 1.5523
    Episode_Reward/rotating_object: 104.3340
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 2.28s
                      Time elapsed: 00:23:20
                               ETA: 00:35:03

################################################################################
                     [1m Learning iteration 600/1500 [0m                      

                       Computation: 43147 steps/s (collection: 2.160s, learning 0.119s)
             Mean action noise std: 2.36
          Mean value_function loss: 111.9689
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 70.1433
                       Mean reward: 529.33
               Mean episode length: 231.23
    Episode_Reward/reaching_object: 1.5325
    Episode_Reward/rotating_object: 104.8909
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 2.28s
                      Time elapsed: 00:23:22
                               ETA: 00:35:00

################################################################################
                     [1m Learning iteration 601/1500 [0m                      

                       Computation: 42069 steps/s (collection: 2.222s, learning 0.115s)
             Mean action noise std: 2.36
          Mean value_function loss: 110.2585
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 70.1664
                       Mean reward: 467.40
               Mean episode length: 212.73
    Episode_Reward/reaching_object: 1.4942
    Episode_Reward/rotating_object: 97.2151
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 2.34s
                      Time elapsed: 00:23:25
                               ETA: 00:34:58

################################################################################
                     [1m Learning iteration 602/1500 [0m                      

                       Computation: 43643 steps/s (collection: 2.150s, learning 0.103s)
             Mean action noise std: 2.37
          Mean value_function loss: 93.3193
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 70.1909
                       Mean reward: 512.17
               Mean episode length: 225.07
    Episode_Reward/reaching_object: 1.5369
    Episode_Reward/rotating_object: 103.5712
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 2.25s
                      Time elapsed: 00:23:27
                               ETA: 00:34:56

################################################################################
                     [1m Learning iteration 603/1500 [0m                      

                       Computation: 42307 steps/s (collection: 2.213s, learning 0.111s)
             Mean action noise std: 2.37
          Mean value_function loss: 97.7230
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 70.2146
                       Mean reward: 522.75
               Mean episode length: 229.38
    Episode_Reward/reaching_object: 1.5255
    Episode_Reward/rotating_object: 103.6353
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 2.32s
                      Time elapsed: 00:23:29
                               ETA: 00:34:53

################################################################################
                     [1m Learning iteration 604/1500 [0m                      

                       Computation: 42861 steps/s (collection: 2.182s, learning 0.111s)
             Mean action noise std: 2.37
          Mean value_function loss: 93.8739
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 70.2411
                       Mean reward: 536.65
               Mean episode length: 232.96
    Episode_Reward/reaching_object: 1.5690
    Episode_Reward/rotating_object: 106.2437
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 2.29s
                      Time elapsed: 00:23:32
                               ETA: 00:34:51

################################################################################
                     [1m Learning iteration 605/1500 [0m                      

                       Computation: 40860 steps/s (collection: 2.312s, learning 0.094s)
             Mean action noise std: 2.37
          Mean value_function loss: 86.8843
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 70.2560
                       Mean reward: 528.53
               Mean episode length: 226.99
    Episode_Reward/reaching_object: 1.5446
    Episode_Reward/rotating_object: 104.6585
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 2.41s
                      Time elapsed: 00:23:34
                               ETA: 00:34:49

################################################################################
                     [1m Learning iteration 606/1500 [0m                      

                       Computation: 43736 steps/s (collection: 2.134s, learning 0.114s)
             Mean action noise std: 2.37
          Mean value_function loss: 85.6580
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 70.2733
                       Mean reward: 563.43
               Mean episode length: 227.44
    Episode_Reward/reaching_object: 1.5717
    Episode_Reward/rotating_object: 109.9480
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 2.25s
                      Time elapsed: 00:23:36
                               ETA: 00:34:46

################################################################################
                     [1m Learning iteration 607/1500 [0m                      

                       Computation: 39048 steps/s (collection: 2.330s, learning 0.188s)
             Mean action noise std: 2.37
          Mean value_function loss: 88.3391
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 70.2898
                       Mean reward: 513.64
               Mean episode length: 228.61
    Episode_Reward/reaching_object: 1.5391
    Episode_Reward/rotating_object: 103.7438
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 2.52s
                      Time elapsed: 00:23:39
                               ETA: 00:34:44

################################################################################
                     [1m Learning iteration 608/1500 [0m                      

                       Computation: 43489 steps/s (collection: 2.160s, learning 0.101s)
             Mean action noise std: 2.38
          Mean value_function loss: 91.8935
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 70.3195
                       Mean reward: 548.53
               Mean episode length: 233.43
    Episode_Reward/reaching_object: 1.5497
    Episode_Reward/rotating_object: 109.0225
        Episode_Reward/action_rate: -0.0401
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 2.26s
                      Time elapsed: 00:23:41
                               ETA: 00:34:42

################################################################################
                     [1m Learning iteration 609/1500 [0m                      

                       Computation: 43742 steps/s (collection: 2.128s, learning 0.119s)
             Mean action noise std: 2.38
          Mean value_function loss: 88.3209
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 70.3594
                       Mean reward: 508.69
               Mean episode length: 222.82
    Episode_Reward/reaching_object: 1.5565
    Episode_Reward/rotating_object: 106.4163
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 2.25s
                      Time elapsed: 00:23:43
                               ETA: 00:34:39

################################################################################
                     [1m Learning iteration 610/1500 [0m                      

                       Computation: 42324 steps/s (collection: 2.159s, learning 0.163s)
             Mean action noise std: 2.38
          Mean value_function loss: 90.6991
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 70.3843
                       Mean reward: 542.83
               Mean episode length: 226.92
    Episode_Reward/reaching_object: 1.4941
    Episode_Reward/rotating_object: 101.7015
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 2.32s
                      Time elapsed: 00:23:46
                               ETA: 00:34:37

################################################################################
                     [1m Learning iteration 611/1500 [0m                      

                       Computation: 44033 steps/s (collection: 2.131s, learning 0.101s)
             Mean action noise std: 2.38
          Mean value_function loss: 96.6390
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 70.4043
                       Mean reward: 590.16
               Mean episode length: 238.75
    Episode_Reward/reaching_object: 1.5300
    Episode_Reward/rotating_object: 106.6279
        Episode_Reward/action_rate: -0.0401
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 2.23s
                      Time elapsed: 00:23:48
                               ETA: 00:34:34

################################################################################
                     [1m Learning iteration 612/1500 [0m                      

                       Computation: 42926 steps/s (collection: 2.166s, learning 0.124s)
             Mean action noise std: 2.39
          Mean value_function loss: 88.8494
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 70.4277
                       Mean reward: 559.81
               Mean episode length: 238.48
    Episode_Reward/reaching_object: 1.5329
    Episode_Reward/rotating_object: 106.1957
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 2.29s
                      Time elapsed: 00:23:50
                               ETA: 00:34:32

################################################################################
                     [1m Learning iteration 613/1500 [0m                      

                       Computation: 42926 steps/s (collection: 2.162s, learning 0.128s)
             Mean action noise std: 2.39
          Mean value_function loss: 91.6977
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 70.4534
                       Mean reward: 520.85
               Mean episode length: 226.86
    Episode_Reward/reaching_object: 1.5205
    Episode_Reward/rotating_object: 102.9484
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 2.29s
                      Time elapsed: 00:23:53
                               ETA: 00:34:30

################################################################################
                     [1m Learning iteration 614/1500 [0m                      

                       Computation: 43981 steps/s (collection: 2.130s, learning 0.106s)
             Mean action noise std: 2.39
          Mean value_function loss: 95.8872
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 70.4763
                       Mean reward: 504.14
               Mean episode length: 217.02
    Episode_Reward/reaching_object: 1.5116
    Episode_Reward/rotating_object: 104.8171
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 2.24s
                      Time elapsed: 00:23:55
                               ETA: 00:34:27

################################################################################
                     [1m Learning iteration 615/1500 [0m                      

                       Computation: 43612 steps/s (collection: 2.147s, learning 0.107s)
             Mean action noise std: 2.39
          Mean value_function loss: 96.2096
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 70.5121
                       Mean reward: 524.91
               Mean episode length: 224.82
    Episode_Reward/reaching_object: 1.5374
    Episode_Reward/rotating_object: 104.8954
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 2.25s
                      Time elapsed: 00:23:57
                               ETA: 00:34:25

################################################################################
                     [1m Learning iteration 616/1500 [0m                      

                       Computation: 43475 steps/s (collection: 2.153s, learning 0.108s)
             Mean action noise std: 2.40
          Mean value_function loss: 100.3085
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 70.5484
                       Mean reward: 551.75
               Mean episode length: 227.56
    Episode_Reward/reaching_object: 1.5153
    Episode_Reward/rotating_object: 105.3555
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 2.26s
                      Time elapsed: 00:23:59
                               ETA: 00:34:22

################################################################################
                     [1m Learning iteration 617/1500 [0m                      

                       Computation: 42804 steps/s (collection: 2.189s, learning 0.108s)
             Mean action noise std: 2.40
          Mean value_function loss: 113.5682
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 70.5846
                       Mean reward: 556.27
               Mean episode length: 226.31
    Episode_Reward/reaching_object: 1.5194
    Episode_Reward/rotating_object: 106.6012
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 2.30s
                      Time elapsed: 00:24:02
                               ETA: 00:34:20

################################################################################
                     [1m Learning iteration 618/1500 [0m                      

                       Computation: 41777 steps/s (collection: 2.187s, learning 0.166s)
             Mean action noise std: 2.40
          Mean value_function loss: 98.2733
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 70.6139
                       Mean reward: 535.92
               Mean episode length: 228.66
    Episode_Reward/reaching_object: 1.5078
    Episode_Reward/rotating_object: 105.0779
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 2.35s
                      Time elapsed: 00:24:04
                               ETA: 00:34:18

################################################################################
                     [1m Learning iteration 619/1500 [0m                      

                       Computation: 42461 steps/s (collection: 2.194s, learning 0.122s)
             Mean action noise std: 2.40
          Mean value_function loss: 104.3549
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 70.6449
                       Mean reward: 521.48
               Mean episode length: 225.06
    Episode_Reward/reaching_object: 1.5068
    Episode_Reward/rotating_object: 102.5702
        Episode_Reward/action_rate: -0.0401
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 2.32s
                      Time elapsed: 00:24:06
                               ETA: 00:34:15

################################################################################
                     [1m Learning iteration 620/1500 [0m                      

                       Computation: 43242 steps/s (collection: 2.166s, learning 0.108s)
             Mean action noise std: 2.41
          Mean value_function loss: 92.9198
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 70.6727
                       Mean reward: 564.72
               Mean episode length: 232.65
    Episode_Reward/reaching_object: 1.5400
    Episode_Reward/rotating_object: 107.9343
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 2.27s
                      Time elapsed: 00:24:08
                               ETA: 00:34:13

################################################################################
                     [1m Learning iteration 621/1500 [0m                      

                       Computation: 43616 steps/s (collection: 2.156s, learning 0.098s)
             Mean action noise std: 2.41
          Mean value_function loss: 98.8550
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 70.6937
                       Mean reward: 554.46
               Mean episode length: 223.85
    Episode_Reward/reaching_object: 1.5284
    Episode_Reward/rotating_object: 106.4327
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 2.25s
                      Time elapsed: 00:24:11
                               ETA: 00:34:10

################################################################################
                     [1m Learning iteration 622/1500 [0m                      

                       Computation: 43486 steps/s (collection: 2.153s, learning 0.107s)
             Mean action noise std: 2.41
          Mean value_function loss: 89.7868
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 70.7089
                       Mean reward: 549.95
               Mean episode length: 227.71
    Episode_Reward/reaching_object: 1.5709
    Episode_Reward/rotating_object: 111.0632
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 2.26s
                      Time elapsed: 00:24:13
                               ETA: 00:34:08

################################################################################
                     [1m Learning iteration 623/1500 [0m                      

                       Computation: 41082 steps/s (collection: 2.267s, learning 0.126s)
             Mean action noise std: 2.41
          Mean value_function loss: 97.0300
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 70.7340
                       Mean reward: 577.45
               Mean episode length: 235.52
    Episode_Reward/reaching_object: 1.5697
    Episode_Reward/rotating_object: 110.6478
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 2.39s
                      Time elapsed: 00:24:15
                               ETA: 00:34:06

################################################################################
                     [1m Learning iteration 624/1500 [0m                      

                       Computation: 41856 steps/s (collection: 2.236s, learning 0.113s)
             Mean action noise std: 2.41
          Mean value_function loss: 96.5109
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 70.7676
                       Mean reward: 537.56
               Mean episode length: 226.51
    Episode_Reward/reaching_object: 1.5350
    Episode_Reward/rotating_object: 105.7488
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 2.35s
                      Time elapsed: 00:24:18
                               ETA: 00:34:03

################################################################################
                     [1m Learning iteration 625/1500 [0m                      

                       Computation: 42707 steps/s (collection: 2.173s, learning 0.129s)
             Mean action noise std: 2.42
          Mean value_function loss: 104.5454
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 70.7893
                       Mean reward: 525.78
               Mean episode length: 221.28
    Episode_Reward/reaching_object: 1.5227
    Episode_Reward/rotating_object: 104.2709
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 2.30s
                      Time elapsed: 00:24:20
                               ETA: 00:34:01

################################################################################
                     [1m Learning iteration 626/1500 [0m                      

                       Computation: 42007 steps/s (collection: 2.207s, learning 0.133s)
             Mean action noise std: 2.42
          Mean value_function loss: 97.0835
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 70.8120
                       Mean reward: 542.49
               Mean episode length: 227.59
    Episode_Reward/reaching_object: 1.5674
    Episode_Reward/rotating_object: 108.8985
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 2.34s
                      Time elapsed: 00:24:22
                               ETA: 00:33:59

################################################################################
                     [1m Learning iteration 627/1500 [0m                      

                       Computation: 40740 steps/s (collection: 2.256s, learning 0.157s)
             Mean action noise std: 2.42
          Mean value_function loss: 98.3457
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 70.8344
                       Mean reward: 517.47
               Mean episode length: 223.75
    Episode_Reward/reaching_object: 1.5813
    Episode_Reward/rotating_object: 111.3890
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 2.41s
                      Time elapsed: 00:24:25
                               ETA: 00:33:56

################################################################################
                     [1m Learning iteration 628/1500 [0m                      

                       Computation: 42054 steps/s (collection: 2.237s, learning 0.101s)
             Mean action noise std: 2.42
          Mean value_function loss: 112.9653
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 70.8560
                       Mean reward: 575.87
               Mean episode length: 230.39
    Episode_Reward/reaching_object: 1.5713
    Episode_Reward/rotating_object: 111.9228
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 2.34s
                      Time elapsed: 00:24:27
                               ETA: 00:33:54

################################################################################
                     [1m Learning iteration 629/1500 [0m                      

                       Computation: 41631 steps/s (collection: 2.255s, learning 0.107s)
             Mean action noise std: 2.42
          Mean value_function loss: 108.7697
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 70.8818
                       Mean reward: 511.94
               Mean episode length: 226.55
    Episode_Reward/reaching_object: 1.5538
    Episode_Reward/rotating_object: 107.9477
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 2.36s
                      Time elapsed: 00:24:29
                               ETA: 00:33:52

################################################################################
                     [1m Learning iteration 630/1500 [0m                      

                       Computation: 42790 steps/s (collection: 2.179s, learning 0.118s)
             Mean action noise std: 2.43
          Mean value_function loss: 112.0433
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 70.8998
                       Mean reward: 518.05
               Mean episode length: 214.32
    Episode_Reward/reaching_object: 1.5198
    Episode_Reward/rotating_object: 109.1652
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 2.30s
                      Time elapsed: 00:24:32
                               ETA: 00:33:49

################################################################################
                     [1m Learning iteration 631/1500 [0m                      

                       Computation: 41014 steps/s (collection: 2.291s, learning 0.106s)
             Mean action noise std: 2.43
          Mean value_function loss: 103.9953
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 70.9260
                       Mean reward: 558.66
               Mean episode length: 230.18
    Episode_Reward/reaching_object: 1.5470
    Episode_Reward/rotating_object: 105.8969
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 2.40s
                      Time elapsed: 00:24:34
                               ETA: 00:33:47

################################################################################
                     [1m Learning iteration 632/1500 [0m                      

                       Computation: 42685 steps/s (collection: 2.203s, learning 0.100s)
             Mean action noise std: 2.43
          Mean value_function loss: 105.3000
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 70.9463
                       Mean reward: 575.23
               Mean episode length: 229.78
    Episode_Reward/reaching_object: 1.5629
    Episode_Reward/rotating_object: 110.7878
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 2.30s
                      Time elapsed: 00:24:36
                               ETA: 00:33:45

################################################################################
                     [1m Learning iteration 633/1500 [0m                      

                       Computation: 40971 steps/s (collection: 2.256s, learning 0.143s)
             Mean action noise std: 2.43
          Mean value_function loss: 102.8425
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 70.9607
                       Mean reward: 577.90
               Mean episode length: 231.58
    Episode_Reward/reaching_object: 1.5454
    Episode_Reward/rotating_object: 107.0221
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 2.40s
                      Time elapsed: 00:24:39
                               ETA: 00:33:43

################################################################################
                     [1m Learning iteration 634/1500 [0m                      

                       Computation: 42923 steps/s (collection: 2.187s, learning 0.103s)
             Mean action noise std: 2.43
          Mean value_function loss: 100.6036
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 70.9771
                       Mean reward: 575.63
               Mean episode length: 235.82
    Episode_Reward/reaching_object: 1.5562
    Episode_Reward/rotating_object: 109.7436
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 2.29s
                      Time elapsed: 00:24:41
                               ETA: 00:33:40

################################################################################
                     [1m Learning iteration 635/1500 [0m                      

                       Computation: 42579 steps/s (collection: 2.190s, learning 0.119s)
             Mean action noise std: 2.43
          Mean value_function loss: 110.7769
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 70.9997
                       Mean reward: 523.87
               Mean episode length: 222.08
    Episode_Reward/reaching_object: 1.5455
    Episode_Reward/rotating_object: 106.4595
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 2.31s
                      Time elapsed: 00:24:43
                               ETA: 00:33:38

################################################################################
                     [1m Learning iteration 636/1500 [0m                      

                       Computation: 42231 steps/s (collection: 2.176s, learning 0.152s)
             Mean action noise std: 2.44
          Mean value_function loss: 108.4533
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 71.0317
                       Mean reward: 559.49
               Mean episode length: 232.73
    Episode_Reward/reaching_object: 1.5834
    Episode_Reward/rotating_object: 108.3668
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 2.33s
                      Time elapsed: 00:24:46
                               ETA: 00:33:35

################################################################################
                     [1m Learning iteration 637/1500 [0m                      

                       Computation: 40531 steps/s (collection: 2.275s, learning 0.151s)
             Mean action noise std: 2.44
          Mean value_function loss: 93.6637
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 71.0773
                       Mean reward: 593.46
               Mean episode length: 235.97
    Episode_Reward/reaching_object: 1.5977
    Episode_Reward/rotating_object: 113.3822
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 2.43s
                      Time elapsed: 00:24:48
                               ETA: 00:33:33

################################################################################
                     [1m Learning iteration 638/1500 [0m                      

                       Computation: 39915 steps/s (collection: 2.305s, learning 0.158s)
             Mean action noise std: 2.44
          Mean value_function loss: 119.0421
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 71.1048
                       Mean reward: 540.52
               Mean episode length: 230.90
    Episode_Reward/reaching_object: 1.5551
    Episode_Reward/rotating_object: 108.7316
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 2.46s
                      Time elapsed: 00:24:51
                               ETA: 00:33:31

################################################################################
                     [1m Learning iteration 639/1500 [0m                      

                       Computation: 40612 steps/s (collection: 2.314s, learning 0.107s)
             Mean action noise std: 2.45
          Mean value_function loss: 114.4112
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 71.1306
                       Mean reward: 577.70
               Mean episode length: 230.03
    Episode_Reward/reaching_object: 1.5492
    Episode_Reward/rotating_object: 108.7353
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 2.42s
                      Time elapsed: 00:24:53
                               ETA: 00:33:29

################################################################################
                     [1m Learning iteration 640/1500 [0m                      

                       Computation: 42321 steps/s (collection: 2.179s, learning 0.144s)
             Mean action noise std: 2.45
          Mean value_function loss: 137.7712
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 71.1580
                       Mean reward: 505.50
               Mean episode length: 220.05
    Episode_Reward/reaching_object: 1.5528
    Episode_Reward/rotating_object: 104.5014
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 2.32s
                      Time elapsed: 00:24:55
                               ETA: 00:33:27

################################################################################
                     [1m Learning iteration 641/1500 [0m                      

                       Computation: 41179 steps/s (collection: 2.215s, learning 0.173s)
             Mean action noise std: 2.45
          Mean value_function loss: 121.1645
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 71.1866
                       Mean reward: 578.74
               Mean episode length: 236.85
    Episode_Reward/reaching_object: 1.5613
    Episode_Reward/rotating_object: 107.1069
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 2.39s
                      Time elapsed: 00:24:58
                               ETA: 00:33:24

################################################################################
                     [1m Learning iteration 642/1500 [0m                      

                       Computation: 41906 steps/s (collection: 2.188s, learning 0.158s)
             Mean action noise std: 2.45
          Mean value_function loss: 124.1986
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 71.2038
                       Mean reward: 521.86
               Mean episode length: 219.07
    Episode_Reward/reaching_object: 1.5236
    Episode_Reward/rotating_object: 104.6297
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 2.35s
                      Time elapsed: 00:25:00
                               ETA: 00:33:22

################################################################################
                     [1m Learning iteration 643/1500 [0m                      

                       Computation: 42368 steps/s (collection: 2.206s, learning 0.114s)
             Mean action noise std: 2.45
          Mean value_function loss: 120.0124
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 71.2250
                       Mean reward: 569.17
               Mean episode length: 230.41
    Episode_Reward/reaching_object: 1.5533
    Episode_Reward/rotating_object: 110.0173
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 2.32s
                      Time elapsed: 00:25:03
                               ETA: 00:33:20

################################################################################
                     [1m Learning iteration 644/1500 [0m                      

                       Computation: 39721 steps/s (collection: 2.306s, learning 0.169s)
             Mean action noise std: 2.46
          Mean value_function loss: 108.1294
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 71.2668
                       Mean reward: 553.42
               Mean episode length: 234.46
    Episode_Reward/reaching_object: 1.5813
    Episode_Reward/rotating_object: 109.7546
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 2.47s
                      Time elapsed: 00:25:05
                               ETA: 00:33:17

################################################################################
                     [1m Learning iteration 645/1500 [0m                      

                       Computation: 41804 steps/s (collection: 2.211s, learning 0.140s)
             Mean action noise std: 2.46
          Mean value_function loss: 95.2199
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 71.2849
                       Mean reward: 563.66
               Mean episode length: 232.03
    Episode_Reward/reaching_object: 1.6063
    Episode_Reward/rotating_object: 112.6956
        Episode_Reward/action_rate: -0.0433
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 2.35s
                      Time elapsed: 00:25:07
                               ETA: 00:33:15

################################################################################
                     [1m Learning iteration 646/1500 [0m                      

                       Computation: 41103 steps/s (collection: 2.297s, learning 0.095s)
             Mean action noise std: 2.46
          Mean value_function loss: 84.8492
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 71.3071
                       Mean reward: 564.04
               Mean episode length: 227.91
    Episode_Reward/reaching_object: 1.5637
    Episode_Reward/rotating_object: 108.5864
        Episode_Reward/action_rate: -0.0423
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 2.39s
                      Time elapsed: 00:25:10
                               ETA: 00:33:13

################################################################################
                     [1m Learning iteration 647/1500 [0m                      

                       Computation: 43146 steps/s (collection: 2.170s, learning 0.108s)
             Mean action noise std: 2.46
          Mean value_function loss: 85.7640
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 71.3484
                       Mean reward: 571.82
               Mean episode length: 228.26
    Episode_Reward/reaching_object: 1.5798
    Episode_Reward/rotating_object: 110.8333
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 2.28s
                      Time elapsed: 00:25:12
                               ETA: 00:33:10

################################################################################
                     [1m Learning iteration 648/1500 [0m                      

                       Computation: 41311 steps/s (collection: 2.270s, learning 0.110s)
             Mean action noise std: 2.47
          Mean value_function loss: 95.8689
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 71.3839
                       Mean reward: 560.79
               Mean episode length: 220.25
    Episode_Reward/reaching_object: 1.5637
    Episode_Reward/rotating_object: 113.5376
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 2.38s
                      Time elapsed: 00:25:14
                               ETA: 00:33:08

################################################################################
                     [1m Learning iteration 649/1500 [0m                      

                       Computation: 42172 steps/s (collection: 2.239s, learning 0.092s)
             Mean action noise std: 2.47
          Mean value_function loss: 98.6193
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 71.4079
                       Mean reward: 549.49
               Mean episode length: 230.97
    Episode_Reward/reaching_object: 1.5538
    Episode_Reward/rotating_object: 107.4111
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 2.33s
                      Time elapsed: 00:25:17
                               ETA: 00:33:06

################################################################################
                     [1m Learning iteration 650/1500 [0m                      

                       Computation: 42464 steps/s (collection: 2.174s, learning 0.141s)
             Mean action noise std: 2.47
          Mean value_function loss: 91.4386
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 71.4354
                       Mean reward: 548.34
               Mean episode length: 234.91
    Episode_Reward/reaching_object: 1.5817
    Episode_Reward/rotating_object: 111.7251
        Episode_Reward/action_rate: -0.0436
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 2.31s
                      Time elapsed: 00:25:19
                               ETA: 00:33:04

################################################################################
                     [1m Learning iteration 651/1500 [0m                      

                       Computation: 43024 steps/s (collection: 2.184s, learning 0.101s)
             Mean action noise std: 2.48
          Mean value_function loss: 92.6171
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 71.4715
                       Mean reward: 568.69
               Mean episode length: 231.52
    Episode_Reward/reaching_object: 1.6255
    Episode_Reward/rotating_object: 114.6367
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 2.28s
                      Time elapsed: 00:25:21
                               ETA: 00:33:01

################################################################################
                     [1m Learning iteration 652/1500 [0m                      

                       Computation: 43250 steps/s (collection: 2.154s, learning 0.119s)
             Mean action noise std: 2.48
          Mean value_function loss: 106.0125
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 71.5022
                       Mean reward: 540.63
               Mean episode length: 223.58
    Episode_Reward/reaching_object: 1.5117
    Episode_Reward/rotating_object: 105.9783
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 2.27s
                      Time elapsed: 00:25:24
                               ETA: 00:32:59

################################################################################
                     [1m Learning iteration 653/1500 [0m                      

                       Computation: 42482 steps/s (collection: 2.195s, learning 0.119s)
             Mean action noise std: 2.48
          Mean value_function loss: 101.2132
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 71.5329
                       Mean reward: 576.17
               Mean episode length: 228.46
    Episode_Reward/reaching_object: 1.5896
    Episode_Reward/rotating_object: 115.2207
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 2.31s
                      Time elapsed: 00:25:26
                               ETA: 00:32:56

################################################################################
                     [1m Learning iteration 654/1500 [0m                      

                       Computation: 41898 steps/s (collection: 2.190s, learning 0.156s)
             Mean action noise std: 2.48
          Mean value_function loss: 110.2079
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 71.5604
                       Mean reward: 571.80
               Mean episode length: 235.44
    Episode_Reward/reaching_object: 1.5794
    Episode_Reward/rotating_object: 109.5758
        Episode_Reward/action_rate: -0.0437
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 2.35s
                      Time elapsed: 00:25:28
                               ETA: 00:32:54

################################################################################
                     [1m Learning iteration 655/1500 [0m                      

                       Computation: 42931 steps/s (collection: 2.181s, learning 0.109s)
             Mean action noise std: 2.48
          Mean value_function loss: 94.8845
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 71.5813
                       Mean reward: 550.77
               Mean episode length: 230.55
    Episode_Reward/reaching_object: 1.5375
    Episode_Reward/rotating_object: 108.0165
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 2.29s
                      Time elapsed: 00:25:31
                               ETA: 00:32:52

################################################################################
                     [1m Learning iteration 656/1500 [0m                      

                       Computation: 41005 steps/s (collection: 2.222s, learning 0.176s)
             Mean action noise std: 2.49
          Mean value_function loss: 110.3307
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 71.5971
                       Mean reward: 555.77
               Mean episode length: 225.88
    Episode_Reward/reaching_object: 1.5393
    Episode_Reward/rotating_object: 107.8967
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 2.40s
                      Time elapsed: 00:25:33
                               ETA: 00:32:49

################################################################################
                     [1m Learning iteration 657/1500 [0m                      

                       Computation: 41942 steps/s (collection: 2.193s, learning 0.151s)
             Mean action noise std: 2.49
          Mean value_function loss: 104.1567
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 71.6309
                       Mean reward: 538.72
               Mean episode length: 227.99
    Episode_Reward/reaching_object: 1.5612
    Episode_Reward/rotating_object: 108.4317
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 2.34s
                      Time elapsed: 00:25:35
                               ETA: 00:32:47

################################################################################
                     [1m Learning iteration 658/1500 [0m                      

                       Computation: 43628 steps/s (collection: 2.162s, learning 0.092s)
             Mean action noise std: 2.49
          Mean value_function loss: 111.4077
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 71.6621
                       Mean reward: 563.08
               Mean episode length: 230.47
    Episode_Reward/reaching_object: 1.5687
    Episode_Reward/rotating_object: 109.2963
        Episode_Reward/action_rate: -0.0435
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 2.25s
                      Time elapsed: 00:25:38
                               ETA: 00:32:45

################################################################################
                     [1m Learning iteration 659/1500 [0m                      

                       Computation: 42259 steps/s (collection: 2.232s, learning 0.094s)
             Mean action noise std: 2.49
          Mean value_function loss: 101.3721
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 71.6833
                       Mean reward: 561.60
               Mean episode length: 230.73
    Episode_Reward/reaching_object: 1.5880
    Episode_Reward/rotating_object: 109.8521
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 2.33s
                      Time elapsed: 00:25:40
                               ETA: 00:32:42

################################################################################
                     [1m Learning iteration 660/1500 [0m                      

                       Computation: 42198 steps/s (collection: 2.135s, learning 0.194s)
             Mean action noise std: 2.50
          Mean value_function loss: 108.3086
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 71.7063
                       Mean reward: 568.57
               Mean episode length: 229.39
    Episode_Reward/reaching_object: 1.6112
    Episode_Reward/rotating_object: 115.2414
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 2.33s
                      Time elapsed: 00:25:42
                               ETA: 00:32:40

################################################################################
                     [1m Learning iteration 661/1500 [0m                      

                       Computation: 42489 steps/s (collection: 2.189s, learning 0.125s)
             Mean action noise std: 2.50
          Mean value_function loss: 107.4054
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 71.7413
                       Mean reward: 583.41
               Mean episode length: 233.67
    Episode_Reward/reaching_object: 1.5711
    Episode_Reward/rotating_object: 109.1629
        Episode_Reward/action_rate: -0.0435
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 2.31s
                      Time elapsed: 00:25:45
                               ETA: 00:32:38

################################################################################
                     [1m Learning iteration 662/1500 [0m                      

                       Computation: 43245 steps/s (collection: 2.162s, learning 0.112s)
             Mean action noise std: 2.50
          Mean value_function loss: 115.0256
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 71.7686
                       Mean reward: 596.52
               Mean episode length: 231.87
    Episode_Reward/reaching_object: 1.5443
    Episode_Reward/rotating_object: 110.0586
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 2.27s
                      Time elapsed: 00:25:47
                               ETA: 00:32:35

################################################################################
                     [1m Learning iteration 663/1500 [0m                      

                       Computation: 42420 steps/s (collection: 2.150s, learning 0.168s)
             Mean action noise std: 2.50
          Mean value_function loss: 106.9843
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 71.7989
                       Mean reward: 545.54
               Mean episode length: 229.47
    Episode_Reward/reaching_object: 1.5792
    Episode_Reward/rotating_object: 109.4701
        Episode_Reward/action_rate: -0.0437
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 2.32s
                      Time elapsed: 00:25:49
                               ETA: 00:32:33

################################################################################
                     [1m Learning iteration 664/1500 [0m                      

                       Computation: 43806 steps/s (collection: 2.099s, learning 0.145s)
             Mean action noise std: 2.51
          Mean value_function loss: 105.4199
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 71.8328
                       Mean reward: 579.24
               Mean episode length: 230.82
    Episode_Reward/reaching_object: 1.5641
    Episode_Reward/rotating_object: 111.6724
        Episode_Reward/action_rate: -0.0434
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 2.24s
                      Time elapsed: 00:25:51
                               ETA: 00:32:30

################################################################################
                     [1m Learning iteration 665/1500 [0m                      

                       Computation: 44746 steps/s (collection: 2.071s, learning 0.126s)
             Mean action noise std: 2.51
          Mean value_function loss: 100.0654
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 71.8528
                       Mean reward: 546.75
               Mean episode length: 221.93
    Episode_Reward/reaching_object: 1.5822
    Episode_Reward/rotating_object: 114.8490
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 2.20s
                      Time elapsed: 00:25:54
                               ETA: 00:32:28

################################################################################
                     [1m Learning iteration 666/1500 [0m                      

                       Computation: 27505 steps/s (collection: 3.470s, learning 0.104s)
             Mean action noise std: 2.51
          Mean value_function loss: 101.7413
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 71.8729
                       Mean reward: 608.87
               Mean episode length: 239.81
    Episode_Reward/reaching_object: 1.6119
    Episode_Reward/rotating_object: 113.4475
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 3.57s
                      Time elapsed: 00:25:57
                               ETA: 00:32:27

################################################################################
                     [1m Learning iteration 667/1500 [0m                      

                       Computation: 14533 steps/s (collection: 6.648s, learning 0.116s)
             Mean action noise std: 2.51
          Mean value_function loss: 93.9623
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 71.8835
                       Mean reward: 544.75
               Mean episode length: 225.38
    Episode_Reward/reaching_object: 1.5799
    Episode_Reward/rotating_object: 112.1133
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 6.76s
                      Time elapsed: 00:26:04
                               ETA: 00:32:30

################################################################################
                     [1m Learning iteration 668/1500 [0m                      

                       Computation: 14092 steps/s (collection: 6.852s, learning 0.124s)
             Mean action noise std: 2.51
          Mean value_function loss: 107.2478
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 71.8992
                       Mean reward: 522.92
               Mean episode length: 224.51
    Episode_Reward/reaching_object: 1.5687
    Episode_Reward/rotating_object: 112.3188
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 6.98s
                      Time elapsed: 00:26:11
                               ETA: 00:32:34

################################################################################
                     [1m Learning iteration 669/1500 [0m                      

                       Computation: 14227 steps/s (collection: 6.790s, learning 0.120s)
             Mean action noise std: 2.52
          Mean value_function loss: 104.0093
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 71.9163
                       Mean reward: 579.89
               Mean episode length: 229.67
    Episode_Reward/reaching_object: 1.5633
    Episode_Reward/rotating_object: 113.5043
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 6.91s
                      Time elapsed: 00:26:18
                               ETA: 00:32:37

################################################################################
                     [1m Learning iteration 670/1500 [0m                      

                       Computation: 13887 steps/s (collection: 6.959s, learning 0.120s)
             Mean action noise std: 2.52
          Mean value_function loss: 117.5005
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 71.9561
                       Mean reward: 539.02
               Mean episode length: 226.41
    Episode_Reward/reaching_object: 1.5783
    Episode_Reward/rotating_object: 111.2277
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 7.08s
                      Time elapsed: 00:26:25
                               ETA: 00:32:40

################################################################################
                     [1m Learning iteration 671/1500 [0m                      

                       Computation: 14352 steps/s (collection: 6.680s, learning 0.170s)
             Mean action noise std: 2.52
          Mean value_function loss: 102.5469
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 71.9922
                       Mean reward: 582.57
               Mean episode length: 233.24
    Episode_Reward/reaching_object: 1.5768
    Episode_Reward/rotating_object: 114.2484
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 6.85s
                      Time elapsed: 00:26:32
                               ETA: 00:32:44

################################################################################
                     [1m Learning iteration 672/1500 [0m                      

                       Computation: 14155 steps/s (collection: 6.831s, learning 0.114s)
             Mean action noise std: 2.52
          Mean value_function loss: 101.4395
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 72.0099
                       Mean reward: 570.56
               Mean episode length: 231.80
    Episode_Reward/reaching_object: 1.5633
    Episode_Reward/rotating_object: 112.7822
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 6.94s
                      Time elapsed: 00:26:39
                               ETA: 00:32:47

################################################################################
                     [1m Learning iteration 673/1500 [0m                      

                       Computation: 14190 steps/s (collection: 6.815s, learning 0.112s)
             Mean action noise std: 2.53
          Mean value_function loss: 98.4848
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 72.0473
                       Mean reward: 533.83
               Mean episode length: 221.65
    Episode_Reward/reaching_object: 1.5855
    Episode_Reward/rotating_object: 114.5158
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 6.93s
                      Time elapsed: 00:26:46
                               ETA: 00:32:50

################################################################################
                     [1m Learning iteration 674/1500 [0m                      

                       Computation: 14175 steps/s (collection: 6.787s, learning 0.148s)
             Mean action noise std: 2.53
          Mean value_function loss: 99.4941
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 72.0781
                       Mean reward: 591.90
               Mean episode length: 232.03
    Episode_Reward/reaching_object: 1.5935
    Episode_Reward/rotating_object: 116.6443
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 6.93s
                      Time elapsed: 00:26:52
                               ETA: 00:32:53

################################################################################
                     [1m Learning iteration 675/1500 [0m                      

                       Computation: 20226 steps/s (collection: 4.767s, learning 0.093s)
             Mean action noise std: 2.53
          Mean value_function loss: 110.7971
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 72.1116
                       Mean reward: 571.16
               Mean episode length: 223.55
    Episode_Reward/reaching_object: 1.5625
    Episode_Reward/rotating_object: 111.2545
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 4.86s
                      Time elapsed: 00:26:57
                               ETA: 00:32:54

################################################################################
                     [1m Learning iteration 676/1500 [0m                      

                       Computation: 44537 steps/s (collection: 2.062s, learning 0.145s)
             Mean action noise std: 2.54
          Mean value_function loss: 108.5071
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 72.1488
                       Mean reward: 533.18
               Mean episode length: 222.22
    Episode_Reward/reaching_object: 1.5574
    Episode_Reward/rotating_object: 111.4449
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 2.21s
                      Time elapsed: 00:27:00
                               ETA: 00:32:51

################################################################################
                     [1m Learning iteration 677/1500 [0m                      

                       Computation: 44461 steps/s (collection: 2.060s, learning 0.151s)
             Mean action noise std: 2.54
          Mean value_function loss: 100.9568
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 72.1704
                       Mean reward: 568.49
               Mean episode length: 228.32
    Episode_Reward/reaching_object: 1.5721
    Episode_Reward/rotating_object: 113.5885
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 2.21s
                      Time elapsed: 00:27:02
                               ETA: 00:32:49

################################################################################
                     [1m Learning iteration 678/1500 [0m                      

                       Computation: 44301 steps/s (collection: 2.108s, learning 0.111s)
             Mean action noise std: 2.54
          Mean value_function loss: 106.8295
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 72.1932
                       Mean reward: 581.94
               Mean episode length: 227.79
    Episode_Reward/reaching_object: 1.5825
    Episode_Reward/rotating_object: 114.5272
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 2.22s
                      Time elapsed: 00:27:04
                               ETA: 00:32:46

################################################################################
                     [1m Learning iteration 679/1500 [0m                      

                       Computation: 44132 steps/s (collection: 2.098s, learning 0.129s)
             Mean action noise std: 2.54
          Mean value_function loss: 99.8072
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 72.2162
                       Mean reward: 549.45
               Mean episode length: 226.30
    Episode_Reward/reaching_object: 1.5688
    Episode_Reward/rotating_object: 112.4293
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 2.23s
                      Time elapsed: 00:27:06
                               ETA: 00:32:44

################################################################################
                     [1m Learning iteration 680/1500 [0m                      

                       Computation: 41261 steps/s (collection: 2.234s, learning 0.149s)
             Mean action noise std: 2.55
          Mean value_function loss: 114.4380
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 72.2416
                       Mean reward: 564.24
               Mean episode length: 225.00
    Episode_Reward/reaching_object: 1.5605
    Episode_Reward/rotating_object: 111.2168
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 2.38s
                      Time elapsed: 00:27:09
                               ETA: 00:32:41

################################################################################
                     [1m Learning iteration 681/1500 [0m                      

                       Computation: 43515 steps/s (collection: 2.102s, learning 0.157s)
             Mean action noise std: 2.55
          Mean value_function loss: 108.8254
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 72.2809
                       Mean reward: 582.21
               Mean episode length: 230.21
    Episode_Reward/reaching_object: 1.5504
    Episode_Reward/rotating_object: 111.0365
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 2.26s
                      Time elapsed: 00:27:11
                               ETA: 00:32:39

################################################################################
                     [1m Learning iteration 682/1500 [0m                      

                       Computation: 42223 steps/s (collection: 2.193s, learning 0.135s)
             Mean action noise std: 2.55
          Mean value_function loss: 121.9317
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 72.3027
                       Mean reward: 561.38
               Mean episode length: 223.92
    Episode_Reward/reaching_object: 1.5690
    Episode_Reward/rotating_object: 109.7407
        Episode_Reward/action_rate: -0.0456
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 2.33s
                      Time elapsed: 00:27:13
                               ETA: 00:32:36

################################################################################
                     [1m Learning iteration 683/1500 [0m                      

                       Computation: 43365 steps/s (collection: 2.173s, learning 0.094s)
             Mean action noise std: 2.55
          Mean value_function loss: 109.8272
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 72.3257
                       Mean reward: 553.98
               Mean episode length: 233.34
    Episode_Reward/reaching_object: 1.5640
    Episode_Reward/rotating_object: 110.5824
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 2.27s
                      Time elapsed: 00:27:15
                               ETA: 00:32:34

################################################################################
                     [1m Learning iteration 684/1500 [0m                      

                       Computation: 45310 steps/s (collection: 2.072s, learning 0.098s)
             Mean action noise std: 2.56
          Mean value_function loss: 107.7063
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 72.3583
                       Mean reward: 589.87
               Mean episode length: 235.00
    Episode_Reward/reaching_object: 1.6035
    Episode_Reward/rotating_object: 114.5064
        Episode_Reward/action_rate: -0.0468
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 2.17s
                      Time elapsed: 00:27:18
                               ETA: 00:32:31

################################################################################
                     [1m Learning iteration 685/1500 [0m                      

                       Computation: 44483 steps/s (collection: 2.093s, learning 0.117s)
             Mean action noise std: 2.56
          Mean value_function loss: 115.8562
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 72.3735
                       Mean reward: 590.04
               Mean episode length: 233.29
    Episode_Reward/reaching_object: 1.5764
    Episode_Reward/rotating_object: 111.9552
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 2.21s
                      Time elapsed: 00:27:20
                               ETA: 00:32:28

################################################################################
                     [1m Learning iteration 686/1500 [0m                      

                       Computation: 46077 steps/s (collection: 2.033s, learning 0.100s)
             Mean action noise std: 2.56
          Mean value_function loss: 105.6066
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 72.3857
                       Mean reward: 585.52
               Mean episode length: 228.22
    Episode_Reward/reaching_object: 1.5678
    Episode_Reward/rotating_object: 108.4691
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 2.13s
                      Time elapsed: 00:27:22
                               ETA: 00:32:26

################################################################################
                     [1m Learning iteration 687/1500 [0m                      

                       Computation: 46081 steps/s (collection: 2.021s, learning 0.113s)
             Mean action noise std: 2.56
          Mean value_function loss: 110.7423
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 72.4102
                       Mean reward: 590.88
               Mean episode length: 238.41
    Episode_Reward/reaching_object: 1.5287
    Episode_Reward/rotating_object: 109.3328
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 2.13s
                      Time elapsed: 00:27:24
                               ETA: 00:32:23

################################################################################
                     [1m Learning iteration 688/1500 [0m                      

                       Computation: 45016 steps/s (collection: 2.071s, learning 0.113s)
             Mean action noise std: 2.56
          Mean value_function loss: 90.8528
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 72.4417
                       Mean reward: 578.06
               Mean episode length: 228.03
    Episode_Reward/reaching_object: 1.5590
    Episode_Reward/rotating_object: 111.9022
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 2.18s
                      Time elapsed: 00:27:26
                               ETA: 00:32:20

################################################################################
                     [1m Learning iteration 689/1500 [0m                      

                       Computation: 45316 steps/s (collection: 2.053s, learning 0.116s)
             Mean action noise std: 2.57
          Mean value_function loss: 102.2154
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 72.4654
                       Mean reward: 593.93
               Mean episode length: 229.33
    Episode_Reward/reaching_object: 1.5869
    Episode_Reward/rotating_object: 113.7528
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 2.17s
                      Time elapsed: 00:27:28
                               ETA: 00:32:18

################################################################################
                     [1m Learning iteration 690/1500 [0m                      

                       Computation: 46730 steps/s (collection: 2.004s, learning 0.100s)
             Mean action noise std: 2.57
          Mean value_function loss: 93.2326
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 72.4984
                       Mean reward: 556.34
               Mean episode length: 227.53
    Episode_Reward/reaching_object: 1.5689
    Episode_Reward/rotating_object: 112.0239
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 2.10s
                      Time elapsed: 00:27:31
                               ETA: 00:32:15

################################################################################
                     [1m Learning iteration 691/1500 [0m                      

                       Computation: 45906 steps/s (collection: 2.027s, learning 0.114s)
             Mean action noise std: 2.57
          Mean value_function loss: 93.9857
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 72.5213
                       Mean reward: 574.79
               Mean episode length: 228.80
    Episode_Reward/reaching_object: 1.5988
    Episode_Reward/rotating_object: 114.9629
        Episode_Reward/action_rate: -0.0471
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 2.14s
                      Time elapsed: 00:27:33
                               ETA: 00:32:12

################################################################################
                     [1m Learning iteration 692/1500 [0m                      

                       Computation: 45715 steps/s (collection: 2.018s, learning 0.133s)
             Mean action noise std: 2.57
          Mean value_function loss: 92.3149
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 72.5424
                       Mean reward: 584.74
               Mean episode length: 232.51
    Episode_Reward/reaching_object: 1.5622
    Episode_Reward/rotating_object: 110.5087
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 2.15s
                      Time elapsed: 00:27:35
                               ETA: 00:32:10

################################################################################
                     [1m Learning iteration 693/1500 [0m                      

                       Computation: 45527 steps/s (collection: 2.058s, learning 0.101s)
             Mean action noise std: 2.58
          Mean value_function loss: 94.0655
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 72.5695
                       Mean reward: 578.10
               Mean episode length: 230.37
    Episode_Reward/reaching_object: 1.6031
    Episode_Reward/rotating_object: 117.0641
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 2.16s
                      Time elapsed: 00:27:37
                               ETA: 00:32:07

################################################################################
                     [1m Learning iteration 694/1500 [0m                      

                       Computation: 46765 steps/s (collection: 2.002s, learning 0.100s)
             Mean action noise std: 2.58
          Mean value_function loss: 91.9852
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 72.6013
                       Mean reward: 573.15
               Mean episode length: 225.23
    Episode_Reward/reaching_object: 1.5625
    Episode_Reward/rotating_object: 111.2621
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 2.10s
                      Time elapsed: 00:27:39
                               ETA: 00:32:04

################################################################################
                     [1m Learning iteration 695/1500 [0m                      

                       Computation: 45297 steps/s (collection: 2.059s, learning 0.112s)
             Mean action noise std: 2.58
          Mean value_function loss: 102.3689
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 72.6360
                       Mean reward: 596.49
               Mean episode length: 229.80
    Episode_Reward/reaching_object: 1.6273
    Episode_Reward/rotating_object: 120.0727
        Episode_Reward/action_rate: -0.0486
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 2.17s
                      Time elapsed: 00:27:41
                               ETA: 00:32:02

################################################################################
                     [1m Learning iteration 696/1500 [0m                      

                       Computation: 45518 steps/s (collection: 2.060s, learning 0.100s)
             Mean action noise std: 2.59
          Mean value_function loss: 92.7070
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 72.6763
                       Mean reward: 544.85
               Mean episode length: 228.71
    Episode_Reward/reaching_object: 1.5683
    Episode_Reward/rotating_object: 111.7903
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 2.16s
                      Time elapsed: 00:27:43
                               ETA: 00:31:59

################################################################################
                     [1m Learning iteration 697/1500 [0m                      

                       Computation: 45154 steps/s (collection: 2.051s, learning 0.126s)
             Mean action noise std: 2.59
          Mean value_function loss: 99.8370
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 72.7162
                       Mean reward: 566.68
               Mean episode length: 227.89
    Episode_Reward/reaching_object: 1.5321
    Episode_Reward/rotating_object: 108.8326
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 2.18s
                      Time elapsed: 00:27:46
                               ETA: 00:31:56

################################################################################
                     [1m Learning iteration 698/1500 [0m                      

                       Computation: 45723 steps/s (collection: 2.024s, learning 0.126s)
             Mean action noise std: 2.59
          Mean value_function loss: 90.1116
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 72.7516
                       Mean reward: 523.47
               Mean episode length: 222.94
    Episode_Reward/reaching_object: 1.5822
    Episode_Reward/rotating_object: 111.5953
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 2.15s
                      Time elapsed: 00:27:48
                               ETA: 00:31:54

################################################################################
                     [1m Learning iteration 699/1500 [0m                      

                       Computation: 45954 steps/s (collection: 2.032s, learning 0.107s)
             Mean action noise std: 2.60
          Mean value_function loss: 81.8855
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 72.7845
                       Mean reward: 615.44
               Mean episode length: 236.89
    Episode_Reward/reaching_object: 1.5832
    Episode_Reward/rotating_object: 114.4094
        Episode_Reward/action_rate: -0.0480
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 2.14s
                      Time elapsed: 00:27:50
                               ETA: 00:31:51

################################################################################
                     [1m Learning iteration 700/1500 [0m                      

                       Computation: 45841 steps/s (collection: 2.046s, learning 0.098s)
             Mean action noise std: 2.60
          Mean value_function loss: 82.8954
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 72.8187
                       Mean reward: 582.00
               Mean episode length: 230.91
    Episode_Reward/reaching_object: 1.6078
    Episode_Reward/rotating_object: 118.0712
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 2.14s
                      Time elapsed: 00:27:52
                               ETA: 00:31:48

################################################################################
                     [1m Learning iteration 701/1500 [0m                      

                       Computation: 46356 steps/s (collection: 2.031s, learning 0.090s)
             Mean action noise std: 2.60
          Mean value_function loss: 87.7327
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 72.8555
                       Mean reward: 579.19
               Mean episode length: 229.01
    Episode_Reward/reaching_object: 1.5607
    Episode_Reward/rotating_object: 115.7823
        Episode_Reward/action_rate: -0.0480
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 2.12s
                      Time elapsed: 00:27:54
                               ETA: 00:31:46

################################################################################
                     [1m Learning iteration 702/1500 [0m                      

                       Computation: 45535 steps/s (collection: 2.051s, learning 0.107s)
             Mean action noise std: 2.61
          Mean value_function loss: 94.9643
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 72.8976
                       Mean reward: 555.54
               Mean episode length: 235.46
    Episode_Reward/reaching_object: 1.5529
    Episode_Reward/rotating_object: 110.4383
        Episode_Reward/action_rate: -0.0480
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 2.16s
                      Time elapsed: 00:27:56
                               ETA: 00:31:43

################################################################################
                     [1m Learning iteration 703/1500 [0m                      

                       Computation: 45971 steps/s (collection: 2.042s, learning 0.097s)
             Mean action noise std: 2.61
          Mean value_function loss: 98.1962
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 72.9339
                       Mean reward: 601.66
               Mean episode length: 238.61
    Episode_Reward/reaching_object: 1.5707
    Episode_Reward/rotating_object: 115.6885
        Episode_Reward/action_rate: -0.0486
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 2.14s
                      Time elapsed: 00:27:58
                               ETA: 00:31:40

################################################################################
                     [1m Learning iteration 704/1500 [0m                      

                       Computation: 42666 steps/s (collection: 2.189s, learning 0.115s)
             Mean action noise std: 2.61
          Mean value_function loss: 98.2879
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 72.9631
                       Mean reward: 583.77
               Mean episode length: 229.27
    Episode_Reward/reaching_object: 1.5577
    Episode_Reward/rotating_object: 111.9429
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 2.30s
                      Time elapsed: 00:28:01
                               ETA: 00:31:38

################################################################################
                     [1m Learning iteration 705/1500 [0m                      

                       Computation: 45397 steps/s (collection: 2.043s, learning 0.122s)
             Mean action noise std: 2.61
          Mean value_function loss: 107.7601
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 72.9770
                       Mean reward: 580.79
               Mean episode length: 230.44
    Episode_Reward/reaching_object: 1.5358
    Episode_Reward/rotating_object: 112.1825
        Episode_Reward/action_rate: -0.0480
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 2.17s
                      Time elapsed: 00:28:03
                               ETA: 00:31:35

################################################################################
                     [1m Learning iteration 706/1500 [0m                      

                       Computation: 43569 steps/s (collection: 2.160s, learning 0.096s)
             Mean action noise std: 2.61
          Mean value_function loss: 105.2261
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 72.9918
                       Mean reward: 585.18
               Mean episode length: 229.74
    Episode_Reward/reaching_object: 1.5039
    Episode_Reward/rotating_object: 108.4678
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 2.26s
                      Time elapsed: 00:28:05
                               ETA: 00:31:33

################################################################################
                     [1m Learning iteration 707/1500 [0m                      

                       Computation: 46437 steps/s (collection: 2.025s, learning 0.092s)
             Mean action noise std: 2.62
          Mean value_function loss: 98.8077
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 73.0220
                       Mean reward: 562.80
               Mean episode length: 222.02
    Episode_Reward/reaching_object: 1.5585
    Episode_Reward/rotating_object: 111.9976
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 2.12s
                      Time elapsed: 00:28:07
                               ETA: 00:31:30

################################################################################
                     [1m Learning iteration 708/1500 [0m                      

                       Computation: 44822 steps/s (collection: 2.089s, learning 0.105s)
             Mean action noise std: 2.62
          Mean value_function loss: 108.2376
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 73.0500
                       Mean reward: 587.80
               Mean episode length: 231.79
    Episode_Reward/reaching_object: 1.5340
    Episode_Reward/rotating_object: 110.9276
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 2.19s
                      Time elapsed: 00:28:10
                               ETA: 00:31:27

################################################################################
                     [1m Learning iteration 709/1500 [0m                      

                       Computation: 44381 steps/s (collection: 2.084s, learning 0.131s)
             Mean action noise std: 2.62
          Mean value_function loss: 104.2586
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 73.0754
                       Mean reward: 558.23
               Mean episode length: 228.51
    Episode_Reward/reaching_object: 1.5496
    Episode_Reward/rotating_object: 112.9955
        Episode_Reward/action_rate: -0.0485
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 2.21s
                      Time elapsed: 00:28:12
                               ETA: 00:31:25

################################################################################
                     [1m Learning iteration 710/1500 [0m                      

                       Computation: 45164 steps/s (collection: 2.083s, learning 0.093s)
             Mean action noise std: 2.63
          Mean value_function loss: 101.8417
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 73.1107
                       Mean reward: 592.41
               Mean episode length: 233.98
    Episode_Reward/reaching_object: 1.5786
    Episode_Reward/rotating_object: 113.6098
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 2.18s
                      Time elapsed: 00:28:14
                               ETA: 00:31:22

################################################################################
                     [1m Learning iteration 711/1500 [0m                      

                       Computation: 44731 steps/s (collection: 2.062s, learning 0.136s)
             Mean action noise std: 2.63
          Mean value_function loss: 113.9937
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 73.1471
                       Mean reward: 569.24
               Mean episode length: 226.82
    Episode_Reward/reaching_object: 1.5585
    Episode_Reward/rotating_object: 111.5396
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 2.20s
                      Time elapsed: 00:28:16
                               ETA: 00:31:20

################################################################################
                     [1m Learning iteration 712/1500 [0m                      

                       Computation: 45726 steps/s (collection: 2.056s, learning 0.094s)
             Mean action noise std: 2.63
          Mean value_function loss: 116.5804
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 73.1759
                       Mean reward: 567.48
               Mean episode length: 223.89
    Episode_Reward/reaching_object: 1.5089
    Episode_Reward/rotating_object: 107.5826
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 2.15s
                      Time elapsed: 00:28:18
                               ETA: 00:31:17

################################################################################
                     [1m Learning iteration 713/1500 [0m                      

                       Computation: 45048 steps/s (collection: 2.057s, learning 0.125s)
             Mean action noise std: 2.63
          Mean value_function loss: 105.0092
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 73.2020
                       Mean reward: 605.77
               Mean episode length: 233.03
    Episode_Reward/reaching_object: 1.6070
    Episode_Reward/rotating_object: 116.0151
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 2.18s
                      Time elapsed: 00:28:20
                               ETA: 00:31:14

################################################################################
                     [1m Learning iteration 714/1500 [0m                      

                       Computation: 45248 steps/s (collection: 2.057s, learning 0.116s)
             Mean action noise std: 2.64
          Mean value_function loss: 104.3680
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 73.2290
                       Mean reward: 588.15
               Mean episode length: 225.17
    Episode_Reward/reaching_object: 1.5976
    Episode_Reward/rotating_object: 116.3692
        Episode_Reward/action_rate: -0.0497
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 2.17s
                      Time elapsed: 00:28:23
                               ETA: 00:31:12

################################################################################
                     [1m Learning iteration 715/1500 [0m                      

                       Computation: 44309 steps/s (collection: 2.085s, learning 0.134s)
             Mean action noise std: 2.64
          Mean value_function loss: 99.8763
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 73.2549
                       Mean reward: 580.61
               Mean episode length: 232.59
    Episode_Reward/reaching_object: 1.6212
    Episode_Reward/rotating_object: 116.6300
        Episode_Reward/action_rate: -0.0504
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 2.22s
                      Time elapsed: 00:28:25
                               ETA: 00:31:09

################################################################################
                     [1m Learning iteration 716/1500 [0m                      

                       Computation: 44406 steps/s (collection: 2.081s, learning 0.133s)
             Mean action noise std: 2.64
          Mean value_function loss: 104.8914
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 73.2811
                       Mean reward: 592.51
               Mean episode length: 233.72
    Episode_Reward/reaching_object: 1.6069
    Episode_Reward/rotating_object: 116.9882
        Episode_Reward/action_rate: -0.0500
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 2.21s
                      Time elapsed: 00:28:27
                               ETA: 00:31:07

################################################################################
                     [1m Learning iteration 717/1500 [0m                      

                       Computation: 43279 steps/s (collection: 2.096s, learning 0.176s)
             Mean action noise std: 2.65
          Mean value_function loss: 129.0478
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 73.3084
                       Mean reward: 571.19
               Mean episode length: 222.55
    Episode_Reward/reaching_object: 1.5515
    Episode_Reward/rotating_object: 109.3322
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 2.27s
                      Time elapsed: 00:28:29
                               ETA: 00:31:04

################################################################################
                     [1m Learning iteration 718/1500 [0m                      

                       Computation: 43226 steps/s (collection: 2.174s, learning 0.100s)
             Mean action noise std: 2.65
          Mean value_function loss: 119.0113
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 73.3447
                       Mean reward: 534.14
               Mean episode length: 225.74
    Episode_Reward/reaching_object: 1.5560
    Episode_Reward/rotating_object: 109.5766
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 2.27s
                      Time elapsed: 00:28:32
                               ETA: 00:31:02

################################################################################
                     [1m Learning iteration 719/1500 [0m                      

                       Computation: 44470 steps/s (collection: 2.107s, learning 0.104s)
             Mean action noise std: 2.65
          Mean value_function loss: 109.3070
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 73.3837
                       Mean reward: 581.38
               Mean episode length: 229.31
    Episode_Reward/reaching_object: 1.6004
    Episode_Reward/rotating_object: 115.9419
        Episode_Reward/action_rate: -0.0500
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 2.21s
                      Time elapsed: 00:28:34
                               ETA: 00:30:59

################################################################################
                     [1m Learning iteration 720/1500 [0m                      

                       Computation: 42222 steps/s (collection: 2.230s, learning 0.098s)
             Mean action noise std: 2.66
          Mean value_function loss: 119.8706
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 73.4172
                       Mean reward: 624.73
               Mean episode length: 230.78
    Episode_Reward/reaching_object: 1.6095
    Episode_Reward/rotating_object: 118.3262
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 2.33s
                      Time elapsed: 00:28:36
                               ETA: 00:30:57

################################################################################
                     [1m Learning iteration 721/1500 [0m                      

                       Computation: 45425 steps/s (collection: 2.070s, learning 0.095s)
             Mean action noise std: 2.66
          Mean value_function loss: 100.6538
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 73.4424
                       Mean reward: 618.97
               Mean episode length: 234.35
    Episode_Reward/reaching_object: 1.5965
    Episode_Reward/rotating_object: 115.6877
        Episode_Reward/action_rate: -0.0504
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 2.16s
                      Time elapsed: 00:28:38
                               ETA: 00:30:54

################################################################################
                     [1m Learning iteration 722/1500 [0m                      

                       Computation: 46373 steps/s (collection: 2.030s, learning 0.090s)
             Mean action noise std: 2.66
          Mean value_function loss: 105.8177
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 73.4694
                       Mean reward: 565.43
               Mean episode length: 226.70
    Episode_Reward/reaching_object: 1.5896
    Episode_Reward/rotating_object: 114.6800
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 2.12s
                      Time elapsed: 00:28:40
                               ETA: 00:30:51

################################################################################
                     [1m Learning iteration 723/1500 [0m                      

                       Computation: 45237 steps/s (collection: 2.072s, learning 0.102s)
             Mean action noise std: 2.66
          Mean value_function loss: 109.2553
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 73.4928
                       Mean reward: 597.32
               Mean episode length: 230.43
    Episode_Reward/reaching_object: 1.5818
    Episode_Reward/rotating_object: 113.4642
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 2.17s
                      Time elapsed: 00:28:43
                               ETA: 00:30:49

################################################################################
                     [1m Learning iteration 724/1500 [0m                      

                       Computation: 46419 steps/s (collection: 2.026s, learning 0.092s)
             Mean action noise std: 2.67
          Mean value_function loss: 105.7064
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 73.5219
                       Mean reward: 575.99
               Mean episode length: 226.33
    Episode_Reward/reaching_object: 1.6016
    Episode_Reward/rotating_object: 116.0832
        Episode_Reward/action_rate: -0.0509
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 2.12s
                      Time elapsed: 00:28:45
                               ETA: 00:30:46

################################################################################
                     [1m Learning iteration 725/1500 [0m                      

                       Computation: 44433 steps/s (collection: 2.067s, learning 0.145s)
             Mean action noise std: 2.67
          Mean value_function loss: 109.8594
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 73.5587
                       Mean reward: 613.66
               Mean episode length: 239.09
    Episode_Reward/reaching_object: 1.5956
    Episode_Reward/rotating_object: 116.4198
        Episode_Reward/action_rate: -0.0507
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 2.21s
                      Time elapsed: 00:28:47
                               ETA: 00:30:43

################################################################################
                     [1m Learning iteration 726/1500 [0m                      

                       Computation: 45675 steps/s (collection: 2.030s, learning 0.123s)
             Mean action noise std: 2.67
          Mean value_function loss: 90.2686
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 73.5920
                       Mean reward: 591.06
               Mean episode length: 235.12
    Episode_Reward/reaching_object: 1.6146
    Episode_Reward/rotating_object: 115.5962
        Episode_Reward/action_rate: -0.0515
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 2.15s
                      Time elapsed: 00:28:49
                               ETA: 00:30:41

################################################################################
                     [1m Learning iteration 727/1500 [0m                      

                       Computation: 45690 steps/s (collection: 2.051s, learning 0.100s)
             Mean action noise std: 2.67
          Mean value_function loss: 107.1885
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 73.6120
                       Mean reward: 541.35
               Mean episode length: 222.73
    Episode_Reward/reaching_object: 1.5853
    Episode_Reward/rotating_object: 110.6251
        Episode_Reward/action_rate: -0.0507
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 2.15s
                      Time elapsed: 00:28:51
                               ETA: 00:30:38

################################################################################
                     [1m Learning iteration 728/1500 [0m                      

                       Computation: 45369 steps/s (collection: 2.079s, learning 0.088s)
             Mean action noise std: 2.68
          Mean value_function loss: 101.8605
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 73.6411
                       Mean reward: 539.37
               Mean episode length: 218.55
    Episode_Reward/reaching_object: 1.5605
    Episode_Reward/rotating_object: 112.3364
        Episode_Reward/action_rate: -0.0501
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 2.17s
                      Time elapsed: 00:28:53
                               ETA: 00:30:36

################################################################################
                     [1m Learning iteration 729/1500 [0m                      

                       Computation: 45815 steps/s (collection: 2.048s, learning 0.098s)
             Mean action noise std: 2.68
          Mean value_function loss: 105.5125
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 73.6614
                       Mean reward: 586.55
               Mean episode length: 233.21
    Episode_Reward/reaching_object: 1.5724
    Episode_Reward/rotating_object: 113.7189
        Episode_Reward/action_rate: -0.0507
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 2.15s
                      Time elapsed: 00:28:56
                               ETA: 00:30:33

################################################################################
                     [1m Learning iteration 730/1500 [0m                      

                       Computation: 45829 steps/s (collection: 2.054s, learning 0.091s)
             Mean action noise std: 2.68
          Mean value_function loss: 100.4589
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 73.6738
                       Mean reward: 523.16
               Mean episode length: 221.52
    Episode_Reward/reaching_object: 1.5560
    Episode_Reward/rotating_object: 111.0432
        Episode_Reward/action_rate: -0.0504
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 2.15s
                      Time elapsed: 00:28:58
                               ETA: 00:30:30

################################################################################
                     [1m Learning iteration 731/1500 [0m                      

                       Computation: 44009 steps/s (collection: 2.084s, learning 0.149s)
             Mean action noise std: 2.68
          Mean value_function loss: 93.7849
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 73.6930
                       Mean reward: 574.65
               Mean episode length: 232.79
    Episode_Reward/reaching_object: 1.6019
    Episode_Reward/rotating_object: 118.3161
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 2.23s
                      Time elapsed: 00:29:00
                               ETA: 00:30:28

################################################################################
                     [1m Learning iteration 732/1500 [0m                      

                       Computation: 39440 steps/s (collection: 2.329s, learning 0.163s)
             Mean action noise std: 2.69
          Mean value_function loss: 97.3346
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 73.7169
                       Mean reward: 581.00
               Mean episode length: 226.46
    Episode_Reward/reaching_object: 1.5877
    Episode_Reward/rotating_object: 117.4195
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 2.49s
                      Time elapsed: 00:29:02
                               ETA: 00:30:26

################################################################################
                     [1m Learning iteration 733/1500 [0m                      

                       Computation: 44840 steps/s (collection: 2.101s, learning 0.091s)
             Mean action noise std: 2.69
          Mean value_function loss: 102.6127
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 73.7664
                       Mean reward: 594.42
               Mean episode length: 234.56
    Episode_Reward/reaching_object: 1.5717
    Episode_Reward/rotating_object: 113.5251
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 2.19s
                      Time elapsed: 00:29:05
                               ETA: 00:30:23

################################################################################
                     [1m Learning iteration 734/1500 [0m                      

                       Computation: 45599 steps/s (collection: 2.062s, learning 0.094s)
             Mean action noise std: 2.69
          Mean value_function loss: 109.6883
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 73.8060
                       Mean reward: 606.39
               Mean episode length: 231.23
    Episode_Reward/reaching_object: 1.5732
    Episode_Reward/rotating_object: 114.8360
        Episode_Reward/action_rate: -0.0514
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 2.16s
                      Time elapsed: 00:29:07
                               ETA: 00:30:20

################################################################################
                     [1m Learning iteration 735/1500 [0m                      

                       Computation: 46217 steps/s (collection: 2.037s, learning 0.090s)
             Mean action noise std: 2.70
          Mean value_function loss: 120.3409
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 73.8391
                       Mean reward: 539.98
               Mean episode length: 224.69
    Episode_Reward/reaching_object: 1.5739
    Episode_Reward/rotating_object: 111.7881
        Episode_Reward/action_rate: -0.0514
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 2.13s
                      Time elapsed: 00:29:09
                               ETA: 00:30:18

################################################################################
                     [1m Learning iteration 736/1500 [0m                      

                       Computation: 43964 steps/s (collection: 2.136s, learning 0.100s)
             Mean action noise std: 2.70
          Mean value_function loss: 102.7008
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 73.8684
                       Mean reward: 533.38
               Mean episode length: 215.11
    Episode_Reward/reaching_object: 1.5360
    Episode_Reward/rotating_object: 110.3931
        Episode_Reward/action_rate: -0.0504
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 2.24s
                      Time elapsed: 00:29:11
                               ETA: 00:30:15

################################################################################
                     [1m Learning iteration 737/1500 [0m                      

                       Computation: 45126 steps/s (collection: 2.081s, learning 0.097s)
             Mean action noise std: 2.70
          Mean value_function loss: 105.5160
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 73.8987
                       Mean reward: 575.67
               Mean episode length: 232.22
    Episode_Reward/reaching_object: 1.5505
    Episode_Reward/rotating_object: 110.3484
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 2.18s
                      Time elapsed: 00:29:13
                               ETA: 00:30:13

################################################################################
                     [1m Learning iteration 738/1500 [0m                      

                       Computation: 45797 steps/s (collection: 2.044s, learning 0.103s)
             Mean action noise std: 2.70
          Mean value_function loss: 109.8178
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 73.9218
                       Mean reward: 523.92
               Mean episode length: 220.04
    Episode_Reward/reaching_object: 1.5601
    Episode_Reward/rotating_object: 110.7617
        Episode_Reward/action_rate: -0.0514
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 2.15s
                      Time elapsed: 00:29:15
                               ETA: 00:30:10

################################################################################
                     [1m Learning iteration 739/1500 [0m                      

                       Computation: 45758 steps/s (collection: 2.046s, learning 0.102s)
             Mean action noise std: 2.71
          Mean value_function loss: 107.6661
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 73.9524
                       Mean reward: 558.57
               Mean episode length: 221.35
    Episode_Reward/reaching_object: 1.5580
    Episode_Reward/rotating_object: 114.7320
        Episode_Reward/action_rate: -0.0514
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 2.15s
                      Time elapsed: 00:29:18
                               ETA: 00:30:07

################################################################################
                     [1m Learning iteration 740/1500 [0m                      

                       Computation: 46331 steps/s (collection: 2.015s, learning 0.107s)
             Mean action noise std: 2.71
          Mean value_function loss: 104.3756
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 73.9847
                       Mean reward: 555.73
               Mean episode length: 224.21
    Episode_Reward/reaching_object: 1.5571
    Episode_Reward/rotating_object: 110.9617
        Episode_Reward/action_rate: -0.0515
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 2.12s
                      Time elapsed: 00:29:20
                               ETA: 00:30:05

################################################################################
                     [1m Learning iteration 741/1500 [0m                      

                       Computation: 44506 steps/s (collection: 2.107s, learning 0.101s)
             Mean action noise std: 2.71
          Mean value_function loss: 116.9696
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 74.0186
                       Mean reward: 544.31
               Mean episode length: 221.95
    Episode_Reward/reaching_object: 1.5792
    Episode_Reward/rotating_object: 113.9432
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 2.21s
                      Time elapsed: 00:29:22
                               ETA: 00:30:02

################################################################################
                     [1m Learning iteration 742/1500 [0m                      

                       Computation: 45616 steps/s (collection: 2.049s, learning 0.106s)
             Mean action noise std: 2.72
          Mean value_function loss: 109.1234
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 74.0426
                       Mean reward: 595.98
               Mean episode length: 226.98
    Episode_Reward/reaching_object: 1.5784
    Episode_Reward/rotating_object: 115.3204
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 2.16s
                      Time elapsed: 00:29:24
                               ETA: 00:30:00

################################################################################
                     [1m Learning iteration 743/1500 [0m                      

                       Computation: 43853 steps/s (collection: 2.074s, learning 0.168s)
             Mean action noise std: 2.72
          Mean value_function loss: 104.9236
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 74.0660
                       Mean reward: 534.88
               Mean episode length: 216.66
    Episode_Reward/reaching_object: 1.5402
    Episode_Reward/rotating_object: 110.4820
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 2.24s
                      Time elapsed: 00:29:26
                               ETA: 00:29:57

################################################################################
                     [1m Learning iteration 744/1500 [0m                      

                       Computation: 44921 steps/s (collection: 2.093s, learning 0.096s)
             Mean action noise std: 2.72
          Mean value_function loss: 100.8678
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 74.1045
                       Mean reward: 564.74
               Mean episode length: 223.48
    Episode_Reward/reaching_object: 1.5724
    Episode_Reward/rotating_object: 113.8056
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 2.19s
                      Time elapsed: 00:29:28
                               ETA: 00:29:55

################################################################################
                     [1m Learning iteration 745/1500 [0m                      

                       Computation: 46210 steps/s (collection: 2.036s, learning 0.092s)
             Mean action noise std: 2.73
          Mean value_function loss: 106.2065
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 74.1362
                       Mean reward: 593.33
               Mean episode length: 223.77
    Episode_Reward/reaching_object: 1.5791
    Episode_Reward/rotating_object: 118.9875
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 2.13s
                      Time elapsed: 00:29:31
                               ETA: 00:29:52

################################################################################
                     [1m Learning iteration 746/1500 [0m                      

                       Computation: 45897 steps/s (collection: 2.036s, learning 0.106s)
             Mean action noise std: 2.73
          Mean value_function loss: 111.3766
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 74.1665
                       Mean reward: 504.29
               Mean episode length: 208.83
    Episode_Reward/reaching_object: 1.5445
    Episode_Reward/rotating_object: 111.7498
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 2.14s
                      Time elapsed: 00:29:33
                               ETA: 00:29:49

################################################################################
                     [1m Learning iteration 747/1500 [0m                      

                       Computation: 45628 steps/s (collection: 2.050s, learning 0.105s)
             Mean action noise std: 2.73
          Mean value_function loss: 119.8306
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 74.2109
                       Mean reward: 542.52
               Mean episode length: 206.85
    Episode_Reward/reaching_object: 1.4838
    Episode_Reward/rotating_object: 109.6414
        Episode_Reward/action_rate: -0.0495
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 2.15s
                      Time elapsed: 00:29:35
                               ETA: 00:29:47

################################################################################
                     [1m Learning iteration 748/1500 [0m                      

                       Computation: 43279 steps/s (collection: 2.160s, learning 0.112s)
             Mean action noise std: 2.74
          Mean value_function loss: 122.6864
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 74.2533
                       Mean reward: 635.96
               Mean episode length: 236.37
    Episode_Reward/reaching_object: 1.5796
    Episode_Reward/rotating_object: 115.1286
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 2.27s
                      Time elapsed: 00:29:37
                               ETA: 00:29:44

################################################################################
                     [1m Learning iteration 749/1500 [0m                      

                       Computation: 45395 steps/s (collection: 2.032s, learning 0.134s)
             Mean action noise std: 2.74
          Mean value_function loss: 119.5437
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 74.2831
                       Mean reward: 582.73
               Mean episode length: 224.27
    Episode_Reward/reaching_object: 1.5374
    Episode_Reward/rotating_object: 112.0676
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 2.17s
                      Time elapsed: 00:29:39
                               ETA: 00:29:42

################################################################################
                     [1m Learning iteration 750/1500 [0m                      

                       Computation: 42896 steps/s (collection: 2.189s, learning 0.103s)
             Mean action noise std: 2.74
          Mean value_function loss: 120.1545
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 74.3085
                       Mean reward: 626.23
               Mean episode length: 233.54
    Episode_Reward/reaching_object: 1.5888
    Episode_Reward/rotating_object: 118.5643
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 2.29s
                      Time elapsed: 00:29:42
                               ETA: 00:29:39

################################################################################
                     [1m Learning iteration 751/1500 [0m                      

                       Computation: 42757 steps/s (collection: 2.165s, learning 0.135s)
             Mean action noise std: 2.75
          Mean value_function loss: 102.1783
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 74.3432
                       Mean reward: 603.27
               Mean episode length: 233.16
    Episode_Reward/reaching_object: 1.5646
    Episode_Reward/rotating_object: 113.7606
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 2.30s
                      Time elapsed: 00:29:44
                               ETA: 00:29:37

################################################################################
                     [1m Learning iteration 752/1500 [0m                      

                       Computation: 42362 steps/s (collection: 2.150s, learning 0.171s)
             Mean action noise std: 2.75
          Mean value_function loss: 112.4483
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 74.3598
                       Mean reward: 600.30
               Mean episode length: 231.05
    Episode_Reward/reaching_object: 1.6012
    Episode_Reward/rotating_object: 119.1358
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 2.32s
                      Time elapsed: 00:29:46
                               ETA: 00:29:34

################################################################################
                     [1m Learning iteration 753/1500 [0m                      

                       Computation: 43999 steps/s (collection: 2.141s, learning 0.093s)
             Mean action noise std: 2.75
          Mean value_function loss: 120.7032
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 74.3789
                       Mean reward: 602.76
               Mean episode length: 229.05
    Episode_Reward/reaching_object: 1.5654
    Episode_Reward/rotating_object: 113.6084
        Episode_Reward/action_rate: -0.0522
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 2.23s
                      Time elapsed: 00:29:48
                               ETA: 00:29:32

################################################################################
                     [1m Learning iteration 754/1500 [0m                      

                       Computation: 44596 steps/s (collection: 2.114s, learning 0.091s)
             Mean action noise std: 2.75
          Mean value_function loss: 110.5941
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 74.4089
                       Mean reward: 558.88
               Mean episode length: 215.54
    Episode_Reward/reaching_object: 1.5506
    Episode_Reward/rotating_object: 114.7071
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 2.20s
                      Time elapsed: 00:29:51
                               ETA: 00:29:29

################################################################################
                     [1m Learning iteration 755/1500 [0m                      

                       Computation: 44620 steps/s (collection: 2.105s, learning 0.098s)
             Mean action noise std: 2.75
          Mean value_function loss: 109.1044
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 74.4304
                       Mean reward: 554.69
               Mean episode length: 222.20
    Episode_Reward/reaching_object: 1.5853
    Episode_Reward/rotating_object: 119.0232
        Episode_Reward/action_rate: -0.0529
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 2.20s
                      Time elapsed: 00:29:53
                               ETA: 00:29:27

################################################################################
                     [1m Learning iteration 756/1500 [0m                      

                       Computation: 43210 steps/s (collection: 2.112s, learning 0.163s)
             Mean action noise std: 2.76
          Mean value_function loss: 103.4951
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 74.4483
                       Mean reward: 561.98
               Mean episode length: 222.29
    Episode_Reward/reaching_object: 1.6135
    Episode_Reward/rotating_object: 118.3636
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 2.28s
                      Time elapsed: 00:29:55
                               ETA: 00:29:24

################################################################################
                     [1m Learning iteration 757/1500 [0m                      

                       Computation: 44472 steps/s (collection: 2.084s, learning 0.126s)
             Mean action noise std: 2.76
          Mean value_function loss: 92.7426
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 74.4796
                       Mean reward: 607.37
               Mean episode length: 234.73
    Episode_Reward/reaching_object: 1.6013
    Episode_Reward/rotating_object: 115.4082
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 2.21s
                      Time elapsed: 00:29:57
                               ETA: 00:29:22

################################################################################
                     [1m Learning iteration 758/1500 [0m                      

                       Computation: 45144 steps/s (collection: 2.074s, learning 0.103s)
             Mean action noise std: 2.76
          Mean value_function loss: 98.6762
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 74.4996
                       Mean reward: 594.25
               Mean episode length: 228.09
    Episode_Reward/reaching_object: 1.5605
    Episode_Reward/rotating_object: 114.0183
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 2.18s
                      Time elapsed: 00:30:00
                               ETA: 00:29:19

################################################################################
                     [1m Learning iteration 759/1500 [0m                      

                       Computation: 45831 steps/s (collection: 2.054s, learning 0.091s)
             Mean action noise std: 2.76
          Mean value_function loss: 96.4895
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 74.5151
                       Mean reward: 571.52
               Mean episode length: 224.94
    Episode_Reward/reaching_object: 1.5878
    Episode_Reward/rotating_object: 116.8468
        Episode_Reward/action_rate: -0.0535
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 2.14s
                      Time elapsed: 00:30:02
                               ETA: 00:29:17

################################################################################
                     [1m Learning iteration 760/1500 [0m                      

                       Computation: 45532 steps/s (collection: 2.036s, learning 0.123s)
             Mean action noise std: 2.77
          Mean value_function loss: 95.3678
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 74.5396
                       Mean reward: 608.61
               Mean episode length: 232.30
    Episode_Reward/reaching_object: 1.6383
    Episode_Reward/rotating_object: 124.5016
        Episode_Reward/action_rate: -0.0553
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 2.16s
                      Time elapsed: 00:30:04
                               ETA: 00:29:14

################################################################################
                     [1m Learning iteration 761/1500 [0m                      

                       Computation: 45288 steps/s (collection: 2.072s, learning 0.099s)
             Mean action noise std: 2.77
          Mean value_function loss: 91.4576
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 74.5693
                       Mean reward: 594.12
               Mean episode length: 233.24
    Episode_Reward/reaching_object: 1.6080
    Episode_Reward/rotating_object: 118.4731
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 2.17s
                      Time elapsed: 00:30:06
                               ETA: 00:29:12

################################################################################
                     [1m Learning iteration 762/1500 [0m                      

                       Computation: 44162 steps/s (collection: 2.090s, learning 0.136s)
             Mean action noise std: 2.77
          Mean value_function loss: 83.5071
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 74.6044
                       Mean reward: 629.12
               Mean episode length: 234.83
    Episode_Reward/reaching_object: 1.6347
    Episode_Reward/rotating_object: 118.7073
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 2.23s
                      Time elapsed: 00:30:08
                               ETA: 00:29:09

################################################################################
                     [1m Learning iteration 763/1500 [0m                      

                       Computation: 44262 steps/s (collection: 2.111s, learning 0.110s)
             Mean action noise std: 2.78
          Mean value_function loss: 83.4612
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 74.6241
                       Mean reward: 598.20
               Mean episode length: 224.11
    Episode_Reward/reaching_object: 1.5896
    Episode_Reward/rotating_object: 116.9040
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 2.22s
                      Time elapsed: 00:30:10
                               ETA: 00:29:06

################################################################################
                     [1m Learning iteration 764/1500 [0m                      

                       Computation: 45589 steps/s (collection: 2.057s, learning 0.100s)
             Mean action noise std: 2.78
          Mean value_function loss: 97.4713
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 74.6389
                       Mean reward: 594.96
               Mean episode length: 225.39
    Episode_Reward/reaching_object: 1.5969
    Episode_Reward/rotating_object: 118.3851
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 2.16s
                      Time elapsed: 00:30:13
                               ETA: 00:29:04

################################################################################
                     [1m Learning iteration 765/1500 [0m                      

                       Computation: 45638 steps/s (collection: 2.063s, learning 0.091s)
             Mean action noise std: 2.78
          Mean value_function loss: 104.9268
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 74.6649
                       Mean reward: 625.71
               Mean episode length: 237.73
    Episode_Reward/reaching_object: 1.6079
    Episode_Reward/rotating_object: 118.3425
        Episode_Reward/action_rate: -0.0550
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 2.15s
                      Time elapsed: 00:30:15
                               ETA: 00:29:01

################################################################################
                     [1m Learning iteration 766/1500 [0m                      

                       Computation: 45068 steps/s (collection: 2.090s, learning 0.091s)
             Mean action noise std: 2.78
          Mean value_function loss: 113.0572
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 74.6893
                       Mean reward: 607.04
               Mean episode length: 226.24
    Episode_Reward/reaching_object: 1.5604
    Episode_Reward/rotating_object: 116.2459
        Episode_Reward/action_rate: -0.0538
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 2.18s
                      Time elapsed: 00:30:17
                               ETA: 00:28:59

################################################################################
                     [1m Learning iteration 767/1500 [0m                      

                       Computation: 43886 steps/s (collection: 2.122s, learning 0.118s)
             Mean action noise std: 2.78
          Mean value_function loss: 86.7160
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 74.7100
                       Mean reward: 622.66
               Mean episode length: 235.03
    Episode_Reward/reaching_object: 1.6219
    Episode_Reward/rotating_object: 122.2275
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 2.24s
                      Time elapsed: 00:30:19
                               ETA: 00:28:56

################################################################################
                     [1m Learning iteration 768/1500 [0m                      

                       Computation: 42217 steps/s (collection: 2.179s, learning 0.149s)
             Mean action noise std: 2.79
          Mean value_function loss: 98.0621
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 74.7413
                       Mean reward: 601.27
               Mean episode length: 229.20
    Episode_Reward/reaching_object: 1.5956
    Episode_Reward/rotating_object: 119.2596
        Episode_Reward/action_rate: -0.0553
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 2.33s
                      Time elapsed: 00:30:22
                               ETA: 00:28:54

################################################################################
                     [1m Learning iteration 769/1500 [0m                      

                       Computation: 43956 steps/s (collection: 2.134s, learning 0.103s)
             Mean action noise std: 2.79
          Mean value_function loss: 86.2443
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 74.7732
                       Mean reward: 614.69
               Mean episode length: 231.51
    Episode_Reward/reaching_object: 1.5706
    Episode_Reward/rotating_object: 115.4319
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 2.24s
                      Time elapsed: 00:30:24
                               ETA: 00:28:51

################################################################################
                     [1m Learning iteration 770/1500 [0m                      

                       Computation: 43347 steps/s (collection: 2.150s, learning 0.118s)
             Mean action noise std: 2.79
          Mean value_function loss: 92.8654
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 74.8001
                       Mean reward: 604.45
               Mean episode length: 230.66
    Episode_Reward/reaching_object: 1.5840
    Episode_Reward/rotating_object: 117.6829
        Episode_Reward/action_rate: -0.0551
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 2.27s
                      Time elapsed: 00:30:26
                               ETA: 00:28:49

################################################################################
                     [1m Learning iteration 771/1500 [0m                      

                       Computation: 42121 steps/s (collection: 2.231s, learning 0.103s)
             Mean action noise std: 2.80
          Mean value_function loss: 89.5380
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 74.8336
                       Mean reward: 620.44
               Mean episode length: 231.39
    Episode_Reward/reaching_object: 1.5835
    Episode_Reward/rotating_object: 118.4847
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 2.33s
                      Time elapsed: 00:30:28
                               ETA: 00:28:47

################################################################################
                     [1m Learning iteration 772/1500 [0m                      

                       Computation: 45321 steps/s (collection: 2.056s, learning 0.113s)
             Mean action noise std: 2.80
          Mean value_function loss: 88.0553
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 74.8519
                       Mean reward: 648.70
               Mean episode length: 235.65
    Episode_Reward/reaching_object: 1.5904
    Episode_Reward/rotating_object: 120.1776
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 2.17s
                      Time elapsed: 00:30:31
                               ETA: 00:28:44

################################################################################
                     [1m Learning iteration 773/1500 [0m                      

                       Computation: 45597 steps/s (collection: 2.040s, learning 0.116s)
             Mean action noise std: 2.80
          Mean value_function loss: 99.3969
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 74.8811
                       Mean reward: 609.69
               Mean episode length: 226.90
    Episode_Reward/reaching_object: 1.5839
    Episode_Reward/rotating_object: 120.5554
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 2.16s
                      Time elapsed: 00:30:33
                               ETA: 00:28:41

################################################################################
                     [1m Learning iteration 774/1500 [0m                      

                       Computation: 44425 steps/s (collection: 2.101s, learning 0.112s)
             Mean action noise std: 2.81
          Mean value_function loss: 109.3705
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 74.9190
                       Mean reward: 556.78
               Mean episode length: 228.82
    Episode_Reward/reaching_object: 1.5597
    Episode_Reward/rotating_object: 114.5606
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 2.21s
                      Time elapsed: 00:30:35
                               ETA: 00:28:39

################################################################################
                     [1m Learning iteration 775/1500 [0m                      

                       Computation: 43085 steps/s (collection: 2.151s, learning 0.130s)
             Mean action noise std: 2.81
          Mean value_function loss: 103.4225
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 74.9410
                       Mean reward: 592.65
               Mean episode length: 231.15
    Episode_Reward/reaching_object: 1.5985
    Episode_Reward/rotating_object: 118.5335
        Episode_Reward/action_rate: -0.0564
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 2.28s
                      Time elapsed: 00:30:37
                               ETA: 00:28:36

################################################################################
                     [1m Learning iteration 776/1500 [0m                      

                       Computation: 45822 steps/s (collection: 2.016s, learning 0.129s)
             Mean action noise std: 2.81
          Mean value_function loss: 92.7842
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 74.9671
                       Mean reward: 584.92
               Mean episode length: 225.90
    Episode_Reward/reaching_object: 1.5542
    Episode_Reward/rotating_object: 115.1142
        Episode_Reward/action_rate: -0.0550
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 2.15s
                      Time elapsed: 00:30:39
                               ETA: 00:28:34

################################################################################
                     [1m Learning iteration 777/1500 [0m                      

                       Computation: 43426 steps/s (collection: 2.097s, learning 0.167s)
             Mean action noise std: 2.81
          Mean value_function loss: 89.4354
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 74.9920
                       Mean reward: 589.18
               Mean episode length: 231.65
    Episode_Reward/reaching_object: 1.6066
    Episode_Reward/rotating_object: 117.0353
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 2.26s
                      Time elapsed: 00:30:42
                               ETA: 00:28:31

################################################################################
                     [1m Learning iteration 778/1500 [0m                      

                       Computation: 45165 steps/s (collection: 2.086s, learning 0.091s)
             Mean action noise std: 2.81
          Mean value_function loss: 94.7125
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 75.0063
                       Mean reward: 597.65
               Mean episode length: 230.41
    Episode_Reward/reaching_object: 1.5808
    Episode_Reward/rotating_object: 117.5532
        Episode_Reward/action_rate: -0.0562
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 2.18s
                      Time elapsed: 00:30:44
                               ETA: 00:28:29

################################################################################
                     [1m Learning iteration 779/1500 [0m                      

                       Computation: 44106 steps/s (collection: 2.134s, learning 0.095s)
             Mean action noise std: 2.82
          Mean value_function loss: 104.9478
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 75.0257
                       Mean reward: 588.30
               Mean episode length: 232.99
    Episode_Reward/reaching_object: 1.5967
    Episode_Reward/rotating_object: 119.7563
        Episode_Reward/action_rate: -0.0565
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 2.23s
                      Time elapsed: 00:30:46
                               ETA: 00:28:26

################################################################################
                     [1m Learning iteration 780/1500 [0m                      

                       Computation: 45082 steps/s (collection: 2.078s, learning 0.102s)
             Mean action noise std: 2.82
          Mean value_function loss: 100.9716
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 75.0647
                       Mean reward: 577.04
               Mean episode length: 222.65
    Episode_Reward/reaching_object: 1.5430
    Episode_Reward/rotating_object: 112.0919
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 2.18s
                      Time elapsed: 00:30:48
                               ETA: 00:28:24

################################################################################
                     [1m Learning iteration 781/1500 [0m                      

                       Computation: 43769 steps/s (collection: 2.118s, learning 0.128s)
             Mean action noise std: 2.82
          Mean value_function loss: 103.1776
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 75.0993
                       Mean reward: 594.80
               Mean episode length: 229.22
    Episode_Reward/reaching_object: 1.5758
    Episode_Reward/rotating_object: 117.4599
        Episode_Reward/action_rate: -0.0561
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 2.25s
                      Time elapsed: 00:30:50
                               ETA: 00:28:21

################################################################################
                     [1m Learning iteration 782/1500 [0m                      

                       Computation: 45025 steps/s (collection: 2.052s, learning 0.132s)
             Mean action noise std: 2.83
          Mean value_function loss: 99.6836
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 75.1204
                       Mean reward: 578.87
               Mean episode length: 225.36
    Episode_Reward/reaching_object: 1.5551
    Episode_Reward/rotating_object: 116.8316
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 2.18s
                      Time elapsed: 00:30:53
                               ETA: 00:28:19

################################################################################
                     [1m Learning iteration 783/1500 [0m                      

                       Computation: 44596 steps/s (collection: 2.093s, learning 0.112s)
             Mean action noise std: 2.83
          Mean value_function loss: 94.8277
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 75.1429
                       Mean reward: 604.80
               Mean episode length: 231.11
    Episode_Reward/reaching_object: 1.5723
    Episode_Reward/rotating_object: 118.5108
        Episode_Reward/action_rate: -0.0560
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 2.20s
                      Time elapsed: 00:30:55
                               ETA: 00:28:16

################################################################################
                     [1m Learning iteration 784/1500 [0m                      

                       Computation: 44055 steps/s (collection: 2.070s, learning 0.162s)
             Mean action noise std: 2.83
          Mean value_function loss: 95.3709
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 75.1696
                       Mean reward: 597.14
               Mean episode length: 226.99
    Episode_Reward/reaching_object: 1.6125
    Episode_Reward/rotating_object: 120.5972
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 2.23s
                      Time elapsed: 00:30:57
                               ETA: 00:28:14

################################################################################
                     [1m Learning iteration 785/1500 [0m                      

                       Computation: 44040 steps/s (collection: 2.117s, learning 0.115s)
             Mean action noise std: 2.84
          Mean value_function loss: 98.7574
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 75.1976
                       Mean reward: 615.68
               Mean episode length: 229.37
    Episode_Reward/reaching_object: 1.5894
    Episode_Reward/rotating_object: 118.9656
        Episode_Reward/action_rate: -0.0566
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 2.23s
                      Time elapsed: 00:30:59
                               ETA: 00:28:11

################################################################################
                     [1m Learning iteration 786/1500 [0m                      

                       Computation: 43112 steps/s (collection: 2.156s, learning 0.125s)
             Mean action noise std: 2.84
          Mean value_function loss: 102.2135
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 75.2234
                       Mean reward: 580.47
               Mean episode length: 227.64
    Episode_Reward/reaching_object: 1.6019
    Episode_Reward/rotating_object: 119.4770
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 2.28s
                      Time elapsed: 00:31:02
                               ETA: 00:28:09

################################################################################
                     [1m Learning iteration 787/1500 [0m                      

                       Computation: 44860 steps/s (collection: 2.073s, learning 0.118s)
             Mean action noise std: 2.84
          Mean value_function loss: 105.1202
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 75.2485
                       Mean reward: 594.43
               Mean episode length: 227.94
    Episode_Reward/reaching_object: 1.5462
    Episode_Reward/rotating_object: 113.1127
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 2.19s
                      Time elapsed: 00:31:04
                               ETA: 00:28:06

################################################################################
                     [1m Learning iteration 788/1500 [0m                      

                       Computation: 43909 steps/s (collection: 2.112s, learning 0.127s)
             Mean action noise std: 2.84
          Mean value_function loss: 89.0432
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 75.2740
                       Mean reward: 640.43
               Mean episode length: 236.73
    Episode_Reward/reaching_object: 1.6034
    Episode_Reward/rotating_object: 121.8948
        Episode_Reward/action_rate: -0.0576
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 2.24s
                      Time elapsed: 00:31:06
                               ETA: 00:28:04

################################################################################
                     [1m Learning iteration 789/1500 [0m                      

                       Computation: 44215 steps/s (collection: 2.131s, learning 0.092s)
             Mean action noise std: 2.84
          Mean value_function loss: 96.4679
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 75.2942
                       Mean reward: 644.77
               Mean episode length: 235.13
    Episode_Reward/reaching_object: 1.5975
    Episode_Reward/rotating_object: 121.7102
        Episode_Reward/action_rate: -0.0576
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 2.22s
                      Time elapsed: 00:31:08
                               ETA: 00:28:01

################################################################################
                     [1m Learning iteration 790/1500 [0m                      

                       Computation: 44445 steps/s (collection: 2.055s, learning 0.157s)
             Mean action noise std: 2.85
          Mean value_function loss: 90.6095
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 75.3226
                       Mean reward: 584.85
               Mean episode length: 226.12
    Episode_Reward/reaching_object: 1.5973
    Episode_Reward/rotating_object: 119.7655
        Episode_Reward/action_rate: -0.0579
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 2.21s
                      Time elapsed: 00:31:10
                               ETA: 00:27:59

################################################################################
                     [1m Learning iteration 791/1500 [0m                      

                       Computation: 42761 steps/s (collection: 2.134s, learning 0.165s)
             Mean action noise std: 2.85
          Mean value_function loss: 94.7294
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 75.3550
                       Mean reward: 617.35
               Mean episode length: 234.35
    Episode_Reward/reaching_object: 1.5826
    Episode_Reward/rotating_object: 119.3201
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 2.30s
                      Time elapsed: 00:31:13
                               ETA: 00:27:56

################################################################################
                     [1m Learning iteration 792/1500 [0m                      

                       Computation: 39934 steps/s (collection: 2.325s, learning 0.137s)
             Mean action noise std: 2.85
          Mean value_function loss: 93.4153
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 75.3743
                       Mean reward: 646.85
               Mean episode length: 239.33
    Episode_Reward/reaching_object: 1.6123
    Episode_Reward/rotating_object: 124.5837
        Episode_Reward/action_rate: -0.0587
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 2.46s
                      Time elapsed: 00:31:15
                               ETA: 00:27:54

################################################################################
                     [1m Learning iteration 793/1500 [0m                      

                       Computation: 45341 steps/s (collection: 2.079s, learning 0.090s)
             Mean action noise std: 2.86
          Mean value_function loss: 92.7897
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 75.3978
                       Mean reward: 618.35
               Mean episode length: 233.72
    Episode_Reward/reaching_object: 1.6129
    Episode_Reward/rotating_object: 120.9659
        Episode_Reward/action_rate: -0.0591
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 2.17s
                      Time elapsed: 00:31:17
                               ETA: 00:27:52

################################################################################
                     [1m Learning iteration 794/1500 [0m                      

                       Computation: 43438 steps/s (collection: 2.172s, learning 0.091s)
             Mean action noise std: 2.86
          Mean value_function loss: 90.9967
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 75.4231
                       Mean reward: 596.32
               Mean episode length: 228.85
    Episode_Reward/reaching_object: 1.5883
    Episode_Reward/rotating_object: 120.4674
        Episode_Reward/action_rate: -0.0581
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 2.26s
                      Time elapsed: 00:31:20
                               ETA: 00:27:49

################################################################################
                     [1m Learning iteration 795/1500 [0m                      

                       Computation: 45705 steps/s (collection: 2.059s, learning 0.092s)
             Mean action noise std: 2.86
          Mean value_function loss: 91.9835
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 75.4521
                       Mean reward: 605.72
               Mean episode length: 236.66
    Episode_Reward/reaching_object: 1.6355
    Episode_Reward/rotating_object: 121.2937
        Episode_Reward/action_rate: -0.0599
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 2.15s
                      Time elapsed: 00:31:22
                               ETA: 00:27:47

################################################################################
                     [1m Learning iteration 796/1500 [0m                      

                       Computation: 44380 steps/s (collection: 2.104s, learning 0.111s)
             Mean action noise std: 2.86
          Mean value_function loss: 91.1405
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 75.4625
                       Mean reward: 562.60
               Mean episode length: 227.13
    Episode_Reward/reaching_object: 1.6136
    Episode_Reward/rotating_object: 121.1928
        Episode_Reward/action_rate: -0.0593
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 2.22s
                      Time elapsed: 00:31:24
                               ETA: 00:27:44

################################################################################
                     [1m Learning iteration 797/1500 [0m                      

                       Computation: 42730 steps/s (collection: 2.146s, learning 0.154s)
             Mean action noise std: 2.86
          Mean value_function loss: 98.6756
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 75.4669
                       Mean reward: 617.54
               Mean episode length: 232.84
    Episode_Reward/reaching_object: 1.5624
    Episode_Reward/rotating_object: 116.4886
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 2.30s
                      Time elapsed: 00:31:26
                               ETA: 00:27:42

################################################################################
                     [1m Learning iteration 798/1500 [0m                      

                       Computation: 42643 steps/s (collection: 2.216s, learning 0.089s)
             Mean action noise std: 2.86
          Mean value_function loss: 103.1418
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 75.4786
                       Mean reward: 577.77
               Mean episode length: 226.45
    Episode_Reward/reaching_object: 1.5957
    Episode_Reward/rotating_object: 119.0319
        Episode_Reward/action_rate: -0.0587
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 2.31s
                      Time elapsed: 00:31:29
                               ETA: 00:27:39

################################################################################
                     [1m Learning iteration 799/1500 [0m                      

                       Computation: 44001 steps/s (collection: 2.115s, learning 0.119s)
             Mean action noise std: 2.87
          Mean value_function loss: 97.3273
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 75.5045
                       Mean reward: 624.66
               Mean episode length: 230.42
    Episode_Reward/reaching_object: 1.6299
    Episode_Reward/rotating_object: 122.2279
        Episode_Reward/action_rate: -0.0597
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 2.23s
                      Time elapsed: 00:31:31
                               ETA: 00:27:37

################################################################################
                     [1m Learning iteration 800/1500 [0m                      

                       Computation: 44961 steps/s (collection: 2.091s, learning 0.096s)
             Mean action noise std: 2.87
          Mean value_function loss: 103.9031
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 75.5266
                       Mean reward: 564.21
               Mean episode length: 221.11
    Episode_Reward/reaching_object: 1.5804
    Episode_Reward/rotating_object: 114.7891
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 2.19s
                      Time elapsed: 00:31:33
                               ETA: 00:27:34

################################################################################
                     [1m Learning iteration 801/1500 [0m                      

                       Computation: 41799 steps/s (collection: 2.242s, learning 0.110s)
             Mean action noise std: 2.87
          Mean value_function loss: 108.2051
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 75.5450
                       Mean reward: 593.35
               Mean episode length: 225.39
    Episode_Reward/reaching_object: 1.6164
    Episode_Reward/rotating_object: 122.1872
        Episode_Reward/action_rate: -0.0596
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 2.35s
                      Time elapsed: 00:31:35
                               ETA: 00:27:32

################################################################################
                     [1m Learning iteration 802/1500 [0m                      

                       Computation: 42691 steps/s (collection: 2.176s, learning 0.127s)
             Mean action noise std: 2.88
          Mean value_function loss: 112.1430
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 75.5794
                       Mean reward: 619.23
               Mean episode length: 232.90
    Episode_Reward/reaching_object: 1.6013
    Episode_Reward/rotating_object: 117.0006
        Episode_Reward/action_rate: -0.0591
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 2.30s
                      Time elapsed: 00:31:38
                               ETA: 00:27:29

################################################################################
                     [1m Learning iteration 803/1500 [0m                      

                       Computation: 42571 steps/s (collection: 2.186s, learning 0.124s)
             Mean action noise std: 2.88
          Mean value_function loss: 103.7406
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 75.6105
                       Mean reward: 628.36
               Mean episode length: 231.89
    Episode_Reward/reaching_object: 1.6095
    Episode_Reward/rotating_object: 120.6396
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 2.31s
                      Time elapsed: 00:31:40
                               ETA: 00:27:27

################################################################################
                     [1m Learning iteration 804/1500 [0m                      

                       Computation: 45462 steps/s (collection: 2.035s, learning 0.127s)
             Mean action noise std: 2.88
          Mean value_function loss: 101.6726
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 75.6281
                       Mean reward: 587.13
               Mean episode length: 235.23
    Episode_Reward/reaching_object: 1.6163
    Episode_Reward/rotating_object: 117.3063
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 2.16s
                      Time elapsed: 00:31:42
                               ETA: 00:27:25

################################################################################
                     [1m Learning iteration 805/1500 [0m                      

                       Computation: 43401 steps/s (collection: 2.164s, learning 0.101s)
             Mean action noise std: 2.88
          Mean value_function loss: 98.1056
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 75.6564
                       Mean reward: 619.81
               Mean episode length: 229.13
    Episode_Reward/reaching_object: 1.6012
    Episode_Reward/rotating_object: 118.9562
        Episode_Reward/action_rate: -0.0588
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 2.26s
                      Time elapsed: 00:31:44
                               ETA: 00:27:22

################################################################################
                     [1m Learning iteration 806/1500 [0m                      

                       Computation: 44077 steps/s (collection: 2.100s, learning 0.131s)
             Mean action noise std: 2.89
          Mean value_function loss: 110.5845
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 75.6793
                       Mean reward: 615.29
               Mean episode length: 229.83
    Episode_Reward/reaching_object: 1.6218
    Episode_Reward/rotating_object: 121.8012
        Episode_Reward/action_rate: -0.0595
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 2.23s
                      Time elapsed: 00:31:47
                               ETA: 00:27:20

################################################################################
                     [1m Learning iteration 807/1500 [0m                      

                       Computation: 41762 steps/s (collection: 2.253s, learning 0.101s)
             Mean action noise std: 2.89
          Mean value_function loss: 115.1302
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 75.7024
                       Mean reward: 587.46
               Mean episode length: 229.04
    Episode_Reward/reaching_object: 1.6121
    Episode_Reward/rotating_object: 118.8727
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 2.35s
                      Time elapsed: 00:31:49
                               ETA: 00:27:17

################################################################################
                     [1m Learning iteration 808/1500 [0m                      

                       Computation: 43520 steps/s (collection: 2.160s, learning 0.098s)
             Mean action noise std: 2.89
          Mean value_function loss: 113.9810
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 75.7244
                       Mean reward: 597.87
               Mean episode length: 223.94
    Episode_Reward/reaching_object: 1.6215
    Episode_Reward/rotating_object: 123.0733
        Episode_Reward/action_rate: -0.0597
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 2.26s
                      Time elapsed: 00:31:51
                               ETA: 00:27:15

################################################################################
                     [1m Learning iteration 809/1500 [0m                      

                       Computation: 42634 steps/s (collection: 2.176s, learning 0.130s)
             Mean action noise std: 2.89
          Mean value_function loss: 123.9962
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 75.7441
                       Mean reward: 569.70
               Mean episode length: 224.63
    Episode_Reward/reaching_object: 1.6099
    Episode_Reward/rotating_object: 119.6264
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 2.31s
                      Time elapsed: 00:31:54
                               ETA: 00:27:12

################################################################################
                     [1m Learning iteration 810/1500 [0m                      

                       Computation: 43126 steps/s (collection: 2.162s, learning 0.117s)
             Mean action noise std: 2.90
          Mean value_function loss: 119.4248
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 75.7689
                       Mean reward: 594.80
               Mean episode length: 230.64
    Episode_Reward/reaching_object: 1.6161
    Episode_Reward/rotating_object: 118.0749
        Episode_Reward/action_rate: -0.0597
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 2.28s
                      Time elapsed: 00:31:56
                               ETA: 00:27:10

################################################################################
                     [1m Learning iteration 811/1500 [0m                      

                       Computation: 45052 steps/s (collection: 2.077s, learning 0.105s)
             Mean action noise std: 2.90
          Mean value_function loss: 137.3388
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 75.7906
                       Mean reward: 594.64
               Mean episode length: 227.99
    Episode_Reward/reaching_object: 1.6038
    Episode_Reward/rotating_object: 117.6613
        Episode_Reward/action_rate: -0.0591
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 2.18s
                      Time elapsed: 00:31:58
                               ETA: 00:27:07

################################################################################
                     [1m Learning iteration 812/1500 [0m                      

                       Computation: 44564 steps/s (collection: 2.105s, learning 0.101s)
             Mean action noise std: 2.90
          Mean value_function loss: 102.2440
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 75.8057
                       Mean reward: 585.34
               Mean episode length: 226.80
    Episode_Reward/reaching_object: 1.6310
    Episode_Reward/rotating_object: 119.3089
        Episode_Reward/action_rate: -0.0601
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 2.21s
                      Time elapsed: 00:32:00
                               ETA: 00:27:05

################################################################################
                     [1m Learning iteration 813/1500 [0m                      

                       Computation: 45467 steps/s (collection: 2.064s, learning 0.098s)
             Mean action noise std: 2.90
          Mean value_function loss: 112.5380
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 75.8293
                       Mean reward: 596.94
               Mean episode length: 225.59
    Episode_Reward/reaching_object: 1.6463
    Episode_Reward/rotating_object: 121.4258
        Episode_Reward/action_rate: -0.0608
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 2.16s
                      Time elapsed: 00:32:02
                               ETA: 00:27:02

################################################################################
                     [1m Learning iteration 814/1500 [0m                      

                       Computation: 44100 steps/s (collection: 2.100s, learning 0.130s)
             Mean action noise std: 2.91
          Mean value_function loss: 110.4115
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 75.8520
                       Mean reward: 605.86
               Mean episode length: 230.89
    Episode_Reward/reaching_object: 1.5911
    Episode_Reward/rotating_object: 116.5107
        Episode_Reward/action_rate: -0.0589
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 2.23s
                      Time elapsed: 00:32:05
                               ETA: 00:27:00

################################################################################
                     [1m Learning iteration 815/1500 [0m                      

                       Computation: 43223 steps/s (collection: 2.099s, learning 0.176s)
             Mean action noise std: 2.91
          Mean value_function loss: 120.9253
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 75.8819
                       Mean reward: 578.62
               Mean episode length: 230.19
    Episode_Reward/reaching_object: 1.6118
    Episode_Reward/rotating_object: 116.2020
        Episode_Reward/action_rate: -0.0598
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 2.27s
                      Time elapsed: 00:32:07
                               ETA: 00:26:57

################################################################################
                     [1m Learning iteration 816/1500 [0m                      

                       Computation: 45230 steps/s (collection: 2.062s, learning 0.111s)
             Mean action noise std: 2.91
          Mean value_function loss: 98.0569
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 75.9114
                       Mean reward: 646.92
               Mean episode length: 237.71
    Episode_Reward/reaching_object: 1.6354
    Episode_Reward/rotating_object: 120.5545
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 2.17s
                      Time elapsed: 00:32:09
                               ETA: 00:26:55

################################################################################
                     [1m Learning iteration 817/1500 [0m                      

                       Computation: 45439 steps/s (collection: 2.064s, learning 0.100s)
             Mean action noise std: 2.91
          Mean value_function loss: 120.1519
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 75.9273
                       Mean reward: 632.71
               Mean episode length: 235.12
    Episode_Reward/reaching_object: 1.6614
    Episode_Reward/rotating_object: 121.3486
        Episode_Reward/action_rate: -0.0611
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 2.16s
                      Time elapsed: 00:32:11
                               ETA: 00:26:52

################################################################################
                     [1m Learning iteration 818/1500 [0m                      

                       Computation: 45456 steps/s (collection: 2.066s, learning 0.097s)
             Mean action noise std: 2.92
          Mean value_function loss: 103.2135
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 75.9441
                       Mean reward: 589.40
               Mean episode length: 229.31
    Episode_Reward/reaching_object: 1.6175
    Episode_Reward/rotating_object: 119.9444
        Episode_Reward/action_rate: -0.0599
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 2.16s
                      Time elapsed: 00:32:13
                               ETA: 00:26:50

################################################################################
                     [1m Learning iteration 819/1500 [0m                      

                       Computation: 46202 steps/s (collection: 2.032s, learning 0.096s)
             Mean action noise std: 2.92
          Mean value_function loss: 91.7711
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 75.9821
                       Mean reward: 626.71
               Mean episode length: 236.03
    Episode_Reward/reaching_object: 1.6505
    Episode_Reward/rotating_object: 122.4325
        Episode_Reward/action_rate: -0.0613
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 2.13s
                      Time elapsed: 00:32:16
                               ETA: 00:26:47

################################################################################
                     [1m Learning iteration 820/1500 [0m                      

                       Computation: 44310 steps/s (collection: 2.075s, learning 0.143s)
             Mean action noise std: 2.92
          Mean value_function loss: 103.5782
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 76.0125
                       Mean reward: 598.32
               Mean episode length: 226.36
    Episode_Reward/reaching_object: 1.6002
    Episode_Reward/rotating_object: 116.6753
        Episode_Reward/action_rate: -0.0595
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 2.22s
                      Time elapsed: 00:32:18
                               ETA: 00:26:45

################################################################################
                     [1m Learning iteration 821/1500 [0m                      

                       Computation: 45179 steps/s (collection: 2.052s, learning 0.124s)
             Mean action noise std: 2.93
          Mean value_function loss: 98.8690
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 76.0282
                       Mean reward: 618.35
               Mean episode length: 229.54
    Episode_Reward/reaching_object: 1.6387
    Episode_Reward/rotating_object: 120.0545
        Episode_Reward/action_rate: -0.0609
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 2.18s
                      Time elapsed: 00:32:20
                               ETA: 00:26:42

################################################################################
                     [1m Learning iteration 822/1500 [0m                      

                       Computation: 45967 steps/s (collection: 2.041s, learning 0.098s)
             Mean action noise std: 2.93
          Mean value_function loss: 102.5306
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 76.0452
                       Mean reward: 598.00
               Mean episode length: 229.16
    Episode_Reward/reaching_object: 1.6433
    Episode_Reward/rotating_object: 121.5570
        Episode_Reward/action_rate: -0.0612
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 2.14s
                      Time elapsed: 00:32:22
                               ETA: 00:26:40

################################################################################
                     [1m Learning iteration 823/1500 [0m                      

                       Computation: 44416 steps/s (collection: 2.125s, learning 0.088s)
             Mean action noise std: 2.93
          Mean value_function loss: 102.4652
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 76.0757
                       Mean reward: 595.20
               Mean episode length: 229.84
    Episode_Reward/reaching_object: 1.6206
    Episode_Reward/rotating_object: 119.6872
        Episode_Reward/action_rate: -0.0608
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 2.21s
                      Time elapsed: 00:32:24
                               ETA: 00:26:37

################################################################################
                     [1m Learning iteration 824/1500 [0m                      

                       Computation: 43128 steps/s (collection: 2.157s, learning 0.122s)
             Mean action noise std: 2.94
          Mean value_function loss: 83.4011
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 76.1135
                       Mean reward: 612.96
               Mean episode length: 236.10
    Episode_Reward/reaching_object: 1.6605
    Episode_Reward/rotating_object: 121.6530
        Episode_Reward/action_rate: -0.0622
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 2.28s
                      Time elapsed: 00:32:27
                               ETA: 00:26:35

################################################################################
                     [1m Learning iteration 825/1500 [0m                      

                       Computation: 45020 steps/s (collection: 2.055s, learning 0.128s)
             Mean action noise std: 2.94
          Mean value_function loss: 91.0145
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 76.1476
                       Mean reward: 571.41
               Mean episode length: 228.10
    Episode_Reward/reaching_object: 1.6202
    Episode_Reward/rotating_object: 121.1358
        Episode_Reward/action_rate: -0.0614
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 2.18s
                      Time elapsed: 00:32:29
                               ETA: 00:26:32

################################################################################
                     [1m Learning iteration 826/1500 [0m                      

                       Computation: 44846 steps/s (collection: 2.061s, learning 0.132s)
             Mean action noise std: 2.94
          Mean value_function loss: 89.0546
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 76.1763
                       Mean reward: 568.97
               Mean episode length: 222.88
    Episode_Reward/reaching_object: 1.5967
    Episode_Reward/rotating_object: 116.4479
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 2.19s
                      Time elapsed: 00:32:31
                               ETA: 00:26:30

################################################################################
                     [1m Learning iteration 827/1500 [0m                      

                       Computation: 45544 steps/s (collection: 2.051s, learning 0.107s)
             Mean action noise std: 2.94
          Mean value_function loss: 87.4385
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 76.2081
                       Mean reward: 583.31
               Mean episode length: 230.19
    Episode_Reward/reaching_object: 1.6387
    Episode_Reward/rotating_object: 121.3646
        Episode_Reward/action_rate: -0.0622
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 2.16s
                      Time elapsed: 00:32:33
                               ETA: 00:26:27

################################################################################
                     [1m Learning iteration 828/1500 [0m                      

                       Computation: 45702 steps/s (collection: 2.052s, learning 0.099s)
             Mean action noise std: 2.95
          Mean value_function loss: 76.8410
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 76.2326
                       Mean reward: 627.54
               Mean episode length: 235.41
    Episode_Reward/reaching_object: 1.6548
    Episode_Reward/rotating_object: 125.1989
        Episode_Reward/action_rate: -0.0626
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 2.15s
                      Time elapsed: 00:32:35
                               ETA: 00:26:25

################################################################################
                     [1m Learning iteration 829/1500 [0m                      

                       Computation: 42653 steps/s (collection: 2.213s, learning 0.092s)
             Mean action noise std: 2.95
          Mean value_function loss: 94.6018
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 76.2588
                       Mean reward: 646.01
               Mean episode length: 231.76
    Episode_Reward/reaching_object: 1.6142
    Episode_Reward/rotating_object: 119.7142
        Episode_Reward/action_rate: -0.0613
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 2.30s
                      Time elapsed: 00:32:38
                               ETA: 00:26:22

################################################################################
                     [1m Learning iteration 830/1500 [0m                      

                       Computation: 43088 steps/s (collection: 2.177s, learning 0.105s)
             Mean action noise std: 2.95
          Mean value_function loss: 100.4640
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 76.2929
                       Mean reward: 615.73
               Mean episode length: 232.81
    Episode_Reward/reaching_object: 1.6255
    Episode_Reward/rotating_object: 119.5184
        Episode_Reward/action_rate: -0.0618
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 2.28s
                      Time elapsed: 00:32:40
                               ETA: 00:26:20

################################################################################
                     [1m Learning iteration 831/1500 [0m                      

                       Computation: 45368 steps/s (collection: 2.054s, learning 0.113s)
             Mean action noise std: 2.96
          Mean value_function loss: 117.9877
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 76.3322
                       Mean reward: 582.20
               Mean episode length: 219.66
    Episode_Reward/reaching_object: 1.5618
    Episode_Reward/rotating_object: 116.6309
        Episode_Reward/action_rate: -0.0597
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 2.17s
                      Time elapsed: 00:32:42
                               ETA: 00:26:18

################################################################################
                     [1m Learning iteration 832/1500 [0m                      

                       Computation: 45535 steps/s (collection: 2.054s, learning 0.105s)
             Mean action noise std: 2.96
          Mean value_function loss: 107.9502
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 76.3688
                       Mean reward: 545.98
               Mean episode length: 217.76
    Episode_Reward/reaching_object: 1.5811
    Episode_Reward/rotating_object: 119.0128
        Episode_Reward/action_rate: -0.0608
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 2.16s
                      Time elapsed: 00:32:44
                               ETA: 00:26:15

################################################################################
                     [1m Learning iteration 833/1500 [0m                      

                       Computation: 45788 steps/s (collection: 2.055s, learning 0.092s)
             Mean action noise std: 2.96
          Mean value_function loss: 110.1023
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 76.3955
                       Mean reward: 597.18
               Mean episode length: 222.45
    Episode_Reward/reaching_object: 1.5903
    Episode_Reward/rotating_object: 118.5032
        Episode_Reward/action_rate: -0.0613
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 2.15s
                      Time elapsed: 00:32:46
                               ETA: 00:26:12

################################################################################
                     [1m Learning iteration 834/1500 [0m                      

                       Computation: 45615 steps/s (collection: 2.053s, learning 0.102s)
             Mean action noise std: 2.97
          Mean value_function loss: 90.4341
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 76.4197
                       Mean reward: 573.07
               Mean episode length: 221.39
    Episode_Reward/reaching_object: 1.6306
    Episode_Reward/rotating_object: 120.8331
        Episode_Reward/action_rate: -0.0630
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 2.16s
                      Time elapsed: 00:32:48
                               ETA: 00:26:10

################################################################################
                     [1m Learning iteration 835/1500 [0m                      

                       Computation: 43603 steps/s (collection: 2.148s, learning 0.106s)
             Mean action noise std: 2.97
          Mean value_function loss: 95.4193
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 76.4457
                       Mean reward: 641.07
               Mean episode length: 236.07
    Episode_Reward/reaching_object: 1.5985
    Episode_Reward/rotating_object: 122.2487
        Episode_Reward/action_rate: -0.0616
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 2.25s
                      Time elapsed: 00:32:51
                               ETA: 00:26:08

################################################################################
                     [1m Learning iteration 836/1500 [0m                      

                       Computation: 41862 steps/s (collection: 2.197s, learning 0.152s)
             Mean action noise std: 2.97
          Mean value_function loss: 94.1289
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 76.4692
                       Mean reward: 643.30
               Mean episode length: 234.35
    Episode_Reward/reaching_object: 1.5942
    Episode_Reward/rotating_object: 117.2063
        Episode_Reward/action_rate: -0.0616
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 2.35s
                      Time elapsed: 00:32:53
                               ETA: 00:26:05

################################################################################
                     [1m Learning iteration 837/1500 [0m                      

                       Computation: 40845 steps/s (collection: 2.230s, learning 0.176s)
             Mean action noise std: 2.97
          Mean value_function loss: 93.1166
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 76.4867
                       Mean reward: 594.05
               Mean episode length: 220.72
    Episode_Reward/reaching_object: 1.6077
    Episode_Reward/rotating_object: 121.5066
        Episode_Reward/action_rate: -0.0622
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 2.41s
                      Time elapsed: 00:32:55
                               ETA: 00:26:03

################################################################################
                     [1m Learning iteration 838/1500 [0m                      

                       Computation: 45277 steps/s (collection: 2.068s, learning 0.103s)
             Mean action noise std: 2.98
          Mean value_function loss: 99.1744
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 76.5029
                       Mean reward: 578.86
               Mean episode length: 227.82
    Episode_Reward/reaching_object: 1.6031
    Episode_Reward/rotating_object: 119.6100
        Episode_Reward/action_rate: -0.0622
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 2.17s
                      Time elapsed: 00:32:58
                               ETA: 00:26:00

################################################################################
                     [1m Learning iteration 839/1500 [0m                      

                       Computation: 43003 steps/s (collection: 2.132s, learning 0.154s)
             Mean action noise std: 2.98
          Mean value_function loss: 94.4008
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 76.5235
                       Mean reward: 602.39
               Mean episode length: 231.23
    Episode_Reward/reaching_object: 1.5952
    Episode_Reward/rotating_object: 116.5565
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 2.29s
                      Time elapsed: 00:33:00
                               ETA: 00:25:58

################################################################################
                     [1m Learning iteration 840/1500 [0m                      

                       Computation: 45151 steps/s (collection: 2.079s, learning 0.098s)
             Mean action noise std: 2.98
          Mean value_function loss: 89.7608
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 76.5516
                       Mean reward: 592.13
               Mean episode length: 226.25
    Episode_Reward/reaching_object: 1.6145
    Episode_Reward/rotating_object: 118.5779
        Episode_Reward/action_rate: -0.0629
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 2.18s
                      Time elapsed: 00:33:02
                               ETA: 00:25:55

################################################################################
                     [1m Learning iteration 841/1500 [0m                      

                       Computation: 42747 steps/s (collection: 2.155s, learning 0.145s)
             Mean action noise std: 2.98
          Mean value_function loss: 91.3752
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 76.5858
                       Mean reward: 619.74
               Mean episode length: 238.14
    Episode_Reward/reaching_object: 1.6186
    Episode_Reward/rotating_object: 120.4358
        Episode_Reward/action_rate: -0.0634
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 2.30s
                      Time elapsed: 00:33:04
                               ETA: 00:25:53

################################################################################
                     [1m Learning iteration 842/1500 [0m                      

                       Computation: 43944 steps/s (collection: 2.115s, learning 0.122s)
             Mean action noise std: 2.99
          Mean value_function loss: 105.3313
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 76.6122
                       Mean reward: 622.77
               Mean episode length: 231.97
    Episode_Reward/reaching_object: 1.6563
    Episode_Reward/rotating_object: 125.7051
        Episode_Reward/action_rate: -0.0646
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 2.24s
                      Time elapsed: 00:33:07
                               ETA: 00:25:51

################################################################################
                     [1m Learning iteration 843/1500 [0m                      

                       Computation: 45245 steps/s (collection: 2.065s, learning 0.108s)
             Mean action noise std: 2.99
          Mean value_function loss: 100.9349
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 76.6411
                       Mean reward: 589.58
               Mean episode length: 219.78
    Episode_Reward/reaching_object: 1.6231
    Episode_Reward/rotating_object: 120.4474
        Episode_Reward/action_rate: -0.0633
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 2.17s
                      Time elapsed: 00:33:09
                               ETA: 00:25:48

################################################################################
                     [1m Learning iteration 844/1500 [0m                      

                       Computation: 45404 steps/s (collection: 2.054s, learning 0.112s)
             Mean action noise std: 2.99
          Mean value_function loss: 97.3394
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 76.6758
                       Mean reward: 628.42
               Mean episode length: 229.64
    Episode_Reward/reaching_object: 1.6087
    Episode_Reward/rotating_object: 121.9276
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 2.17s
                      Time elapsed: 00:33:11
                               ETA: 00:25:46

################################################################################
                     [1m Learning iteration 845/1500 [0m                      

                       Computation: 44119 steps/s (collection: 2.117s, learning 0.111s)
             Mean action noise std: 3.00
          Mean value_function loss: 84.2951
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 76.7103
                       Mean reward: 632.49
               Mean episode length: 240.78
    Episode_Reward/reaching_object: 1.6647
    Episode_Reward/rotating_object: 123.8807
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 2.23s
                      Time elapsed: 00:33:13
                               ETA: 00:25:43

################################################################################
                     [1m Learning iteration 846/1500 [0m                      

                       Computation: 43501 steps/s (collection: 2.132s, learning 0.128s)
             Mean action noise std: 3.00
          Mean value_function loss: 100.3261
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 76.7283
                       Mean reward: 609.17
               Mean episode length: 225.27
    Episode_Reward/reaching_object: 1.6051
    Episode_Reward/rotating_object: 119.8059
        Episode_Reward/action_rate: -0.0629
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 2.26s
                      Time elapsed: 00:33:15
                               ETA: 00:25:41

################################################################################
                     [1m Learning iteration 847/1500 [0m                      

                       Computation: 44819 steps/s (collection: 2.102s, learning 0.092s)
             Mean action noise std: 3.00
          Mean value_function loss: 78.5658
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 76.7476
                       Mean reward: 639.40
               Mean episode length: 242.74
    Episode_Reward/reaching_object: 1.6364
    Episode_Reward/rotating_object: 120.8076
        Episode_Reward/action_rate: -0.0642
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 2.19s
                      Time elapsed: 00:33:18
                               ETA: 00:25:38

################################################################################
                     [1m Learning iteration 848/1500 [0m                      

                       Computation: 44551 steps/s (collection: 2.116s, learning 0.091s)
             Mean action noise std: 3.00
          Mean value_function loss: 90.3382
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 76.7742
                       Mean reward: 603.21
               Mean episode length: 230.59
    Episode_Reward/reaching_object: 1.6048
    Episode_Reward/rotating_object: 120.0890
        Episode_Reward/action_rate: -0.0632
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 2.21s
                      Time elapsed: 00:33:20
                               ETA: 00:25:36

################################################################################
                     [1m Learning iteration 849/1500 [0m                      

                       Computation: 43913 steps/s (collection: 2.128s, learning 0.111s)
             Mean action noise std: 3.01
          Mean value_function loss: 79.9674
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 76.8037
                       Mean reward: 633.76
               Mean episode length: 228.55
    Episode_Reward/reaching_object: 1.6377
    Episode_Reward/rotating_object: 124.2488
        Episode_Reward/action_rate: -0.0643
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 2.24s
                      Time elapsed: 00:33:22
                               ETA: 00:25:33

################################################################################
                     [1m Learning iteration 850/1500 [0m                      

                       Computation: 45092 steps/s (collection: 2.064s, learning 0.116s)
             Mean action noise std: 3.01
          Mean value_function loss: 101.7551
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 76.8302
                       Mean reward: 610.59
               Mean episode length: 229.19
    Episode_Reward/reaching_object: 1.6014
    Episode_Reward/rotating_object: 119.0825
        Episode_Reward/action_rate: -0.0635
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 2.18s
                      Time elapsed: 00:33:24
                               ETA: 00:25:31

################################################################################
                     [1m Learning iteration 851/1500 [0m                      

                       Computation: 41851 steps/s (collection: 2.237s, learning 0.112s)
             Mean action noise std: 3.01
          Mean value_function loss: 99.2428
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 76.8491
                       Mean reward: 620.22
               Mean episode length: 236.58
    Episode_Reward/reaching_object: 1.6427
    Episode_Reward/rotating_object: 124.8479
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 2.35s
                      Time elapsed: 00:33:27
                               ETA: 00:25:28

################################################################################
                     [1m Learning iteration 852/1500 [0m                      

                       Computation: 45118 steps/s (collection: 2.064s, learning 0.115s)
             Mean action noise std: 3.02
          Mean value_function loss: 100.3207
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 76.8813
                       Mean reward: 577.36
               Mean episode length: 225.95
    Episode_Reward/reaching_object: 1.5962
    Episode_Reward/rotating_object: 120.1895
        Episode_Reward/action_rate: -0.0638
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 2.18s
                      Time elapsed: 00:33:29
                               ETA: 00:25:26

################################################################################
                     [1m Learning iteration 853/1500 [0m                      

                       Computation: 43739 steps/s (collection: 2.140s, learning 0.107s)
             Mean action noise std: 3.02
          Mean value_function loss: 92.2571
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 76.9176
                       Mean reward: 581.77
               Mean episode length: 231.12
    Episode_Reward/reaching_object: 1.6459
    Episode_Reward/rotating_object: 122.1533
        Episode_Reward/action_rate: -0.0654
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 2.25s
                      Time elapsed: 00:33:31
                               ETA: 00:25:23

################################################################################
                     [1m Learning iteration 854/1500 [0m                      

                       Computation: 44267 steps/s (collection: 2.094s, learning 0.127s)
             Mean action noise std: 3.02
          Mean value_function loss: 93.9290
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 76.9457
                       Mean reward: 630.02
               Mean episode length: 235.61
    Episode_Reward/reaching_object: 1.6459
    Episode_Reward/rotating_object: 125.4365
        Episode_Reward/action_rate: -0.0653
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 2.22s
                      Time elapsed: 00:33:33
                               ETA: 00:25:21

################################################################################
                     [1m Learning iteration 855/1500 [0m                      

                       Computation: 46144 steps/s (collection: 2.038s, learning 0.093s)
             Mean action noise std: 3.02
          Mean value_function loss: 95.6673
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 76.9665
                       Mean reward: 604.28
               Mean episode length: 225.24
    Episode_Reward/reaching_object: 1.6066
    Episode_Reward/rotating_object: 120.2134
        Episode_Reward/action_rate: -0.0644
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 2.13s
                      Time elapsed: 00:33:35
                               ETA: 00:25:18

################################################################################
                     [1m Learning iteration 856/1500 [0m                      

                       Computation: 44306 steps/s (collection: 2.107s, learning 0.112s)
             Mean action noise std: 3.03
          Mean value_function loss: 98.7188
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 76.9885
                       Mean reward: 635.34
               Mean episode length: 233.57
    Episode_Reward/reaching_object: 1.6152
    Episode_Reward/rotating_object: 119.7710
        Episode_Reward/action_rate: -0.0644
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 2.22s
                      Time elapsed: 00:33:38
                               ETA: 00:25:16

################################################################################
                     [1m Learning iteration 857/1500 [0m                      

                       Computation: 46731 steps/s (collection: 2.008s, learning 0.096s)
             Mean action noise std: 3.03
          Mean value_function loss: 103.9162
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 77.0159
                       Mean reward: 646.81
               Mean episode length: 233.07
    Episode_Reward/reaching_object: 1.6273
    Episode_Reward/rotating_object: 122.9463
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 2.10s
                      Time elapsed: 00:33:40
                               ETA: 00:25:13

################################################################################
                     [1m Learning iteration 858/1500 [0m                      

                       Computation: 43547 steps/s (collection: 2.132s, learning 0.126s)
             Mean action noise std: 3.03
          Mean value_function loss: 99.8542
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 77.0300
                       Mean reward: 569.44
               Mean episode length: 221.68
    Episode_Reward/reaching_object: 1.5971
    Episode_Reward/rotating_object: 120.4569
        Episode_Reward/action_rate: -0.0641
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 2.26s
                      Time elapsed: 00:33:42
                               ETA: 00:25:11

################################################################################
                     [1m Learning iteration 859/1500 [0m                      

                       Computation: 44883 steps/s (collection: 2.090s, learning 0.100s)
             Mean action noise std: 3.03
          Mean value_function loss: 93.9465
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 77.0517
                       Mean reward: 606.51
               Mean episode length: 229.17
    Episode_Reward/reaching_object: 1.6387
    Episode_Reward/rotating_object: 120.2783
        Episode_Reward/action_rate: -0.0655
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 2.19s
                      Time elapsed: 00:33:44
                               ETA: 00:25:09

################################################################################
                     [1m Learning iteration 860/1500 [0m                      

                       Computation: 45381 steps/s (collection: 2.059s, learning 0.107s)
             Mean action noise std: 3.04
          Mean value_function loss: 85.5071
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 77.0679
                       Mean reward: 617.80
               Mean episode length: 232.19
    Episode_Reward/reaching_object: 1.6172
    Episode_Reward/rotating_object: 120.7783
        Episode_Reward/action_rate: -0.0649
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 2.17s
                      Time elapsed: 00:33:46
                               ETA: 00:25:06

################################################################################
                     [1m Learning iteration 861/1500 [0m                      

                       Computation: 43772 steps/s (collection: 2.129s, learning 0.117s)
             Mean action noise std: 3.04
          Mean value_function loss: 86.3134
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 77.0879
                       Mean reward: 622.40
               Mean episode length: 232.63
    Episode_Reward/reaching_object: 1.6444
    Episode_Reward/rotating_object: 120.6593
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 2.25s
                      Time elapsed: 00:33:49
                               ETA: 00:25:04

################################################################################
                     [1m Learning iteration 862/1500 [0m                      

                       Computation: 41031 steps/s (collection: 2.276s, learning 0.120s)
             Mean action noise std: 3.04
          Mean value_function loss: 92.9924
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 77.1106
                       Mean reward: 605.14
               Mean episode length: 226.84
    Episode_Reward/reaching_object: 1.6361
    Episode_Reward/rotating_object: 122.2397
        Episode_Reward/action_rate: -0.0656
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 2.40s
                      Time elapsed: 00:33:51
                               ETA: 00:25:01

################################################################################
                     [1m Learning iteration 863/1500 [0m                      

                       Computation: 43504 steps/s (collection: 2.166s, learning 0.094s)
             Mean action noise std: 3.04
          Mean value_function loss: 89.9666
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 77.1351
                       Mean reward: 619.80
               Mean episode length: 230.13
    Episode_Reward/reaching_object: 1.6200
    Episode_Reward/rotating_object: 120.2908
        Episode_Reward/action_rate: -0.0654
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 2.26s
                      Time elapsed: 00:33:53
                               ETA: 00:24:59

################################################################################
                     [1m Learning iteration 864/1500 [0m                      

                       Computation: 44649 steps/s (collection: 2.108s, learning 0.094s)
             Mean action noise std: 3.05
          Mean value_function loss: 92.7486
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 77.1524
                       Mean reward: 665.14
               Mean episode length: 239.66
    Episode_Reward/reaching_object: 1.6601
    Episode_Reward/rotating_object: 126.4234
        Episode_Reward/action_rate: -0.0670
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 2.20s
                      Time elapsed: 00:33:55
                               ETA: 00:24:56

################################################################################
                     [1m Learning iteration 865/1500 [0m                      

                       Computation: 44486 steps/s (collection: 2.119s, learning 0.091s)
             Mean action noise std: 3.05
          Mean value_function loss: 98.9200
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 77.1752
                       Mean reward: 623.81
               Mean episode length: 238.27
    Episode_Reward/reaching_object: 1.6231
    Episode_Reward/rotating_object: 118.6748
        Episode_Reward/action_rate: -0.0653
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 2.21s
                      Time elapsed: 00:33:58
                               ETA: 00:24:54

################################################################################
                     [1m Learning iteration 866/1500 [0m                      

                       Computation: 44816 steps/s (collection: 2.098s, learning 0.096s)
             Mean action noise std: 3.05
          Mean value_function loss: 92.4311
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 77.1979
                       Mean reward: 620.55
               Mean episode length: 225.12
    Episode_Reward/reaching_object: 1.6128
    Episode_Reward/rotating_object: 123.4248
        Episode_Reward/action_rate: -0.0651
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 2.19s
                      Time elapsed: 00:34:00
                               ETA: 00:24:52

################################################################################
                     [1m Learning iteration 867/1500 [0m                      

                       Computation: 40886 steps/s (collection: 2.248s, learning 0.157s)
             Mean action noise std: 3.05
          Mean value_function loss: 76.9153
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 77.2210
                       Mean reward: 634.53
               Mean episode length: 234.47
    Episode_Reward/reaching_object: 1.6509
    Episode_Reward/rotating_object: 123.2209
        Episode_Reward/action_rate: -0.0668
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 2.40s
                      Time elapsed: 00:34:02
                               ETA: 00:24:49

################################################################################
                     [1m Learning iteration 868/1500 [0m                      

                       Computation: 43982 steps/s (collection: 2.135s, learning 0.100s)
             Mean action noise std: 3.06
          Mean value_function loss: 87.1386
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 77.2324
                       Mean reward: 592.22
               Mean episode length: 229.61
    Episode_Reward/reaching_object: 1.6240
    Episode_Reward/rotating_object: 121.3457
        Episode_Reward/action_rate: -0.0659
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 2.24s
                      Time elapsed: 00:34:04
                               ETA: 00:24:47

################################################################################
                     [1m Learning iteration 869/1500 [0m                      

                       Computation: 40242 steps/s (collection: 2.288s, learning 0.155s)
             Mean action noise std: 3.06
          Mean value_function loss: 91.7988
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 77.2438
                       Mean reward: 599.70
               Mean episode length: 230.15
    Episode_Reward/reaching_object: 1.6455
    Episode_Reward/rotating_object: 124.7235
        Episode_Reward/action_rate: -0.0667
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 2.44s
                      Time elapsed: 00:34:07
                               ETA: 00:24:44

################################################################################
                     [1m Learning iteration 870/1500 [0m                      

                       Computation: 40471 steps/s (collection: 2.264s, learning 0.165s)
             Mean action noise std: 3.06
          Mean value_function loss: 89.7130
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 77.2607
                       Mean reward: 601.08
               Mean episode length: 231.24
    Episode_Reward/reaching_object: 1.6206
    Episode_Reward/rotating_object: 121.9600
        Episode_Reward/action_rate: -0.0660
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 2.43s
                      Time elapsed: 00:34:09
                               ETA: 00:24:42

################################################################################
                     [1m Learning iteration 871/1500 [0m                      

                       Computation: 40254 steps/s (collection: 2.332s, learning 0.110s)
             Mean action noise std: 3.06
          Mean value_function loss: 81.4613
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 77.2858
                       Mean reward: 620.02
               Mean episode length: 241.37
    Episode_Reward/reaching_object: 1.6404
    Episode_Reward/rotating_object: 121.3476
        Episode_Reward/action_rate: -0.0667
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 2.44s
                      Time elapsed: 00:34:12
                               ETA: 00:24:40

################################################################################
                     [1m Learning iteration 872/1500 [0m                      

                       Computation: 43107 steps/s (collection: 2.170s, learning 0.111s)
             Mean action noise std: 3.07
          Mean value_function loss: 89.2859
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 77.3229
                       Mean reward: 626.20
               Mean episode length: 238.43
    Episode_Reward/reaching_object: 1.6290
    Episode_Reward/rotating_object: 124.3014
        Episode_Reward/action_rate: -0.0664
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 2.28s
                      Time elapsed: 00:34:14
                               ETA: 00:24:37

################################################################################
                     [1m Learning iteration 873/1500 [0m                      

                       Computation: 43021 steps/s (collection: 2.162s, learning 0.123s)
             Mean action noise std: 3.07
          Mean value_function loss: 111.2354
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 77.3512
                       Mean reward: 666.60
               Mean episode length: 241.43
    Episode_Reward/reaching_object: 1.6484
    Episode_Reward/rotating_object: 127.1220
        Episode_Reward/action_rate: -0.0673
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 2.28s
                      Time elapsed: 00:34:16
                               ETA: 00:24:35

################################################################################
                     [1m Learning iteration 874/1500 [0m                      

                       Computation: 43685 steps/s (collection: 2.156s, learning 0.095s)
             Mean action noise std: 3.07
          Mean value_function loss: 100.7680
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 77.3750
                       Mean reward: 603.96
               Mean episode length: 229.83
    Episode_Reward/reaching_object: 1.6137
    Episode_Reward/rotating_object: 121.0108
        Episode_Reward/action_rate: -0.0660
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 2.25s
                      Time elapsed: 00:34:19
                               ETA: 00:24:33

################################################################################
                     [1m Learning iteration 875/1500 [0m                      

                       Computation: 44136 steps/s (collection: 2.116s, learning 0.111s)
             Mean action noise std: 3.07
          Mean value_function loss: 90.8698
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 77.4010
                       Mean reward: 647.68
               Mean episode length: 236.93
    Episode_Reward/reaching_object: 1.6500
    Episode_Reward/rotating_object: 123.1742
        Episode_Reward/action_rate: -0.0674
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 2.23s
                      Time elapsed: 00:34:21
                               ETA: 00:24:30

################################################################################
                     [1m Learning iteration 876/1500 [0m                      

                       Computation: 43861 steps/s (collection: 2.137s, learning 0.105s)
             Mean action noise std: 3.08
          Mean value_function loss: 88.6493
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 77.4138
                       Mean reward: 623.26
               Mean episode length: 228.82
    Episode_Reward/reaching_object: 1.6567
    Episode_Reward/rotating_object: 127.2074
        Episode_Reward/action_rate: -0.0676
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 2.24s
                      Time elapsed: 00:34:23
                               ETA: 00:24:28

################################################################################
                     [1m Learning iteration 877/1500 [0m                      

                       Computation: 43156 steps/s (collection: 2.105s, learning 0.173s)
             Mean action noise std: 3.08
          Mean value_function loss: 86.9674
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 77.4357
                       Mean reward: 604.98
               Mean episode length: 226.58
    Episode_Reward/reaching_object: 1.6419
    Episode_Reward/rotating_object: 125.0494
        Episode_Reward/action_rate: -0.0674
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 2.28s
                      Time elapsed: 00:34:25
                               ETA: 00:24:25

################################################################################
                     [1m Learning iteration 878/1500 [0m                      

                       Computation: 44301 steps/s (collection: 2.106s, learning 0.113s)
             Mean action noise std: 3.08
          Mean value_function loss: 89.0137
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 77.4455
                       Mean reward: 619.12
               Mean episode length: 235.19
    Episode_Reward/reaching_object: 1.6780
    Episode_Reward/rotating_object: 124.4211
        Episode_Reward/action_rate: -0.0688
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 2.22s
                      Time elapsed: 00:34:28
                               ETA: 00:24:23

################################################################################
                     [1m Learning iteration 879/1500 [0m                      

                       Computation: 43722 steps/s (collection: 2.132s, learning 0.117s)
             Mean action noise std: 3.08
          Mean value_function loss: 85.4250
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 77.4571
                       Mean reward: 607.85
               Mean episode length: 230.68
    Episode_Reward/reaching_object: 1.6666
    Episode_Reward/rotating_object: 124.5988
        Episode_Reward/action_rate: -0.0683
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 2.25s
                      Time elapsed: 00:34:30
                               ETA: 00:24:20

################################################################################
                     [1m Learning iteration 880/1500 [0m                      

                       Computation: 44390 steps/s (collection: 2.113s, learning 0.102s)
             Mean action noise std: 3.08
          Mean value_function loss: 101.7483
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 77.4768
                       Mean reward: 643.70
               Mean episode length: 236.03
    Episode_Reward/reaching_object: 1.6360
    Episode_Reward/rotating_object: 122.2742
        Episode_Reward/action_rate: -0.0675
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 2.21s
                      Time elapsed: 00:34:32
                               ETA: 00:24:18

################################################################################
                     [1m Learning iteration 881/1500 [0m                      

                       Computation: 43725 steps/s (collection: 2.113s, learning 0.136s)
             Mean action noise std: 3.09
          Mean value_function loss: 98.0528
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 77.5011
                       Mean reward: 579.94
               Mean episode length: 230.52
    Episode_Reward/reaching_object: 1.6078
    Episode_Reward/rotating_object: 117.7419
        Episode_Reward/action_rate: -0.0665
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 2.25s
                      Time elapsed: 00:34:34
                               ETA: 00:24:16

################################################################################
                     [1m Learning iteration 882/1500 [0m                      

                       Computation: 44060 steps/s (collection: 2.138s, learning 0.093s)
             Mean action noise std: 3.09
          Mean value_function loss: 84.7108
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 77.5296
                       Mean reward: 658.91
               Mean episode length: 241.40
    Episode_Reward/reaching_object: 1.6920
    Episode_Reward/rotating_object: 129.6233
        Episode_Reward/action_rate: -0.0696
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 2.23s
                      Time elapsed: 00:34:37
                               ETA: 00:24:13

################################################################################
                     [1m Learning iteration 883/1500 [0m                      

                       Computation: 44824 steps/s (collection: 2.095s, learning 0.099s)
             Mean action noise std: 3.10
          Mean value_function loss: 90.5991
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 77.5708
                       Mean reward: 586.73
               Mean episode length: 223.25
    Episode_Reward/reaching_object: 1.6264
    Episode_Reward/rotating_object: 119.4248
        Episode_Reward/action_rate: -0.0678
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 2.19s
                      Time elapsed: 00:34:39
                               ETA: 00:24:11

################################################################################
                     [1m Learning iteration 884/1500 [0m                      

                       Computation: 43769 steps/s (collection: 2.136s, learning 0.110s)
             Mean action noise std: 3.10
          Mean value_function loss: 92.3809
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 77.6198
                       Mean reward: 605.62
               Mean episode length: 229.06
    Episode_Reward/reaching_object: 1.6411
    Episode_Reward/rotating_object: 123.1572
        Episode_Reward/action_rate: -0.0682
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 2.25s
                      Time elapsed: 00:34:41
                               ETA: 00:24:08

################################################################################
                     [1m Learning iteration 885/1500 [0m                      

                       Computation: 43157 steps/s (collection: 2.134s, learning 0.144s)
             Mean action noise std: 3.10
          Mean value_function loss: 95.5536
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 77.6507
                       Mean reward: 658.71
               Mean episode length: 237.69
    Episode_Reward/reaching_object: 1.6402
    Episode_Reward/rotating_object: 126.4147
        Episode_Reward/action_rate: -0.0682
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 2.28s
                      Time elapsed: 00:34:43
                               ETA: 00:24:06

################################################################################
                     [1m Learning iteration 886/1500 [0m                      

                       Computation: 43975 steps/s (collection: 2.135s, learning 0.100s)
             Mean action noise std: 3.11
          Mean value_function loss: 94.3357
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 77.6747
                       Mean reward: 612.01
               Mean episode length: 223.19
    Episode_Reward/reaching_object: 1.6400
    Episode_Reward/rotating_object: 122.9123
        Episode_Reward/action_rate: -0.0684
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 2.24s
                      Time elapsed: 00:34:45
                               ETA: 00:24:03

################################################################################
                     [1m Learning iteration 887/1500 [0m                      

                       Computation: 44001 steps/s (collection: 2.134s, learning 0.100s)
             Mean action noise std: 3.11
          Mean value_function loss: 106.6009
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 77.6979
                       Mean reward: 605.32
               Mean episode length: 222.64
    Episode_Reward/reaching_object: 1.6042
    Episode_Reward/rotating_object: 122.7028
        Episode_Reward/action_rate: -0.0673
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 2.23s
                      Time elapsed: 00:34:48
                               ETA: 00:24:01

################################################################################
                     [1m Learning iteration 888/1500 [0m                      

                       Computation: 44378 steps/s (collection: 2.099s, learning 0.116s)
             Mean action noise std: 3.11
          Mean value_function loss: 98.1160
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 77.7138
                       Mean reward: 578.57
               Mean episode length: 230.19
    Episode_Reward/reaching_object: 1.5997
    Episode_Reward/rotating_object: 120.9239
        Episode_Reward/action_rate: -0.0672
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 2.22s
                      Time elapsed: 00:34:50
                               ETA: 00:23:59

################################################################################
                     [1m Learning iteration 889/1500 [0m                      

                       Computation: 44191 steps/s (collection: 2.129s, learning 0.096s)
             Mean action noise std: 3.11
          Mean value_function loss: 100.8852
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 77.7358
                       Mean reward: 587.44
               Mean episode length: 223.29
    Episode_Reward/reaching_object: 1.6218
    Episode_Reward/rotating_object: 123.2673
        Episode_Reward/action_rate: -0.0682
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 2.22s
                      Time elapsed: 00:34:52
                               ETA: 00:23:56

################################################################################
                     [1m Learning iteration 890/1500 [0m                      

                       Computation: 43503 steps/s (collection: 2.102s, learning 0.158s)
             Mean action noise std: 3.12
          Mean value_function loss: 90.7428
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 77.7617
                       Mean reward: 575.42
               Mean episode length: 226.03
    Episode_Reward/reaching_object: 1.6113
    Episode_Reward/rotating_object: 119.8582
        Episode_Reward/action_rate: -0.0681
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 2.26s
                      Time elapsed: 00:34:54
                               ETA: 00:23:54

################################################################################
                     [1m Learning iteration 891/1500 [0m                      

                       Computation: 45238 steps/s (collection: 2.058s, learning 0.115s)
             Mean action noise std: 3.12
          Mean value_function loss: 82.7551
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 77.7823
                       Mean reward: 646.01
               Mean episode length: 231.75
    Episode_Reward/reaching_object: 1.6147
    Episode_Reward/rotating_object: 123.1820
        Episode_Reward/action_rate: -0.0683
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 2.17s
                      Time elapsed: 00:34:57
                               ETA: 00:23:51

################################################################################
                     [1m Learning iteration 892/1500 [0m                      

                       Computation: 43187 steps/s (collection: 2.177s, learning 0.099s)
             Mean action noise std: 3.12
          Mean value_function loss: 100.2189
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 77.8082
                       Mean reward: 628.16
               Mean episode length: 235.84
    Episode_Reward/reaching_object: 1.6375
    Episode_Reward/rotating_object: 122.6417
        Episode_Reward/action_rate: -0.0693
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 2.28s
                      Time elapsed: 00:34:59
                               ETA: 00:23:49

################################################################################
                     [1m Learning iteration 893/1500 [0m                      

                       Computation: 44877 steps/s (collection: 2.087s, learning 0.104s)
             Mean action noise std: 3.12
          Mean value_function loss: 79.6489
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 77.8366
                       Mean reward: 635.07
               Mean episode length: 238.88
    Episode_Reward/reaching_object: 1.6303
    Episode_Reward/rotating_object: 123.1576
        Episode_Reward/action_rate: -0.0692
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 2.19s
                      Time elapsed: 00:35:01
                               ETA: 00:23:46

################################################################################
                     [1m Learning iteration 894/1500 [0m                      

                       Computation: 44303 steps/s (collection: 2.091s, learning 0.128s)
             Mean action noise std: 3.13
          Mean value_function loss: 91.9207
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 77.8576
                       Mean reward: 643.61
               Mean episode length: 234.06
    Episode_Reward/reaching_object: 1.6666
    Episode_Reward/rotating_object: 127.9339
        Episode_Reward/action_rate: -0.0706
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 2.22s
                      Time elapsed: 00:35:03
                               ETA: 00:23:44

################################################################################
                     [1m Learning iteration 895/1500 [0m                      

                       Computation: 43950 steps/s (collection: 2.103s, learning 0.134s)
             Mean action noise std: 3.13
          Mean value_function loss: 107.1849
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 77.8815
                       Mean reward: 618.47
               Mean episode length: 233.32
    Episode_Reward/reaching_object: 1.6086
    Episode_Reward/rotating_object: 120.7003
        Episode_Reward/action_rate: -0.0686
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 2.24s
                      Time elapsed: 00:35:05
                               ETA: 00:23:42

################################################################################
                     [1m Learning iteration 896/1500 [0m                      

                       Computation: 43342 steps/s (collection: 2.176s, learning 0.093s)
             Mean action noise std: 3.13
          Mean value_function loss: 102.1423
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 77.9032
                       Mean reward: 595.00
               Mean episode length: 223.06
    Episode_Reward/reaching_object: 1.6149
    Episode_Reward/rotating_object: 122.8112
        Episode_Reward/action_rate: -0.0688
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 2.27s
                      Time elapsed: 00:35:08
                               ETA: 00:23:39

################################################################################
                     [1m Learning iteration 897/1500 [0m                      

                       Computation: 44706 steps/s (collection: 2.103s, learning 0.096s)
             Mean action noise std: 3.14
          Mean value_function loss: 98.7118
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 77.9327
                       Mean reward: 580.23
               Mean episode length: 222.68
    Episode_Reward/reaching_object: 1.6151
    Episode_Reward/rotating_object: 119.2656
        Episode_Reward/action_rate: -0.0689
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 2.20s
                      Time elapsed: 00:35:10
                               ETA: 00:23:37

################################################################################
                     [1m Learning iteration 898/1500 [0m                      

                       Computation: 44905 steps/s (collection: 2.092s, learning 0.098s)
             Mean action noise std: 3.14
          Mean value_function loss: 90.3600
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 77.9646
                       Mean reward: 643.28
               Mean episode length: 234.78
    Episode_Reward/reaching_object: 1.6324
    Episode_Reward/rotating_object: 123.5380
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 2.19s
                      Time elapsed: 00:35:12
                               ETA: 00:23:34

################################################################################
                     [1m Learning iteration 899/1500 [0m                      

                       Computation: 43326 steps/s (collection: 2.110s, learning 0.159s)
             Mean action noise std: 3.14
          Mean value_function loss: 100.4199
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 77.9878
                       Mean reward: 643.89
               Mean episode length: 238.50
    Episode_Reward/reaching_object: 1.6589
    Episode_Reward/rotating_object: 125.4831
        Episode_Reward/action_rate: -0.0708
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 2.27s
                      Time elapsed: 00:35:14
                               ETA: 00:23:32

################################################################################
                     [1m Learning iteration 900/1500 [0m                      

                       Computation: 44259 steps/s (collection: 2.099s, learning 0.122s)
             Mean action noise std: 3.15
          Mean value_function loss: 98.7808
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 78.0160
                       Mean reward: 640.79
               Mean episode length: 228.08
    Episode_Reward/reaching_object: 1.6233
    Episode_Reward/rotating_object: 123.3307
        Episode_Reward/action_rate: -0.0695
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 2.22s
                      Time elapsed: 00:35:17
                               ETA: 00:23:29

################################################################################
                     [1m Learning iteration 901/1500 [0m                      

                       Computation: 43928 steps/s (collection: 2.134s, learning 0.104s)
             Mean action noise std: 3.15
          Mean value_function loss: 106.8644
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 78.0451
                       Mean reward: 632.71
               Mean episode length: 231.03
    Episode_Reward/reaching_object: 1.6180
    Episode_Reward/rotating_object: 121.6291
        Episode_Reward/action_rate: -0.0695
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 2.24s
                      Time elapsed: 00:35:19
                               ETA: 00:23:27

################################################################################
                     [1m Learning iteration 902/1500 [0m                      

                       Computation: 41049 steps/s (collection: 2.275s, learning 0.120s)
             Mean action noise std: 3.15
          Mean value_function loss: 97.9490
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 78.0684
                       Mean reward: 632.17
               Mean episode length: 230.75
    Episode_Reward/reaching_object: 1.6085
    Episode_Reward/rotating_object: 122.2227
        Episode_Reward/action_rate: -0.0691
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 2.39s
                      Time elapsed: 00:35:21
                               ETA: 00:23:25

################################################################################
                     [1m Learning iteration 903/1500 [0m                      

                       Computation: 42104 steps/s (collection: 2.224s, learning 0.111s)
             Mean action noise std: 3.15
          Mean value_function loss: 103.0535
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 78.0875
                       Mean reward: 612.34
               Mean episode length: 226.47
    Episode_Reward/reaching_object: 1.5912
    Episode_Reward/rotating_object: 118.6611
        Episode_Reward/action_rate: -0.0682
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 2.33s
                      Time elapsed: 00:35:24
                               ETA: 00:23:22

################################################################################
                     [1m Learning iteration 904/1500 [0m                      

                       Computation: 42530 steps/s (collection: 2.201s, learning 0.111s)
             Mean action noise std: 3.16
          Mean value_function loss: 125.5042
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 78.0978
                       Mean reward: 609.91
               Mean episode length: 231.58
    Episode_Reward/reaching_object: 1.6385
    Episode_Reward/rotating_object: 125.0939
        Episode_Reward/action_rate: -0.0702
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 2.31s
                      Time elapsed: 00:35:26
                               ETA: 00:23:20

################################################################################
                     [1m Learning iteration 905/1500 [0m                      

                       Computation: 42658 steps/s (collection: 2.180s, learning 0.124s)
             Mean action noise std: 3.16
          Mean value_function loss: 125.2370
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 78.1126
                       Mean reward: 604.24
               Mean episode length: 229.92
    Episode_Reward/reaching_object: 1.6311
    Episode_Reward/rotating_object: 122.9843
        Episode_Reward/action_rate: -0.0699
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 2.30s
                      Time elapsed: 00:35:28
                               ETA: 00:23:18

################################################################################
                     [1m Learning iteration 906/1500 [0m                      

                       Computation: 43806 steps/s (collection: 2.134s, learning 0.110s)
             Mean action noise std: 3.16
          Mean value_function loss: 128.1534
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 78.1286
                       Mean reward: 586.86
               Mean episode length: 219.86
    Episode_Reward/reaching_object: 1.5701
    Episode_Reward/rotating_object: 114.9480
        Episode_Reward/action_rate: -0.0678
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 2.24s
                      Time elapsed: 00:35:30
                               ETA: 00:23:15

################################################################################
                     [1m Learning iteration 907/1500 [0m                      

                       Computation: 42090 steps/s (collection: 2.183s, learning 0.152s)
             Mean action noise std: 3.16
          Mean value_function loss: 111.0393
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 78.1465
                       Mean reward: 628.24
               Mean episode length: 237.36
    Episode_Reward/reaching_object: 1.6276
    Episode_Reward/rotating_object: 120.1933
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 2.34s
                      Time elapsed: 00:35:33
                               ETA: 00:23:13

################################################################################
                     [1m Learning iteration 908/1500 [0m                      

                       Computation: 43742 steps/s (collection: 2.143s, learning 0.105s)
             Mean action noise std: 3.17
          Mean value_function loss: 115.6072
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 78.1729
                       Mean reward: 633.37
               Mean episode length: 231.77
    Episode_Reward/reaching_object: 1.6101
    Episode_Reward/rotating_object: 121.4149
        Episode_Reward/action_rate: -0.0691
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 2.25s
                      Time elapsed: 00:35:35
                               ETA: 00:23:10

################################################################################
                     [1m Learning iteration 909/1500 [0m                      

                       Computation: 43098 steps/s (collection: 2.161s, learning 0.120s)
             Mean action noise std: 3.17
          Mean value_function loss: 102.7079
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 78.1962
                       Mean reward: 609.42
               Mean episode length: 225.79
    Episode_Reward/reaching_object: 1.6435
    Episode_Reward/rotating_object: 118.9478
        Episode_Reward/action_rate: -0.0705
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 2.28s
                      Time elapsed: 00:35:37
                               ETA: 00:23:08

################################################################################
                     [1m Learning iteration 910/1500 [0m                      

                       Computation: 41610 steps/s (collection: 2.208s, learning 0.155s)
             Mean action noise std: 3.17
          Mean value_function loss: 120.4089
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 78.2150
                       Mean reward: 571.53
               Mean episode length: 226.31
    Episode_Reward/reaching_object: 1.6131
    Episode_Reward/rotating_object: 116.6565
        Episode_Reward/action_rate: -0.0696
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 2.36s
                      Time elapsed: 00:35:40
                               ETA: 00:23:06

################################################################################
                     [1m Learning iteration 911/1500 [0m                      

                       Computation: 41585 steps/s (collection: 2.216s, learning 0.148s)
             Mean action noise std: 3.17
          Mean value_function loss: 104.6800
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 78.2291
                       Mean reward: 643.23
               Mean episode length: 229.17
    Episode_Reward/reaching_object: 1.6679
    Episode_Reward/rotating_object: 126.7382
        Episode_Reward/action_rate: -0.0712
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 2.36s
                      Time elapsed: 00:35:42
                               ETA: 00:23:03

################################################################################
                     [1m Learning iteration 912/1500 [0m                      

                       Computation: 43370 steps/s (collection: 2.148s, learning 0.119s)
             Mean action noise std: 3.17
          Mean value_function loss: 111.3081
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 78.2414
                       Mean reward: 645.58
               Mean episode length: 234.13
    Episode_Reward/reaching_object: 1.6237
    Episode_Reward/rotating_object: 122.0335
        Episode_Reward/action_rate: -0.0696
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 2.27s
                      Time elapsed: 00:35:44
                               ETA: 00:23:01

################################################################################
                     [1m Learning iteration 913/1500 [0m                      

                       Computation: 44093 steps/s (collection: 2.119s, learning 0.111s)
             Mean action noise std: 3.18
          Mean value_function loss: 115.0155
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 78.2538
                       Mean reward: 646.52
               Mean episode length: 233.27
    Episode_Reward/reaching_object: 1.6195
    Episode_Reward/rotating_object: 121.1123
        Episode_Reward/action_rate: -0.0699
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 2.23s
                      Time elapsed: 00:35:47
                               ETA: 00:22:58

################################################################################
                     [1m Learning iteration 914/1500 [0m                      

                       Computation: 42688 steps/s (collection: 2.192s, learning 0.111s)
             Mean action noise std: 3.18
          Mean value_function loss: 116.8421
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 78.2770
                       Mean reward: 610.71
               Mean episode length: 224.12
    Episode_Reward/reaching_object: 1.6323
    Episode_Reward/rotating_object: 122.2303
        Episode_Reward/action_rate: -0.0703
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 2.30s
                      Time elapsed: 00:35:49
                               ETA: 00:22:56

################################################################################
                     [1m Learning iteration 915/1500 [0m                      

                       Computation: 44208 steps/s (collection: 2.107s, learning 0.117s)
             Mean action noise std: 3.18
          Mean value_function loss: 116.1280
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 78.2991
                       Mean reward: 624.06
               Mean episode length: 225.23
    Episode_Reward/reaching_object: 1.6391
    Episode_Reward/rotating_object: 123.8605
        Episode_Reward/action_rate: -0.0708
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 2.22s
                      Time elapsed: 00:35:51
                               ETA: 00:22:54

################################################################################
                     [1m Learning iteration 916/1500 [0m                      

                       Computation: 43182 steps/s (collection: 2.138s, learning 0.139s)
             Mean action noise std: 3.18
          Mean value_function loss: 99.8787
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 78.3199
                       Mean reward: 641.24
               Mean episode length: 229.59
    Episode_Reward/reaching_object: 1.6607
    Episode_Reward/rotating_object: 125.5565
        Episode_Reward/action_rate: -0.0716
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 2.28s
                      Time elapsed: 00:35:53
                               ETA: 00:22:51

################################################################################
                     [1m Learning iteration 917/1500 [0m                      

                       Computation: 42598 steps/s (collection: 2.161s, learning 0.147s)
             Mean action noise std: 3.19
          Mean value_function loss: 108.4390
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 78.3409
                       Mean reward: 608.13
               Mean episode length: 224.42
    Episode_Reward/reaching_object: 1.6059
    Episode_Reward/rotating_object: 119.6727
        Episode_Reward/action_rate: -0.0699
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 2.31s
                      Time elapsed: 00:35:56
                               ETA: 00:22:49

################################################################################
                     [1m Learning iteration 918/1500 [0m                      

                       Computation: 43302 steps/s (collection: 2.175s, learning 0.096s)
             Mean action noise std: 3.19
          Mean value_function loss: 84.6381
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 78.3731
                       Mean reward: 643.44
               Mean episode length: 234.94
    Episode_Reward/reaching_object: 1.6535
    Episode_Reward/rotating_object: 126.9329
        Episode_Reward/action_rate: -0.0718
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 2.27s
                      Time elapsed: 00:35:58
                               ETA: 00:22:46

################################################################################
                     [1m Learning iteration 919/1500 [0m                      

                       Computation: 44433 steps/s (collection: 2.112s, learning 0.101s)
             Mean action noise std: 3.19
          Mean value_function loss: 95.7840
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 78.3934
                       Mean reward: 605.15
               Mean episode length: 223.16
    Episode_Reward/reaching_object: 1.6344
    Episode_Reward/rotating_object: 124.0265
        Episode_Reward/action_rate: -0.0713
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 2.21s
                      Time elapsed: 00:36:00
                               ETA: 00:22:44

################################################################################
                     [1m Learning iteration 920/1500 [0m                      

                       Computation: 44402 steps/s (collection: 2.108s, learning 0.106s)
             Mean action noise std: 3.19
          Mean value_function loss: 91.1910
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 78.4100
                       Mean reward: 587.30
               Mean episode length: 225.51
    Episode_Reward/reaching_object: 1.6483
    Episode_Reward/rotating_object: 125.5033
        Episode_Reward/action_rate: -0.0718
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 2.21s
                      Time elapsed: 00:36:02
                               ETA: 00:22:42

################################################################################
                     [1m Learning iteration 921/1500 [0m                      

                       Computation: 43332 steps/s (collection: 2.166s, learning 0.102s)
             Mean action noise std: 3.20
          Mean value_function loss: 82.6563
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 78.4302
                       Mean reward: 675.38
               Mean episode length: 236.23
    Episode_Reward/reaching_object: 1.6331
    Episode_Reward/rotating_object: 124.6600
        Episode_Reward/action_rate: -0.0714
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 2.27s
                      Time elapsed: 00:36:05
                               ETA: 00:22:39

################################################################################
                     [1m Learning iteration 922/1500 [0m                      

                       Computation: 44304 steps/s (collection: 2.062s, learning 0.157s)
             Mean action noise std: 3.20
          Mean value_function loss: 90.5069
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 78.4443
                       Mean reward: 671.54
               Mean episode length: 236.56
    Episode_Reward/reaching_object: 1.6592
    Episode_Reward/rotating_object: 127.5608
        Episode_Reward/action_rate: -0.0724
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 2.22s
                      Time elapsed: 00:36:07
                               ETA: 00:22:37

################################################################################
                     [1m Learning iteration 923/1500 [0m                      

                       Computation: 42424 steps/s (collection: 2.184s, learning 0.133s)
             Mean action noise std: 3.20
          Mean value_function loss: 96.5303
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 78.4692
                       Mean reward: 631.28
               Mean episode length: 228.32
    Episode_Reward/reaching_object: 1.6469
    Episode_Reward/rotating_object: 126.6558
        Episode_Reward/action_rate: -0.0721
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 2.32s
                      Time elapsed: 00:36:09
                               ETA: 00:22:34

################################################################################
                     [1m Learning iteration 924/1500 [0m                      

                       Computation: 41960 steps/s (collection: 2.238s, learning 0.105s)
             Mean action noise std: 3.21
          Mean value_function loss: 103.9440
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 78.5075
                       Mean reward: 578.18
               Mean episode length: 222.23
    Episode_Reward/reaching_object: 1.6354
    Episode_Reward/rotating_object: 122.9671
        Episode_Reward/action_rate: -0.0721
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 2.34s
                      Time elapsed: 00:36:12
                               ETA: 00:22:32

################################################################################
                     [1m Learning iteration 925/1500 [0m                      

                       Computation: 41898 steps/s (collection: 2.195s, learning 0.152s)
             Mean action noise std: 3.21
          Mean value_function loss: 89.1500
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 78.5477
                       Mean reward: 618.25
               Mean episode length: 229.11
    Episode_Reward/reaching_object: 1.6300
    Episode_Reward/rotating_object: 124.2672
        Episode_Reward/action_rate: -0.0717
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 2.35s
                      Time elapsed: 00:36:14
                               ETA: 00:22:30

################################################################################
                     [1m Learning iteration 926/1500 [0m                      

                       Computation: 43012 steps/s (collection: 2.178s, learning 0.108s)
             Mean action noise std: 3.21
          Mean value_function loss: 87.3058
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 78.5720
                       Mean reward: 637.51
               Mean episode length: 232.77
    Episode_Reward/reaching_object: 1.6641
    Episode_Reward/rotating_object: 126.9255
        Episode_Reward/action_rate: -0.0732
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 18.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 2.29s
                      Time elapsed: 00:36:16
                               ETA: 00:22:27

################################################################################
                     [1m Learning iteration 927/1500 [0m                      

                       Computation: 43692 steps/s (collection: 2.133s, learning 0.117s)
             Mean action noise std: 3.21
          Mean value_function loss: 104.1703
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 78.5917
                       Mean reward: 625.30
               Mean episode length: 232.85
    Episode_Reward/reaching_object: 1.6286
    Episode_Reward/rotating_object: 122.7470
        Episode_Reward/action_rate: -0.0721
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 2.25s
                      Time elapsed: 00:36:18
                               ETA: 00:22:25

################################################################################
                     [1m Learning iteration 928/1500 [0m                      

                       Computation: 41952 steps/s (collection: 2.235s, learning 0.109s)
             Mean action noise std: 3.22
          Mean value_function loss: 84.6207
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 78.6148
                       Mean reward: 639.57
               Mean episode length: 230.49
    Episode_Reward/reaching_object: 1.6199
    Episode_Reward/rotating_object: 125.9254
        Episode_Reward/action_rate: -0.0719
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 2.34s
                      Time elapsed: 00:36:21
                               ETA: 00:22:23

################################################################################
                     [1m Learning iteration 929/1500 [0m                      

                       Computation: 43792 steps/s (collection: 2.142s, learning 0.103s)
             Mean action noise std: 3.22
          Mean value_function loss: 88.7001
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 78.6437
                       Mean reward: 642.38
               Mean episode length: 232.75
    Episode_Reward/reaching_object: 1.6090
    Episode_Reward/rotating_object: 121.2675
        Episode_Reward/action_rate: -0.0717
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 2.24s
                      Time elapsed: 00:36:23
                               ETA: 00:22:20

################################################################################
                     [1m Learning iteration 930/1500 [0m                      

                       Computation: 44024 steps/s (collection: 2.122s, learning 0.111s)
             Mean action noise std: 3.22
          Mean value_function loss: 82.3190
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 78.6619
                       Mean reward: 612.20
               Mean episode length: 229.01
    Episode_Reward/reaching_object: 1.6038
    Episode_Reward/rotating_object: 122.5500
        Episode_Reward/action_rate: -0.0718
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 2.23s
                      Time elapsed: 00:36:25
                               ETA: 00:22:18

################################################################################
                     [1m Learning iteration 931/1500 [0m                      

                       Computation: 43082 steps/s (collection: 2.136s, learning 0.146s)
             Mean action noise std: 3.23
          Mean value_function loss: 80.7101
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 78.6779
                       Mean reward: 659.52
               Mean episode length: 240.18
    Episode_Reward/reaching_object: 1.6296
    Episode_Reward/rotating_object: 125.2679
        Episode_Reward/action_rate: -0.0729
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 2.28s
                      Time elapsed: 00:36:27
                               ETA: 00:22:15

################################################################################
                     [1m Learning iteration 932/1500 [0m                      

                       Computation: 40785 steps/s (collection: 2.306s, learning 0.104s)
             Mean action noise std: 3.23
          Mean value_function loss: 91.4581
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 78.7081
                       Mean reward: 660.92
               Mean episode length: 241.52
    Episode_Reward/reaching_object: 1.6424
    Episode_Reward/rotating_object: 125.6080
        Episode_Reward/action_rate: -0.0737
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 2.41s
                      Time elapsed: 00:36:30
                               ETA: 00:22:13

################################################################################
                     [1m Learning iteration 933/1500 [0m                      

                       Computation: 42767 steps/s (collection: 2.176s, learning 0.122s)
             Mean action noise std: 3.23
          Mean value_function loss: 89.6421
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 78.7433
                       Mean reward: 648.48
               Mean episode length: 238.43
    Episode_Reward/reaching_object: 1.6586
    Episode_Reward/rotating_object: 127.4497
        Episode_Reward/action_rate: -0.0747
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 2.30s
                      Time elapsed: 00:36:32
                               ETA: 00:22:11

################################################################################
                     [1m Learning iteration 934/1500 [0m                      

                       Computation: 41829 steps/s (collection: 2.222s, learning 0.129s)
             Mean action noise std: 3.24
          Mean value_function loss: 85.9197
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 78.7734
                       Mean reward: 639.07
               Mean episode length: 232.26
    Episode_Reward/reaching_object: 1.6256
    Episode_Reward/rotating_object: 126.4240
        Episode_Reward/action_rate: -0.0737
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 2.35s
                      Time elapsed: 00:36:35
                               ETA: 00:22:08

################################################################################
                     [1m Learning iteration 935/1500 [0m                      

                       Computation: 43124 steps/s (collection: 2.113s, learning 0.166s)
             Mean action noise std: 3.24
          Mean value_function loss: 91.3118
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 78.7948
                       Mean reward: 616.73
               Mean episode length: 226.48
    Episode_Reward/reaching_object: 1.6409
    Episode_Reward/rotating_object: 127.2984
        Episode_Reward/action_rate: -0.0745
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 2.28s
                      Time elapsed: 00:36:37
                               ETA: 00:22:06

################################################################################
                     [1m Learning iteration 936/1500 [0m                      

                       Computation: 43410 steps/s (collection: 2.157s, learning 0.107s)
             Mean action noise std: 3.24
          Mean value_function loss: 84.7657
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 78.8190
                       Mean reward: 693.58
               Mean episode length: 243.06
    Episode_Reward/reaching_object: 1.6674
    Episode_Reward/rotating_object: 129.0322
        Episode_Reward/action_rate: -0.0758
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 2.26s
                      Time elapsed: 00:36:39
                               ETA: 00:22:03

################################################################################
                     [1m Learning iteration 937/1500 [0m                      

                       Computation: 43699 steps/s (collection: 2.130s, learning 0.120s)
             Mean action noise std: 3.24
          Mean value_function loss: 101.6088
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 78.8437
                       Mean reward: 663.52
               Mean episode length: 234.74
    Episode_Reward/reaching_object: 1.6029
    Episode_Reward/rotating_object: 125.4307
        Episode_Reward/action_rate: -0.0732
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 2.25s
                      Time elapsed: 00:36:41
                               ETA: 00:22:01

################################################################################
                     [1m Learning iteration 938/1500 [0m                      

                       Computation: 44134 steps/s (collection: 2.109s, learning 0.118s)
             Mean action noise std: 3.25
          Mean value_function loss: 89.0602
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 78.8585
                       Mean reward: 663.35
               Mean episode length: 236.49
    Episode_Reward/reaching_object: 1.6462
    Episode_Reward/rotating_object: 128.6926
        Episode_Reward/action_rate: -0.0752
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 2.23s
                      Time elapsed: 00:36:44
                               ETA: 00:21:59

################################################################################
                     [1m Learning iteration 939/1500 [0m                      

                       Computation: 41115 steps/s (collection: 2.221s, learning 0.169s)
             Mean action noise std: 3.25
          Mean value_function loss: 99.2989
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 78.8756
                       Mean reward: 607.13
               Mean episode length: 222.71
    Episode_Reward/reaching_object: 1.6219
    Episode_Reward/rotating_object: 124.1139
        Episode_Reward/action_rate: -0.0744
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 2.39s
                      Time elapsed: 00:36:46
                               ETA: 00:21:56

################################################################################
                     [1m Learning iteration 940/1500 [0m                      

                       Computation: 43034 steps/s (collection: 2.185s, learning 0.099s)
             Mean action noise std: 3.25
          Mean value_function loss: 83.6190
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 78.8978
                       Mean reward: 611.36
               Mean episode length: 230.86
    Episode_Reward/reaching_object: 1.6469
    Episode_Reward/rotating_object: 126.7361
        Episode_Reward/action_rate: -0.0755
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 2.28s
                      Time elapsed: 00:36:48
                               ETA: 00:21:54

################################################################################
                     [1m Learning iteration 941/1500 [0m                      

                       Computation: 44815 steps/s (collection: 2.085s, learning 0.108s)
             Mean action noise std: 3.25
          Mean value_function loss: 84.0699
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 78.9199
                       Mean reward: 624.54
               Mean episode length: 226.80
    Episode_Reward/reaching_object: 1.6103
    Episode_Reward/rotating_object: 124.8856
        Episode_Reward/action_rate: -0.0744
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 2.19s
                      Time elapsed: 00:36:50
                               ETA: 00:21:52

################################################################################
                     [1m Learning iteration 942/1500 [0m                      

                       Computation: 42572 steps/s (collection: 2.132s, learning 0.177s)
             Mean action noise std: 3.26
          Mean value_function loss: 91.5843
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 78.9286
                       Mean reward: 614.26
               Mean episode length: 230.25
    Episode_Reward/reaching_object: 1.6077
    Episode_Reward/rotating_object: 121.5010
        Episode_Reward/action_rate: -0.0744
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 2.31s
                      Time elapsed: 00:36:53
                               ETA: 00:21:49

################################################################################
                     [1m Learning iteration 943/1500 [0m                      

                       Computation: 43903 steps/s (collection: 2.096s, learning 0.143s)
             Mean action noise std: 3.26
          Mean value_function loss: 81.2291
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 78.9457
                       Mean reward: 651.59
               Mean episode length: 239.41
    Episode_Reward/reaching_object: 1.6473
    Episode_Reward/rotating_object: 125.4140
        Episode_Reward/action_rate: -0.0759
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 2.24s
                      Time elapsed: 00:36:55
                               ETA: 00:21:47

################################################################################
                     [1m Learning iteration 944/1500 [0m                      

                       Computation: 43001 steps/s (collection: 2.175s, learning 0.112s)
             Mean action noise std: 3.26
          Mean value_function loss: 94.4172
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 78.9713
                       Mean reward: 602.08
               Mean episode length: 218.77
    Episode_Reward/reaching_object: 1.5845
    Episode_Reward/rotating_object: 120.6090
        Episode_Reward/action_rate: -0.0737
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 2.29s
                      Time elapsed: 00:36:57
                               ETA: 00:21:44

################################################################################
                     [1m Learning iteration 945/1500 [0m                      

                       Computation: 42454 steps/s (collection: 2.133s, learning 0.183s)
             Mean action noise std: 3.26
          Mean value_function loss: 86.8793
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 78.9940
                       Mean reward: 617.65
               Mean episode length: 229.28
    Episode_Reward/reaching_object: 1.6579
    Episode_Reward/rotating_object: 127.5271
        Episode_Reward/action_rate: -0.0766
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 2.32s
                      Time elapsed: 00:37:00
                               ETA: 00:21:42

################################################################################
                     [1m Learning iteration 946/1500 [0m                      

                       Computation: 44422 steps/s (collection: 2.079s, learning 0.134s)
             Mean action noise std: 3.27
          Mean value_function loss: 101.8172
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 79.0107
                       Mean reward: 651.83
               Mean episode length: 229.66
    Episode_Reward/reaching_object: 1.6089
    Episode_Reward/rotating_object: 120.3323
        Episode_Reward/action_rate: -0.0748
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 2.21s
                      Time elapsed: 00:37:02
                               ETA: 00:21:40

################################################################################
                     [1m Learning iteration 947/1500 [0m                      

                       Computation: 43813 steps/s (collection: 2.089s, learning 0.155s)
             Mean action noise std: 3.27
          Mean value_function loss: 100.2661
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 79.0295
                       Mean reward: 592.25
               Mean episode length: 218.90
    Episode_Reward/reaching_object: 1.6068
    Episode_Reward/rotating_object: 124.4528
        Episode_Reward/action_rate: -0.0751
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 2.24s
                      Time elapsed: 00:37:04
                               ETA: 00:21:37

################################################################################
                     [1m Learning iteration 948/1500 [0m                      

                       Computation: 44320 steps/s (collection: 2.117s, learning 0.101s)
             Mean action noise std: 3.27
          Mean value_function loss: 98.6600
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 79.0473
                       Mean reward: 593.78
               Mean episode length: 225.84
    Episode_Reward/reaching_object: 1.5911
    Episode_Reward/rotating_object: 122.3208
        Episode_Reward/action_rate: -0.0746
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 2.22s
                      Time elapsed: 00:37:06
                               ETA: 00:21:35

################################################################################
                     [1m Learning iteration 949/1500 [0m                      

                       Computation: 44392 steps/s (collection: 2.113s, learning 0.101s)
             Mean action noise std: 3.27
          Mean value_function loss: 87.6318
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 79.0688
                       Mean reward: 680.46
               Mean episode length: 244.02
    Episode_Reward/reaching_object: 1.6275
    Episode_Reward/rotating_object: 126.6913
        Episode_Reward/action_rate: -0.0759
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 2.21s
                      Time elapsed: 00:37:08
                               ETA: 00:21:32

################################################################################
                     [1m Learning iteration 950/1500 [0m                      

                       Computation: 41728 steps/s (collection: 2.188s, learning 0.168s)
             Mean action noise std: 3.28
          Mean value_function loss: 90.8220
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 79.0799
                       Mean reward: 667.92
               Mean episode length: 233.99
    Episode_Reward/reaching_object: 1.6089
    Episode_Reward/rotating_object: 123.9383
        Episode_Reward/action_rate: -0.0752
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 2.36s
                      Time elapsed: 00:37:11
                               ETA: 00:21:30

################################################################################
                     [1m Learning iteration 951/1500 [0m                      

                       Computation: 39443 steps/s (collection: 2.381s, learning 0.111s)
             Mean action noise std: 3.28
          Mean value_function loss: 99.5339
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 79.0937
                       Mean reward: 653.08
               Mean episode length: 234.74
    Episode_Reward/reaching_object: 1.6404
    Episode_Reward/rotating_object: 128.7319
        Episode_Reward/action_rate: -0.0765
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 2.49s
                      Time elapsed: 00:37:13
                               ETA: 00:21:28

################################################################################
                     [1m Learning iteration 952/1500 [0m                      

                       Computation: 40882 steps/s (collection: 2.288s, learning 0.116s)
             Mean action noise std: 3.28
          Mean value_function loss: 91.2865
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 79.1154
                       Mean reward: 600.08
               Mean episode length: 217.64
    Episode_Reward/reaching_object: 1.5890
    Episode_Reward/rotating_object: 124.3696
        Episode_Reward/action_rate: -0.0745
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 2.40s
                      Time elapsed: 00:37:16
                               ETA: 00:21:25

################################################################################
                     [1m Learning iteration 953/1500 [0m                      

                       Computation: 41778 steps/s (collection: 2.222s, learning 0.131s)
             Mean action noise std: 3.29
          Mean value_function loss: 86.3762
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 79.1491
                       Mean reward: 640.22
               Mean episode length: 230.64
    Episode_Reward/reaching_object: 1.6464
    Episode_Reward/rotating_object: 127.4292
        Episode_Reward/action_rate: -0.0772
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 2.35s
                      Time elapsed: 00:37:18
                               ETA: 00:21:23

################################################################################
                     [1m Learning iteration 954/1500 [0m                      

                       Computation: 41754 steps/s (collection: 2.167s, learning 0.187s)
             Mean action noise std: 3.29
          Mean value_function loss: 97.2661
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 79.1821
                       Mean reward: 605.19
               Mean episode length: 226.18
    Episode_Reward/reaching_object: 1.6170
    Episode_Reward/rotating_object: 125.0343
        Episode_Reward/action_rate: -0.0758
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 2.35s
                      Time elapsed: 00:37:20
                               ETA: 00:21:21

################################################################################
                     [1m Learning iteration 955/1500 [0m                      

                       Computation: 41945 steps/s (collection: 2.182s, learning 0.161s)
             Mean action noise std: 3.29
          Mean value_function loss: 93.4304
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 79.2035
                       Mean reward: 618.36
               Mean episode length: 227.72
    Episode_Reward/reaching_object: 1.5643
    Episode_Reward/rotating_object: 119.1209
        Episode_Reward/action_rate: -0.0737
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 2.34s
                      Time elapsed: 00:37:23
                               ETA: 00:21:18

################################################################################
                     [1m Learning iteration 956/1500 [0m                      

                       Computation: 41984 steps/s (collection: 2.176s, learning 0.166s)
             Mean action noise std: 3.30
          Mean value_function loss: 93.8682
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 79.2323
                       Mean reward: 606.69
               Mean episode length: 230.02
    Episode_Reward/reaching_object: 1.6218
    Episode_Reward/rotating_object: 126.6901
        Episode_Reward/action_rate: -0.0762
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 2.34s
                      Time elapsed: 00:37:25
                               ETA: 00:21:16

################################################################################
                     [1m Learning iteration 957/1500 [0m                      

                       Computation: 43883 steps/s (collection: 2.143s, learning 0.097s)
             Mean action noise std: 3.30
          Mean value_function loss: 100.9666
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 79.2640
                       Mean reward: 566.39
               Mean episode length: 216.11
    Episode_Reward/reaching_object: 1.6103
    Episode_Reward/rotating_object: 123.6932
        Episode_Reward/action_rate: -0.0758
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 2.24s
                      Time elapsed: 00:37:27
                               ETA: 00:21:14

################################################################################
                     [1m Learning iteration 958/1500 [0m                      

                       Computation: 43194 steps/s (collection: 2.166s, learning 0.110s)
             Mean action noise std: 3.30
          Mean value_function loss: 103.1527
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 79.2880
                       Mean reward: 648.34
               Mean episode length: 229.63
    Episode_Reward/reaching_object: 1.6046
    Episode_Reward/rotating_object: 124.9453
        Episode_Reward/action_rate: -0.0756
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 2.28s
                      Time elapsed: 00:37:30
                               ETA: 00:21:11

################################################################################
                     [1m Learning iteration 959/1500 [0m                      

                       Computation: 41122 steps/s (collection: 2.229s, learning 0.162s)
             Mean action noise std: 3.30
          Mean value_function loss: 100.4833
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 79.3004
                       Mean reward: 638.30
               Mean episode length: 237.26
    Episode_Reward/reaching_object: 1.6374
    Episode_Reward/rotating_object: 126.7200
        Episode_Reward/action_rate: -0.0773
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 2.39s
                      Time elapsed: 00:37:32
                               ETA: 00:21:09

################################################################################
                     [1m Learning iteration 960/1500 [0m                      

                       Computation: 42970 steps/s (collection: 2.189s, learning 0.099s)
             Mean action noise std: 3.31
          Mean value_function loss: 102.2378
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 79.3154
                       Mean reward: 668.65
               Mean episode length: 238.12
    Episode_Reward/reaching_object: 1.6350
    Episode_Reward/rotating_object: 127.0249
        Episode_Reward/action_rate: -0.0771
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 2.29s
                      Time elapsed: 00:37:34
                               ETA: 00:21:07

################################################################################
                     [1m Learning iteration 961/1500 [0m                      

                       Computation: 43742 steps/s (collection: 2.134s, learning 0.113s)
             Mean action noise std: 3.31
          Mean value_function loss: 90.3665
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 79.3371
                       Mean reward: 614.74
               Mean episode length: 225.51
    Episode_Reward/reaching_object: 1.6423
    Episode_Reward/rotating_object: 127.6777
        Episode_Reward/action_rate: -0.0775
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 2.25s
                      Time elapsed: 00:37:37
                               ETA: 00:21:04

################################################################################
                     [1m Learning iteration 962/1500 [0m                      

                       Computation: 42583 steps/s (collection: 2.187s, learning 0.122s)
             Mean action noise std: 3.31
          Mean value_function loss: 99.6005
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 79.3482
                       Mean reward: 571.17
               Mean episode length: 224.63
    Episode_Reward/reaching_object: 1.5989
    Episode_Reward/rotating_object: 121.5011
        Episode_Reward/action_rate: -0.0757
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 2.31s
                      Time elapsed: 00:37:39
                               ETA: 00:21:02

################################################################################
                     [1m Learning iteration 963/1500 [0m                      

                       Computation: 42248 steps/s (collection: 2.190s, learning 0.137s)
             Mean action noise std: 3.31
          Mean value_function loss: 85.1701
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 79.3699
                       Mean reward: 632.78
               Mean episode length: 232.33
    Episode_Reward/reaching_object: 1.6361
    Episode_Reward/rotating_object: 125.4724
        Episode_Reward/action_rate: -0.0778
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 2.33s
                      Time elapsed: 00:37:41
                               ETA: 00:20:59

################################################################################
                     [1m Learning iteration 964/1500 [0m                      

                       Computation: 41933 steps/s (collection: 2.199s, learning 0.145s)
             Mean action noise std: 3.32
          Mean value_function loss: 92.7290
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 79.4000
                       Mean reward: 667.91
               Mean episode length: 235.86
    Episode_Reward/reaching_object: 1.6349
    Episode_Reward/rotating_object: 126.6834
        Episode_Reward/action_rate: -0.0777
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 2.34s
                      Time elapsed: 00:37:44
                               ETA: 00:20:57

################################################################################
                     [1m Learning iteration 965/1500 [0m                      

                       Computation: 41928 steps/s (collection: 2.210s, learning 0.134s)
             Mean action noise std: 3.32
          Mean value_function loss: 92.6315
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 79.4196
                       Mean reward: 684.09
               Mean episode length: 237.19
    Episode_Reward/reaching_object: 1.6172
    Episode_Reward/rotating_object: 128.5288
        Episode_Reward/action_rate: -0.0768
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 2.34s
                      Time elapsed: 00:37:46
                               ETA: 00:20:55

################################################################################
                     [1m Learning iteration 966/1500 [0m                      

                       Computation: 44263 steps/s (collection: 2.122s, learning 0.099s)
             Mean action noise std: 3.32
          Mean value_function loss: 92.9577
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 79.4416
                       Mean reward: 652.96
               Mean episode length: 230.15
    Episode_Reward/reaching_object: 1.6077
    Episode_Reward/rotating_object: 125.0175
        Episode_Reward/action_rate: -0.0764
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 2.22s
                      Time elapsed: 00:37:48
                               ETA: 00:20:52

################################################################################
                     [1m Learning iteration 967/1500 [0m                      

                       Computation: 43587 steps/s (collection: 2.146s, learning 0.109s)
             Mean action noise std: 3.32
          Mean value_function loss: 90.1175
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 79.4635
                       Mean reward: 670.60
               Mean episode length: 238.49
    Episode_Reward/reaching_object: 1.6360
    Episode_Reward/rotating_object: 129.0880
        Episode_Reward/action_rate: -0.0776
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 2.26s
                      Time elapsed: 00:37:50
                               ETA: 00:20:50

################################################################################
                     [1m Learning iteration 968/1500 [0m                      

                       Computation: 44637 steps/s (collection: 2.105s, learning 0.097s)
             Mean action noise std: 3.33
          Mean value_function loss: 91.6327
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 79.4929
                       Mean reward: 636.91
               Mean episode length: 229.86
    Episode_Reward/reaching_object: 1.6419
    Episode_Reward/rotating_object: 127.1095
        Episode_Reward/action_rate: -0.0783
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 2.20s
                      Time elapsed: 00:37:53
                               ETA: 00:20:47

################################################################################
                     [1m Learning iteration 969/1500 [0m                      

                       Computation: 44694 steps/s (collection: 2.105s, learning 0.095s)
             Mean action noise std: 3.33
          Mean value_function loss: 90.0960
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 79.5137
                       Mean reward: 642.79
               Mean episode length: 237.74
    Episode_Reward/reaching_object: 1.6167
    Episode_Reward/rotating_object: 125.2685
        Episode_Reward/action_rate: -0.0773
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 2.20s
                      Time elapsed: 00:37:55
                               ETA: 00:20:45

################################################################################
                     [1m Learning iteration 970/1500 [0m                      

                       Computation: 43889 steps/s (collection: 2.095s, learning 0.145s)
             Mean action noise std: 3.33
          Mean value_function loss: 94.0714
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 79.5269
                       Mean reward: 608.48
               Mean episode length: 221.98
    Episode_Reward/reaching_object: 1.6079
    Episode_Reward/rotating_object: 122.9346
        Episode_Reward/action_rate: -0.0770
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 2.24s
                      Time elapsed: 00:37:57
                               ETA: 00:20:43

################################################################################
                     [1m Learning iteration 971/1500 [0m                      

                       Computation: 43290 steps/s (collection: 2.125s, learning 0.146s)
             Mean action noise std: 3.33
          Mean value_function loss: 87.3799
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 79.5441
                       Mean reward: 644.05
               Mean episode length: 228.46
    Episode_Reward/reaching_object: 1.6410
    Episode_Reward/rotating_object: 127.7998
        Episode_Reward/action_rate: -0.0787
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 2.27s
                      Time elapsed: 00:37:59
                               ETA: 00:20:40

################################################################################
                     [1m Learning iteration 972/1500 [0m                      

                       Computation: 42086 steps/s (collection: 2.200s, learning 0.136s)
             Mean action noise std: 3.34
          Mean value_function loss: 85.5481
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 79.5715
                       Mean reward: 676.25
               Mean episode length: 241.02
    Episode_Reward/reaching_object: 1.6500
    Episode_Reward/rotating_object: 130.2599
        Episode_Reward/action_rate: -0.0789
          Episode_Reward/joint_vel: -0.0353
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 2.34s
                      Time elapsed: 00:38:02
                               ETA: 00:20:38

################################################################################
                     [1m Learning iteration 973/1500 [0m                      

                       Computation: 42997 steps/s (collection: 2.143s, learning 0.143s)
             Mean action noise std: 3.34
          Mean value_function loss: 87.3393
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 79.5906
                       Mean reward: 652.46
               Mean episode length: 228.68
    Episode_Reward/reaching_object: 1.6329
    Episode_Reward/rotating_object: 128.5507
        Episode_Reward/action_rate: -0.0784
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 2.29s
                      Time elapsed: 00:38:04
                               ETA: 00:20:36

################################################################################
                     [1m Learning iteration 974/1500 [0m                      

                       Computation: 43454 steps/s (collection: 2.128s, learning 0.134s)
             Mean action noise std: 3.34
          Mean value_function loss: 89.4775
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 79.6088
                       Mean reward: 614.26
               Mean episode length: 230.82
    Episode_Reward/reaching_object: 1.6504
    Episode_Reward/rotating_object: 127.0653
        Episode_Reward/action_rate: -0.0794
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 2.26s
                      Time elapsed: 00:38:06
                               ETA: 00:20:33

################################################################################
                     [1m Learning iteration 975/1500 [0m                      

                       Computation: 40911 steps/s (collection: 2.259s, learning 0.144s)
             Mean action noise std: 3.34
          Mean value_function loss: 83.1890
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 79.6337
                       Mean reward: 657.90
               Mean episode length: 239.89
    Episode_Reward/reaching_object: 1.6467
    Episode_Reward/rotating_object: 128.0495
        Episode_Reward/action_rate: -0.0795
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 2.40s
                      Time elapsed: 00:38:09
                               ETA: 00:20:31

################################################################################
                     [1m Learning iteration 976/1500 [0m                      

                       Computation: 41691 steps/s (collection: 2.226s, learning 0.132s)
             Mean action noise std: 3.35
          Mean value_function loss: 97.7991
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 79.6556
                       Mean reward: 629.21
               Mean episode length: 227.34
    Episode_Reward/reaching_object: 1.6197
    Episode_Reward/rotating_object: 126.1010
        Episode_Reward/action_rate: -0.0784
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 2.36s
                      Time elapsed: 00:38:11
                               ETA: 00:20:28

################################################################################
                     [1m Learning iteration 977/1500 [0m                      

                       Computation: 43338 steps/s (collection: 2.104s, learning 0.165s)
             Mean action noise std: 3.35
          Mean value_function loss: 101.4324
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 79.6684
                       Mean reward: 629.25
               Mean episode length: 233.89
    Episode_Reward/reaching_object: 1.6301
    Episode_Reward/rotating_object: 124.9904
        Episode_Reward/action_rate: -0.0789
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 2.27s
                      Time elapsed: 00:38:13
                               ETA: 00:20:26

################################################################################
                     [1m Learning iteration 978/1500 [0m                      

                       Computation: 42844 steps/s (collection: 2.150s, learning 0.144s)
             Mean action noise std: 3.35
          Mean value_function loss: 94.8011
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 79.6783
                       Mean reward: 647.35
               Mean episode length: 228.95
    Episode_Reward/reaching_object: 1.6350
    Episode_Reward/rotating_object: 128.6844
        Episode_Reward/action_rate: -0.0791
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 2.29s
                      Time elapsed: 00:38:15
                               ETA: 00:20:24

################################################################################
                     [1m Learning iteration 979/1500 [0m                      

                       Computation: 39571 steps/s (collection: 2.320s, learning 0.164s)
             Mean action noise std: 3.35
          Mean value_function loss: 111.4084
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 79.6941
                       Mean reward: 652.16
               Mean episode length: 233.54
    Episode_Reward/reaching_object: 1.6125
    Episode_Reward/rotating_object: 123.5140
        Episode_Reward/action_rate: -0.0783
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 2.48s
                      Time elapsed: 00:38:18
                               ETA: 00:20:21

################################################################################
                     [1m Learning iteration 980/1500 [0m                      

                       Computation: 38813 steps/s (collection: 2.390s, learning 0.143s)
             Mean action noise std: 3.35
          Mean value_function loss: 102.8589
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 79.7140
                       Mean reward: 656.07
               Mean episode length: 228.36
    Episode_Reward/reaching_object: 1.6181
    Episode_Reward/rotating_object: 127.4501
        Episode_Reward/action_rate: -0.0784
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 2.53s
                      Time elapsed: 00:38:21
                               ETA: 00:20:19

################################################################################
                     [1m Learning iteration 981/1500 [0m                      

                       Computation: 40883 steps/s (collection: 2.233s, learning 0.171s)
             Mean action noise std: 3.36
          Mean value_function loss: 96.3643
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 79.7274
                       Mean reward: 623.14
               Mean episode length: 228.87
    Episode_Reward/reaching_object: 1.5853
    Episode_Reward/rotating_object: 122.4653
        Episode_Reward/action_rate: -0.0772
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 2.40s
                      Time elapsed: 00:38:23
                               ETA: 00:20:17

################################################################################
                     [1m Learning iteration 982/1500 [0m                      

                       Computation: 37960 steps/s (collection: 2.495s, learning 0.094s)
             Mean action noise std: 3.36
          Mean value_function loss: 102.3770
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 79.7509
                       Mean reward: 641.16
               Mean episode length: 229.28
    Episode_Reward/reaching_object: 1.5934
    Episode_Reward/rotating_object: 122.5691
        Episode_Reward/action_rate: -0.0779
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 2.59s
                      Time elapsed: 00:38:25
                               ETA: 00:20:15

################################################################################
                     [1m Learning iteration 983/1500 [0m                      

                       Computation: 44388 steps/s (collection: 2.095s, learning 0.120s)
             Mean action noise std: 3.36
          Mean value_function loss: 80.6058
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 79.7682
                       Mean reward: 657.33
               Mean episode length: 232.43
    Episode_Reward/reaching_object: 1.6371
    Episode_Reward/rotating_object: 126.7165
        Episode_Reward/action_rate: -0.0798
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 2.21s
                      Time elapsed: 00:38:28
                               ETA: 00:20:12

################################################################################
                     [1m Learning iteration 984/1500 [0m                      

                       Computation: 43925 steps/s (collection: 2.134s, learning 0.104s)
             Mean action noise std: 3.37
          Mean value_function loss: 105.1371
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 79.7874
                       Mean reward: 659.82
               Mean episode length: 227.17
    Episode_Reward/reaching_object: 1.6479
    Episode_Reward/rotating_object: 128.5620
        Episode_Reward/action_rate: -0.0799
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 2.24s
                      Time elapsed: 00:38:30
                               ETA: 00:20:10

################################################################################
                     [1m Learning iteration 985/1500 [0m                      

                       Computation: 43943 steps/s (collection: 2.114s, learning 0.123s)
             Mean action noise std: 3.37
          Mean value_function loss: 81.8811
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 79.8126
                       Mean reward: 678.67
               Mean episode length: 236.28
    Episode_Reward/reaching_object: 1.6684
    Episode_Reward/rotating_object: 129.4759
        Episode_Reward/action_rate: -0.0813
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 2.24s
                      Time elapsed: 00:38:32
                               ETA: 00:20:07

################################################################################
                     [1m Learning iteration 986/1500 [0m                      

                       Computation: 44000 steps/s (collection: 2.133s, learning 0.101s)
             Mean action noise std: 3.37
          Mean value_function loss: 80.5012
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 79.8326
                       Mean reward: 691.81
               Mean episode length: 239.04
    Episode_Reward/reaching_object: 1.6900
    Episode_Reward/rotating_object: 134.1907
        Episode_Reward/action_rate: -0.0822
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 2.23s
                      Time elapsed: 00:38:34
                               ETA: 00:20:05

################################################################################
                     [1m Learning iteration 987/1500 [0m                      

                       Computation: 44611 steps/s (collection: 2.087s, learning 0.117s)
             Mean action noise std: 3.37
          Mean value_function loss: 77.6671
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 79.8532
                       Mean reward: 672.88
               Mean episode length: 235.73
    Episode_Reward/reaching_object: 1.6722
    Episode_Reward/rotating_object: 131.7008
        Episode_Reward/action_rate: -0.0816
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 2.20s
                      Time elapsed: 00:38:37
                               ETA: 00:20:03

################################################################################
                     [1m Learning iteration 988/1500 [0m                      

                       Computation: 42550 steps/s (collection: 2.119s, learning 0.192s)
             Mean action noise std: 3.38
          Mean value_function loss: 94.2395
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 79.8712
                       Mean reward: 649.79
               Mean episode length: 235.41
    Episode_Reward/reaching_object: 1.6417
    Episode_Reward/rotating_object: 127.3352
        Episode_Reward/action_rate: -0.0804
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 2.31s
                      Time elapsed: 00:38:39
                               ETA: 00:20:00

################################################################################
                     [1m Learning iteration 989/1500 [0m                      

                       Computation: 42094 steps/s (collection: 2.236s, learning 0.099s)
             Mean action noise std: 3.38
          Mean value_function loss: 79.7668
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 79.8996
                       Mean reward: 690.50
               Mean episode length: 243.92
    Episode_Reward/reaching_object: 1.6714
    Episode_Reward/rotating_object: 130.3462
        Episode_Reward/action_rate: -0.0818
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 2.34s
                      Time elapsed: 00:38:41
                               ETA: 00:19:58

################################################################################
                     [1m Learning iteration 990/1500 [0m                      

                       Computation: 41054 steps/s (collection: 2.238s, learning 0.156s)
             Mean action noise std: 3.38
          Mean value_function loss: 70.5342
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 79.9254
                       Mean reward: 641.58
               Mean episode length: 229.16
    Episode_Reward/reaching_object: 1.6716
    Episode_Reward/rotating_object: 131.2508
        Episode_Reward/action_rate: -0.0823
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 2.39s
                      Time elapsed: 00:38:44
                               ETA: 00:19:56

################################################################################
                     [1m Learning iteration 991/1500 [0m                      

                       Computation: 38761 steps/s (collection: 2.361s, learning 0.175s)
             Mean action noise std: 3.39
          Mean value_function loss: 74.0138
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 79.9534
                       Mean reward: 684.99
               Mean episode length: 240.42
    Episode_Reward/reaching_object: 1.6795
    Episode_Reward/rotating_object: 132.9953
        Episode_Reward/action_rate: -0.0827
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 2.54s
                      Time elapsed: 00:38:46
                               ETA: 00:19:53

################################################################################
                     [1m Learning iteration 992/1500 [0m                      

                       Computation: 43611 steps/s (collection: 2.137s, learning 0.117s)
             Mean action noise std: 3.39
          Mean value_function loss: 79.6801
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 79.9836
                       Mean reward: 612.65
               Mean episode length: 227.20
    Episode_Reward/reaching_object: 1.6212
    Episode_Reward/rotating_object: 126.3400
        Episode_Reward/action_rate: -0.0805
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 2.25s
                      Time elapsed: 00:38:48
                               ETA: 00:19:51

################################################################################
                     [1m Learning iteration 993/1500 [0m                      

                       Computation: 44616 steps/s (collection: 2.096s, learning 0.107s)
             Mean action noise std: 3.39
          Mean value_function loss: 77.5642
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 80.0139
                       Mean reward: 640.90
               Mean episode length: 233.78
    Episode_Reward/reaching_object: 1.6095
    Episode_Reward/rotating_object: 125.2630
        Episode_Reward/action_rate: -0.0803
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 2.20s
                      Time elapsed: 00:38:51
                               ETA: 00:19:49

################################################################################
                     [1m Learning iteration 994/1500 [0m                      

                       Computation: 44056 steps/s (collection: 2.120s, learning 0.111s)
             Mean action noise std: 3.39
          Mean value_function loss: 80.0133
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 80.0436
                       Mean reward: 682.07
               Mean episode length: 239.15
    Episode_Reward/reaching_object: 1.6602
    Episode_Reward/rotating_object: 130.9760
        Episode_Reward/action_rate: -0.0826
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 2.23s
                      Time elapsed: 00:38:53
                               ETA: 00:19:46

################################################################################
                     [1m Learning iteration 995/1500 [0m                      

                       Computation: 43726 steps/s (collection: 2.080s, learning 0.168s)
             Mean action noise std: 3.40
          Mean value_function loss: 65.6146
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 80.0629
                       Mean reward: 633.36
               Mean episode length: 235.35
    Episode_Reward/reaching_object: 1.6423
    Episode_Reward/rotating_object: 128.3971
        Episode_Reward/action_rate: -0.0819
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 2.25s
                      Time elapsed: 00:38:55
                               ETA: 00:19:44

################################################################################
                     [1m Learning iteration 996/1500 [0m                      

                       Computation: 44799 steps/s (collection: 2.065s, learning 0.129s)
             Mean action noise std: 3.40
          Mean value_function loss: 90.3591
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 80.0847
                       Mean reward: 676.11
               Mean episode length: 235.32
    Episode_Reward/reaching_object: 1.6515
    Episode_Reward/rotating_object: 129.2818
        Episode_Reward/action_rate: -0.0827
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 2.19s
                      Time elapsed: 00:38:57
                               ETA: 00:19:41

################################################################################
                     [1m Learning iteration 997/1500 [0m                      

                       Computation: 43925 steps/s (collection: 2.125s, learning 0.113s)
             Mean action noise std: 3.40
          Mean value_function loss: 89.8817
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 80.1123
                       Mean reward: 650.88
               Mean episode length: 237.09
    Episode_Reward/reaching_object: 1.6144
    Episode_Reward/rotating_object: 125.5256
        Episode_Reward/action_rate: -0.0812
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 2.24s
                      Time elapsed: 00:39:00
                               ETA: 00:19:39

################################################################################
                     [1m Learning iteration 998/1500 [0m                      

                       Computation: 44242 steps/s (collection: 2.115s, learning 0.107s)
             Mean action noise std: 3.41
          Mean value_function loss: 80.2743
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 80.1382
                       Mean reward: 652.87
               Mean episode length: 231.43
    Episode_Reward/reaching_object: 1.6334
    Episode_Reward/rotating_object: 128.4862
        Episode_Reward/action_rate: -0.0821
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 2.22s
                      Time elapsed: 00:39:02
                               ETA: 00:19:37

################################################################################
                     [1m Learning iteration 999/1500 [0m                      

                       Computation: 42650 steps/s (collection: 2.150s, learning 0.155s)
             Mean action noise std: 3.41
          Mean value_function loss: 94.9829
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 80.1629
                       Mean reward: 671.87
               Mean episode length: 233.64
    Episode_Reward/reaching_object: 1.6082
    Episode_Reward/rotating_object: 125.7165
        Episode_Reward/action_rate: -0.0811
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 2.30s
                      Time elapsed: 00:39:04
                               ETA: 00:19:34

################################################################################
                     [1m Learning iteration 1000/1500 [0m                     

                       Computation: 13903 steps/s (collection: 6.944s, learning 0.126s)
             Mean action noise std: 3.41
          Mean value_function loss: 93.7631
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 80.1830
                       Mean reward: 634.47
               Mean episode length: 237.00
    Episode_Reward/reaching_object: 1.6322
    Episode_Reward/rotating_object: 127.3424
        Episode_Reward/action_rate: -0.0824
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 7.07s
                      Time elapsed: 00:39:11
                               ETA: 00:19:34

################################################################################
                     [1m Learning iteration 1001/1500 [0m                     

                       Computation: 14469 steps/s (collection: 6.668s, learning 0.126s)
             Mean action noise std: 3.41
          Mean value_function loss: 102.9088
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 80.1963
                       Mean reward: 664.75
               Mean episode length: 234.99
    Episode_Reward/reaching_object: 1.6248
    Episode_Reward/rotating_object: 127.4650
        Episode_Reward/action_rate: -0.0821
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 6.79s
                      Time elapsed: 00:39:18
                               ETA: 00:19:34

################################################################################
                     [1m Learning iteration 1002/1500 [0m                     

                       Computation: 14456 steps/s (collection: 6.659s, learning 0.141s)
             Mean action noise std: 3.42
          Mean value_function loss: 91.3564
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 80.2140
                       Mean reward: 653.26
               Mean episode length: 234.42
    Episode_Reward/reaching_object: 1.6529
    Episode_Reward/rotating_object: 130.5548
        Episode_Reward/action_rate: -0.0834
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 6.80s
                      Time elapsed: 00:39:25
                               ETA: 00:19:34

################################################################################
                     [1m Learning iteration 1003/1500 [0m                     

                       Computation: 14073 steps/s (collection: 6.863s, learning 0.122s)
             Mean action noise std: 3.42
          Mean value_function loss: 93.4942
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 80.2290
                       Mean reward: 627.68
               Mean episode length: 226.79
    Episode_Reward/reaching_object: 1.6471
    Episode_Reward/rotating_object: 128.4556
        Episode_Reward/action_rate: -0.0832
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 6.98s
                      Time elapsed: 00:39:32
                               ETA: 00:19:34

################################################################################
                     [1m Learning iteration 1004/1500 [0m                     

                       Computation: 14382 steps/s (collection: 6.695s, learning 0.140s)
             Mean action noise std: 3.42
          Mean value_function loss: 101.9312
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 80.2414
                       Mean reward: 619.00
               Mean episode length: 224.75
    Episode_Reward/reaching_object: 1.6185
    Episode_Reward/rotating_object: 125.9396
        Episode_Reward/action_rate: -0.0816
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 6.83s
                      Time elapsed: 00:39:39
                               ETA: 00:19:34

################################################################################
                     [1m Learning iteration 1005/1500 [0m                     

                       Computation: 14172 steps/s (collection: 6.798s, learning 0.139s)
             Mean action noise std: 3.42
          Mean value_function loss: 83.3992
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 80.2530
                       Mean reward: 660.43
               Mean episode length: 238.66
    Episode_Reward/reaching_object: 1.6343
    Episode_Reward/rotating_object: 126.8401
        Episode_Reward/action_rate: -0.0827
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 6.94s
                      Time elapsed: 00:39:46
                               ETA: 00:19:34

################################################################################
                     [1m Learning iteration 1006/1500 [0m                     

                       Computation: 14320 steps/s (collection: 6.730s, learning 0.135s)
             Mean action noise std: 3.43
          Mean value_function loss: 94.1200
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 80.2685
                       Mean reward: 620.10
               Mean episode length: 230.67
    Episode_Reward/reaching_object: 1.6075
    Episode_Reward/rotating_object: 120.8711
        Episode_Reward/action_rate: -0.0815
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 6.86s
                      Time elapsed: 00:39:52
                               ETA: 00:19:33

################################################################################
                     [1m Learning iteration 1007/1500 [0m                     

                       Computation: 13884 steps/s (collection: 6.964s, learning 0.116s)
             Mean action noise std: 3.43
          Mean value_function loss: 83.2618
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 80.2842
                       Mean reward: 623.39
               Mean episode length: 231.10
    Episode_Reward/reaching_object: 1.6539
    Episode_Reward/rotating_object: 128.4192
        Episode_Reward/action_rate: -0.0831
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 7.08s
                      Time elapsed: 00:39:59
                               ETA: 00:19:33

################################################################################
                     [1m Learning iteration 1008/1500 [0m                     

                       Computation: 16392 steps/s (collection: 5.875s, learning 0.122s)
             Mean action noise std: 3.43
          Mean value_function loss: 78.9143
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 80.2943
                       Mean reward: 662.68
               Mean episode length: 238.56
    Episode_Reward/reaching_object: 1.6995
    Episode_Reward/rotating_object: 133.5727
        Episode_Reward/action_rate: -0.0852
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 6.00s
                      Time elapsed: 00:40:05
                               ETA: 00:19:33

################################################################################
                     [1m Learning iteration 1009/1500 [0m                     

                       Computation: 47124 steps/s (collection: 1.988s, learning 0.098s)
             Mean action noise std: 3.43
          Mean value_function loss: 95.3126
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 80.3051
                       Mean reward: 648.70
               Mean episode length: 230.44
    Episode_Reward/reaching_object: 1.6606
    Episode_Reward/rotating_object: 130.9119
        Episode_Reward/action_rate: -0.0835
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 2.09s
                      Time elapsed: 00:40:08
                               ETA: 00:19:30

################################################################################
                     [1m Learning iteration 1010/1500 [0m                     

                       Computation: 47750 steps/s (collection: 1.933s, learning 0.126s)
             Mean action noise std: 3.43
          Mean value_function loss: 95.3907
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 80.3172
                       Mean reward: 624.52
               Mean episode length: 228.98
    Episode_Reward/reaching_object: 1.6639
    Episode_Reward/rotating_object: 128.4514
        Episode_Reward/action_rate: -0.0838
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 2.06s
                      Time elapsed: 00:40:10
                               ETA: 00:19:28

################################################################################
                     [1m Learning iteration 1011/1500 [0m                     

                       Computation: 46769 steps/s (collection: 1.935s, learning 0.167s)
             Mean action noise std: 3.43
          Mean value_function loss: 77.5608
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 80.3257
                       Mean reward: 689.45
               Mean episode length: 239.01
    Episode_Reward/reaching_object: 1.6694
    Episode_Reward/rotating_object: 128.0180
        Episode_Reward/action_rate: -0.0844
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 2.10s
                      Time elapsed: 00:40:12
                               ETA: 00:19:25

################################################################################
                     [1m Learning iteration 1012/1500 [0m                     

                       Computation: 46649 steps/s (collection: 1.931s, learning 0.177s)
             Mean action noise std: 3.43
          Mean value_function loss: 79.9800
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 80.3352
                       Mean reward: 629.15
               Mean episode length: 229.92
    Episode_Reward/reaching_object: 1.6621
    Episode_Reward/rotating_object: 128.8939
        Episode_Reward/action_rate: -0.0835
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 2.11s
                      Time elapsed: 00:40:14
                               ETA: 00:19:23

################################################################################
                     [1m Learning iteration 1013/1500 [0m                     

                       Computation: 43055 steps/s (collection: 2.195s, learning 0.089s)
             Mean action noise std: 3.44
          Mean value_function loss: 86.9163
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 80.3576
                       Mean reward: 619.28
               Mean episode length: 227.49
    Episode_Reward/reaching_object: 1.6645
    Episode_Reward/rotating_object: 126.7117
        Episode_Reward/action_rate: -0.0843
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 2.28s
                      Time elapsed: 00:40:16
                               ETA: 00:19:20

################################################################################
                     [1m Learning iteration 1014/1500 [0m                     

                       Computation: 47922 steps/s (collection: 1.948s, learning 0.103s)
             Mean action noise std: 3.44
          Mean value_function loss: 66.2532
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 80.3836
                       Mean reward: 675.94
               Mean episode length: 234.67
    Episode_Reward/reaching_object: 1.6803
    Episode_Reward/rotating_object: 134.5450
        Episode_Reward/action_rate: -0.0850
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 2.05s
                      Time elapsed: 00:40:18
                               ETA: 00:19:18

################################################################################
                     [1m Learning iteration 1015/1500 [0m                     

                       Computation: 44511 steps/s (collection: 2.115s, learning 0.094s)
             Mean action noise std: 3.44
          Mean value_function loss: 76.7480
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 80.4058
                       Mean reward: 638.43
               Mean episode length: 225.31
    Episode_Reward/reaching_object: 1.6470
    Episode_Reward/rotating_object: 130.5337
        Episode_Reward/action_rate: -0.0840
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 2.21s
                      Time elapsed: 00:40:20
                               ETA: 00:19:15

################################################################################
                     [1m Learning iteration 1016/1500 [0m                     

                       Computation: 47410 steps/s (collection: 1.982s, learning 0.091s)
             Mean action noise std: 3.44
          Mean value_function loss: 74.1564
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 80.4241
                       Mean reward: 671.50
               Mean episode length: 237.54
    Episode_Reward/reaching_object: 1.6703
    Episode_Reward/rotating_object: 130.1510
        Episode_Reward/action_rate: -0.0850
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 2.07s
                      Time elapsed: 00:40:22
                               ETA: 00:19:13

################################################################################
                     [1m Learning iteration 1017/1500 [0m                     

                       Computation: 46258 steps/s (collection: 2.013s, learning 0.112s)
             Mean action noise std: 3.45
          Mean value_function loss: 86.6125
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 80.4350
                       Mean reward: 626.12
               Mean episode length: 227.65
    Episode_Reward/reaching_object: 1.6681
    Episode_Reward/rotating_object: 131.8190
        Episode_Reward/action_rate: -0.0848
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 2.13s
                      Time elapsed: 00:40:25
                               ETA: 00:19:10

################################################################################
                     [1m Learning iteration 1018/1500 [0m                     

                       Computation: 45770 steps/s (collection: 2.013s, learning 0.135s)
             Mean action noise std: 3.45
          Mean value_function loss: 87.8049
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 80.4457
                       Mean reward: 654.10
               Mean episode length: 230.48
    Episode_Reward/reaching_object: 1.6542
    Episode_Reward/rotating_object: 131.2036
        Episode_Reward/action_rate: -0.0843
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 2.15s
                      Time elapsed: 00:40:27
                               ETA: 00:19:08

################################################################################
                     [1m Learning iteration 1019/1500 [0m                     

                       Computation: 45898 steps/s (collection: 2.003s, learning 0.139s)
             Mean action noise std: 3.45
          Mean value_function loss: 97.2115
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 80.4628
                       Mean reward: 618.12
               Mean episode length: 226.70
    Episode_Reward/reaching_object: 1.6463
    Episode_Reward/rotating_object: 127.7217
        Episode_Reward/action_rate: -0.0842
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 2.14s
                      Time elapsed: 00:40:29
                               ETA: 00:19:05

################################################################################
                     [1m Learning iteration 1020/1500 [0m                     

                       Computation: 45105 steps/s (collection: 2.054s, learning 0.126s)
             Mean action noise std: 3.45
          Mean value_function loss: 88.0715
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 80.4862
                       Mean reward: 686.14
               Mean episode length: 239.21
    Episode_Reward/reaching_object: 1.6492
    Episode_Reward/rotating_object: 127.3182
        Episode_Reward/action_rate: -0.0847
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 2.18s
                      Time elapsed: 00:40:31
                               ETA: 00:19:03

################################################################################
                     [1m Learning iteration 1021/1500 [0m                     

                       Computation: 47117 steps/s (collection: 1.979s, learning 0.107s)
             Mean action noise std: 3.46
          Mean value_function loss: 101.2312
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 80.5040
                       Mean reward: 627.12
               Mean episode length: 225.53
    Episode_Reward/reaching_object: 1.6118
    Episode_Reward/rotating_object: 126.0307
        Episode_Reward/action_rate: -0.0825
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 2.09s
                      Time elapsed: 00:40:33
                               ETA: 00:19:00

################################################################################
                     [1m Learning iteration 1022/1500 [0m                     

                       Computation: 44621 steps/s (collection: 2.102s, learning 0.101s)
             Mean action noise std: 3.46
          Mean value_function loss: 114.3988
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 80.5170
                       Mean reward: 686.21
               Mean episode length: 241.71
    Episode_Reward/reaching_object: 1.6284
    Episode_Reward/rotating_object: 124.6242
        Episode_Reward/action_rate: -0.0836
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 2.20s
                      Time elapsed: 00:40:35
                               ETA: 00:18:58

################################################################################
                     [1m Learning iteration 1023/1500 [0m                     

                       Computation: 48020 steps/s (collection: 1.940s, learning 0.108s)
             Mean action noise std: 3.46
          Mean value_function loss: 94.9875
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 80.5379
                       Mean reward: 610.39
               Mean episode length: 223.92
    Episode_Reward/reaching_object: 1.6555
    Episode_Reward/rotating_object: 128.3269
        Episode_Reward/action_rate: -0.0841
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 2.05s
                      Time elapsed: 00:40:37
                               ETA: 00:18:55

################################################################################
                     [1m Learning iteration 1024/1500 [0m                     

                       Computation: 47177 steps/s (collection: 1.969s, learning 0.115s)
             Mean action noise std: 3.46
          Mean value_function loss: 99.3479
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 80.5584
                       Mean reward: 639.18
               Mean episode length: 230.23
    Episode_Reward/reaching_object: 1.6249
    Episode_Reward/rotating_object: 125.3937
        Episode_Reward/action_rate: -0.0832
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 2.08s
                      Time elapsed: 00:40:39
                               ETA: 00:18:53

################################################################################
                     [1m Learning iteration 1025/1500 [0m                     

                       Computation: 47659 steps/s (collection: 1.969s, learning 0.094s)
             Mean action noise std: 3.47
          Mean value_function loss: 90.8572
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 80.5782
                       Mean reward: 631.47
               Mean episode length: 228.71
    Episode_Reward/reaching_object: 1.6306
    Episode_Reward/rotating_object: 126.1342
        Episode_Reward/action_rate: -0.0834
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 2.06s
                      Time elapsed: 00:40:42
                               ETA: 00:18:50

################################################################################
                     [1m Learning iteration 1026/1500 [0m                     

                       Computation: 47084 steps/s (collection: 1.971s, learning 0.117s)
             Mean action noise std: 3.47
          Mean value_function loss: 87.5300
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 80.5987
                       Mean reward: 657.39
               Mean episode length: 235.06
    Episode_Reward/reaching_object: 1.6607
    Episode_Reward/rotating_object: 130.0918
        Episode_Reward/action_rate: -0.0847
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 2.09s
                      Time elapsed: 00:40:44
                               ETA: 00:18:48

################################################################################
                     [1m Learning iteration 1027/1500 [0m                     

                       Computation: 46730 steps/s (collection: 1.986s, learning 0.117s)
             Mean action noise std: 3.47
          Mean value_function loss: 104.1740
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 80.6204
                       Mean reward: 631.06
               Mean episode length: 228.14
    Episode_Reward/reaching_object: 1.5975
    Episode_Reward/rotating_object: 123.0352
        Episode_Reward/action_rate: -0.0818
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 2.10s
                      Time elapsed: 00:40:46
                               ETA: 00:18:45

################################################################################
                     [1m Learning iteration 1028/1500 [0m                     

                       Computation: 46685 steps/s (collection: 1.981s, learning 0.125s)
             Mean action noise std: 3.48
          Mean value_function loss: 95.1481
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 80.6521
                       Mean reward: 630.68
               Mean episode length: 231.48
    Episode_Reward/reaching_object: 1.6139
    Episode_Reward/rotating_object: 124.5492
        Episode_Reward/action_rate: -0.0831
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 2.11s
                      Time elapsed: 00:40:48
                               ETA: 00:18:43

################################################################################
                     [1m Learning iteration 1029/1500 [0m                     

                       Computation: 45951 steps/s (collection: 2.021s, learning 0.119s)
             Mean action noise std: 3.48
          Mean value_function loss: 106.5109
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 80.6840
                       Mean reward: 622.64
               Mean episode length: 221.88
    Episode_Reward/reaching_object: 1.6390
    Episode_Reward/rotating_object: 127.9280
        Episode_Reward/action_rate: -0.0843
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 2.14s
                      Time elapsed: 00:40:50
                               ETA: 00:18:40

################################################################################
                     [1m Learning iteration 1030/1500 [0m                     

                       Computation: 47203 steps/s (collection: 1.994s, learning 0.089s)
             Mean action noise std: 3.48
          Mean value_function loss: 99.9586
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 80.7057
                       Mean reward: 667.37
               Mean episode length: 231.88
    Episode_Reward/reaching_object: 1.5887
    Episode_Reward/rotating_object: 123.5822
        Episode_Reward/action_rate: -0.0823
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 2.08s
                      Time elapsed: 00:40:52
                               ETA: 00:18:38

################################################################################
                     [1m Learning iteration 1031/1500 [0m                     

                       Computation: 45738 steps/s (collection: 1.999s, learning 0.150s)
             Mean action noise std: 3.49
          Mean value_function loss: 102.1911
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 80.7199
                       Mean reward: 662.11
               Mean episode length: 232.30
    Episode_Reward/reaching_object: 1.6445
    Episode_Reward/rotating_object: 130.0756
        Episode_Reward/action_rate: -0.0848
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 2.15s
                      Time elapsed: 00:40:54
                               ETA: 00:18:35

################################################################################
                     [1m Learning iteration 1032/1500 [0m                     

                       Computation: 43871 steps/s (collection: 2.128s, learning 0.113s)
             Mean action noise std: 3.49
          Mean value_function loss: 81.6142
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 80.7378
                       Mean reward: 643.96
               Mean episode length: 233.23
    Episode_Reward/reaching_object: 1.6503
    Episode_Reward/rotating_object: 127.3173
        Episode_Reward/action_rate: -0.0851
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 2.24s
                      Time elapsed: 00:40:56
                               ETA: 00:18:33

################################################################################
                     [1m Learning iteration 1033/1500 [0m                     

                       Computation: 46418 steps/s (collection: 2.021s, learning 0.097s)
             Mean action noise std: 3.49
          Mean value_function loss: 97.7646
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 80.7691
                       Mean reward: 670.83
               Mean episode length: 233.40
    Episode_Reward/reaching_object: 1.6621
    Episode_Reward/rotating_object: 132.2080
        Episode_Reward/action_rate: -0.0858
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 2.12s
                      Time elapsed: 00:40:59
                               ETA: 00:18:30

################################################################################
                     [1m Learning iteration 1034/1500 [0m                     

                       Computation: 46262 steps/s (collection: 2.025s, learning 0.100s)
             Mean action noise std: 3.50
          Mean value_function loss: 90.1763
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 80.7971
                       Mean reward: 612.40
               Mean episode length: 218.80
    Episode_Reward/reaching_object: 1.6427
    Episode_Reward/rotating_object: 128.2029
        Episode_Reward/action_rate: -0.0851
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 2.12s
                      Time elapsed: 00:41:01
                               ETA: 00:18:28

################################################################################
                     [1m Learning iteration 1035/1500 [0m                     

                       Computation: 44635 steps/s (collection: 2.036s, learning 0.167s)
             Mean action noise std: 3.50
          Mean value_function loss: 77.3056
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 80.8202
                       Mean reward: 669.21
               Mean episode length: 233.21
    Episode_Reward/reaching_object: 1.6432
    Episode_Reward/rotating_object: 130.9117
        Episode_Reward/action_rate: -0.0854
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 2.20s
                      Time elapsed: 00:41:03
                               ETA: 00:18:25

################################################################################
                     [1m Learning iteration 1036/1500 [0m                     

                       Computation: 46220 steps/s (collection: 2.007s, learning 0.120s)
             Mean action noise std: 3.50
          Mean value_function loss: 91.9350
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 80.8397
                       Mean reward: 651.76
               Mean episode length: 231.72
    Episode_Reward/reaching_object: 1.6412
    Episode_Reward/rotating_object: 129.3111
        Episode_Reward/action_rate: -0.0856
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 2.13s
                      Time elapsed: 00:41:05
                               ETA: 00:18:23

################################################################################
                     [1m Learning iteration 1037/1500 [0m                     

                       Computation: 46113 steps/s (collection: 2.031s, learning 0.101s)
             Mean action noise std: 3.50
          Mean value_function loss: 87.7079
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 80.8578
                       Mean reward: 684.45
               Mean episode length: 239.28
    Episode_Reward/reaching_object: 1.6524
    Episode_Reward/rotating_object: 131.3957
        Episode_Reward/action_rate: -0.0860
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 2.13s
                      Time elapsed: 00:41:07
                               ETA: 00:18:20

################################################################################
                     [1m Learning iteration 1038/1500 [0m                     

                       Computation: 43407 steps/s (collection: 2.127s, learning 0.138s)
             Mean action noise std: 3.50
          Mean value_function loss: 79.4538
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 80.8680
                       Mean reward: 678.51
               Mean episode length: 238.42
    Episode_Reward/reaching_object: 1.6802
    Episode_Reward/rotating_object: 133.7650
        Episode_Reward/action_rate: -0.0876
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 2.26s
                      Time elapsed: 00:41:09
                               ETA: 00:18:18

################################################################################
                     [1m Learning iteration 1039/1500 [0m                     

                       Computation: 45395 steps/s (collection: 2.044s, learning 0.121s)
             Mean action noise std: 3.51
          Mean value_function loss: 91.9791
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 80.8849
                       Mean reward: 667.13
               Mean episode length: 236.96
    Episode_Reward/reaching_object: 1.6124
    Episode_Reward/rotating_object: 126.0378
        Episode_Reward/action_rate: -0.0851
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 2.17s
                      Time elapsed: 00:41:12
                               ETA: 00:18:15

################################################################################
                     [1m Learning iteration 1040/1500 [0m                     

                       Computation: 45913 steps/s (collection: 2.041s, learning 0.100s)
             Mean action noise std: 3.51
          Mean value_function loss: 95.1455
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 80.9053
                       Mean reward: 617.33
               Mean episode length: 222.02
    Episode_Reward/reaching_object: 1.6496
    Episode_Reward/rotating_object: 128.5566
        Episode_Reward/action_rate: -0.0864
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 2.14s
                      Time elapsed: 00:41:14
                               ETA: 00:18:13

################################################################################
                     [1m Learning iteration 1041/1500 [0m                     

                       Computation: 45226 steps/s (collection: 2.080s, learning 0.094s)
             Mean action noise std: 3.51
          Mean value_function loss: 92.0481
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 80.9259
                       Mean reward: 641.20
               Mean episode length: 223.70
    Episode_Reward/reaching_object: 1.6404
    Episode_Reward/rotating_object: 129.6749
        Episode_Reward/action_rate: -0.0862
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 2.17s
                      Time elapsed: 00:41:16
                               ETA: 00:18:10

################################################################################
                     [1m Learning iteration 1042/1500 [0m                     

                       Computation: 46668 steps/s (collection: 2.002s, learning 0.105s)
             Mean action noise std: 3.51
          Mean value_function loss: 88.0950
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 80.9398
                       Mean reward: 675.31
               Mean episode length: 237.87
    Episode_Reward/reaching_object: 1.6569
    Episode_Reward/rotating_object: 129.8661
        Episode_Reward/action_rate: -0.0871
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 2.11s
                      Time elapsed: 00:41:18
                               ETA: 00:18:08

################################################################################
                     [1m Learning iteration 1043/1500 [0m                     

                       Computation: 45582 steps/s (collection: 2.065s, learning 0.092s)
             Mean action noise std: 3.52
          Mean value_function loss: 89.4963
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 80.9540
                       Mean reward: 668.16
               Mean episode length: 237.07
    Episode_Reward/reaching_object: 1.6390
    Episode_Reward/rotating_object: 125.8342
        Episode_Reward/action_rate: -0.0865
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 2.16s
                      Time elapsed: 00:41:20
                               ETA: 00:18:05

################################################################################
                     [1m Learning iteration 1044/1500 [0m                     

                       Computation: 45413 steps/s (collection: 2.052s, learning 0.113s)
             Mean action noise std: 3.52
          Mean value_function loss: 69.1396
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 80.9659
                       Mean reward: 695.07
               Mean episode length: 241.56
    Episode_Reward/reaching_object: 1.6650
    Episode_Reward/rotating_object: 130.4507
        Episode_Reward/action_rate: -0.0876
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 2.16s
                      Time elapsed: 00:41:22
                               ETA: 00:18:03

################################################################################
                     [1m Learning iteration 1045/1500 [0m                     

                       Computation: 44570 steps/s (collection: 2.091s, learning 0.115s)
             Mean action noise std: 3.52
          Mean value_function loss: 80.7918
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 80.9855
                       Mean reward: 699.13
               Mean episode length: 242.81
    Episode_Reward/reaching_object: 1.6873
    Episode_Reward/rotating_object: 130.7524
        Episode_Reward/action_rate: -0.0890
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 2.21s
                      Time elapsed: 00:41:24
                               ETA: 00:18:00

################################################################################
                     [1m Learning iteration 1046/1500 [0m                     

                       Computation: 45945 steps/s (collection: 2.043s, learning 0.097s)
             Mean action noise std: 3.52
          Mean value_function loss: 82.3127
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 81.0096
                       Mean reward: 627.29
               Mean episode length: 225.76
    Episode_Reward/reaching_object: 1.6324
    Episode_Reward/rotating_object: 126.1809
        Episode_Reward/action_rate: -0.0864
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 2.14s
                      Time elapsed: 00:41:27
                               ETA: 00:17:58

################################################################################
                     [1m Learning iteration 1047/1500 [0m                     

                       Computation: 46294 steps/s (collection: 2.028s, learning 0.095s)
             Mean action noise std: 3.53
          Mean value_function loss: 98.6805
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 81.0252
                       Mean reward: 625.74
               Mean episode length: 222.54
    Episode_Reward/reaching_object: 1.6492
    Episode_Reward/rotating_object: 130.8176
        Episode_Reward/action_rate: -0.0870
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 2.12s
                      Time elapsed: 00:41:29
                               ETA: 00:17:55

################################################################################
                     [1m Learning iteration 1048/1500 [0m                     

                       Computation: 45469 steps/s (collection: 2.035s, learning 0.127s)
             Mean action noise std: 3.53
          Mean value_function loss: 68.8237
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 81.0406
                       Mean reward: 661.23
               Mean episode length: 232.48
    Episode_Reward/reaching_object: 1.6761
    Episode_Reward/rotating_object: 131.0540
        Episode_Reward/action_rate: -0.0885
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 2.16s
                      Time elapsed: 00:41:31
                               ETA: 00:17:53

################################################################################
                     [1m Learning iteration 1049/1500 [0m                     

                       Computation: 45800 steps/s (collection: 2.048s, learning 0.098s)
             Mean action noise std: 3.53
          Mean value_function loss: 96.5943
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 81.0562
                       Mean reward: 629.26
               Mean episode length: 225.58
    Episode_Reward/reaching_object: 1.6197
    Episode_Reward/rotating_object: 125.1375
        Episode_Reward/action_rate: -0.0859
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 2.15s
                      Time elapsed: 00:41:33
                               ETA: 00:17:51

################################################################################
                     [1m Learning iteration 1050/1500 [0m                     

                       Computation: 46356 steps/s (collection: 2.023s, learning 0.098s)
             Mean action noise std: 3.53
          Mean value_function loss: 79.6552
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 81.0773
                       Mean reward: 667.24
               Mean episode length: 237.13
    Episode_Reward/reaching_object: 1.6734
    Episode_Reward/rotating_object: 131.6433
        Episode_Reward/action_rate: -0.0885
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 2.12s
                      Time elapsed: 00:41:35
                               ETA: 00:17:48

################################################################################
                     [1m Learning iteration 1051/1500 [0m                     

                       Computation: 46223 steps/s (collection: 2.032s, learning 0.095s)
             Mean action noise std: 3.54
          Mean value_function loss: 86.2079
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 81.0933
                       Mean reward: 662.07
               Mean episode length: 234.20
    Episode_Reward/reaching_object: 1.6692
    Episode_Reward/rotating_object: 131.8985
        Episode_Reward/action_rate: -0.0886
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 2.13s
                      Time elapsed: 00:41:37
                               ETA: 00:17:46

################################################################################
                     [1m Learning iteration 1052/1500 [0m                     

                       Computation: 46254 steps/s (collection: 2.025s, learning 0.101s)
             Mean action noise std: 3.54
          Mean value_function loss: 83.5956
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 81.1110
                       Mean reward: 663.78
               Mean episode length: 227.22
    Episode_Reward/reaching_object: 1.6744
    Episode_Reward/rotating_object: 131.8320
        Episode_Reward/action_rate: -0.0890
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 2.13s
                      Time elapsed: 00:41:39
                               ETA: 00:17:43

################################################################################
                     [1m Learning iteration 1053/1500 [0m                     

                       Computation: 47084 steps/s (collection: 1.999s, learning 0.089s)
             Mean action noise std: 3.54
          Mean value_function loss: 84.9995
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 81.1276
                       Mean reward: 649.30
               Mean episode length: 230.81
    Episode_Reward/reaching_object: 1.6424
    Episode_Reward/rotating_object: 128.1855
        Episode_Reward/action_rate: -0.0876
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 2.09s
                      Time elapsed: 00:41:42
                               ETA: 00:17:41

################################################################################
                     [1m Learning iteration 1054/1500 [0m                     

                       Computation: 46571 steps/s (collection: 1.996s, learning 0.115s)
             Mean action noise std: 3.54
          Mean value_function loss: 85.7101
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 81.1443
                       Mean reward: 656.98
               Mean episode length: 232.83
    Episode_Reward/reaching_object: 1.6549
    Episode_Reward/rotating_object: 131.2809
        Episode_Reward/action_rate: -0.0883
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 2.11s
                      Time elapsed: 00:41:44
                               ETA: 00:17:38

################################################################################
                     [1m Learning iteration 1055/1500 [0m                     

                       Computation: 42788 steps/s (collection: 2.141s, learning 0.157s)
             Mean action noise std: 3.55
          Mean value_function loss: 81.0463
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 81.1590
                       Mean reward: 641.90
               Mean episode length: 230.14
    Episode_Reward/reaching_object: 1.6568
    Episode_Reward/rotating_object: 130.2465
        Episode_Reward/action_rate: -0.0884
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 2.30s
                      Time elapsed: 00:41:46
                               ETA: 00:17:36

################################################################################
                     [1m Learning iteration 1056/1500 [0m                     

                       Computation: 42877 steps/s (collection: 2.151s, learning 0.142s)
             Mean action noise std: 3.55
          Mean value_function loss: 81.6554
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 81.1817
                       Mean reward: 678.70
               Mean episode length: 234.78
    Episode_Reward/reaching_object: 1.6905
    Episode_Reward/rotating_object: 132.3528
        Episode_Reward/action_rate: -0.0902
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 2.29s
                      Time elapsed: 00:41:48
                               ETA: 00:17:33

################################################################################
                     [1m Learning iteration 1057/1500 [0m                     

                       Computation: 43454 steps/s (collection: 2.173s, learning 0.090s)
             Mean action noise std: 3.55
          Mean value_function loss: 80.9265
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 81.1993
                       Mean reward: 710.97
               Mean episode length: 241.03
    Episode_Reward/reaching_object: 1.6452
    Episode_Reward/rotating_object: 130.6294
        Episode_Reward/action_rate: -0.0883
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 2.26s
                      Time elapsed: 00:41:50
                               ETA: 00:17:31

################################################################################
                     [1m Learning iteration 1058/1500 [0m                     

                       Computation: 46696 steps/s (collection: 1.989s, learning 0.116s)
             Mean action noise std: 3.55
          Mean value_function loss: 85.6812
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 81.2193
                       Mean reward: 639.96
               Mean episode length: 231.25
    Episode_Reward/reaching_object: 1.6869
    Episode_Reward/rotating_object: 132.9328
        Episode_Reward/action_rate: -0.0904
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 2.11s
                      Time elapsed: 00:41:53
                               ETA: 00:17:28

################################################################################
                     [1m Learning iteration 1059/1500 [0m                     

                       Computation: 46483 steps/s (collection: 2.022s, learning 0.093s)
             Mean action noise std: 3.55
          Mean value_function loss: 78.5916
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 81.2395
                       Mean reward: 662.84
               Mean episode length: 235.65
    Episode_Reward/reaching_object: 1.6548
    Episode_Reward/rotating_object: 129.5118
        Episode_Reward/action_rate: -0.0888
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 2.11s
                      Time elapsed: 00:41:55
                               ETA: 00:17:26

################################################################################
                     [1m Learning iteration 1060/1500 [0m                     

                       Computation: 47581 steps/s (collection: 1.964s, learning 0.102s)
             Mean action noise std: 3.56
          Mean value_function loss: 110.0074
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 81.2547
                       Mean reward: 617.05
               Mean episode length: 223.92
    Episode_Reward/reaching_object: 1.6397
    Episode_Reward/rotating_object: 127.3801
        Episode_Reward/action_rate: -0.0883
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 2.07s
                      Time elapsed: 00:41:57
                               ETA: 00:17:23

################################################################################
                     [1m Learning iteration 1061/1500 [0m                     

                       Computation: 46712 steps/s (collection: 1.978s, learning 0.126s)
             Mean action noise std: 3.56
          Mean value_function loss: 93.5064
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 81.2761
                       Mean reward: 692.47
               Mean episode length: 238.54
    Episode_Reward/reaching_object: 1.6612
    Episode_Reward/rotating_object: 132.7399
        Episode_Reward/action_rate: -0.0893
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 2.10s
                      Time elapsed: 00:41:59
                               ETA: 00:17:21

################################################################################
                     [1m Learning iteration 1062/1500 [0m                     

                       Computation: 42751 steps/s (collection: 2.136s, learning 0.164s)
             Mean action noise std: 3.56
          Mean value_function loss: 89.8849
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 81.2927
                       Mean reward: 634.79
               Mean episode length: 229.43
    Episode_Reward/reaching_object: 1.6334
    Episode_Reward/rotating_object: 126.0854
        Episode_Reward/action_rate: -0.0880
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 2.30s
                      Time elapsed: 00:42:01
                               ETA: 00:17:19

################################################################################
                     [1m Learning iteration 1063/1500 [0m                     

                       Computation: 44275 steps/s (collection: 2.071s, learning 0.150s)
             Mean action noise std: 3.56
          Mean value_function loss: 83.3793
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 81.3049
                       Mean reward: 692.56
               Mean episode length: 245.97
    Episode_Reward/reaching_object: 1.6919
    Episode_Reward/rotating_object: 132.9831
        Episode_Reward/action_rate: -0.0909
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 2.22s
                      Time elapsed: 00:42:03
                               ETA: 00:17:16

################################################################################
                     [1m Learning iteration 1064/1500 [0m                     

                       Computation: 44419 steps/s (collection: 2.086s, learning 0.127s)
             Mean action noise std: 3.57
          Mean value_function loss: 89.8423
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 81.3282
                       Mean reward: 685.30
               Mean episode length: 242.00
    Episode_Reward/reaching_object: 1.6529
    Episode_Reward/rotating_object: 128.0957
        Episode_Reward/action_rate: -0.0895
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 2.21s
                      Time elapsed: 00:42:06
                               ETA: 00:17:14

################################################################################
                     [1m Learning iteration 1065/1500 [0m                     

                       Computation: 46242 steps/s (collection: 2.016s, learning 0.110s)
             Mean action noise std: 3.57
          Mean value_function loss: 92.6809
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 81.3511
                       Mean reward: 697.85
               Mean episode length: 243.98
    Episode_Reward/reaching_object: 1.6338
    Episode_Reward/rotating_object: 128.7164
        Episode_Reward/action_rate: -0.0881
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 2.13s
                      Time elapsed: 00:42:08
                               ETA: 00:17:11

################################################################################
                     [1m Learning iteration 1066/1500 [0m                     

                       Computation: 42971 steps/s (collection: 2.143s, learning 0.144s)
             Mean action noise std: 3.57
          Mean value_function loss: 89.0566
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 81.3664
                       Mean reward: 651.80
               Mean episode length: 226.14
    Episode_Reward/reaching_object: 1.6353
    Episode_Reward/rotating_object: 128.6585
        Episode_Reward/action_rate: -0.0883
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 2.29s
                      Time elapsed: 00:42:10
                               ETA: 00:17:09

################################################################################
                     [1m Learning iteration 1067/1500 [0m                     

                       Computation: 45460 steps/s (collection: 1.994s, learning 0.168s)
             Mean action noise std: 3.58
          Mean value_function loss: 76.6107
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 81.3842
                       Mean reward: 653.84
               Mean episode length: 232.73
    Episode_Reward/reaching_object: 1.6788
    Episode_Reward/rotating_object: 132.0379
        Episode_Reward/action_rate: -0.0907
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 2.16s
                      Time elapsed: 00:42:12
                               ETA: 00:17:06

################################################################################
                     [1m Learning iteration 1068/1500 [0m                     

                       Computation: 43440 steps/s (collection: 2.166s, learning 0.097s)
             Mean action noise std: 3.58
          Mean value_function loss: 89.1365
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 81.4144
                       Mean reward: 681.67
               Mean episode length: 234.57
    Episode_Reward/reaching_object: 1.6442
    Episode_Reward/rotating_object: 129.4573
        Episode_Reward/action_rate: -0.0890
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 2.26s
                      Time elapsed: 00:42:14
                               ETA: 00:17:04

################################################################################
                     [1m Learning iteration 1069/1500 [0m                     

                       Computation: 43519 steps/s (collection: 2.137s, learning 0.122s)
             Mean action noise std: 3.58
          Mean value_function loss: 95.1938
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 81.4372
                       Mean reward: 591.13
               Mean episode length: 233.17
    Episode_Reward/reaching_object: 1.6682
    Episode_Reward/rotating_object: 128.3302
        Episode_Reward/action_rate: -0.0905
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 2.26s
                      Time elapsed: 00:42:17
                               ETA: 00:17:01

################################################################################
                     [1m Learning iteration 1070/1500 [0m                     

                       Computation: 42352 steps/s (collection: 2.195s, learning 0.126s)
             Mean action noise std: 3.59
          Mean value_function loss: 78.3557
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 81.4619
                       Mean reward: 664.58
               Mean episode length: 231.08
    Episode_Reward/reaching_object: 1.6819
    Episode_Reward/rotating_object: 133.2532
        Episode_Reward/action_rate: -0.0911
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 2.32s
                      Time elapsed: 00:42:19
                               ETA: 00:16:59

################################################################################
                     [1m Learning iteration 1071/1500 [0m                     

                       Computation: 45704 steps/s (collection: 1.989s, learning 0.162s)
             Mean action noise std: 3.59
          Mean value_function loss: 99.4187
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 81.4800
                       Mean reward: 624.79
               Mean episode length: 223.74
    Episode_Reward/reaching_object: 1.6607
    Episode_Reward/rotating_object: 130.4124
        Episode_Reward/action_rate: -0.0904
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 2.15s
                      Time elapsed: 00:42:21
                               ETA: 00:16:57

################################################################################
                     [1m Learning iteration 1072/1500 [0m                     

                       Computation: 45859 steps/s (collection: 2.004s, learning 0.140s)
             Mean action noise std: 3.59
          Mean value_function loss: 101.8391
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 81.4943
                       Mean reward: 684.58
               Mean episode length: 237.87
    Episode_Reward/reaching_object: 1.6431
    Episode_Reward/rotating_object: 129.9747
        Episode_Reward/action_rate: -0.0894
          Episode_Reward/joint_vel: -0.0353
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 2.14s
                      Time elapsed: 00:42:23
                               ETA: 00:16:54

################################################################################
                     [1m Learning iteration 1073/1500 [0m                     

                       Computation: 45778 steps/s (collection: 2.052s, learning 0.095s)
             Mean action noise std: 3.59
          Mean value_function loss: 91.6933
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 81.5243
                       Mean reward: 625.58
               Mean episode length: 225.82
    Episode_Reward/reaching_object: 1.6170
    Episode_Reward/rotating_object: 125.1105
        Episode_Reward/action_rate: -0.0885
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 2.15s
                      Time elapsed: 00:42:25
                               ETA: 00:16:52

################################################################################
                     [1m Learning iteration 1074/1500 [0m                     

                       Computation: 46112 steps/s (collection: 1.998s, learning 0.134s)
             Mean action noise std: 3.60
          Mean value_function loss: 98.8415
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 81.5472
                       Mean reward: 653.29
               Mean episode length: 231.01
    Episode_Reward/reaching_object: 1.6598
    Episode_Reward/rotating_object: 129.7118
        Episode_Reward/action_rate: -0.0907
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 2.13s
                      Time elapsed: 00:42:28
                               ETA: 00:16:49

################################################################################
                     [1m Learning iteration 1075/1500 [0m                     

                       Computation: 45518 steps/s (collection: 2.037s, learning 0.123s)
             Mean action noise std: 3.60
          Mean value_function loss: 107.2446
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 81.5579
                       Mean reward: 635.60
               Mean episode length: 231.35
    Episode_Reward/reaching_object: 1.6339
    Episode_Reward/rotating_object: 127.2096
        Episode_Reward/action_rate: -0.0897
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 2.16s
                      Time elapsed: 00:42:30
                               ETA: 00:16:47

################################################################################
                     [1m Learning iteration 1076/1500 [0m                     

                       Computation: 46122 steps/s (collection: 2.036s, learning 0.095s)
             Mean action noise std: 3.60
          Mean value_function loss: 87.5114
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 81.5669
                       Mean reward: 614.39
               Mean episode length: 228.88
    Episode_Reward/reaching_object: 1.6495
    Episode_Reward/rotating_object: 128.2834
        Episode_Reward/action_rate: -0.0905
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 2.13s
                      Time elapsed: 00:42:32
                               ETA: 00:16:44

################################################################################
                     [1m Learning iteration 1077/1500 [0m                     

                       Computation: 46173 steps/s (collection: 2.031s, learning 0.098s)
             Mean action noise std: 3.60
          Mean value_function loss: 82.6942
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 81.5872
                       Mean reward: 663.79
               Mean episode length: 233.05
    Episode_Reward/reaching_object: 1.6647
    Episode_Reward/rotating_object: 131.0356
        Episode_Reward/action_rate: -0.0918
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 2.13s
                      Time elapsed: 00:42:34
                               ETA: 00:16:42

################################################################################
                     [1m Learning iteration 1078/1500 [0m                     

                       Computation: 46943 steps/s (collection: 1.998s, learning 0.097s)
             Mean action noise std: 3.61
          Mean value_function loss: 80.6993
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 81.6121
                       Mean reward: 659.13
               Mean episode length: 234.66
    Episode_Reward/reaching_object: 1.6495
    Episode_Reward/rotating_object: 130.1938
        Episode_Reward/action_rate: -0.0907
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 2.09s
                      Time elapsed: 00:42:36
                               ETA: 00:16:39

################################################################################
                     [1m Learning iteration 1079/1500 [0m                     

                       Computation: 42601 steps/s (collection: 2.130s, learning 0.178s)
             Mean action noise std: 3.61
          Mean value_function loss: 78.2834
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 81.6407
                       Mean reward: 682.45
               Mean episode length: 239.26
    Episode_Reward/reaching_object: 1.6886
    Episode_Reward/rotating_object: 135.2604
        Episode_Reward/action_rate: -0.0929
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 2.31s
                      Time elapsed: 00:42:38
                               ETA: 00:16:37

################################################################################
                     [1m Learning iteration 1080/1500 [0m                     

                       Computation: 46000 steps/s (collection: 2.023s, learning 0.114s)
             Mean action noise std: 3.61
          Mean value_function loss: 82.5611
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 81.6601
                       Mean reward: 625.83
               Mean episode length: 227.89
    Episode_Reward/reaching_object: 1.6327
    Episode_Reward/rotating_object: 125.7140
        Episode_Reward/action_rate: -0.0905
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 2.14s
                      Time elapsed: 00:42:41
                               ETA: 00:16:35

################################################################################
                     [1m Learning iteration 1081/1500 [0m                     

                       Computation: 46265 steps/s (collection: 2.028s, learning 0.097s)
             Mean action noise std: 3.61
          Mean value_function loss: 82.6990
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 81.6784
                       Mean reward: 646.55
               Mean episode length: 236.40
    Episode_Reward/reaching_object: 1.6521
    Episode_Reward/rotating_object: 128.5334
        Episode_Reward/action_rate: -0.0914
          Episode_Reward/joint_vel: -0.0353
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 2.12s
                      Time elapsed: 00:42:43
                               ETA: 00:16:32

################################################################################
                     [1m Learning iteration 1082/1500 [0m                     

                       Computation: 43684 steps/s (collection: 2.158s, learning 0.092s)
             Mean action noise std: 3.62
          Mean value_function loss: 84.8153
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 81.7017
                       Mean reward: 645.65
               Mean episode length: 232.72
    Episode_Reward/reaching_object: 1.6706
    Episode_Reward/rotating_object: 129.4913
        Episode_Reward/action_rate: -0.0926
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 2.25s
                      Time elapsed: 00:42:45
                               ETA: 00:16:30

################################################################################
                     [1m Learning iteration 1083/1500 [0m                     

                       Computation: 46699 steps/s (collection: 2.014s, learning 0.092s)
             Mean action noise std: 3.62
          Mean value_function loss: 96.5003
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 81.7243
                       Mean reward: 615.88
               Mean episode length: 225.49
    Episode_Reward/reaching_object: 1.6407
    Episode_Reward/rotating_object: 126.8221
        Episode_Reward/action_rate: -0.0915
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 2.11s
                      Time elapsed: 00:42:47
                               ETA: 00:16:27

################################################################################
                     [1m Learning iteration 1084/1500 [0m                     

                       Computation: 47196 steps/s (collection: 1.953s, learning 0.130s)
             Mean action noise std: 3.62
          Mean value_function loss: 86.9275
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 81.7482
                       Mean reward: 641.20
               Mean episode length: 232.90
    Episode_Reward/reaching_object: 1.6427
    Episode_Reward/rotating_object: 127.8523
        Episode_Reward/action_rate: -0.0916
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 2.08s
                      Time elapsed: 00:42:49
                               ETA: 00:16:25

################################################################################
                     [1m Learning iteration 1085/1500 [0m                     

                       Computation: 46645 steps/s (collection: 1.970s, learning 0.137s)
             Mean action noise std: 3.62
          Mean value_function loss: 96.6428
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 81.7720
                       Mean reward: 651.59
               Mean episode length: 234.20
    Episode_Reward/reaching_object: 1.6205
    Episode_Reward/rotating_object: 126.8709
        Episode_Reward/action_rate: -0.0904
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 2.11s
                      Time elapsed: 00:42:51
                               ETA: 00:16:22

################################################################################
                     [1m Learning iteration 1086/1500 [0m                     

                       Computation: 44988 steps/s (collection: 2.013s, learning 0.173s)
             Mean action noise std: 3.63
          Mean value_function loss: 88.6962
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 81.7909
                       Mean reward: 648.77
               Mean episode length: 224.91
    Episode_Reward/reaching_object: 1.6467
    Episode_Reward/rotating_object: 129.2661
        Episode_Reward/action_rate: -0.0919
          Episode_Reward/joint_vel: -0.0353
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 2.19s
                      Time elapsed: 00:42:53
                               ETA: 00:16:20

################################################################################
                     [1m Learning iteration 1087/1500 [0m                     

                       Computation: 44762 steps/s (collection: 2.099s, learning 0.097s)
             Mean action noise std: 3.63
          Mean value_function loss: 94.1644
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 81.8124
                       Mean reward: 649.67
               Mean episode length: 228.14
    Episode_Reward/reaching_object: 1.6604
    Episode_Reward/rotating_object: 131.4832
        Episode_Reward/action_rate: -0.0925
          Episode_Reward/joint_vel: -0.0353
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 2.20s
                      Time elapsed: 00:42:56
                               ETA: 00:16:17

################################################################################
                     [1m Learning iteration 1088/1500 [0m                     

                       Computation: 45720 steps/s (collection: 2.055s, learning 0.096s)
             Mean action noise std: 3.63
          Mean value_function loss: 96.4655
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 81.8369
                       Mean reward: 637.31
               Mean episode length: 231.82
    Episode_Reward/reaching_object: 1.6372
    Episode_Reward/rotating_object: 126.3329
        Episode_Reward/action_rate: -0.0914
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 2.15s
                      Time elapsed: 00:42:58
                               ETA: 00:16:15

################################################################################
                     [1m Learning iteration 1089/1500 [0m                     

                       Computation: 44599 steps/s (collection: 2.109s, learning 0.096s)
             Mean action noise std: 3.63
          Mean value_function loss: 72.4410
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 81.8492
                       Mean reward: 703.66
               Mean episode length: 241.41
    Episode_Reward/reaching_object: 1.6957
    Episode_Reward/rotating_object: 134.1251
        Episode_Reward/action_rate: -0.0941
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 2.20s
                      Time elapsed: 00:43:00
                               ETA: 00:16:13

################################################################################
                     [1m Learning iteration 1090/1500 [0m                     

                       Computation: 42350 steps/s (collection: 2.120s, learning 0.202s)
             Mean action noise std: 3.64
          Mean value_function loss: 92.6554
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 81.8654
                       Mean reward: 660.18
               Mean episode length: 228.57
    Episode_Reward/reaching_object: 1.6274
    Episode_Reward/rotating_object: 129.0860
        Episode_Reward/action_rate: -0.0912
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 2.32s
                      Time elapsed: 00:43:02
                               ETA: 00:16:10

################################################################################
                     [1m Learning iteration 1091/1500 [0m                     

                       Computation: 42868 steps/s (collection: 2.158s, learning 0.135s)
             Mean action noise std: 3.64
          Mean value_function loss: 111.7611
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 81.8848
                       Mean reward: 645.82
               Mean episode length: 230.68
    Episode_Reward/reaching_object: 1.6449
    Episode_Reward/rotating_object: 127.4173
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 2.29s
                      Time elapsed: 00:43:05
                               ETA: 00:16:08

################################################################################
                     [1m Learning iteration 1092/1500 [0m                     

                       Computation: 43391 steps/s (collection: 2.149s, learning 0.116s)
             Mean action noise std: 3.64
          Mean value_function loss: 122.7872
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 81.9012
                       Mean reward: 631.98
               Mean episode length: 228.71
    Episode_Reward/reaching_object: 1.6441
    Episode_Reward/rotating_object: 127.7264
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 2.27s
                      Time elapsed: 00:43:07
                               ETA: 00:16:05

################################################################################
                     [1m Learning iteration 1093/1500 [0m                     

                       Computation: 45961 steps/s (collection: 2.047s, learning 0.092s)
             Mean action noise std: 3.64
          Mean value_function loss: 113.6717
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 81.9203
                       Mean reward: 629.31
               Mean episode length: 229.09
    Episode_Reward/reaching_object: 1.6234
    Episode_Reward/rotating_object: 124.0193
        Episode_Reward/action_rate: -0.0907
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 2.14s
                      Time elapsed: 00:43:09
                               ETA: 00:16:03

################################################################################
                     [1m Learning iteration 1094/1500 [0m                     

                       Computation: 46992 steps/s (collection: 1.993s, learning 0.099s)
             Mean action noise std: 3.65
          Mean value_function loss: 105.5970
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 81.9348
                       Mean reward: 662.98
               Mean episode length: 235.80
    Episode_Reward/reaching_object: 1.6445
    Episode_Reward/rotating_object: 125.8003
        Episode_Reward/action_rate: -0.0921
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 2.09s
                      Time elapsed: 00:43:11
                               ETA: 00:16:00

################################################################################
                     [1m Learning iteration 1095/1500 [0m                     

                       Computation: 46557 steps/s (collection: 2.009s, learning 0.103s)
             Mean action noise std: 3.65
          Mean value_function loss: 109.7184
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 81.9487
                       Mean reward: 616.74
               Mean episode length: 221.14
    Episode_Reward/reaching_object: 1.6355
    Episode_Reward/rotating_object: 127.1883
        Episode_Reward/action_rate: -0.0915
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 2.11s
                      Time elapsed: 00:43:13
                               ETA: 00:15:58

################################################################################
                     [1m Learning iteration 1096/1500 [0m                     

                       Computation: 42935 steps/s (collection: 2.153s, learning 0.136s)
             Mean action noise std: 3.65
          Mean value_function loss: 108.1436
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 81.9586
                       Mean reward: 608.72
               Mean episode length: 225.68
    Episode_Reward/reaching_object: 1.6223
    Episode_Reward/rotating_object: 122.3280
        Episode_Reward/action_rate: -0.0914
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 2.29s
                      Time elapsed: 00:43:15
                               ETA: 00:15:56

################################################################################
                     [1m Learning iteration 1097/1500 [0m                     

                       Computation: 46600 steps/s (collection: 2.010s, learning 0.099s)
             Mean action noise std: 3.65
          Mean value_function loss: 105.4906
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 81.9765
                       Mean reward: 647.50
               Mean episode length: 230.89
    Episode_Reward/reaching_object: 1.6399
    Episode_Reward/rotating_object: 127.5926
        Episode_Reward/action_rate: -0.0921
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 2.11s
                      Time elapsed: 00:43:18
                               ETA: 00:15:53

################################################################################
                     [1m Learning iteration 1098/1500 [0m                     

                       Computation: 42126 steps/s (collection: 2.187s, learning 0.146s)
             Mean action noise std: 3.66
          Mean value_function loss: 105.7583
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 82.0012
                       Mean reward: 653.69
               Mean episode length: 229.74
    Episode_Reward/reaching_object: 1.6537
    Episode_Reward/rotating_object: 128.7217
        Episode_Reward/action_rate: -0.0924
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 2.33s
                      Time elapsed: 00:43:20
                               ETA: 00:15:51

################################################################################
                     [1m Learning iteration 1099/1500 [0m                     

                       Computation: 45883 steps/s (collection: 2.023s, learning 0.119s)
             Mean action noise std: 3.66
          Mean value_function loss: 100.7694
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 82.0202
                       Mean reward: 632.33
               Mean episode length: 226.31
    Episode_Reward/reaching_object: 1.6554
    Episode_Reward/rotating_object: 129.8278
        Episode_Reward/action_rate: -0.0926
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 2.14s
                      Time elapsed: 00:43:22
                               ETA: 00:15:48

################################################################################
                     [1m Learning iteration 1100/1500 [0m                     

                       Computation: 40585 steps/s (collection: 2.228s, learning 0.194s)
             Mean action noise std: 3.66
          Mean value_function loss: 85.0246
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 82.0347
                       Mean reward: 681.23
               Mean episode length: 234.70
    Episode_Reward/reaching_object: 1.6439
    Episode_Reward/rotating_object: 125.1569
        Episode_Reward/action_rate: -0.0923
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 2.42s
                      Time elapsed: 00:43:24
                               ETA: 00:15:46

################################################################################
                     [1m Learning iteration 1101/1500 [0m                     

                       Computation: 44517 steps/s (collection: 2.099s, learning 0.109s)
             Mean action noise std: 3.66
          Mean value_function loss: 88.3718
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 82.0547
                       Mean reward: 663.99
               Mean episode length: 233.74
    Episode_Reward/reaching_object: 1.6422
    Episode_Reward/rotating_object: 125.8292
        Episode_Reward/action_rate: -0.0928
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 2.21s
                      Time elapsed: 00:43:27
                               ETA: 00:15:43

################################################################################
                     [1m Learning iteration 1102/1500 [0m                     

                       Computation: 46119 steps/s (collection: 2.036s, learning 0.095s)
             Mean action noise std: 3.67
          Mean value_function loss: 85.2519
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 82.0763
                       Mean reward: 653.97
               Mean episode length: 234.18
    Episode_Reward/reaching_object: 1.6746
    Episode_Reward/rotating_object: 128.8994
        Episode_Reward/action_rate: -0.0946
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 2.13s
                      Time elapsed: 00:43:29
                               ETA: 00:15:41

################################################################################
                     [1m Learning iteration 1103/1500 [0m                     

                       Computation: 45922 steps/s (collection: 2.049s, learning 0.092s)
             Mean action noise std: 3.67
          Mean value_function loss: 88.9071
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 82.0958
                       Mean reward: 643.35
               Mean episode length: 222.88
    Episode_Reward/reaching_object: 1.6529
    Episode_Reward/rotating_object: 129.6077
        Episode_Reward/action_rate: -0.0932
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 2.14s
                      Time elapsed: 00:43:31
                               ETA: 00:15:39

################################################################################
                     [1m Learning iteration 1104/1500 [0m                     

                       Computation: 45618 steps/s (collection: 2.036s, learning 0.119s)
             Mean action noise std: 3.67
          Mean value_function loss: 88.8614
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 82.1111
                       Mean reward: 683.29
               Mean episode length: 229.01
    Episode_Reward/reaching_object: 1.6589
    Episode_Reward/rotating_object: 133.1472
        Episode_Reward/action_rate: -0.0939
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 2.15s
                      Time elapsed: 00:43:33
                               ETA: 00:15:36

################################################################################
                     [1m Learning iteration 1105/1500 [0m                     

                       Computation: 43933 steps/s (collection: 2.142s, learning 0.096s)
             Mean action noise std: 3.67
          Mean value_function loss: 82.8749
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 82.1335
                       Mean reward: 689.87
               Mean episode length: 233.75
    Episode_Reward/reaching_object: 1.6396
    Episode_Reward/rotating_object: 129.5341
        Episode_Reward/action_rate: -0.0933
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 2.24s
                      Time elapsed: 00:43:35
                               ETA: 00:15:34

################################################################################
                     [1m Learning iteration 1106/1500 [0m                     

                       Computation: 44731 steps/s (collection: 2.038s, learning 0.160s)
             Mean action noise std: 3.67
          Mean value_function loss: 83.0785
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 82.1505
                       Mean reward: 638.66
               Mean episode length: 232.25
    Episode_Reward/reaching_object: 1.6787
    Episode_Reward/rotating_object: 133.6904
        Episode_Reward/action_rate: -0.0956
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 2.20s
                      Time elapsed: 00:43:38
                               ETA: 00:15:31

################################################################################
                     [1m Learning iteration 1107/1500 [0m                     

                       Computation: 45644 steps/s (collection: 2.025s, learning 0.129s)
             Mean action noise std: 3.68
          Mean value_function loss: 81.0515
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 82.1696
                       Mean reward: 641.86
               Mean episode length: 235.47
    Episode_Reward/reaching_object: 1.6426
    Episode_Reward/rotating_object: 129.3742
        Episode_Reward/action_rate: -0.0945
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 2.15s
                      Time elapsed: 00:43:40
                               ETA: 00:15:29

################################################################################
                     [1m Learning iteration 1108/1500 [0m                     

                       Computation: 46658 steps/s (collection: 1.983s, learning 0.124s)
             Mean action noise std: 3.68
          Mean value_function loss: 80.8550
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 82.1958
                       Mean reward: 646.27
               Mean episode length: 226.31
    Episode_Reward/reaching_object: 1.6426
    Episode_Reward/rotating_object: 129.5136
        Episode_Reward/action_rate: -0.0942
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 2.11s
                      Time elapsed: 00:43:42
                               ETA: 00:15:26

################################################################################
                     [1m Learning iteration 1109/1500 [0m                     

                       Computation: 45454 steps/s (collection: 2.043s, learning 0.120s)
             Mean action noise std: 3.68
          Mean value_function loss: 90.6006
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 82.2183
                       Mean reward: 662.35
               Mean episode length: 233.16
    Episode_Reward/reaching_object: 1.6516
    Episode_Reward/rotating_object: 131.1569
        Episode_Reward/action_rate: -0.0953
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 2.16s
                      Time elapsed: 00:43:44
                               ETA: 00:15:24

################################################################################
                     [1m Learning iteration 1110/1500 [0m                     

                       Computation: 45894 steps/s (collection: 2.037s, learning 0.105s)
             Mean action noise std: 3.69
          Mean value_function loss: 82.3561
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 82.2444
                       Mean reward: 705.63
               Mean episode length: 241.93
    Episode_Reward/reaching_object: 1.6536
    Episode_Reward/rotating_object: 131.8236
        Episode_Reward/action_rate: -0.0951
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 2.14s
                      Time elapsed: 00:43:46
                               ETA: 00:15:22

################################################################################
                     [1m Learning iteration 1111/1500 [0m                     

                       Computation: 46684 steps/s (collection: 1.997s, learning 0.109s)
             Mean action noise std: 3.69
          Mean value_function loss: 85.3787
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 82.2711
                       Mean reward: 647.66
               Mean episode length: 232.90
    Episode_Reward/reaching_object: 1.6737
    Episode_Reward/rotating_object: 129.8412
        Episode_Reward/action_rate: -0.0962
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 2.11s
                      Time elapsed: 00:43:48
                               ETA: 00:15:19

################################################################################
                     [1m Learning iteration 1112/1500 [0m                     

                       Computation: 46451 steps/s (collection: 2.012s, learning 0.105s)
             Mean action noise std: 3.69
          Mean value_function loss: 79.0753
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 82.2844
                       Mean reward: 710.39
               Mean episode length: 240.97
    Episode_Reward/reaching_object: 1.6700
    Episode_Reward/rotating_object: 135.7218
        Episode_Reward/action_rate: -0.0963
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 2.12s
                      Time elapsed: 00:43:50
                               ETA: 00:15:17

################################################################################
                     [1m Learning iteration 1113/1500 [0m                     

                       Computation: 45313 steps/s (collection: 2.009s, learning 0.160s)
             Mean action noise std: 3.69
          Mean value_function loss: 93.4635
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 82.2985
                       Mean reward: 689.05
               Mean episode length: 235.98
    Episode_Reward/reaching_object: 1.6693
    Episode_Reward/rotating_object: 131.4367
        Episode_Reward/action_rate: -0.0967
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 2.17s
                      Time elapsed: 00:43:53
                               ETA: 00:15:14

################################################################################
                     [1m Learning iteration 1114/1500 [0m                     

                       Computation: 42168 steps/s (collection: 2.177s, learning 0.154s)
             Mean action noise std: 3.70
          Mean value_function loss: 108.6179
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 82.3120
                       Mean reward: 621.37
               Mean episode length: 222.71
    Episode_Reward/reaching_object: 1.6261
    Episode_Reward/rotating_object: 127.8570
        Episode_Reward/action_rate: -0.0944
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 2.33s
                      Time elapsed: 00:43:55
                               ETA: 00:15:12

################################################################################
                     [1m Learning iteration 1115/1500 [0m                     

                       Computation: 45690 steps/s (collection: 2.059s, learning 0.092s)
             Mean action noise std: 3.70
          Mean value_function loss: 94.6009
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 82.3359
                       Mean reward: 655.76
               Mean episode length: 225.75
    Episode_Reward/reaching_object: 1.6411
    Episode_Reward/rotating_object: 129.6200
        Episode_Reward/action_rate: -0.0953
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 2.15s
                      Time elapsed: 00:43:57
                               ETA: 00:15:09

################################################################################
                     [1m Learning iteration 1116/1500 [0m                     

                       Computation: 43596 steps/s (collection: 2.082s, learning 0.173s)
             Mean action noise std: 3.70
          Mean value_function loss: 89.2415
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 82.3629
                       Mean reward: 638.60
               Mean episode length: 226.14
    Episode_Reward/reaching_object: 1.6511
    Episode_Reward/rotating_object: 129.4625
        Episode_Reward/action_rate: -0.0959
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 2.25s
                      Time elapsed: 00:43:59
                               ETA: 00:15:07

################################################################################
                     [1m Learning iteration 1117/1500 [0m                     

                       Computation: 45599 steps/s (collection: 2.058s, learning 0.098s)
             Mean action noise std: 3.71
          Mean value_function loss: 93.3602
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 82.3850
                       Mean reward: 646.85
               Mean episode length: 226.87
    Episode_Reward/reaching_object: 1.6314
    Episode_Reward/rotating_object: 127.7550
        Episode_Reward/action_rate: -0.0948
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 2.16s
                      Time elapsed: 00:44:01
                               ETA: 00:15:05

################################################################################
                     [1m Learning iteration 1118/1500 [0m                     

                       Computation: 45324 steps/s (collection: 2.026s, learning 0.143s)
             Mean action noise std: 3.71
          Mean value_function loss: 93.6939
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 82.4073
                       Mean reward: 660.80
               Mean episode length: 232.96
    Episode_Reward/reaching_object: 1.6716
    Episode_Reward/rotating_object: 130.5072
        Episode_Reward/action_rate: -0.0968
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 2.17s
                      Time elapsed: 00:44:04
                               ETA: 00:15:02

################################################################################
                     [1m Learning iteration 1119/1500 [0m                     

                       Computation: 44607 steps/s (collection: 2.060s, learning 0.144s)
             Mean action noise std: 3.71
          Mean value_function loss: 108.7500
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 82.4328
                       Mean reward: 608.03
               Mean episode length: 226.74
    Episode_Reward/reaching_object: 1.6399
    Episode_Reward/rotating_object: 126.9116
        Episode_Reward/action_rate: -0.0953
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 2.20s
                      Time elapsed: 00:44:06
                               ETA: 00:15:00

################################################################################
                     [1m Learning iteration 1120/1500 [0m                     

                       Computation: 45903 steps/s (collection: 2.017s, learning 0.125s)
             Mean action noise std: 3.72
          Mean value_function loss: 113.5989
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 82.4517
                       Mean reward: 618.57
               Mean episode length: 228.24
    Episode_Reward/reaching_object: 1.6152
    Episode_Reward/rotating_object: 126.1275
        Episode_Reward/action_rate: -0.0945
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 2.14s
                      Time elapsed: 00:44:08
                               ETA: 00:14:57

################################################################################
                     [1m Learning iteration 1121/1500 [0m                     

                       Computation: 42763 steps/s (collection: 2.155s, learning 0.144s)
             Mean action noise std: 3.72
          Mean value_function loss: 102.3539
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 82.4716
                       Mean reward: 670.76
               Mean episode length: 231.83
    Episode_Reward/reaching_object: 1.6025
    Episode_Reward/rotating_object: 126.2264
        Episode_Reward/action_rate: -0.0935
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 2.30s
                      Time elapsed: 00:44:10
                               ETA: 00:14:55

################################################################################
                     [1m Learning iteration 1122/1500 [0m                     

                       Computation: 45395 steps/s (collection: 2.045s, learning 0.121s)
             Mean action noise std: 3.72
          Mean value_function loss: 99.6449
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 82.4917
                       Mean reward: 642.50
               Mean episode length: 228.12
    Episode_Reward/reaching_object: 1.6498
    Episode_Reward/rotating_object: 129.9987
        Episode_Reward/action_rate: -0.0964
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 2.17s
                      Time elapsed: 00:44:12
                               ETA: 00:14:52

################################################################################
                     [1m Learning iteration 1123/1500 [0m                     

                       Computation: 45765 steps/s (collection: 2.000s, learning 0.148s)
             Mean action noise std: 3.72
          Mean value_function loss: 89.4400
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 82.5044
                       Mean reward: 677.85
               Mean episode length: 232.83
    Episode_Reward/reaching_object: 1.6198
    Episode_Reward/rotating_object: 128.1965
        Episode_Reward/action_rate: -0.0949
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 2.15s
                      Time elapsed: 00:44:15
                               ETA: 00:14:50

################################################################################
                     [1m Learning iteration 1124/1500 [0m                     

                       Computation: 45757 steps/s (collection: 2.047s, learning 0.101s)
             Mean action noise std: 3.73
          Mean value_function loss: 85.6447
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 82.5162
                       Mean reward: 683.80
               Mean episode length: 239.61
    Episode_Reward/reaching_object: 1.6659
    Episode_Reward/rotating_object: 130.7856
        Episode_Reward/action_rate: -0.0975
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 2.15s
                      Time elapsed: 00:44:17
                               ETA: 00:14:48

################################################################################
                     [1m Learning iteration 1125/1500 [0m                     

                       Computation: 43568 steps/s (collection: 2.105s, learning 0.151s)
             Mean action noise std: 3.73
          Mean value_function loss: 86.3297
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 82.5377
                       Mean reward: 694.63
               Mean episode length: 238.36
    Episode_Reward/reaching_object: 1.6948
    Episode_Reward/rotating_object: 134.5123
        Episode_Reward/action_rate: -0.0991
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 2.26s
                      Time elapsed: 00:44:19
                               ETA: 00:14:45

################################################################################
                     [1m Learning iteration 1126/1500 [0m                     

                       Computation: 45591 steps/s (collection: 2.064s, learning 0.092s)
             Mean action noise std: 3.73
          Mean value_function loss: 98.3307
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 82.5597
                       Mean reward: 660.88
               Mean episode length: 231.03
    Episode_Reward/reaching_object: 1.6530
    Episode_Reward/rotating_object: 131.3007
        Episode_Reward/action_rate: -0.0971
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 2.16s
                      Time elapsed: 00:44:21
                               ETA: 00:14:43

################################################################################
                     [1m Learning iteration 1127/1500 [0m                     

                       Computation: 46037 steps/s (collection: 2.014s, learning 0.122s)
             Mean action noise std: 3.73
          Mean value_function loss: 98.7679
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 82.5750
                       Mean reward: 657.51
               Mean episode length: 225.20
    Episode_Reward/reaching_object: 1.6281
    Episode_Reward/rotating_object: 130.9166
        Episode_Reward/action_rate: -0.0960
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 2.14s
                      Time elapsed: 00:44:23
                               ETA: 00:14:40

################################################################################
                     [1m Learning iteration 1128/1500 [0m                     

                       Computation: 45735 steps/s (collection: 2.049s, learning 0.100s)
             Mean action noise std: 3.74
          Mean value_function loss: 82.3898
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 82.5928
                       Mean reward: 719.63
               Mean episode length: 246.15
    Episode_Reward/reaching_object: 1.6535
    Episode_Reward/rotating_object: 132.4772
        Episode_Reward/action_rate: -0.0974
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 2.15s
                      Time elapsed: 00:44:25
                               ETA: 00:14:38

################################################################################
                     [1m Learning iteration 1129/1500 [0m                     

                       Computation: 46202 steps/s (collection: 2.032s, learning 0.096s)
             Mean action noise std: 3.74
          Mean value_function loss: 96.1680
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 82.6039
                       Mean reward: 668.14
               Mean episode length: 230.49
    Episode_Reward/reaching_object: 1.6590
    Episode_Reward/rotating_object: 131.4692
        Episode_Reward/action_rate: -0.0981
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 2.13s
                      Time elapsed: 00:44:28
                               ETA: 00:14:35

################################################################################
                     [1m Learning iteration 1130/1500 [0m                     

                       Computation: 41254 steps/s (collection: 2.265s, learning 0.118s)
             Mean action noise std: 3.74
          Mean value_function loss: 88.3436
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 82.6199
                       Mean reward: 690.76
               Mean episode length: 233.41
    Episode_Reward/reaching_object: 1.6576
    Episode_Reward/rotating_object: 133.1107
        Episode_Reward/action_rate: -0.0984
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 2.38s
                      Time elapsed: 00:44:30
                               ETA: 00:14:33

################################################################################
                     [1m Learning iteration 1131/1500 [0m                     

                       Computation: 43795 steps/s (collection: 2.154s, learning 0.091s)
             Mean action noise std: 3.74
          Mean value_function loss: 85.6814
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 82.6426
                       Mean reward: 648.33
               Mean episode length: 231.13
    Episode_Reward/reaching_object: 1.6381
    Episode_Reward/rotating_object: 128.6623
        Episode_Reward/action_rate: -0.0975
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 2.24s
                      Time elapsed: 00:44:32
                               ETA: 00:14:31

################################################################################
                     [1m Learning iteration 1132/1500 [0m                     

                       Computation: 46187 steps/s (collection: 2.037s, learning 0.091s)
             Mean action noise std: 3.75
          Mean value_function loss: 80.1874
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 82.6560
                       Mean reward: 691.22
               Mean episode length: 236.40
    Episode_Reward/reaching_object: 1.6605
    Episode_Reward/rotating_object: 133.1049
        Episode_Reward/action_rate: -0.0988
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 2.13s
                      Time elapsed: 00:44:34
                               ETA: 00:14:28

################################################################################
                     [1m Learning iteration 1133/1500 [0m                     

                       Computation: 47266 steps/s (collection: 1.987s, learning 0.093s)
             Mean action noise std: 3.75
          Mean value_function loss: 94.2486
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 82.6750
                       Mean reward: 684.64
               Mean episode length: 239.01
    Episode_Reward/reaching_object: 1.6504
    Episode_Reward/rotating_object: 128.3411
        Episode_Reward/action_rate: -0.0980
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 2.08s
                      Time elapsed: 00:44:36
                               ETA: 00:14:26

################################################################################
                     [1m Learning iteration 1134/1500 [0m                     

                       Computation: 46702 steps/s (collection: 2.015s, learning 0.090s)
             Mean action noise std: 3.75
          Mean value_function loss: 85.7743
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 82.6884
                       Mean reward: 661.37
               Mean episode length: 234.21
    Episode_Reward/reaching_object: 1.6585
    Episode_Reward/rotating_object: 131.8735
        Episode_Reward/action_rate: -0.0986
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 2.10s
                      Time elapsed: 00:44:38
                               ETA: 00:14:23

################################################################################
                     [1m Learning iteration 1135/1500 [0m                     

                       Computation: 46249 steps/s (collection: 2.029s, learning 0.097s)
             Mean action noise std: 3.75
          Mean value_function loss: 84.5111
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 82.6984
                       Mean reward: 644.65
               Mean episode length: 223.69
    Episode_Reward/reaching_object: 1.6397
    Episode_Reward/rotating_object: 129.9746
        Episode_Reward/action_rate: -0.0980
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 2.13s
                      Time elapsed: 00:44:41
                               ETA: 00:14:21

################################################################################
                     [1m Learning iteration 1136/1500 [0m                     

                       Computation: 44937 steps/s (collection: 2.009s, learning 0.179s)
             Mean action noise std: 3.76
          Mean value_function loss: 93.9953
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 82.7188
                       Mean reward: 676.93
               Mean episode length: 229.84
    Episode_Reward/reaching_object: 1.6753
    Episode_Reward/rotating_object: 134.1195
        Episode_Reward/action_rate: -0.0999
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 2.19s
                      Time elapsed: 00:44:43
                               ETA: 00:14:19

################################################################################
                     [1m Learning iteration 1137/1500 [0m                     

                       Computation: 45490 steps/s (collection: 2.023s, learning 0.138s)
             Mean action noise std: 3.76
          Mean value_function loss: 84.1683
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 82.7448
                       Mean reward: 666.79
               Mean episode length: 226.99
    Episode_Reward/reaching_object: 1.6194
    Episode_Reward/rotating_object: 129.3671
        Episode_Reward/action_rate: -0.0972
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 2.16s
                      Time elapsed: 00:44:45
                               ETA: 00:14:16

################################################################################
                     [1m Learning iteration 1138/1500 [0m                     

                       Computation: 46722 steps/s (collection: 2.004s, learning 0.100s)
             Mean action noise std: 3.76
          Mean value_function loss: 89.6639
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 82.7676
                       Mean reward: 671.74
               Mean episode length: 232.37
    Episode_Reward/reaching_object: 1.6580
    Episode_Reward/rotating_object: 132.5791
        Episode_Reward/action_rate: -0.0997
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 2.10s
                      Time elapsed: 00:44:47
                               ETA: 00:14:14

################################################################################
                     [1m Learning iteration 1139/1500 [0m                     

                       Computation: 45490 steps/s (collection: 2.034s, learning 0.127s)
             Mean action noise std: 3.76
          Mean value_function loss: 94.8288
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 82.7920
                       Mean reward: 712.97
               Mean episode length: 240.51
    Episode_Reward/reaching_object: 1.6569
    Episode_Reward/rotating_object: 130.7797
        Episode_Reward/action_rate: -0.0996
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 2.16s
                      Time elapsed: 00:44:49
                               ETA: 00:14:11

################################################################################
                     [1m Learning iteration 1140/1500 [0m                     

                       Computation: 46175 steps/s (collection: 2.014s, learning 0.115s)
             Mean action noise std: 3.77
          Mean value_function loss: 104.2912
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 82.8204
                       Mean reward: 592.60
               Mean episode length: 218.88
    Episode_Reward/reaching_object: 1.5857
    Episode_Reward/rotating_object: 124.1764
        Episode_Reward/action_rate: -0.0958
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 2.13s
                      Time elapsed: 00:44:51
                               ETA: 00:14:09

################################################################################
                     [1m Learning iteration 1141/1500 [0m                     

                       Computation: 43899 steps/s (collection: 2.092s, learning 0.147s)
             Mean action noise std: 3.77
          Mean value_function loss: 83.6031
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 82.8431
                       Mean reward: 641.77
               Mean episode length: 225.95
    Episode_Reward/reaching_object: 1.6533
    Episode_Reward/rotating_object: 129.2832
        Episode_Reward/action_rate: -0.1000
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 2.24s
                      Time elapsed: 00:44:54
                               ETA: 00:14:06

################################################################################
                     [1m Learning iteration 1142/1500 [0m                     

                       Computation: 42230 steps/s (collection: 2.179s, learning 0.149s)
             Mean action noise std: 3.77
          Mean value_function loss: 88.1294
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 82.8573
                       Mean reward: 608.24
               Mean episode length: 222.00
    Episode_Reward/reaching_object: 1.6254
    Episode_Reward/rotating_object: 127.4912
        Episode_Reward/action_rate: -0.0985
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 2.33s
                      Time elapsed: 00:44:56
                               ETA: 00:14:04

################################################################################
                     [1m Learning iteration 1143/1500 [0m                     

                       Computation: 44903 steps/s (collection: 2.091s, learning 0.099s)
             Mean action noise std: 3.77
          Mean value_function loss: 101.5649
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 82.8723
                       Mean reward: 664.95
               Mean episode length: 229.61
    Episode_Reward/reaching_object: 1.6404
    Episode_Reward/rotating_object: 129.4404
        Episode_Reward/action_rate: -0.0993
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 2.19s
                      Time elapsed: 00:44:58
                               ETA: 00:14:02

################################################################################
                     [1m Learning iteration 1144/1500 [0m                     

                       Computation: 46976 steps/s (collection: 1.992s, learning 0.100s)
             Mean action noise std: 3.78
          Mean value_function loss: 90.5287
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 82.8892
                       Mean reward: 634.33
               Mean episode length: 223.86
    Episode_Reward/reaching_object: 1.5829
    Episode_Reward/rotating_object: 124.3425
        Episode_Reward/action_rate: -0.0964
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 2.09s
                      Time elapsed: 00:45:00
                               ETA: 00:13:59

################################################################################
                     [1m Learning iteration 1145/1500 [0m                     

                       Computation: 48049 steps/s (collection: 1.957s, learning 0.089s)
             Mean action noise std: 3.78
          Mean value_function loss: 89.0240
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 82.8984
                       Mean reward: 656.10
               Mean episode length: 230.56
    Episode_Reward/reaching_object: 1.6418
    Episode_Reward/rotating_object: 130.6028
        Episode_Reward/action_rate: -0.0996
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 2.05s
                      Time elapsed: 00:45:02
                               ETA: 00:13:57

################################################################################
                     [1m Learning iteration 1146/1500 [0m                     

                       Computation: 46619 steps/s (collection: 2.001s, learning 0.107s)
             Mean action noise std: 3.78
          Mean value_function loss: 92.6867
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 82.9075
                       Mean reward: 646.27
               Mean episode length: 223.17
    Episode_Reward/reaching_object: 1.6169
    Episode_Reward/rotating_object: 128.5839
        Episode_Reward/action_rate: -0.0985
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 2.11s
                      Time elapsed: 00:45:04
                               ETA: 00:13:54

################################################################################
                     [1m Learning iteration 1147/1500 [0m                     

                       Computation: 46663 steps/s (collection: 1.983s, learning 0.124s)
             Mean action noise std: 3.78
          Mean value_function loss: 81.9040
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 82.9183
                       Mean reward: 696.96
               Mean episode length: 239.93
    Episode_Reward/reaching_object: 1.6711
    Episode_Reward/rotating_object: 134.2644
        Episode_Reward/action_rate: -0.1014
          Episode_Reward/joint_vel: -0.0353
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 2.11s
                      Time elapsed: 00:45:06
                               ETA: 00:13:52

################################################################################
                     [1m Learning iteration 1148/1500 [0m                     

                       Computation: 44393 steps/s (collection: 2.078s, learning 0.137s)
             Mean action noise std: 3.79
          Mean value_function loss: 105.5303
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 82.9336
                       Mean reward: 655.31
               Mean episode length: 227.63
    Episode_Reward/reaching_object: 1.6333
    Episode_Reward/rotating_object: 129.0496
        Episode_Reward/action_rate: -0.0997
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 2.21s
                      Time elapsed: 00:45:09
                               ETA: 00:13:49

################################################################################
                     [1m Learning iteration 1149/1500 [0m                     

                       Computation: 45468 steps/s (collection: 2.056s, learning 0.106s)
             Mean action noise std: 3.79
          Mean value_function loss: 94.0848
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 82.9522
                       Mean reward: 648.94
               Mean episode length: 230.81
    Episode_Reward/reaching_object: 1.6082
    Episode_Reward/rotating_object: 128.4938
        Episode_Reward/action_rate: -0.0983
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 2.16s
                      Time elapsed: 00:45:11
                               ETA: 00:13:47

################################################################################
                     [1m Learning iteration 1150/1500 [0m                     

                       Computation: 46808 steps/s (collection: 2.004s, learning 0.096s)
             Mean action noise std: 3.79
          Mean value_function loss: 91.0147
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 82.9676
                       Mean reward: 691.04
               Mean episode length: 233.75
    Episode_Reward/reaching_object: 1.6585
    Episode_Reward/rotating_object: 133.3650
        Episode_Reward/action_rate: -0.1009
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 2.10s
                      Time elapsed: 00:45:13
                               ETA: 00:13:45

################################################################################
                     [1m Learning iteration 1151/1500 [0m                     

                       Computation: 46052 steps/s (collection: 2.044s, learning 0.091s)
             Mean action noise std: 3.79
          Mean value_function loss: 89.1652
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 82.9819
                       Mean reward: 651.10
               Mean episode length: 228.95
    Episode_Reward/reaching_object: 1.6461
    Episode_Reward/rotating_object: 131.5316
        Episode_Reward/action_rate: -0.1008
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 2.13s
                      Time elapsed: 00:45:15
                               ETA: 00:13:42

################################################################################
                     [1m Learning iteration 1152/1500 [0m                     

                       Computation: 47000 steps/s (collection: 1.998s, learning 0.094s)
             Mean action noise std: 3.79
          Mean value_function loss: 87.0469
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 82.9946
                       Mean reward: 691.20
               Mean episode length: 243.82
    Episode_Reward/reaching_object: 1.6432
    Episode_Reward/rotating_object: 132.0246
        Episode_Reward/action_rate: -0.1010
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 2.09s
                      Time elapsed: 00:45:17
                               ETA: 00:13:40

################################################################################
                     [1m Learning iteration 1153/1500 [0m                     

                       Computation: 44204 steps/s (collection: 2.102s, learning 0.122s)
             Mean action noise std: 3.79
          Mean value_function loss: 88.8704
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 83.0039
                       Mean reward: 672.17
               Mean episode length: 232.60
    Episode_Reward/reaching_object: 1.6521
    Episode_Reward/rotating_object: 130.8737
        Episode_Reward/action_rate: -0.1014
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 2.22s
                      Time elapsed: 00:45:19
                               ETA: 00:13:37

################################################################################
                     [1m Learning iteration 1154/1500 [0m                     

                       Computation: 47288 steps/s (collection: 1.980s, learning 0.099s)
             Mean action noise std: 3.80
          Mean value_function loss: 96.3614
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 83.0247
                       Mean reward: 619.89
               Mean episode length: 216.07
    Episode_Reward/reaching_object: 1.6399
    Episode_Reward/rotating_object: 131.1117
        Episode_Reward/action_rate: -0.1007
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 2.08s
                      Time elapsed: 00:45:21
                               ETA: 00:13:35

################################################################################
                     [1m Learning iteration 1155/1500 [0m                     

                       Computation: 45043 steps/s (collection: 2.049s, learning 0.133s)
             Mean action noise std: 3.80
          Mean value_function loss: 99.6701
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 83.0450
                       Mean reward: 673.40
               Mean episode length: 228.23
    Episode_Reward/reaching_object: 1.6600
    Episode_Reward/rotating_object: 133.9625
        Episode_Reward/action_rate: -0.1020
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 2.18s
                      Time elapsed: 00:45:24
                               ETA: 00:13:32

################################################################################
                     [1m Learning iteration 1156/1500 [0m                     

                       Computation: 45269 steps/s (collection: 2.027s, learning 0.144s)
             Mean action noise std: 3.80
          Mean value_function loss: 103.6276
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 83.0688
                       Mean reward: 713.21
               Mean episode length: 241.25
    Episode_Reward/reaching_object: 1.6444
    Episode_Reward/rotating_object: 133.4035
        Episode_Reward/action_rate: -0.1015
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 2.17s
                      Time elapsed: 00:45:26
                               ETA: 00:13:30

################################################################################
                     [1m Learning iteration 1157/1500 [0m                     

                       Computation: 46552 steps/s (collection: 2.017s, learning 0.095s)
             Mean action noise std: 3.81
          Mean value_function loss: 82.3114
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 83.0914
                       Mean reward: 650.75
               Mean episode length: 227.01
    Episode_Reward/reaching_object: 1.6293
    Episode_Reward/rotating_object: 128.9588
        Episode_Reward/action_rate: -0.1005
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 2.11s
                      Time elapsed: 00:45:28
                               ETA: 00:13:28

################################################################################
                     [1m Learning iteration 1158/1500 [0m                     

                       Computation: 46178 steps/s (collection: 2.038s, learning 0.091s)
             Mean action noise std: 3.81
          Mean value_function loss: 87.8517
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 83.1057
                       Mean reward: 665.12
               Mean episode length: 231.60
    Episode_Reward/reaching_object: 1.6464
    Episode_Reward/rotating_object: 129.3336
        Episode_Reward/action_rate: -0.1014
          Episode_Reward/joint_vel: -0.0353
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 2.13s
                      Time elapsed: 00:45:30
                               ETA: 00:13:25

################################################################################
                     [1m Learning iteration 1159/1500 [0m                     

                       Computation: 46122 steps/s (collection: 2.036s, learning 0.096s)
             Mean action noise std: 3.81
          Mean value_function loss: 87.0971
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 83.1295
                       Mean reward: 656.78
               Mean episode length: 234.22
    Episode_Reward/reaching_object: 1.6742
    Episode_Reward/rotating_object: 130.9938
        Episode_Reward/action_rate: -0.1032
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 2.13s
                      Time elapsed: 00:45:32
                               ETA: 00:13:23

################################################################################
                     [1m Learning iteration 1160/1500 [0m                     

                       Computation: 46730 steps/s (collection: 1.992s, learning 0.111s)
             Mean action noise std: 3.82
          Mean value_function loss: 92.3179
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 83.1575
                       Mean reward: 660.60
               Mean episode length: 228.81
    Episode_Reward/reaching_object: 1.6456
    Episode_Reward/rotating_object: 132.6623
        Episode_Reward/action_rate: -0.1017
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 2.10s
                      Time elapsed: 00:45:34
                               ETA: 00:13:20

################################################################################
                     [1m Learning iteration 1161/1500 [0m                     

                       Computation: 45770 steps/s (collection: 2.028s, learning 0.120s)
             Mean action noise std: 3.82
          Mean value_function loss: 75.3618
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 83.1771
                       Mean reward: 700.45
               Mean episode length: 234.47
    Episode_Reward/reaching_object: 1.6582
    Episode_Reward/rotating_object: 133.9974
        Episode_Reward/action_rate: -0.1024
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 2.15s
                      Time elapsed: 00:45:36
                               ETA: 00:13:18

################################################################################
                     [1m Learning iteration 1162/1500 [0m                     

                       Computation: 44840 steps/s (collection: 2.098s, learning 0.095s)
             Mean action noise std: 3.82
          Mean value_function loss: 70.3149
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 83.1892
                       Mean reward: 717.26
               Mean episode length: 237.73
    Episode_Reward/reaching_object: 1.7122
    Episode_Reward/rotating_object: 137.2182
        Episode_Reward/action_rate: -0.1061
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 2.19s
                      Time elapsed: 00:45:39
                               ETA: 00:13:16

################################################################################
                     [1m Learning iteration 1163/1500 [0m                     

                       Computation: 46709 steps/s (collection: 1.987s, learning 0.118s)
             Mean action noise std: 3.82
          Mean value_function loss: 71.5662
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 83.2109
                       Mean reward: 658.87
               Mean episode length: 232.01
    Episode_Reward/reaching_object: 1.6319
    Episode_Reward/rotating_object: 131.7429
        Episode_Reward/action_rate: -0.1019
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 2.10s
                      Time elapsed: 00:45:41
                               ETA: 00:13:13

################################################################################
                     [1m Learning iteration 1164/1500 [0m                     

                       Computation: 46267 steps/s (collection: 2.020s, learning 0.105s)
             Mean action noise std: 3.83
          Mean value_function loss: 93.2575
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 83.2311
                       Mean reward: 639.56
               Mean episode length: 219.60
    Episode_Reward/reaching_object: 1.6343
    Episode_Reward/rotating_object: 131.4201
        Episode_Reward/action_rate: -0.1019
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 2.12s
                      Time elapsed: 00:45:43
                               ETA: 00:13:11

################################################################################
                     [1m Learning iteration 1165/1500 [0m                     

                       Computation: 44990 steps/s (collection: 2.066s, learning 0.119s)
             Mean action noise std: 3.83
          Mean value_function loss: 98.9004
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 83.2428
                       Mean reward: 636.34
               Mean episode length: 219.50
    Episode_Reward/reaching_object: 1.6536
    Episode_Reward/rotating_object: 133.1429
        Episode_Reward/action_rate: -0.1034
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 2.18s
                      Time elapsed: 00:45:45
                               ETA: 00:13:08

################################################################################
                     [1m Learning iteration 1166/1500 [0m                     

                       Computation: 45373 steps/s (collection: 2.046s, learning 0.121s)
             Mean action noise std: 3.83
          Mean value_function loss: 103.0330
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 83.2588
                       Mean reward: 658.49
               Mean episode length: 227.50
    Episode_Reward/reaching_object: 1.6051
    Episode_Reward/rotating_object: 130.3275
        Episode_Reward/action_rate: -0.1009
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 2.17s
                      Time elapsed: 00:45:47
                               ETA: 00:13:06

################################################################################
                     [1m Learning iteration 1167/1500 [0m                     

                       Computation: 47252 steps/s (collection: 1.985s, learning 0.096s)
             Mean action noise std: 3.83
          Mean value_function loss: 91.6230
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 83.2841
                       Mean reward: 690.95
               Mean episode length: 232.58
    Episode_Reward/reaching_object: 1.6048
    Episode_Reward/rotating_object: 128.3341
        Episode_Reward/action_rate: -0.1011
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 2.08s
                      Time elapsed: 00:45:49
                               ETA: 00:13:03

################################################################################
                     [1m Learning iteration 1168/1500 [0m                     

                       Computation: 46157 steps/s (collection: 2.037s, learning 0.093s)
             Mean action noise std: 3.84
          Mean value_function loss: 77.4671
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 83.3129
                       Mean reward: 689.43
               Mean episode length: 232.54
    Episode_Reward/reaching_object: 1.6635
    Episode_Reward/rotating_object: 134.2681
        Episode_Reward/action_rate: -0.1046
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 2.13s
                      Time elapsed: 00:45:51
                               ETA: 00:13:01

################################################################################
                     [1m Learning iteration 1169/1500 [0m                     

                       Computation: 45160 steps/s (collection: 2.041s, learning 0.136s)
             Mean action noise std: 3.84
          Mean value_function loss: 95.9534
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 83.3341
                       Mean reward: 656.88
               Mean episode length: 230.78
    Episode_Reward/reaching_object: 1.6277
    Episode_Reward/rotating_object: 128.9336
        Episode_Reward/action_rate: -0.1029
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 2.18s
                      Time elapsed: 00:45:54
                               ETA: 00:12:59

################################################################################
                     [1m Learning iteration 1170/1500 [0m                     

                       Computation: 47407 steps/s (collection: 1.962s, learning 0.112s)
             Mean action noise std: 3.84
          Mean value_function loss: 88.1814
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 83.3560
                       Mean reward: 669.91
               Mean episode length: 227.69
    Episode_Reward/reaching_object: 1.6205
    Episode_Reward/rotating_object: 131.6203
        Episode_Reward/action_rate: -0.1020
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 2.07s
                      Time elapsed: 00:45:56
                               ETA: 00:12:56

################################################################################
                     [1m Learning iteration 1171/1500 [0m                     

                       Computation: 44949 steps/s (collection: 2.070s, learning 0.117s)
             Mean action noise std: 3.85
          Mean value_function loss: 83.2949
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 83.3850
                       Mean reward: 644.59
               Mean episode length: 223.03
    Episode_Reward/reaching_object: 1.6798
    Episode_Reward/rotating_object: 136.5632
        Episode_Reward/action_rate: -0.1056
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 2.19s
                      Time elapsed: 00:45:58
                               ETA: 00:12:54

################################################################################
                     [1m Learning iteration 1172/1500 [0m                     

                       Computation: 47219 steps/s (collection: 1.988s, learning 0.093s)
             Mean action noise std: 3.85
          Mean value_function loss: 89.3144
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 83.4052
                       Mean reward: 660.57
               Mean episode length: 228.48
    Episode_Reward/reaching_object: 1.6116
    Episode_Reward/rotating_object: 128.4973
        Episode_Reward/action_rate: -0.1018
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 2.08s
                      Time elapsed: 00:46:00
                               ETA: 00:12:51

################################################################################
                     [1m Learning iteration 1173/1500 [0m                     

                       Computation: 45996 steps/s (collection: 1.998s, learning 0.140s)
             Mean action noise std: 3.85
          Mean value_function loss: 90.4584
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 83.4236
                       Mean reward: 657.04
               Mean episode length: 228.38
    Episode_Reward/reaching_object: 1.6333
    Episode_Reward/rotating_object: 131.4634
        Episode_Reward/action_rate: -0.1035
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 2.14s
                      Time elapsed: 00:46:02
                               ETA: 00:12:49

################################################################################
                     [1m Learning iteration 1174/1500 [0m                     

                       Computation: 46395 steps/s (collection: 1.988s, learning 0.131s)
             Mean action noise std: 3.85
          Mean value_function loss: 91.9840
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 83.4384
                       Mean reward: 673.23
               Mean episode length: 237.17
    Episode_Reward/reaching_object: 1.6465
    Episode_Reward/rotating_object: 132.2145
        Episode_Reward/action_rate: -0.1042
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 2.12s
                      Time elapsed: 00:46:04
                               ETA: 00:12:47

################################################################################
                     [1m Learning iteration 1175/1500 [0m                     

                       Computation: 47186 steps/s (collection: 1.984s, learning 0.099s)
             Mean action noise std: 3.86
          Mean value_function loss: 93.7804
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 83.4583
                       Mean reward: 657.20
               Mean episode length: 237.52
    Episode_Reward/reaching_object: 1.6798
    Episode_Reward/rotating_object: 132.4789
        Episode_Reward/action_rate: -0.1063
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 2.08s
                      Time elapsed: 00:46:06
                               ETA: 00:12:44

################################################################################
                     [1m Learning iteration 1176/1500 [0m                     

                       Computation: 47325 steps/s (collection: 1.978s, learning 0.099s)
             Mean action noise std: 3.86
          Mean value_function loss: 86.0342
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 83.4707
                       Mean reward: 718.38
               Mean episode length: 240.67
    Episode_Reward/reaching_object: 1.7063
    Episode_Reward/rotating_object: 139.2904
        Episode_Reward/action_rate: -0.1076
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 2.08s
                      Time elapsed: 00:46:08
                               ETA: 00:12:42

################################################################################
                     [1m Learning iteration 1177/1500 [0m                     

                       Computation: 47084 steps/s (collection: 1.993s, learning 0.095s)
             Mean action noise std: 3.86
          Mean value_function loss: 100.5112
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 83.4888
                       Mean reward: 631.22
               Mean episode length: 220.93
    Episode_Reward/reaching_object: 1.6175
    Episode_Reward/rotating_object: 129.7273
        Episode_Reward/action_rate: -0.1028
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 2.09s
                      Time elapsed: 00:46:10
                               ETA: 00:12:39

################################################################################
                     [1m Learning iteration 1178/1500 [0m                     

                       Computation: 43326 steps/s (collection: 2.115s, learning 0.154s)
             Mean action noise std: 3.86
          Mean value_function loss: 85.5707
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 83.5097
                       Mean reward: 631.31
               Mean episode length: 228.92
    Episode_Reward/reaching_object: 1.6516
    Episode_Reward/rotating_object: 129.5768
        Episode_Reward/action_rate: -0.1050
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 2.27s
                      Time elapsed: 00:46:13
                               ETA: 00:12:37

################################################################################
                     [1m Learning iteration 1179/1500 [0m                     

                       Computation: 42494 steps/s (collection: 2.170s, learning 0.144s)
             Mean action noise std: 3.87
          Mean value_function loss: 87.7958
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 83.5291
                       Mean reward: 654.53
               Mean episode length: 232.52
    Episode_Reward/reaching_object: 1.6663
    Episode_Reward/rotating_object: 133.6296
        Episode_Reward/action_rate: -0.1060
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 2.31s
                      Time elapsed: 00:46:15
                               ETA: 00:12:35

################################################################################
                     [1m Learning iteration 1180/1500 [0m                     

                       Computation: 43050 steps/s (collection: 2.111s, learning 0.172s)
             Mean action noise std: 3.87
          Mean value_function loss: 102.9825
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 83.5460
                       Mean reward: 668.53
               Mean episode length: 232.43
    Episode_Reward/reaching_object: 1.6242
    Episode_Reward/rotating_object: 129.2557
        Episode_Reward/action_rate: -0.1041
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 2.28s
                      Time elapsed: 00:46:17
                               ETA: 00:12:32

################################################################################
                     [1m Learning iteration 1181/1500 [0m                     

                       Computation: 44672 steps/s (collection: 2.082s, learning 0.119s)
             Mean action noise std: 3.87
          Mean value_function loss: 95.6455
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 83.5680
                       Mean reward: 633.72
               Mean episode length: 225.86
    Episode_Reward/reaching_object: 1.6388
    Episode_Reward/rotating_object: 130.7065
        Episode_Reward/action_rate: -0.1051
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 2.20s
                      Time elapsed: 00:46:19
                               ETA: 00:12:30

################################################################################
                     [1m Learning iteration 1182/1500 [0m                     

                       Computation: 44702 steps/s (collection: 2.078s, learning 0.121s)
             Mean action noise std: 3.87
          Mean value_function loss: 82.6152
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 83.5884
                       Mean reward: 681.84
               Mean episode length: 236.57
    Episode_Reward/reaching_object: 1.6391
    Episode_Reward/rotating_object: 132.0491
        Episode_Reward/action_rate: -0.1050
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 2.20s
                      Time elapsed: 00:46:22
                               ETA: 00:12:27

################################################################################
                     [1m Learning iteration 1183/1500 [0m                     

                       Computation: 45464 steps/s (collection: 2.058s, learning 0.104s)
             Mean action noise std: 3.88
          Mean value_function loss: 84.9416
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 83.6043
                       Mean reward: 725.68
               Mean episode length: 242.04
    Episode_Reward/reaching_object: 1.6701
    Episode_Reward/rotating_object: 135.0633
        Episode_Reward/action_rate: -0.1072
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 2.16s
                      Time elapsed: 00:46:24
                               ETA: 00:12:25

################################################################################
                     [1m Learning iteration 1184/1500 [0m                     

                       Computation: 47222 steps/s (collection: 1.976s, learning 0.106s)
             Mean action noise std: 3.88
          Mean value_function loss: 87.4015
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 83.6180
                       Mean reward: 669.75
               Mean episode length: 235.45
    Episode_Reward/reaching_object: 1.6193
    Episode_Reward/rotating_object: 128.6911
        Episode_Reward/action_rate: -0.1045
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 2.08s
                      Time elapsed: 00:46:26
                               ETA: 00:12:23

################################################################################
                     [1m Learning iteration 1185/1500 [0m                     

                       Computation: 45010 steps/s (collection: 2.024s, learning 0.160s)
             Mean action noise std: 3.88
          Mean value_function loss: 90.0977
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 83.6302
                       Mean reward: 651.98
               Mean episode length: 233.55
    Episode_Reward/reaching_object: 1.6148
    Episode_Reward/rotating_object: 127.3343
        Episode_Reward/action_rate: -0.1042
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 2.18s
                      Time elapsed: 00:46:28
                               ETA: 00:12:20

################################################################################
                     [1m Learning iteration 1186/1500 [0m                     

                       Computation: 45625 steps/s (collection: 1.999s, learning 0.155s)
             Mean action noise std: 3.88
          Mean value_function loss: 99.7899
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 83.6490
                       Mean reward: 627.66
               Mean episode length: 227.04
    Episode_Reward/reaching_object: 1.6030
    Episode_Reward/rotating_object: 127.6277
        Episode_Reward/action_rate: -0.1034
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 2.15s
                      Time elapsed: 00:46:30
                               ETA: 00:12:18

################################################################################
                     [1m Learning iteration 1187/1500 [0m                     

                       Computation: 46192 steps/s (collection: 2.037s, learning 0.091s)
             Mean action noise std: 3.89
          Mean value_function loss: 92.3470
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 83.6695
                       Mean reward: 667.20
               Mean episode length: 228.94
    Episode_Reward/reaching_object: 1.6530
    Episode_Reward/rotating_object: 135.1578
        Episode_Reward/action_rate: -0.1066
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 2.13s
                      Time elapsed: 00:46:32
                               ETA: 00:12:15

################################################################################
                     [1m Learning iteration 1188/1500 [0m                     

                       Computation: 46744 steps/s (collection: 2.006s, learning 0.097s)
             Mean action noise std: 3.89
          Mean value_function loss: 92.8598
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 83.6869
                       Mean reward: 681.50
               Mean episode length: 234.35
    Episode_Reward/reaching_object: 1.6375
    Episode_Reward/rotating_object: 131.3892
        Episode_Reward/action_rate: -0.1055
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 2.10s
                      Time elapsed: 00:46:35
                               ETA: 00:12:13

################################################################################
                     [1m Learning iteration 1189/1500 [0m                     

                       Computation: 46515 steps/s (collection: 2.019s, learning 0.095s)
             Mean action noise std: 3.89
          Mean value_function loss: 93.6334
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 83.7108
                       Mean reward: 662.67
               Mean episode length: 233.60
    Episode_Reward/reaching_object: 1.6506
    Episode_Reward/rotating_object: 130.8758
        Episode_Reward/action_rate: -0.1067
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 2.11s
                      Time elapsed: 00:46:37
                               ETA: 00:12:11

################################################################################
                     [1m Learning iteration 1190/1500 [0m                     

                       Computation: 46584 steps/s (collection: 2.017s, learning 0.093s)
             Mean action noise std: 3.89
          Mean value_function loss: 99.2600
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 83.7297
                       Mean reward: 640.96
               Mean episode length: 225.30
    Episode_Reward/reaching_object: 1.6097
    Episode_Reward/rotating_object: 127.6258
        Episode_Reward/action_rate: -0.1040
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 2.11s
                      Time elapsed: 00:46:39
                               ETA: 00:12:08

################################################################################
                     [1m Learning iteration 1191/1500 [0m                     

                       Computation: 45911 steps/s (collection: 2.029s, learning 0.112s)
             Mean action noise std: 3.90
          Mean value_function loss: 89.6732
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 83.7421
                       Mean reward: 652.76
               Mean episode length: 226.32
    Episode_Reward/reaching_object: 1.6184
    Episode_Reward/rotating_object: 130.1258
        Episode_Reward/action_rate: -0.1045
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 2.14s
                      Time elapsed: 00:46:41
                               ETA: 00:12:06

################################################################################
                     [1m Learning iteration 1192/1500 [0m                     

                       Computation: 44069 steps/s (collection: 2.102s, learning 0.129s)
             Mean action noise std: 3.90
          Mean value_function loss: 82.1151
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 83.7603
                       Mean reward: 673.79
               Mean episode length: 234.76
    Episode_Reward/reaching_object: 1.6657
    Episode_Reward/rotating_object: 133.3091
        Episode_Reward/action_rate: -0.1076
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 2.23s
                      Time elapsed: 00:46:43
                               ETA: 00:12:03

################################################################################
                     [1m Learning iteration 1193/1500 [0m                     

                       Computation: 43910 steps/s (collection: 2.090s, learning 0.149s)
             Mean action noise std: 3.90
          Mean value_function loss: 91.0370
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 83.7669
                       Mean reward: 698.23
               Mean episode length: 237.25
    Episode_Reward/reaching_object: 1.6677
    Episode_Reward/rotating_object: 135.0261
        Episode_Reward/action_rate: -0.1077
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 2.24s
                      Time elapsed: 00:46:45
                               ETA: 00:12:01

################################################################################
                     [1m Learning iteration 1194/1500 [0m                     

                       Computation: 42916 steps/s (collection: 2.161s, learning 0.129s)
             Mean action noise std: 3.90
          Mean value_function loss: 106.2905
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 83.7787
                       Mean reward: 667.84
               Mean episode length: 230.73
    Episode_Reward/reaching_object: 1.6548
    Episode_Reward/rotating_object: 133.1169
        Episode_Reward/action_rate: -0.1071
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 2.29s
                      Time elapsed: 00:46:48
                               ETA: 00:11:59

################################################################################
                     [1m Learning iteration 1195/1500 [0m                     

                       Computation: 46673 steps/s (collection: 2.013s, learning 0.094s)
             Mean action noise std: 3.90
          Mean value_function loss: 72.2918
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 83.7942
                       Mean reward: 651.34
               Mean episode length: 225.72
    Episode_Reward/reaching_object: 1.6841
    Episode_Reward/rotating_object: 135.7055
        Episode_Reward/action_rate: -0.1089
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 2.11s
                      Time elapsed: 00:46:50
                               ETA: 00:11:56

################################################################################
                     [1m Learning iteration 1196/1500 [0m                     

                       Computation: 46170 steps/s (collection: 2.026s, learning 0.103s)
             Mean action noise std: 3.90
          Mean value_function loss: 86.5186
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 83.7997
                       Mean reward: 631.38
               Mean episode length: 220.60
    Episode_Reward/reaching_object: 1.6600
    Episode_Reward/rotating_object: 133.3574
        Episode_Reward/action_rate: -0.1079
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 2.13s
                      Time elapsed: 00:46:52
                               ETA: 00:11:54

################################################################################
                     [1m Learning iteration 1197/1500 [0m                     

                       Computation: 45511 steps/s (collection: 2.065s, learning 0.095s)
             Mean action noise std: 3.91
          Mean value_function loss: 101.7035
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 83.8143
                       Mean reward: 658.19
               Mean episode length: 226.40
    Episode_Reward/reaching_object: 1.6609
    Episode_Reward/rotating_object: 134.1566
        Episode_Reward/action_rate: -0.1077
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 2.16s
                      Time elapsed: 00:46:54
                               ETA: 00:11:51

################################################################################
                     [1m Learning iteration 1198/1500 [0m                     

                       Computation: 46160 steps/s (collection: 2.029s, learning 0.101s)
             Mean action noise std: 3.91
          Mean value_function loss: 109.3005
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 83.8287
                       Mean reward: 659.82
               Mean episode length: 232.37
    Episode_Reward/reaching_object: 1.6090
    Episode_Reward/rotating_object: 128.8625
        Episode_Reward/action_rate: -0.1049
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 2.13s
                      Time elapsed: 00:46:56
                               ETA: 00:11:49

################################################################################
                     [1m Learning iteration 1199/1500 [0m                     

                       Computation: 45881 steps/s (collection: 2.041s, learning 0.102s)
             Mean action noise std: 3.91
          Mean value_function loss: 102.7156
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 83.8443
                       Mean reward: 683.57
               Mean episode length: 238.39
    Episode_Reward/reaching_object: 1.6454
    Episode_Reward/rotating_object: 131.1347
        Episode_Reward/action_rate: -0.1073
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 2.14s
                      Time elapsed: 00:46:58
                               ETA: 00:11:47

################################################################################
                     [1m Learning iteration 1200/1500 [0m                     

                       Computation: 45915 steps/s (collection: 2.010s, learning 0.131s)
             Mean action noise std: 3.91
          Mean value_function loss: 85.1456
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 83.8608
                       Mean reward: 685.79
               Mean episode length: 234.35
    Episode_Reward/reaching_object: 1.6825
    Episode_Reward/rotating_object: 133.2603
        Episode_Reward/action_rate: -0.1098
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 2.14s
                      Time elapsed: 00:47:00
                               ETA: 00:11:44

################################################################################
                     [1m Learning iteration 1201/1500 [0m                     

                       Computation: 45573 steps/s (collection: 2.066s, learning 0.091s)
             Mean action noise std: 3.92
          Mean value_function loss: 86.9497
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 83.8730
                       Mean reward: 696.27
               Mean episode length: 232.49
    Episode_Reward/reaching_object: 1.6750
    Episode_Reward/rotating_object: 134.1473
        Episode_Reward/action_rate: -0.1088
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 2.16s
                      Time elapsed: 00:47:03
                               ETA: 00:11:42

################################################################################
                     [1m Learning iteration 1202/1500 [0m                     

                       Computation: 46224 steps/s (collection: 2.032s, learning 0.095s)
             Mean action noise std: 3.92
          Mean value_function loss: 94.1611
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 83.8859
                       Mean reward: 674.30
               Mean episode length: 232.02
    Episode_Reward/reaching_object: 1.6327
    Episode_Reward/rotating_object: 129.9929
        Episode_Reward/action_rate: -0.1066
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 2.13s
                      Time elapsed: 00:47:05
                               ETA: 00:11:39

################################################################################
                     [1m Learning iteration 1203/1500 [0m                     

                       Computation: 46894 steps/s (collection: 2.000s, learning 0.097s)
             Mean action noise std: 3.92
          Mean value_function loss: 117.1602
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 83.8965
                       Mean reward: 635.97
               Mean episode length: 226.98
    Episode_Reward/reaching_object: 1.6007
    Episode_Reward/rotating_object: 126.3626
        Episode_Reward/action_rate: -0.1049
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 2.10s
                      Time elapsed: 00:47:07
                               ETA: 00:11:37

################################################################################
                     [1m Learning iteration 1204/1500 [0m                     

                       Computation: 45231 steps/s (collection: 2.064s, learning 0.110s)
             Mean action noise std: 3.92
          Mean value_function loss: 100.8228
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 83.9019
                       Mean reward: 696.05
               Mean episode length: 233.81
    Episode_Reward/reaching_object: 1.6243
    Episode_Reward/rotating_object: 130.5294
        Episode_Reward/action_rate: -0.1061
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 2.17s
                      Time elapsed: 00:47:09
                               ETA: 00:11:35

################################################################################
                     [1m Learning iteration 1205/1500 [0m                     

                       Computation: 45136 steps/s (collection: 2.060s, learning 0.118s)
             Mean action noise std: 3.92
          Mean value_function loss: 97.9988
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 83.9106
                       Mean reward: 615.56
               Mean episode length: 219.58
    Episode_Reward/reaching_object: 1.6077
    Episode_Reward/rotating_object: 126.6334
        Episode_Reward/action_rate: -0.1051
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 2.18s
                      Time elapsed: 00:47:11
                               ETA: 00:11:32

################################################################################
                     [1m Learning iteration 1206/1500 [0m                     

                       Computation: 44467 steps/s (collection: 2.073s, learning 0.138s)
             Mean action noise std: 3.93
          Mean value_function loss: 109.9214
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 83.9271
                       Mean reward: 666.41
               Mean episode length: 228.29
    Episode_Reward/reaching_object: 1.6240
    Episode_Reward/rotating_object: 129.3973
        Episode_Reward/action_rate: -0.1060
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 2.21s
                      Time elapsed: 00:47:13
                               ETA: 00:11:30

################################################################################
                     [1m Learning iteration 1207/1500 [0m                     

                       Computation: 47064 steps/s (collection: 1.999s, learning 0.090s)
             Mean action noise std: 3.93
          Mean value_function loss: 105.6306
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 83.9419
                       Mean reward: 621.45
               Mean episode length: 226.77
    Episode_Reward/reaching_object: 1.6410
    Episode_Reward/rotating_object: 130.0961
        Episode_Reward/action_rate: -0.1072
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 2.09s
                      Time elapsed: 00:47:15
                               ETA: 00:11:27

################################################################################
                     [1m Learning iteration 1208/1500 [0m                     

                       Computation: 45289 steps/s (collection: 1.999s, learning 0.172s)
             Mean action noise std: 3.93
          Mean value_function loss: 102.1392
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 83.9464
                       Mean reward: 678.64
               Mean episode length: 234.79
    Episode_Reward/reaching_object: 1.6544
    Episode_Reward/rotating_object: 130.9306
        Episode_Reward/action_rate: -0.1079
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 2.17s
                      Time elapsed: 00:47:18
                               ETA: 00:11:25

################################################################################
                     [1m Learning iteration 1209/1500 [0m                     

                       Computation: 46731 steps/s (collection: 2.011s, learning 0.093s)
             Mean action noise std: 3.93
          Mean value_function loss: 100.3363
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 83.9520
                       Mean reward: 688.51
               Mean episode length: 233.01
    Episode_Reward/reaching_object: 1.6476
    Episode_Reward/rotating_object: 132.5292
        Episode_Reward/action_rate: -0.1075
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 2.10s
                      Time elapsed: 00:47:20
                               ETA: 00:11:23

################################################################################
                     [1m Learning iteration 1210/1500 [0m                     

                       Computation: 45890 steps/s (collection: 2.036s, learning 0.106s)
             Mean action noise std: 3.93
          Mean value_function loss: 87.0569
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 83.9738
                       Mean reward: 640.74
               Mean episode length: 222.94
    Episode_Reward/reaching_object: 1.6547
    Episode_Reward/rotating_object: 131.2931
        Episode_Reward/action_rate: -0.1080
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 2.14s
                      Time elapsed: 00:47:22
                               ETA: 00:11:20

################################################################################
                     [1m Learning iteration 1211/1500 [0m                     

                       Computation: 46125 steps/s (collection: 2.041s, learning 0.091s)
             Mean action noise std: 3.94
          Mean value_function loss: 77.3131
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 83.9935
                       Mean reward: 692.16
               Mean episode length: 229.53
    Episode_Reward/reaching_object: 1.6468
    Episode_Reward/rotating_object: 133.4986
        Episode_Reward/action_rate: -0.1083
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 2.13s
                      Time elapsed: 00:47:24
                               ETA: 00:11:18

################################################################################
                     [1m Learning iteration 1212/1500 [0m                     

                       Computation: 47102 steps/s (collection: 1.995s, learning 0.092s)
             Mean action noise std: 3.94
          Mean value_function loss: 105.0392
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 84.0084
                       Mean reward: 633.45
               Mean episode length: 225.63
    Episode_Reward/reaching_object: 1.6445
    Episode_Reward/rotating_object: 132.1189
        Episode_Reward/action_rate: -0.1073
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 2.09s
                      Time elapsed: 00:47:26
                               ETA: 00:11:15

################################################################################
                     [1m Learning iteration 1213/1500 [0m                     

                       Computation: 46655 steps/s (collection: 2.007s, learning 0.100s)
             Mean action noise std: 3.94
          Mean value_function loss: 103.1040
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 84.0285
                       Mean reward: 666.94
               Mean episode length: 232.07
    Episode_Reward/reaching_object: 1.6838
    Episode_Reward/rotating_object: 135.1789
        Episode_Reward/action_rate: -0.1102
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 2.11s
                      Time elapsed: 00:47:28
                               ETA: 00:11:13

################################################################################
                     [1m Learning iteration 1214/1500 [0m                     

                       Computation: 46070 steps/s (collection: 1.999s, learning 0.135s)
             Mean action noise std: 3.94
          Mean value_function loss: 106.3155
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 84.0471
                       Mean reward: 647.03
               Mean episode length: 226.36
    Episode_Reward/reaching_object: 1.5984
    Episode_Reward/rotating_object: 126.7545
        Episode_Reward/action_rate: -0.1049
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 2.13s
                      Time elapsed: 00:47:30
                               ETA: 00:11:11

################################################################################
                     [1m Learning iteration 1215/1500 [0m                     

                       Computation: 45843 steps/s (collection: 1.994s, learning 0.151s)
             Mean action noise std: 3.95
          Mean value_function loss: 91.7648
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 84.0606
                       Mean reward: 669.56
               Mean episode length: 231.56
    Episode_Reward/reaching_object: 1.6295
    Episode_Reward/rotating_object: 131.5986
        Episode_Reward/action_rate: -0.1073
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 2.14s
                      Time elapsed: 00:47:32
                               ETA: 00:11:08

################################################################################
                     [1m Learning iteration 1216/1500 [0m                     

                       Computation: 45637 steps/s (collection: 1.997s, learning 0.157s)
             Mean action noise std: 3.95
          Mean value_function loss: 86.8609
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 84.0809
                       Mean reward: 689.82
               Mean episode length: 236.25
    Episode_Reward/reaching_object: 1.6521
    Episode_Reward/rotating_object: 133.6385
        Episode_Reward/action_rate: -0.1086
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 2.15s
                      Time elapsed: 00:47:35
                               ETA: 00:11:06

################################################################################
                     [1m Learning iteration 1217/1500 [0m                     

                       Computation: 46594 steps/s (collection: 2.012s, learning 0.098s)
             Mean action noise std: 3.95
          Mean value_function loss: 91.0069
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 84.1080
                       Mean reward: 664.76
               Mean episode length: 235.28
    Episode_Reward/reaching_object: 1.6473
    Episode_Reward/rotating_object: 130.7538
        Episode_Reward/action_rate: -0.1084
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 2.11s
                      Time elapsed: 00:47:37
                               ETA: 00:11:03

################################################################################
                     [1m Learning iteration 1218/1500 [0m                     

                       Computation: 45143 steps/s (collection: 2.082s, learning 0.096s)
             Mean action noise std: 3.95
          Mean value_function loss: 91.5664
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 84.1317
                       Mean reward: 650.70
               Mean episode length: 230.47
    Episode_Reward/reaching_object: 1.6357
    Episode_Reward/rotating_object: 132.3239
        Episode_Reward/action_rate: -0.1080
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 2.18s
                      Time elapsed: 00:47:39
                               ETA: 00:11:01

################################################################################
                     [1m Learning iteration 1219/1500 [0m                     

                       Computation: 46511 steps/s (collection: 2.013s, learning 0.101s)
             Mean action noise std: 3.96
          Mean value_function loss: 100.1367
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 84.1518
                       Mean reward: 681.19
               Mean episode length: 229.50
    Episode_Reward/reaching_object: 1.6478
    Episode_Reward/rotating_object: 133.8544
        Episode_Reward/action_rate: -0.1088
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 2.11s
                      Time elapsed: 00:47:41
                               ETA: 00:10:59

################################################################################
                     [1m Learning iteration 1220/1500 [0m                     

                       Computation: 44721 steps/s (collection: 2.089s, learning 0.109s)
             Mean action noise std: 3.96
          Mean value_function loss: 91.6846
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 84.1709
                       Mean reward: 693.71
               Mean episode length: 230.36
    Episode_Reward/reaching_object: 1.6554
    Episode_Reward/rotating_object: 135.0962
        Episode_Reward/action_rate: -0.1093
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 2.20s
                      Time elapsed: 00:47:43
                               ETA: 00:10:56

################################################################################
                     [1m Learning iteration 1221/1500 [0m                     

                       Computation: 44002 steps/s (collection: 2.076s, learning 0.158s)
             Mean action noise std: 3.96
          Mean value_function loss: 104.7687
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 84.1945
                       Mean reward: 604.81
               Mean episode length: 219.32
    Episode_Reward/reaching_object: 1.6044
    Episode_Reward/rotating_object: 126.5044
        Episode_Reward/action_rate: -0.1067
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 2.23s
                      Time elapsed: 00:47:45
                               ETA: 00:10:54

################################################################################
                     [1m Learning iteration 1222/1500 [0m                     

                       Computation: 44612 steps/s (collection: 2.056s, learning 0.148s)
             Mean action noise std: 3.97
          Mean value_function loss: 116.9907
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 84.2222
                       Mean reward: 691.31
               Mean episode length: 235.44
    Episode_Reward/reaching_object: 1.6056
    Episode_Reward/rotating_object: 127.9896
        Episode_Reward/action_rate: -0.1066
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 2.20s
                      Time elapsed: 00:47:48
                               ETA: 00:10:51

################################################################################
                     [1m Learning iteration 1223/1500 [0m                     

                       Computation: 41654 steps/s (collection: 2.155s, learning 0.205s)
             Mean action noise std: 3.97
          Mean value_function loss: 94.0640
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 84.2446
                       Mean reward: 639.55
               Mean episode length: 220.15
    Episode_Reward/reaching_object: 1.6635
    Episode_Reward/rotating_object: 133.1365
        Episode_Reward/action_rate: -0.1098
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 2.36s
                      Time elapsed: 00:47:50
                               ETA: 00:10:49

################################################################################
                     [1m Learning iteration 1224/1500 [0m                     

                       Computation: 45030 steps/s (collection: 2.083s, learning 0.101s)
             Mean action noise std: 3.97
          Mean value_function loss: 112.1502
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 84.2595
                       Mean reward: 610.21
               Mean episode length: 215.66
    Episode_Reward/reaching_object: 1.6374
    Episode_Reward/rotating_object: 131.6181
        Episode_Reward/action_rate: -0.1086
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 2.18s
                      Time elapsed: 00:47:52
                               ETA: 00:10:47

################################################################################
                     [1m Learning iteration 1225/1500 [0m                     

                       Computation: 44369 steps/s (collection: 2.080s, learning 0.136s)
             Mean action noise std: 3.98
          Mean value_function loss: 103.4407
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 84.2698
                       Mean reward: 671.41
               Mean episode length: 238.92
    Episode_Reward/reaching_object: 1.6628
    Episode_Reward/rotating_object: 132.0906
        Episode_Reward/action_rate: -0.1103
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 2.22s
                      Time elapsed: 00:47:54
                               ETA: 00:10:44

################################################################################
                     [1m Learning iteration 1226/1500 [0m                     

                       Computation: 43931 steps/s (collection: 2.101s, learning 0.136s)
             Mean action noise std: 3.98
          Mean value_function loss: 98.8304
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 84.2856
                       Mean reward: 659.49
               Mean episode length: 229.72
    Episode_Reward/reaching_object: 1.6428
    Episode_Reward/rotating_object: 130.9623
        Episode_Reward/action_rate: -0.1090
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 2.24s
                      Time elapsed: 00:47:57
                               ETA: 00:10:42

################################################################################
                     [1m Learning iteration 1227/1500 [0m                     

                       Computation: 46145 steps/s (collection: 2.026s, learning 0.105s)
             Mean action noise std: 3.98
          Mean value_function loss: 83.7770
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 84.3037
                       Mean reward: 630.72
               Mean episode length: 226.08
    Episode_Reward/reaching_object: 1.6531
    Episode_Reward/rotating_object: 131.1954
        Episode_Reward/action_rate: -0.1104
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 2.13s
                      Time elapsed: 00:47:59
                               ETA: 00:10:40

################################################################################
                     [1m Learning iteration 1228/1500 [0m                     

                       Computation: 45055 steps/s (collection: 2.052s, learning 0.130s)
             Mean action noise std: 3.98
          Mean value_function loss: 84.8884
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 84.3142
                       Mean reward: 658.58
               Mean episode length: 228.55
    Episode_Reward/reaching_object: 1.6531
    Episode_Reward/rotating_object: 132.7797
        Episode_Reward/action_rate: -0.1102
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 2.18s
                      Time elapsed: 00:48:01
                               ETA: 00:10:37

################################################################################
                     [1m Learning iteration 1229/1500 [0m                     

                       Computation: 44126 steps/s (collection: 2.109s, learning 0.119s)
             Mean action noise std: 3.98
          Mean value_function loss: 81.8978
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 84.3343
                       Mean reward: 690.18
               Mean episode length: 236.03
    Episode_Reward/reaching_object: 1.7016
    Episode_Reward/rotating_object: 137.5684
        Episode_Reward/action_rate: -0.1136
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 2.23s
                      Time elapsed: 00:48:03
                               ETA: 00:10:35

################################################################################
                     [1m Learning iteration 1230/1500 [0m                     

                       Computation: 46857 steps/s (collection: 1.992s, learning 0.106s)
             Mean action noise std: 3.99
          Mean value_function loss: 85.1893
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 84.3693
                       Mean reward: 672.37
               Mean episode length: 231.40
    Episode_Reward/reaching_object: 1.6629
    Episode_Reward/rotating_object: 132.8468
        Episode_Reward/action_rate: -0.1113
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 2.10s
                      Time elapsed: 00:48:05
                               ETA: 00:10:32

################################################################################
                     [1m Learning iteration 1231/1500 [0m                     

                       Computation: 45360 steps/s (collection: 2.019s, learning 0.149s)
             Mean action noise std: 3.99
          Mean value_function loss: 92.8515
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 84.3968
                       Mean reward: 644.04
               Mean episode length: 229.38
    Episode_Reward/reaching_object: 1.6542
    Episode_Reward/rotating_object: 130.2715
        Episode_Reward/action_rate: -0.1109
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 2.17s
                      Time elapsed: 00:48:07
                               ETA: 00:10:30

################################################################################
                     [1m Learning iteration 1232/1500 [0m                     

                       Computation: 44819 steps/s (collection: 2.054s, learning 0.140s)
             Mean action noise std: 3.99
          Mean value_function loss: 90.5580
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 84.4093
                       Mean reward: 680.81
               Mean episode length: 231.67
    Episode_Reward/reaching_object: 1.6844
    Episode_Reward/rotating_object: 137.4930
        Episode_Reward/action_rate: -0.1124
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 2.19s
                      Time elapsed: 00:48:10
                               ETA: 00:10:28

################################################################################
                     [1m Learning iteration 1233/1500 [0m                     

                       Computation: 45712 steps/s (collection: 2.050s, learning 0.101s)
             Mean action noise std: 4.00
          Mean value_function loss: 100.8342
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 84.4300
                       Mean reward: 661.73
               Mean episode length: 230.73
    Episode_Reward/reaching_object: 1.6324
    Episode_Reward/rotating_object: 130.9222
        Episode_Reward/action_rate: -0.1097
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 2.15s
                      Time elapsed: 00:48:12
                               ETA: 00:10:25

################################################################################
                     [1m Learning iteration 1234/1500 [0m                     

                       Computation: 45835 steps/s (collection: 2.046s, learning 0.099s)
             Mean action noise std: 4.00
          Mean value_function loss: 112.4146
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 84.4496
                       Mean reward: 724.08
               Mean episode length: 242.79
    Episode_Reward/reaching_object: 1.6646
    Episode_Reward/rotating_object: 133.2447
        Episode_Reward/action_rate: -0.1114
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 2.14s
                      Time elapsed: 00:48:14
                               ETA: 00:10:23

################################################################################
                     [1m Learning iteration 1235/1500 [0m                     

                       Computation: 46035 steps/s (collection: 2.031s, learning 0.105s)
             Mean action noise std: 4.00
          Mean value_function loss: 117.6055
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 84.4641
                       Mean reward: 654.19
               Mean episode length: 226.88
    Episode_Reward/reaching_object: 1.6171
    Episode_Reward/rotating_object: 129.6850
        Episode_Reward/action_rate: -0.1093
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 2.14s
                      Time elapsed: 00:48:16
                               ETA: 00:10:21

################################################################################
                     [1m Learning iteration 1236/1500 [0m                     

                       Computation: 45165 steps/s (collection: 2.070s, learning 0.107s)
             Mean action noise std: 4.00
          Mean value_function loss: 100.0563
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 84.4776
                       Mean reward: 639.70
               Mean episode length: 222.58
    Episode_Reward/reaching_object: 1.6229
    Episode_Reward/rotating_object: 127.6670
        Episode_Reward/action_rate: -0.1092
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 2.18s
                      Time elapsed: 00:48:18
                               ETA: 00:10:18

################################################################################
                     [1m Learning iteration 1237/1500 [0m                     

                       Computation: 45200 steps/s (collection: 2.057s, learning 0.118s)
             Mean action noise std: 4.00
          Mean value_function loss: 101.8222
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 84.4873
                       Mean reward: 620.67
               Mean episode length: 225.04
    Episode_Reward/reaching_object: 1.6783
    Episode_Reward/rotating_object: 132.3398
        Episode_Reward/action_rate: -0.1127
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 2.17s
                      Time elapsed: 00:48:20
                               ETA: 00:10:16

################################################################################
                     [1m Learning iteration 1238/1500 [0m                     

                       Computation: 42543 steps/s (collection: 2.124s, learning 0.187s)
             Mean action noise std: 4.01
          Mean value_function loss: 114.1082
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 84.4959
                       Mean reward: 666.62
               Mean episode length: 232.09
    Episode_Reward/reaching_object: 1.6513
    Episode_Reward/rotating_object: 129.7735
        Episode_Reward/action_rate: -0.1110
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 2.31s
                      Time elapsed: 00:48:23
                               ETA: 00:10:13

################################################################################
                     [1m Learning iteration 1239/1500 [0m                     

                       Computation: 45534 steps/s (collection: 2.030s, learning 0.129s)
             Mean action noise std: 4.01
          Mean value_function loss: 104.5479
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 84.5065
                       Mean reward: 659.20
               Mean episode length: 227.59
    Episode_Reward/reaching_object: 1.6077
    Episode_Reward/rotating_object: 125.6910
        Episode_Reward/action_rate: -0.1084
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 2.16s
                      Time elapsed: 00:48:25
                               ETA: 00:10:11

################################################################################
                     [1m Learning iteration 1240/1500 [0m                     

                       Computation: 46009 steps/s (collection: 2.023s, learning 0.113s)
             Mean action noise std: 4.01
          Mean value_function loss: 94.0726
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 84.5155
                       Mean reward: 661.95
               Mean episode length: 231.23
    Episode_Reward/reaching_object: 1.6429
    Episode_Reward/rotating_object: 129.9552
        Episode_Reward/action_rate: -0.1103
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 2.14s
                      Time elapsed: 00:48:27
                               ETA: 00:10:09

################################################################################
                     [1m Learning iteration 1241/1500 [0m                     

                       Computation: 40855 steps/s (collection: 2.284s, learning 0.122s)
             Mean action noise std: 4.01
          Mean value_function loss: 72.9273
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 84.5284
                       Mean reward: 662.02
               Mean episode length: 226.54
    Episode_Reward/reaching_object: 1.6690
    Episode_Reward/rotating_object: 134.0936
        Episode_Reward/action_rate: -0.1121
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 2.41s
                      Time elapsed: 00:48:29
                               ETA: 00:10:06

################################################################################
                     [1m Learning iteration 1242/1500 [0m                     

                       Computation: 44101 steps/s (collection: 2.091s, learning 0.138s)
             Mean action noise std: 4.01
          Mean value_function loss: 71.4903
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 84.5430
                       Mean reward: 645.40
               Mean episode length: 231.18
    Episode_Reward/reaching_object: 1.6850
    Episode_Reward/rotating_object: 131.1424
        Episode_Reward/action_rate: -0.1130
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 2.23s
                      Time elapsed: 00:48:32
                               ETA: 00:10:04

################################################################################
                     [1m Learning iteration 1243/1500 [0m                     

                       Computation: 46240 steps/s (collection: 2.006s, learning 0.120s)
             Mean action noise std: 4.02
          Mean value_function loss: 77.3576
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 84.5545
                       Mean reward: 725.92
               Mean episode length: 243.26
    Episode_Reward/reaching_object: 1.7005
    Episode_Reward/rotating_object: 132.8718
        Episode_Reward/action_rate: -0.1142
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 2.13s
                      Time elapsed: 00:48:34
                               ETA: 00:10:02

################################################################################
                     [1m Learning iteration 1244/1500 [0m                     

                       Computation: 44943 steps/s (collection: 2.074s, learning 0.113s)
             Mean action noise std: 4.02
          Mean value_function loss: 95.8503
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 84.5659
                       Mean reward: 656.88
               Mean episode length: 223.02
    Episode_Reward/reaching_object: 1.6626
    Episode_Reward/rotating_object: 133.9577
        Episode_Reward/action_rate: -0.1123
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 2.19s
                      Time elapsed: 00:48:36
                               ETA: 00:09:59

################################################################################
                     [1m Learning iteration 1245/1500 [0m                     

                       Computation: 45116 steps/s (collection: 2.058s, learning 0.120s)
             Mean action noise std: 4.02
          Mean value_function loss: 93.3458
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 84.5826
                       Mean reward: 649.56
               Mean episode length: 221.83
    Episode_Reward/reaching_object: 1.6559
    Episode_Reward/rotating_object: 134.0901
        Episode_Reward/action_rate: -0.1112
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 2.18s
                      Time elapsed: 00:48:38
                               ETA: 00:09:57

################################################################################
                     [1m Learning iteration 1246/1500 [0m                     

                       Computation: 46096 steps/s (collection: 2.023s, learning 0.109s)
             Mean action noise std: 4.02
          Mean value_function loss: 78.0601
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 84.5973
                       Mean reward: 663.74
               Mean episode length: 228.36
    Episode_Reward/reaching_object: 1.7008
    Episode_Reward/rotating_object: 138.6556
        Episode_Reward/action_rate: -0.1145
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 2.13s
                      Time elapsed: 00:48:40
                               ETA: 00:09:54

################################################################################
                     [1m Learning iteration 1247/1500 [0m                     

                       Computation: 45536 steps/s (collection: 2.014s, learning 0.145s)
             Mean action noise std: 4.03
          Mean value_function loss: 78.8151
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 84.6132
                       Mean reward: 676.98
               Mean episode length: 231.41
    Episode_Reward/reaching_object: 1.6411
    Episode_Reward/rotating_object: 132.7752
        Episode_Reward/action_rate: -0.1118
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 2.16s
                      Time elapsed: 00:48:42
                               ETA: 00:09:52

################################################################################
                     [1m Learning iteration 1248/1500 [0m                     

                       Computation: 41572 steps/s (collection: 2.170s, learning 0.194s)
             Mean action noise std: 4.03
          Mean value_function loss: 94.0607
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 84.6307
                       Mean reward: 613.12
               Mean episode length: 215.12
    Episode_Reward/reaching_object: 1.6405
    Episode_Reward/rotating_object: 133.4463
        Episode_Reward/action_rate: -0.1116
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 2.36s
                      Time elapsed: 00:48:45
                               ETA: 00:09:50

################################################################################
                     [1m Learning iteration 1249/1500 [0m                     

                       Computation: 42383 steps/s (collection: 2.204s, learning 0.116s)
             Mean action noise std: 4.03
          Mean value_function loss: 84.2684
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 84.6478
                       Mean reward: 667.65
               Mean episode length: 225.12
    Episode_Reward/reaching_object: 1.6722
    Episode_Reward/rotating_object: 137.2682
        Episode_Reward/action_rate: -0.1141
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 2.32s
                      Time elapsed: 00:48:47
                               ETA: 00:09:47

################################################################################
                     [1m Learning iteration 1250/1500 [0m                     

                       Computation: 45960 steps/s (collection: 2.011s, learning 0.128s)
             Mean action noise std: 4.03
          Mean value_function loss: 92.8191
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 84.6689
                       Mean reward: 685.44
               Mean episode length: 235.19
    Episode_Reward/reaching_object: 1.6430
    Episode_Reward/rotating_object: 131.8527
        Episode_Reward/action_rate: -0.1123
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 2.14s
                      Time elapsed: 00:48:49
                               ETA: 00:09:45

################################################################################
                     [1m Learning iteration 1251/1500 [0m                     

                       Computation: 43451 steps/s (collection: 2.133s, learning 0.130s)
             Mean action noise std: 4.04
          Mean value_function loss: 87.5023
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 84.6906
                       Mean reward: 710.48
               Mean episode length: 236.68
    Episode_Reward/reaching_object: 1.6788
    Episode_Reward/rotating_object: 137.3705
        Episode_Reward/action_rate: -0.1145
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 2.26s
                      Time elapsed: 00:48:52
                               ETA: 00:09:43

################################################################################
                     [1m Learning iteration 1252/1500 [0m                     

                       Computation: 42136 steps/s (collection: 2.158s, learning 0.175s)
             Mean action noise std: 4.04
          Mean value_function loss: 79.3909
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 84.7088
                       Mean reward: 696.65
               Mean episode length: 232.25
    Episode_Reward/reaching_object: 1.6724
    Episode_Reward/rotating_object: 137.2453
        Episode_Reward/action_rate: -0.1147
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 2.33s
                      Time elapsed: 00:48:54
                               ETA: 00:09:40

################################################################################
                     [1m Learning iteration 1253/1500 [0m                     

                       Computation: 45238 steps/s (collection: 2.074s, learning 0.099s)
             Mean action noise std: 4.04
          Mean value_function loss: 77.2705
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 84.7208
                       Mean reward: 610.18
               Mean episode length: 225.17
    Episode_Reward/reaching_object: 1.6496
    Episode_Reward/rotating_object: 131.0291
        Episode_Reward/action_rate: -0.1136
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 2.17s
                      Time elapsed: 00:48:56
                               ETA: 00:09:38

################################################################################
                     [1m Learning iteration 1254/1500 [0m                     

                       Computation: 44840 steps/s (collection: 2.088s, learning 0.105s)
             Mean action noise std: 4.04
          Mean value_function loss: 77.3730
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 84.7333
                       Mean reward: 720.78
               Mean episode length: 240.56
    Episode_Reward/reaching_object: 1.6974
    Episode_Reward/rotating_object: 136.6635
        Episode_Reward/action_rate: -0.1165
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 2.19s
                      Time elapsed: 00:48:58
                               ETA: 00:09:36

################################################################################
                     [1m Learning iteration 1255/1500 [0m                     

                       Computation: 43765 steps/s (collection: 2.100s, learning 0.146s)
             Mean action noise std: 4.04
          Mean value_function loss: 86.7019
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 84.7477
                       Mean reward: 657.23
               Mean episode length: 228.63
    Episode_Reward/reaching_object: 1.6504
    Episode_Reward/rotating_object: 132.7147
        Episode_Reward/action_rate: -0.1137
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 2.25s
                      Time elapsed: 00:49:01
                               ETA: 00:09:33

################################################################################
                     [1m Learning iteration 1256/1500 [0m                     

                       Computation: 41910 steps/s (collection: 2.208s, learning 0.138s)
             Mean action noise std: 4.05
          Mean value_function loss: 88.1190
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 84.7639
                       Mean reward: 710.20
               Mean episode length: 236.75
    Episode_Reward/reaching_object: 1.6768
    Episode_Reward/rotating_object: 136.9130
        Episode_Reward/action_rate: -0.1155
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 2.35s
                      Time elapsed: 00:49:03
                               ETA: 00:09:31

################################################################################
                     [1m Learning iteration 1257/1500 [0m                     

                       Computation: 45128 steps/s (collection: 2.065s, learning 0.114s)
             Mean action noise std: 4.05
          Mean value_function loss: 106.4626
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 84.7846
                       Mean reward: 708.53
               Mean episode length: 235.26
    Episode_Reward/reaching_object: 1.6160
    Episode_Reward/rotating_object: 130.6854
        Episode_Reward/action_rate: -0.1116
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 2.18s
                      Time elapsed: 00:49:05
                               ETA: 00:09:28

################################################################################
                     [1m Learning iteration 1258/1500 [0m                     

                       Computation: 45258 steps/s (collection: 2.065s, learning 0.107s)
             Mean action noise std: 4.05
          Mean value_function loss: 93.3391
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 84.8051
                       Mean reward: 692.38
               Mean episode length: 233.07
    Episode_Reward/reaching_object: 1.6514
    Episode_Reward/rotating_object: 132.0000
        Episode_Reward/action_rate: -0.1143
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 2.17s
                      Time elapsed: 00:49:07
                               ETA: 00:09:26

################################################################################
                     [1m Learning iteration 1259/1500 [0m                     

                       Computation: 45259 steps/s (collection: 2.046s, learning 0.126s)
             Mean action noise std: 4.05
          Mean value_function loss: 77.8474
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 84.8195
                       Mean reward: 686.37
               Mean episode length: 236.56
    Episode_Reward/reaching_object: 1.6938
    Episode_Reward/rotating_object: 135.4326
        Episode_Reward/action_rate: -0.1169
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 2.17s
                      Time elapsed: 00:49:09
                               ETA: 00:09:24

################################################################################
                     [1m Learning iteration 1260/1500 [0m                     

                       Computation: 43153 steps/s (collection: 2.111s, learning 0.167s)
             Mean action noise std: 4.06
          Mean value_function loss: 84.9241
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 84.8355
                       Mean reward: 720.14
               Mean episode length: 242.37
    Episode_Reward/reaching_object: 1.6624
    Episode_Reward/rotating_object: 132.5148
        Episode_Reward/action_rate: -0.1147
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 2.28s
                      Time elapsed: 00:49:12
                               ETA: 00:09:21

################################################################################
                     [1m Learning iteration 1261/1500 [0m                     

                       Computation: 42737 steps/s (collection: 2.190s, learning 0.110s)
             Mean action noise std: 4.06
          Mean value_function loss: 76.7318
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 84.8603
                       Mean reward: 704.52
               Mean episode length: 234.50
    Episode_Reward/reaching_object: 1.6842
    Episode_Reward/rotating_object: 136.0917
        Episode_Reward/action_rate: -0.1167
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 2.30s
                      Time elapsed: 00:49:14
                               ETA: 00:09:19

################################################################################
                     [1m Learning iteration 1262/1500 [0m                     

                       Computation: 43702 steps/s (collection: 2.108s, learning 0.142s)
             Mean action noise std: 4.06
          Mean value_function loss: 70.7959
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 84.8845
                       Mean reward: 716.03
               Mean episode length: 238.43
    Episode_Reward/reaching_object: 1.6832
    Episode_Reward/rotating_object: 136.3943
        Episode_Reward/action_rate: -0.1167
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 2.25s
                      Time elapsed: 00:49:16
                               ETA: 00:09:17

################################################################################
                     [1m Learning iteration 1263/1500 [0m                     

                       Computation: 43494 steps/s (collection: 2.160s, learning 0.101s)
             Mean action noise std: 4.06
          Mean value_function loss: 77.4149
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 84.8935
                       Mean reward: 725.06
               Mean episode length: 242.08
    Episode_Reward/reaching_object: 1.6991
    Episode_Reward/rotating_object: 138.0668
        Episode_Reward/action_rate: -0.1175
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 2.26s
                      Time elapsed: 00:49:18
                               ETA: 00:09:14

################################################################################
                     [1m Learning iteration 1264/1500 [0m                     

                       Computation: 45967 steps/s (collection: 2.022s, learning 0.117s)
             Mean action noise std: 4.07
          Mean value_function loss: 77.4461
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 84.9081
                       Mean reward: 718.20
               Mean episode length: 245.33
    Episode_Reward/reaching_object: 1.6627
    Episode_Reward/rotating_object: 134.8882
        Episode_Reward/action_rate: -0.1157
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 2.14s
                      Time elapsed: 00:49:21
                               ETA: 00:09:12

################################################################################
                     [1m Learning iteration 1265/1500 [0m                     

                       Computation: 42222 steps/s (collection: 2.203s, learning 0.125s)
             Mean action noise std: 4.07
          Mean value_function loss: 87.4028
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 84.9316
                       Mean reward: 726.43
               Mean episode length: 244.45
    Episode_Reward/reaching_object: 1.6757
    Episode_Reward/rotating_object: 135.2231
        Episode_Reward/action_rate: -0.1172
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 2.33s
                      Time elapsed: 00:49:23
                               ETA: 00:09:10

################################################################################
                     [1m Learning iteration 1266/1500 [0m                     

                       Computation: 44849 steps/s (collection: 2.088s, learning 0.104s)
             Mean action noise std: 4.07
          Mean value_function loss: 88.0141
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 84.9511
                       Mean reward: 677.80
               Mean episode length: 233.12
    Episode_Reward/reaching_object: 1.6670
    Episode_Reward/rotating_object: 135.7092
        Episode_Reward/action_rate: -0.1161
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 2.19s
                      Time elapsed: 00:49:25
                               ETA: 00:09:07

################################################################################
                     [1m Learning iteration 1267/1500 [0m                     

                       Computation: 44577 steps/s (collection: 2.103s, learning 0.103s)
             Mean action noise std: 4.07
          Mean value_function loss: 78.2137
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 84.9674
                       Mean reward: 691.23
               Mean episode length: 235.14
    Episode_Reward/reaching_object: 1.6590
    Episode_Reward/rotating_object: 134.5786
        Episode_Reward/action_rate: -0.1160
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 2.21s
                      Time elapsed: 00:49:27
                               ETA: 00:09:05

################################################################################
                     [1m Learning iteration 1268/1500 [0m                     

                       Computation: 44215 steps/s (collection: 2.109s, learning 0.114s)
             Mean action noise std: 4.08
          Mean value_function loss: 86.1000
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 84.9880
                       Mean reward: 654.28
               Mean episode length: 226.92
    Episode_Reward/reaching_object: 1.6532
    Episode_Reward/rotating_object: 131.7403
        Episode_Reward/action_rate: -0.1162
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 2.22s
                      Time elapsed: 00:49:30
                               ETA: 00:09:02

################################################################################
                     [1m Learning iteration 1269/1500 [0m                     

                       Computation: 43309 steps/s (collection: 2.104s, learning 0.166s)
             Mean action noise std: 4.08
          Mean value_function loss: 82.4242
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 85.0065
                       Mean reward: 710.07
               Mean episode length: 242.55
    Episode_Reward/reaching_object: 1.6842
    Episode_Reward/rotating_object: 136.7343
        Episode_Reward/action_rate: -0.1182
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 2.27s
                      Time elapsed: 00:49:32
                               ETA: 00:09:00

################################################################################
                     [1m Learning iteration 1270/1500 [0m                     

                       Computation: 43446 steps/s (collection: 2.127s, learning 0.136s)
             Mean action noise std: 4.08
          Mean value_function loss: 83.3515
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 85.0245
                       Mean reward: 680.20
               Mean episode length: 232.73
    Episode_Reward/reaching_object: 1.6692
    Episode_Reward/rotating_object: 136.2523
        Episode_Reward/action_rate: -0.1173
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 2.26s
                      Time elapsed: 00:49:34
                               ETA: 00:08:58

################################################################################
                     [1m Learning iteration 1271/1500 [0m                     

                       Computation: 45824 steps/s (collection: 2.044s, learning 0.102s)
             Mean action noise std: 4.08
          Mean value_function loss: 79.8201
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 85.0352
                       Mean reward: 728.54
               Mean episode length: 242.60
    Episode_Reward/reaching_object: 1.6769
    Episode_Reward/rotating_object: 136.5273
        Episode_Reward/action_rate: -0.1181
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 2.15s
                      Time elapsed: 00:49:36
                               ETA: 00:08:55

################################################################################
                     [1m Learning iteration 1272/1500 [0m                     

                       Computation: 44942 steps/s (collection: 2.090s, learning 0.098s)
             Mean action noise std: 4.09
          Mean value_function loss: 80.0884
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 85.0445
                       Mean reward: 638.34
               Mean episode length: 227.21
    Episode_Reward/reaching_object: 1.6584
    Episode_Reward/rotating_object: 131.4393
        Episode_Reward/action_rate: -0.1174
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 2.19s
                      Time elapsed: 00:49:38
                               ETA: 00:08:53

################################################################################
                     [1m Learning iteration 1273/1500 [0m                     

                       Computation: 44809 steps/s (collection: 2.084s, learning 0.110s)
             Mean action noise std: 4.09
          Mean value_function loss: 77.6612
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 85.0595
                       Mean reward: 712.97
               Mean episode length: 244.25
    Episode_Reward/reaching_object: 1.6719
    Episode_Reward/rotating_object: 134.0356
        Episode_Reward/action_rate: -0.1183
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 2.19s
                      Time elapsed: 00:49:41
                               ETA: 00:08:51

################################################################################
                     [1m Learning iteration 1274/1500 [0m                     

                       Computation: 43769 steps/s (collection: 2.127s, learning 0.119s)
             Mean action noise std: 4.09
          Mean value_function loss: 75.2775
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 85.0808
                       Mean reward: 702.77
               Mean episode length: 241.28
    Episode_Reward/reaching_object: 1.6930
    Episode_Reward/rotating_object: 137.9642
        Episode_Reward/action_rate: -0.1197
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 2.25s
                      Time elapsed: 00:49:43
                               ETA: 00:08:48

################################################################################
                     [1m Learning iteration 1275/1500 [0m                     

                       Computation: 44529 steps/s (collection: 2.085s, learning 0.123s)
             Mean action noise std: 4.09
          Mean value_function loss: 71.3257
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 85.1040
                       Mean reward: 703.26
               Mean episode length: 239.35
    Episode_Reward/reaching_object: 1.7030
    Episode_Reward/rotating_object: 139.1856
        Episode_Reward/action_rate: -0.1206
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 2.21s
                      Time elapsed: 00:49:45
                               ETA: 00:08:46

################################################################################
                     [1m Learning iteration 1276/1500 [0m                     

                       Computation: 43915 steps/s (collection: 2.113s, learning 0.125s)
             Mean action noise std: 4.10
          Mean value_function loss: 79.4498
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 85.1137
                       Mean reward: 671.78
               Mean episode length: 230.29
    Episode_Reward/reaching_object: 1.6500
    Episode_Reward/rotating_object: 131.7308
        Episode_Reward/action_rate: -0.1173
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 2.24s
                      Time elapsed: 00:49:47
                               ETA: 00:08:44

################################################################################
                     [1m Learning iteration 1277/1500 [0m                     

                       Computation: 45174 steps/s (collection: 2.068s, learning 0.109s)
             Mean action noise std: 4.10
          Mean value_function loss: 83.3062
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 85.1270
                       Mean reward: 702.15
               Mean episode length: 239.84
    Episode_Reward/reaching_object: 1.6569
    Episode_Reward/rotating_object: 133.0402
        Episode_Reward/action_rate: -0.1179
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 2.18s
                      Time elapsed: 00:49:49
                               ETA: 00:08:41

################################################################################
                     [1m Learning iteration 1278/1500 [0m                     

                       Computation: 45269 steps/s (collection: 2.037s, learning 0.134s)
             Mean action noise std: 4.10
          Mean value_function loss: 75.2043
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 85.1444
                       Mean reward: 678.07
               Mean episode length: 232.69
    Episode_Reward/reaching_object: 1.6597
    Episode_Reward/rotating_object: 133.6546
        Episode_Reward/action_rate: -0.1183
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 2.17s
                      Time elapsed: 00:49:52
                               ETA: 00:08:39

################################################################################
                     [1m Learning iteration 1279/1500 [0m                     

                       Computation: 43849 steps/s (collection: 2.045s, learning 0.197s)
             Mean action noise std: 4.10
          Mean value_function loss: 74.4206
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 85.1623
                       Mean reward: 691.15
               Mean episode length: 234.91
    Episode_Reward/reaching_object: 1.6692
    Episode_Reward/rotating_object: 134.5691
        Episode_Reward/action_rate: -0.1192
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 2.24s
                      Time elapsed: 00:49:54
                               ETA: 00:08:37

################################################################################
                     [1m Learning iteration 1280/1500 [0m                     

                       Computation: 44570 steps/s (collection: 2.072s, learning 0.134s)
             Mean action noise std: 4.11
          Mean value_function loss: 92.2715
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 85.1850
                       Mean reward: 682.13
               Mean episode length: 235.49
    Episode_Reward/reaching_object: 1.6480
    Episode_Reward/rotating_object: 133.3282
        Episode_Reward/action_rate: -0.1175
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 2.21s
                      Time elapsed: 00:49:56
                               ETA: 00:08:34

################################################################################
                     [1m Learning iteration 1281/1500 [0m                     

                       Computation: 41925 steps/s (collection: 2.233s, learning 0.112s)
             Mean action noise std: 4.11
          Mean value_function loss: 75.5635
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 85.2104
                       Mean reward: 699.94
               Mean episode length: 236.93
    Episode_Reward/reaching_object: 1.6708
    Episode_Reward/rotating_object: 134.9514
        Episode_Reward/action_rate: -0.1196
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 2.34s
                      Time elapsed: 00:49:58
                               ETA: 00:08:32

################################################################################
                     [1m Learning iteration 1282/1500 [0m                     

                       Computation: 45207 steps/s (collection: 2.074s, learning 0.101s)
             Mean action noise std: 4.11
          Mean value_function loss: 90.0367
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 85.2301
                       Mean reward: 658.86
               Mean episode length: 233.16
    Episode_Reward/reaching_object: 1.6754
    Episode_Reward/rotating_object: 136.3475
        Episode_Reward/action_rate: -0.1196
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 2.17s
                      Time elapsed: 00:50:01
                               ETA: 00:08:29

################################################################################
                     [1m Learning iteration 1283/1500 [0m                     

                       Computation: 44687 steps/s (collection: 2.038s, learning 0.161s)
             Mean action noise std: 4.11
          Mean value_function loss: 88.1762
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 85.2437
                       Mean reward: 649.03
               Mean episode length: 234.30
    Episode_Reward/reaching_object: 1.6468
    Episode_Reward/rotating_object: 133.2557
        Episode_Reward/action_rate: -0.1184
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 2.20s
                      Time elapsed: 00:50:03
                               ETA: 00:08:27

################################################################################
                     [1m Learning iteration 1284/1500 [0m                     

                       Computation: 43845 steps/s (collection: 2.090s, learning 0.152s)
             Mean action noise std: 4.12
          Mean value_function loss: 88.6408
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 85.2611
                       Mean reward: 676.53
               Mean episode length: 231.89
    Episode_Reward/reaching_object: 1.6638
    Episode_Reward/rotating_object: 133.9979
        Episode_Reward/action_rate: -0.1193
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 2.24s
                      Time elapsed: 00:50:05
                               ETA: 00:08:25

################################################################################
                     [1m Learning iteration 1285/1500 [0m                     

                       Computation: 45728 steps/s (collection: 2.047s, learning 0.103s)
             Mean action noise std: 4.12
          Mean value_function loss: 79.7609
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 85.2819
                       Mean reward: 724.53
               Mean episode length: 238.42
    Episode_Reward/reaching_object: 1.6644
    Episode_Reward/rotating_object: 136.0430
        Episode_Reward/action_rate: -0.1194
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 2.15s
                      Time elapsed: 00:50:07
                               ETA: 00:08:22

################################################################################
                     [1m Learning iteration 1286/1500 [0m                     

                       Computation: 45644 steps/s (collection: 2.055s, learning 0.099s)
             Mean action noise std: 4.12
          Mean value_function loss: 95.5732
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 85.2874
                       Mean reward: 652.44
               Mean episode length: 227.48
    Episode_Reward/reaching_object: 1.6400
    Episode_Reward/rotating_object: 131.4818
        Episode_Reward/action_rate: -0.1184
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 2.15s
                      Time elapsed: 00:50:09
                               ETA: 00:08:20

################################################################################
                     [1m Learning iteration 1287/1500 [0m                     

                       Computation: 44811 steps/s (collection: 2.091s, learning 0.102s)
             Mean action noise std: 4.12
          Mean value_function loss: 85.9342
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 85.2910
                       Mean reward: 684.46
               Mean episode length: 239.35
    Episode_Reward/reaching_object: 1.6639
    Episode_Reward/rotating_object: 135.8224
        Episode_Reward/action_rate: -0.1201
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 2.19s
                      Time elapsed: 00:50:12
                               ETA: 00:08:18

################################################################################
                     [1m Learning iteration 1288/1500 [0m                     

                       Computation: 45633 steps/s (collection: 2.044s, learning 0.110s)
             Mean action noise std: 4.12
          Mean value_function loss: 80.3132
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 85.2983
                       Mean reward: 705.07
               Mean episode length: 241.76
    Episode_Reward/reaching_object: 1.6548
    Episode_Reward/rotating_object: 133.8266
        Episode_Reward/action_rate: -0.1196
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 2.15s
                      Time elapsed: 00:50:14
                               ETA: 00:08:15

################################################################################
                     [1m Learning iteration 1289/1500 [0m                     

                       Computation: 45299 steps/s (collection: 2.075s, learning 0.095s)
             Mean action noise std: 4.12
          Mean value_function loss: 86.0622
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 85.3116
                       Mean reward: 696.04
               Mean episode length: 235.41
    Episode_Reward/reaching_object: 1.6796
    Episode_Reward/rotating_object: 135.9231
        Episode_Reward/action_rate: -0.1213
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 2.17s
                      Time elapsed: 00:50:16
                               ETA: 00:08:13

################################################################################
                     [1m Learning iteration 1290/1500 [0m                     

                       Computation: 42300 steps/s (collection: 2.230s, learning 0.094s)
             Mean action noise std: 4.13
          Mean value_function loss: 92.5041
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 85.3286
                       Mean reward: 663.75
               Mean episode length: 226.32
    Episode_Reward/reaching_object: 1.6409
    Episode_Reward/rotating_object: 131.1085
        Episode_Reward/action_rate: -0.1188
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 2.32s
                      Time elapsed: 00:50:18
                               ETA: 00:08:11

################################################################################
                     [1m Learning iteration 1291/1500 [0m                     

                       Computation: 45570 steps/s (collection: 2.054s, learning 0.104s)
             Mean action noise std: 4.13
          Mean value_function loss: 80.8892
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 85.3407
                       Mean reward: 663.66
               Mean episode length: 233.93
    Episode_Reward/reaching_object: 1.6892
    Episode_Reward/rotating_object: 135.8529
        Episode_Reward/action_rate: -0.1220
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 2.16s
                      Time elapsed: 00:50:20
                               ETA: 00:08:08

################################################################################
                     [1m Learning iteration 1292/1500 [0m                     

                       Computation: 43533 steps/s (collection: 2.160s, learning 0.099s)
             Mean action noise std: 4.13
          Mean value_function loss: 74.5255
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 85.3518
                       Mean reward: 704.35
               Mean episode length: 240.63
    Episode_Reward/reaching_object: 1.6691
    Episode_Reward/rotating_object: 133.6460
        Episode_Reward/action_rate: -0.1207
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 2.26s
                      Time elapsed: 00:50:23
                               ETA: 00:08:06

################################################################################
                     [1m Learning iteration 1293/1500 [0m                     

                       Computation: 45640 steps/s (collection: 2.046s, learning 0.108s)
             Mean action noise std: 4.13
          Mean value_function loss: 77.4216
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 85.3622
                       Mean reward: 677.60
               Mean episode length: 239.58
    Episode_Reward/reaching_object: 1.6987
    Episode_Reward/rotating_object: 134.7740
        Episode_Reward/action_rate: -0.1229
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 2.15s
                      Time elapsed: 00:50:25
                               ETA: 00:08:03

################################################################################
                     [1m Learning iteration 1294/1500 [0m                     

                       Computation: 43330 steps/s (collection: 2.097s, learning 0.172s)
             Mean action noise std: 4.14
          Mean value_function loss: 80.2102
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 85.3711
                       Mean reward: 675.67
               Mean episode length: 236.94
    Episode_Reward/reaching_object: 1.6680
    Episode_Reward/rotating_object: 135.0776
        Episode_Reward/action_rate: -0.1214
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 2.27s
                      Time elapsed: 00:50:27
                               ETA: 00:08:01

################################################################################
                     [1m Learning iteration 1295/1500 [0m                     

                       Computation: 42891 steps/s (collection: 2.170s, learning 0.122s)
             Mean action noise std: 4.14
          Mean value_function loss: 84.3596
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 85.3793
                       Mean reward: 697.02
               Mean episode length: 236.05
    Episode_Reward/reaching_object: 1.6256
    Episode_Reward/rotating_object: 131.4914
        Episode_Reward/action_rate: -0.1183
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 2.29s
                      Time elapsed: 00:50:29
                               ETA: 00:07:59

################################################################################
                     [1m Learning iteration 1296/1500 [0m                     

                       Computation: 43637 steps/s (collection: 2.094s, learning 0.159s)
             Mean action noise std: 4.14
          Mean value_function loss: 78.8996
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 85.3917
                       Mean reward: 673.01
               Mean episode length: 229.67
    Episode_Reward/reaching_object: 1.6609
    Episode_Reward/rotating_object: 133.4596
        Episode_Reward/action_rate: -0.1210
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 2.25s
                      Time elapsed: 00:50:32
                               ETA: 00:07:56

################################################################################
                     [1m Learning iteration 1297/1500 [0m                     

                       Computation: 42614 steps/s (collection: 2.155s, learning 0.152s)
             Mean action noise std: 4.14
          Mean value_function loss: 80.4038
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 85.4130
                       Mean reward: 726.21
               Mean episode length: 240.62
    Episode_Reward/reaching_object: 1.6974
    Episode_Reward/rotating_object: 141.7059
        Episode_Reward/action_rate: -0.1225
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 2.31s
                      Time elapsed: 00:50:34
                               ETA: 00:07:54

################################################################################
                     [1m Learning iteration 1298/1500 [0m                     

                       Computation: 44623 steps/s (collection: 2.098s, learning 0.105s)
             Mean action noise std: 4.15
          Mean value_function loss: 77.7256
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 85.4366
                       Mean reward: 722.42
               Mean episode length: 242.25
    Episode_Reward/reaching_object: 1.6780
    Episode_Reward/rotating_object: 137.0404
        Episode_Reward/action_rate: -0.1220
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 2.20s
                      Time elapsed: 00:50:36
                               ETA: 00:07:52

################################################################################
                     [1m Learning iteration 1299/1500 [0m                     

                       Computation: 42487 steps/s (collection: 2.211s, learning 0.103s)
             Mean action noise std: 4.15
          Mean value_function loss: 88.9515
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 85.4556
                       Mean reward: 703.38
               Mean episode length: 240.50
    Episode_Reward/reaching_object: 1.6871
    Episode_Reward/rotating_object: 136.7377
        Episode_Reward/action_rate: -0.1233
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 2.31s
                      Time elapsed: 00:50:38
                               ETA: 00:07:49

################################################################################
                     [1m Learning iteration 1300/1500 [0m                     

                       Computation: 43904 steps/s (collection: 2.116s, learning 0.123s)
             Mean action noise std: 4.15
          Mean value_function loss: 81.3644
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 85.4715
                       Mean reward: 675.10
               Mean episode length: 229.15
    Episode_Reward/reaching_object: 1.6371
    Episode_Reward/rotating_object: 132.0096
        Episode_Reward/action_rate: -0.1192
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 2.24s
                      Time elapsed: 00:50:41
                               ETA: 00:07:47

################################################################################
                     [1m Learning iteration 1301/1500 [0m                     

                       Computation: 41838 steps/s (collection: 2.206s, learning 0.144s)
             Mean action noise std: 4.16
          Mean value_function loss: 82.8539
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 85.4869
                       Mean reward: 691.00
               Mean episode length: 233.69
    Episode_Reward/reaching_object: 1.6821
    Episode_Reward/rotating_object: 137.0901
        Episode_Reward/action_rate: -0.1225
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 2.35s
                      Time elapsed: 00:50:43
                               ETA: 00:07:45

################################################################################
                     [1m Learning iteration 1302/1500 [0m                     

                       Computation: 44152 steps/s (collection: 2.105s, learning 0.122s)
             Mean action noise std: 4.16
          Mean value_function loss: 97.6574
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 85.5043
                       Mean reward: 667.09
               Mean episode length: 231.79
    Episode_Reward/reaching_object: 1.6562
    Episode_Reward/rotating_object: 133.1448
        Episode_Reward/action_rate: -0.1210
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 2.23s
                      Time elapsed: 00:50:45
                               ETA: 00:07:42

################################################################################
                     [1m Learning iteration 1303/1500 [0m                     

                       Computation: 42934 steps/s (collection: 2.057s, learning 0.232s)
             Mean action noise std: 4.16
          Mean value_function loss: 75.3953
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 85.5170
                       Mean reward: 703.77
               Mean episode length: 236.11
    Episode_Reward/reaching_object: 1.6725
    Episode_Reward/rotating_object: 137.7671
        Episode_Reward/action_rate: -0.1215
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 2.29s
                      Time elapsed: 00:50:48
                               ETA: 00:07:40

################################################################################
                     [1m Learning iteration 1304/1500 [0m                     

                       Computation: 44839 steps/s (collection: 2.086s, learning 0.106s)
             Mean action noise std: 4.17
          Mean value_function loss: 90.1051
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 85.5376
                       Mean reward: 662.80
               Mean episode length: 227.32
    Episode_Reward/reaching_object: 1.6639
    Episode_Reward/rotating_object: 136.9118
        Episode_Reward/action_rate: -0.1214
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 2.19s
                      Time elapsed: 00:50:50
                               ETA: 00:07:38

################################################################################
                     [1m Learning iteration 1305/1500 [0m                     

                       Computation: 41639 steps/s (collection: 2.140s, learning 0.221s)
             Mean action noise std: 4.17
          Mean value_function loss: 87.5177
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 85.5642
                       Mean reward: 675.94
               Mean episode length: 225.61
    Episode_Reward/reaching_object: 1.6447
    Episode_Reward/rotating_object: 131.5918
        Episode_Reward/action_rate: -0.1209
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 2.36s
                      Time elapsed: 00:50:52
                               ETA: 00:07:35

################################################################################
                     [1m Learning iteration 1306/1500 [0m                     

                       Computation: 44742 steps/s (collection: 2.043s, learning 0.155s)
             Mean action noise std: 4.17
          Mean value_function loss: 69.0462
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 85.5906
                       Mean reward: 715.51
               Mean episode length: 240.47
    Episode_Reward/reaching_object: 1.6906
    Episode_Reward/rotating_object: 136.6798
        Episode_Reward/action_rate: -0.1247
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 2.20s
                      Time elapsed: 00:50:54
                               ETA: 00:07:33

################################################################################
                     [1m Learning iteration 1307/1500 [0m                     

                       Computation: 45601 steps/s (collection: 2.038s, learning 0.118s)
             Mean action noise std: 4.17
          Mean value_function loss: 71.0292
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 85.6108
                       Mean reward: 686.93
               Mean episode length: 232.45
    Episode_Reward/reaching_object: 1.6543
    Episode_Reward/rotating_object: 133.6644
        Episode_Reward/action_rate: -0.1220
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 2.16s
                      Time elapsed: 00:50:56
                               ETA: 00:07:31

################################################################################
                     [1m Learning iteration 1308/1500 [0m                     

                       Computation: 46429 steps/s (collection: 2.023s, learning 0.094s)
             Mean action noise std: 4.18
          Mean value_function loss: 90.8892
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 85.6244
                       Mean reward: 669.38
               Mean episode length: 232.96
    Episode_Reward/reaching_object: 1.6644
    Episode_Reward/rotating_object: 132.9825
        Episode_Reward/action_rate: -0.1229
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 2.12s
                      Time elapsed: 00:50:59
                               ETA: 00:07:28

################################################################################
                     [1m Learning iteration 1309/1500 [0m                     

                       Computation: 45500 steps/s (collection: 2.066s, learning 0.095s)
             Mean action noise std: 4.18
          Mean value_function loss: 94.8294
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 85.6434
                       Mean reward: 673.21
               Mean episode length: 227.70
    Episode_Reward/reaching_object: 1.6515
    Episode_Reward/rotating_object: 135.5545
        Episode_Reward/action_rate: -0.1215
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 2.16s
                      Time elapsed: 00:51:01
                               ETA: 00:07:26

################################################################################
                     [1m Learning iteration 1310/1500 [0m                     

                       Computation: 45413 steps/s (collection: 2.045s, learning 0.120s)
             Mean action noise std: 4.18
          Mean value_function loss: 77.4138
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 85.6590
                       Mean reward: 688.18
               Mean episode length: 229.47
    Episode_Reward/reaching_object: 1.6822
    Episode_Reward/rotating_object: 138.4044
        Episode_Reward/action_rate: -0.1239
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 2.16s
                      Time elapsed: 00:51:03
                               ETA: 00:07:23

################################################################################
                     [1m Learning iteration 1311/1500 [0m                     

                       Computation: 43394 steps/s (collection: 2.084s, learning 0.181s)
             Mean action noise std: 4.19
          Mean value_function loss: 76.7638
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 85.6835
                       Mean reward: 642.58
               Mean episode length: 225.11
    Episode_Reward/reaching_object: 1.6508
    Episode_Reward/rotating_object: 134.3841
        Episode_Reward/action_rate: -0.1223
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 2.27s
                      Time elapsed: 00:51:05
                               ETA: 00:07:21

################################################################################
                     [1m Learning iteration 1312/1500 [0m                     

                       Computation: 43919 steps/s (collection: 2.105s, learning 0.133s)
             Mean action noise std: 4.19
          Mean value_function loss: 86.9880
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 85.7026
                       Mean reward: 691.48
               Mean episode length: 229.60
    Episode_Reward/reaching_object: 1.6143
    Episode_Reward/rotating_object: 132.1958
        Episode_Reward/action_rate: -0.1201
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 2.24s
                      Time elapsed: 00:51:07
                               ETA: 00:07:19

################################################################################
                     [1m Learning iteration 1313/1500 [0m                     

                       Computation: 44510 steps/s (collection: 2.087s, learning 0.122s)
             Mean action noise std: 4.19
          Mean value_function loss: 84.4052
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 85.7268
                       Mean reward: 670.11
               Mean episode length: 226.97
    Episode_Reward/reaching_object: 1.6421
    Episode_Reward/rotating_object: 134.1855
        Episode_Reward/action_rate: -0.1224
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 2.21s
                      Time elapsed: 00:51:10
                               ETA: 00:07:16

################################################################################
                     [1m Learning iteration 1314/1500 [0m                     

                       Computation: 44332 steps/s (collection: 2.085s, learning 0.133s)
             Mean action noise std: 4.19
          Mean value_function loss: 97.5613
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 85.7454
                       Mean reward: 682.90
               Mean episode length: 238.85
    Episode_Reward/reaching_object: 1.6272
    Episode_Reward/rotating_object: 128.6711
        Episode_Reward/action_rate: -0.1215
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 2.22s
                      Time elapsed: 00:51:12
                               ETA: 00:07:14

################################################################################
                     [1m Learning iteration 1315/1500 [0m                     

                       Computation: 45109 steps/s (collection: 2.056s, learning 0.124s)
             Mean action noise std: 4.20
          Mean value_function loss: 93.4880
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 85.7538
                       Mean reward: 666.35
               Mean episode length: 231.37
    Episode_Reward/reaching_object: 1.6421
    Episode_Reward/rotating_object: 131.1943
        Episode_Reward/action_rate: -0.1229
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 2.18s
                      Time elapsed: 00:51:14
                               ETA: 00:07:12

################################################################################
                     [1m Learning iteration 1316/1500 [0m                     

                       Computation: 43012 steps/s (collection: 2.115s, learning 0.170s)
             Mean action noise std: 4.20
          Mean value_function loss: 86.5466
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 85.7700
                       Mean reward: 702.83
               Mean episode length: 235.64
    Episode_Reward/reaching_object: 1.6771
    Episode_Reward/rotating_object: 137.8407
        Episode_Reward/action_rate: -0.1247
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 2.29s
                      Time elapsed: 00:51:16
                               ETA: 00:07:09

################################################################################
                     [1m Learning iteration 1317/1500 [0m                     

                       Computation: 44533 steps/s (collection: 2.090s, learning 0.118s)
             Mean action noise std: 4.20
          Mean value_function loss: 82.8626
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 85.7965
                       Mean reward: 635.77
               Mean episode length: 230.34
    Episode_Reward/reaching_object: 1.6643
    Episode_Reward/rotating_object: 133.5802
        Episode_Reward/action_rate: -0.1243
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 2.21s
                      Time elapsed: 00:51:18
                               ETA: 00:07:07

################################################################################
                     [1m Learning iteration 1318/1500 [0m                     

                       Computation: 45206 steps/s (collection: 2.078s, learning 0.097s)
             Mean action noise std: 4.20
          Mean value_function loss: 86.3711
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 85.8140
                       Mean reward: 659.30
               Mean episode length: 232.02
    Episode_Reward/reaching_object: 1.6504
    Episode_Reward/rotating_object: 132.1889
        Episode_Reward/action_rate: -0.1234
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 2.17s
                      Time elapsed: 00:51:21
                               ETA: 00:07:05

################################################################################
                     [1m Learning iteration 1319/1500 [0m                     

                       Computation: 41608 steps/s (collection: 2.214s, learning 0.149s)
             Mean action noise std: 4.21
          Mean value_function loss: 101.1228
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 85.8264
                       Mean reward: 691.44
               Mean episode length: 231.42
    Episode_Reward/reaching_object: 1.6691
    Episode_Reward/rotating_object: 137.7805
        Episode_Reward/action_rate: -0.1248
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 2.36s
                      Time elapsed: 00:51:23
                               ETA: 00:07:02

################################################################################
                     [1m Learning iteration 1320/1500 [0m                     

                       Computation: 43587 steps/s (collection: 2.070s, learning 0.185s)
             Mean action noise std: 4.21
          Mean value_function loss: 97.2181
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 85.8425
                       Mean reward: 639.46
               Mean episode length: 226.11
    Episode_Reward/reaching_object: 1.6240
    Episode_Reward/rotating_object: 131.7808
        Episode_Reward/action_rate: -0.1221
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 2.26s
                      Time elapsed: 00:51:25
                               ETA: 00:07:00

################################################################################
                     [1m Learning iteration 1321/1500 [0m                     

                       Computation: 44778 steps/s (collection: 2.074s, learning 0.121s)
             Mean action noise std: 4.21
          Mean value_function loss: 83.8383
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 85.8536
                       Mean reward: 685.90
               Mean episode length: 239.65
    Episode_Reward/reaching_object: 1.6871
    Episode_Reward/rotating_object: 138.2391
        Episode_Reward/action_rate: -0.1266
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 2.20s
                      Time elapsed: 00:51:27
                               ETA: 00:06:58

################################################################################
                     [1m Learning iteration 1322/1500 [0m                     

                       Computation: 45288 steps/s (collection: 2.060s, learning 0.111s)
             Mean action noise std: 4.21
          Mean value_function loss: 80.0087
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 85.8641
                       Mean reward: 735.73
               Mean episode length: 241.05
    Episode_Reward/reaching_object: 1.6469
    Episode_Reward/rotating_object: 135.0642
        Episode_Reward/action_rate: -0.1236
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 2.17s
                      Time elapsed: 00:51:30
                               ETA: 00:06:55

################################################################################
                     [1m Learning iteration 1323/1500 [0m                     

                       Computation: 44065 steps/s (collection: 2.125s, learning 0.106s)
             Mean action noise std: 4.22
          Mean value_function loss: 85.1059
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 85.8775
                       Mean reward: 679.90
               Mean episode length: 237.74
    Episode_Reward/reaching_object: 1.6515
    Episode_Reward/rotating_object: 133.5749
        Episode_Reward/action_rate: -0.1246
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 2.23s
                      Time elapsed: 00:51:32
                               ETA: 00:06:53

################################################################################
                     [1m Learning iteration 1324/1500 [0m                     

                       Computation: 42015 steps/s (collection: 2.164s, learning 0.175s)
             Mean action noise std: 4.22
          Mean value_function loss: 84.4289
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 85.8949
                       Mean reward: 686.90
               Mean episode length: 239.62
    Episode_Reward/reaching_object: 1.6807
    Episode_Reward/rotating_object: 138.3154
        Episode_Reward/action_rate: -0.1260
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 2.34s
                      Time elapsed: 00:51:34
                               ETA: 00:06:51

################################################################################
                     [1m Learning iteration 1325/1500 [0m                     

                       Computation: 44294 steps/s (collection: 2.068s, learning 0.152s)
             Mean action noise std: 4.22
          Mean value_function loss: 86.0972
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 85.9156
                       Mean reward: 659.99
               Mean episode length: 228.70
    Episode_Reward/reaching_object: 1.6254
    Episode_Reward/rotating_object: 131.5636
        Episode_Reward/action_rate: -0.1232
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 2.22s
                      Time elapsed: 00:51:36
                               ETA: 00:06:48

################################################################################
                     [1m Learning iteration 1326/1500 [0m                     

                       Computation: 44516 steps/s (collection: 2.109s, learning 0.100s)
             Mean action noise std: 4.22
          Mean value_function loss: 84.6495
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 85.9406
                       Mean reward: 638.63
               Mean episode length: 228.56
    Episode_Reward/reaching_object: 1.6387
    Episode_Reward/rotating_object: 128.4485
        Episode_Reward/action_rate: -0.1248
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 2.21s
                      Time elapsed: 00:51:39
                               ETA: 00:06:46

################################################################################
                     [1m Learning iteration 1327/1500 [0m                     

                       Computation: 46158 steps/s (collection: 2.025s, learning 0.104s)
             Mean action noise std: 4.23
          Mean value_function loss: 83.7108
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 85.9581
                       Mean reward: 655.90
               Mean episode length: 232.16
    Episode_Reward/reaching_object: 1.6356
    Episode_Reward/rotating_object: 132.9559
        Episode_Reward/action_rate: -0.1240
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 2.13s
                      Time elapsed: 00:51:41
                               ETA: 00:06:44

################################################################################
                     [1m Learning iteration 1328/1500 [0m                     

                       Computation: 44193 steps/s (collection: 2.125s, learning 0.100s)
             Mean action noise std: 4.23
          Mean value_function loss: 75.0745
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 85.9752
                       Mean reward: 648.65
               Mean episode length: 234.02
    Episode_Reward/reaching_object: 1.6413
    Episode_Reward/rotating_object: 131.5027
        Episode_Reward/action_rate: -0.1247
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 2.22s
                      Time elapsed: 00:51:43
                               ETA: 00:06:41

################################################################################
                     [1m Learning iteration 1329/1500 [0m                     

                       Computation: 42484 steps/s (collection: 2.144s, learning 0.170s)
             Mean action noise std: 4.23
          Mean value_function loss: 93.8462
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 85.9847
                       Mean reward: 668.99
               Mean episode length: 230.49
    Episode_Reward/reaching_object: 1.6539
    Episode_Reward/rotating_object: 134.8677
        Episode_Reward/action_rate: -0.1258
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 2.31s
                      Time elapsed: 00:51:45
                               ETA: 00:06:39

################################################################################
                     [1m Learning iteration 1330/1500 [0m                     

                       Computation: 43466 steps/s (collection: 2.149s, learning 0.113s)
             Mean action noise std: 4.23
          Mean value_function loss: 83.3225
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 85.9927
                       Mean reward: 685.97
               Mean episode length: 234.25
    Episode_Reward/reaching_object: 1.6663
    Episode_Reward/rotating_object: 135.6801
        Episode_Reward/action_rate: -0.1266
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 2.26s
                      Time elapsed: 00:51:48
                               ETA: 00:06:36

################################################################################
                     [1m Learning iteration 1331/1500 [0m                     

                       Computation: 44366 steps/s (collection: 2.102s, learning 0.114s)
             Mean action noise std: 4.24
          Mean value_function loss: 82.6709
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 86.0037
                       Mean reward: 677.37
               Mean episode length: 237.64
    Episode_Reward/reaching_object: 1.6626
    Episode_Reward/rotating_object: 133.3741
        Episode_Reward/action_rate: -0.1263
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 2.22s
                      Time elapsed: 00:51:50
                               ETA: 00:06:34

################################################################################
                     [1m Learning iteration 1332/1500 [0m                     

                       Computation: 42147 steps/s (collection: 2.215s, learning 0.118s)
             Mean action noise std: 4.24
          Mean value_function loss: 94.8702
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 86.0229
                       Mean reward: 683.04
               Mean episode length: 228.05
    Episode_Reward/reaching_object: 1.6403
    Episode_Reward/rotating_object: 134.9717
        Episode_Reward/action_rate: -0.1248
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 2.33s
                      Time elapsed: 00:51:52
                               ETA: 00:06:32

################################################################################
                     [1m Learning iteration 1333/1500 [0m                     

                       Computation: 19234 steps/s (collection: 4.995s, learning 0.115s)
             Mean action noise std: 4.24
          Mean value_function loss: 71.2061
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 86.0451
                       Mean reward: 672.56
               Mean episode length: 235.26
    Episode_Reward/reaching_object: 1.6659
    Episode_Reward/rotating_object: 133.9343
        Episode_Reward/action_rate: -0.1268
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 5.11s
                      Time elapsed: 00:51:57
                               ETA: 00:06:30

################################################################################
                     [1m Learning iteration 1334/1500 [0m                     

                       Computation: 14169 steps/s (collection: 6.808s, learning 0.130s)
             Mean action noise std: 4.24
          Mean value_function loss: 96.0969
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 86.0613
                       Mean reward: 648.17
               Mean episode length: 231.06
    Episode_Reward/reaching_object: 1.6872
    Episode_Reward/rotating_object: 136.5023
        Episode_Reward/action_rate: -0.1281
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 6.94s
                      Time elapsed: 00:52:04
                               ETA: 00:06:28

################################################################################
                     [1m Learning iteration 1335/1500 [0m                     

                       Computation: 14135 steps/s (collection: 6.819s, learning 0.136s)
             Mean action noise std: 4.25
          Mean value_function loss: 87.5173
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 86.0783
                       Mean reward: 677.83
               Mean episode length: 231.02
    Episode_Reward/reaching_object: 1.6565
    Episode_Reward/rotating_object: 134.7217
        Episode_Reward/action_rate: -0.1262
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 6.95s
                      Time elapsed: 00:52:11
                               ETA: 00:06:26

################################################################################
                     [1m Learning iteration 1336/1500 [0m                     

                       Computation: 14311 steps/s (collection: 6.736s, learning 0.133s)
             Mean action noise std: 4.25
          Mean value_function loss: 102.2951
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 86.0981
                       Mean reward: 668.81
               Mean episode length: 230.69
    Episode_Reward/reaching_object: 1.6769
    Episode_Reward/rotating_object: 136.7911
        Episode_Reward/action_rate: -0.1275
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 6.87s
                      Time elapsed: 00:52:18
                               ETA: 00:06:24

################################################################################
                     [1m Learning iteration 1337/1500 [0m                     

                       Computation: 14545 steps/s (collection: 6.634s, learning 0.124s)
             Mean action noise std: 4.25
          Mean value_function loss: 83.3123
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 86.1218
                       Mean reward: 668.82
               Mean episode length: 231.01
    Episode_Reward/reaching_object: 1.6457
    Episode_Reward/rotating_object: 133.4250
        Episode_Reward/action_rate: -0.1260
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 6.76s
                      Time elapsed: 00:52:25
                               ETA: 00:06:23

################################################################################
                     [1m Learning iteration 1338/1500 [0m                     

                       Computation: 14288 steps/s (collection: 6.760s, learning 0.120s)
             Mean action noise std: 4.26
          Mean value_function loss: 90.3881
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 86.1425
                       Mean reward: 672.11
               Mean episode length: 234.76
    Episode_Reward/reaching_object: 1.6375
    Episode_Reward/rotating_object: 133.8030
        Episode_Reward/action_rate: -0.1260
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 6.88s
                      Time elapsed: 00:52:32
                               ETA: 00:06:21

################################################################################
                     [1m Learning iteration 1339/1500 [0m                     

                       Computation: 14575 steps/s (collection: 6.619s, learning 0.126s)
             Mean action noise std: 4.26
          Mean value_function loss: 74.5047
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 86.1687
                       Mean reward: 673.62
               Mean episode length: 231.71
    Episode_Reward/reaching_object: 1.6610
    Episode_Reward/rotating_object: 135.6681
        Episode_Reward/action_rate: -0.1272
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 6.74s
                      Time elapsed: 00:52:38
                               ETA: 00:06:19

################################################################################
                     [1m Learning iteration 1340/1500 [0m                     

                       Computation: 14542 steps/s (collection: 6.630s, learning 0.129s)
             Mean action noise std: 4.26
          Mean value_function loss: 100.0330
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 86.1896
                       Mean reward: 673.14
               Mean episode length: 229.50
    Episode_Reward/reaching_object: 1.6672
    Episode_Reward/rotating_object: 136.0920
        Episode_Reward/action_rate: -0.1278
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 6.76s
                      Time elapsed: 00:52:45
                               ETA: 00:06:17

################################################################################
                     [1m Learning iteration 1341/1500 [0m                     

                       Computation: 12861 steps/s (collection: 7.452s, learning 0.192s)
             Mean action noise std: 4.26
          Mean value_function loss: 90.1215
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 86.2059
                       Mean reward: 674.47
               Mean episode length: 226.18
    Episode_Reward/reaching_object: 1.6064
    Episode_Reward/rotating_object: 130.6910
        Episode_Reward/action_rate: -0.1236
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 7.64s
                      Time elapsed: 00:52:53
                               ETA: 00:06:15

################################################################################
                     [1m Learning iteration 1342/1500 [0m                     

                       Computation: 47115 steps/s (collection: 1.993s, learning 0.094s)
             Mean action noise std: 4.27
          Mean value_function loss: 101.6169
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 86.2255
                       Mean reward: 715.75
               Mean episode length: 235.26
    Episode_Reward/reaching_object: 1.6425
    Episode_Reward/rotating_object: 134.5742
        Episode_Reward/action_rate: -0.1263
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 2.09s
                      Time elapsed: 00:52:55
                               ETA: 00:06:13

################################################################################
                     [1m Learning iteration 1343/1500 [0m                     

                       Computation: 46574 steps/s (collection: 2.013s, learning 0.098s)
             Mean action noise std: 4.27
          Mean value_function loss: 83.2241
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 86.2424
                       Mean reward: 634.96
               Mean episode length: 229.82
    Episode_Reward/reaching_object: 1.6700
    Episode_Reward/rotating_object: 130.9536
        Episode_Reward/action_rate: -0.1288
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 2.11s
                      Time elapsed: 00:52:57
                               ETA: 00:06:11

################################################################################
                     [1m Learning iteration 1344/1500 [0m                     

                       Computation: 48475 steps/s (collection: 1.935s, learning 0.093s)
             Mean action noise std: 4.27
          Mean value_function loss: 92.0244
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 86.2600
                       Mean reward: 699.26
               Mean episode length: 237.61
    Episode_Reward/reaching_object: 1.6601
    Episode_Reward/rotating_object: 133.3820
        Episode_Reward/action_rate: -0.1280
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 2.03s
                      Time elapsed: 00:52:59
                               ETA: 00:06:08

################################################################################
                     [1m Learning iteration 1345/1500 [0m                     

                       Computation: 48830 steps/s (collection: 1.923s, learning 0.091s)
             Mean action noise std: 4.27
          Mean value_function loss: 91.0663
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 86.2742
                       Mean reward: 658.92
               Mean episode length: 228.04
    Episode_Reward/reaching_object: 1.6469
    Episode_Reward/rotating_object: 133.0683
        Episode_Reward/action_rate: -0.1273
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 2.01s
                      Time elapsed: 00:53:01
                               ETA: 00:06:06

################################################################################
                     [1m Learning iteration 1346/1500 [0m                     

                       Computation: 48336 steps/s (collection: 1.941s, learning 0.093s)
             Mean action noise std: 4.27
          Mean value_function loss: 96.4808
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 86.2795
                       Mean reward: 697.41
               Mean episode length: 236.10
    Episode_Reward/reaching_object: 1.6674
    Episode_Reward/rotating_object: 133.8457
        Episode_Reward/action_rate: -0.1288
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 2.03s
                      Time elapsed: 00:53:03
                               ETA: 00:06:03

################################################################################
                     [1m Learning iteration 1347/1500 [0m                     

                       Computation: 48816 steps/s (collection: 1.921s, learning 0.093s)
             Mean action noise std: 4.28
          Mean value_function loss: 87.4590
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 86.2873
                       Mean reward: 674.11
               Mean episode length: 229.68
    Episode_Reward/reaching_object: 1.6284
    Episode_Reward/rotating_object: 130.8486
        Episode_Reward/action_rate: -0.1261
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 2.01s
                      Time elapsed: 00:53:05
                               ETA: 00:06:01

################################################################################
                     [1m Learning iteration 1348/1500 [0m                     

                       Computation: 47920 steps/s (collection: 1.954s, learning 0.098s)
             Mean action noise std: 4.28
          Mean value_function loss: 81.1345
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 86.2950
                       Mean reward: 733.66
               Mean episode length: 240.72
    Episode_Reward/reaching_object: 1.7062
    Episode_Reward/rotating_object: 140.5926
        Episode_Reward/action_rate: -0.1312
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 2.05s
                      Time elapsed: 00:53:07
                               ETA: 00:05:59

################################################################################
                     [1m Learning iteration 1349/1500 [0m                     

                       Computation: 48406 steps/s (collection: 1.927s, learning 0.104s)
             Mean action noise std: 4.28
          Mean value_function loss: 78.8199
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 86.3137
                       Mean reward: 678.45
               Mean episode length: 236.46
    Episode_Reward/reaching_object: 1.6563
    Episode_Reward/rotating_object: 133.3655
        Episode_Reward/action_rate: -0.1280
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 2.03s
                      Time elapsed: 00:53:09
                               ETA: 00:05:56

################################################################################
                     [1m Learning iteration 1350/1500 [0m                     

                       Computation: 46567 steps/s (collection: 1.935s, learning 0.176s)
             Mean action noise std: 4.29
          Mean value_function loss: 83.1381
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 86.3387
                       Mean reward: 689.79
               Mean episode length: 237.92
    Episode_Reward/reaching_object: 1.6664
    Episode_Reward/rotating_object: 137.1169
        Episode_Reward/action_rate: -0.1292
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 2.11s
                      Time elapsed: 00:53:11
                               ETA: 00:05:54

################################################################################
                     [1m Learning iteration 1351/1500 [0m                     

                       Computation: 44541 steps/s (collection: 2.062s, learning 0.145s)
             Mean action noise std: 4.29
          Mean value_function loss: 84.5119
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 86.3652
                       Mean reward: 694.77
               Mean episode length: 234.01
    Episode_Reward/reaching_object: 1.6676
    Episode_Reward/rotating_object: 137.4330
        Episode_Reward/action_rate: -0.1298
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 2.21s
                      Time elapsed: 00:53:13
                               ETA: 00:05:51

################################################################################
                     [1m Learning iteration 1352/1500 [0m                     

                       Computation: 45599 steps/s (collection: 1.999s, learning 0.157s)
             Mean action noise std: 4.29
          Mean value_function loss: 84.5739
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 86.3875
                       Mean reward: 727.83
               Mean episode length: 242.74
    Episode_Reward/reaching_object: 1.6713
    Episode_Reward/rotating_object: 137.2008
        Episode_Reward/action_rate: -0.1296
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 2.16s
                      Time elapsed: 00:53:16
                               ETA: 00:05:49

################################################################################
                     [1m Learning iteration 1353/1500 [0m                     

                       Computation: 46835 steps/s (collection: 1.990s, learning 0.109s)
             Mean action noise std: 4.29
          Mean value_function loss: 74.4453
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 86.3991
                       Mean reward: 667.72
               Mean episode length: 234.41
    Episode_Reward/reaching_object: 1.6829
    Episode_Reward/rotating_object: 137.6945
        Episode_Reward/action_rate: -0.1312
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 2.10s
                      Time elapsed: 00:53:18
                               ETA: 00:05:47

################################################################################
                     [1m Learning iteration 1354/1500 [0m                     

                       Computation: 47343 steps/s (collection: 1.937s, learning 0.139s)
             Mean action noise std: 4.30
          Mean value_function loss: 88.1303
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 86.4143
                       Mean reward: 673.31
               Mean episode length: 226.99
    Episode_Reward/reaching_object: 1.6442
    Episode_Reward/rotating_object: 133.5636
        Episode_Reward/action_rate: -0.1284
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 2.08s
                      Time elapsed: 00:53:20
                               ETA: 00:05:44

################################################################################
                     [1m Learning iteration 1355/1500 [0m                     

                       Computation: 43601 steps/s (collection: 2.134s, learning 0.121s)
             Mean action noise std: 4.30
          Mean value_function loss: 69.9510
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 86.4359
                       Mean reward: 696.77
               Mean episode length: 233.95
    Episode_Reward/reaching_object: 1.6583
    Episode_Reward/rotating_object: 136.7708
        Episode_Reward/action_rate: -0.1297
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 2.25s
                      Time elapsed: 00:53:22
                               ETA: 00:05:42

################################################################################
                     [1m Learning iteration 1356/1500 [0m                     

                       Computation: 49064 steps/s (collection: 1.902s, learning 0.101s)
             Mean action noise std: 4.30
          Mean value_function loss: 74.3438
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 86.4584
                       Mean reward: 692.56
               Mean episode length: 243.22
    Episode_Reward/reaching_object: 1.6728
    Episode_Reward/rotating_object: 133.9864
        Episode_Reward/action_rate: -0.1312
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 2.00s
                      Time elapsed: 00:53:24
                               ETA: 00:05:40

################################################################################
                     [1m Learning iteration 1357/1500 [0m                     

                       Computation: 46835 steps/s (collection: 1.960s, learning 0.139s)
             Mean action noise std: 4.31
          Mean value_function loss: 82.9440
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 86.4800
                       Mean reward: 707.38
               Mean episode length: 239.35
    Episode_Reward/reaching_object: 1.6708
    Episode_Reward/rotating_object: 136.1405
        Episode_Reward/action_rate: -0.1310
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 2.10s
                      Time elapsed: 00:53:26
                               ETA: 00:05:37

################################################################################
                     [1m Learning iteration 1358/1500 [0m                     

                       Computation: 47586 steps/s (collection: 1.953s, learning 0.113s)
             Mean action noise std: 4.31
          Mean value_function loss: 70.0470
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 86.5025
                       Mean reward: 707.12
               Mean episode length: 234.91
    Episode_Reward/reaching_object: 1.6705
    Episode_Reward/rotating_object: 137.7553
        Episode_Reward/action_rate: -0.1317
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 2.07s
                      Time elapsed: 00:53:28
                               ETA: 00:05:35

################################################################################
                     [1m Learning iteration 1359/1500 [0m                     

                       Computation: 46477 steps/s (collection: 1.975s, learning 0.141s)
             Mean action noise std: 4.31
          Mean value_function loss: 62.8981
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 86.5167
                       Mean reward: 657.01
               Mean episode length: 228.86
    Episode_Reward/reaching_object: 1.6642
    Episode_Reward/rotating_object: 135.7033
        Episode_Reward/action_rate: -0.1313
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 2.12s
                      Time elapsed: 00:53:30
                               ETA: 00:05:32

################################################################################
                     [1m Learning iteration 1360/1500 [0m                     

                       Computation: 48177 steps/s (collection: 1.931s, learning 0.110s)
             Mean action noise std: 4.31
          Mean value_function loss: 63.2285
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 86.5400
                       Mean reward: 676.43
               Mean episode length: 234.85
    Episode_Reward/reaching_object: 1.6546
    Episode_Reward/rotating_object: 133.3692
        Episode_Reward/action_rate: -0.1309
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 2.04s
                      Time elapsed: 00:53:32
                               ETA: 00:05:30

################################################################################
                     [1m Learning iteration 1361/1500 [0m                     

                       Computation: 48130 steps/s (collection: 1.942s, learning 0.100s)
             Mean action noise std: 4.32
          Mean value_function loss: 63.8742
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 86.5636
                       Mean reward: 730.35
               Mean episode length: 241.43
    Episode_Reward/reaching_object: 1.6998
    Episode_Reward/rotating_object: 140.5308
        Episode_Reward/action_rate: -0.1344
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 2.04s
                      Time elapsed: 00:53:34
                               ETA: 00:05:28

################################################################################
                     [1m Learning iteration 1362/1500 [0m                     

                       Computation: 48384 steps/s (collection: 1.940s, learning 0.092s)
             Mean action noise std: 4.32
          Mean value_function loss: 69.4795
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 86.5877
                       Mean reward: 698.44
               Mean episode length: 236.05
    Episode_Reward/reaching_object: 1.6569
    Episode_Reward/rotating_object: 135.3851
        Episode_Reward/action_rate: -0.1327
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 2.03s
                      Time elapsed: 00:53:36
                               ETA: 00:05:25

################################################################################
                     [1m Learning iteration 1363/1500 [0m                     

                       Computation: 48955 steps/s (collection: 1.918s, learning 0.091s)
             Mean action noise std: 4.32
          Mean value_function loss: 71.4191
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 86.6052
                       Mean reward: 708.42
               Mean episode length: 237.12
    Episode_Reward/reaching_object: 1.6377
    Episode_Reward/rotating_object: 135.3215
        Episode_Reward/action_rate: -0.1311
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 2.01s
                      Time elapsed: 00:53:38
                               ETA: 00:05:23

################################################################################
                     [1m Learning iteration 1364/1500 [0m                     

                       Computation: 47631 steps/s (collection: 1.961s, learning 0.102s)
             Mean action noise std: 4.32
          Mean value_function loss: 94.6474
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 86.6188
                       Mean reward: 645.82
               Mean episode length: 221.11
    Episode_Reward/reaching_object: 1.6118
    Episode_Reward/rotating_object: 131.5521
        Episode_Reward/action_rate: -0.1292
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 2.06s
                      Time elapsed: 00:53:40
                               ETA: 00:05:20

################################################################################
                     [1m Learning iteration 1365/1500 [0m                     

                       Computation: 48142 steps/s (collection: 1.939s, learning 0.103s)
             Mean action noise std: 4.33
          Mean value_function loss: 63.4336
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 86.6378
                       Mean reward: 707.18
               Mean episode length: 239.63
    Episode_Reward/reaching_object: 1.6817
    Episode_Reward/rotating_object: 139.4386
        Episode_Reward/action_rate: -0.1344
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 2.04s
                      Time elapsed: 00:53:43
                               ETA: 00:05:18

################################################################################
                     [1m Learning iteration 1366/1500 [0m                     

                       Computation: 49084 steps/s (collection: 1.908s, learning 0.095s)
             Mean action noise std: 4.33
          Mean value_function loss: 88.8578
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 86.6496
                       Mean reward: 675.66
               Mean episode length: 239.13
    Episode_Reward/reaching_object: 1.6539
    Episode_Reward/rotating_object: 134.1054
        Episode_Reward/action_rate: -0.1325
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 2.00s
                      Time elapsed: 00:53:45
                               ETA: 00:05:16

################################################################################
                     [1m Learning iteration 1367/1500 [0m                     

                       Computation: 49613 steps/s (collection: 1.880s, learning 0.101s)
             Mean action noise std: 4.33
          Mean value_function loss: 87.5802
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 86.6615
                       Mean reward: 664.93
               Mean episode length: 235.78
    Episode_Reward/reaching_object: 1.6669
    Episode_Reward/rotating_object: 136.4621
        Episode_Reward/action_rate: -0.1334
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 1.98s
                      Time elapsed: 00:53:47
                               ETA: 00:05:13

################################################################################
                     [1m Learning iteration 1368/1500 [0m                     

                       Computation: 48961 steps/s (collection: 1.918s, learning 0.090s)
             Mean action noise std: 4.33
          Mean value_function loss: 67.2437
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 86.6764
                       Mean reward: 658.84
               Mean episode length: 232.45
    Episode_Reward/reaching_object: 1.6387
    Episode_Reward/rotating_object: 135.3049
        Episode_Reward/action_rate: -0.1319
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 2.01s
                      Time elapsed: 00:53:49
                               ETA: 00:05:11

################################################################################
                     [1m Learning iteration 1369/1500 [0m                     

                       Computation: 49080 steps/s (collection: 1.907s, learning 0.096s)
             Mean action noise std: 4.34
          Mean value_function loss: 81.1290
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 86.6928
                       Mean reward: 686.32
               Mean episode length: 234.35
    Episode_Reward/reaching_object: 1.6175
    Episode_Reward/rotating_object: 130.8684
        Episode_Reward/action_rate: -0.1304
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 2.00s
                      Time elapsed: 00:53:51
                               ETA: 00:05:08

################################################################################
                     [1m Learning iteration 1370/1500 [0m                     

                       Computation: 45710 steps/s (collection: 2.023s, learning 0.127s)
             Mean action noise std: 4.34
          Mean value_function loss: 82.6772
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 86.7113
                       Mean reward: 679.56
               Mean episode length: 234.44
    Episode_Reward/reaching_object: 1.6279
    Episode_Reward/rotating_object: 131.2458
        Episode_Reward/action_rate: -0.1309
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 2.15s
                      Time elapsed: 00:53:53
                               ETA: 00:05:06

################################################################################
                     [1m Learning iteration 1371/1500 [0m                     

                       Computation: 47387 steps/s (collection: 1.944s, learning 0.130s)
             Mean action noise std: 4.34
          Mean value_function loss: 78.8042
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 86.7260
                       Mean reward: 689.84
               Mean episode length: 232.15
    Episode_Reward/reaching_object: 1.6526
    Episode_Reward/rotating_object: 135.8413
        Episode_Reward/action_rate: -0.1331
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 2.07s
                      Time elapsed: 00:53:55
                               ETA: 00:05:04

################################################################################
                     [1m Learning iteration 1372/1500 [0m                     

                       Computation: 45050 steps/s (collection: 2.036s, learning 0.146s)
             Mean action noise std: 4.34
          Mean value_function loss: 85.3978
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 86.7460
                       Mean reward: 719.28
               Mean episode length: 239.41
    Episode_Reward/reaching_object: 1.6589
    Episode_Reward/rotating_object: 136.5083
        Episode_Reward/action_rate: -0.1339
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 2.18s
                      Time elapsed: 00:53:57
                               ETA: 00:05:01

################################################################################
                     [1m Learning iteration 1373/1500 [0m                     

                       Computation: 47524 steps/s (collection: 1.975s, learning 0.093s)
             Mean action noise std: 4.35
          Mean value_function loss: 78.3681
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 86.7670
                       Mean reward: 692.15
               Mean episode length: 236.80
    Episode_Reward/reaching_object: 1.6450
    Episode_Reward/rotating_object: 135.0003
        Episode_Reward/action_rate: -0.1334
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 2.07s
                      Time elapsed: 00:53:59
                               ETA: 00:04:59

################################################################################
                     [1m Learning iteration 1374/1500 [0m                     

                       Computation: 45742 steps/s (collection: 2.012s, learning 0.138s)
             Mean action noise std: 4.35
          Mean value_function loss: 76.7550
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 86.7826
                       Mean reward: 680.55
               Mean episode length: 232.61
    Episode_Reward/reaching_object: 1.6549
    Episode_Reward/rotating_object: 135.8802
        Episode_Reward/action_rate: -0.1337
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 2.15s
                      Time elapsed: 00:54:01
                               ETA: 00:04:57

################################################################################
                     [1m Learning iteration 1375/1500 [0m                     

                       Computation: 47853 steps/s (collection: 1.958s, learning 0.096s)
             Mean action noise std: 4.35
          Mean value_function loss: 85.0704
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 86.8027
                       Mean reward: 686.64
               Mean episode length: 241.05
    Episode_Reward/reaching_object: 1.6541
    Episode_Reward/rotating_object: 131.1150
        Episode_Reward/action_rate: -0.1341
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 2.05s
                      Time elapsed: 00:54:03
                               ETA: 00:04:54

################################################################################
                     [1m Learning iteration 1376/1500 [0m                     

                       Computation: 46787 steps/s (collection: 1.988s, learning 0.113s)
             Mean action noise std: 4.36
          Mean value_function loss: 83.3268
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 86.8179
                       Mean reward: 717.93
               Mean episode length: 238.90
    Episode_Reward/reaching_object: 1.6428
    Episode_Reward/rotating_object: 134.0264
        Episode_Reward/action_rate: -0.1334
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 2.10s
                      Time elapsed: 00:54:05
                               ETA: 00:04:52

################################################################################
                     [1m Learning iteration 1377/1500 [0m                     

                       Computation: 46963 steps/s (collection: 1.998s, learning 0.095s)
             Mean action noise std: 4.36
          Mean value_function loss: 83.3158
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 86.8330
                       Mean reward: 692.20
               Mean episode length: 231.54
    Episode_Reward/reaching_object: 1.6441
    Episode_Reward/rotating_object: 138.0405
        Episode_Reward/action_rate: -0.1331
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 2.09s
                      Time elapsed: 00:54:07
                               ETA: 00:04:49

################################################################################
                     [1m Learning iteration 1378/1500 [0m                     

                       Computation: 48276 steps/s (collection: 1.944s, learning 0.092s)
             Mean action noise std: 4.36
          Mean value_function loss: 83.5582
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 86.8476
                       Mean reward: 688.42
               Mean episode length: 233.51
    Episode_Reward/reaching_object: 1.6280
    Episode_Reward/rotating_object: 134.3899
        Episode_Reward/action_rate: -0.1322
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 2.04s
                      Time elapsed: 00:54:09
                               ETA: 00:04:47

################################################################################
                     [1m Learning iteration 1379/1500 [0m                     

                       Computation: 46487 steps/s (collection: 2.000s, learning 0.114s)
             Mean action noise std: 4.36
          Mean value_function loss: 77.9979
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 86.8636
                       Mean reward: 710.69
               Mean episode length: 238.31
    Episode_Reward/reaching_object: 1.6368
    Episode_Reward/rotating_object: 134.6078
        Episode_Reward/action_rate: -0.1327
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 2.11s
                      Time elapsed: 00:54:12
                               ETA: 00:04:45

################################################################################
                     [1m Learning iteration 1380/1500 [0m                     

                       Computation: 47354 steps/s (collection: 1.969s, learning 0.107s)
             Mean action noise std: 4.36
          Mean value_function loss: 72.0400
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 86.8730
                       Mean reward: 697.81
               Mean episode length: 239.33
    Episode_Reward/reaching_object: 1.6451
    Episode_Reward/rotating_object: 134.7906
        Episode_Reward/action_rate: -0.1338
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 2.08s
                      Time elapsed: 00:54:14
                               ETA: 00:04:42

################################################################################
                     [1m Learning iteration 1381/1500 [0m                     

                       Computation: 48629 steps/s (collection: 1.912s, learning 0.109s)
             Mean action noise std: 4.37
          Mean value_function loss: 85.7673
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 86.8807
                       Mean reward: 724.78
               Mean episode length: 242.00
    Episode_Reward/reaching_object: 1.6473
    Episode_Reward/rotating_object: 136.2719
        Episode_Reward/action_rate: -0.1339
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 2.02s
                      Time elapsed: 00:54:16
                               ETA: 00:04:40

################################################################################
                     [1m Learning iteration 1382/1500 [0m                     

                       Computation: 48349 steps/s (collection: 1.939s, learning 0.095s)
             Mean action noise std: 4.37
          Mean value_function loss: 68.3375
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 86.8998
                       Mean reward: 699.87
               Mean episode length: 236.90
    Episode_Reward/reaching_object: 1.6304
    Episode_Reward/rotating_object: 132.5780
        Episode_Reward/action_rate: -0.1341
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 2.03s
                      Time elapsed: 00:54:18
                               ETA: 00:04:37

################################################################################
                     [1m Learning iteration 1383/1500 [0m                     

                       Computation: 48047 steps/s (collection: 1.933s, learning 0.113s)
             Mean action noise std: 4.37
          Mean value_function loss: 74.9013
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 86.9117
                       Mean reward: 692.55
               Mean episode length: 239.57
    Episode_Reward/reaching_object: 1.6420
    Episode_Reward/rotating_object: 134.4974
        Episode_Reward/action_rate: -0.1338
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 2.05s
                      Time elapsed: 00:54:20
                               ETA: 00:04:35

################################################################################
                     [1m Learning iteration 1384/1500 [0m                     

                       Computation: 45799 steps/s (collection: 2.004s, learning 0.143s)
             Mean action noise std: 4.37
          Mean value_function loss: 93.8813
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 86.9288
                       Mean reward: 686.41
               Mean episode length: 234.65
    Episode_Reward/reaching_object: 1.6416
    Episode_Reward/rotating_object: 136.1265
        Episode_Reward/action_rate: -0.1343
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 2.15s
                      Time elapsed: 00:54:22
                               ETA: 00:04:33

################################################################################
                     [1m Learning iteration 1385/1500 [0m                     

                       Computation: 46551 steps/s (collection: 1.953s, learning 0.159s)
             Mean action noise std: 4.38
          Mean value_function loss: 86.1247
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 86.9489
                       Mean reward: 684.18
               Mean episode length: 227.88
    Episode_Reward/reaching_object: 1.6420
    Episode_Reward/rotating_object: 137.2250
        Episode_Reward/action_rate: -0.1331
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 2.11s
                      Time elapsed: 00:54:24
                               ETA: 00:04:30

################################################################################
                     [1m Learning iteration 1386/1500 [0m                     

                       Computation: 47532 steps/s (collection: 1.927s, learning 0.141s)
             Mean action noise std: 4.38
          Mean value_function loss: 91.3815
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 86.9665
                       Mean reward: 686.76
               Mean episode length: 232.36
    Episode_Reward/reaching_object: 1.6617
    Episode_Reward/rotating_object: 137.1315
        Episode_Reward/action_rate: -0.1350
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 2.07s
                      Time elapsed: 00:54:26
                               ETA: 00:04:28

################################################################################
                     [1m Learning iteration 1387/1500 [0m                     

                       Computation: 46834 steps/s (collection: 1.958s, learning 0.141s)
             Mean action noise std: 4.38
          Mean value_function loss: 82.8401
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 86.9851
                       Mean reward: 748.61
               Mean episode length: 243.63
    Episode_Reward/reaching_object: 1.6691
    Episode_Reward/rotating_object: 137.2096
        Episode_Reward/action_rate: -0.1362
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 2.10s
                      Time elapsed: 00:54:28
                               ETA: 00:04:26

################################################################################
                     [1m Learning iteration 1388/1500 [0m                     

                       Computation: 47303 steps/s (collection: 1.980s, learning 0.098s)
             Mean action noise std: 4.38
          Mean value_function loss: 85.0502
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 87.0001
                       Mean reward: 678.37
               Mean episode length: 229.04
    Episode_Reward/reaching_object: 1.6576
    Episode_Reward/rotating_object: 136.7029
        Episode_Reward/action_rate: -0.1346
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 2.08s
                      Time elapsed: 00:54:30
                               ETA: 00:04:23

################################################################################
                     [1m Learning iteration 1389/1500 [0m                     

                       Computation: 46320 steps/s (collection: 2.030s, learning 0.092s)
             Mean action noise std: 4.39
          Mean value_function loss: 104.0846
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 87.0170
                       Mean reward: 655.42
               Mean episode length: 228.86
    Episode_Reward/reaching_object: 1.6158
    Episode_Reward/rotating_object: 132.0684
        Episode_Reward/action_rate: -0.1320
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 2.12s
                      Time elapsed: 00:54:32
                               ETA: 00:04:21

################################################################################
                     [1m Learning iteration 1390/1500 [0m                     

                       Computation: 46543 steps/s (collection: 1.955s, learning 0.157s)
             Mean action noise std: 4.39
          Mean value_function loss: 105.8714
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 87.0351
                       Mean reward: 714.44
               Mean episode length: 240.45
    Episode_Reward/reaching_object: 1.6615
    Episode_Reward/rotating_object: 137.7359
        Episode_Reward/action_rate: -0.1349
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 2.11s
                      Time elapsed: 00:54:34
                               ETA: 00:04:18

################################################################################
                     [1m Learning iteration 1391/1500 [0m                     

                       Computation: 48007 steps/s (collection: 1.941s, learning 0.107s)
             Mean action noise std: 4.39
          Mean value_function loss: 91.5769
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 87.0575
                       Mean reward: 648.29
               Mean episode length: 224.89
    Episode_Reward/reaching_object: 1.6813
    Episode_Reward/rotating_object: 138.2415
        Episode_Reward/action_rate: -0.1365
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 2.05s
                      Time elapsed: 00:54:37
                               ETA: 00:04:16

################################################################################
                     [1m Learning iteration 1392/1500 [0m                     

                       Computation: 47167 steps/s (collection: 1.970s, learning 0.114s)
             Mean action noise std: 4.40
          Mean value_function loss: 103.9586
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 87.0704
                       Mean reward: 662.01
               Mean episode length: 222.01
    Episode_Reward/reaching_object: 1.6163
    Episode_Reward/rotating_object: 133.2558
        Episode_Reward/action_rate: -0.1321
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 2.08s
                      Time elapsed: 00:54:39
                               ETA: 00:04:14

################################################################################
                     [1m Learning iteration 1393/1500 [0m                     

                       Computation: 47175 steps/s (collection: 1.984s, learning 0.100s)
             Mean action noise std: 4.40
          Mean value_function loss: 92.9484
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 87.0895
                       Mean reward: 659.88
               Mean episode length: 230.32
    Episode_Reward/reaching_object: 1.6372
    Episode_Reward/rotating_object: 131.0486
        Episode_Reward/action_rate: -0.1343
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 2.08s
                      Time elapsed: 00:54:41
                               ETA: 00:04:11

################################################################################
                     [1m Learning iteration 1394/1500 [0m                     

                       Computation: 47666 steps/s (collection: 1.970s, learning 0.092s)
             Mean action noise std: 4.40
          Mean value_function loss: 93.7936
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 87.1107
                       Mean reward: 722.97
               Mean episode length: 238.43
    Episode_Reward/reaching_object: 1.6608
    Episode_Reward/rotating_object: 139.4483
        Episode_Reward/action_rate: -0.1355
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 2.06s
                      Time elapsed: 00:54:43
                               ETA: 00:04:09

################################################################################
                     [1m Learning iteration 1395/1500 [0m                     

                       Computation: 47357 steps/s (collection: 1.966s, learning 0.110s)
             Mean action noise std: 4.41
          Mean value_function loss: 86.0336
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 87.1373
                       Mean reward: 733.41
               Mean episode length: 240.96
    Episode_Reward/reaching_object: 1.6704
    Episode_Reward/rotating_object: 137.8613
        Episode_Reward/action_rate: -0.1363
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 2.08s
                      Time elapsed: 00:54:45
                               ETA: 00:04:07

################################################################################
                     [1m Learning iteration 1396/1500 [0m                     

                       Computation: 46386 steps/s (collection: 2.020s, learning 0.099s)
             Mean action noise std: 4.41
          Mean value_function loss: 77.6568
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 87.1640
                       Mean reward: 743.75
               Mean episode length: 239.81
    Episode_Reward/reaching_object: 1.6707
    Episode_Reward/rotating_object: 139.4145
        Episode_Reward/action_rate: -0.1365
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 2.12s
                      Time elapsed: 00:54:47
                               ETA: 00:04:04

################################################################################
                     [1m Learning iteration 1397/1500 [0m                     

                       Computation: 47184 steps/s (collection: 1.985s, learning 0.099s)
             Mean action noise std: 4.41
          Mean value_function loss: 91.1852
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 87.1780
                       Mean reward: 664.40
               Mean episode length: 234.43
    Episode_Reward/reaching_object: 1.6113
    Episode_Reward/rotating_object: 128.8904
        Episode_Reward/action_rate: -0.1328
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 2.08s
                      Time elapsed: 00:54:49
                               ETA: 00:04:02

################################################################################
                     [1m Learning iteration 1398/1500 [0m                     

                       Computation: 45459 steps/s (collection: 2.017s, learning 0.145s)
             Mean action noise std: 4.41
          Mean value_function loss: 94.7554
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 87.1908
                       Mean reward: 682.56
               Mean episode length: 230.28
    Episode_Reward/reaching_object: 1.6378
    Episode_Reward/rotating_object: 137.2581
        Episode_Reward/action_rate: -0.1350
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 2.16s
                      Time elapsed: 00:54:51
                               ETA: 00:03:59

################################################################################
                     [1m Learning iteration 1399/1500 [0m                     

                       Computation: 46603 steps/s (collection: 2.007s, learning 0.103s)
             Mean action noise std: 4.41
          Mean value_function loss: 103.7276
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 87.2061
                       Mean reward: 650.64
               Mean episode length: 227.39
    Episode_Reward/reaching_object: 1.6286
    Episode_Reward/rotating_object: 132.1656
        Episode_Reward/action_rate: -0.1348
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 2.11s
                      Time elapsed: 00:54:53
                               ETA: 00:03:57

################################################################################
                     [1m Learning iteration 1400/1500 [0m                     

                       Computation: 47552 steps/s (collection: 1.969s, learning 0.098s)
             Mean action noise std: 4.42
          Mean value_function loss: 105.1591
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 87.2220
                       Mean reward: 681.73
               Mean episode length: 230.23
    Episode_Reward/reaching_object: 1.6436
    Episode_Reward/rotating_object: 134.9638
        Episode_Reward/action_rate: -0.1351
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 2.07s
                      Time elapsed: 00:54:55
                               ETA: 00:03:55

################################################################################
                     [1m Learning iteration 1401/1500 [0m                     

                       Computation: 45669 steps/s (collection: 2.023s, learning 0.129s)
             Mean action noise std: 4.42
          Mean value_function loss: 83.9406
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 87.2355
                       Mean reward: 672.19
               Mean episode length: 228.96
    Episode_Reward/reaching_object: 1.6175
    Episode_Reward/rotating_object: 133.5126
        Episode_Reward/action_rate: -0.1341
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 2.15s
                      Time elapsed: 00:54:58
                               ETA: 00:03:52

################################################################################
                     [1m Learning iteration 1402/1500 [0m                     

                       Computation: 46003 steps/s (collection: 2.039s, learning 0.098s)
             Mean action noise std: 4.42
          Mean value_function loss: 87.9342
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 87.2470
                       Mean reward: 673.13
               Mean episode length: 228.92
    Episode_Reward/reaching_object: 1.6801
    Episode_Reward/rotating_object: 137.1104
        Episode_Reward/action_rate: -0.1390
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 2.14s
                      Time elapsed: 00:55:00
                               ETA: 00:03:50

################################################################################
                     [1m Learning iteration 1403/1500 [0m                     

                       Computation: 48637 steps/s (collection: 1.920s, learning 0.101s)
             Mean action noise std: 4.43
          Mean value_function loss: 71.1577
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 87.2639
                       Mean reward: 673.79
               Mean episode length: 233.97
    Episode_Reward/reaching_object: 1.6646
    Episode_Reward/rotating_object: 136.0399
        Episode_Reward/action_rate: -0.1376
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 2.02s
                      Time elapsed: 00:55:02
                               ETA: 00:03:48

################################################################################
                     [1m Learning iteration 1404/1500 [0m                     

                       Computation: 46167 steps/s (collection: 2.033s, learning 0.097s)
             Mean action noise std: 4.43
          Mean value_function loss: 85.4512
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 87.2891
                       Mean reward: 685.92
               Mean episode length: 230.44
    Episode_Reward/reaching_object: 1.6775
    Episode_Reward/rotating_object: 139.0792
        Episode_Reward/action_rate: -0.1387
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 2.13s
                      Time elapsed: 00:55:04
                               ETA: 00:03:45

################################################################################
                     [1m Learning iteration 1405/1500 [0m                     

                       Computation: 46506 steps/s (collection: 2.000s, learning 0.114s)
             Mean action noise std: 4.43
          Mean value_function loss: 83.1020
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 87.3121
                       Mean reward: 690.06
               Mean episode length: 230.04
    Episode_Reward/reaching_object: 1.6991
    Episode_Reward/rotating_object: 141.2648
        Episode_Reward/action_rate: -0.1402
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 2.11s
                      Time elapsed: 00:55:06
                               ETA: 00:03:43

################################################################################
                     [1m Learning iteration 1406/1500 [0m                     

                       Computation: 48062 steps/s (collection: 1.929s, learning 0.117s)
             Mean action noise std: 4.43
          Mean value_function loss: 86.9990
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 87.3343
                       Mean reward: 710.17
               Mean episode length: 236.56
    Episode_Reward/reaching_object: 1.6644
    Episode_Reward/rotating_object: 136.9506
        Episode_Reward/action_rate: -0.1378
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 2.05s
                      Time elapsed: 00:55:08
                               ETA: 00:03:41

################################################################################
                     [1m Learning iteration 1407/1500 [0m                     

                       Computation: 45303 steps/s (collection: 2.053s, learning 0.117s)
             Mean action noise std: 4.44
          Mean value_function loss: 63.2061
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 87.3556
                       Mean reward: 686.87
               Mean episode length: 231.90
    Episode_Reward/reaching_object: 1.6741
    Episode_Reward/rotating_object: 140.3892
        Episode_Reward/action_rate: -0.1391
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 2.17s
                      Time elapsed: 00:55:10
                               ETA: 00:03:38

################################################################################
                     [1m Learning iteration 1408/1500 [0m                     

                       Computation: 48149 steps/s (collection: 1.925s, learning 0.117s)
             Mean action noise std: 4.44
          Mean value_function loss: 79.0288
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 87.3752
                       Mean reward: 664.83
               Mean episode length: 223.54
    Episode_Reward/reaching_object: 1.6756
    Episode_Reward/rotating_object: 137.4401
        Episode_Reward/action_rate: -0.1391
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 2.04s
                      Time elapsed: 00:55:12
                               ETA: 00:03:36

################################################################################
                     [1m Learning iteration 1409/1500 [0m                     

                       Computation: 47139 steps/s (collection: 1.953s, learning 0.133s)
             Mean action noise std: 4.44
          Mean value_function loss: 84.7023
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 87.4005
                       Mean reward: 731.10
               Mean episode length: 240.79
    Episode_Reward/reaching_object: 1.6704
    Episode_Reward/rotating_object: 140.8358
        Episode_Reward/action_rate: -0.1393
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 2.09s
                      Time elapsed: 00:55:14
                               ETA: 00:03:33

################################################################################
                     [1m Learning iteration 1410/1500 [0m                     

                       Computation: 48094 steps/s (collection: 1.930s, learning 0.114s)
             Mean action noise std: 4.45
          Mean value_function loss: 65.8286
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 87.4162
                       Mean reward: 685.24
               Mean episode length: 234.70
    Episode_Reward/reaching_object: 1.6754
    Episode_Reward/rotating_object: 139.9271
        Episode_Reward/action_rate: -0.1401
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 2.04s
                      Time elapsed: 00:55:16
                               ETA: 00:03:31

################################################################################
                     [1m Learning iteration 1411/1500 [0m                     

                       Computation: 44843 steps/s (collection: 2.089s, learning 0.104s)
             Mean action noise std: 4.45
          Mean value_function loss: 79.9005
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 87.4280
                       Mean reward: 734.51
               Mean episode length: 240.22
    Episode_Reward/reaching_object: 1.6660
    Episode_Reward/rotating_object: 138.3841
        Episode_Reward/action_rate: -0.1395
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 2.19s
                      Time elapsed: 00:55:18
                               ETA: 00:03:29

################################################################################
                     [1m Learning iteration 1412/1500 [0m                     

                       Computation: 46236 steps/s (collection: 2.001s, learning 0.125s)
             Mean action noise std: 4.45
          Mean value_function loss: 80.8540
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 87.4324
                       Mean reward: 706.62
               Mean episode length: 237.45
    Episode_Reward/reaching_object: 1.6601
    Episode_Reward/rotating_object: 135.1460
        Episode_Reward/action_rate: -0.1391
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 2.13s
                      Time elapsed: 00:55:21
                               ETA: 00:03:26

################################################################################
                     [1m Learning iteration 1413/1500 [0m                     

                       Computation: 46027 steps/s (collection: 2.017s, learning 0.119s)
             Mean action noise std: 4.45
          Mean value_function loss: 98.1085
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 87.4415
                       Mean reward: 681.77
               Mean episode length: 231.38
    Episode_Reward/reaching_object: 1.6540
    Episode_Reward/rotating_object: 134.8091
        Episode_Reward/action_rate: -0.1390
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 2.14s
                      Time elapsed: 00:55:23
                               ETA: 00:03:24

################################################################################
                     [1m Learning iteration 1414/1500 [0m                     

                       Computation: 46674 steps/s (collection: 2.006s, learning 0.100s)
             Mean action noise std: 4.45
          Mean value_function loss: 85.9043
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 87.4567
                       Mean reward: 714.05
               Mean episode length: 237.25
    Episode_Reward/reaching_object: 1.6314
    Episode_Reward/rotating_object: 132.5459
        Episode_Reward/action_rate: -0.1379
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 2.11s
                      Time elapsed: 00:55:25
                               ETA: 00:03:22

################################################################################
                     [1m Learning iteration 1415/1500 [0m                     

                       Computation: 46437 steps/s (collection: 2.001s, learning 0.116s)
             Mean action noise std: 4.46
          Mean value_function loss: 85.7882
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 87.4703
                       Mean reward: 639.63
               Mean episode length: 221.43
    Episode_Reward/reaching_object: 1.6468
    Episode_Reward/rotating_object: 132.3797
        Episode_Reward/action_rate: -0.1389
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 2.12s
                      Time elapsed: 00:55:27
                               ETA: 00:03:19

################################################################################
                     [1m Learning iteration 1416/1500 [0m                     

                       Computation: 44217 steps/s (collection: 2.030s, learning 0.194s)
             Mean action noise std: 4.46
          Mean value_function loss: 90.5863
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 87.4838
                       Mean reward: 679.27
               Mean episode length: 231.77
    Episode_Reward/reaching_object: 1.6272
    Episode_Reward/rotating_object: 134.1978
        Episode_Reward/action_rate: -0.1374
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 2.22s
                      Time elapsed: 00:55:29
                               ETA: 00:03:17

################################################################################
                     [1m Learning iteration 1417/1500 [0m                     

                       Computation: 46002 steps/s (collection: 1.995s, learning 0.142s)
             Mean action noise std: 4.46
          Mean value_function loss: 84.0647
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 87.5033
                       Mean reward: 694.21
               Mean episode length: 231.68
    Episode_Reward/reaching_object: 1.6899
    Episode_Reward/rotating_object: 140.2733
        Episode_Reward/action_rate: -0.1414
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 2.14s
                      Time elapsed: 00:55:31
                               ETA: 00:03:15

################################################################################
                     [1m Learning iteration 1418/1500 [0m                     

                       Computation: 46953 steps/s (collection: 1.985s, learning 0.109s)
             Mean action noise std: 4.46
          Mean value_function loss: 91.8830
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 87.5160
                       Mean reward: 603.38
               Mean episode length: 229.10
    Episode_Reward/reaching_object: 1.6411
    Episode_Reward/rotating_object: 131.6448
        Episode_Reward/action_rate: -0.1382
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 2.09s
                      Time elapsed: 00:55:33
                               ETA: 00:03:12

################################################################################
                     [1m Learning iteration 1419/1500 [0m                     

                       Computation: 47097 steps/s (collection: 1.980s, learning 0.107s)
             Mean action noise std: 4.47
          Mean value_function loss: 88.9280
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 87.5240
                       Mean reward: 701.63
               Mean episode length: 233.97
    Episode_Reward/reaching_object: 1.6535
    Episode_Reward/rotating_object: 135.4149
        Episode_Reward/action_rate: -0.1392
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 2.09s
                      Time elapsed: 00:55:36
                               ETA: 00:03:10

################################################################################
                     [1m Learning iteration 1420/1500 [0m                     

                       Computation: 46091 steps/s (collection: 2.019s, learning 0.114s)
             Mean action noise std: 4.47
          Mean value_function loss: 82.9237
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 87.5412
                       Mean reward: 693.23
               Mean episode length: 232.41
    Episode_Reward/reaching_object: 1.6802
    Episode_Reward/rotating_object: 139.2717
        Episode_Reward/action_rate: -0.1409
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 2.13s
                      Time elapsed: 00:55:38
                               ETA: 00:03:07

################################################################################
                     [1m Learning iteration 1421/1500 [0m                     

                       Computation: 47304 steps/s (collection: 1.984s, learning 0.095s)
             Mean action noise std: 4.47
          Mean value_function loss: 81.4918
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 87.5594
                       Mean reward: 666.52
               Mean episode length: 228.58
    Episode_Reward/reaching_object: 1.6520
    Episode_Reward/rotating_object: 135.3244
        Episode_Reward/action_rate: -0.1398
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 2.08s
                      Time elapsed: 00:55:40
                               ETA: 00:03:05

################################################################################
                     [1m Learning iteration 1422/1500 [0m                     

                       Computation: 47000 steps/s (collection: 1.975s, learning 0.117s)
             Mean action noise std: 4.47
          Mean value_function loss: 100.5992
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 87.5710
                       Mean reward: 625.42
               Mean episode length: 221.98
    Episode_Reward/reaching_object: 1.6421
    Episode_Reward/rotating_object: 136.5816
        Episode_Reward/action_rate: -0.1385
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 2.09s
                      Time elapsed: 00:55:42
                               ETA: 00:03:03

################################################################################
                     [1m Learning iteration 1423/1500 [0m                     

                       Computation: 46272 steps/s (collection: 2.004s, learning 0.121s)
             Mean action noise std: 4.48
          Mean value_function loss: 83.0551
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 87.5831
                       Mean reward: 701.85
               Mean episode length: 234.60
    Episode_Reward/reaching_object: 1.6556
    Episode_Reward/rotating_object: 136.2188
        Episode_Reward/action_rate: -0.1396
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 2.12s
                      Time elapsed: 00:55:44
                               ETA: 00:03:00

################################################################################
                     [1m Learning iteration 1424/1500 [0m                     

                       Computation: 47640 steps/s (collection: 1.962s, learning 0.102s)
             Mean action noise std: 4.48
          Mean value_function loss: 95.1383
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 87.5982
                       Mean reward: 740.93
               Mean episode length: 245.09
    Episode_Reward/reaching_object: 1.6474
    Episode_Reward/rotating_object: 136.3011
        Episode_Reward/action_rate: -0.1391
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 2.06s
                      Time elapsed: 00:55:46
                               ETA: 00:02:58

################################################################################
                     [1m Learning iteration 1425/1500 [0m                     

                       Computation: 46179 steps/s (collection: 2.030s, learning 0.099s)
             Mean action noise std: 4.48
          Mean value_function loss: 81.7318
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 87.6166
                       Mean reward: 695.87
               Mean episode length: 235.43
    Episode_Reward/reaching_object: 1.6786
    Episode_Reward/rotating_object: 139.2430
        Episode_Reward/action_rate: -0.1414
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 2.13s
                      Time elapsed: 00:55:48
                               ETA: 00:02:56

################################################################################
                     [1m Learning iteration 1426/1500 [0m                     

                       Computation: 47093 steps/s (collection: 1.963s, learning 0.125s)
             Mean action noise std: 4.48
          Mean value_function loss: 91.5236
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 87.6400
                       Mean reward: 694.53
               Mean episode length: 231.60
    Episode_Reward/reaching_object: 1.6301
    Episode_Reward/rotating_object: 135.5466
        Episode_Reward/action_rate: -0.1381
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 2.09s
                      Time elapsed: 00:55:50
                               ETA: 00:02:53

################################################################################
                     [1m Learning iteration 1427/1500 [0m                     

                       Computation: 47869 steps/s (collection: 1.946s, learning 0.107s)
             Mean action noise std: 4.49
          Mean value_function loss: 82.4937
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 87.6607
                       Mean reward: 700.09
               Mean episode length: 231.58
    Episode_Reward/reaching_object: 1.6333
    Episode_Reward/rotating_object: 135.1238
        Episode_Reward/action_rate: -0.1386
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 2.05s
                      Time elapsed: 00:55:52
                               ETA: 00:02:51

################################################################################
                     [1m Learning iteration 1428/1500 [0m                     

                       Computation: 46468 steps/s (collection: 1.986s, learning 0.130s)
             Mean action noise std: 4.49
          Mean value_function loss: 98.3140
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 87.6717
                       Mean reward: 631.08
               Mean episode length: 217.96
    Episode_Reward/reaching_object: 1.6330
    Episode_Reward/rotating_object: 134.0804
        Episode_Reward/action_rate: -0.1389
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 2.12s
                      Time elapsed: 00:55:54
                               ETA: 00:02:49

################################################################################
                     [1m Learning iteration 1429/1500 [0m                     

                       Computation: 46683 steps/s (collection: 1.990s, learning 0.116s)
             Mean action noise std: 4.49
          Mean value_function loss: 93.0786
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 87.6798
                       Mean reward: 701.31
               Mean episode length: 236.65
    Episode_Reward/reaching_object: 1.6575
    Episode_Reward/rotating_object: 137.1355
        Episode_Reward/action_rate: -0.1408
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 2.11s
                      Time elapsed: 00:55:57
                               ETA: 00:02:46

################################################################################
                     [1m Learning iteration 1430/1500 [0m                     

                       Computation: 47547 steps/s (collection: 1.952s, learning 0.115s)
             Mean action noise std: 4.49
          Mean value_function loss: 94.3119
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 87.6886
                       Mean reward: 699.02
               Mean episode length: 233.01
    Episode_Reward/reaching_object: 1.6617
    Episode_Reward/rotating_object: 139.0113
        Episode_Reward/action_rate: -0.1411
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 2.07s
                      Time elapsed: 00:55:59
                               ETA: 00:02:44

################################################################################
                     [1m Learning iteration 1431/1500 [0m                     

                       Computation: 46569 steps/s (collection: 1.994s, learning 0.117s)
             Mean action noise std: 4.50
          Mean value_function loss: 83.2837
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 87.7028
                       Mean reward: 686.37
               Mean episode length: 232.87
    Episode_Reward/reaching_object: 1.6411
    Episode_Reward/rotating_object: 135.8220
        Episode_Reward/action_rate: -0.1401
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 2.11s
                      Time elapsed: 00:56:01
                               ETA: 00:02:41

################################################################################
                     [1m Learning iteration 1432/1500 [0m                     

                       Computation: 47244 steps/s (collection: 1.979s, learning 0.102s)
             Mean action noise std: 4.50
          Mean value_function loss: 73.2599
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 87.7266
                       Mean reward: 710.03
               Mean episode length: 240.50
    Episode_Reward/reaching_object: 1.6884
    Episode_Reward/rotating_object: 139.8743
        Episode_Reward/action_rate: -0.1441
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 2.08s
                      Time elapsed: 00:56:03
                               ETA: 00:02:39

################################################################################
                     [1m Learning iteration 1433/1500 [0m                     

                       Computation: 46030 steps/s (collection: 2.040s, learning 0.096s)
             Mean action noise std: 4.50
          Mean value_function loss: 83.1233
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 87.7421
                       Mean reward: 659.73
               Mean episode length: 228.88
    Episode_Reward/reaching_object: 1.6669
    Episode_Reward/rotating_object: 134.6413
        Episode_Reward/action_rate: -0.1426
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 2.14s
                      Time elapsed: 00:56:05
                               ETA: 00:02:37

################################################################################
                     [1m Learning iteration 1434/1500 [0m                     

                       Computation: 46130 steps/s (collection: 2.022s, learning 0.109s)
             Mean action noise std: 4.51
          Mean value_function loss: 85.8881
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 87.7635
                       Mean reward: 694.92
               Mean episode length: 231.60
    Episode_Reward/reaching_object: 1.6320
    Episode_Reward/rotating_object: 134.8233
        Episode_Reward/action_rate: -0.1400
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 2.13s
                      Time elapsed: 00:56:07
                               ETA: 00:02:34

################################################################################
                     [1m Learning iteration 1435/1500 [0m                     

                       Computation: 47643 steps/s (collection: 1.973s, learning 0.091s)
             Mean action noise std: 4.51
          Mean value_function loss: 86.9512
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 87.7856
                       Mean reward: 708.46
               Mean episode length: 237.57
    Episode_Reward/reaching_object: 1.6275
    Episode_Reward/rotating_object: 133.4340
        Episode_Reward/action_rate: -0.1398
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 2.06s
                      Time elapsed: 00:56:09
                               ETA: 00:02:32

################################################################################
                     [1m Learning iteration 1436/1500 [0m                     

                       Computation: 46804 steps/s (collection: 1.999s, learning 0.102s)
             Mean action noise std: 4.51
          Mean value_function loss: 85.2876
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 87.8051
                       Mean reward: 636.59
               Mean episode length: 225.96
    Episode_Reward/reaching_object: 1.6643
    Episode_Reward/rotating_object: 137.0383
        Episode_Reward/action_rate: -0.1422
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 2.10s
                      Time elapsed: 00:56:11
                               ETA: 00:02:30

################################################################################
                     [1m Learning iteration 1437/1500 [0m                     

                       Computation: 48775 steps/s (collection: 1.904s, learning 0.111s)
             Mean action noise std: 4.52
          Mean value_function loss: 74.2385
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 87.8289
                       Mean reward: 709.43
               Mean episode length: 235.33
    Episode_Reward/reaching_object: 1.6886
    Episode_Reward/rotating_object: 141.1832
        Episode_Reward/action_rate: -0.1448
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 2.02s
                      Time elapsed: 00:56:13
                               ETA: 00:02:27

################################################################################
                     [1m Learning iteration 1438/1500 [0m                     

                       Computation: 47038 steps/s (collection: 1.974s, learning 0.116s)
             Mean action noise std: 4.52
          Mean value_function loss: 79.2629
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 87.8499
                       Mean reward: 675.96
               Mean episode length: 229.04
    Episode_Reward/reaching_object: 1.6562
    Episode_Reward/rotating_object: 135.6579
        Episode_Reward/action_rate: -0.1426
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 2.09s
                      Time elapsed: 00:56:15
                               ETA: 00:02:25

################################################################################
                     [1m Learning iteration 1439/1500 [0m                     

                       Computation: 47963 steps/s (collection: 1.934s, learning 0.115s)
             Mean action noise std: 4.52
          Mean value_function loss: 70.3970
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 87.8582
                       Mean reward: 718.63
               Mean episode length: 239.69
    Episode_Reward/reaching_object: 1.6912
    Episode_Reward/rotating_object: 139.6209
        Episode_Reward/action_rate: -0.1448
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 2.05s
                      Time elapsed: 00:56:17
                               ETA: 00:02:23

################################################################################
                     [1m Learning iteration 1440/1500 [0m                     

                       Computation: 48683 steps/s (collection: 1.926s, learning 0.093s)
             Mean action noise std: 4.52
          Mean value_function loss: 84.5582
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 87.8678
                       Mean reward: 712.95
               Mean episode length: 232.51
    Episode_Reward/reaching_object: 1.6332
    Episode_Reward/rotating_object: 135.7153
        Episode_Reward/action_rate: -0.1411
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 2.02s
                      Time elapsed: 00:56:19
                               ETA: 00:02:20

################################################################################
                     [1m Learning iteration 1441/1500 [0m                     

                       Computation: 48148 steps/s (collection: 1.943s, learning 0.099s)
             Mean action noise std: 4.52
          Mean value_function loss: 81.6144
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 87.8788
                       Mean reward: 698.60
               Mean episode length: 235.80
    Episode_Reward/reaching_object: 1.6641
    Episode_Reward/rotating_object: 135.9957
        Episode_Reward/action_rate: -0.1442
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 2.04s
                      Time elapsed: 00:56:21
                               ETA: 00:02:18

################################################################################
                     [1m Learning iteration 1442/1500 [0m                     

                       Computation: 48298 steps/s (collection: 1.931s, learning 0.104s)
             Mean action noise std: 4.53
          Mean value_function loss: 88.9127
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 87.8948
                       Mean reward: 652.91
               Mean episode length: 227.74
    Episode_Reward/reaching_object: 1.6398
    Episode_Reward/rotating_object: 134.7658
        Episode_Reward/action_rate: -0.1418
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 2.04s
                      Time elapsed: 00:56:23
                               ETA: 00:02:16

################################################################################
                     [1m Learning iteration 1443/1500 [0m                     

                       Computation: 45166 steps/s (collection: 2.051s, learning 0.126s)
             Mean action noise std: 4.53
          Mean value_function loss: 85.9827
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 87.9089
                       Mean reward: 699.50
               Mean episode length: 241.58
    Episode_Reward/reaching_object: 1.6694
    Episode_Reward/rotating_object: 137.7265
        Episode_Reward/action_rate: -0.1444
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 2.18s
                      Time elapsed: 00:56:26
                               ETA: 00:02:13

################################################################################
                     [1m Learning iteration 1444/1500 [0m                     

                       Computation: 47500 steps/s (collection: 1.975s, learning 0.095s)
             Mean action noise std: 4.53
          Mean value_function loss: 94.0629
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 87.9287
                       Mean reward: 709.55
               Mean episode length: 237.71
    Episode_Reward/reaching_object: 1.6597
    Episode_Reward/rotating_object: 138.5041
        Episode_Reward/action_rate: -0.1433
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 2.07s
                      Time elapsed: 00:56:28
                               ETA: 00:02:11

################################################################################
                     [1m Learning iteration 1445/1500 [0m                     

                       Computation: 46322 steps/s (collection: 2.001s, learning 0.121s)
             Mean action noise std: 4.54
          Mean value_function loss: 93.6752
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 87.9558
                       Mean reward: 676.15
               Mean episode length: 237.85
    Episode_Reward/reaching_object: 1.6585
    Episode_Reward/rotating_object: 134.6566
        Episode_Reward/action_rate: -0.1435
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 2.12s
                      Time elapsed: 00:56:30
                               ETA: 00:02:08

################################################################################
                     [1m Learning iteration 1446/1500 [0m                     

                       Computation: 48457 steps/s (collection: 1.935s, learning 0.094s)
             Mean action noise std: 4.54
          Mean value_function loss: 73.4551
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 87.9675
                       Mean reward: 695.01
               Mean episode length: 230.60
    Episode_Reward/reaching_object: 1.6763
    Episode_Reward/rotating_object: 138.1686
        Episode_Reward/action_rate: -0.1450
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 2.03s
                      Time elapsed: 00:56:32
                               ETA: 00:02:06

################################################################################
                     [1m Learning iteration 1447/1500 [0m                     

                       Computation: 47629 steps/s (collection: 1.951s, learning 0.113s)
             Mean action noise std: 4.54
          Mean value_function loss: 78.0895
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 87.9793
                       Mean reward: 674.83
               Mean episode length: 228.76
    Episode_Reward/reaching_object: 1.6738
    Episode_Reward/rotating_object: 139.8290
        Episode_Reward/action_rate: -0.1445
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 2.06s
                      Time elapsed: 00:56:34
                               ETA: 00:02:04

################################################################################
                     [1m Learning iteration 1448/1500 [0m                     

                       Computation: 46297 steps/s (collection: 2.015s, learning 0.109s)
             Mean action noise std: 4.55
          Mean value_function loss: 69.6302
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 87.9986
                       Mean reward: 699.72
               Mean episode length: 235.67
    Episode_Reward/reaching_object: 1.6824
    Episode_Reward/rotating_object: 139.1855
        Episode_Reward/action_rate: -0.1454
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 2.12s
                      Time elapsed: 00:56:36
                               ETA: 00:02:01

################################################################################
                     [1m Learning iteration 1449/1500 [0m                     

                       Computation: 48400 steps/s (collection: 1.923s, learning 0.108s)
             Mean action noise std: 4.55
          Mean value_function loss: 87.2971
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 88.0186
                       Mean reward: 658.40
               Mean episode length: 220.75
    Episode_Reward/reaching_object: 1.6846
    Episode_Reward/rotating_object: 139.4290
        Episode_Reward/action_rate: -0.1459
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 2.03s
                      Time elapsed: 00:56:38
                               ETA: 00:01:59

################################################################################
                     [1m Learning iteration 1450/1500 [0m                     

                       Computation: 47890 steps/s (collection: 1.958s, learning 0.095s)
             Mean action noise std: 4.55
          Mean value_function loss: 95.2577
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 88.0243
                       Mean reward: 657.61
               Mean episode length: 229.32
    Episode_Reward/reaching_object: 1.6257
    Episode_Reward/rotating_object: 131.3972
        Episode_Reward/action_rate: -0.1423
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 2.05s
                      Time elapsed: 00:56:40
                               ETA: 00:01:57

################################################################################
                     [1m Learning iteration 1451/1500 [0m                     

                       Computation: 46706 steps/s (collection: 2.009s, learning 0.096s)
             Mean action noise std: 4.55
          Mean value_function loss: 105.4655
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 88.0315
                       Mean reward: 637.55
               Mean episode length: 217.84
    Episode_Reward/reaching_object: 1.6127
    Episode_Reward/rotating_object: 132.3391
        Episode_Reward/action_rate: -0.1411
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 2.10s
                      Time elapsed: 00:56:42
                               ETA: 00:01:54

################################################################################
                     [1m Learning iteration 1452/1500 [0m                     

                       Computation: 48593 steps/s (collection: 1.931s, learning 0.092s)
             Mean action noise std: 4.55
          Mean value_function loss: 93.2636
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 88.0428
                       Mean reward: 684.17
               Mean episode length: 227.96
    Episode_Reward/reaching_object: 1.6727
    Episode_Reward/rotating_object: 136.9592
        Episode_Reward/action_rate: -0.1457
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 2.02s
                      Time elapsed: 00:56:44
                               ETA: 00:01:52

################################################################################
                     [1m Learning iteration 1453/1500 [0m                     

                       Computation: 44578 steps/s (collection: 2.021s, learning 0.185s)
             Mean action noise std: 4.56
          Mean value_function loss: 91.9496
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 88.0562
                       Mean reward: 613.26
               Mean episode length: 221.14
    Episode_Reward/reaching_object: 1.6090
    Episode_Reward/rotating_object: 130.7792
        Episode_Reward/action_rate: -0.1404
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 2.21s
                      Time elapsed: 00:56:46
                               ETA: 00:01:50

################################################################################
                     [1m Learning iteration 1454/1500 [0m                     

                       Computation: 47267 steps/s (collection: 1.964s, learning 0.116s)
             Mean action noise std: 4.56
          Mean value_function loss: 92.2149
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 88.0759
                       Mean reward: 675.16
               Mean episode length: 227.13
    Episode_Reward/reaching_object: 1.6410
    Episode_Reward/rotating_object: 135.8543
        Episode_Reward/action_rate: -0.1439
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 2.08s
                      Time elapsed: 00:56:49
                               ETA: 00:01:47

################################################################################
                     [1m Learning iteration 1455/1500 [0m                     

                       Computation: 47748 steps/s (collection: 1.933s, learning 0.126s)
             Mean action noise std: 4.56
          Mean value_function loss: 95.9128
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 88.0998
                       Mean reward: 636.37
               Mean episode length: 214.42
    Episode_Reward/reaching_object: 1.6312
    Episode_Reward/rotating_object: 134.2522
        Episode_Reward/action_rate: -0.1423
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 2.06s
                      Time elapsed: 00:56:51
                               ETA: 00:01:45

################################################################################
                     [1m Learning iteration 1456/1500 [0m                     

                       Computation: 45581 steps/s (collection: 1.969s, learning 0.188s)
             Mean action noise std: 4.56
          Mean value_function loss: 81.9521
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 88.1121
                       Mean reward: 651.14
               Mean episode length: 219.39
    Episode_Reward/reaching_object: 1.6536
    Episode_Reward/rotating_object: 135.8654
        Episode_Reward/action_rate: -0.1442
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 2.16s
                      Time elapsed: 00:56:53
                               ETA: 00:01:43

################################################################################
                     [1m Learning iteration 1457/1500 [0m                     

                       Computation: 45830 steps/s (collection: 2.015s, learning 0.130s)
             Mean action noise std: 4.56
          Mean value_function loss: 85.0503
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 88.1180
                       Mean reward: 705.14
               Mean episode length: 230.87
    Episode_Reward/reaching_object: 1.6747
    Episode_Reward/rotating_object: 139.7151
        Episode_Reward/action_rate: -0.1455
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 2.14s
                      Time elapsed: 00:56:55
                               ETA: 00:01:40

################################################################################
                     [1m Learning iteration 1458/1500 [0m                     

                       Computation: 47673 steps/s (collection: 1.957s, learning 0.105s)
             Mean action noise std: 4.57
          Mean value_function loss: 70.6770
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 88.1297
                       Mean reward: 680.82
               Mean episode length: 233.09
    Episode_Reward/reaching_object: 1.6893
    Episode_Reward/rotating_object: 139.8461
        Episode_Reward/action_rate: -0.1468
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 2.06s
                      Time elapsed: 00:56:57
                               ETA: 00:01:38

################################################################################
                     [1m Learning iteration 1459/1500 [0m                     

                       Computation: 47103 steps/s (collection: 1.997s, learning 0.090s)
             Mean action noise std: 4.57
          Mean value_function loss: 78.4688
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 88.1458
                       Mean reward: 719.69
               Mean episode length: 241.84
    Episode_Reward/reaching_object: 1.6834
    Episode_Reward/rotating_object: 138.3871
        Episode_Reward/action_rate: -0.1471
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 2.09s
                      Time elapsed: 00:56:59
                               ETA: 00:01:36

################################################################################
                     [1m Learning iteration 1460/1500 [0m                     

                       Computation: 47206 steps/s (collection: 1.988s, learning 0.095s)
             Mean action noise std: 4.57
          Mean value_function loss: 89.4470
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 88.1607
                       Mean reward: 656.94
               Mean episode length: 220.51
    Episode_Reward/reaching_object: 1.6517
    Episode_Reward/rotating_object: 137.1157
        Episode_Reward/action_rate: -0.1445
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 2.08s
                      Time elapsed: 00:57:01
                               ETA: 00:01:33

################################################################################
                     [1m Learning iteration 1461/1500 [0m                     

                       Computation: 47372 steps/s (collection: 1.983s, learning 0.093s)
             Mean action noise std: 4.58
          Mean value_function loss: 87.1737
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 88.1823
                       Mean reward: 670.84
               Mean episode length: 229.49
    Episode_Reward/reaching_object: 1.6514
    Episode_Reward/rotating_object: 134.4531
        Episode_Reward/action_rate: -0.1443
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 2.08s
                      Time elapsed: 00:57:03
                               ETA: 00:01:31

################################################################################
                     [1m Learning iteration 1462/1500 [0m                     

                       Computation: 45964 steps/s (collection: 2.037s, learning 0.102s)
             Mean action noise std: 4.58
          Mean value_function loss: 97.2917
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 88.2030
                       Mean reward: 677.48
               Mean episode length: 230.94
    Episode_Reward/reaching_object: 1.6454
    Episode_Reward/rotating_object: 131.8500
        Episode_Reward/action_rate: -0.1448
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 2.14s
                      Time elapsed: 00:57:05
                               ETA: 00:01:28

################################################################################
                     [1m Learning iteration 1463/1500 [0m                     

                       Computation: 48754 steps/s (collection: 1.921s, learning 0.095s)
             Mean action noise std: 4.58
          Mean value_function loss: 91.4397
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 88.2187
                       Mean reward: 709.38
               Mean episode length: 231.73
    Episode_Reward/reaching_object: 1.6440
    Episode_Reward/rotating_object: 135.5975
        Episode_Reward/action_rate: -0.1442
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 2.02s
                      Time elapsed: 00:57:07
                               ETA: 00:01:26

################################################################################
                     [1m Learning iteration 1464/1500 [0m                     

                       Computation: 48501 steps/s (collection: 1.934s, learning 0.093s)
             Mean action noise std: 4.58
          Mean value_function loss: 90.3481
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 88.2280
                       Mean reward: 685.07
               Mean episode length: 229.75
    Episode_Reward/reaching_object: 1.6403
    Episode_Reward/rotating_object: 135.4738
        Episode_Reward/action_rate: -0.1446
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 2.03s
                      Time elapsed: 00:57:09
                               ETA: 00:01:24

################################################################################
                     [1m Learning iteration 1465/1500 [0m                     

                       Computation: 45299 steps/s (collection: 2.043s, learning 0.128s)
             Mean action noise std: 4.59
          Mean value_function loss: 90.0036
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 88.2414
                       Mean reward: 683.74
               Mean episode length: 231.33
    Episode_Reward/reaching_object: 1.6747
    Episode_Reward/rotating_object: 137.3967
        Episode_Reward/action_rate: -0.1466
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 2.17s
                      Time elapsed: 00:57:12
                               ETA: 00:01:21

################################################################################
                     [1m Learning iteration 1466/1500 [0m                     

                       Computation: 46649 steps/s (collection: 1.972s, learning 0.135s)
             Mean action noise std: 4.59
          Mean value_function loss: 77.0913
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 88.2618
                       Mean reward: 701.93
               Mean episode length: 233.74
    Episode_Reward/reaching_object: 1.6581
    Episode_Reward/rotating_object: 135.5221
        Episode_Reward/action_rate: -0.1457
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 2.11s
                      Time elapsed: 00:57:14
                               ETA: 00:01:19

################################################################################
                     [1m Learning iteration 1467/1500 [0m                     

                       Computation: 46718 steps/s (collection: 2.004s, learning 0.100s)
             Mean action noise std: 4.59
          Mean value_function loss: 103.1234
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 88.2823
                       Mean reward: 696.48
               Mean episode length: 230.30
    Episode_Reward/reaching_object: 1.6568
    Episode_Reward/rotating_object: 136.0447
        Episode_Reward/action_rate: -0.1464
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 2.10s
                      Time elapsed: 00:57:16
                               ETA: 00:01:17

################################################################################
                     [1m Learning iteration 1468/1500 [0m                     

                       Computation: 46173 steps/s (collection: 2.002s, learning 0.127s)
             Mean action noise std: 4.59
          Mean value_function loss: 95.0459
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 88.2960
                       Mean reward: 738.86
               Mean episode length: 245.96
    Episode_Reward/reaching_object: 1.6761
    Episode_Reward/rotating_object: 137.5414
        Episode_Reward/action_rate: -0.1472
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 2.13s
                      Time elapsed: 00:57:18
                               ETA: 00:01:14

################################################################################
                     [1m Learning iteration 1469/1500 [0m                     

                       Computation: 45343 steps/s (collection: 2.003s, learning 0.165s)
             Mean action noise std: 4.60
          Mean value_function loss: 101.2848
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 88.3025
                       Mean reward: 692.44
               Mean episode length: 230.93
    Episode_Reward/reaching_object: 1.6719
    Episode_Reward/rotating_object: 136.4732
        Episode_Reward/action_rate: -0.1473
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 2.17s
                      Time elapsed: 00:57:20
                               ETA: 00:01:12

################################################################################
                     [1m Learning iteration 1470/1500 [0m                     

                       Computation: 44679 steps/s (collection: 2.094s, learning 0.107s)
             Mean action noise std: 4.60
          Mean value_function loss: 97.2826
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 88.3184
                       Mean reward: 701.98
               Mean episode length: 232.83
    Episode_Reward/reaching_object: 1.6568
    Episode_Reward/rotating_object: 136.8026
        Episode_Reward/action_rate: -0.1455
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 2.20s
                      Time elapsed: 00:57:22
                               ETA: 00:01:10

################################################################################
                     [1m Learning iteration 1471/1500 [0m                     

                       Computation: 48097 steps/s (collection: 1.949s, learning 0.095s)
             Mean action noise std: 4.60
          Mean value_function loss: 121.2411
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 88.3354
                       Mean reward: 679.19
               Mean episode length: 224.64
    Episode_Reward/reaching_object: 1.6328
    Episode_Reward/rotating_object: 131.7592
        Episode_Reward/action_rate: -0.1438
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 2.04s
                      Time elapsed: 00:57:24
                               ETA: 00:01:07

################################################################################
                     [1m Learning iteration 1472/1500 [0m                     

                       Computation: 46921 steps/s (collection: 1.999s, learning 0.096s)
             Mean action noise std: 4.60
          Mean value_function loss: 126.7186
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 88.3472
                       Mean reward: 636.76
               Mean episode length: 214.97
    Episode_Reward/reaching_object: 1.6185
    Episode_Reward/rotating_object: 130.4584
        Episode_Reward/action_rate: -0.1427
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 2.10s
                      Time elapsed: 00:57:26
                               ETA: 00:01:05

################################################################################
                     [1m Learning iteration 1473/1500 [0m                     

                       Computation: 44900 steps/s (collection: 2.042s, learning 0.148s)
             Mean action noise std: 4.61
          Mean value_function loss: 97.4099
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 88.3560
                       Mean reward: 709.82
               Mean episode length: 234.29
    Episode_Reward/reaching_object: 1.6479
    Episode_Reward/rotating_object: 133.9498
        Episode_Reward/action_rate: -0.1457
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 2.19s
                      Time elapsed: 00:57:29
                               ETA: 00:01:03

################################################################################
                     [1m Learning iteration 1474/1500 [0m                     

                       Computation: 46428 steps/s (collection: 2.008s, learning 0.109s)
             Mean action noise std: 4.61
          Mean value_function loss: 114.0355
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 88.3659
                       Mean reward: 686.81
               Mean episode length: 230.99
    Episode_Reward/reaching_object: 1.6597
    Episode_Reward/rotating_object: 134.1730
        Episode_Reward/action_rate: -0.1461
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 2.12s
                      Time elapsed: 00:57:31
                               ETA: 00:01:00

################################################################################
                     [1m Learning iteration 1475/1500 [0m                     

                       Computation: 47551 steps/s (collection: 1.952s, learning 0.116s)
             Mean action noise std: 4.61
          Mean value_function loss: 118.6469
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 88.3717
                       Mean reward: 686.09
               Mean episode length: 230.28
    Episode_Reward/reaching_object: 1.6364
    Episode_Reward/rotating_object: 132.5676
        Episode_Reward/action_rate: -0.1443
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 2.07s
                      Time elapsed: 00:57:33
                               ETA: 00:00:58

################################################################################
                     [1m Learning iteration 1476/1500 [0m                     

                       Computation: 47040 steps/s (collection: 1.980s, learning 0.110s)
             Mean action noise std: 4.61
          Mean value_function loss: 124.3509
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 88.3783
                       Mean reward: 670.18
               Mean episode length: 222.59
    Episode_Reward/reaching_object: 1.6346
    Episode_Reward/rotating_object: 132.2743
        Episode_Reward/action_rate: -0.1444
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 2.09s
                      Time elapsed: 00:57:35
                               ETA: 00:00:56

################################################################################
                     [1m Learning iteration 1477/1500 [0m                     

                       Computation: 46875 steps/s (collection: 2.006s, learning 0.091s)
             Mean action noise std: 4.61
          Mean value_function loss: 144.7504
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 88.3900
                       Mean reward: 639.27
               Mean episode length: 218.16
    Episode_Reward/reaching_object: 1.5816
    Episode_Reward/rotating_object: 126.1244
        Episode_Reward/action_rate: -0.1409
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 2.10s
                      Time elapsed: 00:57:37
                               ETA: 00:00:53

################################################################################
                     [1m Learning iteration 1478/1500 [0m                     

                       Computation: 47421 steps/s (collection: 1.967s, learning 0.106s)
             Mean action noise std: 4.61
          Mean value_function loss: 114.2863
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 88.4064
                       Mean reward: 681.24
               Mean episode length: 227.15
    Episode_Reward/reaching_object: 1.6294
    Episode_Reward/rotating_object: 132.4838
        Episode_Reward/action_rate: -0.1436
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 2.07s
                      Time elapsed: 00:57:39
                               ETA: 00:00:51

################################################################################
                     [1m Learning iteration 1479/1500 [0m                     

                       Computation: 46789 steps/s (collection: 2.001s, learning 0.100s)
             Mean action noise std: 4.62
          Mean value_function loss: 104.7356
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 88.4237
                       Mean reward: 664.75
               Mean episode length: 224.70
    Episode_Reward/reaching_object: 1.6410
    Episode_Reward/rotating_object: 131.5940
        Episode_Reward/action_rate: -0.1447
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 2.10s
                      Time elapsed: 00:57:41
                               ETA: 00:00:49

################################################################################
                     [1m Learning iteration 1480/1500 [0m                     

                       Computation: 45577 steps/s (collection: 1.998s, learning 0.159s)
             Mean action noise std: 4.62
          Mean value_function loss: 101.4748
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 88.4392
                       Mean reward: 675.01
               Mean episode length: 226.98
    Episode_Reward/reaching_object: 1.6753
    Episode_Reward/rotating_object: 135.4052
        Episode_Reward/action_rate: -0.1480
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 2.16s
                      Time elapsed: 00:57:43
                               ETA: 00:00:46

################################################################################
                     [1m Learning iteration 1481/1500 [0m                     

                       Computation: 47640 steps/s (collection: 1.967s, learning 0.097s)
             Mean action noise std: 4.62
          Mean value_function loss: 85.8683
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 88.4568
                       Mean reward: 695.96
               Mean episode length: 236.10
    Episode_Reward/reaching_object: 1.6691
    Episode_Reward/rotating_object: 133.8558
        Episode_Reward/action_rate: -0.1478
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 2.06s
                      Time elapsed: 00:57:45
                               ETA: 00:00:44

################################################################################
                     [1m Learning iteration 1482/1500 [0m                     

                       Computation: 47034 steps/s (collection: 1.994s, learning 0.097s)
             Mean action noise std: 4.62
          Mean value_function loss: 105.9874
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 88.4709
                       Mean reward: 667.52
               Mean episode length: 225.27
    Episode_Reward/reaching_object: 1.6613
    Episode_Reward/rotating_object: 135.1323
        Episode_Reward/action_rate: -0.1464
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 2.09s
                      Time elapsed: 00:57:47
                               ETA: 00:00:42

################################################################################
                     [1m Learning iteration 1483/1500 [0m                     

                       Computation: 44225 steps/s (collection: 2.043s, learning 0.180s)
             Mean action noise std: 4.63
          Mean value_function loss: 112.3911
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 88.4886
                       Mean reward: 636.42
               Mean episode length: 228.23
    Episode_Reward/reaching_object: 1.6548
    Episode_Reward/rotating_object: 131.8530
        Episode_Reward/action_rate: -0.1461
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 2.22s
                      Time elapsed: 00:57:50
                               ETA: 00:00:39

################################################################################
                     [1m Learning iteration 1484/1500 [0m                     

                       Computation: 48141 steps/s (collection: 1.950s, learning 0.092s)
             Mean action noise std: 4.63
          Mean value_function loss: 84.1222
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 88.5107
                       Mean reward: 670.70
               Mean episode length: 228.52
    Episode_Reward/reaching_object: 1.6516
    Episode_Reward/rotating_object: 131.2125
        Episode_Reward/action_rate: -0.1461
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 2.04s
                      Time elapsed: 00:57:52
                               ETA: 00:00:37

################################################################################
                     [1m Learning iteration 1485/1500 [0m                     

                       Computation: 47312 steps/s (collection: 1.963s, learning 0.115s)
             Mean action noise std: 4.63
          Mean value_function loss: 95.5504
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 88.5209
                       Mean reward: 700.90
               Mean episode length: 232.13
    Episode_Reward/reaching_object: 1.6709
    Episode_Reward/rotating_object: 135.4025
        Episode_Reward/action_rate: -0.1487
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 2.08s
                      Time elapsed: 00:57:54
                               ETA: 00:00:35

################################################################################
                     [1m Learning iteration 1486/1500 [0m                     

                       Computation: 47795 steps/s (collection: 1.938s, learning 0.119s)
             Mean action noise std: 4.63
          Mean value_function loss: 82.0571
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 88.5343
                       Mean reward: 738.08
               Mean episode length: 239.44
    Episode_Reward/reaching_object: 1.6919
    Episode_Reward/rotating_object: 138.8260
        Episode_Reward/action_rate: -0.1498
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 2.06s
                      Time elapsed: 00:57:56
                               ETA: 00:00:32

################################################################################
                     [1m Learning iteration 1487/1500 [0m                     

                       Computation: 47500 steps/s (collection: 1.959s, learning 0.111s)
             Mean action noise std: 4.64
          Mean value_function loss: 104.5803
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 88.5457
                       Mean reward: 662.35
               Mean episode length: 226.93
    Episode_Reward/reaching_object: 1.6383
    Episode_Reward/rotating_object: 132.6844
        Episode_Reward/action_rate: -0.1466
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 2.07s
                      Time elapsed: 00:57:58
                               ETA: 00:00:30

################################################################################
                     [1m Learning iteration 1488/1500 [0m                     

                       Computation: 47730 steps/s (collection: 1.957s, learning 0.103s)
             Mean action noise std: 4.64
          Mean value_function loss: 88.1680
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 88.5573
                       Mean reward: 701.98
               Mean episode length: 231.46
    Episode_Reward/reaching_object: 1.6656
    Episode_Reward/rotating_object: 136.8378
        Episode_Reward/action_rate: -0.1481
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 2.06s
                      Time elapsed: 00:58:00
                               ETA: 00:00:28

################################################################################
                     [1m Learning iteration 1489/1500 [0m                     

                       Computation: 48212 steps/s (collection: 1.944s, learning 0.095s)
             Mean action noise std: 4.64
          Mean value_function loss: 98.9562
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 88.5676
                       Mean reward: 670.62
               Mean episode length: 229.55
    Episode_Reward/reaching_object: 1.6264
    Episode_Reward/rotating_object: 129.4878
        Episode_Reward/action_rate: -0.1456
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 2.04s
                      Time elapsed: 00:58:02
                               ETA: 00:00:25

################################################################################
                     [1m Learning iteration 1490/1500 [0m                     

                       Computation: 47590 steps/s (collection: 1.968s, learning 0.097s)
             Mean action noise std: 4.64
          Mean value_function loss: 82.2793
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 88.5812
                       Mean reward: 710.20
               Mean episode length: 234.00
    Episode_Reward/reaching_object: 1.6918
    Episode_Reward/rotating_object: 136.7857
        Episode_Reward/action_rate: -0.1508
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 2.07s
                      Time elapsed: 00:58:04
                               ETA: 00:00:23

################################################################################
                     [1m Learning iteration 1491/1500 [0m                     

                       Computation: 48583 steps/s (collection: 1.925s, learning 0.098s)
             Mean action noise std: 4.65
          Mean value_function loss: 61.6586
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 88.5974
                       Mean reward: 702.73
               Mean episode length: 235.53
    Episode_Reward/reaching_object: 1.7126
    Episode_Reward/rotating_object: 138.7260
        Episode_Reward/action_rate: -0.1526
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 2.02s
                      Time elapsed: 00:58:06
                               ETA: 00:00:21

################################################################################
                     [1m Learning iteration 1492/1500 [0m                     

                       Computation: 48342 steps/s (collection: 1.936s, learning 0.097s)
             Mean action noise std: 4.65
          Mean value_function loss: 76.1610
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 88.6043
                       Mean reward: 703.17
               Mean episode length: 241.02
    Episode_Reward/reaching_object: 1.7046
    Episode_Reward/rotating_object: 141.3392
        Episode_Reward/action_rate: -0.1525
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 2.03s
                      Time elapsed: 00:58:08
                               ETA: 00:00:18

################################################################################
                     [1m Learning iteration 1493/1500 [0m                     

                       Computation: 47191 steps/s (collection: 1.968s, learning 0.115s)
             Mean action noise std: 4.65
          Mean value_function loss: 67.5194
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 88.6103
                       Mean reward: 700.67
               Mean episode length: 230.93
    Episode_Reward/reaching_object: 1.7067
    Episode_Reward/rotating_object: 139.7175
        Episode_Reward/action_rate: -0.1528
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 2.08s
                      Time elapsed: 00:58:10
                               ETA: 00:00:16

################################################################################
                     [1m Learning iteration 1494/1500 [0m                     

                       Computation: 48102 steps/s (collection: 1.935s, learning 0.109s)
             Mean action noise std: 4.65
          Mean value_function loss: 88.8677
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 88.6159
                       Mean reward: 701.29
               Mean episode length: 230.58
    Episode_Reward/reaching_object: 1.6852
    Episode_Reward/rotating_object: 139.7893
        Episode_Reward/action_rate: -0.1505
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 2.04s
                      Time elapsed: 00:58:12
                               ETA: 00:00:14

################################################################################
                     [1m Learning iteration 1495/1500 [0m                     

                       Computation: 47093 steps/s (collection: 1.976s, learning 0.111s)
             Mean action noise std: 4.65
          Mean value_function loss: 92.4137
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 88.6295
                       Mean reward: 677.10
               Mean episode length: 226.69
    Episode_Reward/reaching_object: 1.6851
    Episode_Reward/rotating_object: 138.3488
        Episode_Reward/action_rate: -0.1516
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 2.09s
                      Time elapsed: 00:58:14
                               ETA: 00:00:11

################################################################################
                     [1m Learning iteration 1496/1500 [0m                     

                       Computation: 47324 steps/s (collection: 1.973s, learning 0.104s)
             Mean action noise std: 4.66
          Mean value_function loss: 83.4351
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 88.6511
                       Mean reward: 696.11
               Mean episode length: 232.47
    Episode_Reward/reaching_object: 1.6559
    Episode_Reward/rotating_object: 136.8332
        Episode_Reward/action_rate: -0.1498
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 2.08s
                      Time elapsed: 00:58:16
                               ETA: 00:00:09

################################################################################
                     [1m Learning iteration 1497/1500 [0m                     

                       Computation: 47115 steps/s (collection: 1.976s, learning 0.111s)
             Mean action noise std: 4.66
          Mean value_function loss: 87.1779
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 88.6668
                       Mean reward: 671.30
               Mean episode length: 235.08
    Episode_Reward/reaching_object: 1.7103
    Episode_Reward/rotating_object: 140.1734
        Episode_Reward/action_rate: -0.1539
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 2.09s
                      Time elapsed: 00:58:19
                               ETA: 00:00:07

################################################################################
                     [1m Learning iteration 1498/1500 [0m                     

                       Computation: 46806 steps/s (collection: 1.998s, learning 0.103s)
             Mean action noise std: 4.66
          Mean value_function loss: 87.4558
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 88.6836
                       Mean reward: 692.00
               Mean episode length: 228.35
    Episode_Reward/reaching_object: 1.6839
    Episode_Reward/rotating_object: 138.8289
        Episode_Reward/action_rate: -0.1526
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 2.10s
                      Time elapsed: 00:58:21
                               ETA: 00:00:04

################################################################################
                     [1m Learning iteration 1499/1500 [0m                     

                       Computation: 47027 steps/s (collection: 1.970s, learning 0.120s)
             Mean action noise std: 4.67
          Mean value_function loss: 83.0185
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 88.7069
                       Mean reward: 665.73
               Mean episode length: 226.33
    Episode_Reward/reaching_object: 1.6420
    Episode_Reward/rotating_object: 134.0979
        Episode_Reward/action_rate: -0.1492
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 2.09s
                      Time elapsed: 00:58:23
                               ETA: 00:00:02

